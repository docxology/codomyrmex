# Integration Template Configuration
# This is a template configuration file for creating multi-module integration examples
# Copy this file and customize it for your specific integration scenario

# Output settings
output:
  format: json                    # Output format: json or text
  file: output/integration_template_results.json  # Output file path
  compress: false                 # Whether to compress output

# Logging configuration
logging:
  level: INFO                     # Log level: DEBUG, INFO, WARNING, ERROR
  file: logs/integration_template.log  # Log file path
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"  # Log format
  max_file_size: 10485760         # Max log file size in bytes (10MB)
  backup_count: 5                 # Number of backup log files

# Integration-specific configuration
integration:
  workflow_id: "integration_template_workflow"  # Unique workflow identifier
  fail_fast: false                # Stop on first step failure
  enable_events: true             # Enable event-driven communication
  max_execution_time: 300         # Maximum execution time in seconds
  retry_failed_steps: true        # Retry failed workflow steps
  max_retries: 2                  # Maximum retry attempts per step

  # Modules to integrate
  modules:
    - "{module1}"
    - "{module2}"
    - "{module3}"

  # Integration scenarios to execute
  scenarios:
    - name: "basic_integration"
      description: "Basic multi-module integration workflow"
      timeout: 120
      steps:
        - name: "data_ingestion"
          module: "{module1}"
          operation: "ingest_data"
          parameters:
            source: "sample_data"
            format: "json"
          timeout: 30
          retry_count: 2

        - name: "data_processing"
          module: "{module2}"
          operation: "process_data"
          parameters:
            input: "ingested_data"
            transformations:
              - "normalize"
              - "validate"
          depends_on:
            - "data_ingestion"
          timeout: 60
          retry_count: 1

        - name: "result_persistence"
          module: "{module3}"
          operation: "save_results"
          parameters:
            data: "processed_data"
            destination: "database"
            table: "integration_results"
          depends_on:
            - "data_processing"
          timeout: 30
          retry_count: 2

    - name: "advanced_workflow"
      description: "Advanced workflow with parallel processing and error handling"
      timeout: 180
      parallel_execution: true
      steps:
        - name: "input_validation"
          module: "{module1}"
          operation: "validate_input"
          parameters:
            strict: true
            schema: "strict_schema.json"
          timeout: 20

        - name: "parallel_processing_a"
          module: "{module2}"
          operation: "parallel_process"
          parameters:
            workers: 3
            task_type: "analysis"
            priority: "high"
          depends_on:
            - "input_validation"
          timeout: 90

        - name: "parallel_processing_b"
          module: "{module2}"
          operation: "parallel_process"
          parameters:
            workers: 2
            task_type: "transformation"
            priority: "medium"
          depends_on:
            - "input_validation"
          timeout: 60

        - name: "quality_assurance"
          module: "{module3}"
          operation: "quality_check"
          parameters:
            threshold: 0.95
            metrics:
              - "accuracy"
              - "completeness"
              - "consistency"
          depends_on:
            - "parallel_processing_a"
            - "parallel_processing_b"
          timeout: 45

        - name: "final_reporting"
          module: "{module3}"
          operation: "generate_report"
          parameters:
            format: "comprehensive"
            include_metrics: true
            include_visualizations: true
          depends_on:
            - "quality_assurance"
          timeout: 30

# Module-specific configurations
{module1}:
  name: "{module1}"
  version: "1.0.0"
  config:
    data_sources:
      - "api"
      - "filesystem"
      - "database"
    ingestion_batch_size: 100
    validation_enabled: true
    error_handling: "strict"

{module2}:
  name: "{module2}"
  version: "1.0.0"
  config:
    processing_engine: "parallel"
    max_workers: 4
    memory_limit: "1GB"
    temp_directory: "/tmp/integration_temp"
    enable_caching: true

{module3}:
  name: "{module3}"
  version: "1.0.0"
  config:
    storage_backend: "database"
    retention_policy: "30_days"
    backup_enabled: true
    compression: "gzip"
    indexing: true

# Event system configuration
events:
  enabled: true
  event_bus_size: 1000
  event_retention_hours: 24
  handlers:
    workflow_started:
      - "log_workflow_start"
      - "initialize_monitoring"
    workflow_completed:
      - "log_workflow_completion"
      - "generate_summary_report"
    step_failed:
      - "log_step_failure"
      - "trigger_error_recovery"
    module_error:
      - "log_module_error"
      - "update_error_metrics"

# Monitoring and observability
monitoring:
  enabled: true
  metrics_collection_interval: 10
  enable_performance_monitoring: true
  enable_health_checks: true
  alert_thresholds:
    max_execution_time: 300
    error_rate_threshold: 0.1
    memory_usage_threshold: 0.8

# Resource management
resources:
  max_concurrent_workflows: 3
  resource_pool_size: 10
  cleanup_interval: 60
  resource_timeout: 300

# Error handling and recovery
error_handling:
  enable_circuit_breaker: true
  circuit_breaker_threshold: 5
  recovery_strategies:
    - "retry"
    - "fallback"
    - "degradation"
  notification_channels:
    - "log"
    - "email"
    - "slack"

# Performance optimization
performance:
  enable_optimization: true
  cache_enabled: true
  cache_size: 1000
  parallel_execution: true
  batch_processing: true

# Testing configuration
testing:
  enable_integration_tests: true
  mock_external_dependencies: false
  generate_test_data: true
  test_scenarios:
    - "happy_path"
    - "error_recovery"
    - "resource_exhaustion"
    - "parallel_execution"
