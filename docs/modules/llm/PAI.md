# Personal AI Infrastructure — LLM Module

**Version**: v0.1.7 | **Status**: Active | **Last Updated**: February 2026

## Overview

The LLM module supports Personal AI Infrastructure through local-first large language model execution and provider management.

## Local-First AI

Full Ollama integration for running models locally; hybrid mode supports fallback to cloud providers

## PAI Capabilities

- Local model execution via Ollama
- Configurable provider selection (local vs cloud)
- Model caching and optimization

## Detailed PAI Documentation

For comprehensive PAI integration details, see the source module's PAI documentation:
- [src/codomyrmex/llm/PAI.md](../../../src/codomyrmex/llm/PAI.md)

## Configuration

See [README.md](README.md) for configuration options and environment variables.

## Signposting

### Navigation

- **Self**: [PAI.md](PAI.md)
- **Parent**: [../PAI.md](../PAI.md) — Modules PAI documentation
- **Project Root PAI**: [../../../PAI.md](../../../PAI.md) — Main PAI documentation

### Related Documentation

- [README.md](README.md) — Module overview
- [AGENTS.md](AGENTS.md) — Agent coordination
- [SPEC.md](SPEC.md) — Functional specification
