# llm

**Version**: v0.1.0 | **Status**: Active | **Last Updated**: January 2026

## Overview

LLM module providing language model integration, prompt management, and output handling for the Codomyrmex platform. Supports multi-provider backends (OpenAI, Anthropic, Ollama) and streaming responses.

## Directory Contents

- `API_SPECIFICATION.md` – File
- `PAI.md` – File
- `README.md` – File
- `SECURITY.md` – File
- `SPEC.md` – File
- `__init__.py` – File
- `chains/` – Subdirectory
- `config.py` – File
- `exceptions.py` – File
- `fabric/` – Subdirectory
- `memory/` – Subdirectory
- `ollama/` – Subdirectory
- `outputs/` – Subdirectory
- `prompt_templates/` – Subdirectory
- `providers/` – Subdirectory
- `tools/` – Subdirectory

## Navigation

- **Parent Directory**: [codomyrmex](../README.md)
- **Project Root**: ../../../README.md
