# Codomyrmex Agents â€” src/codomyrmex/llm

**Version**: v0.1.0 | **Status**: Active | **Last Updated**: February 2026

## Purpose

LLM module providing language model integration, prompt management, and output handling for the Codomyrmex platform. Supports multi-provider backends (OpenAI, Anthropic, Ollama) and streaming responses.

## Active Components

- `API_SPECIFICATION.md` â€“ Project file
- `PAI.md` â€“ Project file
- `README.md` â€“ Project file
- `SECURITY.md` â€“ Project file
- `SPEC.md` â€“ Project file
- `__init__.py` â€“ Project file
- `chains/` â€“ Directory containing chains components
- `config.py` â€“ Project file
- `exceptions.py` â€“ Project file
- `fabric/` â€“ Directory containing fabric components
- `memory/` â€“ Directory containing memory components
- `ollama/` â€“ Directory containing ollama components
- `outputs/` â€“ Directory containing outputs components
- `prompt_templates/` â€“ Directory containing prompt_templates components
- `providers/` â€“ Directory containing providers components
- `tools/` â€“ Directory containing tools components

## Operating Contracts

- Maintain alignment between code, documentation, and configured workflows.
- Ensure Model Context Protocol interfaces remain available for sibling agents.
- Record outcomes in shared telemetry and update TODO queues when necessary.

## Navigation Links

- **ğŸ“ Parent Directory**: [codomyrmex](../README.md) - Parent directory documentation
- **ğŸ  Project Root**: ../../../README.md - Main project documentation
