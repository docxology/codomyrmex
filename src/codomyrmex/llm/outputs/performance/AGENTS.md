# Codomyrmex Agents â€” src/codomyrmex/llm/outputs/performance

**Version**: v0.1.0 | **Status**: Active | **Last Updated**: January 2026

## Purpose

Stores performance benchmark results and metrics for LLM operations. Contains structured JSON files documenting latency, throughput, consistency, and quality measurements for various models and configurations.

## Active Components

- `latency_benchmark.json` - Response latency measurements
- `token_generation_speed.json` - Token throughput metrics
- `consistency_evaluation.json` - Output reproducibility analysis
- `edge_case_handling.json` - Edge case behavior tests
- `model_health_check.json` - Model availability and readiness
- `response_quality_evaluation.json` - Output quality metrics
- `SPEC.md` - Directory specification
- `README.md` - Directory documentation

## Benchmark Types

### latency_benchmark.json
Measures end-to-end response times:
- Time to first token
- Total generation time
- Streaming chunk intervals
- Percentile distributions (p50, p95, p99)

### token_generation_speed.json
Measures token throughput:
- Tokens per second (input processing)
- Tokens per second (output generation)
- Batch processing efficiency
- Memory utilization during generation

### consistency_evaluation.json
Evaluates output reproducibility:
- Semantic similarity across runs
- Temperature effect analysis
- Seed reproducibility tests
- Cross-session consistency

### edge_case_handling.json
Tests boundary conditions:
- Empty input handling
- Maximum length inputs
- Special character processing
- Malformed input recovery

### model_health_check.json
Monitors model availability:
- Model load status
- GPU/CPU utilization
- Memory consumption
- Error rates

### response_quality_evaluation.json
Assesses output quality:
- Relevance scores
- Coherence metrics
- Factual accuracy (where verifiable)
- Format compliance

## Operating Contracts

- Benchmarks include hardware context (CPU, GPU, RAM)
- Timestamps for all measurements
- Statistical significance noted for comparisons
- Methodology documented for reproducibility
- Results versioned with model version

## Signposting

- **Generated By**: Performance testing scripts, `ollama/model_runner.py`
- **Parent Directory**: [outputs](../README.md) - Parent outputs directory
- **Related Modules**:
  - `reports/` - Security-focused reports
  - `integration/` - End-to-end test results
- **Project Root**: [../../../../../README.md](../../../../../README.md) - Main project documentation
