{
  "version": null,
  "last_updated": null,
  "source_url": "/Users/mini/Documents/GitHub/codomyrmex/src/codomyrmex/fpf/FPF-Spec.md",
  "source_hash": null,
  "metadata": {
    "total_patterns": 144
  },
  "patterns": [
    {
      "id": "A.0",
      "title": "Onboarding Glossary (NQD & E/E‑LOG)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.0 - Onboarding Glossary (NQD & E/E‑LOG)\n**One‑screen purpose (manager‑first).** This pattern gives newcomers a plain‑language starter kit for FPF’s *generative* engine so they can run a lawful **problem‑solving / search loop** on day one. It explains the few terms you must publish when you **generate, select, and ship portfolios** (not single “winners”), and points to the formal anchors you’ll use later. *(OEE is a Pillar; NQD/E/E‑LOG are the engine parts.)*\n\n**Builds on.** E.2 (**P‑10 Open‑Ended Evolution; P‑2 Didactic Primacy**), A.5, C.17–C.19 - **Coordinates with.** E.7, E.8, E.10; F.17 (UTS); G.5, G.9–G.12 - **Constrains.** Any pattern/UTS row that **describes a generator, selector, or portfolio**.\n\n**Keywords & queries.** *novelty, quality‑diversity (NQD), explore/exploit (E/E‑LOG), **portfolio (set)**, illumination map *(report‑only telemetry)*, parity run, comparability, ReferencePlane, CL^plane, **ParetoOnly** default*\n",
        "problem": "### 2) Problem\n\nIn current practice:\n\n* **Single‑winner bias.** Teams look for “the best” option and publish a leaderboard, suppressing **coverage & diversity** signals essential to search.\n* **Metric confusion.** “Novelty” and “quality” are used informally; units/scales are omitted; ordinal values are averaged, breaking comparability.\n* **Hidden policies.** Explore/exploit budgets and governor rules are implicit; results are irreproducible and **refresh‑unsafe** (no edition/policy pins).\n* **Tool lock‑in.** Implementation terms (pipelines, file formats) leak into the Core, violating Guard‑Rails.\n\nFPF needs a **short, normative glossary** that names the generative primitives in **Plain** register and ties each to its **formal anchor**—so portfolios, not single scores, become the default publication. \n",
        "forces": "### 3) Forces\n\n| Force                         | Tension                                                                         |\n| ----------------------------- | ------------------------------------------------------------------------------- |\n| **Readability vs Rigor**      | One‑liners for managers ↔ lawful definitions with editions and scale types.     |\n| **Creativity vs Assurance**   | Open‑ended search (OEE/QD) ↔ conformance, parity, and publication discipline.   |\n| **Comparability vs Locality** | Shared N‑U‑C‑D terms ↔ context‑local CG‑frames and bridges with CL.             |\n| **Tool‑agnostic Core**        | Conceptual publication in UTS ↔ engineering teams’ urge to cite specific tools. |\n",
        "solution": "### 4) Solution — **Normative onboarding glossary and publication hooks**\n\n#### 4.1 Plain one‑liners (normative on‑ramp; formal anchors in C.17–C.19)\n\n| Term                      | Plain definition (on‑ramp)                                                                                                                                   | See        |\n| ------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------ | ---------- |\n| **Novelty (N)**           | *How unlike the known set in your declared **CharacteristicSpace**. **Compute lawfully** (declared `DescriptorMapRef` + `DistanceDefRef`; no ad‑hoc normalisation). | C.17, C.18 |\n| **Use‑Value (U / ValueGain)** | *What it helps you achieve now under your **CG‑Frame**; tie to acceptance/tests; **publish units, scale kind, polarity, ReferencePlane**.                   | C.17, C.18 |\n| **Constraint‑Fit (C)**    | *Satisfies must‑constraints (Resource/Risk/Ethics)*; legality via **CG‑Spec**; **unknowns propagate** (never coerce to zero).                                | C.18, G.4  |\n| **Diversity_P (portfolio)** | *Adds a new niche to the **portfolio**; measured against the **active archive/grid**, not a single list; declare **ReferencePlane** for each head.          | C.17, C.18 |\n| **E/E‑LOG**               | *Named, versioned **explore↔exploit** policy*; governs when to widen space vs refine candidates; **policy‑id is published**.                                   | C.19       |\n| **ReferencePlane**        | *Where a value lives:* **world** (system), **concept** (definition), **episteme** (about a claim). **Plane‑crossings add CL^plane** (penalties to **R only**); cite policy‑id. | F.9, G.6   |\n| **Scale Variables (S)**  | *The **monotone knobs** along which improvement is expected* (e.g., parameterisation breadth, data exposure, iteration budget, resolution). **Declare S** for any generator/selector claimed to scale. | C.18.1       |\n| **Scale Elasticity (χ)** | *Qualitative class of improvement when moving along S* (e.g., **rising**, **knee**, **flat** in the declared window). Used as a **selection lens**; numeric laws live in domain contexts.              | C.18.1       |\n| **BLP (Bitter‑Lesson Preference)**  | *Default policy that **prefers general, scale‑amenable methods** over domain‑specific heuristics, unless forbidden by deontics or overturned by a scale‑probe.*                                        | C.19.1, C.24 |\n| **Iso‑Scale Parity**  | *Fair comparison across candidates at equalised **scale budgets** along S*; may also include **scale‑probes** (two points) to test elasticity.                                                         | G.9, C.18.1  |\n\n*(Registers & forbidden forms per **LEX‑BUNDLE**; avoid “axis/dimension/validity/process” for measurement and scope.)*  \n\n#### 4.2 Publication & telemetry duties (where these terms **show up**)\n\n1. **UTS surface (Part F).** When a **UTS row describes a generator, selector, or portfolio**, it **MUST** surface **N, U, C, Diversity_P, E/E‑LOG `policy‑id`, `ReferencePlane`**, with **units/scale/polarity** typed under **MM‑CHR / CG‑Spec**, and lawful references to `DescriptorMapRef`/`DistanceDefRef`. *(Row schema: F.17; shipping via G.10.)*  \n2. **Parity & edition pins (Part G).** When QD/OEE is in scope, **pin** `DescriptorMapRef.edition` and `DistanceDefRef.edition` (and, where applicable, `CharacteristicSpaceRef.edition`, `TransferRulesRef.edition`) and record `policy‑id` + `PathSliceId`. Treat **illumination/coverage as report‑only telemetry**; publish an **Illumination Map** where G‑kit mandates parity artefacts. **Declare S** (Scale Variables) and run at least one **scale‑probe** (two points along S) when claiming **scale‑amenability**. **Dominance policy defaults to `ParetoOnly`;** including illumination in dominance **MUST** cite a CAL policy‑id.\n3. **Tell‑Show‑Show (E.7/E.8).** Any arhitectural pattern that claims generative behaviour **MUST** embed **both** a **U.System** and a **U.Episteme** illustration using this glossary (manager‑first didactics). \n\n#### 4.3 Minimal recipe (run this on day one)\n1) Declare **CG‑Frame** (what “quality” means; lawful units/scales) and **ReferencePlane**.  \n2) Pick 2–4 **Q components** + a simple **DescriptorMap** (≥2 dims) for N/D; publish **editions**.  \n3) Choose an **E/E‑LOG policy** (explore↔exploit budget); record **policy‑id**.  \n4) Call the selector under **G.5** with parity pins; **return a set** (Pareto/Archive), not a single score.  \n5) **Publish to UTS** + **PathIds/PathSliceId**; **Illumination Map** is **report‑only telemetry** by default.\n",
        "archetypal_grounding": "### 5) Archetypal Grounding\n*Informative; manager‑first (E.7/E.8 Tell‑Show‑Show).*  <!-- exact heading per CC‑AG.1 -->\n\n**Show‑A - SRE capacity plan (selector returns a set).**\n*Frame.* We must raise service commitment headroom for Q4 without breaking latency SLOs.\n*Portfolio.* `{cache‑expansion, read‑replicas, query‑shaping, circuit‑breaker tuning, schema‑denorm}`.\n*Glossary in action.* `U = latency@p95 & error‑rate`, `C = budget ≤ $X, risk ≤ R`, `N = dissimilarity to current playbook`, `Diversity_P = adds a previously empty niche in our archive (e.g., “shifts load to edge”)`. E/E‑LOG starts **Explore‑heavy**, flips **Exploit‑heavy** once ≥ K distinct niches are lit. *(Publish UTS row + parity pins; illumination stays report‑only telemetry.)*  \n\n**Show‑B - Policy search with QD archive (MAP‑Elites‑class).**\n*Frame.* Robotics team explores gaits that trade stability vs energy use.\n*Glossary in action.* `CharacteristicSpace = {step‑frequency, lateral‑stability}`, `ArchiveConfig = CVT grid`, `N` from descriptor distance, `U` = task reward, `Diversity_P` = coverage gain; **PortfolioMode=Archive**. Families include **MAP‑Elites (2015)**, **CMA‑ME/MAE (2020–)**, **Differentiable QD/MEGA (2022–)**, **QDax (2024)**; publish editions and policy‑ids; treat illumination as **report‑only telemetry**.  \n\n*(Optional)* **Show‑C - OEE parity (POET/Enhanced‑POET).**\nCo‑evolve `{environment, method}` portfolios; publish **coverage/regret** as telemetry metrics; pin `TransferRulesRef.edition`; return *sets*, not a single winner. \n  \n**Show‑Epi - Evidence synthesis (U.Episteme).**\n*Frame.* A living review compares rival **causal identification** methods (e.g., IV vs. DiD vs. RCT‑adjacent surrogates) across policy domains.\n*Glossary in action.* `U = external‑validity gain @ F/G‑declared lanes`, `C = ethics & data‑licence constraints`, `N = dissimilarity in **ClaimGraph** transformations`, `D_P = coverage of identification niches in the archive`. `ReferencePlane = episteme`. Illumination/coverage stays **report‑only telemetry**; selection returns a **portfolio** of methods per niche. *(Publish UTS rows; cite Bridges + CL for cross‑domain reuse; edition‑pin Descriptor/Distance defs where QD applies.)*\n",
        "bias‑annotation": "### 6) Bias‑Annotation\n\n**Scope.** Trans‑disciplinary; glossary applies to both **System** and **Episteme** work.\n**Known risks & mitigations.**\n*Over‑aggregation:* forbid mixed‑scale sums; use **CG‑frame** and **MM‑CHR**.\n*Terminology drift:* enforce **LEX‑BUNDLE** registers; ban tool jargon in Core.\n*Optimization monoculture:* require **portfolio** publication where G‑kit mandates parity; illumination stays **report‑only telemetry** unless a CAL policy promotes it (policy‑id cited).   \n",
        "conformance_checklist": "### 7) Conformance Checklist (SCR/RSCR stubs)\n\n| ID          | Requirement                                                                                                                                                                               | Purpose                                                                         |\n| ----------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------- |\n| **CC‑A0‑1** | If a pattern/UTS row **describes a generator, selector, or portfolio**, it **MUST** surface **N, U, C, Diversity_P, `ReferencePlane`, and E/E‑LOG `policy‑id`**; **units/scale/polarity** **MUST** be declared. | Makes generative claims comparable and auditable (UTS as publication surface).  |\n| **CC‑A0‑2** | When QD/OEE is in scope, **pin** editions: `DescriptorMapRef.edition`, `DistanceDefRef.edition` (and, where applicable, `CharacteristicSpaceRef.edition`, `TransferRulesRef.edition`); log `PathSliceId` and policy‑ids. | Enables lawful *parity/refresh*; edition‑aware telemetry.                       |\n| **CC‑A0‑3** | **No mixed‑scale roll‑ups**; ordinal data **SHALL NOT** be averaged; any roll‑up **MUST** live under a declared **CG‑frame**.                                                             | Prevents illegal scoring; keeps comparisons lawful.                             |\n| **CC‑A0‑4** | Where the G‑kit requires parity, **publish an Illumination Map** (coverage per niche); **single‑number leaderboards are non‑conformant** on the Core surface when a ParityReport is required. | Portfolio‑first publication; avoids single‑winner bias.                         |\n| **CC‑A0‑5** | Keep **illumination/coverage** as **report‑only telemetry**; **dominance policy defaults to `ParetoOnly`**; any change is CAL‑authorised and cited by policy‑id.                                          | Separates fit from exploration; preserves auditability.                         |\n| **CC‑A0‑6** | Apply **E.7/E.8**: include a **U.System** and a **U.Episteme** illustration when claiming generative behaviour; obey **E.10** register hygiene; use the exact subsection title **“Archetypal Grounding.”** | Locks didactic primacy; prevents jargon drift.                                  |\n| **CC-A0-7** | **ReferencePlane declared** for every N/U/C/Diversity_P head and **CL^plane** penalties **route to R only**; **Φ_plane** policy-id published when planes differ.                            | Prevents plane/stance category errors; aligns with Bridge/**GateCrossing visibility** guards (Bridge+UTS+CL/Φ_plane). |\n| **CC‑A0‑8** | **Diversity_P ≠ Illumination.** Diversity_P may enter dominance; **Illumination** remains **report‑only telemetry** unless explicitly promoted by CAL policy‑id.                                         | Matches QD triad semantics and parity defaults.                                 |\n| **CC‑A0‑9** | If a generator/selector is claimed **scale‑amenable**, **declare S (Scale Variables)** and an **E/E‑LOG scale policy‑id**; otherwise mark **S = N/A**.                                      | Makes scale assumptions explicit and comparable across contexts.                 |\n| **CC‑A0‑10** | For scale‑amenable claims, execute a **scale‑probe** (≥ 2 points along S) and report a **Scale Elasticity class** (*rising/knee/flat*) in the UTS row.                                      | Forces early strategy‑relevant evidence without over‑specifying numerics.        |\n| **CC‑A0‑11** | Apply **Iso‑Scale Parity** in parity runs when S is declared; where infeasible, state the **loss notes** and treat results as **non‑parity** with an explicit penalty in **R**.             | Keeps comparisons fair and auditable under scale constraints.                    |\n| **CC‑A0‑12** | **BLP default.** If a domain‑specific heuristic is selected over a general, scale‑amenable method, record a **BLP‑waiver** reason: *deontic*, *scale‑probe overturn*, or *context‑specific*. | Prevents silent violations of the Bitter Lesson; improves selector transparency. |\n",
        "consequences": "### 8) Consequences\n\n**Benefits.**\n• **Immediate usability** for engineer‑managers (plain one‑liners) with **formal anchors** for auditors.\n• **Portfolio‑first** culture (sets & illumination) instead of brittle leaderboards.\n• **Edition‑aware comparability**; parity/refresh is routine, not ad‑hoc.\n\n**Trade‑offs & mitigations.**\n• Slightly longer UTS rows → mitigated by consistent schema and copy‑paste snippets.\n• Requires discipline on units/scales → mitigated by CG‑frame templates.\n",
        "rationale": "### 9) Rationale\n\nThis pattern **instantiates P‑10 Open‑Ended Evolution** by making *generation‑selection‑publication* **operational** at the on‑ramp: readers get just enough shared vocabulary to run *search as standard practice*. It aligns with **Didactic Primacy (P‑2)** and **LEX‑BUNDLE (E.10)** by keeping definitions *plain‑first* and scale‑lawful, and with **Plug‑in Layering (P‑5)** by pointing to C.17–C.19 for formal anchors without tool lock‑in. The post‑2015 line (MAP‑Elites → CMA‑ME/MAE → Differentiable QD/MEGA → QDax; POET/Enhanced‑POET/Darwinian Goedel Machine) normalised **quality‑diversity** and **open‑endedness** as first‑class search objectives; this glossary surfaces those ideas as **publication standards**, not tool recipes.  \n",
        "relations": "### 10) Relations\n\n**Builds on.** **E.2 Pillars** (P-10, P-2, P-6), **A.5** (Open-Ended Kernel), **B.5/B.5.2.1** (Abductive loops + NQD integration), **C.17–C.19** (Creativity-CHR, NQD-CAL, E/E-LOG).    \n\n**Coordinates with.** **E.7/E.8** (Archetypal Grounding; Authoring template), **E.10** (LEX‑BUNDLE), **F.17** (UTS), **G.5/G.9–G.12** (set‑returning selectors, **iso‑scale** parity, shipping & refresh).\n**Constrains.** Any generator/selector/portfolio publication on the Core surface: **N‑U‑C‑Diversity_P + policy‑ids; S/Scale‑probe where applicable; parity pins; lawful scales; portfolio‑first where mandated**. (Ties into UTS rows and parity artefacts.)\n**Editor’s cross‑reference.** For agentic orchestration of scalable tool‑calls under **BLP**/**SLL**, see **C.24 (Agent‑Tools‑CAL)**.\n",
        "editor’s_note_(implementation_hint)": "### Editor’s note (implementation hint)\n\nThis pattern is an **on‑ramp**: it **does not replace** C.17–C.19. It binds Plain definitions to **publication/telemetry** expectations so newcomers can *use* NQD/E/E‑LOG immediately while experts follow the formal trails. \n",
        "a.0:end": "### A.0:End\n\n"
      },
      "content": "### A.0:End\n\n",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.1",
      "title": "Holonic Foundation: Entity → Holon",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.1 - Holonic Foundation: Entity → Holon\n> **Type:** Architectural (A)  \n> **Status:** Stable  \n> **Normativity:** Normative\n\n> *“Name the thing without smuggling in its parts.”*\n",
        "problem": "### A.1:2 - Problem\n\nIf FPF treats **system** as the universal root, two recurrent failure modes appear:\n\n1. **Category Error** — physical affordances get projected onto abstract artifacts (ports on theories; kilogram‑mass of paradigms).\n2. **Mereological Over‑reach** — part–whole calculus is applied to genuinely atomic entities (prime numbers, elementary charges), producing meaningless “sub‑parts.”\n\nA robust kernel **separates identity from structure**: first say *what can be singled out*, then say *what has parts*.\n",
        "forces": "### A.1:3 - Forces\n\n| Force                         | Tension                                                                                                    |\n| ----------------------------- | ---------------------------------------------------------------------------------------------------------- |\n| **Universality vs Intuition** | Precision of a new root term (*Holon*) ↔ practitioner expectation of familiar words (*System*, *Theory*).  |\n| **Purity vs Pragmatism**      | Clean formalism ↔ immediate usability for engineers, scientists, managers.                                 |\n| **Structure vs Identity**     | Need to talk about atoms with zero parts ↔ need full mereology for composites.                             |\n",
        "solution": "### A.1:4 - Solution — A three‑tier root (Entity ⊃ Holon ⊃ {System, Episteme})\n\nFPF adopts a **three‑tier root ontology** refining Koestler’s “holon,” with crisp boundaries and safe composition. \n\n#### A.1:4.1 - `U.Entity` — Primitive of Distinction\nAnything that can be individuated and referenced. **No structural assumptions.** Use when you need to name “a something” without committing to having parts.\n\n> **Naming note (mint vs reuse).** `U.Entity` and `U.Holon` are minted kernel terms: they reuse familiar words but intentionally diverge from domain‑specific ontologies and DDD “Entity”, so we can reason cross‑domain without importing hidden assumptions.\n\n#### A.1:4.2 - `U.Holon` — Unit of Composition\nA `U.Entity` that is *simultaneously* **(a)** a whole composed of parts and **(b)** a part within a larger whole. Formally, `U.Holon ⊑ U.Entity`.\nWell‑formedness constraints:\n\n* **WF‑A1‑1 (Single boundary).** A holon has **exactly one** `U.Boundary` that separates it from its environment.\n* **WF‑A1‑2 (Γ domain).** The universal aggregation operator **Γ** is defined **only** on sets of `U.Holon` (never on bare `U.Entity`).\n* **WF‑A1‑3 (Γ scope).** A Γ‑application is scoped to a declared context and a single declared temporal scope (design **or** run); order/time are routed to Γ\\_ctx / Γ\\_time (B.1.4).\n\nThese constraints make composition rules uniform across domains and prevent Γ from being misapplied.\n\n#### A.1:4.3 - Interface primitives: `U.Boundary` & `U.Interaction`\nEvery holon is defined by **how** it is separated and **what** crosses the separation.\n\n* **`U.Boundary`** — physical or conceptual surface delimiting the holon’s scope.\n* **`U.Interaction`** — any flow of matter, energy, or information that crosses a boundary.\n  **Canonical boundary kinds (with twin archetypes):**\n\n| Kind          | Permitted exchanges             | `U.System` archetype               | `U.Episteme` archetype                                        |\n| ------------- | ------------------------------- | ---------------------------------- | ------------------------------------------------------------- |\n| **Open**      | Matter, energy, information     | Microservice exposing a public API | Public wiki editable by anyone                                |\n| **Closed**    | Energy, information (no matter) | Sealed cooling loop in a server    | Version‑locked theory accepting new evidence but fixed axioms |\n| **Permeable** | User‑filtered subset            | Cell membrane regulating ions      | Legal code allowing specific amendment classes only           |\n\nThis pair (`Boundary`, `Interaction`) makes interfaces explicit, reviewable, and testable across domains.\n\n#### A.1:4.4 - Inside/Outside decision procedure\nTo decide whether an entity **E** is *inside* a holon **H**, apply:\n\n1. **Dependency test:** removing **E** breaks a core invariant of **H**.\n2. **Interaction test:** **E** participates in causal loops wholly within **H**’s boundary.\n3. **Emergence test:** **E** contributes to a novel collective property warranting **H** as a single unit.\n   Fail all three → **E** is *outside*. This practical triage prevents “scope creep” and forces explicit modeling of environment vs interior.\n\n> **Collections vs collectives.** A set/collection of holons is not itself an acting unit. If a grouping is expected to act, model it as a `U.System` holon with its own boundary and attach roles/methods/work to that system (see CC‑A1.6; details in A.2 and A.15).\n\n#### A.1:4.5 - Archetypal sub‑holons\nFPF fixes two **archetypal** specializations to ground cross‑domain universality:\n\n| Subtype                    | Essence                                                | Home architheory |\n| -------------------------- | ------------------------------------------------------ | ---------------- |\n| **`U.System ⊑ U.Holon`**   | Physical, operational holon obeying conservation laws. | **Sys‑CAL**      |\n| **`U.Episteme ⊑ U.Holon`** | Knowledge holon (axioms, evidence, argument graph).    | **KD‑CAL**       |\n\n> **Agency rule.** Behavioural roles and executed methods/work attach to `U.System` holons only; `U.Episteme` is passive content. Any change to an episteme is performed by an external system acting across a boundary (cf. CC‑A1.5 and A.2/A.15).\n\n*Naming guideline:* keep “**System**” and “**Episteme**” for practitioner comfort; reserve **Holon** for meta‑level discourse and formal signatures.\n",
        "archetypal_grounding": "### A.1:5 - Archetypal Grounding (System / Episteme)\n\n| Holonic slot | **`U.System` — Water‑pump**            | **`U.Episteme` — Scientific theory**            |\n| ------------ | -------------------------------------- | ----------------------------------------------- |\n| **Identity** | Pump #37 stamped on the name‑plate     | “Newtonian Gravitation”, 1726 edition           |\n| **Boundary** | Cast‑iron casing; inlet/outlet flanges | Axiomatic scope and vocabulary                  |\n| **Parts**    | Motor, impeller, seals, housing        | Axioms, definitions, theorems, datasets         |\n| **Whole**    | Operable assembly that moves fluid     | Coherent body of knowledge predicting phenomena |\n\nShowing the **same structural slots** filled by a machine and a theory demonstrates the **substrate‑independent universality** of `U.Holon`. This is the didactic “Tell–Show–Show” anchor required by the Style‑Guide for architectural patterns. \n",
        "bias_annotation": "### A.1:6 - Bias-Annotation — Boundary-first modelling risks\n\nThis kernel distinction is intentionally **boundary‑first**: it treats “where the boundary is” as a modelling decision that shapes everything downstream. That framing is powerful, but it can also smuggle bias if boundary choices are made implicitly or for political convenience.\n\n| Lens | Typical bias risk | Mitigation in this pattern |\n|---|---|---|\n| **Gov** | Boundary decisions become “org charts”, not defensible model choices. | Record boundary rationale in the working model and require the **Inside/Outside test** (A.1:4.4) for contested cases. |\n| **Arch** | Over‑modularisation: every interaction becomes a “system” with hard edges. | Prefer **permeable boundaries** when the phenomenon is gradient‑like; keep the `U.Entity`/`U.Holon` split minimal and push dynamics into Roles (A.2) and Work (A.15). |\n| **Onto/Epist** | Category error: treating knowledge artifacts as physical actors (or vice‑versa). | Keep `U.Episteme` passive; model transformations as actions of a `U.System` in role, acting via explicit carriers (see A.10). |\n| **Prag** | “Holon” becomes jargon that slows teams down. | Use `U.System` / `U.Episteme` in day‑to‑day models; reserve “holon” for kernel‑level discourse (see naming guidance in A.1:4.5 and CC‑A1.8). |\n| **Didactic** | Readers infer semantics from overloaded labels or inconsistent headings. | Keep canonical titles and the `U.*` prefixes explicit; avoid informal deontic language in normative clauses (E.8). |\n",
        "conformance_checklist": "### A.1:7 - Conformance Checklist (normative)\n\n| ID          | Requirement                                                                                                                                                                    | Purpose / Notes                                                                                                        |\n| ----------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------- |\n| **CC‑A1.1** | Any modelled object that exhibits a part–whole structure **MUST** be typed as `U.Holon` or its subtype.                                                                        | Prevents applying Γ to atomic entities; makes aggregation well‑typed.                                                  |\n| **CC‑A1.2** | Each `U.Holon` **MUST** reference exactly one `U.Boundary` and declare its boundary kind (*open / closed / permeable*).                                                        | Enables boundary inheritance and environmental Standards; aligns with the canonical boundary kinds introduced in A.1.  |\n| **CC‑A1.3** | Domain architheories **MUST** explicitly subtype their root concept (`U.System`, `U.Episteme`, …) from `U.Holon`.                                                              | Ensures cross‑domain compatibility of aggregation and emergence patterns.                                              |\n| **CC‑A1.4** | Inside/Outside decisions for any candidate part **SHALL** be justified by the three‑step test (Dependency → Interaction → Emergence) and recorded with the boundary reference. | Makes holon membership auditable and repeatable; uses A.1’s decision procedure.                                        |\n| **CC‑A1.5** | Behavioural roles (**including** `TransformerRole`) **SHALL** attach only to `U.System` (the bearer), not to `U.Holon` in general and not to `U.Episteme`.                     | Preserves Strict Distinction and prevents category errors; episteme roles are classificatory only.                     |\n| **CC‑A1.6** | Do **not** model acting groups as sets. If a grouping is expected to **act**, it **SHALL** be modelled as a **collective system** (with boundary, role, Method/Work).          | Distinguishes `MemberOf` (collection) from mereology; prepares for A.14 Portions/Phases.                               |\n| **CC‑A1.7** | The universal aggregation operator **Γ** **SHALL** be applied **only** to sets of `U.Holon` within a single declared temporal scope (design **or** run) and context.           | Prevents “chimera” graphs; routes order/time to Γ\\_ctx / Γ\\_time (B.1.4).                                              |\n| **CC‑A1.8** | Prose and diagrams **SHALL** follow the naming guideline: use **Holon** for meta‑level discourse; prefer **System / Episteme** in practitioner‑level statements.               | Reduces jargon friction; keeps signatures precise and text readable.                                                   |\n\n> *Audit tip.* CC‑A1.5 is frequently violated when authors write “holon bearing TransformerRole”. Rewrite to “**system** bearing TransformerRole” or provide the explicit `U.RoleAssignment`. See A.2/A.15 for role mechanics.\n",
        "common_anti‑patterns_and_how_to_avoid_them_—_manager’s_quick_checks": "### A.1:8 - Common Anti‑Patterns and How to Avoid Them — Manager’s quick checks\n\n1. **“Ports on a theory.”** Treating a proof corpus as if it had physical connectors. *Fix:* model `U.Interaction` only across **boundaries**; for epistemes, interactions are **symbolic flows** via carriers and citations (see A.10), not power or mass.\n2. **“Document edited itself.”** Assigning actions to an episteme. *Fix:* actions are executed by a **system bearing a role** (A.12/A.15); epistemes are transformed **via external transformers** acting on their **symbol carriers**.\n3. **“Parts everywhere.”** Forcing a part–whole onto atomic entities (e.g., prime numbers). *Fix:* if no meaningful parts exist, stay at `U.Entity`; apply Γ only to `U.Holon`.\n4. **“Scope ≡ section.”** Using “scope” as a text region rather than a modeled boundary. *Fix:* define a `U.Boundary` and state what crosses it (`U.Interaction`).\n\n> **When in doubt:** first decide **what is a holon**, then state **its boundary**, then list **what crosses**. Roles and methods come *after* (see A.2 and A.15).\n",
        "consequences": "### A.1:9 - Consequences (informative)\n\n| Benefits                                                                                                                                                         | Trade‑offs / Mitigations                                                                                                        |\n| ---------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------- |\n| **Eliminates category errors** across physical and abstract realms by cleanly separating identity (Entity), structure (Holon), and behaviour (Role/Method/Work). | Introduces the unfamiliar term **Holon**; mitigated by Tell‑Show‑Show pedagogy and dual archetypal examples (System/Episteme).  |\n| **Unifies aggregation**: a single algebra Γ composes pumps, proofs, genomes, and teams under one roof.                                                           | Requires refactoring legacy “System‑only” language; addressed by A.2/A.3 role calculus and the Γ‑family in B.1.                 |\n| **Predictable extension point**: CAL/LOG/CHR architheories add constraints without touching the core types.                                                      | Imposes discipline on boundary declarations; mitigated by boundary kinds and the Inside/Outside test.                           |\n",
        "rationale": "### A.1:10 - Rationale — Cross‑domain corroboration (post‑2015, informative)\n\nThe separation **Entity → Holon → {System, Episteme}** is not only ontologically clean; it is **empirically validated across domains since 2015**:\n\n* **Compositional open systems.** Category‑theoretic treatments show that *boundaried* components compose safely (decorated cospans, open systems). This mirrors Γ’s reliance on declared boundaries. *(Fong & Spivak, 2019; Baez & Courser, 2017)*\n* **Microservices & bounded contexts.** Modern software architecture stresses strong service boundaries and local reasoning as the route to evolvability—our `U.Boundary` and Inside/Outside test encode the same discipline. *(Newman, 2021; Vernon, 2022)*\n* **FAIR & provenance.** Data/knowledge communities require explicit distinction between **content** and **carrier**, and auditable provenance—precisely the System/Episteme + SCR split used in A.1/A.10. *(Wilkinson et al., 2016; Boeckhout et al., 2018)*\n* **Digital Twin / Thread.** Engineering practice since late‑2010s emphasises the run↔design seam and boundary‑consistent aggregation of subsystems—formalised in our Γ‑family and boundary inheritance rules. *(Grieves & Vickers, 2017; NIST DT/Thread reports 2019‑2021)*\n* **Layered control of CPS.** Standard‑based, multi‑rate architectures justify explicit holon boundaries and scale transitions—feeding directly into B.2 Meta‑Holon Transition. *(Matni et al., 2024)*\n\nThese streams converge on one point: **make boundaries and composition first‑class** and separate **what a thing is** from **what it is doing here‑and‑now**—the heart of A.1/A.2.\n",
        "sota_echoing": "### A.1:11 - SoTA-Echoing (post‑2015, informative)\n\nThis solution echoes several modern (post‑2015) research and engineering streams. We **adopt** their boundary‑and‑composition insights, but **reject** any requirement to commit to a single formalism (per Notational Independence).\n\n| Stream | Representative sources | Adopt / Adapt / Reject | What we take (and what we diverge from) |\n|---|---|---|---|\n| Compositional open systems | Baez & Courser (2017); Fong & Spivak (2019) | **Adapt** | Take the idea that composition should be explicit and typed; diverge by keeping the Core notation‑independent (no category‑theory prerequisite). |\n| Software boundaries and bounded contexts | Newman (2021); Vernon (2022) | **Adopt** | Take boundary‑scoped meaning and ownership as the default; diverge by lifting “bounded context” to a kernel boundary concept rather than a software‑only practice. |\n| FAIR / provenance for epistemic artifacts | Wilkinson et al. (2016); Boeckhout et al. (2018) | **Adopt** | Take provenance and carrier/content separation; diverge by modelling knowledge artifacts as `U.Episteme` (passive) rather than agents. |\n| Digital twin / digital thread | Grieves & Vickers (2017); NIST DT/Thread (2019–2021) | **Adapt** | Take the run↔design seam; diverge by requiring a boundary kind at the holon level. |\n| Systems/control criteria for emergence | Matni et al. (2024) | **Adopt** | Take emergence as a criterion for systemhood; diverge by requiring explicit boundary declarations even when “obvious”. |\n",
        "relations": "### A.1:12 - Relations\n\n* **Builds / Grounds:**\n\n  * **A.2 Role Taxonomy** — A.1 provides the substantial characteristic (`Holon`), A.2 introduces the functional characteristic (`Role` and `U.RoleAssignment`). Together they prevent role/type explosion and keep agency contextual.\n  * **A.7 Strict Distinction (Clarity Lattice)** — A.1 supplies the *slots* (Entity/Holon/System/Episteme); A.7 guards their separation in prose and models, stopping Object ≠ Description ≠ Carrier conflations.\n  * **A.14 Advanced Mereology: Portions & Phases** — A.1’s holon substrate is the target of A.14’s edge discipline (`ComponentOf`, `ConstituentOf`, `PortionOf`, `PhaseOf`); only mereological subtypes build holarchies.\n\n* **Interacts with the Γ‑family (B‑cluster):**\n\n  * **B.1 Universal Algebra of Aggregation** — Γ is defined **on holons** and respects CC‑A1.\\*; Γ\\_ctx/Γ\\_time carry order and temporal composition, Γ\\_work handles resource ledgers.\n  * **B.2 Meta‑Holon Transition (MHT)** — uses A.1’s boundary and Inside/Outside rules to decide when aggregation yields a **new** whole with novel properties.\n  * **B.3 Trust & Assurance Calculus** — evidence attaches to carriers (SCR/RSCR) of epistemes; assurance levels depend on A.1/A.10 alignment.\n  * **B.4 Canonical Evolution Loop** — operationalises the **design↔run** seam at holon boundaries; observation itself is an external transformation across a boundary.\n\n* **Specialised by architheories:** `U.System` (Sys‑CAL) and `U.Episteme` (KD‑CAL) are archetypal sub‑holons that supply domain‑specific invariants while inheriting A.1’s boundary and aggregation duties. \n\n*Without the holon, parts drift; without the role, purpose evaporates.* (Carry this epigraph with A.1 to cue the A.2 hand‑off.)\n",
        "a.1:end": "### A.1:End\n"
      },
      "content": "### A.1:End\n",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.1.1",
      "title": "`U.BoundedContext`: The Semantic Frame",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.1.1 - `U.BoundedContext`: The Semantic Frame\n\n> **Type:** Architectural (A)  \n> **Status:** Stable  \n> **Normativity:** Normative\n\n*Make meaning local; make translation explicit.*\n",
        "problem": "### A.1.1:2 - Problem\n\nAbsent an explicit, first-class semantic frame:\n\n1. **Ambiguity becomes structural debt.** Integrations silently overwrite meanings (“process” becomes “procedure”; “role” becomes “permission”), and the resulting model cannot be audited.\n2. **Pluralism looks like contradiction.** Two valid perspectives appear mutually exclusive because the frame of reference is implicit (e.g., Pluto as `PlanetRole` vs `DwarfPlanetRole`).\n3. **Roles lose semantic footing.** A `U.Role` without a declared frame degenerates into a global label, violating the kernel’s insistence that roles are contextual masks (A.2, A.2.1).\n4. **Local rules leak globally.** Team- or theory-specific invariants are mistaken for universal laws, producing incoherent cross-domain reasoning.\n",
        "forces": "### A.1.1:3 - Forces\n\n| Force | Tension |\n| :--- | :--- |\n| **Local coherence** | A context must be internally unambiguous ↔ real work crosses boundaries and needs translation. |\n| **Pluralism** | Multiple valid frames must coexist ↔ readers demand apparent “one truth”. |\n| **Governance cost** | Explicit boundaries and rules improve reliability ↔ too many contexts create overhead and fragmentation. |\n| **Evolvability** | Contexts must change over time ↔ change must remain traceable and non-destructive to prior meaning. |\n| **Familiarity** | Practitioners use domain-native vocabulary ↔ the kernel must stay universal and type-stable. |\n| **Domain-family convenience** | People want “the domain” as a handle ↔ FPF requires specific, named semantic frames. |\n\n#### A.1.1:3.1 - Prophylactic clarification — Domain family vs `U.BoundedContext`\n\nTo prevent a common category error, **Domain (as used colloquially)** and **`U.BoundedContext`** are **not synonyms** in FPF, and “Domain” is not a kernel type.\nPer **E.10.D1 (D.CTX)**, **Domain is an informative family label** grouping multiple contexts; there is no “domain context”.\n\n| Characteristic | **Domain family (informative)** (e.g., Healthcare, Physics, Workflow) | **`U.BoundedContext`** (e.g., `Hospital.OR_2025`, `Theory:QuantumMechanics`, `BPMN_2_0`) |\n| :--- | :--- | :--- |\n| **Nature** | An external field of practice/knowledge; a catalog handle. | An internal FPF holon: a named semantic frame with local vocabulary and local invariants. |\n| **Role in FPF** | Groups contexts for survey, coverage, and stewardship discussions. | Localizes meaning and rules; provides a semantic firewall where words and obligations are coherent. |\n| **Relationship** | One family hosts many legitimate perspectives/editions. | One context hosts one such perspective with explicit `Glossary`, `Invariants`, `Roles`, and optional `Bridges`. |\n\n**Well-formedness constraint (didactic):** In any `U.RoleAssignment`, `context` is total and points to **exactly one** `U.BoundedContext` (cardinality **1..1**).\n*Think “specific room” (e.g., `Hospital.OR_2025`), not “the whole building” (e.g., “Healthcare”).*\n\n**Manager’s one-liner:** A **Domain family** is the *territory label*; a **Bounded Context** is a *purpose-made map* of one perspective on that territory.\n",
        "solution": "### A.1.1:4 - Solution\n\nFPF elevates **semantic framing** to a kernel primitive by introducing `U.BoundedContext` as a first-class holon of meaning.\nInspired by Domain-Driven Design (DDD) but generalized beyond software, a bounded context is not a mere namespace: it is **a governable model locale** with explicit vocabulary, rules, and role taxonomy.\n\n#### A.1.1:4.1 - Term & Definition\n\n* **Term:** `U.BoundedContext`\n* **Definition:** A **`U.BoundedContext`** is a `U.Holon` that serves as an explicit **semantic frame of reference**. It declares a boundary within which a specific vocabulary, role taxonomy, and invariant set are coherent and authoritative. It is FPF’s kernel mechanism for localizing meaning and managing complexity by partitioning a larger conceptual space into smaller, coherent, independently governable **semantic locales** (Contexts).\n\n**Mint vs reuse** (informative): The label \"Bounded Context\" is reused from DDD; `U.BoundedContext` is the FPF-defined kernel type (generalized beyond software). Cross-context sameness is never inferred from spelling; cross-context alignment is represented only via explicit `Bridge` artifacts (F.9; E.10.U9; see CC-A1.1.5).\n\n#### A.1.1:4.2 - Core components (normative shape)\n\nA `U.BoundedContext` is a composite holon whose *parts* constitute the context’s local “constitution”:\n\n* **`Glossary` (Local Lexicon):** A set of `U.Lexeme` entries (Lang-CHR) defining the local vocabulary and its intended senses. This is where a context can state: “Inside here, `ticket` denotes `U.WorkItem`, not `U.TravelPermit`.”\n* **`Invariants` (Local Rules):** A set of `U.ConstraintRule`s (Norm-CAL) that must hold for artifacts and processes operating in this context. These rules define the context’s local “physics”.\n  * *Example (role compatibility):* “Within this context, a `holder` cannot simultaneously play `AuditorRole` and `DeveloperRole`.”\n  * *Example (state transition):* “A `U.WorkItem` can transition from `InProgress` to `InReview`, never directly to `Done`.”\n* **`Roles` (Local Taxonomy):** A partial order of `U.Role`s that are defined and valid only within this context. It specifies the “masks” available on this stage (A.2).\n* **`Bridges` (Optional alignments):** A set of explicit cross-context relations (`U.Alignment`, formalized in F.9 / E.10.U9) describing how meaning translates when information crosses context boundaries, including loss/fit notes.\n  * *Example (alignment):* “`AgileDevelopment:UserStory` is congruent (CL=1) to `FormalEngineering:Requirement` under the stated loss policy.”\n\n#### A.1.1:4.3 - Context interactions with other kernel objects (normative)\n\n* **As a `U.Holon`:** A `U.BoundedContext` has a defined `U.Boundary` and internal parts (`Glossary`, `Invariants`, …). However, **contexts do not form holarchies with each other**: per E.10.D1 (D.CTX), contexts have no is‑a or containment relations; cross-context relationships are expressed only via explicit `Bridges`.\n* **As the semantic frame for `U.RoleAssignment`:** The `context` field of `U.RoleAssignment` identifies the unique semantic frame in which the holder-role assignment is interpreted (A.2.1).\n* **As the scope carrier for rules and objectives:** `U.Objective`s and `U.ConstraintRule`s are typically authored and evaluated relative to a specific context’s invariants.\n* **As a change target:** Context evolution (new invariants, revised glosses, deprecated roles) is modeled as a `U.Transformer` acting on the `U.BoundedContext` holon itself. Where time is merely stance (`design`/`run`), treat it as a TimeScope tag, not a new context (C‑7; D.CTX).\n\n> *If meaning is local by design, then translation must be explicit by design.*\n\n**Admissibility constraints (concept-level; non-deontic).**\n\n* **BC‑1 (Holon nature).**  A `U.BoundedContext` is a `U.Holon` and declares a `U.Boundary`.\n* **BC‑2 (Flat context map).** No `U.BoundedContext` is modeled as inheriting from, containing, or being contained by another `U.BoundedContext`; cross-context relations are represented only via explicit `Bridges` (E.10.D1 / E.10.U9).\n* **BC‑3 (Role localization).** Every `U.Role` is defined in the `Roles` taxonomy of at least one `U.BoundedContext`; a \"global role\" is not a valid kernel object.\n* **BC‑4 (Invariant scope).** Any invariant authored in a Context applies only to holons and processes operating within that Context; cross-context reuse is mediated by Bridges and re‑stated locally.\n* **BC‑5 (Bridge explicitness).** Any interaction or semantic alignment between two Contexts is represented by an explicit `Bridge` artifact.\n* **BC-6 (RoleAssignment context field).** A `U.RoleAssignment` references exactly one `U.BoundedContext` in its `context` field (cardinality 1..1).\n* **BC‑7 (Domain is metadata).** \"Domain\" denotes only an informative family label grouping multiple contexts; it is not a kernel type and does not substitute for `U.BoundedContext` (E.10.D1).\n",
        "archetypal_grounding": "### A.1.1:5 - Archetypal Grounding\n\nThe concept of a `U.BoundedContext` is universal and applies to both physical/operational domains and purely abstract/epistemic ones. Understanding these two archetypes clarifies its role as a fundamental FPF primitive.\n\n| Archetype | Stewarding community | `U.BoundedContext` Example | Core Components Illustrated |\n| :--- | :--- | :--- | :--- |\n| **`U.System` Archetype** | A modern software engineering team | **`AgileProject:Phoenix`** | **`Glossary`**: Defines \"Story Point,\" \"Sprint,\" \"Velocity.\" <br> **`Invariants`**: \"Daily stand-up must not exceed 15 minutes.\" \"A Story cannot move to 'Done' without a linked Test Case.\" <br> **`Roles`**: `ProductOwnerRole`, `ScrumMasterRole`, `DeveloperRole`. <br> **`Bridges`**: Maps `Velocity` metric to the `FinanceDept` context's `CostCenter:BudgetBurnRate`. |\n| **`U.Episteme` Archetype** | A scientific community | **`Theory:SpecialRelativity`** | **`Glossary`**: Defines \"Inertial Frame,\" \"Lorentz Transformation,\" \"Proper Time.\" <br> **`Invariants`**: \"The speed of light in a vacuum is constant for all observers.\" \"The laws of physics are the same in all inertial frames.\" <br> **`Roles`**: `Postulate#AxiomaticCoreRole`, `Experiment#EvidenceRole`. <br> **`Bridges`**: Maps its concept of \"Spacetime\" to the `GeneralRelativity` context's more complex concept of \"Curved Spacetime.\" |\n\n**Key takeaway from grounding:**\nThis illustrates that a `U.BoundedContext` is not an abstract container but a **holon with tangible content**. For the engineering team, it's their project's \"operating system.\" For the scientific theory, it's the \"intellectual constitution.\" In both cases, the context defines what is true, what is possible, and what words mean *locally*.\n",
        "bias_annotation": "### A.1.1:6 - Bias-Annotation\n\nThis pattern is intentionally universal, but it can be misread through narrower lenses:\n\n* **Software-centrism bias:** Readers may assume “bounded context” only applies to microservices/teams. *Mitigation:* the Episteme archetype is first-class; contexts apply equally to theories, standards, and scientific practices.\n* **Boundary reification bias:** Authors may treat boundaries as “natural facts” rather than modelling choices. *Mitigation:* boundaries are declared for governance and clarity, and cross-context relations are handled via Bridges with explicit loss/fit.\n* **English-label bias:** Examples often use English surface terms, which can hide multilingual drift. *Mitigation:* language/edition discipline in D.CTX governs when to split/merge contexts; multilingual labels are metadata when semantics are truly bound.\n",
        "conformance_checklist": "### A.1.1:7 - Conformance Checklist\n\nTo ensure `U.BoundedContext` is used consistently and rigorously, the following normative checks apply.\n\n| ID | Requirement (Normative Predicate) | Purpose / Rationale |\n| :--- | :--- | :--- |\n| **CC-A1.1.1 (Holon Nature)** | A `U.BoundedContext` **MUST** be modeled as a `U.Holon` with a defined `U.Boundary`. | Reinforces that contexts are well-defined entities, not vague groupings. Enables reasoning about contexts themselves as systems. |\n| **CC-A1.1.2 (Flat Context Map)** | A `U.BoundedContext` **MUST NOT** be modeled as inheriting from, containing, or being contained by another `U.BoundedContext`. Cross-context relations **MUST** be expressed only via explicit `Bridges` (E.10.D1 / E.10.U9). | Prevents semantic leakage and hidden globalism; keeps cross-context translation auditable and loss-aware. |\n| **CC-A1.1.3 (Role Localization)** | Every `U.Role` **MUST** be defined within the `Roles` taxonomy of at least one `U.BoundedContext`. A \"global role\" is forbidden. | Ensures roles are never context-free; meaning remains local and checkable. |\n| **CC-A1.1.4 (Invariant Scope)** | An invariant defined within a context **MUST** only apply to holons and processes operating *within* that context. | Prevents local rules from leaking into global reasoning; preserves modularity. |\n| **CC-A1.1.5 (Bridge Explicitness)** | Any interaction or alignment between two `U.BoundedContext`s **MUST** be modeled as an explicit `Bridge` artifact. | Forbids implicit cross-context equivalences; makes dependencies visible and auditable. |\n| **CC-A1.1.6 (RoleAssignment Context Binding)** | Every `U.RoleAssignment` **MUST** reference exactly one `U.BoundedContext` in its `context` field (cardinality 1..1). | Guarantees that each assignment is interpreted in one authoritative frame of meaning. |\n| **CC-A1.1.7 (Domain family is informative)** | “Domain context” **MUST NOT** appear in normative prose; Domain labels **MAY** appear only as informative family metadata that groups multiple contexts (E.10.D1). | Prevents the domain/context conflation that breaks locality and auditability. |\n",
        "anti_patterns": "### A.1.1:8 - Common Anti-Patterns and How to Avoid Them\n\nThese failure modes recur when applying `U.BoundedContext` in real programs and knowledge work.\n\n| Anti-pattern | Symptom | Why it fails (force violated) | How to avoid / repair |\n| :--- | :--- | :--- | :--- |\n| **Domain-as-Context** | “Healthcare” or “Physics” is used where a specific context is required. | Violates Domain-family convenience vs precision; meaning stays ambiguous. | Use a specific context id (edition- and source-scoped), and keep the domain label as informative family metadata only. |\n| **Implicit equivalence across contexts** | The same string in two contexts is treated as “obviously the same”. | Violates local coherence; creates silent semantic overwrites. | Publish an explicit Bridge with relation kind and loss/fit note (F.9 / E.10.U9). |\n| **Context hierarchy / nesting** | Authors model “sub-contexts” as containment or is‑a between contexts. | Violates the flat context map discipline; leaks rules by inheritance. | Remove context-to-context containment; express relationships via Bridges only (E.10.D1). |\n| **Time-as-Context** | “Design context” and “Runtime context” are created as separate contexts. | Violates evolvability and clarity; multiplies frames incorrectly. | Use TimeScope tags (`design`/`run`) on artifacts and sources; keep the semantic frame fixed (C‑7; D.CTX). |\n| **Glossary-only context** | A context is defined by vocabulary but has no invariants or role taxonomy. | Violates governance intent; “local truth” remains implicit. | Add at least one invariant and a minimal local role taxonomy, even if initially coarse. |\n",
        "consequences": "### A.1.1:9 - Consequences\n\n| Benefits | Trade-offs / Mitigations |\n| :--- | :--- |\n| **Enables True Modularity:** By encapsulating models, FPF can support large, complex systems where different teams can work on their own bounded contexts in parallel with minimal interference. | **Modeling Overhead:** Requires architects to explicitly think about and define the boundaries of their models, which can feel like extra work initially. *Mitigation:* This upfront effort is a strategic investment that prevents the much higher cost of integration chaos and semantic ambiguity later in the project. |\n| **Resolves Ambiguity and Paradox:** Provides a formal mechanism to manage synonyms, homonyms, and conflicting models (like the Pluto example). It transforms \"it depends\" into a precise, queryable structure. | **Bridge Maintenance:** As contexts evolve, the bridges between them must be maintained. *Mitigation:* FPF tooling should support \"link integrity\" checks to automatically flag broken or outdated bridges. |\n| **Makes Rules Explicit:** The `Invariants` component of a context makes the local rules and invariants for a project or theory explicit, documented, and auditable. | - |\n| **Foundation for Scalable Autonomy:** In multi-agent systems, each agent can operate within its own bounded context, communicating with others through well-defined bridges. This is a prerequisite for building robust, decentralized systems. | - |\n",
        "rationale": "### A.1.1:10 - Rationale\n\n**Lineage and fit with Domain‑Driven Design (DDD).**  \nFPF generalizes the proven DDD idea of a **Bounded Context** from software into a universal modeling primitive:\n\n| DDD concept | FPF counterpart | Generalization in FPF |\n| :--- | :--- | :--- |\n| Bounded Context | **U.BoundedContext** (a holon) | Used for systems **and** knowledge; first‑class object with explicit Glossary, Invariants, local Roles, Bridges. |\n| Ubiquitous Language | **Glossary** of the context | The shared vocabulary is an explicit component, not just narrative. |\n| Context Map | **Bridges/Alignment** between contexts | Cross‑context relations are modeled explicitly rather than assumed globally. |\n\n**Why this matters here.**  \n`U.BoundedContext` gives `U.RoleAssignment` (A.2.1) its footing: role meanings are **local by design**, conflicts are checked **inside** the same context, and differences **across** contexts are handled by **explicit Bridges** instead of “global truth.”\n\nThe introduction of `U.BoundedContext` as a first-class holon is a direct implementation of several core FPF principles and is strongly supported by contemporary practice.\n\n*   **Philosophical Grounding:** The idea that meaning is always local and context-dependent is a cornerstone of late 20th-century philosophy of language (e.g., Wittgenstein's \"language-games\"). FPF operationalizes this insight.\n*   **Domain-Driven Design (DDD):** The concept is a direct borrowing and generalization from Eric Evans' seminal work on DDD, where the Bounded Context is the central strategic pattern for managing complexity in large-scale software. Its success over the past two decades in the software industry provides powerful empirical validation for its utility. FPF elevates it from a software design pattern to a universal ontological primitive.\n*   **Architectural Necessity:** For FPF to fulfill its promise of being an \"operating system for thought,\" it needs a mechanism analogous to an OS's \"process separation.\" A `U.BoundedContext` is precisely that: a protected \"memory space\" for a model, preventing different models from corrupting each other.\n*   **Enabler for Key Patterns:** The `Contextual Role Assignment` pattern (A.2.1) would be incoherent without a formal definition of \"Context.\" This pattern provides that necessary foundation, making the entire role-based architecture sound.\n\nIn essence, `U.BoundedContext` is the architectural pattern that allows FPF to be both **universal** in its core principles and **specific** and **pluralistic** in its applications. It is the mechanism that tames complexity and makes large-scale, multi-paradigm modeling possible.\n",
        "sota_echoing": "### A.1.1:11 - SoTA-Echoing (post-2015 practice alignment)\n\nThe `U.BoundedContext` concept aligns strongly with contemporary (post‑2015) practice in software architecture, socio-technical design, and knowledge/provenance disciplines. Where FPF differs, it does so to preserve kernel universality, explicit loss-aware translation, and auditability.\n\n| Claim (A.1.1 need) | SoTA practice (post‑2015) | Primary source (post‑2015) | Alignment with A.1.1 | Adoption status |\n| :--- | :--- | :--- | :--- | :--- |\n| Meaning boundaries must be explicit to scale development. | Modern microservice architecture stresses clear service boundaries and local reasoning to keep systems evolvable. | Newman (2021), *Building Microservices* (2nd ed.). | A.1.1 adopts the boundary-first stance but generalizes it from “service boundaries” to a universal semantic holon with explicit local invariants and roles. | **Adopt/Adapt.** Adopt boundary discipline; adapt by making the semantic frame a first-class kernel object, not only a team convention. |\n| Organizational boundaries and cognitive load shape semantic boundaries. | Socio-technical architecture practice encourages team-aligned boundaries and explicit interaction modes to prevent cognitive overload. | Skelton & Pais (2019), *Team Topologies*. | A.1.1 aligns by treating a context as governable by a stewarding community, but requires explicit Bridges when knowledge crosses boundaries (rather than relying on tacit coordination). | **Adopt.** Directly supports local autonomy; tighten with explicit cross-context translation artifacts. |\n| Cross-domain data integration needs explicit contracts, not implicit “one truth”. | Data Mesh emphasizes domain-oriented data products and explicit interoperability contracts across domains. | Dehghani (2022), *Data Mesh* (book form of the 2019–2021 program). | A.1.1 matches the “data product boundary” move, but insists that interoperability is expressed as explicit Bridges with loss/fit notes, preserving pluralism instead of collapsing it. | **Adapt.** Adopt the decentralization intuition; adapt by requiring explicit semantic alignment artifacts rather than assuming shared enterprise semantics. |\n| Knowledge and artifacts must carry machine-actionable semantics and provenance. | FAIR and modern research-object packaging push for explicit metadata, provenance, and reuse conditions. | Wilkinson et al. (2016), FAIR Principles; RO‑Crate community specs (2019→). | A.1.1 supports this by making local meaning explicit (Glossary + Invariants) and making cross-context translation explicit (Bridges), enabling auditable reuse without pretending to globalize semantics. | **Adopt/Adapt.** Adopt provenance and reuse intent; adapt by separating semantic frame (Context) from carriers and by making loss explicit on crossings. |\n",
        "relations": "### A.1.1:12 - Relations\n\n*   **Constitutes:** The foundational \"semantic space\" for patterns like `A.2 Role Taxonomy` and `A.13 The Agential Role`.\n*   **Builds on:** `A.1 Holonic Foundation`, as a `U.BoundedContext` is itself a `U.Holon`.\n*   **Constrained by:** `E.10.D1 D.CTX`, which fixes the lexical discipline for “Context”, forbids context hierarchies, and makes Domain family informative.\n*   **Interacts with:**\n    *   `Norm-CAL`: A context's `Invariants` are typically expressed as `U.ConstraintRule`s.\n    *   `Lang-CHR`: A context's `Glossary` is a collection of `U.Lexeme`s.\n    *   `Decsn-CAL`: Decisions and objectives are often scoped to a specific context.\n    *   `F.9 Alignment & Bridge`: the canonical locus of cross-context relations and loss policies.\n*   **Enables:** The resolution of conflicts as modeled in `D.3 Holonic Conflict Topology`, by showing that many conflicts are context-dependent.\n    ",
        "a.1.1:end": "### A.1.1:End\n\n"
      },
      "content": "### A.1.1:End\n\n",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.2",
      "title": "Role Taxonomy",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.2 - Role Taxonomy\n> **Type:** Architectural (A)\n> **Status:** Stable\n> **Normativity:** Normative\n\n*A holon’s essence tells us **what it is**; its roles tell us **what it is being, here and now**.*\n",
        "problem": "### A.2:2 - Problem\n\nWithout an explicit role calculus:\n\n1. **Type explosion & conflation.** Each new purpose breeds a new “subtype” (`PumpAsCoolingLoop`, `PumpAsFuelLoop`, …), violating parsimony and fusing substance with function.\n2. **Agency opacity.** It becomes unclear whether *any* system may act as a transformer/agent, or only pre-declared special kinds.\n3. **Epistemic blindness.** Knowledge artefacts (papers, proofs) cannot be given roles, blocking modelling of citation, evidence, or design-time justification.\n",
        "forces": "### A.2:3 - Forces\n\n| Force                                | Tension                                                              |   |\n| ------------------------------------ | -------------------------------------------------------------------- | - |\n| **Identity vs Function**             | A holon’s make‑up ↔ its transient, contextual purpose.               |   |\n| **Static vs Dynamic classification** | Fixed type lattice ↔ late‑binding of new roles.                      |   |\n| **Universality vs Familiarity**      | One mechanism for pumps **and** papers ↔ domain‑specific role names. |   |\n| **Simplicity vs Expressiveness**     | Minimal primitives ↔ multi‑role, multi‑holder scenarios.             |   |\n",
        "solution": "### A.2:4 - Solution\n\nWe elevate **Role** to a first‑class semantic construct: a context‑bound *mask* (capability/obligation schema) worn by a holon. **Behaviour** and **resource deltas** live in **Method**/**Work**, not in the role itself.\n\n#### A.2:4.1 - S‑level definitions (normative)\n\n* **`U.Role`** — a **context-bound** capability/obligation schema that a holon **may bear (play)** for a time interval. A role has **no parts** and **no resource deltas** of its own. *(A7 guard)*\n* **`U.RoleAssignment`** — a first-class assignment record recording that a holon **bears (plays)** a role **in** a bounded context over an optional **Window**. Keep the signature aligned with **A.2.1 Role Assignment Standard**; governance metadata (authority/justification/provenance) is captured via `U.RoleAssigning` and the evidence graph (A.10).\n\n```\nU.RoleAssignment {\n  holder        : U.Holon,\n  role          : U.Role,\n  context       : U.BoundedContext,\n  window? : U.Window\n  justification?: U.Episteme,  // why (standard, SOP, evidence)\n  provenance?   : U.Method     // how assignment/verification was done\n}\n```\n\nShort form (readable): `Holder#Role:Context@Window`.\n\n> **Why a first-class assignment record?** It keeps identity (holon), function (role), context (semantics), and time (run-window) separate yet linked, preventing the substance/function conflation identified above. The early `playsRoleOf(Holon, Role, span)` relation in the draft is subsumed by `U.RoleAssignment` and extended with **Context** (and optional governance fields).\n\n#### A.2:4.2 - Temporal & behavioural alignment\n\n* **MethodDescription** persists as Episteme. A Role **binds** to Method (design‑time), and Work **performs** Method under that Role (run‑time). This preserves the *role ≠ behaviour* split and the *design ↔ run* duality.\n* Only **Work** carries resource deltas (feeds Γ\\_work); a Role never does.\n\n#### A.2:4.3 - Admissibility constraints (concept-level; non-deontic).\n\n1. **Locality.** `role ∈ Roles(context)`. Outside its context, a role’s meaning is undefined.\n2. **Non‑mereological.** No Role (nor Method/MethodDescription) may appear in any `partOf` chain; holarchies are for substantial holons only.\n3. **Multiplicity.** A holder may **bear** multiple roles concurrently; a role may be **borne** by many holders—subject to each context’s compatibility rules.\n4. **Time anchoring.** `timespan` (if present) is non-empty and finite for run-time claims; design-time assignments are timeless but versioned via `MethodDescription` identity.\n5. **Behavioural coherence.** For any `U.Work` window, the performer plays the Role that binds the executed Method. *(No hidden role swaps.)*\n\n#### A.2:4.4 - Taxonomic frame (within a context)\n\nWithin each `U.BoundedContext`, role names are organised as a **partial order** (refinements) plus an **incompatibility** relation (mutually exclusive roles). Typical **substrate‑neutral** anchors:\n\n| Kernel Role       | Intent                                | System archetype              | Episteme archetype                       |   |\n| ----------------- | ------------------------------------- | ----------------------------- | ---------------------------------------- | - |\n| `TransformerRole` | Changes other holons via Method/Work. | Robot arm assembling casings. | Prover constructing a new lemma.         |   |\n| `ObserverRole`    | Collects evidence / metrics.          | Sensor array on a test‑rig.   | Reviewer annotating an article.          |   |\n| `SupervisorRole`  | Governs subordinate holons.           | PLC orchestrating a line.     | Meta‑analysis curator combining studies. |   |\n\n> Domains refine these anchors: e.g., `CoolingCirculatorRole`, `CitationSourceRole`, `LemmaRole`.\n",
        "archetypal_grounding": "### A.2:5 - Archetypal Grounding (Tell–Show–Show: System / Episteme)\n\n**Tell.** A single holon can be the *same bearer* across time while taking on different, context‑bound roles. A role is a *mask* (capability/obligation schema) that explains *what it is being* in a given `U.BoundedContext`; behavioural facts and resource deltas remain in `U.Method` / `U.Work`.\n\n**Show.**\n\n**System case — Cooling loop**\n`PumpUnit#3#HydraulicPump:Plant‑A`\n`HydraulicPump ↦binds↦ ChannelFluid` (design)\n`run‑2025‑08‑08 isExecutionOf centrifugal_pump_curve.ld` and `performedBy PumpUnit#3` (run)\n*(All behavioural/resource facts live in Work; the Role is the mask.)*\n\n**Episteme case — Standard in design**\n`RFC‑9110.pdf#ProtocolStandard:WorldWideWeb` justifies `MethodDescription` selection; the **system** bearing `TransformerRole` is the design service that executed the selection work. The episteme did **not** act.\n\n**Collective vs set (safety pitfall)**\nA **set** `{Alice, Bob, 3.14}` has no behaviour; a **team** is a **system** with boundary, coordination **Method**, and supervision **Work**; only the latter can bear agentic roles.\n",
        "bias_annotation": "### A.2:6 - Bias-Annotation\n\nLenses tested: **Arch**, **Onto/Epist**, **Prag**, **Did**. Scope: **Universal** (A‑cluster).\n\n* **Architecture bias (Arch):** treating roles as structural parts can smuggle function into mereology and break holarchies.\n\n* *Mitigation:* keep `partOf` chains role‑free; roles are not constituents (see CC‑A2.1).\n  +* **Onto/Epist bias (Onto/Epist):** anthropomorphising epistemes collapses evidence into agency.\n* *Mitigation:* epistemes can justify/authorize; only systems perform methods and work (CC‑A2.2).\n  +* **Pragmatic bias (Prag):** over‑contextualising can fragment reuse and create naming drift.\n* *Mitigation:* require explicit `:Context` binding and explicit bridges instead of silent equivalence (CC‑A2.4).\n  +* **Didactic bias (Did):** metaphors (“mask”) may be misread as informal.\n* *Mitigation:* bind obligations to CC items; avoid imperative prose outside CC.\n",
        "authoring_guidance_(for_engineers_and_leads)": "### A.2:7 - Authoring guidance (for engineers and leads)\n\n* **Name roles for intent, not mechanics.** Prefer `CoolingCirculatorRole` over `ChannelFluidWithCentrifugalProfile`.\n* **Pin the context early.** If two teams disagree, split contexts and (optionally) define an alignment bridge; do not over‑generalise the role.\n* **Document the enactment chain.** For any operational claim, be ready to point to: `RoleAssigning → Method ↔ MethodDescription → Work`. (Readers’ dictionary: *BPMN workflow → MethodDescription; operation/job → Work.*)\n",
        "conformance_checklist": "### A.2:8 - Conformance Checklist (CC‑A2.\\*)\n\n|                      ID | Requirement                                                                                                                                                                                                                                                                          | Practical test (manager‑oriented)                                                                                                                                                             |\n| ----------------------: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n|             **CC‑A2.1** | A **Role** SHALL NOT be a mereological part of any holon; roles are never constituents of holarchies.                                                                                                                                                                                | If a diagram shows `Role →(part‑of)→ Holon`, the model **fails**. Replace the edge with `playsRoleOf(Holon, Role, span)` (A.14 governs parts).                                                |\n|             **CC‑A2.2** | Only a **System** can bear **behavioural** roles (e.g., `TransformerRole`, `AgentialRole`) and thus bind **Method**/**Work**; an **Episteme** MAY bear **non‑behavioural** roles (e.g., `ReferenceRole`, `ConstraintSourceRole`) only.                                               | Lint the model: any `U.Episteme` that `bindsMethod` or is a `performedBy` target **fails**; move behaviour to a system bearing the role and act on episteme **carriers** (A.7, A.12, A.15).   |\n|             **CC‑A2.3** | Every **non‑abstract Role** SHALL `bindsMethod ≥ 1`; roles with no bound method are **abstract** and non‑executable.                                                                                                                                                                 | If a role participates in `Work` without some `Method ⟷ MethodDescription` chain, flag “unbound role” and add a binding (A.15).                                                                      |\n|             **CC‑A2.4** | Every **role reference** in normative text SHALL be **context‑indexed** by a declared **Bounded Context** (local to the pattern or glossary). Local shorthand **“Transformer”** is permitted only if the pattern’s Glossary **re‑binds** it to “**System bearing TransformerRole**”. | If prose says “Transformer updates the spec”, the pattern MUST define the local alias and its target; otherwise rewrite to the canonical long form (E.10, A.7).                               |\n|             **CC‑A2.5** | Each `U.RoleAssignment` SHALL carry an explicit `window` **or** be traceably open‑ended from an assignment time (e.g., via `U.RoleAssigning`). Open intervals are allowed but must be explicit. | Search for RoleAssignments with neither `window` nor a traceable assignment time; add `@t₀..t₁` (or open bound) and/or an issuing RoleAssigning Work. |\n|             **CC‑A2.6** | If two roles are declared **incompatible inside the same context**, a bearer SHALL NOT hold them over **overlapping** spans.                                                                                                                                                         | Check the context’s role‑compatibility grid; if overlaps exist, either split the Work by `PhaseOf` or change staffing (A.14; B.1.4/Γ\\_time).                                                  |\n|             **CC‑A2.7** | For any **Work** item, `performedBy` MUST reference the **concrete RoleAssignment** of the performer, and its window MUST cover the Work’s window. | Assert `performedBy(Work) = RA` and `RA.window ⊇ window(Work)`; split Work or update assignments if the performer changes mid‑window (A.2.1, A.15). |\n|             **CC‑A2.8** | Every **Method** bound to a role SHALL be `isDescribedBy ≥ 1` **MethodDescription** (`U.Episteme`) and every **Work** SHALL be `isExecutionOf` exactly one **MethodDescription** version.                                                                                                          | If a Work lacks `isExecutionOf`, or a Method lacks `MethodDescription`, the audit fails (A.15; A.10 evidencing hook).                                                                                |\n|             **CC‑A2.9** | **Evidence** for claims about roles and execution MUST anchor to **symbol carriers** (SCR/RSCR); self‑evidence is forbidden.                                                                                                                                                         | A role effectiveness claim without SCR/RSCR or with cyclic provenance fails (A.10).                                                                                                           |\n|            **CC‑A2.10** | When a Role assignment implies **order** or **temporal** structure, the pattern SHALL defer to **Γ\\_ctx**/**Γ\\_time** rather than overloading role edges.                                                                                                                               | If argument order matters, use Γ\\_ctx folds and record OrderSpec; version/evolution goes via Γ\\_time (B.1.3 §4.5).                                                                            |\n|            **CC‑A2.11** | Use of legacy nouns “creator/actor/agent” in Core text is prohibited unless they are explicitly typed as **roles** with bearers; the term **“Transformer”** is a local alias, **not** a type.                                                                                        | Scan for bare nouns; replace with “system bearing TransformerRole” or define an alias in the Glossary (A.7 canonical rewrites; E.10 registers).                                               |\n| **CC‑A2.12 (advisory)** | A reified **RoleAssigning** object SHOULD capture `context`, `window`, optional `authority`, `justification (U.Episteme)`, and `provenance (U.Method)`. | Recommended for governance‑heavy domains; it improves explainability without changing Core semantics. |\n\nRecommended for governance‑heavy domains; it improves explainability without changing Core semantics (ties to A.10; B.3 Trust).                                                               |\n\n> **Note.** CC‑A2.2 aligns with **A.7 Role‑domain guards** (“behavioural roles’ domain = system; epistemes bear non‑behavioural roles only”).\n",
        "anti_patterns": "### A.2:9 - Common Anti-Patterns and How to Avoid Them\n\n1. **“Transformer as system subtype.”**\n   ✗ *“`U.TransformerSystem` builds pumps.”*\n   ✓ *“`RobotArm R‑45#Transformer:Plant‑A` executed Work W.”* (Role is a mask; behaviour is Method/Work.)\n\n2. **“Role as part.”**\n   ✗ *“The pump’s role is one of its components.”*\n   ✓ Roles are **never** parts; components are substantial. Keep all `partOf` chains role‑free.\n\n3. **“Episteme acts by itself.”**\n   ✗ *“The PDF enforced the SOP.”*\n   ✓ An **episteme** can hold roles like `ProtocolStandard` **in context**, but only a **system** performs the Method/Work that uses it.\n\n4. **“Context leakage.”**\n   ✗ *“Pluto is Planet and DwarfPlanet.”* (in one tacit space)\n   ✓ *“`Pluto#Planet:Early20thCenturyAstronomy`; `Pluto#DwarfPlanet:IAU_2006_Definition`.”* No contradiction—different bounded contexts. (Illustrative of `U.RoleAssignment` semantics carried forward from the A.2.1.)\n\n",
        "consequences": "### A.2:10 - Consequences\n\n| Benefit                     | Why it matters                                                                                                       | Trade‑off / Mitigation                                                                       |\n| --------------------------- | -------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------- |\n| **Category‑error immunity** | Clear firewall between **identity** (holarchies) and **function** (roles) prevents mixing “parts” with “masks”.      | Slight modelling overhead; templates provide checklists (A.7, A.14).                         |\n| **Operational clarity**     | Who does what, when, and under which mask becomes audit‑ready (`performedBy ⊆ playsRoleOf`).                         | Requires spans on Role assignments; mitigated by default “open‑ended” spans in drafts.          |\n| **Epistemic hygiene**       | Knowledge holons contribute as **evidence** or **constraints**, never as doers.                                      | Authors must rewrite anthropomorphic prose; canonical rewrites help.                         |\n| **Cross-context pluralism** | Same bearer can hold different roles across contexts without contradiction; differences are explicit in the assignment. | Requires declaring the **bounded context**; E.10 eases the ceremony with registers/aliases.  |\n| **Γ‑coherence**             | Order/time/aggregation stay in Γ‑operators, not overloaded into “role\" edges.                                        | Authors learn when to call Γ\\_ctx/Γ\\_time; the Part B on‑ramp is short.                      |\n",
        "rationale": "### A.2:11 - Rationale (post‑2015 cross‑domain corroboration)\n\n*Why insist on roles as contextual masks and externalised transformers?*\n\n1. **Constructor Theory (2015–2022).** Post‑2015 work by Deutsch & Marletto re‑centres physics on **possible tasks and constructors** rather than objects, mirroring FPF’s **TransformerRole**: behaviour is attached to “who can realise a task,” not to substance per se. Our separation of **SubstantialHolon** vs **Role** and the insistence on **external** transformers directly echo this shift. *(Conceptual alignment noted in A.2 Solution and A.12 intent.)* \n2. **Layered Control Architectures (Matni–Ames–Doyle, 2024).** The modern control stack cleanly **externalises** regulators and planners relative to plants. FPF’s obligatory “system bearing TransformerRole” (A.7, A.12) is isomorphic to that separation, keeping supervision and actuation **outside** the controlled holon. \n3. **Active‑Inference / Agency spectrum (2017–2023).** Contemporary models treat agency as **graded** and **contextual** (percept‑act loops tuned by free‑energy bounds). A.13 adopts exactly this: **AgentialRole** is a role worn by a holon, with graded measurements via **Agency‑CHR**, not a static type.\n4. **Basal Cognition & multi‑scale organisation (2019–2024).** Fields & Levin argue for **cross‑scale** control and information flows; FPF encodes this via Γ‑flavours and the **Meta‑Holon Transition** triggers, ensuring Role assignments compose across scales without collapsing identity into function.\n5. **Knowledge ecosystems & safety cases (2018–2025).** Modern assurance relies on **traceable evidence** and conservative integration (no “truth averaging”): our A.10 anchors (SCR/RSCR) and Γ\\_epist’s **weakest‑link** fold implement that discipline and forbid self‑evidence. \n\n> Summing up: post‑2015 science and engineering converge on **roles as contextual capabilities**, **externalised control**, and **traceable evidence**. A.2 codifies these insights in a substrate‑neutral way, keeping the Core small yet powerful.\n",
        "sota_echoing": "### A.2:12 - SoTA-Echoing (post‑2015 alignment, informative)\n\n| Claim (A.2 need) | SoTA practice (post‑2015) | Primary source (post‑2015) | Alignment with A.2 | Adoption status |\n| --- | --- | --- | --- | --- |\n| Roles are context‑dependent, anti‑rigid descriptors rather than structural parts. | Conceptual modeling distinguishes substantial types from role types; roles depend on context/relational situations. | Guizzardi (2019), *Ontological Foundations for Conceptual Modeling*; recent OntoUML/UFO literature. | Maps to `U.Role` as context‑bound schema; keeps `partOf` free of roles. | **Adopt.** |\n| Meaning boundaries must be explicit; reuse across boundaries must be declared, not assumed. | Modern DDD and socio‑technical architecture emphasise explicit bounded contexts and explicit translation/alignment. | Vernon (2016), *Domain‑Driven Design Distilled*; Newman (2021), *Building Microservices*. | Matches `role ∈ Roles(context)` and CC‑A2.4 context binding + explicit bridge discipline. | **Adopt/Adapt.** Adopt boundaries; adapt reuse via FPF Bridges + CL. |\n| Agency should not be attributed to artifacts; treat evidence/provenance as first‑class. | Safety/assurance and governance treat documents as evidence and constraints; provenance is required for claims. | ISO 26262:2018; NIST SP 800‑53 Rev. 5 (2020). | Supports “episteme as justification” and CC‑A2.2/CC‑A2.9 evidence binding. | **Adopt.** |\n| “Agency” is graded and mediated by active systems + policies. | Cognitive/agentic modeling treats agency as spectrum, mediated by control loops and policies. | Friston et al. (2017), Active Inference; basal cognition surveys (2018+). | Supports separating role labels from behavioural work; aligns with A.13/A.15. | **Adopt (with scope).** Keep obligations in CC. |\n\n> **Note.** Prefer citing a maintained SoTA synthesis pack for roles/contexts if your Context has one.\n",
        "relations": "### A.2:13 - Relations\n\n* **Builds on:**\n  **A.1 Holonic Foundation** (role/mereology split), **A.7 Strict Distinction** (role ≠ behaviour; episteme ≠ carrier), **A.14 Advanced Mereology** (no roles in holarchies).  \n* **Specialises / Coordinates with:**\n  **A.13 Agential Role & Agency Spectrum** (behavioural roles over systems; graded agency), **A.15 Role–Method–Work Alignment** (bindsMethod / isExecutionOf discipline). \n* **Constrains / Used by B‑cluster:**\n  **B.1 Universal Algebra of Aggregation (Γ)** (keep order/time in Γ\\_ctx/Γ\\_time; keep provenance in Γ\\_epist), **B.2 Meta‑Holon Transition** (promotion when supervision/closure appears), **B.3 Trust & Assurance** (evidence & congruence).  \n* **Interlocks with E‑cluster (governance & language):**\n  **E.10 Lexical Discipline** (registers, tier disambiguation, local aliases like “Transformer”), **E.5.1 DevOps Lexical Firewall** (ban tooling tokens in Core patterns). \n* **Reinforces:**\n  **A.10 Evidence Graph Referring** (external transformer; SCR/RSCR), **A.12 External Transformer Principle** (agent externalisation). \n",
        "a.2:end": "### A.2:End\n  "
      },
      "content": "### A.2:End\n  ",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.2.1",
      "title": "U.RoleAssignment: Contextual Role Assignment",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.2.1 - U.RoleAssignment: Contextual Role Assignment\n\n> **Type:** Definitional (D)\n> **Status:** Stable\n> **Normativity:** Normative\n\n*with `Role Performance View`, `U.RoleStateGraph (RSG)`, and `Role Characterisation Space (RCS)` hooks*\n\n**Builds on:** A.1 **Holonic Foundation**, A.1.1 **`U.BoundedContext`**, A.2 **Role Taxonomy**.  \n**Coordinates with:** A.13 **Agential Role & Agency Spectrum**, A.15 **Role–Method–Work Alignment**, E.10.D1 **D.CTX (Context discipline)**, E.10.D2 **Strict Distinction**.  \n**Lexical discipline.** *Context* ≡ `U.BoundedContext` (E.10.D1). *Appointment* is **colloquial only**; the canonical term in this specification is **Role Assignment** (see **CC‑LX‑1**).\n\n**Mint vs reuse.** This pattern defines `U.RoleAssignment` and `U.RoleEnactment` and introduces the labels `Role Characterisation Space (RCS)` and `Role State Graph (RSG)` as intensional facets recorded in `RoleDescription` / `RoleSpec`. It reuses existing kernel terms (`U.Holon`, `U.System`, `U.Episteme`, `U.BoundedContext`, `U.Work`, `U.Method`) without changing their meanings.\n",
        "problem": "### A.2.2:2 - Problem (what goes wrong without this concept)\n\n1. **Permission ≠ ability.** A Role assignment authorizes execution in a context; it does **not** prove the system can meet the required **WorkScope** and **WorkMeasures**.\n2. **Recipe ≠ ability.** A Method says *how* to do something; it does not guarantee that *this* holder can meet the target outcomes under the required constraints.\n3. **Execution log ≠ ability.** A past Work record does not, by itself, establish a stable ability; conditions may have been favorable or unique.\n4. **Cross‑team confusion.** Enterprise terms like “capability”, “service”, and the old “function” are used interchangeably; planning, staffing, and assurance become fragile.\n\n",
        "forces": "### A.2.2:3 - Forces (what we must balance)\n\n| Force                                   | Tension we resolve                                                                                                                   |\n| --------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------ |\n| **Stability vs. change**                | Ability is a relatively stable property of a system, yet it evolves with upgrades, wear, calibration, and environment.               |\n| **Universality vs. domain‑specificity** | One universal notion must serve robots, teams, and software services, while letting each domain keep its own performance vocabulary. |\n| **Evidence vs. simplicity**             | We want an ability claim to be evidence‑backed, but the core idea must stay simple enough for planning conversations.                |\n| **Local conditions vs. reusability**    | Ability depends on conditions (inputs, environment); still, the concept must be reusable across contexts via explicit scoping.       |\n\n",
        "solution": "### A.2.2:4 - Solution — define the ability explicitly\n\n#### A.2.2:4.1 Definition\n**`U.Capability`** is a **dispositional property of a `U.System`** that states its **ability to produce a class of outcomes** (i.e., execute a class of Work) **within a declared `U.WorkScope` (conditions/assumptions) and meeting stated `U.WorkMeasures`**. It is **not** an assignment (Role), **not** a recipe (Method), and **not** an execution (Work).\n\n> **One-liner to remember:** *Capability = “can do (within its **WorkScope** and measures)”*, independent of *“is assigned now”* or *“did do at time t”*.\n\n**Capability declaration (summary).** A capability SHALL declare, as **separate** items:\n* **`U.WorkScope`** (*Work scope*) — the set of `U.ContextSlice` under which the capability can deliver the intended `U.Work` (see **A.2.6 §6.4**);\n* **`U.WorkMeasures`** — measurable targets with units evaluated on a **JobSlice** (R‑lane facet);\n* **`U.QualificationWindow`** — the time policy that governs operational admissibility at **`Γ_time`** (R‑lane facet).\n**Note.** This separation supersedes the legacy “envelope + measures + validity interval” bundle. **Work scope is the set of conditions (USM), not a Characteristic; measures are CHR‑characteristics; capability packages both.**\n\n**Reminder (measurement & scope).** *WorkScope* is a **set‑valued USM object** (membership, set algebra) and **not** a CHR Characteristic; *WorkMeasures* are **CHR Characteristics** with declared scales/units. **Admission checks these separately** (see § 10.3 WG‑2/WG‑3).\n\n#### A.2.2:4.2 Conceptual descriptors (not a data schema)\n\nWhen you describe a capability in a model or a review, anchor it by answering these five didactic prompts:\n\n1. **Holder:** *Whose ability is this?* → a specific `U.System`.\n2. **Context:** *In which bounded context were the measures established?* → `U.BoundedContext` (strongly recommended for clarity and comparability).\n3. **Task family:** *Ability to do **what kind** of work?* → reference the relevant **MethodDescription**(s) or method family the system can execute.\n4. **WorkScope:** *Under what conditions?* → inputs/resources/environment assumptions (e.g., voltage, pressure, ambient, tool head).\n5. **Performance measures:** *With what bounds?* → CHR‑style measures (throughput, precision, latency, reliability, MTBF…) with ranges/targets.\n\nOptional descriptors that improve trust without adding bureaucracy:\n\n* **QualificationWindow:** calibration/qualification window for the stated **WorkScope** (abilities drift).\n* **Evidence:** links to test reports, certifications, prior Work summaries (as **Episteme**).\n* **Degradation/upgrade notes:** known change points that affect the **WorkScope**.\n\n> **Didactic guardrail:** Capabilities are stated in **positive, measurable terms** (“can weld seam type W at ±0.2 mm up to 12/min at 18 °C–30 °C”). Avoid role words (“welder”) or recipe detail (step flows) here.\n\n#### A.2.2:4.3 Shorthand for everyday speech\n\nTo keep discussions terse yet precise, teams often write:\n\n* **“S#17 can \\<MethodDescription / task family> @ \\<WorkScope> → \\<measures>.”**\n* Or as a bullet in a capability table scoped to a context, e.g., *AssemblyLine\\_2025 Capability Sheet*.\n\nThis is not a formal notation—just a consistent way to keep the five prompts in view.\n",
        "archetypal_grounding": "### A.2.2:6 - Archetypal grounding (parallel structural and organizational examples)\n\n#### A.2.2:6.1 Physical system on a line (structural example)\n\n* **Holder:** `RobotArm_A` (`U.System`).\n* **Task family:** seam welding per `Weld_MIG_v3` **MethodDescription**.\n* **WorkScope:** workpiece steel grades S235–S355; ambient 18–30 °C; argon mix 92–95 %; torch T‑MIG‑07.\n* **Measures:** bead width 6.0 mm ± 0.2 mm; throughput ≤ 12 seams/min; defect rate < 0.5 %.\n* **Context:** `AssemblyLine_2025`.\n* **Readable claim:** *RobotArm\\_A can execute Weld\\_MIG\\_v3 within the stated **WorkScope** at the stated measures (AssemblyLine\\_2025).*\n* **What this is not:** It is **not** “the welder”—that is a **Role assignment** when assigned on a shift. It is **not** the weld recipe— that is the **MethodDescription**.\n\n#### A.2.2:6.2 Software service in operations (structural, cyber-physical)\n\n* **Holder:** `PlannerService_v4` (deployed system).\n* **Task family:** job‑shop schedule generation per `JS_Schedule_v4` MethodDescription.\n* **WorkScope:** 50–500 jobs; 5–40 machines; hard deadlines only; network latency ≤ 20 ms.\n* **Measures:** schedule completion within 0.95 of theoretical optimum (benchmark set), 98 % on‑time delivery in simulation.\n* **Context:** `PlantScheduling_2025`.\n* **Use:** Steps that “require ScheduleGeneration capability ≥ 0.90 optimality” will only pass if the holder’s capability meets or exceeds that bound.\n\n#### A.2.2:6.3 Organizational unit (enterprise sense)\n\n* **Holder:** `FinanceDept` (`U.System` as OrgUnit).\n* **Task family:** period close per `CloseBooks_v3` MethodDescription.\n* **WorkScope:** IFRS; ERP v12; 8 legal entities; staffing ≥ 6 FTE; cut‑off rules X.\n* **Measures:** close in ≤ 5 business days; adjustment error rate < 0.2 %.\n* **Context:** `OperatingModel_2025`.\n* **Distinction:** This is **ability**; the **Service** “Provide month‑end close” is the external promise derived from this ability once formally offered.\n\n",
        "bias_annotation": "### A.2.1:6 - Bias-Annotation\n\nLenses tested: **Arch**, **Onto/Epist**, **Socio‑tech**, **Prag**, **Did**. Scope: **Kernel** (A‑cluster).\n\n* **Architecture bias (Arch):** treating roles/assignments as structural parts can smuggle function into mereology and break holarchies.  \n  *Mitigation:* keep roles out of BoM/structure trees; close windows instead of deleting history.\n\n* **Onto/Epist bias (Onto/Epist):** anthropomorphising epistemes collapses evidence into agency (“the SOP approved”).  \n  *Mitigation:* only Systems enact Work; Epistemes may justify, constrain, and gate; enforce RE‑1 and CC‑SD‑2.\n\n* **Socio‑technical bias (Socio‑tech):** role eligibility rules can silently encode exclusion, power asymmetries, or discrimination (e.g., “Approver must be X” with no rationale).  \n  *Mitigation:* keep eligibility refinements explicit in the Context, recorded as Episteme policy, and review them under D.2/D.* ethics patterns; prefer capability/competence evidence over demographic proxies.\n\n* **Pragmatic bias (Prag):** over‑localising role labels can fragment reuse and create naming drift.  \n  *Mitigation:* require explicit `:Context` binding and explicit Bridges with CL/loss notes instead of silent equivalence.\n\n* **Didactic bias (Did):** metaphors (“badge”, “mask”, “green gate”) may be misread as informal or security‑only.  \n  *Mitigation:* bind obligations to the Conformance Checklist; keep metaphors as mnemonic only.\n",
        "conformance_checklist": "### A.2.2:8 - Conformance Checklist (normative)\n\n**CC‑A2.2‑1 (Holder type).**\nA capability **belongs to** a **`U.System`** (physical, cyber, socio‑technical, or organizational). Capabilities are **not** assigned to `U.Episteme`.\n\n**CC‑A2.2‑2 (Separation of concerns).**\nA capability is **not** a Role, **not** a Method/MethodDescription, **not** a Work, and **not** a Service. Models **SHALL NOT** use capability declarations to stand in for assignments, recipes, executions, or promises.\n\n**CC‑A2.2‑3 (WorkScope required for operational use).**\nWhen a capability is used to qualify a step or to support planning, its statement **MUST** name a **WorkScope** (conditions/assumptions) and **WorkMeasures** (targets/ranges). **Guards that admit Work MUST test** that the **holder’s WorkScope covers the step’s JobSlice** (i.e., `WorkScope ⊇ JobSlice`) **and that WorkMeasures meet the step’s thresholds, with an explicit `Γ_time` window bound**. Without a WorkScope and measures, a capability is advisory and **SHALL NOT** be used for step admission or assurance claims.\n\n**CC‑A2.2‑4 (Context anchor).**\nCapability statements that drive operational decisions **MUST** be anchored to a **`U.BoundedContext`** (the “Context” whose vocabulary and test norms apply).\n\n**CC‑A2.2‑5 (QualificationWindow).**\nWhen capabilities are used operationally (e.g., to gate Work), the statement **MUST** carry a **QualificationWindow** (calibration window, software version window, etc.) and the guard **MUST name the `Γ_time` window** used for the check. Outside the QualificationWindow, the claim is not admissible for gating.\n\n**CC‑A2.2‑6 (Past work remains past).**\nUpdates to a capability statement **SHALL NOT** retroactively invalidate already recorded Work. Past Work is judged against the capability declaration that was valid **at the time of execution**.\n\n**CC‑A2.2‑7 (Threshold checks are orthogonal to roles).**\nA step that requires both a Role and a capability threshold admits a Work only if **both** are satisfied: (i) the performer’s **Role assignment** is active in the step window; (ii) the **holder’s capability** meets or exceeds the threshold **with `WorkScope ⊇ JobSlice` and within the **QualificationWindow** at the named **`Γ_time`**.**\n\n**CC‑A2.2‑8 (Derived capabilities).**\nIf a capability is claimed for a **composite system** (assembled by Γ), the claim **MUST** be stated as a property of that composite holder (not of its parts) with clear dependency notes (e.g., “valid while Subsystem B meets X”). Details of derivation belong to the context’s methodology, not to this definition.\n\n**CC‑A2.2‑9 (No capability for epistemes).**\nAlgorithms, standards, and documents provide **evidence** or **recipes**; they **do not** “have capability.” Only systems do.\n\n**CC-A2.2-10 (`Γ_time` selector in guards).**\nScope-sensitive guards (including Method–Work gates) **MUST** include an explicit **`Γ_time`** selector indicating the window *W* over which **ScopeCoverage** and **WorkMeasures** are evaluated.\n",
        "anti_patterns": "### A.2.1:8 - Common Anti-Patterns and How to Avoid Them\n\n| #      | Anti‑pattern          | Symptom                                    | Why it’s harmful                   | FPF fix (conceptual move)                                         |\n| ------ | --------------------- | ------------------------------------------ | ---------------------------------- | ----------------------------------------------------------------- |\n| **A1** | **Global role label** | “Alice is Lead Engineer” (nowhere)         | Meaning drifts; untestable         | Always anchor to Context: `Alice#LeadEngineer:ProjectPhoenix`      |\n| **A2** | **Role as part**      | BoM lists “Cooling Function”               | Category error (structure vs role) | Keep BoM structural; model `Pump#Cooling:ThermalMgmt`              |\n| **A3** | **Document acts**     | “The SOP closed the ticket”                | Epistemes don’t enact Work         | Give the doc a status role; make a System enact the step           |\n| **A4** | **Role chains**       | “Transformer assigned to be Agent”         | Hides taxonomy; defeats checks     | Use role algebra (`≤`) and/or require both roles on the Method step |\n| **A5** | **Hidden state**      | Acting while *Authorized? Active?* unclear | Safety & audit gaps                | Use RSG with StateAssertions gating enactment                      |\n| **A6** | **Edition blur**      | Context “ITIL” with no version             | Sense slippage                     | Context card must carry edition (E.10.D1/F.1)                      |\n| **A7** | **Bridge‑by‑name**    | Equating roles across Contexts by label    | Cross‑context drift                | Use F.9 Bridge with CL & loss notes                                |\n ",
        "consequences": "### A.2.2:16 - Consequences\n\n| Benefits                                                                                           | Trade‑offs / mitigations                                                                                                      |\n| -------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------- |\n| **Truthful planning.** Schedulers and managers can ask “can do?” independently of “assigned now?” | **Extra column in tables.** Adding scope/measures/valid‑through is a small burden that repays itself in fewer reschedules. |\n| **Safer gating.** Steps gate on both role and ability; fewer silent failures.                      | **Two checks instead of one.** Keep the checklist simple: *badge + bounds*.                                                   |\n| **Clear service design.** Services become explicit promises built on visible abilities.            | **Temptation to over‑promise.** Keep service SLOs within demonstrated capability measures.                                    |\n| **Clean separation with Dynamics and PBS/SBS.** No more “process” or “function” soup.              | **Some retraining.** Use the litmus tables (from the lexical rules) during onboarding.                                        |\n\n",
        "rationale": "### A.2.1:10 - Rationale\n\n* **Strict Distinction (A.7).** Keeps **identity** (Holon) separate from **assignment** (RoleAssignment), **behaviour** (Method/Work), and **knowledge** (Episteme).\n* **Ontological Parsimony (A.11).** One universal binding, three tiny in‑Context relations (`≤, ⊥, ⊗`), no global role types.\n* **Universal core (A.8).** The same mechanism works across systems (machines, software, teams) and epistemes (standards, requirements), demonstrated in §5.\n* **Lexical discipline (E.10.D1 & E.10.D2).** Roles are **context‑local**; descriptions (RCS, RSG) are **descriptions of intensional roles**, not the roles themselves.\n* **Assurance posture.** Windows + RSG + StateAssertions make authorisation explicit and reviewable; Bridges + CL make cross‑Context reuse explicit and risk‑graded (B.3).\n",
        "sota_echoing": "### A.2.1:11 - SoTA-Echoing (notes)\n\n| Topic this pattern leans on | Post‑2015 anchor (example) | How A.2.1 uses it | Status |\n| --- | --- | --- | --- |\n| Context‑local meaning boundaries | Vernon (2016) *DDD Distilled*; Newman (2021) *Building Microservices* | `role ∈ Roles(context)`; no equivalence by label; cross‑Context reuse via Bridges | Adopt/Adapt |\n| Roles as context‑dependent (anti‑rigid) types | Guizzardi et al. (2018–2022) work on roles in OntoUML/UFO | Separates holder identity from contextual function; prevents type explosion | Adopt |\n| Separation of duties & traceable responsibility | NIST SP 800‑53 Rev. 5 (2020); ISO/IEC 27001:2022 | `⊥` incompatibilities; auditable windows; reviewer independence hooks | Adopt |\n| Continuous authorisation / policy enforcement | NIST SP 800‑207 (2020) Zero Trust Architecture | Window + RSG state as explicit gates; “green gate” as a checkable condition | Adapt |\n| Checklist‑based state progression | OMG Essence 1.2 (2019) | RSG states with explicit checklists and StateAssertions | Adapt |\n| Requirements/standards as first‑class normative artefacts | ISO/IEC/IEEE 29148:2018; ISO 26262:2018 | Epistemes hold Normative‑Status/Requirement roles; Systems act; Work is evaluated against them | Adopt |\n",
        "relations": "### A.2.2:17 - Relations\n\n* **Builds on:** A.1 Holonic Foundation; A.1.1 `U.BoundedContext`; A.2 Role; A.2.1 `U.RoleAssignment`.\n* **Coordinates with:** A.3 (Transformation & role masks); A.15 (Role–Method–Work Alignment).\n* **Constrains:** Step design: thresholds belong on steps; BoM/PBS must stay structural.\n* **Informs:** `U.ServiceClause` definitional pattern (external promises derive from capabilities); `U.Dynamics` definitional pattern (models used as evidence or predictors); Γ/aggregation (capability of composites is stated at the whole).\n* **Lexical guards:** E.10.x **L‑FUNC** (do not call capability “function”); E.10.y **L‑PROC** (do not call capability “process”).\n\n",
        "a.2.1:end": "### A.2.1:End\n\n\n## A.2.2 — U.Capability\n",
        "a.2.2:1___context_(plain‑language_motivation)": "### A.2.2:1 - Context (plain‑language motivation)\n\nIn real projects we must answer two different questions:\n\n* **“Can this system do X?”** — this is about an **ability** inherent to the system.\n* **“Is this system assigned to do X here and now?”** — this is about an **assignment** (a **Role assignment**) inside a bounded context.\n\nTeams frequently blur the two, and then further mix them with **how** the work is done (the **Method**) and **what actually happened** (the **Work**). `U.Capability` isolates **ability as a first‑class concept** so that you can plan realistically, staff responsibly, and audit cleanly.\n",
        "a.2.2:5___clear_distinctions_(litmus_tests_managers_can_apply)": "### A.2.2:5 - Clear distinctions (litmus tests managers can apply)\n\n| If you are talking about…                  | Use                     | Litmus test                                                                                  |\n| ------------------------------------------ | ----------------------- | -------------------------------------------------------------------------------------------- |\n| **assignment** (who is being what, where) | **Role → Role assignment** | Can you reassign to another holder without changing the system’s composition? If yes → Role. |\n| **Ability** (can do within bounds)         | **Capability**          | Would you still say “can do” even if not currently assigned? If yes → Capability.           |\n| **Recipe** (how‑to)                        | **Method / MethodDescription** | Has inputs/outputs and steps but no date/time.                                               |\n| **Execution** (what happened)              | **Work**                | Has a start/end, consumed resources, left a log.                                             |\n| **External promise**                       | **Service**             | Framed as “we provide/guarantee to others.”                                                  |\n| **Law/model of change**                    | **Dynamics**            | Describes state evolution, not an ability of one system.                                     |\n\n**Two useful corollaries**\n\n* A step in a Method may **require** a Role; **optionally** it may also stipulate a **capability threshold** (e.g., precision ≤ 0.2 mm). assignment and ability are checked separately.\n* A Service depends on **having** the needed capabilities **and** being **assigned** to deliver under the Service’s context.\n\n",
        "a.2.2:7___bias‑annotation_(as_in_cluster‑e_patterns)": "### A.2.2:7 - Bias‑Annotation (as in cluster‑E patterns)\n\n* **Lenses tested:** `Arch`, `Prag`, `Did`, `Epist`.\n* **Scope declaration:** Universal; holder constrained to `U.System`.\n* **Rationale:** Gives the kernel a clean, reusable **ability concept** so Role (assignment), Method (recipe), Work (execution), and Service (promise) do not collapse into each other. Keeps planning talk truthful and checkable without introducing governance machinery here. **`U.Capability`** is a **dispositional property of a `U.System`** that states its **ability to produce a class of outcomes** (i.e., execute a class of Work) **within a declared `U.WorkScope` (conditions/assumptions) and meeting stated `U.WorkMeasures`**.\n",
        "a.2.2:9___capability_thresholds_on_steps_(how_a.15_uses_this_concept)": "### A.2.2:9 - Capability thresholds on steps (how A.15 uses this concept)\n\nA step in a **Method** may define **required roles** (assignment) and **capability thresholds** (ability). A Work passes the gate if:\n\n1. **assignment check:** the Work’s `performedBy` points to a valid **Role assignment** that covers the step window and satisfies the role relation (including specialization `≤` inside the context).\n2. **Ability check:** the **holder** of that Role assignment has a **capability** whose **WorkScope covers the step’s JobSlice** (i.e., declared superset) and whose **WorkMeasures** meet the step’s threshold(s) within `Γ_time(W)` and while the capability’s **QualificationWindow** includes *W*.\n\n**Idioms managers can reuse (plain text):**\n\n* *“S1 requires `IncisionOperatorRole` and Precision ≤ 0.2 mm (OR\\_2025 norms) **in window W**.”*\n* *“S2 requires `PlannerRole`, **WorkScope ⊇ JobSlice\\[W]**, and Optimality ≥ 0.90 on `JS_Schedule_v4`.”*\n\n**What to avoid:**\n\n* Putting “Precision ≤ 0.2 mm” into the Role name. Keep thresholds attached to the **step**; keep **ability** on the **holder**.\n\n",
        "a.2.2:10___time_and_change_(calibration,_drift,_upgrades)": "### A.2.2:10 - Time and change (calibration, drift, upgrades)\n\nCapabilities are **stable but not static**. Three simple practices keep reasoning honest:\n\n* **Qualification windows.** Abilities drift. Put a **QualificationWindow** on the statement (e.g., “valid for software v4.2; recalibration due 2025-09-30”).\n* **Change points.** Note upgrades/downgrades that affect the WorkScope or measures.\n* **Snapshot at execution.** When Work is recorded, it is implicitly tied to the **then‑current** capability statement; later edits do not rewrite history (see CC‑A2.2‑6).\n\n**Manager’s rule of thumb:** if you would reschedule a job after a tool change, the capability statement needs a new window.\n\n",
        "a.2.2:11___composition_and_γ_(how_assembled_systems_“can_do”)": "### A.2.2:11 - Composition and Γ (how assembled systems “can do”)\n\nΓ builds a **new holder** (a composite system). Its capability is not the algebraic sum of parts; it is an **ability of the whole** under its own WorkScope.\n\n* **Express at the whole.** “Cell\\_3 can place 12 PCB/min with ±0.1 mm” — that is a capability of **Cell\\_3**, not of the pick‑and‑place head alone.\n* **State dependencies.** “Valid while Feeder\\_A delivers reels at ≥ X; vision subsystem calibrated ≤ 72 h ago.”\n* **Constructor vs. transformer.** The **ConstructorRole** builds the composite (Γ); the resulting **TransformerRole** may later act on products. Capability belongs to the holder relevant to the action (builder’s ability vs operator’s ability).\n\n",
        "a.2.2:12___interaction_with_service_(external_promise)": "### A.2.2:12 - Interaction with Service (external promise)\n\nA **Service** is an **external promise**. It relies on capability but is not identical to it.\n\n* **From capability to service.** You normally **derive** a Service by taking a capability and **fixing** the promise outward (e.g., “We guarantee close ≤ 5 days”).\n* **From service back to capability.** If the promise raises the bar (e.g., tighter SLA), the underlying capability must meet or exceed it under the service’s context.\n* **Staffing.** Delivering a Service still requires **Role assignments**; capability alone does not authorize action.\n\n**Memory aid:** Capability = *can do*; Service = *promise to others that we will do*.\n\n",
        "a.2.2:13___interaction_with_dynamics_(laws_vs._abilities)": "### A.2.2:13 - Interaction with Dynamics (laws vs. abilities)\n\n* **Dynamics** describe **how states evolve** (models, laws, trajectories).\n* **Capability** says **what this system can achieve** within an WorkScope.\n* Dynamics often serve as **evidence** or **explanatory models** for capability but are **not** the capability itself.\n\n**Physics example:** an “isothermal process” (process here as transformation) is a **Work** instance whose path is explained by a **Dynamics** episteme; a lab rig’s ability to run that path repeatably is its **capability**.\n",
        "a.2.2:14___anti‑patterns_(and_the_right_move)": "### A.2.2:14 - Anti‑patterns (and the right move)\n\n* **Role‑as‑capability.** “Welder role ensures ±0.2 mm.” → Keep **role** as assignment; put **precision** in a **capability** on the holder; put the **threshold** on the **step**.\n* **Recipe‑as‑capability.** “We have the ‘Etch\\_Al2O3’ capability.” → Recipe is **Method/MethodDescription**; ability is “can execute Etch\\_Al2O3 within WorkScope E at measures M.”\n* **Work‑as‑capability.** “We did it once, so we can.” → One Work log is not a stable ability; state envelope and measures if you want a capability claim.\n* **Context‑less claims.** “This tool can machine titanium.” → Say **where and under what bounds** (context + WorkScope + measures).\n* **Stuffing capabilities into BoM/PBS.** Structure lists **what it is**; capabilities belong to **what it can do** (the holder), not inside the parts list.\n* **Service‑as‑capability.** “We have the Month‑end Close capability (promise).” → Promise is **Service**; ability is internal, promise is external.\n\n",
        "a.2.2:15___migration_notes_(quick_wins_for_existing_texts)": "### A.2.2:15 - Migration notes (quick wins for existing texts)\n\n1. **Underline WorkScopes.** For every “can do” sentence, add **conditions** and **measures**; otherwise treat it as background color, not a gate.\n2. **Pull thresholds out of roles.** Move “≤ 0.2 mm”, “≥ 0.90 optimality” from role labels into **step requirements**; leave roles clean (assignments).\n3. **Pin contexts.** Add the bounded context name to each capability table (“Capability Sheet — AssemblyLine\\_2025”).\n4. **Snapshot validity.** Add a “valid through” column (software version or calibration horizon).\n5. **Separate recipe/execution.** Move flowcharts under **MethodDescription**, runs under **Work**; link the capability to the **holder** with references to those specs.\n\n",
        "a.2.2:18___didactic_quick_cards_(reuse_in_specs_and_slides)": "### A.2.2:18 - Didactic quick cards (reuse in specs and slides)\n\n* **Capability = can do (within bounds).** assignment ≠ ability ≠ recipe ≠ execution ≠ promise.\n* **Gate every critical step with two checks:** *badge (Role assignment)* + *bounds (Capability)*.\n* **Write the Context on every claim:** context name, **WorkScope**, measures, **QualificationWindow/valid-through**.\n",
        "a.2.2:end": "### A.2.2:End\n"
      },
      "content": "### A.2.2:End\n",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.2.3",
      "title": "`U.ServiceClause` (Service Clause)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.2.3 - `U.ServiceClause` (Service Clause)\n",
        "a.2.3:1___context": "### A.2.3:1 - Context\n\nAcross domains the word **service** is used for many different things: a server or **provider**, an **API**, a **procedure**, a **run**, a **department**, even a **product bundle**. Such polysemy is productive in everyday speech but toxic in a normative model.\n\nFPF therefore reserves **`U.ServiceClause`** for exactly one kernel meaning: **promise content** — a **service clause** (a consumer‑facing promise statement). Any other “service” sense MUST be modeled explicitly as `U.System`, `U.RoleAssignment`/principal, `U.MethodDescription`, or `U.Work` inside an appropriate `U.BoundedContext` and, in normative prose, MUST be written with an explicit **facet head phrase** per **A.6.8 (RPR‑SERV)**.\n\n**Legacy alias (compatibility).** `U.Service` is a deprecated alias for `U.ServiceClause`. It MAY appear in pre‑refactor material, but conforming new normative text and machine‑checkable artefacts SHALL use `U.ServiceClause`.\n\nThis keeps the kernel minimal while keeping the prose readable to non‑mathematicians: the canonical symbol is `U.ServiceClause` (legacy alias: `U.Service`), and the head kind in normative text is always *service clause*.\n\n**Modularity note.** A.2.3 defines only the promise‑content object (the **service clause**) and its direct links to roles, access specification, acceptance criteria, and work evidence. The multi‑facet “service situation” bundle that also names provider principals/systems/access points/commitments/acts is handled as a precision‑restoration lens in **A.6.8 (`serviceSituation(…)`)**. Contract‑talk unpacking (and routing of “contract / SLA / guarantee” language) is handled by **A.6.C**, which calls A.6.8 when service‑cluster tokens appear.\n\nIn the Role–Method–Work alignment, the **service clause** must say something **external‑facing** and **consumer‑oriented**, yet remain separate from *how* the provider does it (Method/MethodDescription) and *what actually happened* (Work).\n\n> Intuition: a **service** is the promise you advertise and are judged by; **work** is what you do to keep that promise; **method/spec** is how you know what to do.\n> (Normative head-kind rewrite): a **service clause** is the promise clause you advertise and are judged by; **work** is what you do (and what can be evidenced) to satisfy that promise; **method/spec** is how you know what to do.\n\n**Lexical note (L‑SERV / RPR‑SERV)**\n\nThe surface forms *service/service‑level/service use/service access* (and the adjacent cluster *service provider*, *server*) are **ambiguous** across domains. In the kernel, **`U.ServiceClause`** (legacy alias: `U.Service`) is reserved for promise content only and is written in prose as a **service clause**.\n\nNormative prose therefore SHALL treat the bare head noun **service** as **always‑unpack** (PTG=Guarded): every head‑noun occurrence MUST be rewritten to a facet head phrase (service clause / service provider principal / service access point / service delivery system / …) or to the correct underlying FPF object (team, ticket, endpoint host, procedure, work item), per **A.6.8 (RPR‑SERV)**.\n\nE.10’s lexical anchor **L‑SERV** SHOULD be implemented as “pointer + lint rule” to A.6.8: the short rule names the hazard, while A.6.8 provides the full rewrite recipe and the facet head phrase set.\n\n",
        "problem": "### A.2.3:2 - Problem\n\nWithout a first‑class `U.ServiceClause`, models drift into five recurring errors:\n\n1. **Provider = Service.** Calling the **system** or **team** “the service” collapses structure with promise.\n2. **API = Service.** Treating an **interface/endpoint** as the service hides the consumer‑oriented promise (effect + acceptance).\n3. **Process = Service.** Mapping a **procedure/Method** (or a WorkPlan) to “service” confuses recipe/schedule with the external commitment.\n4. **Run = Service.** Logging **Work** as “a service” erases the Standard/promise layer and breaks SLA reasoning.\n5. **Business ontology lock‑in.** Large domain schemes (e.g., “business service” stacks) are imported wholesale, losing FPF’s universality and comparability across contexts.\n\n",
        "forces": "### A.2.3:3 - Forces\n\n| Force                                       | Tension                                                                                                       |\n| ------------------------------------------- | ------------------------------------------------------------------------------------------------------------- |\n| **External promise vs internal capability** | Service must be consumer‑facing, while capability is provider‑internal.                                       |\n| **Specification vs execution**              | Service is a **specifiable** obligation; value is **realised** only by runs of Work.                          |\n| **Universality vs domain richness**         | One kernel meaning must cover IT, utilities, healthcare, public services—without absorbing domain taxonomies. |\n| **Measurability vs privacy**                | Consumers need SLO/SLA and outcomes; providers want implementation freedom (Method autonomy).                 |\n| **Stability vs evolution**                  | Services version and change without invalidating prior Work evidence.                                         |\n\n",
        "solution": "### A.2.3:4 - Solution — The unified concept `U.ServiceClause`\n\n**Definition (normative).**\nWithin a `U.BoundedContext`, a **`U.ServiceClause`** is an **externally oriented promise clause**: a context‑local statement of (i) a **promised external effect**, (ii) **eligibility + access** (how a consumer may request/use), and (iii) **acceptance criteria** (SLO/SLA‑like targets) by which fulfillment is judged.\n\n`U.ServiceClause` is **promise content** (`U.Episteme`), not a deontic binding. One or more explicit **`U.Commitment`** objects (A.2.8) MAY reference a `U.ServiceClause` as payload to bind an accountable principal/role‑assignment; the clause itself does not “obligate” anyone until such a commitment is represented.\n\nIn normative prose, the head phrase for `U.ServiceClause` is **service clause** (or **service promise clause**) per A.6.8; the bare noun *service* is not a valid shorthand for this kernel object.\n\n* **Type:** `U.Episteme` (a promise clause on a carrier).\n* **Scope:** design‑time concept; judged at run‑time by evidence from `U.Work`.\n* **Time stance:** design-time concept; judged at run-time by evidence from `U.Work`.\n* **Orientation:** consumer‑facing (“what you can rely on”), as opposed to capability (“what we can do”).\n* **Prose head (normative):** *service clause* (Tech) / *service promise clause* (Plain). (Both twins retain an explicit **clause** head‑kind to avoid act/content ambiguity and to comply with A.6.8 headword governance.)\n\n#### A.2.3:4.1 - Core structure (minimal fields)\n\n```\nU.ServiceClause {\n  context        : U.BoundedContext,   // where the promise is meaningful\n  purpose        : Text/Episteme,      // the externally observable effect/value\n  providerRole   : U.Role,             // role kind that may provide it (not a person/system)\n  consumerRole?  : U.Role,             // optional role kind allowed to consume\n  claimScope?    : U.ClaimScope,       // where the promise holds (G) — operating conditions/populations/locales\n  accessSpec?    : U.MethodDescription,       // service access spec: request-facing interface/eligibility; not an access point system\n  acceptanceSpec : U.Episteme,         // targets: SLO/SLA, quality/throughput/latency/accuracy…\n  unitOfDelivery?: Episteme,           // how delivered units are counted/measured\n  version?       : SemVer/Text,\n  timespan?      : Interval\n}\n```\n\n* `providerRole` and `consumerRole` are **role kinds**; the actual performers are **RoleAssignments** at run‑time.\n* `acceptanceSpec` defines **what counts as fulfilled** (the test).\n* `accessSpec` is **how to ask** (eligibility, protocol, counter, desk, API).\n* **Internal delivery methods/runbooks are not part of the service clause.** Model them as `U.MethodDescription` and relate them to the clause via `serviceSituation(…)` (A.6.8) or explicit context relations; providers retain **Method autonomy**.\n\n#### A.2.3:4.2 - What `U.ServiceClause` is **not**\n\n* **Not a provider:** use `System#ServiceProviderRole:Context` `U.RoleAssignment`.\n* **Not a deontic commitment:** that is `U.Commitment` (A.2.8) referencing the service clause as payload.\n* **Not an access point:** addressable “services/servers/desks/endpoints” are `U.System` (see A.6.8: *service access point* / *service delivery system*).\n* **Not a method/recipe:** that is `U.Method/MethodDescription`.\n* **Not a run/incident/ticket:** that is `U.Work`.\n* **Not a schedule:** that is `U.WorkPlan`.\n* **Not a capability:** capability is **provider‑intrinsic ability**; service is **outward promise**. A service may **require** certain capabilities, but it **is not** the capability.\n* **Not a scope label:** do **not** use *applicability*, *envelope*, *generality*, or *validity* as **scope characteristics**; declare **Claim scope (G)** or **Work scope** explicitly where needed (A.2.6).\n\n#### A.2.3:4.3 - Position in the enactment chain\n\n* **Design‑time:**\n  The context **declares Claim scope (G)** for acceptance (operating conditions, populations, locales) per A.2.6.\n  The context may assert: `bindsCapability(ServiceProviderRole, Capability)`.\n  Providers choose `Method/MethodDescription` to realise the promised effect described by the service clause.\n\n* **Run‑time:**\n  A **consumer** performs `Work` (e.g., a request/visit) — `performedBy: ConsumerRoleAssigning`.\n  The **provider** performs `Work` to fulfil the service clause — `performedBy: ProviderRoleAssigning`.\n  Delivered `Work` instances are evaluated against `acceptanceSpec` and **counted** via `unitOfDelivery`.\n  SLA/SLO outcomes are therefore functions over **Work evidence**, not over the service clause object itself.\n \n  (Terminology note: use `…RoleAssignment` consistently for the run‑time enactor relation; avoid the “RoleAssigning” variant unless it is a separately defined kind in the Context.)\n\n> **Memory hook:** *Service clause promises, Method describes, Work proves.*\n\n#### A.2.3:4.4 - Didactic card: The service delivery chain (clause → commitment → situation → work → acceptance)\n\n> **Didactic (non‑normative).** This is a one‑screen “map” that stitches the modular pieces together:\n> `U.ServiceClause` (A.2.3) → `U.Commitment` (A.2.8) → provider `U.RoleAssignment` (A.2.1) → *serviceSituation(...)* facet slots (A.6.8 lens) → `U.Work + carriers` (A.15) → acceptance verdict (A.2.3).\n>  \n> This is **not new ontology**. It is a reader‑safety diagram that prevents two common category errors:\n> (i) treating `U.ServiceClause` as something addressable (“the service you call”), and\n> (ii) treating `serviceSituation(...)` as semantics rather than a *binding lens* over already‑defined kinds.\n\n```mermaid\nflowchart LR\n  SC[\"Service clause<br/>(U.ServiceClause · Episteme)\"]\n  C[\"Commitment<br/>(U.Commitment · D)\"]\n  RA[\"Provider role assignment<br/>(U.RoleAssignment · accountable subject in Context/window)\"]\n\n  subgraph LENS[\"Optional lens (A.6.8): serviceSituation(...)\"]\n    AS[\"Access spec<br/>(U.MethodDescription · request‑facing)\"]\n    AP[\"Access point<br/>(U.System · addressable)\"]\n    DS[\"Delivery system<br/>(U.System · realizer)\"]\n    DM[\"Delivery method<br/>(U.MethodDescription · runbook/procedure)\"]\n  end\n\n  W[\"Work + evidence<br/>(U.Work + carriers · E)\"]\n  V[\"Acceptance verdict<br/>(pass/fail/grade; computed)\"]\n\n  SC -->|\"payload/ref\"| C\n  C -->|\"binds subject\"| RA\n\n  RA --> AS\n  RA --> AP\n  RA --> DS\n  RA --> DM\n\n  AS -->|\"invoked via\"| W\n  AP -->|\"requests arrive via\"| W\n  DS -->|\"fulfillment work\"| W\n  DM -->|\"procedure used in\"| W\n\n  W -->|\"evaluate\"| V\n  SC -->|\"acceptanceSpec\"| V\n```\n\n**Reading guide (one breath).**\n* The **service clause** is *what is promised* (promise content).\n* The **commitment** is *who is bound* (deontic accountability) and it **references** the clause.\n* The **provider role assignment** is the accountable subject *that can act* in a given Context/window.\n* `serviceSituation(...)` (A.6.8) is a **facet‑binding lens** that names the common “service talk” participants (access spec / access point / delivery system / delivery method) **without** collapsing them into the clause.\n* **Work + evidence** is what happened; the **acceptance verdict** is computed by applying the clause’s `acceptanceSpec` to work evidence (not by reading the clause, and not by “looking at the service” as a system).\n\n**Litmus rule (addressability).**\nIf you can *call / connect to / visit / restart / scale* it, you are talking about a **service access point** (system facet), not the **service clause** (promise content).\n\n",
        "archetypal_grounding": "### A.2.3:5 - Archetypal grounding (engineer‑manager friendly)\n\n| Domain                    | **`U.ServiceClause` (promise)**                           | Provider & Consumer (as Roles)                                   | Access (how to ask)                  | Fulfilment (Work)                        | Typical acceptance targets                  |\n| ------------------------- | --------------------------------------------------------- | ---------------------------------------------------------------- | ------------------------------------ | ---------------------------------------- | ------------------------------------------- |\n| **Cloud/IT**              | “**Object Storage**: durable PUT/GET of blobs up to 5 TB” | `CloudTeam#ServiceProviderRole`, `BackupJob#ServiceConsumerRole` | `S3_API_Spec_vX` (`MethodDescription`)      | Each PUT/GET run; data durability checks | Availability ≥ 99.9%, durability 11×9       |\n| **Manufacturing Utility** | “**Compressed air** at 8 bar in Zone B”                   | `Maintenance#Provider`, `LineB#Consumer`                         | Manifold access rules (`AccessSpec`) | Compressor cycles & delivery logs        | Pressure window, purity class, flow ceiling |\n| **Public Service**        | “**Passport issuance** within 20 days”                    | `Agency#Issuer`, `Citizen#Applicant`                             | Portal/desk SOP (`AccessSpec`)       | Case handling runs                       | Lead time ≤ 20 days, defect ≤ 1%            |\n\n**Key takeaway:** the **same kernel object** models S3, a plant utility, and a government service: a **promise with access and acceptance**. Everything else (APIs, compressors, clerks, workflows, tickets) is mapped via **Role/Method/Work**.\n\n",
        "a.2.3:6___mapping_the_common_“service”_picture_to_fpf_(didactic_bridge)": "### A.2.3:6 - Mapping the common “service” picture to FPF (didactic bridge)\n\nThe popular service diagrams (provider ↔ access ↔ use ↔ capability/activity) map to FPF as follows:\n\n* **Agent (as Service Provider)** → `System#ServiceProviderRole:Context` (`U.RoleAssignment`).\n* **Service Agreement / SLA** → `U.ServiceClause.acceptanceSpec` (+ optional `WorkPlan` for windows).\n* **Operating conditions / “where the promise holds”** → `claimScope : U.ClaimScope (G)` (or embedded in `acceptanceSpec`) per A.2.6.\n* **Service Presence / Access** → `accessSpec : MethodDescription` (interface/eligibility); actual endpoints are **systems** playing interface roles.\n* **Individual Service Use** → **consumer and provider `U.Work`** instances linked to the `U.ServiceClause` they fulfil.\n* **Service‑Enabled Capability / Activity** → effects on the consumer side: either a **Capability** gained/used, or **Work** performed; do **not** reify as a new kernel type.\n\n(Where a domain needs richer structures—catalogs, exposure layers, charging, entitlement—model them **in the domain context** and relate them to `U.ServiceClause` via `U.RoleAssignment` and alignment bridges.)\n",
        "conformance_checklist": "### A.2.3:7 - Conformance Checklist (normative)\n\n**CC‑A2.3‑0 (Prose head phrase).**\nIn normative prose, an instance of `U.ServiceClause` (legacy alias: `U.Service`) SHALL be referred to as a **service clause** (or **service promise clause**) and SHALL NOT be referenced by the bare head noun *service*. Unqualified *service* usage (and the co‑moving cluster *service provider* / *server*) SHALL be unpacked per A.6.8 (RPR‑SERV).\n\n**CC‑A2.3‑1 (Type).**\n`U.ServiceClause` **IS** an `U.Episteme` (a consumer‑facing **service clause** on a carrier). It is **not** a `U.System`, **not** a `U.Method/MethodDescription`, **not** a `U.Work`, and **not** a `U.WorkPlan`.\n\n**CC‑A2.3‑2 (Context).**\nEvery **service clause** **MUST** be declared **inside** a `U.BoundedContext`. Names and meaning are **local**; cross‑context reuse requires a Bridge (`U.Alignment`).\n\n**CC‑A2.3‑3 (Role kinds, not people/systems).**\n`providerRole` and (if used) `consumerRole` **MUST** be **role kinds** (see A.2). Actual performers at run‑time are `U.RoleAssignment`s.\n\n**CC-A2.3-4 (Acceptance).**\n`acceptanceSpec` **MUST** be present and **MUST** define how delivered `U.Work` is judged (pass/fail/graded) against declared targets (SLO/SLA-like), and **MUST** declare **Claim scope (G)** where relevant (operating conditions, populations, locales). Every verdict binds to an explicit **Γ_time** window.\n\n**CC‑A2.3‑5 (Access).**\nIf consumers must request/obtain the service through an interface, `accessSpec` **MUST** reference the MethodDescription that defines eligibility and invocation rules (API/desk/SOP). If the service is ambient (e.g., compressed air on a manifold), accessSpec **MAY** be omitted, but the eligibility condition **MUST** be stated in the context.\n\n**CC‑A2.3‑6 (Unit of delivery).**\nIf performance is counted/charged, `unitOfDelivery` **SHOULD** be declared (e.g., “request”, “kWh”, “case”).\n\n**CC‑A2.3‑7 (No actuals on Service).**\nResource/time **actuals** and incident logs **MUST** attach to `U.Work` only (A.15.1). Services carry no actuals.\n\n**CC‑A2.3‑8 (Capability requirement).**\nIf the context requires provider abilities, it **MUST** express them as `bindsCapability(providerRole, Capability)` in the context, not by stuffing capabilities into the Service object.\n\n**CC‑A2.3‑9 (Versioning & timespan).**\nService clauses **MAY** carry `version`/`timespan`. A `U.Work` that claims/fulfils a service clause **MUST** record which service‑clause version it used.\n\n**CC‑A2.3‑10 (Lexical rule).**\nUnqualified head‑noun uses of *service* (and the co‑moving cluster *service provider* / *server*) in normative prose **MUST** be disambiguated per **A.6.8 (RPR‑SERV)** and its lexical anchor **L‑SERV** (E.10). When the intended referent is `U.Service`, the head phrase SHALL be **service clause**.\n\n**CC‑A2.3‑11 (No mereology).**\nDo **not** place a Service in PBS/SBS or treat it as a part/component. Structural assemblies live in PBS/SBS; Service is a promise.\n\n**CC‑A2.3‑12 (Plan–run split).**\nWindows and calendars belong to `U.WorkPlan` (A.15.2). Fulfilment evidence belongs to `U.Work` (A.15.1).\n\n**CC-A2.3-13 (Scope lexicon & guards).**\nDeprecated labels *applicability/envelope/generality/validity* **MUST NOT** appear as scope characteristics in guards or conformance blocks. Use **`U.ClaimScope (G)`** for epistemes and **`U.WorkScope`** for capabilities (A.2.6/A.2.2). Scope-sensitive guards **MUST** use **ScopeCoverage** with explicit **Γ_time** selectors.\n\n**CC-A2.3-14 (Bridges & CL).**\nCross-context mappings via Bridges keep **F/G** stable; **CL** penalties apply to **R**. A mapping **MAY** recommend **narrowing** the mapped **Claim scope (G)** as best practice (A.2.6/B-line).\n",
        "relations": "### A.2.3:11 - Relations\n\n* **Builds on:** A.1.1 `U.BoundedContext`; A.2 `U.Role`; A.2.1 `U.RoleAssignment`; A.2.2 `U.Capability`; **A.2.6 `U.Scope` / `U.ClaimScope (G)` / `U.WorkScope`**.\n* **Coordinates with:** A.3.1 `U.Method`; A.3.2 `U.MethodDescription`; A.15.1 `U.Work`; A.15.2 `U.WorkPlan`; **A.6.8 (RPR‑SERV)** for normative prose unpacking of the service cluster; **B-line Bridges & CL (CL→R; may recommend ΔG narrowing)**.\n* **Constrained by lexical rules:** **E.10 L‑SERV** (service disambiguation); also **L‑FUNC**, **L‑PROC**, **L‑SCHED**, **L‑ACT**.\n* **Informs:** Reporting/assurance patterns (service KPIs, SLA dashboards); catalog/exposure patterns in domain contexts.\n\n",
        "a.2.3:9___anti‑patterns_(and_the_right_move)": "### A.2.3:9 - Anti‑patterns (and the right move)\n\n* **“The microservice **is** the service.”**\n  Rewrite to facet‑explicit terms (A.6.8): the microservice is typically a **service delivery system** (`U.System`) and/or a **service access point** (`U.System`). Keep the **promise content** as a **service clause** in `U.ServiceClause` (legacy alias: `U.Service`), and bind accountability via `U.Commitment` if needed.\n\n* **“The API **is** the service.”**\n  The API is typically a **service access spec** (`accessSpec : MethodDescription`) (and systems playing interface roles). The **service clause** is the promise content judged by `acceptanceSpec`.\n\n* **“Our **process** is the service.”**\n  Process/recipe is `U.Method/MethodDescription`; schedule is `U.WorkPlan`. The **service clause** is **what is promised to the consumer**.\n\n* **“The **ticket** is the service.”**\n  A ticket/case is `U.Work` (and perhaps a `WorkPlan` item). Evidence and outcomes sit on Work, not on the service clause.\n\n* **“Attach cost to the service.”**\n  Actual cost/time attach to `U.Work` only (A.15.1). Service metrics are computed **from** Work.\n\n* **“Put service under BoM.”**\n  Services are not structural parts. Keep PBS/SBS clean.\n\n* **“Hard‑code people into the service.”**\n  Name **role kinds** in the service clause (`U.Service`); run‑time performers are `U.RoleAssignment`s.\n\n",
        "a.2.3:10___migration_notes_(quick_wins)": "### A.2.3:10 - Migration notes (quick wins)\n\n1. **Name the promises.** List 5–15 consumer‑facing promises your context lives by; reify each as `U.ServiceClause` with `acceptanceSpec` and, if needed, `accessSpec` and `unitOfDelivery`.\n2. **Separate provider from service clause.** Keep systems/teams as `U.System`; make them providers via `…#ServiceProviderRole:Context`.\n3. **Wire evidence.** Ensure every relevant `U.Work` has `claimsServiceClause` (and `fulfilsServiceClause` post‑verdict).\n4. **Choose metrics.** For each Service, define 2–4 KPIs and the **exact** Work-based formulas (availability, lead-time, rejection rate, cost-to-serve), and declare the **Claim scope (G)** and **Γ_time** policy used for each KPI.\n   → For each **service clause**, define 2–4 KPIs and the exact Work-based formulas, with explicit `Γ_time`.\n5. **Bridge domains.** If a business ontology already exists (“business/technical/internal service”), keep it in its own context and map to `U.Service` via Bridges.\n6. **Tidy language.** Apply **A.6.8 (RPR‑SERV)** / **L‑SERV**: ban unqualified “service” as a synonym for server/team/process/ticket in normative prose; map them explicitly.\n\n",
        "a.2.3:12___didactic_quick_cards_(engineer‑manager_ready)": "### A.2.3:12 - Didactic quick cards (engineer‑manager ready)\n\n* **Service clause = Promise content.** *What we advertise and are judged by.*\n* **Method/Spec = Recipe.** *How we usually do it (provider‑internal).*\n* **Work = Evidence.** *What actually happened and consumed resources.*\n* **Provider/Consumer = Roles.** *assignment via RoleAssigning at run‑time.*\n* **Metrics from Work.** *Uptime, lead time, quality are computed from Work, not from the Service object.*\n* **Keep PBS/SBS clean.** *Services are not parts; they are promises.*\n  ",
        "a.2.3:end": "### A.2.3:End\n"
      },
      "content": "### A.2.3:End\n",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.2.4",
      "title": "`U.EvidenceRole`",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.2.4 - `U.EvidenceRole`\n\n> *This pattern defines how a knowledge artefact (“episteme”) serves as **evidence** for a specific claim or theory **inside a bounded context**. It is a **non-behavioural** role enacted via `U.RoleAssignment`; the evidence-role assignment **must** declare the **target claim**, the **claim-scope**, and a **timespan of relevance**. Evidence is a classificatory status of an episteme; it is not an action and it is not an assignment of an actor.*\n",
        "a.2.4:1___context_and_intent": "### A.2.4:1 - Context and intent\n\nFPF separates **what exists** (holons and their kinds) from **what acts** (systems under roles performing work) and from **what is known** (epistemes carried on symbols). Roles are contextual masks that holons may wear; role meanings are **local to a `U.BoundedContext`**. In this setting, we need a kernel‑level way to say that *this* episteme **counts as evidence** about *that* claim, **here**, and **for this period**, without confusing evidence with services, methods, or work. \n\n**Intent.** Provide one uniform, discipline‑neutral role by which an episteme can be assigned as evidence, while keeping:\n\n* **Agency** on systems performing `U.Work` (not on epistemes).\n* **Promise** and Standardual language on `U.ServiceClause` (not on evidence).\n* **Recipe** and eligibility on `U.Method` / `U.MethodDescription` (not on evidence).\n",
        "problem": "### A.2.4:2 - Problem\n\n1. **Anthropomorphising epistemes.** Models say “the paper proves…”, implicitly treating a document as an actor.\n2. **Citation without scope.** Links exist but lack explicit **target claim**, **applicability scope**, and **time window**.\n3. **Deductive versus empirical conflation.** A formal derivation and a lab dataset are both called “support” although their semantics and ageing differ.\n4. **Staleness and drift.** Empirical evidence ages; without explicit validity windows, stale evidence keeps influencing conclusions.\n5. **Cross‑context leakage.** Evidence is interpreted as “global,” skipping the bridge that is required to move meaning across contexts.\n",
        "forces": "### A.2.4:3 - Forces\n\n| Force                                     | Tension to resolve                                                                                |\n| ----------------------------------------- | ------------------------------------------------------------------------------------------------- |\n| **Universality versus domain practice**   | One role must cover proofs, datasets, replications, benchmarks, model fits, calibrations.         |\n| **Static truth versus ageing confidence** | Axiomatic proofs are stable relative to a theory; empirical evidence decays and requires refresh. |\n| **Local meaning versus reuse**            | Meaning is context‑local; reuse must pass through explicit bridges, not tacit “global truth.”     |\n| **Clarity versus brevity**                | Kernel must stay expressive without importing domain governance or tooling procedures.            |\n",
        "solution": "### A.2.4:4 - Solution — Term and definition\n\n**Term.**\n`U.EvidenceRole` — a **non-behavioural role** that a `U.Episteme` may play **inside a `U.BoundedContext`** to serve as **evidence** for a declared target claim (or theory/version).\nThe target claim, its applicability scope, polarity, weighting model, and other normative facets are **properties of the `U.EvidenceRole` definition itself** *within that bounded context*.\n\n**How it is enacted.**\nThe role is enacted by a standard `U.RoleAssignment` that connects:\n\n```\nRoleAssigning {\n  holder  : U.Episteme,        // the artefact: paper, proof, dataset, report…\n  role    : U.EvidenceRole,    // a context-defined role with normative properties\n  context : U.BoundedContext   // where the role definition is valid\n  timespan?: Interval          // optional: relevance window for this specific assignment\n}\n```\n\nThe **normative properties** of the role (e.g., `claimRef`, `claimScope`, `polarity`, `weightModelRef`) are set in the **role’s definition** in the given `U.BoundedContext`, not in the evidence-role assignment.\n`U.RoleAssignment` carries only the linkage between a concrete episteme and a role already defined and attributed in that context.\n\n> **Non-behavioural guard.** The holder is an episteme; any actions that produced it are `U.Work` performed by systems. Evidence classifies an artefact’s evidential status; it does not itself enact behaviour.\n\n**Minimal readable grammar (informative).**\n`<Episteme>#<EvidenceRole>:<Context>` — where `<EvidenceRole>` in `<Context>` already normatively specifies `polarity Claim / Scope [weight]`.\n\n**Examples.**\n\n* In `Cardio_2026`, `ModelFitEvidenceRole` is defined with:\n  `claim = β-blocker > placebo`, `claimScope = adults 40–65`, `polarity = supports`, `weightModelRef = KD:SupportMeasure`.\n  Binding:\n  `Trial-R3.csv#ModelFitEvidenceRole:Cardio_2026`.\n\n* In `Theory_T`, `AxiomaticProofRole` is defined with:\n  `claim = Theorem-12`, `claimScope = all x ∈ D`, `polarity = supports`.\n  Binding:\n  `Lemma-12.proof#AxiomaticProofRole:Theory_T`.\n\n",
        "a.2.4:5___role_family_and_specialisations": "### A.2.4:5 - Role family and specialisations\n\n`U.EvidenceRole` is a **role kind** refined by **specialisation** (no mereology of roles). The recommended, substrate‑neutral specialisations are:\n\n**5.1 Axiomatic line (deductive inside a fixed theory)**\n\n* **`AxiomaticProofRole`** — a proof that **entails** a target statement in a declared `U.TheoryVersion`.\n* **`CounterexampleRole`** — a witness that **refutes** a universally quantified claim in the theory.\n* **`DerivationRole`** — a lemma or intermediary derivation establishing a dependency in the proof spine.\n* **`EquiconsistencyEvidenceRole`** — a metaproof establishing equiconsistency or relative strength, often used to **constrain** theory choice.\n\n**Semantics.** In a fixed theory version, these roles are **boolean** and **non‑decaying**. If the axiom base or definitions change, the binding must be re‑issued for the new version; there is no silent carry‑over.\n\n**5.2 Experimental line (empirical, inductive, and model‑selection)**\n\n* **`ObservationEvidenceRole`** — raw or processed observations under a declared method.\n* **`MeasurementEvidenceRole`** — calibrated measurements with an error model and traceability.\n* **`ModelFitEvidenceRole`** — comparative fit or likelihood of data to competing models; supports one **over** another within the declared scope.\n* **`ReplicationEvidenceRole`** — independent replication status (full, partial, failed).\n* **`CalibrationEvidenceRole`** — evidence about the measurement chain (instrument validity), typically **constraining** claims.\n* **`BenchmarkEvidenceRole`** — standardised tasks or suites producing comparable scores.\n\n**Semantics.** Experimental roles require a **claim‑scope** and a **relevance timespan**. Their contribution to confidence is **graded** and may **decay**; the same artefact may carry multiple bindings for different claims or scopes (distinct role assignments).\n\n> **Specialisation, not stacking.** Do not build chains like “transformer‑agent‑observer role.” A system enacts behavioural roles (e.g., `TransformerRole`) to **perform work**; an episteme enacts `U.EvidenceRole` to **classify** its evidential function. Keep enactment lines separate.\n",
        "a.2.4:6___clear_distinctions_(strict_distinction,_litmus_tests)": "### A.2.4:6 - Clear distinctions (Strict Distinction, litmus tests)\n\n| If you are talking about…               | Use in FPF                                                    | Why                                                                   |\n| --------------------------------------- | ------------------------------------------------------------- | --------------------------------------------------------------------- |\n| **Who acted and consumed resources**    | `U.System` with `U.RoleAssignment` performing `U.Work`           | Only systems act; work records resource deltas.                       |\n| **What was promised to a consumer**     | `U.ServiceClause` (promise with access and acceptance)              | A promise is not evidence; it is judged from work.                    |\n| **How work should be done or invoked**  | `U.Method` / `U.MethodDescription`                                   | Recipes and interfaces are not evidence.                              |\n| **What counts as evidence for a claim** | `U.Episteme` holding `U.EvidenceRole` via `U.RoleAssignment`     | Evidence is a status of an artefact relative to a claim in a context. |\n| **Moving meaning across contexts**      | An explicit bridge/alignment pattern in the receiving context | Role meanings are context‑local by design.                            |\n",
        "a.2.4:7___core_invariants_(concept_level)": "### A.2.4:7 - Core invariants (concept level)\n\n1. **Holder type.** `U.EvidenceRole` is held by a **`U.Episteme`** only; never by a system, work, method, or service.  # [M‑0]\n2. **Context anchor.** Every evidence-role assignment **must** name a `U.BoundedContext`; meaning is local and does not propagate implicitly.\n3. **Target claim.** Every evidence-role assignment **must** reference a resolvable claim or theory statement and declare **polarity** `{supports | refutes | constrains | neutral}`.\n4. **Claim-scope.** Every evidence-role assignment **must** declare an applicability scope; for the axiomatic line this can be the theory’s domain.\n5. **Timespan.** Every evidence-role assignment **must** declare a relevance interval. Axiomatic roles may be open-ended **for a fixed theory version**; experimental roles require finite or refreshable windows.  **Gating:** narrative only at **M-0**; explicit `timespan` & `decayClass` at **M-2**; version fence & `proofChecks` at **F-**.  # [M/F]\n6. **Non-self-evidence.** The provenance of experimental evidence-role assignments **must** trace to external `U.Work` performed by systems under roles; an episteme cannot “evidence itself.”\n7. **No mixing of stances.** Do not mix design‑time proof artefacts and run‑time traces in one provenance chain; relate them via separate bindings if needed.\n8. **No role mereology.** Roles have **no parts**; refine by **specialisation** only. This prevents confusing “sub‑role” with “subsystem”.   **Profile note:** The constraint is universal (applies to **all profiles**).  # [all]\n\n**Minimal readable grammar (informative).**  \n`<Episteme>#<EvidenceRole>:<Context>` — where `<EvidenceRole>` is **defined inside `<Context>`** with normative facets (`claimRef`, `claimScope`, `polarity`, optional `weightModelRef`, decay policy).\n\n**Examples (illustrative only):**\n\n*Cardio (empirical line)*  \nRole **definition** in `Cardio_2026`:  \n`ModelFitEvidenceRole` with  \n`claimRef = (β-blocker > placebo)`, `claimScope = adults 40–65`, `polarity = supports`, `weightModelRef = KD:SupportMeasure`.  \n**Binding:**  \n`Trial-R3.csv#ModelFitEvidenceRole:Cardio_2026`\n\n*Graph theory (formal line)*  \nRole **definition** in `GraphTheory`:  \n`AxiomaticProofRole` with `claimRef = Theorem-12`, `claimScope = all finite DAG`, `polarity = supports` (entails), fenced to `TheoryVersion = 3.1`.  \n**Binding:**  \n`Lemma-12.proof#AxiomaticProofRole:GraphTheory`\n",
        "a.2.4:8___facets_and_semantics_(normative)": "### A.2.4:8 - Facets and semantics (normative)\n\nThis section deepens the definition of `U.EvidenceRole` by specifying **which normative facets** are attached to its definition within a `U.BoundedContext`, **how decay is handled**, **what provenance anchors are required**, and **how the role contributes to assurance computation**.\n\n#### A.2.4:8.1 - Claim-scope schema\n\nEvery `U.EvidenceRole` definition **within a `U.BoundedContext`** **MUST** declare a claim-scope record. This record ties the role’s meaning to the exact target claim and its claim scope, and aligns with the typed-claim form used in B.3:\n\n| Field           | Meaning                            | Norms                                                                                               |\n| --------------- | ---------------------------------- | --------------------------------------------------------------------------------------------------- |\n| `claimRef`      | Identifier of the supported claim  | MUST resolve within the context’s claim graph; dangling IDs forbidden.                              |\n| `claimHost`     | The holon whose claim is supported | MAY be `U.System` or `U.Episteme`.                                                                  |\n| `epistemicMode` | `formal` or `postulative`          | MUST be present; governs stability and decay rules.                                                 |\n| `assuranceUse`  | `TA` / `VA` / `LA`                 | Declares whether the evidence functions as typing, verification, or validation input (B.3.3).       |\n| `applicability` | Domain subset (envelope)           | Optional for formal proofs; REQUIRED for empirical evidence (units, constraints, parameter ranges). |\n| `resultKind`    | Kind of content on the carrier     | Examples: theorem/proof obligation; dataset; calibration; model-fit result.                         |\n| `notes`         | Additional context                 | Pointers to SCR/RSCR entries; congruence rationale; bridge IDs if imported from another context.    |\n\n#### A.2.4:8.2 - Timespan and decay\n\nEvidence is perishable unless proven otherwise.\n\n* **Formal (axiomatic) roles** MAY have open-ended `timespan.to = null` **only** if fenced to a specific `U.TheoryVersion` and justified in `notes`.\n* **Empirical roles** MUST have a finite or refreshable `timespan`. Decay parameters (half-life, renewal window) are set by the context policy and referenced in the role definition.\n\nWhen the relevance window closes (`validUntil` reached), the evidence incurs **Epistemic Debt (ED)**. Per B.3.4, debt must trigger one of three managed actions:\n\n1. **Refresh** — new work produces fresh evidence for the same claim and scope.\n2. **Deprecate** — role is retired; claim support is reduced or removed.\n3. **Waive** — explicit steward decision to accept the stale evidence temporarily.\n\n#### A.2.4:8.3 - Provenance hooks\n\nEach `U.EvidenceRole` **MUST** anchor into the **Evidence–Provenance DAG** (A.10):\n\n* **Formal**: `verifiedBy` → proof artefact carrier(s), with optional `checkedBy` metadata for proof-checker runs.\n* **Empirical**: `validatedBy` → data carriers from observed `U.Work` runs; `protocolRef` → `U.MethodDescription`; `fromWorkSet` → IDs of those runs.\n* SCR/RSCR anchors (A.10) are mandatory for all carriers.\n\n**No self-evidence rule**: the producing `U.Work` must have been performed by a system in an **external** role; an episteme cannot “prove itself” without independent generation.\n\n#### A.2.4:8.4 - Contribution to assurance\n\nA `U.EvidenceRole` classifies an artefact; its contribution to the target claim’s assurance tuple ⟨F, G, R⟩ is computed in B.3 using:\n\n* **F (formality)** — lower-bounded by the least formal constituent in the provenance path.\n* **G (ClaimScope)** — limited to the claim scope; unsupported regions are dropped (WLNK).\n* **R (reliability)** — computed as:\n\n```\nR_eff := max(0, min_path( min_claimR(path) − Φ(CL_min(path)) ))\n```\n\nHere:\n\n* `min_claimR(path)` is the smallest justified reliability along the path from the role to the claim in the context’s support graph.\n* `CL_min(path)` is the lowest congruence level on that path.\n* `Φ` is the penalty function defined by the context policy; it must be monotonic (lower CL → greater penalty).\n\nIf any element in the support chain is `postulative`, the aggregate `epistemicMode` is `postulative`.\n\n**TA/VA/LA distinctions**:\n\n* **TA (Typing assurance)** — primary effect is to improve `CL` on edges, reducing penalties in R computation.\n* **VA (Verification assurance)** — primarily raises F and the logical component of R.\n* **LA (Validation assurance)** — raises empirical R and constrains G to the validated envelope.\n",
        "a.2.4:9___worked_examples": "### A.2.4:9 - Worked examples\n\n#### A.2.4:9.1 - Formal line — *Proof as evidence for a theorem*\n\n**Role definition (in `GraphTheory`)**  \n`AxiomaticProofRole`  \n- `claimRef = Theorem-12` (“Every finite acyclic graph admits a topological ordering”),  \n- `claimScope = all finite DAG`,  \n- `polarity = supports` (entails),  \n- `epistemicMode = formal`, `assuranceUse = VA`,  \n- fenced to `TheoryVersion = 3.1` (open-ended relevance as long as that version stands).\n\n**Role assignment(s)**  \n`Lemma-12.proof#AxiomaticProofRole:GraphTheory`\n\n**Provenance sketch**  \n`verifiedBy → Carrier#Proof_p1` (machine-checked), `usedCarrier → Carrier#Def_graph`.\n\n**Effect on assurance (informative)**  \nHigh **F** (machine-checked proof), **G** = “finite DAG”, **R** from proof-obligation integrity; potential CL penalty if an ontology bridge is used.\n\n##### A.2.4:9.2 - Empirical line — *Sensor calibration as evidence for an accuracy claim*\n\n**Role definition (in `Cardio_2026`)**  \n`ModelFitEvidenceRole`  \n- `claimRef = “Sensor S achieves ±0.3 °C accuracy in [0,70] °C under lab conditions L”`,  \n- `claimScope = temperature [0,70] °C; humidity 30–50%; environment L`,  \n- `polarity = supports`,  \n- `epistemicMode = postulative`, `assuranceUse = LA`,  \n- `weightModelRef = KD:SupportMeasure`, `decayPolicy = annual recalibration`.\n\n**Role assignment(s)**  \n`Trial-R3.csv#ModelFitEvidenceRole:Cardio_2026`\n\n**Provenance sketch**  \n`validatedBy → Carrier#Dataset_calib_v5`, `protocolRef → MethodDescription#ThermoCalibration`, `fromWorkSet → {cal_run_0502, cal_run_0503}`.\n\n**Effect on assurance (informative)**  \n**F** from formalised procedure, **G** = measured envelope, **R** from replication and CL on unit mapping; **R** decays after the policy window unless refreshed.\n",
        "conformance_checklist": "### A.2.4:10 - Conformance checklist (normative)\n\n**CC-ER-01 (Type & holder)**\n`U.EvidenceRole` **MUST** be held by a `U.Episteme` via `U.RoleAssignment`. Systems, services, methods, or works **MUST NOT** hold this role.\n\n**CC-ER-02 (Context)**\nEvery evidence-role assignment **MUST** name a `U.BoundedContext`. Role meanings are local and do not propagate without an explicit bridge.\n\n**CC-ER-03 (Target claim)**\nEvery evidence-role assignment **MUST** reference a resolvable `claimRef@version` and declare `polarity ∈ {supports | refutes | constrains | neutral}`.\n\n**CC-ER-04 (Claim-scope)**\nEvery evidence-role assignment **MUST** declare `claimScope`. For formal proofs this may be the theory’s domain; for empirical evidence it is mandatory to state population, environment, and parameter envelope.\n\n**CC-ER-05 (Timespan)**\nEvery evidence-role assignment **MUST** carry a non-empty `timespan`. Formal line may have open-end **only** if fenced to a fixed theory version; empirical line must have a finite or refreshable end.\n\n**CC-ER-06 (Provenance)**\nEvery evidence-role assignment **MUST** anchor into the EPV-DAG (A.10). For empirical line, `fromWorkSet` must point to external `U.Work`; self-evidence is prohibited.\n\n**CC-ER-07 (Reproducibility)**\nEmpirical evidence-role assignments **MUST** state `reproducibility` ∈ {replicated-independent, replicated-internal, not-replicated, irreproducible}, with references where applicable.\n\n**CC-ER-08 (Weight discipline)**\nIf `weight.score` is present, `weight.modelRef` **MUST** be named and all required inputs supplied.\n\n**CC-ER-09 (Cross-context)**\nCross-context reuse **MUST** go via `U.Alignment` bridge; record `CL_min` on the path for assurance penalties.\n\n**CC-ER-10 (Version fences)**\nIf the claim or episteme versions, create a new binding; do not mutate in place.\n\n**CC-ER-11 (No role-of-role)**\nRoles never hold roles; there is no chaining of behavioural sub-roles into non-behavioural ones.\n\n**CC-ER-12 (Terminology)**\nUse *specialisation* for role refinements; reserve *sub* for mereology of systems or artefacts only.\n\n**CC-ER-13 (Lane declaration)**\nEvery binding **SHALL** declare `assuranceUse ∈ {TA | VA | LA}` and, for **empirical** (LA) bindings, expose `timespan/valid_until` and `decayPolicy` so that SCR can report lane‑separated contributions and freshness (B.3).\n",
        "a.2.4:11___anti_patterns_and_remedies": "### A.2.4:11 - Anti-patterns and remedies\n\n| Anti-pattern                | Symptom                                                | Remedy                                                                  |\n| --------------------------- | ------------------------------------------------------ | ----------------------------------------------------------------------- |\n| **Data speaks for itself**  | Binding with no `context` or `claimRef`.               | Anchor to context and explicit claim; set polarity and timespan.        |\n| **Evidence = the work run** | Treating `U.Work` as the episteme.                     | Keep factual record on `U.Work`; create a report episteme to bind.      |\n| **Attach to system**        | Holder is `U.System`.                                  | Holder must be an episteme; system may be `claimHost`, not role holder. |\n| **Global evidence**         | Using one binding across contexts with no bridge.      | Create explicit `U.Alignment` bridge; declare loss policy.              |\n| **Ad-hoc weight**           | Number assigned with no declared model.                | Use context-declared model; supply required inputs.                     |\n| **Service proves itself**   | Service KPI logged as evidence.                        | KPIs come from `U.Work`; service evaluation can be bound as evidence.   |\n| **Scope blur**              | Mixing design-time and run-time provenance in one EPV. | Split into separate bindings; relate via claim graph or bridge.         |\n\n",
        "a.2.4:12___operators_(conceptual,_tooling_agnostic)": "### A.2.4:12 - Operators (conceptual, tooling-agnostic)\n\nThese operators extend E.6.1 citation graph capabilities for evidence analysis inside a `U.BoundedContext`:\n\n**12.1 Per-claim evidence**\n`evidenceFor(claim, t?) → Set[EvidenceRoleAssigning]`\n`counterEvidenceFor(claim, t?) → Set[EvidenceRoleAssigning]`\n`weight(claim, t?, model?) → score`   # returns **ordinal** at M‑mode; **numeric** at M‑2/F‑mode.  # [M/F]\n\n**12.2 Decay and windows**\n`window(claim, [t0,t1])` — filter evidence-role assignments by `timespan`.\n`decayedWeight(assignment, t)` — apply context decay policy.\n\n**12.3 Replication and provenance**\n`replicationLedger(binding) → Ledger`\n`isIndependentReplication(binding) → boolean`\n\n**12.4 Formal line hooks**\n`proofChecks(binding) → {assistant, status, hash, kind∈{classical, constructive}}`  # [F‑\\*]\n`dependsOnAxioms(binding) → Set[AxiomId]`\n\n**12.5 Empirical line hooks**\n`fromWorkSet(binding) → Set[WorkId]`\n`protocol(binding) → MethodDescriptionId`\n",
        "relations": "### A.2.4:13 - Relations\n\n**Builds on:**\nA.2 `U.Role`, A.2.1 `U.RoleAssignment` (role as mask, binding as assignment), A.10 Evidence Graph Referring (EPV-DAG), B.3 Trust & Assurance Calculus.\n\n**Coordinates with:**\nA.3.2 `U.MethodDescription` (protocols, proof obligations), E.6.1 Epistemic Roles via `U.RoleAssignment` (didactic gateway).\n\n**Informs:**\nKD-CAL (knowledge dynamics, assurance cases), Norm-CAL (policy claims with evidence), planned `U.ServiceClauseEvaluation` (services judged from work and reported as epistemes with evidence bindings).\n\n",
        "a.2.4:14___migration_notes_(quick_wins)": "### A.2.4:14 - Migration notes (quick wins)\n\n1. **Enumerate claims**: For each evidence collection, identify claims and create explicit bindings with polarity.\n2. **Separate work from reports**: Facts stay on `U.Work`; create report epistemes to link as evidence.\n3. **Name the calculus**: Replace free-form confidence with context-declared weight model and required inputs.\n4. **Fence by version/time**: Bindings carry `timespan` and version fences; add decay class if applicable.\n5. **Bridge explicitly**: Cross-context evidence goes through `U.Alignment`, not by fiat.\n",
        "a.2.4:15___didactic_quick_cards_(engineer_manager_ready)": "### A.2.4:15 - Didactic quick cards (engineer-manager ready)\n\nThese are short reminders for non-specialist readers to apply `U.EvidenceRole` correctly:\n\n* **Evidence ≠ Work** — Work is *what happened*; Evidence is a *documented argument* (episteme) about a claim in a context.\n* **Local, not global** — Evidence links *in a room* (context). Outside that room, you need a bridge (`U.Alignment`).\n* **Two lines of trust** — Formal line: proof artefacts checked in a declared theory version. Empirical line: observations from Work under a declared method. Both are epistemes wearing `U.EvidenceRole`.\n* **Services are promises; Work proves** — KPIs are measured from Work; service evaluations can be bound as evidence for policy claims.\n* **Specialise, don’t stack** — Use specialisations of `U.EvidenceRole` to refine meaning; never chain behavioural roles into evidence.\n\n",
        "a.2.4:16___scr/rscr_audit_stubs_(assurance_scaffolding)": "### A.2.4:16 - SCR/RSCR audit stubs (assurance scaffolding)\n\nThese stubs allow concept-level validation of evidence-role assignments, without implying any specific tooling.\n\n**SCR-A2.4-E1 (Assignment integrity)**\nAssert: `holder` is `U.Episteme`; `context` present; `claimRef` resolves; `timespan` non-empty; provenance anchored to EPV.\n\n**SCR-A2.4-E2 (Weight discipline)**\nAssert: if `weight.score` present → `weight.modelRef` present and all required inputs provided; recompute to check.\n\n**SCR-A2.4-E3 (Traceability)**\nFor empirical evidence-role assignments: assignment → `fromWorkSet` → each `U.Work` has performer `U.RoleAssignment` and timestamps; no missing hops.\n\n**RSCR-A2.4-R1 (Regression on version bump)**\nWhen `claimRef` or holder episteme versions change, ensure **new** bindings are created; no in-place mutation.\n\n**RSCR-A2.4-R2 (Decay check)**\nBindings past `timespan.to` or with expired `decayClass` are flagged for review per context policy.\n\n",
        "a.2.4:17___minimal_evidence_role_assignment_schema_(informative)": "### A.2.4:17 - Minimal evidence-role assignment schema (informative)\n\n```yaml\nEvidenceRoleAssigning:\n  id: ERB-…\n  context: <BoundedContextId>\n  holder: <EpistemeId>                # paper/proof/dataset/report\n  role: <EvidenceRoleId>              # defined within the context, with normative properties\n  timespan?: {from: ISO-8601, to: ISO-8601|null} # optional assignment window\n  provenance:\n    formal?: { theoryRef: <TheoryId>, proofArtifactRef: <CarrierId>, checkedBy?: <ProofCheckId> }\n    empirical?: { protocolRef: <MethodDescriptionId>, fromWorkSet: [<WorkId>… ], dataCarrierRef?: <CarrierId> }\n```\n",
        "a.2.4:18___memory_hooks_and_acceptance_cross_checks_(informative)": "### A.2.4:18 - Memory hooks and acceptance cross-checks (informative)\n\n**Memory hook:** *“Evidence links a **document** to a **claim** in a **Context**, for a **time**, with a **trail**.”*\n(document = episteme; claim = scoped thesis; Context = bounded context; time = timespan/decay; trail = provenance)\n\n**Acceptance cross-checks before publishing a binding:**\n\n1. **Holder**: Is it a `U.Episteme`?\n2. **Context**: Is the `U.BoundedContext` declared?\n3. **Claim**: Does `claimRef` resolve? Is `polarity` set?\n4. **Scope**: Is `claimScope` complete? For empirical, are population/env/parameters given?\n5. **Timespan**: Is it finite or fenced (formal line)?\n6. **Provenance**: Is EPV anchored? Any self-evidence?\n7. **Reproducibility**: For empirical, is it declared?\n8. **Weight**: If scored, is the model named and inputs complete?\n9. **Cross-context**: If imported, is `U.Alignment` bridge in place with CL\\_min recorded?\n10. **No role-of-role**: Is this role bound directly to an episteme without chaining behavioural roles?\n",
        "a.2.4:end": "### A.2.4:End\n"
      },
      "content": "### A.2.4:End\n",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.2.5",
      "title": "U.RoleStateGraph: The Named State Space of a Role",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.2.5 - U.RoleStateGraph: The Named State Space of a Role\n",
        "a.2.5:1___purpose_&_scope_(why_this_exists)": "### A.2.5:1 - Purpose & scope (why this exists)\n\nA **role** is not only a name; it is a *trajectory of admissible states* that governs when, and under which conditions, a holder of that role may **enact** steps of a `U.MethodDescription`. FPF therefore introduces a first‑class intensional object:\n\n> **`U.RoleStateGraph` (RSG)** — the **finite, named state space** of a **`U.Role` in a given `U.BoundedContext`**, with transitions guarded by conditions over the **Role Characterisation Space (RCS)** and contextual events.\n\nThe RSG is the **gate** between *assignment* (`U.RoleAssignment`) and *action* (`U.Work`). A step may be performed **only** when the performer’s assignment is **in an enactable RSG state** at the relevant **Window** (time slice) and this is **proven** by a contemporaneous **StateAssertion** (verdict of `U.Evaluation` against the state’s **Checklist**).\n\n",
        "problem": "### A.2.5:2 - Problem frame (what goes wrong without an RSG)\n\n1. **Readiness blur.** Teams conflate “has the badge” with “is fit to act now”. Without explicit states (*Ready*, *Calibrated*, *Authorized*, *Suspended*…), enactment checks dissolve into ad‑hoc judgement.\n2. **Checklist drift.** Criteria for “ready/approved” live in scattered documents; there is no single conceptual anchor tying them to the role.\n3. **Workflow/role confusion.** “State” of a *workflow* (according to workplan) is mistaken for the *state of a role* (eligibility to enact).\n4. **Status ≠ enactment.** Epistemic/Normative roles (e.g., *NormativeStandard*, *ApprovedSpecification*) need *statuses* that are **not enactable**, yet are used to gate decisions.\n5. **Cross‑context substitution by name.** Labels like *Approved* or *Ready* silently cross contexts with different criteria; the loss is hidden and unaudited.\n\n**Consequences.** Violations of **Strict Distinction (A.7)** and **Didactic Primacy (E.12)**: ambiguous authority to act, unsafe SoD, and non‑reproducible evaluations.\n\n",
        "a.2.5:3___core_idea_(didactic)": "### A.2.5:3 - Core idea (didactic)\n\nThink of a **Role** as a **mask**, and the **RSG** as the **traffic lights for that mask** inside one context of meaning.\n\n* The **nodes** are **named states** (*Ready*, *Degraded*, *Suspended*, *Approved*, *Obsolete*…).\n* The **edges** are **transitions** with **guards** (checkable conditions over RCS characteristics and contextual events, e.g., *CalibrationAge ≤ 30d*; *AuthorizationSpeechAct recorded*).\n* Each **state** is paired with a **Checklist** (criteria you test to issue a **StateAssertion** for a given **Window**).\n* Some states are **enactable = true** (green lights); others are **not enactable** (status lights) and therefore can **gate decisions** but **cannot** directly authorize `U.Work`.\n\n> **One sentence.** **RSG says *when a badge is green*.** The Checklist proves it, the **StateAssertion** records it, and the Method step may proceed.\n\n",
        "a.2.5:4___minimal_vocabulary_(this_pattern_only)": "### A.2.5:4 - Minimal vocabulary (this pattern only)\n\n* **`U.RoleStateGraph` (RSG).** Intensional object *owned by* `(Role, Context)`. Finite set of named **States** and typed **Transitions** with guards.\n* **RSG.State.** Intensional **named place**. Properties:\n\n  * `enactable ∈ {true,false}` — whether being in this state authorizes enactment of steps that require this role.\n  * `initial?`, `terminal?` — optional markers for lifecycle reasoning.\n* **RSG.Transition.** Edge `state_i → state_j` with **Guard** (predicate over RCS characteristics and/or contextual events such as `U.SpeechAct`, `U.Observation`, `U.Evaluation` results).\n* **RCS (Role Characterisation Space).** The **characteristic bundle** that characterises this role in this Context (e.g., *CalibrationAge*, *AuthorizationScope*, *FatigueIndex*, *IndependenceFlag*, *EvidenceFreshness*). *(Defined in A.2 Role Taxonomy / RoleDescription.)*\n* **State Checklist (description).** A **RoleDescription** component that enumerates **criteria** to test whether a holder can legitimately be treated as **in** a given state for a **Window**. *(Description, not the state itself.)*\n* **`U.Evaluation` → StateAssertion (verdict).** The **result** of applying the state’s Checklist to a **concrete holder** at a **time window**, yielding a **verdict** “IN‑STATE(S) @Window” with provenance to observations/evidence.\n* **Window.** Temporal interval to which the StateAssertion applies (e.g., `[2025‑05‑01, 2025‑06‑01]`).\n\n> **Strict distinction note.**\n>\n> * **RSG** and its **States** are **intensionals** (what the role *is allowed to be*).\n> * **Checklists** and **StateAssertions** are **descriptions/evaluations** (how we *know* a specific holder *is* in that state now).\n\n",
        "a.2.5:5___what_an_rsg_is_**not**_(guardrails)": "### A.2.5:5 - What an RSG is **not** (guardrails)\n\n* **Not a workflow.** RSG transitions do **not** encode task order; they encode **eligibility changes** of the *role*.\n* **Not a capability list.** RSG is **authorization/readiness over time**, distinct from `U.Capability` (ability).\n* **Not a global status set.** RSG lives **inside one Context**; the label *Ready* in another Context is **a different state** unless bridged (F.9).\n* **Not a log.** RSG is not a history. Histories are **StateAssertions** over Windows; **`U.Work`** is the record of enactments.\n* **Not a document lifecycle.** Epistemic role RSGs can *look like* document lifecycles, but they remain **role‑status graphs**; the **carrier** lifecycle stays separate (A.7, `U.Carrier`).\n\n",
        "a.2.5:6___invariants_(preview)": "### A.2.5:6 - Invariants (preview)\n\n1. **Locality.** `RSG(Role, Context)` is defined **only** within that `U.BoundedContext`.\n2. **Finiteness.** The **State** set is finite and named.\n3. **Checklist pairing.** Every State has a **Checklist** in the Role’s **RoleDescription**; every enactable State has **at least one** observable criterion.\n4. **Green‑gate discipline.** A Method step requiring `Role` may proceed **only** if a contemporaneous **StateAssertion** exists for an **enactable** State.\n5. **No silent Cross‑context reuse.** Cross‑Context reuse requires a **Bridge** with CL and loss notes; local `⊥/≤/⊗` always prevail.\n",
        "a.2.5:7___formal_structure_of_an_rsg_(intensional,_context‑local)": "### A.2.5:7 - Formal structure of an RSG (intensional, context‑local)\n\n> **Definition.** For a given **`U.Role`** in a given **`U.BoundedContext`**, its **`U.RoleStateGraph`** is the tuple\n> `RSG(Role, Context) = ⟨S, S_en, T, Guard, init?⟩`, where:\n\n* **`S`** — a **finite set of named States** (`StateName ∈ Tech register`, with a Plain label). Names are **local to `(Role, Context)`**.\n* **`S_en ⊆ S`** — the subset of **enactable** states (“green lights”). States in `S \\ S_en` are **status‑only** (not enactable).\n* **`T ⊆ S × S`** — a set of **typed transitions** `sᵢ → sⱼ`. Transitions are optional; the RSG may be acyclic or cyclic.\n* **`Guard`** — for each transition (and optionally for state maintenance), a **predicate over**:\n\n  * the role’s **RCS snapshot** at a **Window** (values on named characteristics; see A.2.3), and\n  * **Context events** (e.g., presence of a `U.SpeechAct`, freshness of `U.Observation`, validity of a prior `U.Evaluation`).\n* **`init? : S → {true,false}`** — optionally marks **initial** state(s). (Useful for lifecycles; not required for gating.)\n\n**Naming discipline (RSG‑N1…N3).**\n\n1. **RSG‑N1 (Minimal set).** `|S| ≥ 1`. At least **one** state must exist; if **no** state is enactable, the role is **status‑only** in this Context.\n2. **RSG‑N2 (Disjoint labels).** State names are **unique** within `(Role, Context)`; reusing global labels (e.g., “Ready”) across contexts is allowed **only** via Bridges (F.9).\n3. **RSG‑N3 (Human scale).** For didactics, **≤ 7 states** is the default target; exceeding it requires a one‑sentence rationale (“distinct gate we will actually use”).\n\n",
        "a.2.5:8___enactability_&_checklist_semantics_(how_a_state_is_*known*,_now)": "### A.2.5:8 - Enactability & Checklist semantics (how a state is *known*, now)\n\nAn RSG **does not** determine history; it determines **what counts as being in a state**, and which states **authorize enactment**.\n\n#### A.2.5:8.1 - State Checklists (description, not the state)\n\nFor each `s ∈ S`, the **RoleDescription** (A.2.3) includes a **State Checklist** `Checklist(s)` — a **named set of criteria** that can be evaluated at a **Window** to test “**holder is in state `s`**”.\n\n* **Criterion kinds (illustrative):**\n\n  * **Threshold over RCS characteristic:** `CalibrationAge ≤ 30 days`.\n  * **Presence of act:** `AuthorizationSpeechAct exists within 90 days`.\n  * **Evidence freshness:** `Evidence(type=SafetyTest).age ≤ 12 months`.\n  * **SoD flag:** `IndependenceFlag = true`.\n  * **External status:** `StandardStatus = Approved`.\n\n> **Strict distinction.** `Checklist(s)` is a **description**; the **state** `s` is an **intensional place** in the role’s RSG.\n\n#### A.2.5:8.2 - From Checklist to **StateAssertion** (verdict of `U.Evaluation`)\n\nEvaluating `Checklist(s)` at a **Window** produces an **`U.Evaluation` verdict**:\n\n> **`StateAssertion(holder, Role, Context, s, Window)`** — “*For this Window, this holder **is** in state `s`*”, with provenance to the actual observations/evidence.\n\n**Rules (RSG‑C1…C5).**\n\n* **RSG‑C1 (All‑must‑hold).** A `StateAssertion` **MUST** justify that **all required criteria** in `Checklist(s)` hold at the Window.\n* **RSG‑C2 (Window freshness).** Each criterion **MUST** define its freshness window; if omitted, default is **instantaneous** at the Window’s end time.\n* **RSG‑C3 (No guess).** Pure opinion is disallowed; every criterion is grounded in **observable facts** (`U.Observation`, `U.Work` record, `U.SpeechAct`, or a derived `U.Evaluation`).\n* **RSG‑C4 (Non‑monotonic over time).** A `StateAssertion` is **not** permanent; once the Window ends, a new evaluation is needed unless a **maintenance guard** keeps it valid (see 8.3).\n* **RSG‑C5 (Uniqueness not required).** Multiple states may be asserted for the same Window if their criteria do not conflict (e.g., `Ready` and `Authorized`). **Enactability** is governed by §8.4.\n\n#### A.2.5:8.3 - Transitions & guards (admission, maintenance, exit)\n\nRSG transitions **express how eligibility changes** when guards fire. Guards are **predicates**; the RSG stays **notation‑neutral**.\n\n* **Admission guard (`→ s`)** declares **conditions to enter** state `s`.\n* **Maintenance guard (`s ↺`)** must hold to **remain** in `s` (e.g., *FatigueIndex < 0.8*, checked every shift).\n* **Exit guard (`s →`)** declares **conditions to leave** `s` (e.g., *CalibrationAge > 30d*).\n\n**Rules (RSG‑G1…G3).**\n\n* **RSG‑G1 (Checklists vs guards).** Checklists decide **recognition** (“am I in `s` now?”). Guards describe **change** (“what moves me in/out of `s`?”). They may reuse the **same predicates**; their roles are distinct.\n* **RSG‑G2 (No control‑flow).** Guards may refer to **events** (e.g., “Calibration completed”), but RSG is **not a task graph**; it does not prescribe task order.\n* **RSG‑G3 (Observable basis).** Every guard references **observable** RCS characteristics or recorded events (no hidden timers).\n\n#### A.2.5:8.4 - The **Green‑Gate Law** (enactment gating)\n\n> **Law (RSG‑E1).** A `U.MethodDescription` step that **requires** role `R` **may be enacted** at Window `W` **iff** there exists a `StateAssertion(holder, R, Context, s, W)` with `s ∈ S_en`.\n\nCorollaries:\n\n* **RSG‑E2 (Specialization lift).** If the step requires a **general role** `R`, and the holder has a `StateAssertion` for a **specialist role** `R' ≤ R` in an **enactable** state whose **lift** (see §9.1) is enactable for `R`, the gate passes.\n* **RSG‑E3 (Bundle gate).** If the step requires a **bundle** `R* = R₁ ⊗ … ⊗ Rₙ`, enactment requires **n distinct `StateAssertions`** meeting RSG‑E1 for each `Rᵢ` (unless the Context defines a **CompositeRole** with its own RSG; see §9.3).\n* **RSG‑E4 (Status‑only roles).** Roles with `S_en = ∅` can **never** authorize enactment; they may **gate decisions** (e.g., *ApprovedSpecRole*) but not `U.Work`.\n\n",
        "a.2.5:9___interaction_with_role_algebra_(`≤`,_`⊥`,_`⊗`)_and_refinement": "### A.2.5:9 - Interaction with role algebra (`≤`, `⊥`, `⊗`) and refinement\n\n#### A.2.5:9.1 - Specialization (`≤`) — RSG refinement map\n\nWhen **`R' ≤ R`** (Specialist role refines General role) **in the same Context**, their RSGs **must align** by a **refinement map**.\n\n> **Rule (RSG‑R1 Refinement).** There exists a **surjective mapping**\n> `π : S(R') → S(R)` such that:\n>\n> 1. **Enactability preservation:** `s' ∈ S_en(R') ⇒ π(s') ∈ S_en(R)`.\n> 2. **Checklist entailment:** `Checklist_R'(s') ⇒ Checklist_R(π(s'))` (each specialist state’s criteria **imply** the general state’s criteria).\n> 3. **Guard monotonicity (informal):** Transitions in `R'` **do not weaken** the general readiness implied by `R` (entering/exiting patterns respect π).\n\n**Interpretation.** Being in `s'` for `R'` *guarantees* being in `π(s')` for `R`. Thus **StateAssertions lift** along π, enabling **RSG‑E2**.\n\n**Design note.** RCS for `R'` may **extend** that of `R`; specialist states can be **stricter** (more criteria) but not **looser** than their general counterparts.\n\n#### A.2.5:9.2 - Incompatibility (`⊥`) — state‑aware SoD\n\n`R_A ⊥ R_B` (within the same Context) states that **a single holder** **must not** have **overlapping, enactable authority** for both roles.\n\n> **Rule (RSG‑I1).** At **Window `W`**, a holder **violates** `R_A ⊥ R_B` iff there exist **StateAssertions**\n> `… in s_A ∈ S_en(R_A)` **and** `… in s_B ∈ S_en(R_B)` **both valid at `W`**.\n\n**Optional refinement (soft ⊥).** Contexts **may** tighten incompatibility by listing **state pairs** that are forbidden (e.g., `Ready_A ⊥ Authorized_B`), while allowing benign combinations (e.g., `Suspended_A` + `Ready_B`). By default, **any** enactable pair conflicts.\n\n**Didactic payoff.** SoD is checked by **states in Windows**, not by static role labels.\n\n#### A.2.5:9.3 - Bundles (`⊗`) — conjunction without product explosion\n\nA **bundle role** `R* := R₁ ⊗ … ⊗ Rₙ` expresses “**must wear all these badges at once**”.\n\n> **Rule (RSG‑B1).** If `R*` exists **only as a requirement macro**, **do not** construct a product RSG. The **gate** for a step requiring `R*` is satisfied by **n separate StateAssertions** `sᵢ ∈ S_en(Rᵢ)` at the same Window.\n\n> **Rule (RSG‑B2 CompositeRole).** If the Context **declares `R*` as a first‑class `U.Role`**, it **MUST** also specify an `RSG(R*)` and an embedding `ιᵢ : S(R*) → S(Rᵢ)` that **preserves enactability**; being in an enactable state of `R*` **implies** being enactable in each `Rᵢ`.\n\n**Rationale.** Avoid combinatorial blow‑up by default; allow a composite role **only** when the organization genuinely maintains its **own** readiness graph.\n\n#### A.2.5:9.4 - Readiness monotonicity across specialization & bundles\n\n* **RSG‑M1 (Specialist suffices).** If a step requires `R`, any `R' ≤ R` whose **lifted state** is enactable **suffices**.\n* **RSG‑M2 (Bundle conjunctivity).** If a step requires `R₁ ⊗ R₂`, the performer must produce **both** gates (two StateAssertions), unless a CompositeRole with RSG exists and is used.\n\n",
        "a.2.5:10___guard_design_(types_and_discipline)": "### A.2.5:10 - Guard design (types and discipline)\n\nTo keep RSGs **operational** but **not procedural**, guards draw on **observable** inputs only.\n\n**Guard types (non‑exhaustive).**\n\n1. **Threshold guards** over RCS characteristics\n   `FatigueIndex < 0.8`, `CalibrationAge ≤ 30d`, `EvidenceFreshness(role=Tester) ≤ 90d`.\n2. **Event guards** (occurrence since last Window)\n   `exists SpeechAct(type=Authorization)`, `exists Evaluation(verdict=Pass, checklist=SafetyKit)`.\n3. **Temporal guards** (time within range)\n   `now ∈ AuthorizationValidityWindow`, `MaintenanceWindow not active`.\n4. **Relational guards**\n   `IndependenceFrom(holder=X) = true` (for SoD), `NoOpenIncident(severity≥High)`.\n\n**Rules (RSG‑G4…G6).**\n\n* **RSG‑G4 (Observable only).** Each guard **MUST** be checkable from **observable artefacts** (observations, work logs, speech acts, evaluations) or present RCS values.\n* **RSG‑G5 (Context‑local semantics).** Guard semantics are **scoped to Context**; Cross‑context reuse requires a Bridge (§14 in Part 1/4, F.9).\n* **RSG‑G6 (Didactic sparseness).** Prefer **few, stable guards** over many brittle micro‑conditions. If a guard encodes **task order**, you are drifting into workflow; refactor back to eligibility.\n\nAllowed guard evidences include:\n* Observation facts (measurements/metrics),\n* Evaluation verdicts (checklist results),\n* SpeechAct occurrences (communicative `U.Work`), identified by role, act kind, and window (e.g., “Approved(change=4711)”).\n\nA SpeechAct can change the state (e.g., Prepared→Authorized) but does not by itself satisfy operational steps; it only opens their Green‑Gate.\n",
        "a.2.5:11___putting_it_together_(one‑screen_mental_model)": "### A.2.5:11 - Putting it together (one‑screen mental model)\n\nAt any **Window**:\n\n1. **RoleAssignment exists** (A.2.1): `Holder#Role:Context`.\n2. **StateAssertion(s) exist**: the holder is **in** one or more **states** as proven by checklists (`U.Evaluation`).\n3. **Green‑Gate Law** applies: if at least one asserted state is **enactable**, role‑gated **Method steps** may be enacted; if all are **status‑only**, the role can **gate decisions** but **not** perform work.\n4. **Role algebra** checks: specialization lifts readiness; bundles require **conjunction**; incompatibilities are detected when **two enactable states** coincide for the same holder at the same Window.\n\nThis yields a **clean separation**:\n\n* **assignment** (RoleAssignment)\n* **Readiness** (RSG + Checklists + StateAssertions)\n* **Action** (`U.Work`, gated by RSG)\n\n…and keeps meaning **local**, evidence **observable**, and reasoning **testable**.\n",
        "a.2.5:12___archetypal_rolestategraphs_(cross‑domain_patterns)": "### A.2.5:12 - Archetypal RoleStateGraphs (cross‑domain patterns)\n\nBelow are **didactic, reusable** RSG skeletons for the three principal **behavioural** role families and for **epistemic/status** roles. Names and criteria are **context‑local**; treat them as **templates** to specialise inside your `U.BoundedContext` (E.10.D1). For each RSG we list:\n\n* **`S`** — candidate **States** (enactable states marked **\\[E]**);\n* **Checklist gist** — the **recognition** criteria (cf. §8.1);\n* **Guards** — illustrative **admission/maintenance/exit** predicates (cf. §8.3).\n\n> **Reminder.** Only **enactable** states (**`S_en`**) can open the **Green‑Gate** for `U.Work` (RSG‑E1). Status‑only states **gate decisions** but never execution.\n\n#### A.2.5:12.1 - AgentialRole (decision‑capable actor)\n\n**Context sketch:** `Ops_ChangeManagement_2025`.\n**RCS (characteristics, examples):** *CompetenceLevel, FatigueIndex, IndependenceFlag, AuthorizationValidity, IncidentLoad, RiskClass.*\n\n**States `S`**\n\n* **Unprepared** — training incomplete; checklists fail.\n* **Prepared** — training + competence thresholds met.\n* **Authorized** — valid approval window present. **\\[E]**\n* **Ready** — `Prepared ∧ Authorized ∧ FatigueIndex < τ`. **\\[E]**\n* **Active** — contemporaneous **`U.Work`** step is underway under this role (**with a valid StateAssertion in the window**). **\\[E]**\n* **Suspended** — temporary block (incident/conflict).\n* **Revoked** — authorization expired/withdrawn.\n\n**Checklist gist**\n\n* *Prepared*: certificates valid; recency of practice ≤ X; simulator score ≥ Y.\n* *Authorized*: `exists SpeechAct(type=Approval, scope=Role, age≤30d)`.\n* *Ready*: *Prepared ∧ Authorized ∧* independence from conflicting work; fatigue within limits.\n\n**Guards**\n\n* Admission `→ Prepared`: `ExamPassed ∧ SimulatorScore≥Y`.\n* Admission `→ Authorized`: presence of approval speech‑act within window.\n* Maintenance `Ready ↺`: `FatigueIndex<τ ∧ IncidentLoad≤k`.\n* Exit `Ready → Suspended`: high‑severity incident assigned OR SoD violation detected.\n* Exit `Authorized → Revoked`: window elapsed or explicit revoke speech‑act.\n\n#### A.2.5:12.2 - TransformerRole (non‑agential executor of change)\n\n**Context sketch:** `PlantOps_Pipeline_2025`.\n**RCS:** *CalibrationAge, SafetyInterlock, SelfTestPass, EnvRangeOK, DegradationIndex.*\n\n**States `S`**\n\n* **Unavailable** — offline, missing prerequisites.\n* **Calibrated** — calibration fresh; self‑test ok.\n* **Permitted** — safety interlocks clear; clearance token valid.\n* **Ready** — `Calibrated ∧ Permitted ∧ EnvRangeOK`. **\\[E]**\n* **Running** — executing a method step (**with contemporaneous StateAssertion**). **\\[E]**\n* **Degraded** — still operable under derated envelope. **\\[E]** (if policy allows)\n* **Quarantined** — suspected hazard; no enactment.\n\n**Checklist gist**\n\n* *Calibrated*: `CalibrationAge≤30d ∧ SelfTestPass=true`.\n* *Permitted*: `SafetyInterlock = Clear ∧ NoOpenIncident(sev≥High)`.\n* *Ready*: *Calibrated ∧ Permitted ∧* environment in spec.\n\n**Guards**\n\n* Admission `→ Calibrated`: calibration record timestamp ≤30d.\n* Maintenance `Ready ↺`: env sensors within limits; no new hazard event.\n* Exit `Ready → Quarantined`: detected leak OR hazard alarm.\n* Transition `Running → Ready`: step completed ∧ cool‑down satisfied.\n* Transition `Ready → Degraded`: `DegradationIndex∈[d₁,d₂]` ∧ derate policy active.\n\n#### A.2.5:12.3 - ObserverRole (measurement actor, incl. SOSA/SSN style)\n\n**Context sketch:** `Lab_Thermo_2025`.\n**RCS:** *CalibrationAge, TraceabilityChainOK, DriftRate, SyncError, CleanlinessScore.*\n\n**States `S`**\n\n* **Unqualified** — no metrological chain.\n* **Calibrated** — with traceability to standard.\n* **Synchronized** — time/phase sync within tolerance.\n* **In‑Range** — drift & environment within spec.\n* **Measuring** — performing observation. **\\[E]**\n* **Stale** — calibration or sync expired.\n* **Quarantined** — suspect bias/contamination.\n\n**Checklist gist**\n\n* *Calibrated*: traceability cert valid; calibration within period.\n* *Synchronized*: `SyncError≤ε`.\n* *In‑Range*: drift ≤ threshold; contamination tests passed.\n* *Measuring*: *Calibrated ∧ Synchronized ∧ In‑Range* AND observation procedure active.\n\n**Guards**\n\n* Admission `→ Calibrated`: calibration event recorded < 180d.\n* Exit `Calibrated → Stale`: calibration age > threshold.\n* Exit `In‑Range → Quarantined`: contamination alert OR failed control sample.\n* Transition `Measuring → In‑Range`: procedure complete.\n\n> **Note.** Many ObserverRole states are **pre‑enactment** gates; only **Measuring** is enactable.\n\n\n#### A.2.5:12.4 - Epistemic/status roles (no enactment)\n\nThese roles are **status‑only**; **`S_en = ∅`**. They **gate decisions** (e.g., can be cited, can constrain), but can never authorize `U.Work`.\n\n##### A.2.5:12.4.1 - NormativeStandardRole\n\n**States:** *Draft*, *Candidate*, *Approved*, *Superseded*, *Deprecated*.\n**Checklist gist:** governance decision records; publication identifiers; supersession links.\n**Guards:** *Approved → Superseded* on adoption of newer edition; *Candidate → Approved* after ratification vote.\n\n##### A.2.5:12.4.2 - EvidenceRole\n\n**States:** *Collected*, *Verified*, *Validated*, *Obsolete*, *Contested*.\n**Checklist gist:** verification/validation `U.Evaluation` present; freshness window; reproducibility tag.\n**Guards:** decay to *Obsolete* by age; transition to *Contested* upon counter‑evidence.\n\n##### A.2.5:12.4.3 - RequirementRole\n\n**States:** *Proposed*, *Accepted*, *Implemented*, *Verified*, *Waived*.\n**Checklist gist:** acceptance decision; trace links to `U.Work`; verification report; waiver authorization.\n**Guards:** *Accepted → Implemented* when linked executions close; *Implemented → Verified* on passed acceptance checklist; *Any → Waived* by authorized speech‑act.\n\n",
        "a.2.5:13___one‑screen_authoring_templates_(didactic_cards)": "### A.2.5:13 - One‑screen authoring templates (didactic cards)\n\nKeep each RSG **teachable on one screen**. Use the following **notation‑neutral** templates when drafting RoleDescriptions (A.2.3).\n\n#### A.2.5:13.1 - RSG card (per Role, per Context)\n\n```\nRSG for: <RoleName>   Context: <ContextName/Edition>\nRCS characteristics (gist): <characteristic1>, <characteristic2>, … \nStates (◉ = enactable):\n  - [◉] <StateName> — checklist gist; typical admission/maintenance/exit\n  - [  ] <StateName> — … \n  - … \nGreen‑Gate: step requiring <RoleName> is enactable iff holder asserts any ◉ state at Window.\nRole algebra hooks: specialization (≤ … ), incompatibility (⊥ … ), bundles (⊗ … ).\n```\n\n#### A.2.5:13.2 - State checklist snippet (per State)\n\n```\nState <StateName> (enactable? yes/no)\nChecklist (all must hold at Window):\n  - <Observable criterion 1>  (e.g., CalibrationAge ≤ 30d)\n  - <Observable criterion 2>  (e.g., exists SpeechAct(Approval) age ≤ 30d)\nMaintenance (optional): <predicate> (e.g., EnvRangeOK)\nEvidence Graph Ref: <Observation/Evaluation ids>\n```\n\n#### A.2.5:13.3 - Specialization refinement map (R' ≤ R)\n\n```\nRefinement map π : S(R') → S(R)\nR' state        π(state in R)   entailment note (why Checklist_R' ⇒ Checklist_R)\n-----------     -------------    -----------------------------------------------\n<Ready+>        Ready            adds stricter fatigue & independence thresholds\n<Authorized+>   Authorized       requires same approval + extra duty segregation\n… \n```\n\n#### A.2.5:13.4 - SoD focus (⊥) — enactable pairs\n\n```\nIncompatibility ⊥ (applies when both sides enactable at same Window):\n  <RoleA.StateX>  ⊥  <RoleB.StateY>\n  <RoleA.(any ◉)> ⊥  <RoleB.(any ◉)>   // default if not refined\nRationale: <one‑line reason>\n```\n\n> **Didactic cue.** If your “template” spills beyond a screen, you’re drifting into **workflow**. Pull back to **eligibility** (RSG) and **recognition** (checklists).\n\n",
        "a.2.5:14___cross‑context_adjustments_(via_bridges,_not_imports)": "### A.2.5:14 - Cross‑context adjustments (via Bridges, not imports)\n\nRSGs are **context‑local**. When similar roles appear in different Contexts, relate them with an **Alignment Bridge** (F.9), never by silently importing state names.\n\n#### A.2.5:14.1 - State name correspondence (lossy mapping)\n\n**Bridge example:** *Observer readiness* across two contexts:\n\n```\nBridge: Observer-RSG alignment\nFrom: Lab_Thermo_2025.ObserverRole\nTo:   Metrology_Line_2025.ObserverRole\nMap (with CL):\n  Calibrated(Lab)     ≈  Calibrated(Metro)            CL=3 (minor criterion diffs)\n  In‑Range(Lab)       ↘  Fit‑for‑Use(Metro)           CL=2 (Metro adds robustness test)\n  Measuring(Lab)      ↔  Measuring(Metro)             CL=3\nNotes: 'Synchronized' in Lab maps to 'Time‑Aligned' in Metro (terminology shift).\nLosses: Metro’s 'Robustness' has no direct Lab counterpart (explicit loss recorded).\n```\n\n**Rule (RSG‑X1).** A Bridge **MUST** record **losses** and **extra criteria**; it **MUST NOT** assert identity without a stated `CL` (congruence level).\n\n#### A.2.5:14.2 - Authorization vocabulary drift (deontic vs operational)\n\n**Bridge note:** In some IT change contexts, “**Authorized**” (deontic) overlaps with “**Permitted**” (operational). A Bridge can **explain** the design choice:\n\n* `Authorized(AgentialRole@ITIL)` ↔ `Permitted(TransformerRole@IEC)` with **CL=1** and a note: *operational interlock ≠ managerial approval; both required to lift to Ready under our policy.*\n\n> **Payoff.** Bridges keep **local honesty** while enabling **Cross‑context reasoning** with explicit penalties (B.3).\n\n",
        "a.2.5:15___author_conformance_(write_good_rsgs)": "### A.2.5:15 - Author conformance (write good RSGs)\n\nWhen you define or revise an RSG, check these **concept‑level** rules. They are easy to hold in mind; no tooling implied.\n\n**CC‑RSG‑01 (Locality).** State names and meanings are **scoped** to `(Role, Context)`. Reuse across contexts **only via a Bridge** (F.9).\n\n**CC‑RSG‑02 (Enactability).** Mark **which** states are enactable (**S\\_en**). If none are, the role is **status‑only** (valid); then it **cannot** open the Green‑Gate.\n\n**CC‑RSG‑03 (Observable criteria).** Every checklist item must be **observable** (Observation, Work record, SpeechAct, or derived Evaluation). No opinions.\n\n**CC‑RSG‑04 (Guard discipline).** Guards **gate change**, checklists **recognise state**. Don’t smuggle **task order** into guards; workflow lives elsewhere (A.15).\n\n**CC‑RSG‑05 (Refinement map).** If you declare `R' ≤ R`, provide a **π‑map** and ensure **entailment** (RSG‑R1). Specialist states may be **stricter**, never **weaker**.\n\n**CC‑RSG‑06 (SoD by state).** Define **⊥** in terms of **enactable pairs**. Avoid blanket ⊥ if finer, state‑aware rules reduce false conflicts.\n\n**CC‑RSG‑07 (Human scale).** Default to **≤ 7 states**. If you exceed, add a one‑sentence **didactic rationale** (“distinct gate we will actually use”).\n\n**CC‑RSG‑08 (Green‑Gate wiring).** Ensure every `MethodDescription` step that requires this Role **names** the **◉ states** it expects, or relies on the default “any ◉”.\n\n**CC‑RSG‑09 (Window clarity).** Checklists specify **freshness windows**; state assertions are **Window‑bound** and **non‑permanent**.\n\n**CC‑RSG‑10 (Status/behaviour split).** Epistemic/status roles: **`S_en = ∅`**. They gate **decisions**, not **Work**. Behavioural roles require `U.System` holders (A.2.1).\n",
        "a.2.5:16___extended_grounding_across_four_disciplines": "### A.2.5:16 - Extended grounding across four disciplines\n\nEach vignette shows **(i)** the **Context**, **Role**, **RCS characteristics**, **States** (◉ = enactable), **Green‑Gate** condition, and **how a `U.Work` is gated** by a `U.RoleAssignment`+RSG. Names are **context‑local**.\n\n#### A.2.5:16.1 - Clinical surgery (medicine)\n\n**Context.** `Hospital.OR_2026`\n**Role.** `SurgeonRole` (AgentialRole)\n**RCS characteristics.** *CompetenceLevel, FatigueIndex, AuthorizationValidity, CaseComplexityBand, TeamSoD*.\n\n**States.**\n\n* **Unprepared** — training/recency incomplete.\n* **Prepared** — credentials valid; recency ≤ 90 days.\n* **Authorized** — procedure‑specific approval active.\n* **Ready** — `Prepared ∧ Authorized ∧ FatigueIndex<τ ∧ TeamSoD_OK`. **◉**\n* **Operating** — currently performing steps. **◉**\n* **Suspended** — incident or conflict raised.\n* **Revoked** — approval expired/withdrawn.\n\n**Green‑Gate.** A `MethodDescription` step tagged `requires: SurgeonRole` is **enactable** iff the performer’s `RoleAssignment` asserts **Ready** at the **Window**.\n\n**Work gating.**\n`performedBy = Dr.Kim#SurgeonRole:Hospital.OR_2026` is **valid** for step *“Incision”* only when `Ready(Dr.Kim, SurgeonRole, OR_2026, W)` holds (checklist items: approval id, fatigue score, SoD against *AuditorRole*).\n\n\n#### A.2.5:16.2 - Software operations (SRE)\n\n**Context.** `SRE_Prod_Cluster_EU_2026`\n**Role.** `IncidentCommanderRole` (AgentialRole)\n**RCS characteristics.** *OnCallStatus, PageFreshness, AuthorityToken, CognitiveLoad, ConflictSoD*.\n\n**States.**\n\n* **Off‑Duty** — not on call.\n* **On‑Call** — rota active; page reachable.\n* **Authorized** — escalation token valid.\n* **Ready** — `On‑Call ∧ Authorized ∧ CognitiveLoad≤k ∧ SoD_OK`. **◉**\n* **RunningIncident** — commanding an active incident. **◉**\n* **CoolingDown** — post‑incident refractory period.\n* **Blocked** — conflict with *ChangeAuthorRole* detected.\n\n**Green‑Gate.** Steps in *“Major Incident Process”* that `require: IncidentCommanderRole` open only with **Ready**.\n\n**Work gating.**\n`performedBy = Dana#IncidentCommanderRole:SRE_Prod_Cluster_EU_2026` is **invalid** for “Declare SEV‑1” if `ConflictSoD(ChangeAuthorRole)` holds or `PageFreshness>5 min`.\n\n\n#### A.2.5:16.3 - Laboratory metrology\n\n**Context.** `Metrology_Thermo_2026`\n**Role.** `ThermometerObserverRole` (ObserverRole)\n**RCS characteristics.** *CalibrationAge, DriftRate, TraceabilityChainOK, CleanlinessScore, SyncError*.\n\n**States.**\n\n* **Unqualified** — missing traceability.\n* **Calibrated** — cert valid (≤ 180 d); drift within baseline.\n* **Synchronized** — `SyncError≤ε`.\n* **In‑Range** — contamination absent; env OK.\n* **Measuring** — procedure active. **◉**\n* **Stale** — calibration/sync expired.\n* **Quarantined** — suspected bias.\n\n**Green‑Gate.** `MethodDescription` step *“Record temperature”* is enactable only in state **Measuring** (which requires *Calibrated ∧ Synchronized ∧ In‑Range*).\n\n**Work gating.**\n`performedBy = SensorT‑17#ThermometerObserverRole:Metrology_Thermo_2026` is **rejected** if `CalibrationAge>180 d` or `ControlSampleBias>δ`.\n\n\n#### A.2.5:16.4 - Governance / compliance\n\n**Context.** `Finance_Audit_2026`\n**Role.** `IndependentAuditorRole` (AgentialRole) and `EvidenceRole` (status‑only)\n**RCS (auditor).** *CertificationLevel, IndependenceFlag, AssignmentToken, CaseLoad*.\n**States (auditor).** **Ready**/**Auditing** as in §12.1; **⊥** with `DeveloperRole`.\n**RCS (evidence).** *VerificationStatus, ValidationStatus, Age, ProvenanceChainOK*.\n**States (evidence).** *Collected, Verified, Validated, Contested, Obsolete* (status‑only).\n\n**Green‑Gate.** Audit step `requires: IndependentAuditorRole` — enactable only with **Ready** and **⊥ DeveloperRole** at the Window. Evidence states **gate decisions** (e.g., “accept finding”), never open Work.\n\n**Work gating.**\n`performedBy = Alice#IndependentAuditorRole:Finance_Audit_2026` **fails** if Alice holds any overlapping `DeveloperRole` binding in the same context.\n\n",
        "a.2.5:17___acceptance_harness_(static_conformance)": "### A.2.5:17 - Acceptance harness (static conformance)\n\nAuthor‑facing checks; **notation‑free**, **concept‑level**. Use them when drafting or reviewing an RSG.\n\n**SCR‑A.2.5‑S01 - Local scope.** Every state name is qualified by `(Role, Context)`. No global states.\n**SCR‑A.2.5‑S02 - Enactability mark.** The set **S\\_en** is explicit; each ◉ state is listed.\n**SCR‑A.2.5‑S03 - Observable checklists.** Each state has a Checklist of **observable** predicates (Observation / Evaluation / SpeechAct / Work evidence).\n**SCR‑A.2.5‑S04 - Green‑Gate wiring.** Every `MethodDescription` step that names the Role either (a) names its ◉ state(s) or (b) relies on the default “any ◉” policy; the RSG declares which.\n**SCR‑A.2.5‑S05 - Guard discipline.** Guards only **gate transitions**; they do not encode task order.\n**SCR‑A.2.5‑S06 - SoD by state.** Incompatibilities (⊥) are declared over **states** (or “any ◉”), not over bare role names.\n**SCR‑A.2.5‑S07 - Specialisation entailment.** For every `R' ≤ R`, a refinement map `π: S(R')→S(R)` is provided; each mapped pair has an entailment note (why `Checklist_R' ⇒ Checklist_R`).\n**SCR‑A.2.5‑S08 - Human scale.** `|S| ≤ 7` unless a one‑line didactic rationale is recorded.\n**SCR‑A.2.5‑S09 - Status‑only roles.** If `S_en=∅`, the Role is explicitly tagged **status‑only**; it cannot open the Green‑Gate.\n**SCR‑A.2.5‑S10 - Bridge discipline.** Any cross‑context reuse is via an Alignment Bridge (F.9) with recorded `CL` and losses; no silent imports.\n\n",
        "a.2.5:18___regression_harness_(evolution_checks)": "### A.2.5:18 - Regression harness (evolution checks)\n\nUse when **adding/removing states**, **changing criteria**, or **bridging** across contexts.\n\n**RSCR‑A.2.5‑R01 - State churn impact.** For every added/removed/renamed state, list affected `MethodDescription` steps and `Work` validators; confirm the Green‑Gate policy remains decidable.\n**RSCR‑A.2.5‑R02 - Entailment stability.** When `R' ≤ R` changes, update the `π` map and re‑justify entailments; fail the check if any previously valid entailment breaks.\n**RSCR‑A.2.5‑R03 - SoD coverage.** After edits, recompute the set of **enactable pairs**; verify declared ⊥ still blocks all intended conflicts and no longer blocks permitted cases.\n**RSCR‑A.2.5‑R04 - Evidence freshness.** If any checklist predicate uses **age/freshness**, ensure default Windows are documented and existing state assertions re‑evaluate accordingly.\n**RSCR‑A.2.5‑R05 - Bridge congruence drift.** If a Bridge maps states with `CL=k`, and either side’s checklist changes, revisit the mapping; **do not** keep `CL` unchanged by default—raise or lower with a short rationale.\n**RSCR‑A.2.5‑R06 - Status/behaviour split.** Verify behavioural roles still require `U.System` holders (A.2.1); status‑only roles still have `S_en=∅`.\n**RSCR‑A.2.5‑R07 - One‑screen rule.** If cumulative edits push the RSG beyond one screen, split states or tighten criteria; record a one‑line teaching rationale if you must exceed.\n\n",
        "a.2.5:19___common_failure_modes_(and_quick_remedies)": "### A.2.5:19 - Common failure modes (and quick remedies)\n\n| Failure            | Symptom                               | Why it hurts                       | Quick remedy                                                              |\n| ------------------ | ------------------------------------- | ---------------------------------- | ------------------------------------------------------------------------- |\n| **Workflow creep** | Guards encode task order              | RSG becomes a hidden workflow model | Move ordering to `MethodDescription`; keep guards as **eligibility** only |\n| **Vague criteria** | “experienced”, “mature” in checklists | Non‑decidable Green‑Gate           | Replace with observable proxies (hours, exam score, age thresholds)       |\n| **Global states**  | “Ready” reused across contexts        | Meaning leakage                    | Qualify by `(Role, Context)`; use Bridges for Cross‑context talk             |\n| **Over‑broad ⊥**   | Many false conflicts                  | Blocks delivery                    | Make ⊥ **state‑aware**; restrict to enactable pairs                       |\n| **Missing π‑map**  | Specialisation with no entailment     | Unsafe substitutions               | Add `π` and entailment notes; otherwise drop `≤`                          |\n\n",
        "a.2.5:20___didactic_script_(90_seconds):_how_a.2.5_ties_to_a.2.1_&_a.2.3": "### A.2.5:20 - Didactic script (90 seconds): how A.2.5 ties to A.2.1 & A.2.3\n\n> \\*“A role assignment says **who wears which mask where** (A.2.1). The **RoleStateGraph** says **when that mask is actually wearable**. Each role’s RSG is a **small named state space** with **checklists** for each state. Some states are **enactable** (◉): they open the **Green‑Gate** for `Work`. Others are **status‑only**: they gate decisions, never execution.\n>\n> A **RoleDescription** (A.2.3) is where you publish the role’s **RCS** (characteristics), its **RSG** (states + checklists + guards), and any **role algebra** (≤, ⊥, ⊗) specific to your context.\n>\n> In practice: a `MethodDescription` step lists **required roles**; at runtime, a `Work` record is valid only if its **performer** is a `RoleAssignment` whose RSG asserts an **enactable** state at the **Window**. That’s the Green‑Gate.\n>\n> Different Contexts may use the same role labels. We never assume global meaning; we relate Contexts with **Bridges** that map states and record losses.\n>\n> Keep each RSG **on one screen**, with **observable** checklists. If you’re writing task order, you’ve slipped into workflow—move it to the Method. If you’re writing opinions, convert them into **observables** or drop them. That’s the whole trick.”\\*\n\n",
        "relations": "### A.2.5:21 - Relations (quick pointers)\n\n* **Builds on:** A.2.1 `U.RoleAssignment` (the binding that can assert states); A.2.3 `U.RoleDescription` (the carrier of RSG); E.10.D1 (Context discipline).\n* **Enables.** A.15 (Role‑Method‑Work Alignment via Green‑Gate); B.3 (Trust penalties when crossing Bridges with lower `CL`).\n* **Interacts with.** D‑cluster deontics (speech‑acts gate **Authorized**‑like states for agential roles); F.9 (state‑level alignment across contexts).\n",
        "a.2.5:end": "### A.2.5:End\n"
      },
      "content": "### A.2.5:End\n",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.2.6",
      "title": "Unified Scope Mechanism (USM): Context Slices & Scopes",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.2.6 - Unified Scope Mechanism (USM): Context Slices & Scopes\n\n> **One-line summary.** Introduces a single, context-local **scope mechanism** for all holons: **`U.ContextSlice`** (where we reason and measure) and a family of **set-valued scope types** (**USM scope objects, `U.Scope`**), specialized as **`U.ClaimScope`** for epistemes (**G** in **F–G–R**), **`U.WorkScope`** for system capabilities, and **`U.PublicationScope`** for publication carriers; with one algebra (∩ / SpanUnion / translate / widen / narrow / refit) and uniform Cross-context handling (Bridge + CL).\n\n**Replaces / deprecates.**\nThis pattern **supersedes** the scattered use of labels *applicability*, *envelope*, *generality*, *universality* and *capability envelope* where they tried to stand in for the one scope mechanism. From now on:\n\n* For epistemes, the only **scope type** is **`U.ClaimScope`** (nick **G** in F–G–R).\n* For system capabilities, the only **scope type** is **`U.WorkScope`**.\n* For publication carriers (views/cards/lanes), the only **scope type** is **`U.PublicationScope`**.\n* The abstract architectural notion is **`U.Scope`** — a **set-valued USM object** over `ContextSliceSet` with its own algebra (∩ / SpanUnion / translate / widen / narrow / refit); it is **not** a `U.Characteristic` and MUST NOT appear in any `CharacteristicSpace`.\n\nLegacy words (*applicability / envelope / generality / capability envelope*) MAY appear **only** as explanatory aliases in non‑normative notes.\n\n**Cross‑references.**\n— **C.2.3** (Unified Formality **F**) and **C.2.2** (F–G–R): this pattern **defines G** as `U.ClaimScope`.\n— **A.2.2** (Capabilities): capability gating now **SHALL** use `U.WorkScope`.\n— **Part B** (Bridges & CL): Cross‑context transfers **MUST** declare a Bridge with **CL**; CL affects **R**, not **F/G**.\n— **Part E** (Publication discipline; e.g., **E.17 MVPK**): publication views/cards/lanes MAY declare `U.PublicationScope` to bound **where** a publication is admissible; `U.PublicationScope` MUST NOT widen the underlying `U.ClaimScope`/`U.WorkScope`. (USM supplies the scope calculus; Part E supplies publication discipline.)\n",
        "a.2.6:1___purpose_&_audience": "### A.2.6:1 - Purpose & Audience\n\nThis pattern gives **engineering managers and assurance architects** one vocabulary, one model, and one set of operations to talk about **where** a claim holds and **under which conditions** a system can deliver a piece of **Work**. It removes the need to remember whether a document said “applicability,” a model said “envelope,” or a safety plan said “capability envelope.” **Scope is scope.** The only distinction that matters is **what carries it**:\n\n* **Knowledge/episteme** → **Claim scope** (G).\n* **System/capability** → **Work scope** (conditions under which Work at the promised measures is deliverable).\n\nWith USM, teams can:\n\n* specify, compare, and compose scope **without translation games**;\n* gate ESG and Method–Work steps with **observable, context‑local scope checks**;\n* cross Contexts safely using Bridges and **explicit CL penalties** applied to **R**.\n\nThis pattern **defines** the **scope mechanism** (Context slices, set‑valued scopes, algebra, and guard usage) and the canonical **lexicon** (Claim scope (G), Work scope). It does **not** prescribe which Contexts must widen/narrow scope, nor which assurance levels are required; those are set by context‑local ESG and Method–Work policies, which SHALL reference the mechanisms defined here.\n",
        "a.2.6:2___context": "### A.2.6:2 - Context\n\n#### A.2.6:2.1 - Cross‑disciplinary pressures\n\nModern projects couple **formal specs**, **data‑driven models**, **safety cases**, and **operational playbooks**. Each artifact must say **where it is valid**—yet terminology drifts:\n\n* Standards and specs often say *applicability* or *scope*.\n* Modeling communities say *envelope*.\n* Safety and performance documents speak about *capability envelope*.\n* Knowledge patterns have used *generality* (G) as if it were “more abstract,” when we actually need “**where the statement holds**.”\n\n#### A.2.6:2.2 - context‑local reasoning\n\nFPF is context‑local: decisions, checks, and state assertions are **valid inside a bounded context**. Every practical question—*Is this claim usable here? Can this capability deliver that Work now?*—must be answered **on a concrete slice of context** (terminology, versions, environmental parameters, time selector **Γ\\_time**). USM provides a first‑class object for such slices and a single scope calculus atop them.\n\n#### A.2.6:2.3 - Minimal, composable trust math\n\nIn **F–G–R**:\n\n* **F** (formality) is “how strictly a claim is expressed” (C.2.3).\n* **G** must be “**where it holds**,” not “how abstract it sounds.”\n* **R** measures evidence and decays/penalties (freshness, CL).\n\nWhen **G** is a **set‑valued scope**, composition becomes precise: serial dependencies **intersect** scopes; parallel, independently supported lines can publish a **SpanUnion**—but only where each line is supported.\n\n",
        "problem": "### A.2.6:3 - Problem\n\n1. **Synonym soup.** *Applicability, envelope, generality, capability envelope*—different labels for the **same mechanism** led to mismatches in gating, review, and reuse.\n2. **Abstraction confusion.** Calling G “generality” invited teams to treat “more abstract wording” as “broader scope,” silently masking unstated assumptions.\n3. **Split mechanics.** Episteme vs system text used different algebra and guard language, though **the same set operations** were meant.\n4. **Cross‑context opacity.** Transfers between Contexts lacked a shared carrier and a rule for what changes (trust) vs what stays (scope).\n5. **Overloaded words.** *Validity* clashed with **Validation Assurance (LA)**; *operation/operational* clashed with **Work/Run** in A.15, producing governance ambiguity.\n\n",
        "forces": "### A.2.6:4 - Forces\n\n| Force                                             | Tension to resolve                                                                                                                                               |\n| ------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **One mechanism vs two worlds**                   | We must serve both **knowledge about the world** (claims) and **doing work in the world** (capabilities) **without** duplicating concepts.                       |\n| **Locality vs interoperability**                  | Scope must be **context‑local** and precisely checkable, yet transferable across Contexts via Bridges **without redefining** the characteristic.                       |\n| **Expressivity vs minimal vocabulary**            | Teams need to capture rich conditions (time windows, environment, versions) but not explode the lexicon into “envelope/applicability/…” variants.                |\n| **Static content vs operational change**          | Claims may hold broadly while current operations are narrow (or vice versa). The mechanism must keep “what is true” and “what can be done” aligned yet distinct. |\n| **Open‑world exploration vs closed‑world gating** | Exploration benefits from permissive drafts; **gates** require crisp, observable checks. The same scope object must support both.                                |\n\n",
        "solution": "### A.2.6:5 - Solution — Overview (preview; full definitions in Part 2)\n\n**USM** introduces:\n\n* **`U.ContextSlice`** — an addressable **slice of a bounded context** (terminology, parameter ranges, versions/Standards, and a mandatory **Γ\\_time** selector). All scope checks are performed **on slices**.\n* **`U.Scope`** — the abstract **set‑valued scope object** over `U.ContextSlice`.\n* **Specializations:**\n  **`U.ClaimScope`** (nick **G**) on `U.Episteme` (“**where the claim holds**”),\n  **`U.WorkScope`** on `U.Capability` (“**where the capability can deliver Work at declared measures within qualification windows**”), and\n  **`U.PublicationScope`** on publication carriers (“**where the publication surface is admissible**”).\n* **One algebra:** serial **intersection**, parallel **SpanUnion** (only where supported), **translate** via Bridge (CL affects **R**, not **F/G**), and **widen / narrow / refit** operations for scope evolution.\n\n**Lexical commitments (normative):**\n— In normative text and guards, use **Claim scope (G)**, **Work scope**, and **Publication scope**.  \n— Do **not** name the characteristic “applicability/envelope/generality/capability envelope/**publication applicability**/validity.” Those words are permitted only as explanatory aliases in notes.\n",
        "a.2.6:6___normative_definitions": "### A.2.6:6 - Normative Definitions\n\n#### A.2.6:6.0 - USM as a `U.Mechanism.Intension` (normalization for A.6.1/A.6.5)\n\n**Intent.** This subsection makes the **USM** definition in A.2.6 explicitly conform to the\n`U.Mechanism` *intension* requirements (A.6.1) and the `…Slot` / `…Ref` lexical discipline (A.6.5),\nwithout changing USM’s meaning.\n\n**USM Mechanism.Intension (normative; A.6.1 decomposition).**\n\n* **Imports (USM).** `U.ContextSlice`, `U.ContextSliceSet`, Part B **Bridge/CL** (`U.Bridge`, `U.CongruenceLevel`), and `U.GammaTimePolicy`.\n* **BaseType (USM).** `U.ContextSliceSet` (set‑valued scope objects range over sets of addressable `U.ContextSlice`).\n* **SliceSet (USM).** `U.ContextSliceSet` (addressable `U.ContextSlice`s; see §6.1).\n* **SubjectKind (USM).** `U.Scope` with kind specialisations:  \n  `U.ClaimScope ⊑ U.Scope`, `U.WorkScope ⊑ U.Scope`, `U.PublicationScope ⊑ U.Scope`.\n* **ExtentRule (USM).** The quantifier domain is the set of **well‑formed scope objects** over the SliceSet: `Extension(U.Scope, slice) = { S | S ⊆ U.ContextSliceSet }`.\n* **ResultKind? (USM).** `U.Scope` (for operators that return scopes, e.g., `∩`, `SpanUnion`, `translate`).\n\n**SlotIndex (USM) for operators/guards (normative; A.6.0:4.1.1 + A.6.5).**  \nThese SlotKinds are stable names for signatures, substitution laws, and guard templates; they are **not** additional data slots on carriers.\n\n| SlotKind             | ValueKind              | refMode  | Meaning |\n|----------------------|------------------------|----------|---------|\n| `ScopeSlot`          | `U.Scope`              | byRef    | A scope object (set of slices) owned by a carrier |\n| `LeftScopeSlot`      | `U.Scope`              | byRef    | Left scope operand (binary ops/relations) |\n| `RightScopeSlot`     | `U.Scope`              | byRef    | Right scope operand (binary ops/relations) |\n| `ScopeFamilySlot`    | `Set[U.Scope]`          | byRef    | Finite family of scopes (for `SpanUnion`) |\n| `SliceSlot`          | `U.ContextSlice`       | byValue  | A single addressable slice (membership target) |\n| `SliceSetSlot`       | `U.ContextSliceSet`    | byRef    | A finite target set of slices (coverage target) |\n| `BridgeRef`          | `U.Bridge`             | byRef    | Bridge used for `translate` / Cross‑context guards |\n| `CLSlot`             | `U.CongruenceLevel`    | byValue  | Congruence Level bound in Cross‑context guards |\n| `GammaTimeSlot`      | `U.GammaTimePolicy`    | byValue  | Explicit `Γ_time` selector/policy bound in guards |\n\n**OperationAlgebra (USM) with SlotSpecs (normative).**\n\n* `member(SliceSlot, ScopeSlot)` — surface form: `SliceSlot ∈ ScopeSlot`.\n* `subset(LeftScopeSlot, RightScopeSlot)` — surface form: `LeftScopeSlot ⊆ RightScopeSlot`.\n* `intersect(LeftScopeSlot, RightScopeSlot) → U.Scope` — surface form: `LeftScopeSlot ∩ RightScopeSlot`.\n* `spanUnion(ScopeFamilySlot) → U.Scope` — surface form: `SpanUnion(ScopeFamilySlot)`.\n* `translate(BridgeRef, ScopeSlot) → U.Scope` — Cross‑context mapping via Bridge.\n* `widen(LeftScopeSlot, RightScopeSlot)` — Δ‑move, requires `LeftScopeSlot ⊂ RightScopeSlot`.\n* `narrow(LeftScopeSlot, RightScopeSlot)` — Δ‑move, requires `RightScopeSlot ⊂ LeftScopeSlot`.\n* `refit(LeftScopeSlot, RightScopeSlot)` — normalization, requires `LeftScopeSlot = RightScopeSlot`.\n\n**Derived guard predicates (USM).**\n\n* `coversSlice(ScopeSlot, SliceSlot) := (SliceSlot ∈ ScopeSlot)`.\n* `coversSet(ScopeSlot, SliceSetSlot) := (SliceSetSlot ⊆ ScopeSlot)`.\n\n**LawSet (USM).** Serial composition uses **intersection**; parallel publication uses **SpanUnion** only with an explicit independence justification (§7.3).\n\n**AdmissibilityConditions (USM).** Scope coverage predicates MUST be **tri‑state** under unknowns: unknown inputs yield **unknown**, and guards MUST either (a) **abstain** (fail closed) or (b) **degrade** trust in the admitting decision via **R**; unknown MUST NOT be implicitly coerced to `false`/`0`. (See also §7.1 and §10.1.)\n\n**Applicability (USM).** USM governs **Claim/Work/Publication** scope objects inside a `U.BoundedContext`; coverage judgments are evaluated on explicit `U.ContextSlice` tuples (§6.1) and are not comparable/scorable as CHR values.\n\n**Audit (USM).** Record scope‑aware decisions with the `TargetSlice` tuple, guard outcomes, and any Bridge+CL used (see §14.1).\n\n**Transport (USM).** Cross‑context usage is **Bridge‑only** with explicit **CL**; CL penalties apply to `R_eff = R · Φ(CL)` and MUST NOT rewrite **F** or **G** (§7.4/§7.5).\n\n**Γ_timePolicy (USM).** `Γ_time` is mandatory in slices and guards (§8.2); implicit “latest” is forbidden.\n\n**PlaneRegime (USM).** Not applicable to set‑valued scope objects (no `CL^plane` effect on scopes).\n\n**Mechanism specialisation (USM; A.6.1:4.2.1).** A bounded context MAY publish a specialisation of USM as either a refinement `USM′ ⊑ USM` (tighten LawSet/AdmissibilityConditions) or an extension `USM ⊑⁺ USM′` (add new operators/slots). Any such specialisation SHALL (i) name its parent (`USM`), (ii) declare the morphism kind (`⊑` vs `⊑⁺`), (iii) preserve the same BaseType and SlotKinds for inherited operators (no renaming), (iv) avoid adding new mandatory inputs to inherited signatures. It MAY narrow ValueKinds/refModes monotonically and add admissibility constraints, but MUST remain substitutable for the inherited USM operators.\n\n#### A.2.6:6.1 - `U.ContextSlice` — where scope is evaluated\n\n**Definition.** `U.ContextSlice` is an addressable, context‑local selection of a bounded context comprising:\n\n* **Vocabulary & roles.** The active terminology, role bindings, and local dictionaries.\n* **Standards & versions.** Concrete versioned interfaces, schemas, notations, or service Standards in force.\n* **Environment selectors.** Named parameters/ranges (e.g., temp, humidity, platform, jurisdiction, dataset cohort).\n* **Time selector `Γ_time`.** A **mandatory** selector for the temporal frame of reference (point, window, or policy), disallowing implicit “latest”.\n\n**Semantics.** All scope checks, guards, and compositions are evaluated **inside** an explicitly named `U.ContextSlice`. Cross‑context or cross‑slice usage MUST be mediated by a Bridge (Part B) with an explicit CL rating; see §7.4.\n\n**Addressability.** A slice MUST be identifiable via a canonical tuple (Context, vocab‑id, Standard/version ids, env selector(s), `Γ_time`). A slice MAY be a singleton or a finite set if a guard tests multiple coherent sub‑conditions. \n\n**Slice key (minimal).** A `U.ContextSlice` **SHALL** be addressable by a tuple containing at least: `(Context, Standard/version ids (if any), environment selectors, Γ_time)`. Contexts MAY extend this tuple (e.g., vocab/roleset ids).\n\n#### A.2.6:6.2 - `U.Scope` — the abstract set‑valued scope property (USM kind; **not** a CSLC measurement)\n\n**Definition.** `U.Scope ⊆ ContextSliceSet` is a **set‑valued USM property** whose values are sets of `U.ContextSlice` where a given statement, behavior, or capability is **fit‑for‑use**. It is **not** numeric; its internal order is the subset relation `⊆`. There is no “unit”. The primitive judgement is **membership**: `slice ∈ Scope`.  \n\n+**Guard (normative).** `U.Scope`, `U.ClaimScope (G)`, `U.WorkScope`, and `U.PublicationScope` are **not** `U.Characteristic`s in the A.17/CSLC sense; do **not** include them as slots in any `U.CharacteristicSpace`, and do **not** attach normalizations/scores to them. They are **USM scope objects**.\n\n**Operations.** USM admits:\n\n* **Intersection `∩`** (serial composition).\n* **SpanUnion** (parallel, independently supported coverage) **only when an explicit named independence assumption is declared** (features/axes named, validity window stated, evidence class cited). See **A.6.1/USM LawSet** for the normative template.\n* **Translate** (Cross‑context mapping via Bridge).\n* **Widen / Narrow** (monotone changes to the set).\n* **Refit** (content‑preserving re‑expression; set equality).\n\n**Locality.** `U.Scope` values are defined and reasoned about **context‑locally**. Translation between Contexts never occurs implicitly; see §7.4.\n\n#### A.2.6:6.3 - `U.ClaimScope` (nick **G**) — scope of a claim (episteme)\n\n**Carrier.** `U.Episteme` (claims, specifications, theories, policies).\n\n**Meaning.** The set of `U.ContextSlice` where the **claim holds** as stated. This is **G** in the F–G–R triple. **G is not “abstraction level”**; it is the applicability area of the claim.\n\n**Expression.** Authors SHALL declare Claim scope as explicit predicates or condition blocks (assumptions, parameter ranges, cohorts, platform/Standard versions, `Γ_time` windows).\n\n**Path composition (serial).** Along any essential dependency path supporting the claim, the effective scope is the **intersection** of contributors’ Claim scopes (see §7.2). Empty intersection makes the path inapplicable.\n\n**Parallel support.** Where **independent** lines of support justify disjoint areas, the episteme MAY publish a **SpanUnion** (see §7.3) limited strictly to the covered slices.\n\n**Δ‑moves.**\n\n* **ΔG+ (widen).** Replace scope S with S′ such that S ⊂ S′.\n* **ΔG− (narrow).** Replace scope S with S′ such that S′ ⊂ S.\n* **Refit.** Replace S with S′ where S′ = S (normalization, re‑parametrization).\n* **Translate.** Map S across Contexts via a declared Bridge; CL penalties apply to **R**, not to **F/G**.\n\n**Orthogonality.** Changes in **F** (form of expression) or **D/AT** (detail/abstraction tiers) do not change **G** unless the declared area of validity changes.\n\n\n#### A.2.6:6.4 - `U.WorkScope` — scope of doing Work (capability)\n\n**Carrier.** `U.Capability` (a system’s ability to deliver specified `U.Work`).\n\n**Meaning.** The set of `U.ContextSlice` (conditions, Standards, platforms, operating parameters, `Γ_time`) under which the capability can **deliver the intended Work** at the declared **measures**, within declared **qualification windows**.\n\n**Expression.** Capability owners SHALL declare **`U.WorkScope`** as explicit **conditions/constraints over `U.ContextSlice` only** (environment, platforms, Standards by version, resource regimes, `Γ_time`). Quantitative deliverables and operation windows are **not** part of the scope value:  \n* Declare targets as **`U.WorkMeasures`** (e.g., latency ≤ L, throughput ≥ T, tolerance ≤ ε) bound in guards (WG‑2).  \n* Declare inspection/recertification policies as **`U.QualificationWindow`** bound in guards (WG‑3).  \nThe use‑time admission requires **all** of: `WorkScope covers JobSlice` **AND** `WorkMeasures satisfied` **AND** `QualificationWindow holds`.\n\n**Method–Work gating.** A Work step’s guard MUST check that the target slice is **covered** by the capability’s Work scope **and** that required measures and qualification windows are satisfied.\n\n**Composition and Δ‑moves.** Work scope uses the **same algebra** as Claim scope (∩ / SpanUnion / translate / widen / narrow / refit). Translation across Contexts follows §7.4.\n\n**Separation from knowledge.** Work scope does **not** assert a proposition about the world; it asserts **deliverability** of Work under conditions. Evidence for deliverability feeds **R** (Reliability) via measurements and monitoring.\n\n**Required guard facets (capabilities).**  \n* **`U.WorkMeasures` (mandatory).** A set of measurable targets with units and tolerated ranges, evaluated on the JobSlice.  \n* **`U.QualificationWindow` (mandatory for operational use).** A time policy (point/window/rolling) stating when the capability is considered qualified; evaluated at `Γ_time`.  \nThese facets are **separate** from `U.WorkScope` and live in the **R‑lane** (assurance). They MUST be referenced in Method–Work guards (see §10.3 WG‑2/WG‑3).\n\n#### A.2.6:6.5 - `U.PublicationScope` — scope of a publication (view/surface)\n**Carrier.** Publication carriers (e.g., **PublicationSurface/InteropSurface** views/cards/lanes in Part E; MVPK faces).\n**Meaning.** The set of `U.ContextSlice` where a **publication** (a view/card/lane about some object or morphism) is **admissible for use** without introducing claims beyond its underlying carrier.\n\n**Relation to other scopes (normative).**\n* If the publication is **about an episteme `E`**:  \n  `PublicationScope(view_E) ⊆ ClaimScope(E)`.\n* If the publication is **about a capability `C`**:  \n  `PublicationScope(view_C) ⊆ WorkScope(C)`.\n* If the publication is **about a composition and/or crosses Contexts**:  \n  `PublicationScope(view) ⊆ translate(Bridge, ⋂ scopes of contributors)`; CL penalties apply to **R** only (scope set membership is unaffected).\n\n**Expression.** Authors SHALL declare `U.PublicationScope` as explicit predicates over `U.ContextSlice` (Context, Standard/version ids, environment selectors, `Γ_time`). It MAY be **narrower** than the underlying scope (e.g., due to pin availability, labeling, or audience constraints) but MUST NOT be wider.\n\n**Algebra & Δ‑moves.** Inherits the USM algebra (∩ / SpanUnion / translate / widen / narrow / refit). **Widen** is permitted only when the underlying `U.ClaimScope`/`U.WorkScope` widens accordingly; otherwise the publication MAY refit or narrow.\n\n**Orthogonality to measurement.** `U.PublicationScope` is a **USM scope object** (set‑valued), not a CHR Characteristic and MUST NOT appear as a slot in a `U.CharacteristicSpace`.\n\n**View refinement (profiles).** When a stricter publication profile/view **refines** another (e.g., a typed card that requires additional pins), its `U.PublicationScope` **MUST NOT** be wider than that of the less formal view.\n",
        "a.2.6:7___scope_algebra": "### A.2.6:7 - Scope Algebra\n\n#### A.2.6:7.1 - Membership & Coverage\n\n* **Membership judgement.** `slice ∈ Scope` is the primitive check.\n* **Coverage guard.** A guard “Scope **covers** TargetSlice” means either:\n\n  * **singleton:** `TargetSlice ∈ Scope`, or\n  * **set:** `TargetSet ⊆ Scope`.\n* **No implicit expansion.** Absent an explicit declaration, guards MUST NOT treat “close” slices as covered; widening requires a ΔG+ change.\n\n**Tri‑state admissibility under unknowns (normative; aligns A.6.1).**\n\n* If any required input to a membership/coverage check is **unknown** (missing slice selector, unknown Standard version, unmappable Bridge leg, unspecified `Γ_time`, etc.), the check result is **unknown**, not `false`.\n* Guards MUST either **abstain** (fail closed) or explicitly route the outcome through an **R‑lane degradation** policy; unknown MUST NOT be coerced to `false/0`.\n\n#### A.2.6:7.2 - Serial Composition (Intersection)\n\n**Rule S‑INT (serial).** For an essential dependency chain `C1 → C2 → … → Ck` that supports a claim/capability, the effective scope along that chain is:\n\n```\nScope_serial = ⋂_{i=1..k} Scope(Ci)\n```\n\nIf `Scope_serial = ∅`, the chain is **inapplicable** and MUST NOT contribute to published scope.\n\n**Monotonicity.** Adding a new essential dependency can only narrow (or leave unchanged) the serial scope.\n\n\n#### A.2.6:7.3 - Parallel Support (SpanUnion)\n\n**Rule P‑UNION (parallel).** If there exist **independent** support lines `L₁,…,Lₙ` for the **same** claim/capability, each with serial scope `S_i`, the publisher MAY declare:\n\n```\nScope_published = SpanUnion({S_i})  =  ⋃_{i=1..n} S_i\n```\n\n**Constraints.**\n\n* Independence MUST be justified (different support lines must not rely on the same weakest link).\n* The union MUST NOT exceed the union of supported slices; “hopeful” areas are disallowed.\n* Publishers SHOULD annotate coverage density/heterogeneity (informative) to aid R assessment, but numeric “coverage” is not part of G.\n* **Independence criterion.** Support lines in a **SpanUnion** MUST be partitioned so that each line has a set of **essential components** disjoint from the others’ essential components (no shared weakest link). The partition (or a certificate thereof) SHALL be referenced in the publication.\n\n#### A.2.6:7.4 - Why a **G-ladder/levels/scales** is not needed (and **must not** be introduced)\n\n**1) G is not an ordinal scale; it is set-valued.**\nUnder **USM**, `U.ClaimScope` is a **set‑valued** **USM scope object** over `U.ContextSlice`. The only well‑typed primitives are **membership** and **set operations** (`⊆`, `∩`, `⋃`). Imposing ordinal “levels” such as **G0…Gk** violates the type discipline and produces non‑invariant behavior (the **same set** could be “rated” with different numbers under different heuristics). (See also LEX‑CHR‑STRICT.)\n\n**2) G composes via `∩` / `SpanUnion`, not via `min` / `avg`.**\nUSM already fixes composition: along a **dependent path** use **intersection**; across **independent support lines** publish **SpanUnion**. None of these operations relies on (or preserves) any linear order. An ordinal “G ladder” invites people to take **minimums/averages**, which is **incorrect** for sets and breaks the established algebra.\n\n**3) A G ladder drags in “abstraction level,” which is orthogonal.**\nEarly “G ladders” effectively encoded **abstraction/typing** (instances → patterns → formal classes/types → up‑to‑iso). That is valuable **didactics**, but **not applicability**. We have already separated these concerns: **abstraction** is captured, if needed, by **`U.AbstractionTier (AT)`** as an optional facet; **applicability** is **`U.ClaimScope (G)`**.\n\n**4) A G ladder breaks locality and Bridge semantics.**\nCross‑context transfer maps a **set** `Scope` via a **Bridge** and penalizes **R** by **CL**. There is no canonical way to “translate” an **ordinal G level** between Contexts: the mapped area may be **strictly narrower** or differently factored. Level numbers would become non‑portable, causing hidden loss or inflation of trust. With USM, we **translate sets** and keep the CL penalty where it belongs—**in R**, not in G.\n\n**5) A G ladder duplicates ESG guards without adding decision power.**\nWhat teams often want to “compress into a G number” is actually (a) the **quality of expression** and (b) the **completeness** of the declared scope. The first is an **F threshold** (e.g., require **`U.Formality ≥ F4`** so the scope is predicate‑like and addressable); the second is handled by explicit **ESG guards**: “**Scope covers TargetSlice**,” “**`Γ_time` is specified**,” and “**freshness window holds**” (R‑lane). A ladder for G adds confusion but no additional control.\n\n**Normative directive.**\n`U.ClaimScope (G)` **SHALL** remain a **set‑valued** characteristic; **no ordinal or numeric ladder SHALL be defined** for G. Authoring and gating **SHOULD** use **F thresholds** (C.2.3) and **explicit guard predicates** (A.2.6) rather than pseudo‑levels of G.\n\n#### A.2.6:7.5 - Translation across Contexts (Bridge & CL)\n\n**Rule T‑BRIDGE.** To use a scope in a different bounded context (room), an explicit **Bridge** MUST be declared with:\n\n* **Mapping.** A documented mapping from source to target `U.ContextSlice` vocabulary/characteristics.\n* **Congruence Level (CL).** A rating of mapping congruence.\n* **Loss notes.** Any known losses, assumptions, or non‑isomorphisms.\n\n**Effect.** The mapped scope is `T(Scope)` in the target Context. **CL penalties apply to R** (the trust in support/evidence), **not to F or G**. If mapping is coarse, the publisher SHOULD also narrow the mapped scope to the area where losses are negligible (best practice, not a requirement).\n\n\n#### A.2.6:7.6 - Δ‑Operations (Widen, Narrow, Refit)\n\n* **ΔG+ (widen).** Monotone expansion: `S ⊂ S′`. Requires new support or stronger bridges.\n* **ΔG− (narrow).** Monotone restriction: `S′ ⊂ S`. Often used to remove areas invalidated by new findings.\n* **Refit.** `S′ = S` after normalization (e.g., re‑parameterization, changing units, factoring common predicates). Refit MUST NOT alter membership.\n\n**Refit (normalization).** A refit **MUST preserve membership** exactly (S′ = S). Any change that alters boundary inclusion (due to rounding, unit conversion, discretization) is a ΔG± change, not a refit.\n\n**Edition triggers.** Any change that alters the published set (ΔG±) is a content change and MAY trigger a new edition per Context policy (see A.2.x on editions). Refit is not a content change.\n\n#### A.2.6:7.7 - Invariants\n\n* **I‑LOCAL.** All scope evaluation is **context‑local**. Cross‑context usage MUST follow §7.4.\n* **I‑SERIAL.** Serial scope is an **intersection**; it cannot grow by adding dependencies.\n* **I‑PARALLEL.** Parallel scope MAY grow by union, but only where **independently supported**.\n* **I‑WLNK.** Weakest‑link applies to **F** and **R** on dependency paths; **G** follows set rules (∩ / ⋃).\n* **I‑IDS.** Idempotence: Intersecting or unioning a set with itself does not change it.\n* **I‑EMPTY.** Empty scope is a first‑class value; guards MUST treat it as “not applicable”.\n\n\n#### A.2.6:7.8 - Empty & Partial Scopes\n\n* **Empty scope (`∅`).** The claim/capability is **currently not usable anywhere** in the Context; guards MUST fail.\n* **Partial scope.** Publishers SHOULD avoid “global” language when actual scope is thin; instead, publish explicit slices and (informatively) coverage hints to guide R assessment.\n\n",
        "a.2.6:8___locality,_time_&_version_semantics": "### A.2.6:8 - Locality, Time & Version Semantics\n\n#### A.2.6:8.1 - context‑locality\n\nScopes are **owned and evaluated** within a `U.BoundedContext`. State assertions (ESG/RSG) and Method–Work gates MUST NOT assume that a scope declared in another Context applies verbatim; see §7.4.\n\n#### A.2.6:8.2 - Time selector `Γ_time`\n\nEvery scope declaration and every guard MUST specify a **`Γ_time` selector** (point, window, or policy such as “rolling 180 days”) whenever time‑dependent assumptions exist. Implicit “latest” is forbidden. When `Γ_time` differs between contributors, serial intersection resolves the overlap.\n\n#### A.2.6:8.3 - Standards, versions & notations\n\nScope predicates SHALL name Standards/interfaces/schemas **by version**. Changing symbols/notations with a faithful mapping does not change **G** (it may change **CL** for the mapping and thus affect **R**).\n\n#### A.2.6:8.4 - Determinism of evaluation\n\nGiven fixed inputs (slice tuple, declared scope), the membership judgement MUST be deterministic. Guards SHALL fail closed (no membership ⇒ no use).\n\n#### A.2.6:8.5 - Interaction with R (freshness & decay)\n\nFor empirical claims and operational capabilities, **R** typically binds evidence freshness windows. Scope does not decay with time; **trust in the support** does. Guards MAY combine “Scope covers” with “Evidence freshness holds” as separate predicates.\n\n",
        "a.2.6:9___lexical_discipline_(part_e_compliance)": "### A.2.6:9 - Lexical Discipline (Part E compliance)\n\n**L‑USM‑1 (names).** Use **Claim scope (G)** for epistemes, **Work scope** for capabilities, and **Publication scope** for publication carriers. Use **Scope** only when discussing the abstract mechanism. Avoid naming any **characteristic** as “applicability,” “envelope,” “generality,” “capability envelope,” or “validity”.\n\n**L‑USM‑2 (Work/Run).** Prefer **Work/Run** vocabulary from A.15 for system execution contexts. Do not introduce “operation/operating” as characteristic names; use **Work scope**.\n\n**L‑USM‑3 (Validation).** “Validation/Validate” remain reserved for **LA** in assurance lanes (Part B). Do not name the scope characteristic “validity”.\n\n**L‑USM‑4 (Domain).** “Domain” is a descriptive convenience. Scopes are evaluated on **Context slices**; guards SHALL reference slices, not generic “domains”.\n\n**L‑USM‑5 (First mention).** On first use in a Context, include the parenthetical nick: *“Claim scope (**G**)”* to preserve the F–G–R mapping.\n",
        "a.2.6:10___guard_patterns_(esg_&_method–work)": "### A.2.6:10 - Guard Patterns (ESG & Method–Work)\n\n#### A.2.6:10.1 - Common guard shape\n\nA scope‑aware guard has the form:\n\n```\nGuard := ScopeCoverage AND TimePolicy AND (EvidenceFreshness?) AND (BridgePolicy?)\n```\n\n**Admissibility note (normative; A.6.1 alignment).** If `ScopeCoverage` is **unknown** (due to unknown slice keys, unmappable translation, missing `Γ_time`, etc.), the guard MUST NOT silently treat this as `false`. It MUST either abstain (fail closed) or apply an explicit R‑lane degradation policy.\n\nWhere:\n\n* **ScopeCoverage**: `Scope covers TargetSlice` (singleton or finite set), see §7.1.\n* **TimePolicy**: explicit `Γ_time` selector(s); implicit “latest” is forbidden (§8.2).\n* **EvidenceFreshness**: optional R‑lane freshness/decay predicates; **separate** from ScopeCoverage (§8.5).\n* **BridgePolicy**: required if the Scope and TargetSlice are in **different Contexts**; declares Bridge, CL, loss notes (§7.4).\n\nThe guard **fails closed** (no membership ⇒ denial), and evaluation is **deterministic** given the slice tuple (§8.4).\n\n\n#### A.2.6:10.2 - ESG guard families (epistemes)\n\n**EG‑1 - ClaimScopeCoverage (mandatory).**\nThe state transition MUST include a predicate:\n\n```\nU.ClaimScope(episteme) covers TargetSlice\n```\n\n* **Singleton**: `TargetSlice ∈ ClaimScope`.\n* **Finite set**: `TargetSet ⊆ ClaimScope`.\n\n**EG‑2 - Formality threshold (if required by ESG).**\nWhen rigor is gated, the guard MUST reference C.2.3:\n\n```\nU.Formality(episteme) ≥ F_k\n```\n\n**EG‑3 - Evidence freshness (R‑lane).**\nIf the state implies trust, a separate predicate MUST assert freshness windows for bound evidence:\n\n```\nFresh(evidence, window)  AND  (NoExpiredBindings)\n```\n\n**EG‑4 - Cross‑context usage.**\nIf `TargetSlice.Context ≠ episteme.Context`, the guard MUST require a declared Bridge and CL:\n\n```\nBridge(source=episteme.Context, target=TargetSlice.Context)  AND  CL ≥ c\n```\n\n> **Effect:** CL penalties apply to **R**, not to **F/G** (§7.4). The ESG guard MAY also **narrow** the mapped Claim scope when mapping losses are known.\n\n**EG‑5 - ΔG triggers.**\nIf the transition publishes a **wider** Claim scope (ΔG+), the guard MUST capture the new support or the new Bridge and, if Context policy so dictates, mint a new edition (PhaseOf).\n\n**EG‑6 - Independence for SpanUnion (when claiming parallel scope).**\nWhen the episteme declares a **SpanUnion** across independent lines, the guard MUST include an **independence justification** (pointer to the support partition). No independence ⇒ no union.\n\n*(Informative note.)* Managers often combine EG‑1 (coverage) + EG‑2 (F threshold) + EG‑3 (freshness) for “Effective” or “Approved” states, and EG‑4 when adopting claims across Contexts.\n\n\n#### A.2.6:10.3 - Method–Work guard families (capabilities)\n\n**WG‑1 - WorkScopeCoverage (mandatory).**\nA capability can be used to deliver a Work step only if:\n\n```\nU.WorkScope(capability) covers JobSlice\n```\n\n**WG‑2 - `U.WorkMeasures` satisfied** (mandatory for deliverables).\nGuards MUST bind quantitative measures that the capability promises in the JobSlice:\n\n```\nSLO/target measures satisfied (latency ≤ L, throughput ≥ T, tolerance ≤ ε, … )\n```\n\n**WG‑3 - `U.QualificationWindow` holds** (mandatory for operational use).\nOperational guards MUST assert that qualification windows (qualification/inspection/recert intervals) hold **at `Γ_time`**:\n\n```\nValidityWindow(capability) holds at Γ_time\n```\n\n**WG‑4 - Cross‑context use of capability.**\nIf the JobSlice is in another Context:\n\n```\nBridge(source=capability.Context, target=JobSlice.Context)  AND  CL ≥ c\n```\n\nCL penalties affect **R** (confidence in deliverability), **not** Work scope; however, the guard SHOULD narrow the mapped Work scope to account for known mapping losses.\n\n**WG‑5 - Δ(WorkScope).**\nWhen widening Work scope (new operating ranges/platforms), the guard MUST require evidence at the new slices (measures + qualification windows). Refit (e.g., new units/parametrization) requires no new evidence.\n\n\n#### A.2.6:10.4 - Bridge‑aware guard macro (reusable)\n\nA reusable macro for Cross‑context guards:\n\n```\nGuard_XContext(Scope, TargetSlice) :=\n    exists Bridge b: (b.source = owner(Scope).Context AND b.target = TargetSlice.Context)\nAND CL(b) ≥ c\nAND Scope’ = translate(b, Scope)\nAND Scope’ covers TargetSlice\nAND (Apply CL penalty to R)\n```\n\n+* **Owner(Scope).** The carrier that declares the scope: an **Episteme** (for `U.ClaimScope`), a **Capability** (for `U.WorkScope`), or a **Publication carrier** (for `U.PublicationScope`).  \n* **Translate(b, Scope).** The partial mapping of a set of source slices to target slices induced by Bridge **b**. If a source slice is unmappable, it is dropped. The result is a set of target slices; **CL penalties apply to R only**.\n* **Penalty to R**: applied per trust calculus; F and G remain as declared.\n\n#### A.2.6:10.5 - Selector policy (Γ\\_time)\n\nAll ESG and Method–Work guards MUST spell out **`Γ_time`**:\n\n* **Point** (“as of 2026‑03‑31T00:00Z”).\n* **Window** (“rolling 180 days”).\n* **Policy** (“last lab calibration within 90 days”).\n\nImplicit “latest” is not allowed. If multiple contributors declare different policies, **serial intersection** computes the overlap (§8.2).\n\n",
        "conformance_checklist": "### A.2.6:11 - Conformance Checklist (USM)\n\n| ID                                    | Requirement                                                                                                                                                                                    |\n| ------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **CC‑USM‑1 (Declaration).**           | Epistemes **SHALL** declare **`U.ClaimScope`**, capabilities **SHALL** declare **`U.WorkScope`**. The abstract `U.Scope` MAY be used in architectural notes but not in guards.                 |\n| **CC‑USM‑2 (Set‑valued).**            | Scope characteristics are **set‑valued** over `U.ContextSlice`. Implementations MUST support **membership**, **intersection**, **SpanUnion**, **translate**, **widen/narrow**, **refit**.      |\n| **CC‑USM‑3 (Coverage guards).**       | ESG and Method–Work guards **MUST** use `Scope covers TargetSlice` predicates and **MUST** specify `Γ_time`. Guards fail closed.                                                               |\n| **CC‑USM‑4 (Serial intersection).**   | Along essential dependency paths, effective scope **SHALL** be the **intersection**; empty intersection invalidates the path.                                                                  |\n| **CC‑USM‑5 (SpanUnion constraints).** | Parallel scope **MAY** use **SpanUnion** only if independent support lines are **justified**; published union **MUST NOT** exceed supported slices.                                            |\n| **CC‑USM‑6 (Cross‑context).**            | Any Cross‑context use **MUST** declare a Bridge and **CL**; CL penalties apply to **R**, not **F/G**.                                                                                             |\n| **CC‑USM‑7 (No synonym drift).**      | In normative text and guards, **MUST** use **Claim scope (G)** or **Work scope**. Terms “applicability/envelope/generality/capability envelope/validity” **MUST NOT** name the characteristic. |\n| **CC‑USM‑8 (Determinism).**           | Membership evaluation **MUST** be deterministic given the slice tuple; no heuristic “close enough” matching.                                                                                   |\n| **CC‑USM‑9 (Edition triggers).**      | ΔG± (widen/narrow) constitutes a **content change**; refit does not.                                                                                                                          |\n| **CC‑USM‑10 (Publication discipline).** | Publication carriers that gate usage **SHALL** declare `U.PublicationScope`. For any publication **about** an episteme or capability, `PublicationScope` **MUST** be a subset of the underlying `U.ClaimScope`/`U.WorkScope`. Cross‑context publications **MUST** cite Bridge + CL; CL penalties **apply to R only** (scope membership unchanged). |\n| **CC‑USM‑11 (Separation).**           | Scope coverage checks and evidence freshness/assurance checks **MUST** be separate predicates (G vs R).                                                                                        |\n| **CC‑USM‑12 (Versioned Standards).**  | Scope predicates **SHALL** name Standards/interfaces by **version**; changes in notations with faithful mapping do not change **G** (may change CL for R).                                     |\n| **CC‑USM‑13 (Min‑info publication).** | Published scopes **SHOULD** enumerate slices or predicate blocks sufficient to re‑evaluate membership without external folklore.                                                               |\n| **CC‑USM‑14 (Slot discipline).**      | Where USM operations/guards are referenced in signatures or templates, they **SHALL** use explicit SlotSpecs and obey the A.6.5 lexical discipline (`…Slot` for SlotKinds; `…Ref` only for RefKinds/refs). |\n| **CC‑USM‑15 (Unknown handling).**     | Membership/coverage evaluation MUST be tri‑state under unknown inputs: unknown → {abstain (fail closed) \\| degrade via R}; unknown MUST NOT be coerced to `false/0`. |\n",
        "a.2.6:12___worked_examples": "### A.2.6:12 - Worked Examples\n\n> Each example declares the Context, the scope, the target slice, and shows the guard outcome. Where relevant, serial intersection, SpanUnion, and Bridge & CL are illustrated.\n\n#### A.2.6:12.1 - Research claim (controlled narrative → predicate)\n\n* **Context:** `MaterialsLab@2026`.\n* **Episteme:** claim “Adhesive X retains ≥85 % tensile strength on Al6061 for 2 h at 120–150 °C.”\n* **Claim scope (G):** `{substrate=Al6061, temp∈[120,150]°C, dwell≤2h, Γ_time = window(1y), rig=Calib‑v3}`.\n* **Target slice:** `{substrate=Al6061, temp=140 °C, dwell=90 min, Γ_time=2026‑04‑02, rig=Calib‑v3}`.\n* **Guard (EG‑1, EG‑2):** `covers(TargetSlice)` **true**; `U.Formality ≥ F4` **true** (predicates in spec).\n* **Outcome:** state transition allowed (freshness checked separately under R).\n\n#### A.2.6:12.2 - Cross‑context use of the research claim\n\n* **target Context:** `AssemblyFloor@EU‑PLANT‑B`.\n* **Bridge:** declared mapping of rigs and temp measurement correction; **CL=2** (loss: ±2 °C bias).\n* **Mapped Claim scope:** `translate(Bridge, G)` narrows temp to `[122,148]°C`.\n* **Guard (EG‑4):** Bridge present, `CL≥2` **true**; **R** is penalized per Φ(CL).\n* **Outcome:** allowed; **G** remains the mapped set; **R** lowered.\n\n#### A.2.6:12.3 - Capability: robotic weld Work scope\n\n* **Context:** `RobotCell‑Weld@2026`.\n* **Capability:** “Weld seam W at bead width 2.5 ± 0.3 mm, cycle ≤ 12 s.”\n* **Work scope:** `{humidity<60 %, current∈[35,45]A, wire=ER70S‑6, Γ_time=rolling(90d), controller=FW‑2.1}`.\n* **Job slice:** `{humidity=55 %, current=40A, wire=ER70S‑6, Γ_time=now, controller=FW‑2.1}`.\n* **Guards (WG‑1..3):** coverage **true**; measures satisfied; qualification window **true** (controller certified 60 d ago).\n* **Outcome:** capability admitted for this Work.\n\n#### A.2.6:12.4 - Serial intersection (API + dataset compatibility)\n\n* **Claim A (API Standard):** `v2.3` request schema with constraint “idempotent under retry”.\n* **Claim B (Dataset cohort):** “metrics valid for cohort K with schema `ds‑14`”.\n* **Composition:** service S depends on both A and B → **serial intersection** of Claim scopes: `{api=v2.3} ∩ {cohort=K, schema=ds‑14}`.\n* **Target slice:** `{api=v2.3, cohort=K, schema=ds‑14}` → membership **true**.\n* **Any drift (e.g., `ds‑15`)** empties the intersection ⇒ path inapplicable.\n\n#### A.2.6:12.5 - Parallel support (SpanUnion) in a safety case\n\n* **Line L1:** tests on **dry asphalt** support braking property; scope `S1={surface=dry, speed≤50 km/h}`.\n* **Line L2:** simulations for **wet asphalt**; scope `S2={surface=wet, speed≤40 km/h}`.\n* **Published scope:** `SpanUnion({S1,S2})` = `{(dry, ≤50), (wet, ≤40)}` with independence note (L1 empirical, L2 model‑validated).\n* **Guard:** allowed; union does **not** include `(wet, 45)` because not supported.\n\n#### A.2.6:12.6 - ML model deployment across Contexts\n\n* **Model claim:** “AUC ≥ 0.92 on cohort K, pipeline P, features F, `Γ_time=rolling(180d)`.”\n* **Claim scope:** `{cohort=K, pipeline=P, features=F, Γ_time=rolling(180d)}`.\n* **target Context:** product `On‑Device@v7`, features `F’` (subset), pipeline `P’`.\n* **Bridge:** declared mapping `F→F’`, `P→P’`, **CL=1** (notably lossy).\n* **Guard:** Bridge present; `translate(G)` covers a **strict subset**; CL=1 penalizes **R** strongly; ESG requires **F≥F5** (executable semantics) and **freshness < 90 d**.\n* **Outcome:** allowed only for the covered subset; adoption flagged with reduced **R**.\n\n",
        "a.2.6:13___playbooks_(informative)": "### A.2.6:13 - Playbooks (Informative)\n\n#### A.2.6:13.1 - Manager’s 6‑step adoption checklist\n\n1. **Name the TargetSlice.** Write the tuple (Context, versions, environment params, `Γ_time`).\n2. **Check scope coverage.** “Claim/Work scope covers TargetSlice?” If **no**, either **ΔG+** (publish wider scope with support) or **decline**.\n3. **Check rigor if gated.** If ESG requires it, ensure `U.Formality ≥ F_k`.\n4. **Check evidence freshness (R).** Validate windows/decay policies; do not conflate with coverage.\n5. **Bridge if Cross‑context.** Require declared Bridge, CL, and loss notes; accept **R** penalties.\n6. **Record the decision.** Keep the slice and guard outcomes with the StateAssertion (auditability).\n\n#### A.2.6:13.2 - Architect’s design rubric for scopes\n\n* **Prefer predicates over prose.** Name parameters, ranges, Standards by **version**, and `Γ_time`.\n* **Factor common conditions.** Use Refit to normalize units and factor shared predicates; do not widen by stealth.\n* **Partition support lines.** If you plan a **SpanUnion**, document independence up front.\n* **Keep scope thin & honest.** Publish what you can support; add slices as support appears (ΔG+).\n* **Design Bridges early.** When interop is planned, sketch mapping characteristics and **expected CL**; plan **R** penalties.\n\n#### A.2.6:13.3 - Review anti‑patterns & fixes\n\n| Anti‑pattern                                    | Why it’s wrong                   | Fix                                                        |\n| ----------------------------------------------- | -------------------------------- | ---------------------------------------------------------- |\n| “Latest” time by default                        | Non‑deterministic; violates §8.2 | Declare `Γ_time` explicitly (point/window/policy)          |\n| Using “domain” in guards                        | Not addressable; hides slices    | Replace with concrete `U.ContextSlice` tuples              |\n| Treating “more abstract wording” as wider scope | Abstraction ≠ applicability      | Keep **AT/D** separate; widen **G** only with explicit ΔG+ |\n| Publishing union without independence           | Overstates coverage              | Justify independence or publish serial intersection only   |\n| Cross‑context use without Bridge                   | Silent semantic drift            | Require Bridge + CL; apply **R** penalties                 |\n\n#### A.2.6:13.4 - Minimal DSL snippet for scope blocks (illustrative)\n\n```\nclaimScope:\n  Context: MaterialsLab@2026\n  Standards:\n    - rig: Calib-v3\n    - api: v2.3\n  env:\n    substrate: Al6061\n    temp: [120, 150] # °C\n    dwell: { max: \"2h\" }\n  gamma_time: { window_days: 365 }\n```\n\n*(Illustrative only; the specification does not mandate a particular syntax.)*\n\n#### A.2.6:13.5 - Profiles as Scope configurations (informative)\n**Idea.** A **Scope profile** is a **named, editioned configuration** that expands to a concrete `U.Scope` predicate block (over `U.ContextSlice`), used to avoid repetition and to keep declarations consistent across carriers.\n\n**Rules.**\n* **P1 (Expansion).** Profiles are macros: guards **MUST** expand them to explicit predicates before evaluating `Scope covers TargetSlice`.\n* **P2 (Edition).** Profiles are editioned; changing a profile’s predicates is a content change for any carrier that references it.\n* **P3 (No stealth widen).** A profile update MUST NOT implicitly widen a carrier’s published scope; ΔG+ must be explicit in that carrier.\n* **P4 (Bridge awareness).** If a profile implies Cross‑context use, it MUST name the Bridge and CL policy; CL penalties apply to **R** only.\n* **P5 (Locality).** Profiles are context‑local conveniences; they do not introduce new scope types.\n\n**Examples (illustrative).**  \n— An engineering context defines `Ops‑Lab‑v3` as a profile pinning Standards, environment selectors, and a rolling `Γ_time` policy; claims, capabilities, and publications may reference it as a shorthand.  \n— A publication stack defines `TechCard‑Lite@Σ` as a profile that **narrows** `U.PublicationScope` to slices where required pins are available.\n",
        "a.2.6:14___governance_hooks_&_audits": "### A.2.6:14 - Governance Hooks & Audits\n\n#### A.2.6:14.1 - Governance metadata (normative)\n\nContexts that adopt USM SHALL record, per scope‑aware decision:\n\n* **Owner.** Episteme (for Claim scope) or Capability (for Work scope).\n* **TargetSlice tuple.** Context, vocab/roles, versioned Standards, environment selectors, **`Γ_time`**.\n* **Guard outcomes.** Membership result, Bound measures (for Work scope), Freshness predicates (R).\n* **Bridge info (if any).** Mapping summary, **CL**, loss notes, applied R penalty.\n* **ΔG log.** Widen/narrow/refit; edition policy outcome.\n\n#### A.2.6:14.2 - USM compliance levels (informative)\n\n* **USM‑Ready.** Context declares adoption; editors trained; lexicon updated.\n* **USM‑Guarded.** All ESG/Method–Work guards use Claim/Work scope and `Γ_time`.\n* **USM‑Auditable.** Decision records include TargetSlice tuples and Bridge/CL details.\n* **USM‑Composed.** Serial intersection and SpanUnion are implemented in composition tooling.\n\n#### A.2.6:14.3 - Audit checklist (informative)\n\n* Does each guard **name** a concrete **TargetSlice**?\n* Is **membership** deterministically recomputable from published predicates?\n* Are **freshness** and **coverage** separate predicates?\n* For Cross‑context use: is there a **Bridge** with **CL** and loss notes?\n* For parallel support: is **independence** justified?\n\n#### A.2.6:14.4 - Risk controls (informative)\n\n* **Silent widening.** Require ΔG+ review; flag any scope increase without new support/Bridge.\n* **Opaque slices.** Disallow “domain” placeholders; enforce addressable selectors.\n* **Time drift.** Require `Γ_time` policies (rolling windows) for time‑sensitive scopes.\n\n",
        "a.2.6:15___cross‑pattern_coordination": "### A.2.6:15 - Cross‑Pattern Coordination\n\n#### A.2.6:15.1 - With F–G–R (C.2.2)\n\n* **G is Claim scope.** Use set algebra (∩ / SpanUnion).\n* **F** remains the expression rigor (C.2.3); **R** captures evidence freshness and CL penalties.\n* **Weakest‑link.** On dependency paths: **F\\_composite = min(F)**, **R\\_composite = min(R)**; **G** follows §7.2–§7.3 (set rules).\n\n#### A.2.6:15.2 - With Formality (C.2.3)\n\n* **No conflation.** Raising **F** does not change **G** unless scope predicates change.\n* **Guarding rigor.** ESG may use `U.Formality ≥ F_k` alongside scope coverage.\n\n#### A.2.6:15.3 - With Work & Run (A.15)\n\n* **Work scope** aligns with the **execution context** of `U.Work`.\n* Method–Work gates use **Work scope coverage** plus **measures** and **qualification windows**.\n\n#### A.2.6:15.4 - With Bridges & CL (Part B)\n\n* **CL only impacts R.** CL penalties reduce trust; they never rewrite **F** or **G**.\n* **Best practice.** Narrow mapped scopes where mapping losses are material.\n\n#### A.2.6:15.5 - With Capability governance (A.2.2)\n\n* Capabilities MUST declare **Work scope**, **measures**, **qualification windows**; gates MUST verify all three.\n* Capability refits that preserve the set (unit changes) are **Refit**, not Δ(WorkScope).\n\n",
        "a.2.6:16___extended_faq_(informative)": "### A.2.6:16 - Extended FAQ (informative)\n\n**Q1. Is “Claim scope” the same as “domain”?**\n**No.** “Domain” is descriptive and often fuzzy. **Claim scope** is **addressable**: it names concrete `U.ContextSlice` conditions and a **`Γ_time`** policy. Guards MUST reference slices, not generic “domains”.\n\n**Q2. How do we express partial coverage across different cohorts or platforms?**\nDeclare each supported serial scope (`S₁, S₂, …`) and publish **SpanUnion({Sᵢ})** with independence justification. Do **not** include unsupported slices.\n\n**Q3. Can raising F (formalizing) widen G?**\nOnly if the formalization **explicitly changes** the scope predicates (ΔG+). Formalization alone does not widen scope.\n\n**Q4. What is the difference between Work scope and SLOs?**\n**Work scope** is **where** the capability can deliver; **measures** within the guard are **what** it promises there (SLO targets). Both are required at use time (WG‑1..3).\n\n**Q5. Can we assign numeric coverage to G?**\nNot normatively. G is set‑valued. You MAY attach **informative** coverage metrics (e.g., proportions) to aid **R** assessment, but guards use set membership.\n\n**Q6. How do we handle “latest data” scopes?**\nYou don’t. Declare a **`Γ_time`** policy (e.g., rolling 90 days). “Latest” is forbidden to ensure reproducible evaluation.\n\n**Q7. How do we move a scope to another Context?**\nDeclare a **Bridge** with **CL** and loss notes; compute `translate(Bridge, Scope)`; apply CL penalty to **R**; consider narrowing the mapped set.\n\n**Q8. What about abstraction level or detail?**\nKeep **AT (AbstractionTier)** and **D (Detail/Resolution)** as orthogonal, optional annotations. They never substitute for **Claim/Work scope**.\n\n**Q9. Can a capability’s Work scope be broader than a predecessor claim’s Claim scope on a dependency path?**\nThey are on different carriers. In a serial dependency, the **effective** scope is the **intersection**; the broader one does not dominate.\n\n**Q10. When does an empty scope make sense?**\nIt indicates “not usable anywhere (here, now)”. Guards MUST fail. This is common during early drafting or after a refutation.\n\n",
        "a.2.6:17___annexes_(informative)": "### A.2.6:17 - Annexes (informative)\n\n#### A.2.6:17.1 - Legacy → USM dictionary\n\n| Legacy wording                      | USM term                                                 |\n| ----------------------------------- | -------------------------------------------------------- |\n| applicability (of a claim)          | **Claim scope (G)**                                      |\n| envelope (of a requirement/spec)    | **Claim scope**                                          |\n| generality G                        | **Claim scope (G)**                                      |\n| capability envelope                 | **Work scope**                                           |\n| validity (as a characteristic name) | **Claim scope** or **Work scope** (depending on carrier) |\n| operational applicability           | **Work scope**                                           |\n| publication/view applicability      | **Publication scope**                                    |\n\n*(Use legacy terms only in explanatory notes; not in guards or conformance text.)*\n\n#### A.2.6:17.2 - Minimal data model hints\n\n**ContextSlice tuple (suggested keys):**\n`Context`, `vocabId`, `rolesetId?`, `Standards: [{name, version}]`, `env: {param: range/value}`, `gamma_time: {point|window|policy}`.\n\n**Claim scope block:**\n`assumptions`, `cohorts`, `platforms/Standards`, `env`, `gamma_time`.\n\n**Work scope block:**\n`conditions (env/platform/Standards)`, `measures (targets & units)`, `validity_windows`, `gamma_time`.\n\n*(These are informative; the spec does not mandate a concrete serialization.)*\n\n#### A.2.6:18.3 - Pseudocode membership (illustrative)\n\n```python\ndef covers(scope: Set[Slice], target: Union[Slice, Set[Slice]]) -> bool:\n    if isinstance(target, Slice):\n        return target in scope\n    return target.issubset(scope)\n```\n",
        "rationale": "### A.2.6:17. 4 Rationale - F‑Cluster Unification for A.2.6 (F.17 / F.18)\n\n> **Intent.** This annex applies the **F‑cluster method** to triangulate **USM** terms against a diverse set of post‑2015 sources and communities (“Contexts”), and then fixes the **Unified Tech** and **Plain** names used in A.2.6. Results are ready for downstream lexicon entries (Part E) and guard templates (ESG / Method–Work).\n\n#### A.2.6:17.4.1 - F.17 Unified Term Survey (UTS) — Method & Scope\n\n**Contexts surveyed (SoTA, diverse):**\n\n1. **ISO/IEC/IEEE 42010** (architecture description)\n2. **OMG Essence** (Kernel: Alphas, Work Products, States)\n3. **NIST AI RMF 1.0/1.1** (trustworthy AI)\n4. **ASME V\\&V 40–2018 / FDA 2021–2023** (model credibility)\n5. **W3C SHACL (2017+) / SHACL‑AF** (data constraints)\n6. **OWL 2 / ontology engineering (2012+, current practice)**\n7. **IETF BCP 14 (RFC 2119/8174)** (normative keywords & guard style)\n8. **DO‑178C + DO‑333** (avionics, formal methods supplement)\n9. **ISO 26262:2018/2025** (automotive functional safety)\n10. **IEC 61508 (2010+, current revisions)** (basic safety)\n11. **ACM Artifact Review & Badging v1.1** (reproducibility signals)\n12. **MLOps/Cloud SLO practice (SRE / platform)** (operational guardrails)\n\n**Survey focus (terms we align):** `U.ContextSlice`, generic **Scope** and set algebra, **Claim scope (G)**, **Work scope**, **Bridge & CL**, **Γ\\_time**, **widen/narrow/refit/translate**, **SpanUnion / serial intersection**, separation from **F** and **R**, avoidance of overloaded **validity/operation** terms.\n\n\n#### A.2.6:17.4.2 - UTS Table (F.17) — Cross‑context term mapping\n\n|  # | Context / Source      | Local label(s) (native)                                                     | Closest USM concept                                                                      | Notes on fit & deltas                                                                                                                                                                         |\n| -: | ------------------ | --------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n|  1 | ISO/IEC/IEEE 42010 | *Architecture context; environment; stakeholder concerns; viewpoints/views* | **ContextSlice** (addressable slice); **Scope** as view‑specific applicability           | 42010 is about **views in context**; it has no first‑class set‑valued scope char but aligns with “evaluate **in a concrete context**” → USM uses explicit **slice tuples**.                   |\n|  2 | OMG Essence        | *Alpha State; Work Product State; Level of Detail (LoD)*                    | **Work scope** (guards), **Detail (D)** (LoD), **ESG/RSG**                               | Essence separates **status** (states) and **work evidence**; LoD is **detail**, not scope. USM treats **scope** as guardable membership over slices; states/LoD map to ESG & **D**, not to G. |\n|  3 | NIST AI RMF        | *Context of use; validity, reliability, robustness; monitoring*             | **Claim scope (G)**; **R** freshness/monitoring                                          | “Context of use” = **where a claim/model holds** → maps to **G**. “Validity” is part of **R** vocabulary; we **avoid** naming the characteristic “validity” to prevent LA confusion.          |\n|  4 | ASME V\\&V 40 / FDA | *Context of use; credibility factors; verification/validation*              | **Claim scope (G)**; **R** (credibility)                                                 | Direct fit for G via “context of use”. Credibility/evidence freshness contribute to **R**, not to G; USM keeps them separate in guards.                                                       |\n|  5 | W3C SHACL          | *Shapes; targets (sh\\:targetClass, sh\\:target); constraints*                | **Claim scope** (targets define **where** constraints apply); **F≥4** (predicate form)   | SHACL “target” ≈ **membership predicate** on a dataset context; perfect analogue of **Claim scope** on data slices; constraint language supports **F4**‑style predicates.                     |\n|  6 | OWL 2 practice     | *Class extension; domain/range; imports/version IRI*                        | **Claim scope** as class extension over an ontology context                              | Class extension is set‑semantics by design; **G** naturally maps to extension over a versioned ontology (part of **ContextSlice**).                                                           |\n|  7 | IETF BCP 14        | *MUST/SHALL/SHOULD; requirements language*                                  | **Guard style** (observable predicates)                                                  | BCP 14 doesn’t define scope but dictates how guards are worded; USM aligns by requiring **observable, deterministic** membership checks.                                                      |\n|  8 | DO‑178C / DO‑333   | *Operational conditions; DAL; formal method objectives; TQL*                | **Work scope** (operating conditions); **F** (proof‑grade), **R** (assurance objectives) | Operational applicability = **Work scope**; formal method objectives lift **F**; Tool qualification impacts **TA/R**, not G.                                                                  |\n|  9 | ISO 26262          | *Operational situation & operating modes; ASIL; OSED*                       | **Work scope** (operating modes/situations)                                              | OSED/operating modes define **where capability can be exercised** → **Work scope**. Assurance level (ASIL) relates to **R**, not G.                                                           |\n| 10 | IEC 61508          | *SIL; demand mode; proof test interval*                                     | **Work scope** (demand vs continuous mode) + **R freshness**                             | Mode concepts influence **where/how** a function can be claimed → **Work scope**; proof test interval sits in **R** (freshness/decay).                                                        |\n| 11 | ACM Artifacts      | *Available/Evaluated/Reusable; Reproduced/Replicated*                       | **R** signals; **ContextSlice** (reproduction environment)                               | Badges encode **evidence availability/strength**; the declared environment maps to a **slice**; scope of claim is often implicit → USM makes it explicit.                                     |\n| 12 | SRE / Cloud SLO    | *SLOs; error budgets; regions/tiers; rollout windows*                       | **Work scope** (regions/tiers/windows) + **measures**; **Γ\\_time** policies              | SLOs attach **measures** within a **Work scope** (region/tier/time window); perfect fit for USM Method–Work guards (WG‑1..3).                                                                 |\n\n**Summary.** Across all Contexts, two stable notions recur: (1) **evaluate in a concrete context** (→ `U.ContextSlice`), and (2) **declare where something holds/is deliverable** (→ set‑valued **Scope**). “Context of use,” “operating modes,” “targets,” “class extension,” and “OSED” are all Context‑flavored presentations of **Claim scope** or **Work scope**. Terms like *validity* and *operation* are semantically close but collide with **LA** and FPF’s **Work/Run** lexicon; we therefore **do not** adopt them as characteristic names.\n\n\n#### A.2.6:17.4.3 - F.18 Term Selection — Unified Tech & Plain names\n\n##### A.2.6:17.4.3.1 - Selected names (normative)\n\n| Concept in A.2.6                | **Unified Tech** (lexicon)                      | **Unified Plain** (manager‑friendly) | Allowed short form   | Deprecated / avoid                                                    |\n| ------------------------------- | ----------------------------------------------- | ------------------------------------ | -------------------- | --------------------------------------------------------------------- |\n| Addressable evaluation context  | **`U.ContextSlice`**                            | **Context slice**                    | *Slice* (when local) | “domain” (as guard input), “latest” time                              |\n| Abstract mechanism (set‑valued) | **`U.Scope`**                                   | **Scope**                            | —                    | “applicability”, “envelope”, “validity” (as characteristic names)     |\n| Episteme applicability          | **`U.ClaimScope`** (*nick **G**)               | **Claim scope**                      | **G**                | “generality”, “applicability/envelope (of claim)”                     |\n| Capability applicability        | **`U.WorkScope`**                               | **Work scope**                       | “capability envelope”, “operational applicability”, “operation scope” |\n| Time selector                   | **`Γ_time`**                                    | **Time selector**                    | —                    | implicit “latest”                                                     |\n| Cross‑context mapping              | **Bridge + CL**                                 | **Bridge + congruence level**        | **CL**               | silent reuse across Contexts                                             |\n| Parallel coverage               | **SpanUnion**                                   | **Union of supported areas**         | —                    | unqualified “union” without independence                              |\n| Serial dependency               | **Intersection**                                | **Intersection of scopes**           | —                    | ordinal “more/less general” language                                  |\n| Scope edits                     | **ΔG+ (widen), ΔG− (narrow), Refit, Translate** | **Widen, narrow, refit, translate**  | —                    | stealth widening (“it’s obvious”)                                     |\n| Optional didactics              | **`U.Detail (D)`, `U.AbstractionTier (AT)`**    | **Detail / abstraction tier**        | **D / AT**           | using AT/D as G substitutes                                           |\n\n**Why these names (decision grounds):**\n\n* **“Scope” wins over “envelope/applicability/validity”.** It is short, **self‑documenting**, and already idiomatic in SRE/SW, while “validity” clashes with **Validation Assurance (LA)** and “envelope” suggests geometry, not **membership**.\n* **“Claim scope” vs “Work scope”.** Two‑word compounds meet the FPF clarity rule: the first token reveals the **carrier** (Claim vs Work/Capability), the second the **mechanism** (scope).\n* **Keep **G**.** The F–G–R triple is canonical; we retain **G** as nickname for **Claim scope**.\n* **“Context slice”** is the only term that makes the evaluation target **addressable** (Context, versions, params, **Γ\\_time**).\n* **“Operation/operating/validity” avoided.** They are **overloaded** in existing FPF lanes (Work/Run, LA) and create policy ambiguities in guards.\n\n##### A.2.6:17.4.3.2 - Phrasebook (for editors, normative)\n\n* Use **“Claim scope (G) covers TargetSlice”** and **“Work scope covers JobSlice”** in guards.\n* Always spell **`Γ_time`**; never say “latest”.\n* To compose, say: **“intersection along dependency paths; SpanUnion across independent support lines.”**\n* For Cross‑context use, say: **“via Bridge; CL penalties apply to R (trust), not to F/G (content/scope).”**\n* When widening/narrowing, write **“ΔG+ / ΔG−”** and log the support change; use **“Refit”** for unit/param normalization.\n\n##### A.2.6:17.4.3.3 - Rosetta summary (informative, for rationale box)\n\n| local context phrase                          | Use in USM wording                                          |\n| ------------------------------------------ | ----------------------------------------------------------- |\n| “Context of use” (NIST, ASME/FDA)          | **Claim scope (G)** on explicit **Context slice**           |\n| “Operating modes/situations” (ISO 26262)   | **Work scope** with measures & qualification windows             |\n| “Target (class/shape)” (SHACL/OWL)         | **Claim scope predicates** (membership)                     |\n| “Architecture view context” (42010)        | **Context slice** + **Scope** checks inside the view        |\n| “Capability envelope” (legacy safety docs) | **Work scope**                                              |\n| “Domain” (informal)                        | **Context slice** elements; not acceptable as a guard input |\n\n\n**Outcome.** The UTS shows strong convergence across SoTA Contexts on **addressable context** and **set‑valued applicability**. F.18 therefore fixes: **Context slice**, **Scope**, **Claim scope (G)**, **Work scope**, **Publication scope** with the algebra and guard clauses mandated in A.2.6. This closes synonym drift while remaining readable for engineering managers and precise for assurance tooling.\n",
        "a.2.6:end": "### A.2.6:End\n"
      },
      "content": "### A.2.6:End\n",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.2.7",
      "title": "U.RoleAlgebra: In‑Context Role Relations",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.2.7 - U.RoleAlgebra: In‑Context Role Relations\n\n> **Type:** Definitional (D)\n> **Status:** Stable\n> **Normativity:** Normative\n\n*with `requiredRoles` substitution, SoD (`⊥`), and bundle (`⊗`) hooks*\n\n**Builds on:** A.1.1 **`U.BoundedContext`**, A.2 **Role Taxonomy**.  \n**Coordinates with:** A.2.1 **`U.RoleAssignment`**, A.15 **Role–Method–Work Alignment**.\n",
        "problem": "### A.2.7:1 - Problem frame\n\n**Intent.** Provide a tiny, explicit algebra over **role types** inside one Context so engines can (a) substitute specialisations, (b) enforce separation of duties, and (c) treat frequent conjunctions as named bundles—without encoding taxonomy in RoleAssignments.\n\n**Scope.**\n\n* Defines three in‑Context relations/operators: specialization `≤`, incompatibility `⊥`, and bundle `⊗`.\n* States substitution semantics used when checking `MethodStep.requiredRoles`.\n* States overlap‑prohibition semantics used to validate RoleAssignments.\n\n**Non‑goals.**\n\n* No cross‑Context equivalence by label; cross‑Context reuse is **Bridge‑only** (F.9).\n* No mereology; role algebra does not describe part‑of or structure membership.\n* No capability model; intrinsic ability evidence lives in `U.Capability` and related patterns.\n\n**Disambiguation.** Do not confuse role specialization `≤` with kind subsumption `⊑` (Kind‑CAL).  \n`≤` is **requirement substitution** between role *types* in one Context; `⊑` is **typing** between kinds.\n",
        "solution": "### A.2.7:2 - Solution (the three operators)\n\nRole algebra relates **role types** inside **one** `U.BoundedContext`. It is **not** mereology.\n\n#### A.2.7:2.1 - Specialization (narrower assignment)\n\n* **Notation:** `RoleS ≤ RoleG`\n* **Semantics (normative):** For any `U.RoleAssignment` with `role = RoleS` in this Context, the holder **also satisfies** requirements for `RoleG` in this Context.\n* **Use:** Stable expertise ladders; privilege inheritance; “junior→senior” substitution.\n* **CC‑ALG‑1.** Engines that check `requiredRoles` **MUST** treat `≤` as admissible substitution.\n\n#### A.2.7:2.2 - Incompatibility (conceptual role incompatibility)\n\n* **Notation:** `RoleA ⊥ RoleB`\n* **Semantics (normative):** Overlapping `window`s on the same holder for assignments to both roles in this Context are **ill‑formed**.\n* **Use:** Separation‑of‑duties (SoD); independence constraints (e.g., performer vs reviewer).\n* **CC‑ALG‑2.** Validation **MUST** reject overlapping assignments that violate `⊥`.\n\n#### A.2.7:2.3 - Bundles (conjunctive requirement)\n\n* **Notation:** `RoleC := Role1 ⊗ Role2 ⊗ …`\n* **Semantics:** `RoleC` is **satisfied iff** the holder has **simultaneous** valid assignments for each conjunct role (in this Context).\n* **Use:** Frequent conjunctions (e.g., “On‑call Incident Commander” = *Engineer ⊗ Communicator ⊗ Decision‑Maker*).\n* **CC‑ALG‑3.** Engines that check `requires: [RoleC]` **MUST** expand to conjunctive checks.\n\n+> **Didactic guardrails.**\n+> Use `≤` for lasting ladders, `⊥` for critical safety/governance, `⊗` for frequent conjunctions. Prefer listing multiple `requiredRoles` on Method steps to avoid ornate lattices.\n\n+### A.2.7:3 - Relations\n\n**Builds on / depends on**\n\n* **A.1.1 `U.BoundedContext`** — the locality boundary within which the algebra holds.\n* **A.2 Role Taxonomy** — role families and context‑local naming.\n\n**Used by**\n\n* **A.2.1 `U.RoleAssignment`** — avoids chained assignments; uses `≤/⊥/⊗` for checking and validation.\n* **A.15 Role–Method–Work Alignment** — expands `requiredRoles` and enforces SoD requirements.\n* **D.2** ethics/governance patterns — encode SoD and independence via `⊥`.\n",
        "a.2.7:end": "### A.2.7:End\n"
      },
      "content": "### A.2.7:End\n",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.2.8",
      "title": "`U.Commitment` (Deontic Commitment Object)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.2.8 - `U.Commitment` (Deontic Commitment Object)\n\n> **Type:** Definitional (D)\n> **Status:** Stable\n> **Normativity:** Normative (unless explicitly marked informative)\n> **Placement:** Part A → **A.2 Roles & Agency Kernel**\n> **Refines:** A.2 (Role Taxonomy)\n> **Builds on:** E.8 (authoring template), A.2.1 (RoleAssignment), A.2.6 (Scope & `Γ_time`), A.7 (Object≠Description≠Carrier), A.2.3 (`U.ServiceClause` as promise), A.15.1 (`U.Work`)\n> **Purpose (one line):** Provide a minimal, reusable kernel object for deontic commitments (who is accountable, under what modality, in what scope/window, with respect to which referents, with which adjudication hooks), **explicitly separating the commitment object from its utterance descriptions** (A.7), so deontics stop “living” in naming patterns and become stable across A.6 and later governance patterns.\n",
        "a.2.8:0___terminology:_“binding”_is_overloaded_(normative)": "### A.2.8:0 - Terminology: “binding” is overloaded (normative)\n\nThe word family “bind/binding” is used throughout FPF for **technical binding** (name/slot binding, parameter binding, etc.). This pattern introduces a narrower lexical constraint: **do not use “binding” as the Tech-level term for deontic governance relations.** Use **commitment** and model it as `U.Commitment`. If source material uses “binding contract/promise” rhetoric, rewrite it into explicit `U.Commitment` fields (`subject`, `modality`, `scope/window`, `referents`, and—when auditable—`adjudication`).\n\nThis pattern therefore treats **commitment** as the canonical Tech-level term and uses `U.Commitment` as the kernel object.\n\nIf your source material uses “binding” rhetoric (e.g., “binding contract”, “legally binding promise”), treat it as Plain-level phrasing that **MUST** be rewritten into explicit `U.Commitment` fields (`subject`, `modality`, `scope/window`, `referents`, and—when auditable—`adjudication`).\n",
        "problem": "### A.2.9:2 — Problem\n\nHow can FPF represent communicative enactments so that:\n\n1. **Agency is explicit:** a concrete accountable subject performs the act (role/role‑enactor), not a document/spec/interface.\n2. **The act is locatable in time:** the act has an explicit Window (and thus freshness can be evaluated).\n3. **The act is locatable in meaning:** the act is recognized inside a declared **bounded context** (the `U.Work` judgement context), not via `U.ClaimScope` (which expresses applicability of claims/commitments, not the judgement context for Work occurrences).\n4. **The act is auditable:** it has at least one declared utterance description and/or evidence carrier when used for gating or governance.\n5. **Institutional effects are linkable:** the act can institute (or update/revoke) commitments, role assignments, statuses, etc., by reference.\n6. **Ambiguity is handled pragmatically:** the model supports multi‑function / multi‑party communication without requiring full linguistic pragmatics.\n",
        "forces": "### A.2.9:3 — Forces\n\n| Force                  | Tension                                                                                                                 |\n| ---------------------- | ----------------------------------------------------------------------------------------------------------------------- |\n| Minimality             | Needs to be light enough for routine modeling and linting; not a full pragmatics or legal-contract system.              |\n| Auditability           | If used as a gate, it must be evidence-backed; but not all communicative acts are equally observable or retainable.     |\n| Context locality       | Meaning and “institutional force” are context-local; cross-context reuse must remain explicit (Bridge-only discipline). |\n| Multi-party reality    | Many real boundaries are multiparty (protocols, organizations); dyadic “speaker-hearer” is too narrow.                  |\n| Multi-function reality | One utterance can carry multiple recognizable functions; “one act = one force” is often false.                          |\n| Separation discipline  | Must preserve A.7 splits: **act object** ≠ **utterance description** ≠ **carrier/traces**.                              |\n",
        "solution": "### A.2.9:4 — Solution\n\n`U.SpeechAct` is a **kernel Work object**: a recorded communicative enactment performed by an accountable role‑enactor within a bounded context, optionally addressed to others, that is **recognized** (in that context) as updating an information and/or governance state. The act is **not** the utterance text; it points to utterance descriptions and evidence carriers.\n\n#### A.2.9:4.1 — Normative definition\n\nA **`U.SpeechAct`** is a **`U.Work`** occurrence whose primary (intended) effect is **communicative**: it places an utterance into a context in a way that is recognized by that context’s institutional semantics (policies, procedures, protocol rules) as potentially:\n\n* asserting/informing,\n* requesting/directing,\n* promising/committing (as an instituting act),\n* declaring/authorizing/revoking (status-changing acts),\n* notifying (event announcement relevant for downstream work).\n\nPer A.7, `U.SpeechAct` is an **object/event**; its **utterance descriptions** are descriptions (epistemes/spec clauses/messages‑as‑content), and its **carriers** are artifacts/traces that support observation and audit. *(Note: “Surface” is reserved for MVPK publication/interoperability surfaces; do not use it here.)*\n\nWhether a given `actType` institutes commitments/permissions/status changes is **entirely context‑policy dependent**. Absent an explicit policy, treat a `U.SpeechAct` as a communicative Work occurrence with observable provenance only; do not infer deontic bindings from the act by default.\n\n#### A.2.9:4.2 — Minimal structure (normative)\n\nA conforming `U.SpeechAct` **SHALL** be representable by the following minimal record (field names are illustrative; the constraints are normative):\n\n```\nU.SpeechAct <: U.Work\n\nInvariant: U.Work.kind = Communicative\n\nU.SpeechAct ::=\n  U.Work\n  & {\n      actTypes: set<SpeechActTypeRef>,               // ≥1 act types (supports multi-function)\n      addressedTo: optional<set<AddresseeRef>>,      // optional: who is addressed / audience\n      utteranceRefs: optional<set<DescriptionRef>>,  // where the utterance content is stated/recorded (A.7: Description)\n      carrierRefs: optional<set<CarrierRef>>,        // evidence carriers/traces (A.7: Carrier; use A.10 when evidentiary)\n      institutes: optional<InstitutedEffects>,       // references to objects/claims instituted/updated by this act\n      notes: optional<InformativeText>               // explicitly informative\n    }\n\nDescriptionRef ::=\n  ClaimIdRef | EpistemeRef\n  // Pointer to an utterance description (e.g., spec clause claim ID, a policy episteme, a message-content episteme).\n\nSpeechActTypeRef ::=\n  ContextLocalTokenRef\n  // Must be defined/recognized in the Work’s judgement context (bounded context).\n\nAddresseeRef ::=\n  PartyRef | RoleRef | RoleAssignmentRef\n\nInstitutedEffects ::=\n  {\n    commitments: optional<set<CommitmentIdRef>>,\n    roleAssignments: optional<set<RoleAssignmentRef>>,\n    statusClaims: optional<set<ClaimIdRef>>,         // e.g., “StandardStatus=Approved” if modeled as claims\n    other: optional<set<ObjectIdRef>>\n  }\n```\n\n**Normative constraints:**\n\n* **(SA‑C0) Work conformance applies.** Because `U.SpeechAct <: U.Work`, a speech‑act record **MUST** satisfy `U.Work` conformance (A.15.1), including the required anchors (`isExecutionOf`, `performedBy`, `executedWithin`, `window`, and state‑plane / judgement‑context anchoring). A speech act **MUST** have at least one `affected` referent (the thing it is *about/updates*), even if it is purely governance‑state.\n* **(SA‑C1) PerformedBy must be an accountable actor.** `performedBy` **MUST** resolve to a `RoleAssignmentRef` whose holder is an accountable system/party in the named scope. It **MUST NOT** be a spec/interface/document as an episteme.\n* **(SA‑C2) ActTypes are required and context-local.** `actTypes` **MUST** contain at least one `SpeechActTypeRef` recognized in the Work’s judgement context (local meaning). Free‑text verbs are nonconformant unless registered as a context token.\n* **(SA‑C3) Time honesty.** `window` **MUST** be explicit (or inherited from the parent `U.Work` record) so freshness rules can be evaluated.\n* **(SA‑C4) If used for gating/audit, it must be observable.** If a speech act is used as a checklist criterion, guard condition, or provenance hook for a `U.Commitment`, the model **SHALL** include at least one observable handle: `utteranceRefs` and/or `carrierRefs`. When the act is used as evidence, at least one carrier reference **SHOULD** be SCR/RSCR‑resolvable per A.10.\n* **(SA‑C5) Institutional effects are references, not paraphrases.** When the act is intended to institute/update commitments, role assignments, or statuses, `institutes.*` **SHOULD** reference the corresponding object IDs/claim IDs rather than restating content.\n* **(SA‑C6) Cross-context use is Bridge-only.** If a `SpeechActRef` is used for checking/gating/provenance in a **different bounded context** than the act’s judgement context, the referencing object **MUST** satisfy the spec’s cross-context discipline by citing an explicit Bridge/policy that licenses the interpretation (and surfacing congruence vs loss where applicable), rather than assuming equivalence by label.\n\n#### A.2.9:4.3 — `SpeechActRef` discipline (normative)\n\nA **`SpeechActRef`** is a reference to `U.SpeechAct.id`.\n\n* If another object (e.g., `U.Commitment.source.speechActRef`) cites a `SpeechActRef`, the referenced `U.SpeechAct` **MUST** satisfy **SA‑C0…SA‑C4** (and SA‑C6 when used cross‑context).\n* A `SpeechActRef` **MUST NOT** be replaced by an `EpistemeRef` (“see the document”) when provenance is needed; the episteme is an utterance description, not the act.\n* If a system cannot record a full `U.SpeechAct`, it may record a **stub** that still satisfies **SA‑C0…SA‑C4** (minimal `actTypes`, performer, judgement context, window, `affected`, plus at least one observable handle). When a required `U.Work` anchor is unknown, the stub **MUST** use an explicit placeholder (e.g., an “AdHocCommunication” MethodDescription) rather than omitting the field.\n\n#### A.2.9:4.4 — Separation rules with `U.Commitment` and `U.ServiceClause` (normative)\n\n1. **Speech act is not the deontic binding.**\n   A speech act may **institute** a `U.Commitment`, but the deontic relation itself is the `U.Commitment` object (A.2.8). Do not encode obligations/permissions inside `U.SpeechAct` as prose; instead, create/point to `U.Commitment` IDs in `institutes.commitments`.\n\n2. **Speech act is not the service promise clause.**\n   `U.ServiceClause` / service clauses are promise content; a speech act may be the act of offering/issuing that promise, but the promise content lives in the service/service clause objects and is referenced from the resulting commitments.\n\n3. **Speech act is not the carrier.**\n   A “signed approval PDF”, “ticket record”, “Slack message”, or “API call log” is a carrier (and may carry an episteme as utterance content); the speech act is the Work occurrence that produced/issued it.\n\n4. **Publishing a spec is not a commitment by default.**\n   **Default interpretation rule (normative).** A conformant model/interpreter **MUST NOT** infer `U.Commitment` objects solely from `Publish`/`Approve` speech acts. Publication MAY institute publication/status claims (e.g., “Published”, “Approved”, “Deprecated”), but any obligations/permissions on implementers/operators/providers **MUST** be modeled explicitly as `U.Commitment` objects (A.2.8). If a Context defines a policy that maps publication acts to commitment-instituting effects (e.g., a named `SpecPublicationPolicy@Context`), that policy **MUST** be named and cited where the implication is used.\n\n#### A.2.9:4.5 — Multi-function and multi-party support (normative)\n\n* **Multi-function:** `actTypes` is a **set**. If one utterance performs multiple recognizable acts (e.g., “approve + instruct + warn”), the model may either:\n\n   * represent one `U.SpeechAct` with multiple `actTypes` entries, or\n   * represent multiple `U.SpeechAct` records that share the same `carrierRefs/utteranceRefs`.\n   In either case, institutional effects must remain referenceable (SA‑C5).\n\n* **Multi-party:** `addressedTo` is a set and may include roles/parties/assignments. If addressees matter for validity (e.g., “approval by CAB chair to deployment bot”), they should be explicit.\n",
        "archetypal_grounding": "### A.2.9:5 — Archetypal Grounding (Tell–Show–Show)\n\n#### A.2.9:5.1 — Tell (universal rule)\n\nWhen governance or gating depends on “someone said/did X”, model **that saying/doing** as a `U.SpeechAct` (a Work occurrence), and keep the utterance text and carriers separate. If the saying/doing creates obligations, model those obligations as `U.Commitment` objects instituted by the speech act.\n\n#### A.2.9:5.2 — Show #1 (system archetype: change-control approval gates a deployment)\n\n**Situation (messy prose):**\n“Change is approved, so the pipeline may deploy.”\n\n**Conformant modeling sketch:**\n\n* `U.SpeechAct SA-Approve-4711`\n\n  * `actTypes = {SpeechActTypeRef(Approval@ChangeControl)}`\n  * `performedBy = RoleAssignmentRef(CAB_Chair as ApproverRole@ChangeControl)`\n  * `isExecutionOf = MethodDescriptionRef(ChangeApprovalProcedure_v3)`\n  * `executedWithin = ChangeControlBoardSystem`\n  * `window = [t,t]`\n  * `affected = {ChangeRequestId(4711), WorkRef(Deploy-4711)}`\n  * `utteranceRefs = {EpistemeRef(ChangeTicket#4711)}`\n  * `carrierRefs = {CarrierRef(TicketSystemRecord#4711)}`\n  * `institutes.commitments = {CommitmentIdRef(D-Deploy-Authorized)}`\n\n* `U.Commitment D-Deploy-Authorized`\n\n  * `subject = RoleAssignmentRef(OpsBot#DeployerRole:CD_Pipeline_v7)`\n  * `modality = MAY` (permission to enact)\n  * `referents = {A-Gate-Deploy-4711}`\n  * `source.speechActRef = SA-Approve-4711`\n\n* Gate predicate `A-Gate-Deploy-4711` may include:\n  `exists SpeechAct(type=Approval, affected includes ChangeRequestId(4711), performedBy role=ApproverRole, within 90d)`.\n\nThis preserves:\n\n* act vs text vs carrier,\n* explicit performer,\n* time window for freshness,\n* explicit provenance from commitment back to the instituting act.\n\n#### A.2.9:5.3 — Show #2 (episteme archetype: publishing a spec edition without making the spec an agent)\n\n**Situation (anti-pattern):**\n“The interface spec declares MUST/SHALL requirements.”\n\n**Conformant modeling sketch:**\n\n* `U.SpeechAct SA-Publish-API-v12`\n\n  * `actTypes = {SpeechActTypeRef(Publish@APISpecContext), SpeechActTypeRef(DeclareNorms@APISpecContext)}`\n  * `performedBy = RoleAssignmentRef(StandardsEditor as PublisherRole@APISpecContext)`\n  * `isExecutionOf = MethodDescriptionRef(SpecReleaseProcedure_v12)`\n  * `executedWithin = SpecPublicationSystem`\n  * `window = [t,t]`\n  * `affected = {EpistemeRef(APISpec_v12)}`\n  * `utteranceRefs = {EpistemeRef(APISpec_v12)}`\n  * `carrierRefs = {CarrierRef(GitTag:v12), CarrierRef(SignedReleaseArtifact:v12)}`\n  * `institutes.statusClaims = {ClaimIdRef(D-StdStatus-APISpec_v12-Published)}` (if modeled)\n\nNorms live in the **published utterance surfaces** (spec clauses as routed claims), but the **act of publication** is a speech act performed by an accountable role. This avoids “the spec promises/commits” category errors while preserving auditability.\n",
        "bias_annotation": "### A.2.9:6 — Bias-Annotation\n\nLenses tested: **Gov**, **Arch**, **Onto/Epist**, **Prag**, **Did**. Scope: **Kernel universal** for speech-act usage that matters for governance, eligibility, gating, provenance, and protocol boundaries.\n\n* **Gov bias:** favors explicit accountable performers and auditable records; increases clarity but adds modeling overhead.\n* **Arch bias:** optimizes evolvability by keeping institutional effects referenceable rather than embedded in prose.\n* **Onto/Epist bias:** enforces act≠utterance≠carrier and prevents episteme-as-agent metaphors.\n* **Prag bias:** models only what is needed for decisions/audit (not full intention/sincerity/perlocutionary psychology).\n* **Did bias:** keeps the record minimal and queryable for state checklists and boundary reviews.\n",
        "conformance_checklist": "### A.2.9:7 — Conformance Checklist (normative)\n\n1. **CC‑A.2.9‑1 (Accountable performer).** A normative `U.SpeechAct` record **MUST** identify `performedBy` as an accountable `RoleAssignmentRef` and **MUST NOT** use an episteme (spec/interface/document) as performer.\n2. **CC‑A.2.9‑2 (ActTypes declared).** A `U.SpeechAct` record **MUST** include at least one `SpeechActTypeRef` recognized in its judgement context.\n3. **CC‑A.2.9‑3 (Window explicit).** A `U.SpeechAct` record **MUST** have an explicit `window` (or inherit a window from its parent work record) so freshness and gating can be evaluated.\n4. **CC‑A.2.9‑4 (Observable when used for gating/provenance).** If a speech act is cited by a checklist/guard or by `U.Commitment.source.speechActRef`, it **SHALL** have at least one `utteranceRef` or `carrierRef` that supports observation/audit in the given context; evidence‑critical uses **SHOULD** anchor at least one carrier via SCR/RSCR per A.10.\n5. **CC‑A.2.9‑5 (Effects by reference).** If the act is intended to institute/update commitments/roles/statuses, those effects **SHOULD** be referenced in `institutes.*` by stable IDs.\n6. **CC‑A.2.9‑6 (Bridge-only cross-context use).** If a `SpeechActRef` is interpreted for gating/provenance in a different bounded context than the act’s judgement context, the referencing object **MUST** cite the Bridge/policy that licenses that cross-context interpretation (no “same label implies same force”).\n\n",
        "anti_patterns": "### A.2.9:8 — Common Anti-Patterns and How to Avoid Them\n\n| Anti-pattern                                                              | Why it fails                         | Repair                                                                                   |\n| ------------------------------------------------------------------------- | ------------------------------------ | ---------------------------------------------------------------------------------------- |\n| **Episteme-as-actor** (“the spec approves/declares”)                      | assigns agency to descriptions       | represent the publishing/approving act as `U.SpeechAct(performedBy=RoleAssignment)`      |\n| **Carrier-as-act** (“the signed PDF is the approval”)                     | conflates carrier with act           | model `U.SpeechAct` and point to PDF as `carrier`/`utteranceSurface`                     |\n| **Free-text type** (“type=‘approved-ish’”)                                | not lintable; drifts across faces    | register `SpeechActTypeRef` in the context and use it                                    |\n| **Act carries obligations** (obligations embedded as prose in speech act) | collapses act and deontic binding    | model obligations as `U.Commitment` objects instituted by the act                        |\n| **Gating without window**                                                 | cannot evaluate freshness            | add explicit `window` and reference it in the guard/checklist                            |\n| **Hidden multi-act** (one event silently creates multiple commitments)    | loses traceability; creates disputes | represent multi-function via `actTypes` set or multiple speech acts sharing the same carrier |\n",
        "consequences": "### A.2.9:9 — Consequences\n\n**Benefits**\n\n* Makes approvals/authorizations/notices **first-class and queryable**, enabling clean RSG checklists and guard rules.\n* Provides stable provenance: commitments and status transitions can cite the **instituting act** explicitly.\n* Prevents recurring category errors: “documents promise”, “interfaces commit”, “logs prove”.\n\n**Trade-offs / mitigations**\n\n* Requires recording a small structured object for communicative events; mitigated by allowing minimal stubs that still satisfy CC‑A.2.9‑1…4.\n* Requires context-local `SpeechActTypeRef` registration; mitigated by starting with a small set (Approve, Revoke, Publish, Notify, Authorize) and extending as needed.\n",
        "rationale": "### A.2.9:10 — Rationale\n\nFPF already relies on communicative acts (approvals, notices, overrides) as operationally meaningful events, but without a kernel object they blur into examples, naming choices, or prose. A.2.9 anchors speech acts where they belong: as a **Work-kind** with explicit performer, scope, and time, and with disciplined links to utterance surfaces, carriers, and deontic bindings (`U.Commitment`).\n\nThis also improves modularity:\n\n* **F.18** can remain a **lexical anchor** for naming (why “SpeechAct/utterance” as a label family is useful),\n* while **A.2.9** carries the ontology and conformance discipline for how speech acts behave as objects and how they connect to commitments and evidence.\n",
        "sota_echoing": "### A.2.8:11 - SoTA-Echoing (informative; post‑2015 alignment)\n\n> **Informative.** Alignment notes; not normative requirements.\n\n* **BCP 14 (RFC 2119 + RFC 8174) / modern spec-language discipline (2017+).** Treating modality tokens as a controlled family is standard; `U.Commitment.modality` makes this family explicit and lintable.\n* **Policy-as-code ecosystems (2016+).** Modern governance stacks often encode gates as code (e.g., Kubernetes admission controls, OPA/Rego-style policy evaluation) and obligations as process controls; the `U.Commitment` structure helps keep “gate predicates” separate from “actor duties”, while still linking them by reference.\n* **ODRL-style duty/permission/prohibition modeling (W3C ODRL 2.2, 2018).** The minimal “subject + modality + constraint/window + target” shape is widely used; `U.Commitment` adopts the kernel of that idea while keeping FPF’s boundary routing and evidence discipline.\n* **Trace-based compliance and audit (2018+ supply-chain / reproducibility practice).** “Compliance is evidenced by artifacts” is mainstream; `adjudication.evidenceRefs` captures this without turning evidence into semantics.\n* **Supply-chain attestations (2021+).** Attestation-oriented schemes (e.g., SLSA-style provenance, transparency logs) operationalize “claims + evidence carriers”; `adjudication.evidenceRefs` is the bridge point without collapsing evidence into truth.\n",
        "relations": "### A.2.9:12 — Relations\n\n**Uses / builds on**\n\n* Uses **A.15.1 (`U.Work`)** for the event/work backbone (performedBy + window + stance).\n* Uses **A.7** for the strict act≠description≠carrier split.\n* Coordinates with **A.2.6** for scope/window discipline.\n\n**Used by**\n\n* **A.2.8 (`U.Commitment`)** as a concrete target for `source.speechActRef` provenance.\n* **A.2.5 (RSG checklists/guards)** when “presence of authorization/approval act” is a criterion.\n* **A.6.C (Contract unpacking)** as the “utterance/instituting act” hook that prevents episteme-as-agent claims and improves provenance.\n",
        "a.2.8:end": "### A.2.8:End\n\n\n## A.2.9 — `U.SpeechAct` (Communicative Work Object)\n\n> **Type:** Definitional (D)\n> **Status:** Stable\n> **Normativity:** Normative (unless explicitly marked informative)\n> **Placement:** Part A → **A.2 Roles & Agency Kernel**\n> **Refines:** A.2 (Role Taxonomy)\n> **Builds on:** A.2.1 (RoleAssignment), A.2.6 (`Γ_time` / windows), A.7 (Object≠Description≠Carrier), A.10 (SCR/RSCR carrier discipline), A.15.1 (`U.Work`)\n> **Purpose (one line):** Provide a minimal, lintable kernel object for **communicative enactments** (approvals, authorizations, revocations, notices, declarations, publications) as **`U.Work`**, explicitly separating the **act** from its **utterance descriptions** and **evidence carriers**, so governance and gating can cite `SpeechActRef` without “contract soup” or episteme‑as‑agent mistakes.\n\n> FPF already treats communicative acts as observable events used in role-state checklists and grounding (“presence of act: AuthorizationSpeechAct exists…”, and `U.SpeechAct` is listed as an observable basis for state assertions).\n> The spec’s micro-examples and conformance gates distinguish **communicative Work** (“performed a SpeechAct”) from **operational Work** (“executed Work”) while keeping both inside `U.Work` (cf. CC‑A15‑10 GateSplit).\n> F.18 currently frames `U.SpeechAct` as the “utterance” label in the promise/utterance/commitment triad; A.2.9 keeps that as **naming intuition** while putting the ontology and conformance discipline in Part A where it can be linted and reused.\n",
        "a.2.9:11_—_sota‑echoing_(informative;_post‑2015_alignment)": "### A.2.9:11 — SoTA‑Echoing (informative; post‑2015 alignment)\n\n> **Informative.** Alignment notes; not normative requirements.\n\n* **Adopt — ISO 24617‑2:2020 / multi-dimensional communicative functions.** Modern dialogue‑act standards treat communicative behavior as potentially multi‑functional. A.2.9 mirrors this by allowing `actTypes` to be a **set** and by supporting shared carriers across multiple acts.\n* **Adapt — commitment-based semantics for communication (multi-agent/protocol practice, 2015+).** A pragmatic way to avoid mental-state modeling is to track communication by its **social/institutional effects**, especially on commitments and protocol states. A.2.9 reflects this via `institutes.commitments` and explicit links to `U.Commitment` without modeling sincerity or intention.\n* **Adopt (warning) — illocutionary pluralism in multiparty discourse (2015+).** One utterance commonly performs multiple recognizable functions. A.2.9 avoids the “single force” trap by permitting multi‑type acts and/or multiple acts sharing the same utterance and carriers.\n",
        "a.2.9:end": "### A.2.9:End\n "
      },
      "content": "### A.2.9:End\n ",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.3",
      "title": "Transformer Constitution (Quartet)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.3 - Transformer Constitution (Quartet)\n",
        "intent": "### A.3:1 - Intent\n\nEstablish a single, substrate‑neutral way to say **who acts**, **under which role**, **according to which description**, **by which capability**, and **what actually happened**—without “self‑magic” and without blurring design‑time and run‑time. The pattern fixes the **Transformer Quartet** so all kernel and Γ‑patterns reuse the *same four anchors*. It builds directly on **Holon‑Role Duality (A.2)** and **Temporal Duality (A.4)** and is guarded by **Strict Distinction (A.7)** and **Evidence Graph Referring (A.10)**.\n",
        "context": "### A.3:2 - Context\n\n* **Holonic substrate.** FPF separates *what things are* (Holon → {System, Episteme, …}) from *what they are being right now* via **roles**. Only **systems** can bear **behavioural** roles and execute methods/work; epistemes are changed **via their symbol carriers**.\n* **Role as mask; behaviour as method/work.** A role is a **mask**, not behaviour; behaviour is a **Method** (order‑sensitive capability) that may be executed as **Work** (dated occurrence).\n* **Design‑time vs run‑time.** A holon’s states belong to disjoint scopes **Tᴰ** and **Tᴿ**; transitions are physically grounded by a system bearing **TransformerRole**.\n* **Evidence & carriers.** Claims about outcomes must anchor to **carriers** (SCR/RSCR) and to an **external** evidencing transformer.\n",
        "problem": "### A.3:3 - Problem\n\nLegacy phrasing (“actor / process / blueprint”) causes recurrent failures:\n\n1. **Self‑magic:** “the system configures itself” (no external acting side, causality lost).\n2. **Plan = event:** blueprint/algorithm reported as if execution happened.\n3. **Capability = result:** possession of a method counted as evidence of work.\n4. **Episteme as doer:** documents/models treated as actors.\n5. **Scope leak:** design‑time and run‑time mixed; run traces lack carriers/method ties.\n   A.2/A.4/A.7/A.10 collectively forbid these, but A.3 must give the **canonical quartet** that authors can apply consistently.\n",
        "forces": "### A.3:4 - Forces\n\n| Force                       | Tension                                                                                     |\n| --------------------------- | ------------------------------------------------------------------------------------------- |\n| **Identity vs behaviour**   | Keep holon identity stable while roles/behaviours change.                                   |\n| **Simplicity vs precision** | Managers want one “process” box; kernel must keep **MethodDescription / Method / Work** distinct.  |\n| **Universality vs idioms**  | Pumps, proofs, and data‑pipelines must read the same, yet allow domain names.               |\n| **Design vs run**           | No overlap of **Tᴰ** and **Tᴿ**; bridges explicit and causal.                               |\n| **Evidence vs mereology**   | Provenance edges (EPV‑DAG) must never turn into part‑whole edges.                           |\n",
        "solution": "### A.3:5 - Solution — The Transformer Quartet\n\nA.3 defines four anchors, tied together by **Role Assignment (`U.RoleAssignment`)** and aligned with **Temporal Duality**.\n\n#### A.3:5.1 - The four anchors (terms & types)\n\n1. **Acting side:** a **system bearing TransformerRole** — the only holon kind allowed to enact transformations (behavioural role). *Canonical phrase:* **“system bearing TransformerRole”**. *Local shorthand:* after explicit binding in the **same subsection**, you MAY write **“Transformer”** to denote that same system; re‑bind on context change and **do not** use shorthand where the domain already has a conflicting “transformer” term.\n\n2. **MethodDescription (design‑time description):** protocol / algorithm / SOP / script — all are **idioms of MethodDescription**; they live in **Tᴰ** and are **epistemes** with carriers (SCR/RSCR).\n\n3. **Method (design‑time capability):** order‑sensitive composition the system *can* enact at run‑time (Γ\\_method); it is **not** an occurrence.\n\n4. **Work (run‑time occurrence):** dated execution producing state change and consuming resources (Γ\\_work); every Work **isExecutionOf** exactly one MethodDescription version and is **performedBy** exactly one performer (possibly a collective system).\n\n> **Safe memory line:** *MethodDescription → (describes) Method → (executed as) Work.*\n> Roles are **masks** (A.2/A.7); methods/work are **behaviour**.\n\n#### A.3:5.2 - Contextual Role Assignmnent (`U.RoleAssignment`) for transformations\n\nUse the universal assignment to state **who plays which role where and when**:\n\n```\nU.RoleAssignment(\n  holder  : U.System,          -- the acting system (bearer)\n  role    : U.TransformerRole, -- behavioural role\n  context : U.BoundedContext,  -- semantic boundary\n  timespan?: Interval          -- optional validity window\n)\n```\n\n* A role is **local to context** and **time‑indexed**.\n* The same system may bear multiple roles **if** the context allows compatibility.\n* For epistemes, the target of change is their **symbol carriers**; the acting side is still a **system**.\n\n#### A.3:5.3 - Boundary & externality\n\nEvery transformation is modelled with **two sides** and an explicit **U.Interaction** boundary: **acting** (system bearing TransformerRole) and **target** (system being transformed, or the **carrier** of an episteme). There is **no self‑doing**; “self‑like” stories are handled by the **reflexive split** (regulator vs regulated subsystems) or by promoting a meta‑holon and keeping evidence external (A.12).\n\n#### A.3:5.4 - Temporal alignment (A.4 bridge)\n\n* **MethodDescription** lives in **Tᴰ**;\n* **Method** is defined at design-time and **executed as `U.Work` at run-time by a `U.System` with a valid `U.RoleAssignment` (window-aligned) and a live **StateAssertion** for an **enactable** RSG state**;\n* **Work** lives in **Tᴿ**;\n* transitions **Tᴰ → Tᴿ** and **Tᴿ → Tᴰ** are **grounded** by executions of appropriate methods by an **external** transformer (e.g., fabrication or observation).\n\n#### A.3:5.5 - Evidence Graph Referring\n\nEach Work anchors to **carriers** and to the **MethodDescription** it instantiates; evidencing transformers are **external** (no self‑evidence). This sits in the **EPV‑DAG** and never in mereology.\n\n#### A.3:5.6 - Didactic dictionary (safe mappings)\n\n* “Process / Workflow / SOP / Algorithm” ⇒ **MethodDescription** (design‑time description).\n* “Operation / Job / Run / Performance” ⇒ **Work** (run‑time occurrence).\n* “Function (equipment spec)” ⇒ **Method** (or MethodDescription if purely textual).\n* “Creator” (legacy) ⇒ **Transformer** (shorthand for **system bearing TransformerRole** after local binding).\n",
        "illustrative_scenarios_(substrate‑neutral)": "### A.3:6 - Illustrative scenarios (substrate‑neutral)\n\n#### A.3:6.1 - Physical system — Cooling loop\n`PumpUnit#3` (**system bearing TransformerRole**) executes `ChannelFluid` (**Method**) as per `centrifugal_pump_curve.ld` (**MethodDescription**), producing `run‑2025‑08‑08‑T14:03` (**Work**, 3.6 kWh; ΔT=6 K). Evidence goes to carriers in SCR; resource spend goes to Γ\\_work.\n\n#### A.3:6.2 - Epistemic change — Proof revision\n`LeanServer` (**system bearing TransformerRole**) edits `proof_tactic.lean` (carrier) per MethodDescription; `lemma‑42‑check‑2025‑08‑08` is **Work**; the **episteme** (theorem) changes through its carriers; evidence is attributed to the external transformer.\n\n#### A.3:6.3 - Reflexive maintenance — “calibrates itself”\nSplit into **Regulator** (calibration module, acting side) and **Regulated** (sensor suite, target) with an interaction boundary; credit evidence to the regulator; no self‑evidence.\n",
        "conformance_checklist": "### A.3:7 - Conformance Checklist (normative)\n\n**CC‑A3‑0 - U.RoleAssgnment presence.**\nEvery claim that a holon “performs a transformation” MUST be backed by at least one **RoleAssignment** triple:\n`U.RoleAssignment(holder: U.Holon, role: U.Role=TransformerRole, context: U.BoundedContext, timespan?)`.\nThis is the canonical way to say *who acts, in which role, where (semantically), and when*. See **A.2.1** for the universal **`U.RoleAssignment`** Standard and its invariants.\n\n**CC‑A3‑1 - External transformer discipline.**\nThe **bearer** of `TransformerRole` MUST NOT be the same model instance as the **object‑under‑change** within the same assignment. Self-modification is modelled via two **`U.RoleAssignment`s** (same holder playing two roles) or via an explicit controller–plant split. This upholds **Agent Externalization** (A.12).\n\n**CC‑A3‑2 - Design–Run separation.**\n`U.MethodDescription` (recipe, definition) is a **design‑time** artefact; `U.Method` (mask‑of‑work) and `U.Work` (executed work) are **run‑time**. It is non‑conformant to mutate a `MethodDescription` inside a `Work` log or to treat a `Work` as a `MethodDescription`. This enforces the kernel’s **Temporal Duality** (A.4) and the A.15 alignment.\n\n**CC‑A3‑3 - Boundary‑crossing evidence.**\nA conformant transformation that changes a system’s state MUST reference the **boundary effects** it induces: interactions, flows, or state transitions attach to the target system’s boundary (per Γ‑defaults for additive, min/AND/OR folds). Conservation‑class effects MUST satisfy B‑invariants (e.g., **B‑1 Conservation**).\n\n**CC‑A3‑4 - Method ←→ Work traceability.**\nEvery `U.Work` MUST (i) name the `U.Method` it instantiates and (ii) trace the `U.MethodDescription` it claims to follow (versioned). If a deviation occurs, it MUST be logged as a **policy override** or **exception path**; silent drift is non‑conformant. (A.15 guards the vocabulary; Γ\\_work aggregates resource deltas.)\n\n**CC‑A3‑5 - Episteme as object‑under‑change.**\nWhen the changed holon is an **episteme** (document, dataset, theory), the transformer is still a **system**; the episteme’s history MUST be recorded via **PhaseOf** (versioning) and **ConstituentOf/PortionOf** as appropriate (not via component trees). See A.14’s mereology firewalls and Γ\\_epist hooks.\n\n**CC‑A3‑6 - Units and measures for resource effects.**\nAny resource consumption/production in `U.Work` MUST specify the **measure μ** and **units** (e.g., kg, J, bytes); “percentage” effects MUST be grounded in a PortionOf μ to be Γ‑aggregatable. (A.14 POR‑axioms; Γ\\_work usage.)\n\n**CC‑A3‑7 - Provenance minimum.**\nFor each `U.RoleAssignment` and `U.Work`, the following fields are REQUIRED: `{authority?, justification?, provenance?}` where `justification: U.Episteme` and `provenance: U.Method`/process evidence. This aligns with the kernel’s governance and B‑cluster lineage practices.\n\n**CC‑A3‑8 - Policy–Plan–Action separation for agentic cases.**\nIf the transformer bearer is agentic, the log MUST separate `D.Policy → U.PlannedAction → U.Action` (A.15/A.13), preserving where failure occurred (strategy, plan, or execution).\n\n**CC‑A3‑9 - Context‑local conflicts.**\nConflicts among roles (including `TransformerRole`) are only **within the same bounded context**; cross‑context differences are admissible if bridges are declared. Non‑conformance arises only when a context’s own incompatibility rules are violated. (A.2.1 `U.RoleAssignment` invariants.)\n\n**CC‑A3‑10 - Γ‑compatibility.**\nDescriptions MUST be sufficient for the relevant Γ‑aggregations to run: Γ\\_method for recipe composition, Γ\\_work for resource deltas, Γ\\_sys for boundary integration, Γ\\_time for ordering. Each Γ flavour declares its A.14 hooks (Portion/Phase) and inherits B‑invariants.\n\n",
        "consequences": "### A.3:8 - Consequences\n\n**Benefits**\n\n* **Explainability by construction.** Every transformative claim carries *who/what/when/why/how* via **`U.RoleAssignment`** + provenance fields; audits become mechanical rather than heroic. (B‑invariants and Γ tables do the heavy lifting.)\n* **No category errors.** Keeping methods/roles out of mereology and enforcing design/run separation prevents the usual “process‑as‑part” and “version‑as‑component” mistakes. (A.14 + A.15.)\n* **Composable analytics.** With measures and boundary folds explicit, cross‑scale proofs (Σ/Π/min/∧/∨) are predictable.\n* **Contextual pluralism without chaos.** Divergent domain practices coexist as distinct bounded contexts with bridges; disagreements are localised and tractable.\n\n**Trade‑offs**\n\n* **More declarations up‑front.**  `U.RoleAssignment` + units + policy/plan/action feels verbose, but yields deterministic Γ‑runs and reproducible audits.\n* **Discipline for “self‑modifiers.”** Modellers must split controller vs plant or dual‑role the same carrier; this adds one line but avoids hidden identity conflations.\n\n",
        "rationale": "### A.3:9 - Rationale (post‑2015 cross‑domain support)\n\n**Constructor theory (post‑2015).**\nOur **Transformer Principle** mirrors constructor theory’s shift from *dynamics* to *tasks*: what transformations are **possible** vs **impossible**, and why. By making the **transformer** (constructor) an explicit bearer of a role and keeping recipes as `MethodDescription`, A.3 captures the core “tasks & constructors” distinction and aligns with constructor‑theoretic thermodynamics linking work, heat, and informational constraints. ([Royal Society Publishing][1], [arXiv][2], [Constructor Theory][3])\n\n**Active inference & free‑energy mechanics (2017→).**\nWhere transformers are *agentic*, A.3’s policy–plan–action split and boundary‑centred accounting dovetail with **active inference** and **free‑energy** formulations of self‑organising systems (Markov blankets; Bayesian mechanics). This legitimises `U.Objective`/cost function links and makes design–run duality natural (prior vs posterior policies). ([MIT Press Direct][4], [PubMed][5], [arXiv][6])\n\n**Provenance and FAIR packaging (2016→).**\nProvenance minima in CC‑A3‑7 reflect **FAIR** principles (machine‑actionable reuse), **RO‑Crate** (methods+data+context packaged together), and operational lineage standards such as **OpenLineage** and **ML Metadata (TFX)** that treat *artefacts, runs, and jobs* as first‑class, with typed facets and versioning — exactly what enactment + Γ\\_work need. ([Nature][7], [researchobject.org][8], [SAGE Journals][9], [openlineage.io][10], [GitHub][11], [arXiv][12])\n\nTogether, these lines of work argue for **explicit role‑bearing transformers**, **recipe/run separation**, **boundary‑grounded deltas**, and **traceable contexts** — the four pillars that CC‑A3 enforces.\n\n",
        "relations": "### A.3:10 - Relations\n\n**A.7 Strict Distinction.**\nA.3 operationalises A.7 by keeping **object ≠ description ≠ observation**:\n*object* = target holon; *description* = `MethodDescription`; *observation/log* = `Work`. Violations (e.g., treating a recipe as a part) are non‑conformant and usually surface as Γ failures.\n\n**A.12 Agent Externalization & External Transformer.**\nA.3’s CC‑A3‑1 is the mechanical guard‑rail for A.12: even in self‑modification, the *modelling split* keeps the agent (transformer bearer) distinct from the object‑under‑change.\n\n**A.13 Agential Role.**\nWhen the bearer is an **Agent**, A.3 defers identity and states management to Agent‑CAL (`U.Agent`, `U.Intent`, `U.Action`), while still requiring `RoleAssigning` + Γ compatibility. This is where policy/plan/action pipelines live.\n\n**A.15 Role–Method–Work Alignment.**\nA.3 relies on A.15’s vocabulary guard‑rails (roles are not parts; methods are masks of work; specs are recipes). CC‑A3‑2/‑4 are enforceable precisely because A.15 fixes the naming discipline.\n\n**A.14 Advanced Mereology.**\nA.3 consumes A.14’s **PortionOf** (for quantitative deltas) and **PhaseOf** (for versioning) and forbids role/recipe leakage into part–whole trees. Γ‑flavours declare which A.14 hooks they use.\n\n**B‑cluster (Γ‑sections).**\nA.3 is executable only because Γ‑operators provide aggregation and invariants:\n\n* **Γ\\_sys** enforces boundary folds and conservation;\n* **Γ\\_epist** preserves document/data provenance and versioning;\n* **Γ\\_time** orders work;\n* **Γ\\_method** composes recipes;\n* **Γ\\_work** accounts resource deltas; each inherits B‑invariants (e.g., B‑1 Conservation, B‑2 No‑Duplication).\n\n**Indexing to the glossary.**\nTerms used here (TransformerRole, Work, Method, MethodDescription, PortionOf, PhaseOf, BoundedContext) remain exactly as defined in Annex A; see A.1/A.2/A.14/A.15 entries for lexical registers.\n\n[1]: https://royalsocietypublishing.org/doi/10.1098/rspa.2014.0540 \"Constructor theory of information | Proceedings of the Royal Society A\"\n[2]: https://arxiv.org/abs/1405.5563 \"Constructor Theory of Information\"\n[3]: https://www.constructortheory.org/wp-content/uploads/2016/07/THD-ArXiv-Final.pdf \"[PDF] Constructor Theory of Thermodynamics\"\n[4]: https://direct.mit.edu/neco/article/29/1/1/8207/Active-Inference-A-Process-Theory \"Active Inference: A Process Theory | Neural Computation | MIT Press\"\n[5]: https://pubmed.ncbi.nlm.nih.gov/27870614/ \"Active Inference: A Process Theory - PubMed\"\n[6]: https://arxiv.org/abs/1906.10184 \"A free energy principle for a particular physics\"\n[7]: https://www.nature.com/articles/sdata201618 \"The FAIR Guiding Principles for scientific data management and … \"\n[8]: https://www.researchobject.org/ro-crate/about_ro_crate \"About RO-Crate - Research Object\"\n[9]: https://journals.sagepub.com/doi/10.3233/DS-210053 \"Packaging research artefacts with RO-Crate - Sage Journals\"\n[10]: https://openlineage.io/docs/ \"About OpenLineage | OpenLineage\"\n[11]: https://github.com/OpenLineage/OpenLineage \"GitHub - OpenLineage/OpenLineage: An Open Standard for lineage metadata collection\"\n[12]: https://arxiv.org/pdf/2010.02013 \"[PDF] A Brief History Of TensorFlow Extended (TFX) - arXiv\"\n",
        "a.3:end": "### A.3:End\n"
      },
      "content": "### A.3:End\n",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.3.1",
      "title": "U.Method",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.3.1 - U.Method\n",
        "a.3.1:1___context_(plain‑language_motivation)": "### A.3.1:1 - Context (plain‑language motivation)\n\nTeams must talk about **how** something is done without entangling:\n\n* **Who** is assigned (that is **Role**/**RoleAssigning**),\n* **Whether** the holder can do it (that is **Capability**), and\n* **What actually happened** (that is **Work**).\n\n`U.Method` supplies the *how*—the **abstract way of performing a transformation**, independent of a specific run, a specific assignee, or a specific notation. It works across paradigms:\n\n* **Imperative** (step‑graphs, SOPs, BPMN),\n* **Functional** (pure mappings and compositions, no “steps”),\n* **Logical/constraint/optimization** (goals, rules, admissible solutions).\n\nIn FPF, a **system** bearing a **TransformerRole** *enacts* a `U.Method` (producing **Work**) by following a **MethodDescription**—an episteme that describes the method in some representation.\n",
        "problem": "### A.3.1:2 - Problem (what goes wrong without a clean notion of “method”)\n\n1. **Process soup.** “Process” gets used for recipe, execution, schedule, or org area. Planning, staffing, and audit blur together.\n2. **Spec = run fallacy.** A flowchart (or code) is taken as if execution already happened; conversely, logs get mistaken for the recipe.\n3. **Role leakage.** People encode assignments inside the recipe (“this step is the surgeon”), tying **who** to **how** and making reuse impossible.\n4. **Notation lock‑in.** When “method” is defined as “a set of steps,” functional or logical styles become second‑class citizens and cannot be modeled cleanly.\n",
        "forces": "### A.3.1:3 - Forces (what the definition must balance)\n\n| Force                                  | Tension we resolve                                                                                        |\n| -------------------------------------- | --------------------------------------------------------------------------------------------------------- |\n| **Universality vs. specificity**       | One notion must cover welding, ETL, proofs, and schedulers, while letting each domain keep its idioms.    |\n| **Representation vs. semantics**       | Many notations express the same “way of doing”; we need one semantic anchor across specs.                 |\n| **Reusability vs. assignment**        | The *how* should be reusable regardless of *who* is assigned this time.                                  |\n| **Compositionality vs. executability** | Methods compose (serial/parallel/choice/iteration), but execution may diverge due to conditions/failures. |\n| **Determinism vs. search**             | Methods may be deterministic algorithms or constraint problems with admissible solution sets.             |\n\n",
        "solution": "### A.3.1:4 - Solution — the method as an abstract, paradigm‑agnostic “way of doing”\n\n#### A.3.1:4.1 - Definition\n\n**`U.Method`** is a **context‑defined abstract transformation type**—the **semantic “way of doing”** a kind of work.  \nIt is:\n**Described** (never *identical*) by one or more **`U.MethodDescription`** epistemes (code/SOP/diagram/rules),  \n**Enacted** by a `U.System` bearing an appropriate **Role** (usually a **TransformerRole**) to produce **`U.Work`**, and  \n**Independent** of who is assigned, what instance ran, or which notation was used.\n\n**Strict Distinction (didactic):**  \n* **Method** = *how in principle* (semantic Standard).  \n* **MethodDescription** = *how it is written* (artifact on a carrier).  \n* **Work** = *how it actually went this time* (dated execution).\n\n#### A.3.1:4.2 - Representation‑agnostic stance (specs may be imperative/functional/logical)\n\nA `U.Method` does **not** require an imperative step structure. **Representations live in `U.MethodDescription`, not in the Method itself.**  \nTypical **MethodDescription forms** include:\n\n* **Imperative MethodDescription:** step‑graph/flow (serial/parallel/branch).  \n* **Functional MethodDescription:** a composition `f ∘ g ∘ h` with typed interfaces/constraints, no “steps”.  \n* **Logical/constraint MethodDescription:** a goal/constraint set with admissible solutions and search/optimization semantics.  \n* **Hybrid MethodDescription:** imperative scaffolding with functional kernels and/or solver calls.\n\n**Semantic identity criterion (context‑local).** Two MethodDescriptions **describe the same `U.Method`** in a given `U.BoundedContext` iff, for all admissible inputs and conditions recognized by that context, they entail the **same preconditions**, **guarantee the same postconditions/effects**, and satisfy the **same non‑functional bounds** (allowing permitted non‑determinism). Internal control‑flow/search details may differ.\n\n\n#### A.3.1:4.3 - Method vs MethodDescription vs Work (quick litmus)\n\n| You have in your hand…           | In FPF it is…                 | Why                                                                             |\n| -------------------------------- | ----------------------------- | ------------------------------------------------------------------------------- |\n| A flowchart/BPMN/SOP text        | **`U.MethodDescription`** (Episteme) | A description on a carrier.                                                     |\n| A git repo with code | **`U.MethodDescription`** (Episteme) | Still a description (even if executable). The Method is the semantic “way” it denotes. |\n| A log/run report with timestamps | **`U.Work`**                  | A concrete event that happened.                                                 |\n| “The way we weld seams type W”   | **`U.Method`**                | The abstract *how*, represented by one or more specs and realized by many runs. |\n\n**Didactic rule:** when referencing *the idea* of “how”, say **Method**; when referencing *the document or code*, say **MethodDescription**; when referencing *the run*, say **Work**.\n\n#### A.3.1:4.4 - Interface and effect (conceptual descriptors)\n\nWhen presenting a `U.Method` in a review, anchor it with these paradigm‑neutral elements (not a data schema):\n\n1. **Interface** — what is required/provided in general (inputs/outputs/types or resources/roles/ports).\n2. **Preconditions** — what must already hold (guards, invariants, Standard “requires”).\n3. **Postconditions / Effects** — what is guaranteed after successful enactment (Standard “ensures”).\n4. **Non‑functional constraints** — latency, accuracy, cost, safety envelope (ties to **Capability** thresholds).\n5. **Failure modes** — known failure classes and recoverability hints.\n6. **Compositional hooks** — whether this method composes serially/parallel/choice/iteration (see §4.5).\n\n#### A.3.1:4.5 - Method mereology (composition without confusing it with runtime)\n\nMethods compose into bigger methods; executions compose into bigger executions—**do not conflate** the two.\n\n**Method composition (design‑time):** serial (`-`), parallel (`‖`), choice (`|`), iteration (`*`), refinement/substitution—yield **new `U.Method`s**.\n**Work composition (run‑time):** the corresponding **Work** may split/merge/overlap differently due to scheduling, failures, or environment, yet it is still **execution of the same Method**.\n**Mapping advice:** avoid naming run‑time artifacts inside the method definition (no “this thread”, “this person”); keep those in **Role**/**Work**.\n\n#### A.3.1:4.6 - Constructor‑theoretic reading (why Method ≠ algorithm ≠ spec)\n\nConstructor Theory views a **constructor** as a physical entity that **effects transformations**. In FPF:\n\n* A `U.System` with **TransformerRole** is the constructor (the performer).  \n* A **`U.Method`** is the abstract **transformation type** it enacts (semantic Standard).  \n* An **algorithm artifact** is a **`U.MethodDescription`** for an **information‑transformation Method**.  \n* A **universal transformer** generalizes the **Turing machine** by **executing any `U.Method` described by a physically admissible `U.MethodDescription`** (not only informational ones).\n\nThus, welding, milling, reagent mixing, and proof construction are all **Methods**; textbooks/code/derivations are their **MethodDescriptions**; **Work** are the concrete runs.\n\n#### A.3.1:4.7 - Context anchoring\n\n`U.Method` is **local to a `U.BoundedContext`**: terminology, admissible pre/postconditions, and non‑functional constraints are interpreted **inside that context**. If two teams or theories use the same name for different “ways of doing,” they are different Methods in different contexts unless bridged explicitly.\n\n",
        "archetypal_grounding": "### A.3.1:5 - Archetypal grounding (cross-paradigm examples: imperative / functional / logical)\n\n#### A.3.1:5.1 - Industrial transformation (imperative flavor)\n\n* **Method:** `Etch_Al2O3`.\n* **MethodDescription:** SOP document; a PLC program that controls gas mix and timing.\n* **Enactment:** `Tool_42#TransformerRole:FabLine_A` produces **Work** runs W‑101, W‑102….\n* **Notes:** Step diagram exists, but a later **functional** spec may also exist (composition of gas‑flow functions). Both **specs** describe the **same Method**.\n\n#### A.3.1:5.2 - Operational planning (functional/optimization flavor)\n\n* **Method:** `JS_Schedule_v4` (job‑shop scheduling).\n* **MethodDescription:** a MILP model + solver configuration; documentation of constraints/objective.\n* **Enactment:** `PlannerService_v4#TransformerRole:PlantScheduling_2025` produces **Work** `Run_2025‑W32‑P1`.\n* **Notes:** No “steps” are visible at the method level; the solver’s search is internal. Still a `U.Method`.\n\n#### A.3.1:5.3 - Scientific proof (logical flavor)\n\n* **Method:** `Gauss_Elimination`.\n* **MethodDescription:** formal rules in a proof assistant; textbook chapter as a second spec.\n* **Enactment:** `CAS_Alpha#TransformerRole:MathLab_2025` generates a **Work** proof instance for a concrete matrix.\n* **Notes:** The **Episteme** (spec) is not the **ability** (that belongs to the CAS system) and not the **execution** (the proof run).\n\n",
        "a.3.1:6___didactic_quick_grammar_(for_managers)": "### A.3.1:6 - Didactic quick grammar (for managers)\n\n* **Who?** `Holder#Role:Context` (**Role assignment**)\n* **Can?** `Capability(holder)` within envelope/measures\n* **How (in principle)?** **`Method`**, described by **`MethodDescription`**\n* **Did?** **`Work`** (execution), linked by `performedBy → RoleAssigning` and `isExecutionOf → MethodDescription`\n\n> *Keep the four words apart and plans become dependable.*\n\n",
        "a.3.1:7___bias‑annotation_(as_in_cluster‑e_patterns)": "### A.3.1:7 - Bias‑Annotation (as in cluster‑E patterns)\n\n* **Lenses tested:** `Arch`, `Prag`, `Did`, `Epist`.\n* **Scope declaration:** Universal; semantics are context‑local via `U.BoundedContext`.\n* **Rationale:** Gives FPF a **paradigm‑neutral** “how” that bridges MethodDescription (knowledge on a carrier) and Work (execution), while staying independent of Role (assignment) and Capability (ability).\n",
        "conformance_checklist": "### A.3.1:8 - Conformance Checklist (normative)\n\n**CC‑A3.1‑1 (Strict Distinction).**\n`U.Method` is the **semantic “way of doing”**. It is **not** a `U.MethodDescription` (artifact on a carrier), **not** a `U.Work` (dated execution), **not** a `U.Role`/assignment, and **not** a `U.ServiceClause`/promise.\n\n**CC‑A3.1‑2 (Context anchoring).**\nEvery `U.Method` **MUST** be defined **within** a `U.BoundedContext`. Identity, admissible pre/postconditions, and non‑functional bounds are interpreted **in that context**.\n\n**CC‑A3.1‑3 (Specification linkage).**\nA `U.Method` **SHOULD** be **described by** ≥1 `U.MethodDescription`. For operational gating, at least one `MethodDescription` **MUST** be present and named. Multiple specs may coexist (imperative/functional/logic), see CC‑A3.1‑7.\n\n**CC‑A3.1‑4 (assignment‑free).**\nA `U.Method` **SHALL NOT** hard‑code holders or assignments. If a step “needs a surgeon”, express that as a **role requirement** (to be satisfied via `U.RoleAssignment` at run time), not as a named person/unit inside the method.\n\n**CC‑A3.1‑5 (Runtime‑free).**\nA `U.Method` **SHALL NOT** contain schedule, calendar slots, or run IDs; those belong to `U.WorkPlan` (plans) and `U.Work` (executions). Methods are timeless.\n\n**CC‑A3.1‑6 (Interface & effects).**\nA `U.Method` **MUST** admit a context‑local statement of interface (inputs/outputs or ports/resources), **preconditions**, **postconditions/effects**, and (when relevant) **non‑functional bounds**. These anchor semantic identity beyond a particular notation.\n\n**CC‑A3.1‑7 (Multi‑spec semantic identity).**\nTwo or more `U.MethodDescription` **describe the same `U.Method`** in a given context **iff** they entail the **same admissible preconditions**, **guarantee the same effects**, and satisfy the **same non‑functional bounds** for all inputs/conditions recognized by that context (allowing permitted non‑determinism). Internal control‑flow/search differences are irrelevant.\n\n**CC‑A3.1‑8 (Composition vs execution).**\nComposition of Methods (design‑time) and composition of Work (run‑time) **MUST** be kept distinct. Method composition yields **new Methods**; Work composition yields **composed executions**. They may correspond but are not identical.\n\n**CC‑A3.1‑9 (Parameterization).**\nIf a Method is parameterized, parameters are **declared** at the Method/MethodDescription level; **concrete values** are bound **at `U.Work` creation**. Avoid freezing parameter values inside the Method definition.\n\n**CC‑A3.1‑10 (Dynamics ≠ Method).**\nLaws/trajectories (`U.Dynamics`) are models of state evolution and **SHALL NOT** be labeled as Methods. A Method **may** rely on a Dynamics model (e.g., for control), but they remain distinct artifacts/concepts.\n\n**CC‑A3.1‑11 (Capability checks are orthogonal).**\nA step may impose capability thresholds; those thresholds are checked **against the holder’s `U.Capability`** independently of assignment and independently of the Method’s description.\n\n**CC‑A3.1‑12 (Constructor‑theoretic alignment).**\nAlgorithm artifacts are `U.MethodDescription` for information‑transforming Methods. Physical Methods are equally valid (matter/energy transformations). A “universal transformer” is a system that can enact **any physically admissible MethodDescription**; this does **not** collapse Method into “algorithm.”\n\n",
        "a.3.1:9___method_mereology_(composition)_—_design‑time_only": "### A.3.1:9 - Method mereology (composition) — design‑time only\n\n**Operators (conceptual, context‑scoped):**\n\n* **Serial composition (`-`)** — do A then B → `A - B` is a new Method.\n* **Parallel composition (`‖`)** — do A and B concurrently (with declared independence/joins).\n* **Choice (`|`)** — do **one** of {A, B} under guard/selector.\n* **Iteration (`*`)** — repeat A under a loop invariant/termination condition.\n* **Refinement (`≤ₘ`)** — Method M' preserves M’s interface/effects and **strengthens** preconditions or **tightens** non‑functional bounds (context‑defined lattice).\n* **Substitution** — replace a Method factor with a semantically equivalent one (`M ≡ N` in context) without changing the whole’s Standard.\n\n**Design‑time laws (intuitive, not mechanized here):**\n\n* Associativity for `-` and, where admissible, for `‖`.\n* Distributivity over guarded choice under context rules.\n* Identity elements (e.g., `Skip` that preserves state and satisfies neutral bounds).\n* Monotonicity: refinement of a factor **should not** break the whole’s postconditions.\n\n**Run‑time mapping (do not conflate):**\n`U.Work` instances of `A - B` **may** interleave differently due to scheduling or failure‑handling and still be executions of `A - B`. The mapping is “execution semantics,” not part of Method mereology.\n",
        "a.3.1:10___how_methods_interact_with_roles,_capability,_work,_dynamics_(manager’s_view)": "### A.3.1:10 - How Methods interact with Roles, Capability, Work, Dynamics (manager’s view)\n\n* **Roles (assignment).** Steps stipulate **role kinds** (e.g., `IncisionOperatorRole`), not people. At run time, `U.Work` references a **`U.RoleAssignment`** that satisfies the role kind.\n* **Capability (ability).** Steps may require **thresholds** (e.g., “precision ≤ 0.2 mm”). They are checked against the **holder’s `U.Capability`** in the context/envelope.\n* **Work (execution).** Each run records `isExecutionOf → MethodDescription` (the spec used) and `performedBy → RoleAssigning`. Logs, resources, and timestamps live here.\n* **Dynamics (laws/models).** Methods may cite or assume a Dynamics model; runs may attach traces that are explained by that model. Do not label the model itself as the Method.\n\n",
        "a.3.1:11___anti‑patterns_(and_the_right_move)": "### A.3.1:11 - Anti‑patterns (and the right move)\n\n* **Spec = Method.** “The BPMN is the Method.” → The BPMN is a **MethodDescription**; the **Method** is the semantic way it denotes.\n* **Run = Method.** “Yesterday’s process is our Method.” → Yesterday’s run is **Work**.\n* **Role leakage.** “Step 3 is done by Alice.” → Step 3 **requires** `SurgeonRole`; Alice may be assigned via **RoleAssigning**.\n* **Schedule leakage.** “Run at 02:00 daily” inside the Method. → This belongs to **WorkPlan**; Methods are timeless.\n* **BoM entanglement.** Putting parts/assemblies inside Method definition. → Structure stays in PBS/SBS; Method references **interfaces/resources**, not a BoM.\n* **Algorithm‑only bias.** Declaring that only code counts as a Method. → Physical transformations (welding, mixing) are Methods too; their SOPs/parameters are MethodDescriptions.\n* **Hard‑coding capability.** Baking “≤ 0.2 mm” into a role name or Method name. → Keep thresholds on **steps**; **capability** lives on the **holder**.\n\n",
        "a.3.1:12___migration_notes_(quick_wins)": "### A.3.1:12 - Migration notes (quick wins)\n\n1. **Rename wisely.** Where texts say “process/method” but mean a diagram or code repo, label it **MethodDescription**; where they mean the abstract “how,” label it **Method**.\n2. **Extract assignments.** Replace named people/units in specs with **role kinds**; enforce assignments via **RoleAssigning** at run time.\n3. **Pull time out.** Move calendars/schedules from specs into **WorkPlan**.\n4. **Parameter hygiene.** Declare parameters at Method/MethodDescription; bind values in **Work**.\n5. **Equivalence notes.** When two specs are intended as the same Method, write an **equivalence note** in the context (pre/post/bounds parity).\n\n",
        "consequences": "### A.3.1:13 - Consequences\n\n| Benefits                                                                                                                    | Trade‑offs / mitigations                                                                           |\n| --------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------- |\n| **Clarity across paradigms.** Methods are first‑class regardless of notation; teams stop arguing step‑vs‑functional.        | **One more name to learn.** Use the quick grammar card; it pays off fast.                          |\n| **Reuse without personnel lock‑in.** assignment moves to RoleAssigning; Methods remain portable.                             | **Extra role tables.** Keep role‑kind lists short and context‑local.                               |\n| **Robust audits.** Logs are Work, specs are MethodDescription, Standards are Method; no more “we thought the diagram was the run.” | **Discipline needed.** Enforce the three‑way split in reviews.                                     |\n| **Constructor‑theoretic coherence.** Physical and informational transformations are peers.                                  | **Cultural shift.** Not every team is used to seeing SOPs and code as the same class (MethodDescription). |\n\n",
        "relations": "### A.3.1:14 - Relations\n\n* **Builds on:** A.1 Holonic Foundation; A.1.1 `U.BoundedContext`; A.2 `U.Role`; A.2.1 `U.RoleAssignment`; A.2.2 `U.Capability`.\n* **Coordinates with:** A.3 (role masks for transformers/constructors/observers); A.15 (Role–Method–Work Alignment); B.1 Γ (aggregation) for method families vs assembly of systems.\n* **Informs:** `U.WorkPlan` definitional pattern (plans reference Methods they schedule); `U.ServiceClause` definitional pattern (promises cite Methods as delivery means); `U.Dynamics` definitional pattern (models that Methods may assume).\n\n",
        "a.3.1:15___didactic_quick_cards_(reuse_in_specs_and_onboarding)": "### A.3.1:15 - Didactic quick cards (reuse in specs and onboarding)\n\n* **Method / MethodDescription / Work** = *how in principle* / *how it is written* / *how it went this time*.\n* **Four‑slot grammar:** Who? → **RoleAssigning**. Can? → **Capability**. How? → **Method** (via **MethodDescription**). Did? → **Work**.\n* **Design‑time vs run‑time:** Composition of Methods ≠ composition of Work.\n* **No steps required:** Functional, logical, and hybrid MethodDescriptions are first‑class.\n* **Keep time and people out:** Schedules → **WorkPlan**; assignees → **RoleAssigning**.\n  ",
        "a.3.1:end": "### A.3.1:End\n"
      },
      "content": "### A.3.1:End\n",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.3.2",
      "title": "U.MethodDescription",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.3.2 - U.MethodDescription\n",
        "a.3.2:1___context_(plain‑language_motivation)": "### A.3.2:1 - Context (plain‑language motivation)\n\nProjects need a **stable way to express “how it is written”**—the recipe, code, SOP, rule set, or formal proof—**without confusing it** with:\n\n* the **semantic “way of doing”** (that is `U.Method`),\n* the **assignment** (that is `U.RoleAssignment`),\n* the **ability** (that is `U.Capability`),\n* the **execution** (that is `U.Work`), or\n* the **calendar plan** (that is `U.WorkPlan`).\n\n`U.MethodDescription` gives this anchor. It treats **algorithms, programs, proofs, SOPs, BPMN diagrams, solver models, playbooks** as **one class of epistemes**: *knowledge on a carrier that describes a Method*. This unifies software and “paper” procedures and lets teams switch notations without breaking the model.\n\n",
        "problem": "### A.3.2:2 - Problem (what breaks without a clear `MethodDescription`)\n\n1. **Spec/run conflation.** A flowchart or code is mistaken for the run; audits and SLOs become unreliable.\n2. **Who/time leakage.** People and calendars creep into the recipe; reuse and staffing agility die.\n3. **Step‑only bias.** Functional or logical styles are treated as “not real methods”; designs get contorted into faux steps.\n4. **Algorithm‑centrism.** Only code is considered “the method”, leaving SOPs and scientific procedures second‑class.\n5. **Structure entanglement.** BoM/PBS elements end up inside the recipe; method and product structure tangle.\n6. **Unstated equivalence.** Two specs intended to mean “the same method” are not declared equivalent; teams fork semantics by accident.\n\n",
        "forces": "### A.3.2:3 - Forces (what we must balance)\n\n| Force                              | Tension we resolve                                                                                  |\n| ---------------------------------- | --------------------------------------------------------------------------------------------------- |\n| **Representation vs. semantics**   | Many notations, one meaning: specs may differ, method stays one.                                    |\n| **Universality vs. domain idioms** | SOPs, code, solver models, proofs—all first‑class, yet domain terms remain local.                   |\n| **Timelessness vs. operability**   | Specs are timeless, but must be precise enough to drive execution and audit.                        |\n| **Reusability vs. constraints**    | Specs should declare role kinds, capabilities, safety bounds—without baking in people or calendars. |\n| **Evolvability vs. identity**      | Specs change; we need a way to evolve them without losing the method’s identity or history.         |\n\n",
        "solution": "### A.3.2:4 - Solution — the specification as an episteme describing a Method\n\n#### A.3.2:4.1 - Definition\n\n**`U.MethodDescription`** is an **`U.Episteme`** that **describes a `U.Method`** in a concrete representation (text, code, diagram, model). It is **knowledge on a carrier** that can be reviewed and validated; at run-time a **`U.System`** **uses it to execute the `U.Method` as `U.Work` under a `U.RoleAssignment`**.\n\n> **Strict Distinction (memory aid):**\n> **Method** = *how in principle* (semantic Standard).\n> **MethodDescription** = *how it is written* (artifact/description).\n> **Work** = *how it went this time* (dated execution).\n\n#### A.3.2:4.2 - Representation‑agnostic stance (independent of “algorithmic paradigm”)\n\n`U.MethodDescription` **does not privilege any single notation**. Typical forms include (non‑exhaustive):\n\n* **Imperative Spec** — SOP, BPMN/flowchart, PLC ladder, shell/pipeline scripts.\n* **Functional Spec** — compositions of pure functions, typed pipelines, category‑style combinators.\n* **Logical/Constraint Spec** — rules/goal sets, SAT/SMT/MILP models, theorem‑prover scripts.\n* **Statistical/ML Spec** — model definitions, training/evaluation procedures, inference pipelines.\n* **Reactive/Event‑driven Spec** — statecharts, observers/triggers, stream/CEP rules.\n* **Hybrid Spec** — mixtures (e.g., imperative orchestration calling solver kernels).\n\n**Same Method, different MethodDescriptions.** In a single `U.BoundedContext`, several MethodDescriptions **may describe the same `U.Method`** if they entail the **same preconditions**, **guarantee the same effects**, and meet the **same non‑functional bounds** (cf. A.3.1).\n\n#### A.3.2:4.3 - What a good MethodDescription states (paradigm‑neutral content)\n\nNot a schema—these are **content prompts** for reviewers:\n\n1. **Purpose & Name of the Method** it describes (link to `U.Method`).\n2. **Interface/ports** (inputs/outputs/resources/Standards) in the context’s vocabulary.\n3. **Preconditions** (guards, invariants, required states).\n4. **Postconditions / Effects** (what is guaranteed upon success).\n5. **Non‑functional constraints** (latency, precision, cost, safety envelope).\n6. **Role requirements** for enactment (**kinds**, not people)—to be satisfied at run time via **`U.RoleAssignment`**.\n7. **Capability thresholds** the performer must meet (checked against **`U.Capability`** of the holder).\n8. **Failure semantics** (detectable failures, compensations, rollback/forward strategies).\n9. **Compositional hooks** (how this spec composes: serial/parallel/choice/iteration), without embedding calendars.\n10. **Parameter declarations** (what may vary per run; values bound at `U.Work` creation).\n\n> **Didactic guardrail:** A MethodDescription **does not** embed a schedule, assignees, or BoM. Calendars → `U.WorkPlan`; people/units → `U.RoleAssignment`; product structure → PBS/SBS.\n\n#### A.3.2:4.4 - Epistemic roles for MethodDescriptions (via `U.RoleAssignment`)\n\nBeing an Episteme, a MethodDescription may itself play epistemic roles via `U.RoleAssignment` in a context (classification, not action), e.g.:\n\n* `ApprovedProcedureRole`, `RegulatedProcedureRole`, `SafetyCriticalProcedureRole`, `De‑factoStandardRole`.\n* These **do not** make the spec an actor; they classify its **status** within the context (who may use it, in which settings).\n\n#### A.3.2:4.5 - Constructor‑theoretic note (unifying “algorithms” and “physical recipes”)\n\nIn the constructor‑theoretic reading used by FPF:\n\n* **Algorithms, programs, solver models, proofs** are all **`U.MethodDescription`**—descriptions of Methods that transform **information**.\n* **SOPs, control recipes, lab protocols** are **`U.MethodDescription`**—descriptions of Methods that transform **matter/energy**.\n* A **universal transformer** (a system with sufficient capability) enacts **any physically admissible MethodDescription**—not only informational ones.\n\nThis keeps software and “wet lab” on equal footing.\n\n",
        "a.3.2:5___clear_distinctions_(quick_litmus_for_managers)": "### A.3.2:5 - Clear distinctions (quick litmus for managers)\n\n| You are holding…                          | It is…                         | Why                                           |\n| ----------------------------------------- | ------------------------------ | --------------------------------------------- |\n| A BPMN diagram or SOP                     | **`U.MethodDescription`**             | A description on a carrier.                   |\n| A git repo or compiled binary             | **`U.MethodDescription`**             | Still a description (even if executable).     |\n| “The way we do X in principle”            | **`U.Method`**                 | Semantic Standard beyond any single notation. |\n| A run log with timestamps                 | **`U.Work`**                   | A dated execution event.                      |\n| A role description (“surgeon”, “planner”) | **`U.Role` / `U.RoleAssignment`** | assignment, not recipe.                      |\n| “Can achieve ±0.2 mm”                     | **`U.Capability`**             | Ability of a holder, not a spec.              |\n| A calendar for next week’s runs           | **`U.WorkPlan`**               | Plan/schedule, not a recipe.                  |\n| A state‑transition law                    | **`U.Dynamics`**               | Model of evolution, not a method description. |\n\n",
        "archetypal_grounding": "### A.3.2:6 - Archetypal grounding (parallel cases)\n\n#### A.3.2:6.1 - Industrial SOP (imperative)\n\n* **Method:** `Etch_Al2O3`.\n* **MethodDescription:** `SOP_Etch_v7.pdf` + PLC ladder file.\n* **Role requirements:** `EtchOperatorRole`; **Capability:** gas‑control precision ≤ threshold.\n* **Execution:** `Tool_42#TransformerRole:Fab_A` enacts the spec → **Work** runs W‑143…W‑155.\n\n#### A.3.2:6.2 - Optimization model (logical/constraint)\n\n* **Method:** `JS_Schedule_v4`.\n* **MethodDescription:** MILP model + solver config; admissible solution definition.\n* **Execution:** `PlannerService_v4#TransformerRole:Plant_2025` produces **Work** `Run_2025‑W32‑P1`.\n\n#### A.3.2:6.3 - Clinical guideline (epistemic, status via RoleStateGraph + State Assertion)\n\n* **Method:** `AcuteAppendicitis_Triage`.\n* **MethodDescription:** clinical decision rule set; **Epistemic Role**: `RegulatedProcedureRole:Hospital_Context`.\n* **Execution:** `ER_Team#TransformerRole:ER_Shift` enacts the spec on a case → **Work** visit V‑8842.\n\n",
        "a.3.2:7___bias‑annotation_(as_in_e‑cluster)": "### A.3.2:7 - Bias‑Annotation (as in E‑cluster)\n\n* **Lenses tested:** `Did`, `Prag`, `Arch`, `Epist`.\n* **Scope declaration:** Universal; semantics are **context‑local** via `U.BoundedContext`.\n* **Rationale:** Elevates **all** procedural artifacts—code, SOPs, proofs, models—to a single class, avoiding algorithm‑centrism and step‑only bias. Keeps the strict split among **Method / MethodDescription / Work / Role / Capability**.\n",
        "conformance_checklist": "### A.3.2:8 - Conformance Checklist (normative)\n\n**CC‑A3.2‑1 (Episteme status).**\n`U.MethodDescription` **IS** an `U.Episteme` (knowledge on a carrier). It is **not** a `U.Method` (semantic way), **not** a `U.Work` (execution), **not** a `U.Role/RoleAssigning` (assignment), **not** a `U.WorkPlan` (schedule), and **not** PBS/SBS content.\n\n**CC‑A3.2‑2 (Context anchoring).**\nEvery `U.MethodDescription` **MUST** be interpreted **within** a `U.BoundedContext`. Names, Standards, and admissible non‑functional bounds are **local** to that context.\n\n**CC‑A3.2‑3 (Method linkage).**\nA `U.MethodDescription` **MUST** declare the `U.Method` it describes. Multiple MethodDescriptions **MAY** describe the same Method (see CC‑A3.2‑8).\n\n**CC‑A3.2‑4 (assignment/time‑free).**\nA MethodDescription **SHALL NOT** embed assignees, org units, or calendars. People/units are bound via **`U.RoleAssignment`** at run time; calendars belong to **`U.WorkPlan`**.\n\n**CC‑A3.2‑5 (Structure‑free).**\nBoM/PBS/SBS artifacts **SHALL NOT** be embedded in MethodDescriptions. Reference **interfaces/resources** and constraints instead of listing parts/assemblies.\n\n**CC‑A3.2‑6 (Role and capability requirements).**\nA MethodDescription **MAY** state **role kinds** and **capability thresholds** required for enactment. These are **requirements**, not bindings. They are checked at run time against `U.RoleAssignment` and `U.Capability`.\n\n**CC‑A3.2‑7 (Parameterization).**\nParameters **MUST** be **declared** in the Method/MethodDescription; concrete values are **bound** when creating `U.Work`. Default values in a spec are allowed but **SHALL NOT** force a schedule or assignee.\n\n**CC‑A3.2‑8 (Semantic equivalence).**\nTwo MethodDescriptions **describe the same `U.Method`** in a given context **iff** they entail the **same preconditions**, **guarantee the same postconditions/effects**, and satisfy the **same non‑functional bounds** for all admissible inputs/conditions of that context (per A.3.1 CC‑A3.1‑7). Differences in control flow, search, or notation do **not** break equivalence.\n\n**CC‑A3.2‑9 (Refinement).**\n`Spec₂` **refines** `Spec₁` for the same Method iff it **preserves interface**, **does not weaken** postconditions/effects, and **tightens** (or equal) non‑functional bounds under **equal or stronger** preconditions. Declare refinement explicitly in the context.\n\n**CC‑A3.2‑10 (Compatibility claims).**\nClaims such as “sound but incomplete” or “complete but potentially unsound” relative to another MethodDescription **MUST** be stated explicitly and scoped to the context (e.g., solver approximations).\n\n**CC‑A3.2‑11 (Executable specs).**\nExecutability does **not** change status: an executable artifact (program, script) is still a **MethodDescription**. Its runs are **Work**; its semantics are the **Method** it denotes.\n\n**CC‑A3.2‑12 (Epistemic roles via `U.RoleAssignment`).**\nA MethodDescription **MAY** play **epistemic roles** via `U.RoleAssignment` (e.g., `ApprovedProcedureRole`, `RegulatedProcedureRole`) that classify its status. Such bindings **do not** make the spec an actor.\n\n**CC‑A3.2‑13 (Non‑determinism declaration).**\nIf a MethodDescription permits non‑determinism (e.g., search/optimization), the **space of admissible outcomes** and **acceptance criteria** **MUST** be stated (so that Work can be judged).\n\n**CC‑A3.2‑14 (Bridging across contexts).**\nIf two contexts use different MethodDescriptions for “the same‑named way,” an explicit **Bridge (`U.Alignment`)** **SHOULD** be provided to map terms/assumptions. Do **not** assume cross‑context identity by name alone.\n\n",
        "a.3.2:9___methoddescription_mereology_(epistemic_composition;_not_method_composition)": "### A.3.2:9 - MethodDescription mereology (epistemic composition; not method composition)\n\nKeep two worlds separate:\n\n* **Method composition (design‑time semantic):** combines Methods into **new Methods** (A.3.1 §9).\n* **MethodDescription mereology (epistemic):** combines **documents/code/models** into larger **spec artifacts**. This is about **parts of the description**, not about the semantic method algebra.\n\n**Epistemic part relations (illustrative):**\n\n* **`ConstituentOf`** — a chapter/module/snippet is a constituent of a larger spec.\n* **`Imports/Uses`** — this spec reuses a library/rule set.\n* **`VariantOf`** — this spec is a variant (e.g., for different equipment) with declared deltas.\n* **`RepresentationOf`** — this visual diagram is a representation of the textual rule set.\n\n**Didactic rule:** Do not infer that a spec with two modules **means** a Method with “two steps.” Modules are **parts of the description**, not necessarily steps of the Method.\n\n",
        "a.3.2:10___parameterization_&_variability_(templates,_defaults,_configs)": "### A.3.2:10 - Parameterization & variability (templates, defaults, configs)\n\n**Templates.** A MethodDescription may serve as a **template** with parameters (e.g., temperature set‑points, solver tolerances, objective weights).\n\n**Binding time.**\n\n* **Declare** parameters in the spec;\n* **Bind** values when creating `U.Work` (or at an agreed “compile” stage);\n* Keep bound values **visible** in the Work record (so runs can be compared).\n\n**Defaults and guards.**\n\n* Defaults are allowed; list **valid ranges** and **guards** (e.g., safety constraints).\n* If a default has safety impact, state it explicitly as part of **preconditions**.\n\n**Variants.**\n\n* When variants differ only by **parameter ranges** → keep one Method with one MethodDescription template.\n* When variants differ by **Standard** (effects/bounds) → either declare a **refinement** or introduce a **distinct Method** (context decision).\n\n",
        "a.3.2:11___equivalence_&_compatibility_(across_notations_and_contexts)": "### A.3.2:11 - Equivalence & compatibility (across notations and contexts)\n\n**Within one context.**\n\n* Use **semantic equivalence** (CC‑A3.2‑8) to assert that BPMN vs code vs solver model are the **same Method**.\n* Prefer a short **equivalence note** showing parity of pre/post/bounds.\n\n**Across contexts.**\n\n* Treat identity as **not guaranteed**.\n* Provide **Bridges (`U.Alignment`)** that map terms, units, roles, and acceptance criteria.\n* Be explicit if one spec is only **sound** (never returns forbidden outcomes) vs **complete** (can return all allowed outcomes).\n\n**Observational perspective (pragmatic).**\nTwo specs are observationally equivalent for stakeholders **if**, under declared conditions, they are indistinguishable by the acceptance tests of that context (even if internal strategies differ).\n\n",
        "a.3.2:12___anti‑patterns_(and_the_right_move)": "### A.3.2:12 - Anti‑patterns (and the right move)\n\n* **Spec = run.** “Yesterday’s process log is our spec.” → The log is **Work**; write a **MethodDescription** and link runs to it.\n* **Who/time in the spec.** “Step 3 by Alice at 02:00 daily.” → Use **RoleAssigning** at run time; schedule via **WorkPlan**.\n* **Stuffing BoM.** Listing parts/assemblies inside the spec. → Reference **interfaces/resources**; keep PBS/SBS separate.\n* **Algorithm‑only bias.** Treating code as “real spec” and SOPs as “notes.” → Both are **MethodDescription**; judge by Standards, not by format.\n* **Hiding non‑determinism.** Solver model with no acceptance criteria. → Declare admissible outcome set and tests.\n* **Silent parameter capture.** Hard‑coding values without declaring parameters. → Declare parameters with ranges; bind at Work creation.\n* **Undeclared variant drift.** Copy‑pasting specs and tweaking silently. → Use **VariantOf** with stated deltas or declare a refinement.\n\n",
        "a.3.2:13___migration_notes_(quick_wins)": "### A.3.2:13 - Migration notes (quick wins)\n\n1. **Label the artifacts.** Wherever a repo/diagram/document “is the process,” rename it **MethodDescription** and link it to a named **Method**.\n2. **Extract people and calendars.** Move all assignees to **RoleAssigning** and all schedules to **WorkPlan**.\n3. **Introduce parameter blocks.** Add a small “Parameters” section with ranges/defaults and safety guards.\n4. **Write acceptance criteria.** Especially for search/optimization or ML specs.\n5. **Declare equivalence/refinement.** Where two notations intend “the same way,” add an **equivalence note**; where the new one tightens bounds, declare **refinement**.\n6. **Bridge domains.** If two departments use different vocabularies, add a **Bridge (`U.Alignment`)** rather than forcing a single spec.\n\n",
        "consequences": "### A.3.2:14 - Consequences\n\n| Benefits                                                                                                          | Trade‑offs / mitigations                                                                           |\n| ----------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------- |\n| **One class for all recipes.** SOPs, code, models, proofs become peers; teams can choose the best notation.       | **A bit more ceremony.** You name the Method and the MethodDescription separately; the payoff is clarity. |\n| **Cleaner audits.** Specs vs runs vs assignments vs abilities never mix.                                         | **Discipline required.** Keep schedules and people out of specs.                                   |\n| **Easier reuse and substitution.** Equivalence/refinement rules enable swapping notations without semantic drift. | **Equivalence is a claim.** Back it with short acceptance tests.                                   |\n| **Cross‑domain coherence.** Bridges allow controlled translation between contexts.                                | **Bridge maintenance.** Someone owns the mapping; keep it short and focused.                       |\n\n",
        "relations": "### A.3.2:15 - Relations\n\n* **Builds on:** A.3.1 `U.Method` (the semantic way it describes); A.1.1 `U.BoundedContext`.\n* **Coordinates with:** A.2 `U.Role`, A.2.1 `U.RoleAssignment` (who enacts it); A.2.2 `U.Capability` (ability thresholds); A.15 Role–Method–Work (linking `isExecutionOf` to runs).\n* **Informs:** `U.WorkPlan` (plans reference MethodDescriptions); `U.Dynamics` (models that specs may assume); Epistemic Role patterns (status of specs RoleStateGraph + State Assertion).\n* **Lexical guards:** E.10.y **L‑PROC** (do not call MethodDescription “process” when you mean Work/WorkPlan); E.10.x **L‑FUNC** (avoid “function/functionality” confusion).\n\n",
        "a.3.2:16___didactic_quick_cards": "### A.3.2:16 - Didactic quick cards\n\n* **Spec ≠ Method ≠ Work.** *Written recipe* ≠ *semantic way* ≠ *dated execution*.\n* **Keep people/time out.** Assignees → **RoleAssigning**; schedules → **WorkPlan**.\n* **Declare parameters & acceptance.** Bind values at Work; state how success is judged.\n* **Same method, different specs.** BPMN/code/solver can be equivalent **if** pre/post/bounds match.\n* **Bridge, do not blur.** Cross‑team/domain differences go through **`U.Alignment`**, not wishful thinking.\n  ",
        "a.3.2:end": "### A.3.2:End\n"
      },
      "content": "### A.3.2:End\n",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.3.3",
      "title": "`U.Dynamics`",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.3.3 - `U.Dynamics`\n",
        "a.3.3:1___context": "### A.3.3:1 - Context\n\nTeams need one place to say **how a thing changes**. Physicists call this “dynamics” (equations of motion, state‑transition maps). In IT and enterprise change, we often talk about **evolution of characteristics** (latency, cost, reliability, compliance, architectural fitness) across time. In knowledge work, **KD‑CAL** (knowledge dynamics) reasons about how the **status of claims** shifts as evidence arrives. All these are *the same modeling need*: a context‑local description of **state space** and **allowed transitions**.\n\nFPF already separates:\n\n* **what a holon is** (structure, PBS/SBS),\n* **how we act** (Method/MethodDescription, Work),\n* **what we promise** (Service).\n\nWhat is missing without `U.Dynamics` is the **law of change**—the model that tells us how states evolve **with or without** our interventions.\n\n> Intuition: **Method** tells an agent what to do; **Dynamics** tells everyone how the world (or a model of it) changes when something happens (or even when nothing happens).\n\n**Lexical note.** Terms like *process* and *thermodynamic process* are mapped by **L‑PROC**:\n\n* the **recipe** is `U.Method/MethodDescription`,\n* the **dated run** is `U.Work`,\n* the **law/trajectory model** is `U.Dynamics`.\n",
        "problem": "### A.3.3:2 - Problem\n\nWithout a first‑class `U.Dynamics`, models suffer predictable failures:\n\n1. **Recipe = Law.** Teams put the *procedure* (Method/MethodDescription) where the *state law* should be, so simulations and predictions become impossible to compare with reality.\n2. **Run = Law.** Logs of Work are mistaken for dynamics; past events are treated as if they defined what *must* happen.\n3. **No state space.** Discussions jump between metrics (latency! throughput!) without an explicit **characteristic space** or invariants, so “improvements” cannot be reasoned about.\n4. **Domain lock‑in.** “Dynamics” is left to domain vocabularies (physics, control, finance), losing a trans‑disciplinary way to speak about change in a single kernel.\n",
        "forces": "### A.3.3:3 - Forces\n\n| Force                                  | Tension                                                                                                                 |\n| -------------------------------------- | ----------------------------------------------------------------------------------------------------------------------- |\n| **Universality vs. richness**          | One kernel notion must cover ODE/PDE, Markov chains, queues, discrete events, and enterprise “fitness characteristics”. |\n| **Model vs. reality**                  | A law must be **design‑time** (an `Episteme`), yet judged by **run‑time** evidence (Work).                              |\n| **Continuous vs. discrete vs. hybrid** | Different time bases and update rules must coexist.                                                                     |\n| **Open vs. closed systems**            | Exogenous inputs (control/disturbances) may be explicit or implicit.                                                    |\n| **Predictive use vs. diagnostic use**  | The same dynamics can guide planning or explain incidents; interfaces must support both.                                |\n\n",
        "solution": "### A.3.3:4 - Solution — The unified concept `U.Dynamics`\n\n**Definition (normative).**\nWithin a `U.BoundedContext`, **`U.Dynamics`** is an **`U.Episteme` that specifies a state space and a state‑transition law** (deterministic or stochastic, continuous/discrete/hybrid) for one or more holons, possibly under exogenous inputs and constraints. It **does not** prescribe what an agent should do (that is `U.Method/MethodDescription`) and **is not** the dated evolution itself (that is `U.Work` evidence).\n\n* **Type:** `U.Episteme` (design‑time model/law on a carrier).\n* **Orientation:** descriptive/predictive about **how states evolve**; can be used by Methods but remains separate from them.\n* **Judged by:** conformance of observed **Work‑derived traces** to the law and invariants.\n\n#### A.3.3:4.1 - Core structure (minimal fields)\n\n```\nU.Dynamics {\n  context        : U.BoundedContext,     // where the model’s meaning and units are defined\n  stateSpace     : CharacteristicSpace,  // explicit characteristics & units; may include topology/geometry\n  transitionLaw  : Episteme,             // equations/relations/kernels/transition matrices/rules\n  timeBase       : {continuous|discrete|hybrid},\n  stochasticity? : {deterministic|stochastic}, // incl. noise/likelihood model if stochastic\n  inputs?        : P(Characteristic),    // control/disturbances/environmental drivers\n  observation?   : Episteme,             // measurement/observation map from state to observables\n  constraints?   : Episteme,             // invariants/safety envelopes/guards\n  validity?      : Conditions,           // operating region, approximations, version, timespan\n  calibration?   : Episteme              // parameter identification / priors\n}\n```\n\n* **`stateSpace`** uses FPF **characteristics** (not “characteristics”) so we can talk about **architecture fitness** (e.g., latency, MTBF, cost) just like temperature/pressure/volume in physics.\n* **`transitionLaw`** is paradigm‑agnostic: ODE/PDE, finite‑state relation, Petri net firing, queueing kernel, Bayesian update, etc.\n* **`observation`** separates what exists from what we *measure* (key for monitoring/assurance).\n\n#### A.3.3:4.2 - What `U.Dynamics` is **not**\n\n* **Not a Method/MethodDescription:** no imperative steps or prescriptions.\n* **Not Work:** no timestamps/resources attached; evidence lives on `U.Work`.\n* **Not a Service:** no consumer promise; dynamics may underpin service SLOs but does not define the promise.\n* **Not PBS/SBS:** do not place dynamics inside structural BoMs.\n\n",
        "a.3.3:5___where_`u.dynamics`_sits_in_enactment": "### A.3.3:5 - Where `U.Dynamics` sits in enactment\n\n* **Design‑time:**\n  Methods may *reference* Dynamics for planning/control (e.g., MPC uses a plant model).\n  Services may *derive* acceptance targets from Dynamics (e.g., queueing predictions → SLO).\n\n* **Run‑time:**\n  Work produces **state samples/telemetry**; applying the **observation** map yields traces.\n  Conformance/violation is decided by comparing traces with **constraints** and predictions from the transition law.\n  Updates to model parameters flow via **calibration** (design‑time again).\n\n> Memory hook: **Method decides**, **Dynamics predicts**, **Work reveals**.\n",
        "a.3.3:6___prediction_use_in_gating_(normative)": "### A.3.3:6 - Prediction Use In Gating (normative)\n\nWhen **predicted** coordinates (from a dynamics model) are used for **comparison or gating**, one of the following **MUST** hold:\n1) a **fresh observation** is available for the gate’s window; or\n2) the applied flow/map `Φ_{Δt}` is proven **non‑expansive** (Lipschitz ≤ 1) under the declared distance overlay (see § 5.1.7), **and** it **commutes** with the invariantization step (§ 5.1.6) — i.e., `Quot/Fix_g ∘ Φ_{Δt} = Φ_{Δt} ∘ Quot/Fix_g` on the domain of use.\n\nIf neither condition is satisfied, using prediction for gating is **forbidden**; the system **MUST** fall back to observation. Any use of `Φ_{Δt}` **SHALL** declare its validity window (range, Δt).\n",
        "archetypal_grounding": "### A.3.3:7 - Archetypal grounding (engineer‑manager friendly)\n\n| Domain                        | Holon & State Space                     | Transition Law Example               | Observation                 | Typical Questions                                                 |\n| ----------------------------- | --------------------------------------- | ------------------------------------ | --------------------------- | ----------------------------------------------------------------- |\n| **Process control**           | Reactor: {Temperature, Concentration}   | Non‑linear ODE with disturbance term | Thermocouples, analyzers    | Will we overshoot? What control horizon keeps safety constraints? |\n| **Reliability/ops**           | Service platform: {MTBF, MTTR, Backlog} | Birth–death/queueing model           | Incident logs, uptime pings | Given load, what SLO is feasible?                                 |\n| **Evolutionary architecture** | System: {Latency, Cost, Coupling}       | Discrete‑time map per release        | Perf tests, bills           | If we change X, how does latency trend next 3 sprints?            |\n| **KD‑CAL (knowledge)**        | Claim: {Belief, Support}                | Bayesian update rule                 | Evidence artifacts          | How does confidence evolve as studies arrive?                     |\n\n**Key takeaway:** one kernel object captures **trajectories in a characteristic space**, from thermodynamics to software quality and knowledge confidence.\n",
        "conformance_checklist": "### A.3.3:8 - Conformance Checklist (normative)\n\n**CC‑A3.3‑1 (Type).**\n`U.Dynamics` **IS** an `U.Episteme` (design‑time model/law on a carrier). It is **not** a `U.Method/MethodDescription`, **not** `U.Work`, and **not** a structural part of any PBS/SBS.\n\n**CC‑A3.3‑2 (Context).**\nEvery `U.Dynamics` **MUST** be declared **inside** a `U.BoundedContext`. Units, characteristic names, admissible regions, and time base are **local to the context**; cross‑context reuse requires a Bridge (`U.Alignment`).\n\n**CC‑A3.3‑3 (Explicit state space).**\n`stateSpace` **MUST** enumerate characteristics with units/scales (continuous/discrete/ordinal) and any topology/geometry needed for trajectories. Do **not** refer to informal “axes”.\n\n**CC‑A3.3‑4 (Transition law).**\n`transitionLaw` **MUST** specify a state‑transition relation/map/kernel suitable for the declared time base (`continuous|discrete|hybrid`) and stochasticity (deterministic or with a likelihood/noise model).\n\n**CC‑A3.3‑5 (Observation model).**\nIf evidence from `U.Work` is to be checked against the law, an `observation` mapping **MUST** be provided (identity is acceptable only if explicitly stated). Sampling rate/granularity **SHOULD** be declared.\n\n**CC‑A3.3‑6 (Constraints & validity).**\nIf safety/envelope constraints apply, they **MUST** be declared under `constraints`. Operating region, approximations, version, and `timespan` **SHOULD** be stated under `validity`.\n\n**CC‑A3.3‑7 (Separation from Method).**\nA `U.Dynamics` **SHALL NOT** prescribe imperative steps or responsibilities. Planning/control algorithms that *use* the dynamics belong to `U.Method/MethodDescription`.\n\n**CC‑A3.3‑8 (No actuals on Dynamics).**\nResource/time **actuals** and telemetry **MUST** attach to `U.Work`. Calibration outcomes produce **new versions** of `U.Dynamics`; the law object itself carries no run‑time logs.\n\n**CC‑A3.3‑9 (Multi‑scale declaration).**\nIf state is aggregated across parts or time, the aggregation policy (`Γ_time`, `Γ_work`, averaging vs. sum vs. percentile) **MUST** be stated to prevent incoherent comparisons.\n\n**CC‑A3.3‑10 (Lexical hygiene).**\nAmbiguous uses of *process/processual* (laws vs. runs vs. recipes) **MUST** be resolved per **L‑PROC**/**L‑ACT**:\n\n* law → `U.Dynamics`,\n* recipe → `U.Method/MethodDescription`,\n* run → `U.Work`.\n\n**CC‑A3.3‑11 (Link to Services—optional).**\nIf Service SLOs are derived from a dynamics model, the Service **SHOULD** reference that `U.Dynamics` (A.2.3), but the Service remains the promise, not the law.\n\n",
        "a.3.3:9___evidence_and_operators_(traces,_prediction,_conformance)": "### A.3.3:9 - Evidence and operators (traces, prediction, conformance)\n\nLet `D` be a `U.Dynamics` in context `C`. Let `W` be a set of `U.Work` records produced under `C`. Let `obs_D(-)` be the declared observation map for `D`.\n\n#### A.3.3:9.1 - Derived evidence\n\n* **`trace(W, D)` → Sequence\\<t, y>:**\n  derive an ordered sequence of observed values `y` at times `t` by applying `obs_D` to Work/telemetry associated with `W`. (Not a kernel type; a derived artifact for analysis/assurance.)\n\n* **`inputs(W)` → Series:**\n  exogenous inputs/control signals recovered from Work metadata if the model declares `inputs`.\n\n* **`initialState(W, D)` → x₀:**\n  the assumed/estimated state at trace start (from Work context or a stated estimation rule).\n\n#### A.3.3:9.2 - Prediction & simulation\n\n* **`predict(D, x₀, inputs?, horizon)` → Trajectory:**\n  propagate the law to obtain a predicted trajectory in the declared state space.\n\n* **`admissible(D, x)` → bool:**\n  test whether state `x` satisfies `constraints`.\n\n* **`reach(D, S₀, S₁, inputs?, horizon)` → bool:**\n  reachability: can states in `S₀` evolve into `S₁` under the law.\n\n#### A.3.3:9.3 - Conformance & drift\n\n* **`residuals(D, trace)` → Series:**\n  discrepancies between predicted and observed series under a stated alignment (point‑wise, windowed, distributional).\n\n* **`fits(D, trace, tol)` → {pass|fail|partial}:**\n  verdict under tolerance policy `tol` defined by the context (e.g., sup‑norm ≤ ε, percentile bands, likelihood threshold).\n\n* **`drift(D₁, D₂, domain)` → Measure:**\n  divergence between two model versions over a declared operating domain (e.g., max deviation of eigenvalues, KL between predictive distributions).\n\n#### A.3.3:9.4 - Invariants\n\n* `fits(D, trace, tol)=pass` ⇒ every sample lies in `admissible(D,-)` unless the context explicitly permits out‑of‑envelope transients.\n* If two traces are generated under identical `inputs` and initial conditions, recorded differences must be explainable by the declared stochasticity/noise model or flagged as violations.\n\n> **Didactic hook:** *Dynamics predicts; Work reveals; Conformance compares.*\n\n",
        "a.3.3:10___anti‑patterns_(and_the_right_move)": "### A.3.3:10 - Anti‑patterns (and the right move)\n\n* **“Dynamics = procedure.”**\n  Control recipes/step graphs belong to `Method/MethodDescription`. Keep the law in `U.Dynamics`.\n\n* **“Telemetry = dynamics.”**\n  Logs are `Work` evidence. Build `trace(Work, D)` and compare to the law; do not store logs inside the law.\n\n* **“No state space.”**\n  KPI lists without an explicit `stateSpace` turn into dashboard folklore. Name characteristics with units and ranges.\n\n* **“Hard‑coding SLO inside the law.”**\n  Service targets are promises (`U.ServiceClause.acceptanceSpec`). Keep predictions and promises separate; link them.\n\n* **“Stuffing Dynamics into BoM.”**\n  A model is not a component. Leave PBS/SBS for structure.\n\n* **“One size fits all time base.”**\n  If parts of the system evolve on different clocks, declare `hybrid` and separate update rules.\n\n",
        "a.3.3:11___migration_notes_(quick_path_to_value)": "### A.3.3:11 - Migration notes (quick path to value)\n\n1. **Name the changing things.** Pick 3–7 **characteristics** that matter (physical or architectural). Declare `stateSpace` with units and ranges.\n2. **Write the law you already use.** Even if it is a queueing approximation or a simple ARIMA—put it under `transitionLaw` and state assumptions under `validity`.\n3. **Separate recipe from law.** Move control procedures to `Method/MethodDescription`; keep forecasting/plant equations in `U.Dynamics`.\n4. **Wire evidence.** Ensure production `Work` emits the measurements needed by `observation`. Build `trace(Work, D)`.\n5. **Start conformance.** Define a simple `tol` and compute `fits(D, trace, tol)` weekly. Raise issues on drift; version the model when calibrating.\n6. **Link to promises (optional).** If SLOs depend on the law, reference `U.Dynamics` from `U.ServiceClause` and derive targets transparently.\n7. **For KD‑CAL.** Treat belief/support as characteristics; declare a Bayesian/likelihood update in `transitionLaw`; evaluate conformance against evidence arrivals.\n\n",
        "relations": "### A.3.3:12 - Relations\n\n* **Builds on:**\n  `A.1.1 U.BoundedContext` (local meaning/units),\n  `A.2 Role` / `A.2.1 RoleAssigning` (agents that *use* the law),\n  `A.15.1 U.Work` (run‑time evidence).\n\n* **Coordinates with:**\n  `A.3.1 U.Method` / `A.3.2 U.MethodDescription` (planning/control using the law),\n  `A.2.3 U.ServiceClause` (promises informed by predictions),\n  **KD‑CAL** (knowledge dynamics as a specialisation: belief‑update laws),\n  **Resrc‑CAL** (cost/energy models as dynamics over resources).\n\n* **Constrained by lexical rules:**\n  **E.10 L‑PROC** (process disambiguation), **L‑ACT** (activity/action), **L‑FUNC** (function).\n\n",
        "a.3.3:13___didactic_quick_cards_(engineer‑manager_ready)": "### A.3.3:13 - Didactic quick cards (engineer‑manager ready)\n\n* **Dynamics = Law of Change.** A design‑time model of how states evolve.\n* **State space = Named characteristics with units.** No vague “axes”.\n* **Method vs Dynamics.** Method decides *what we do*; Dynamics predicts *what will happen*.\n* **Work = Evidence.** Only Work has timestamps and resource actuals.\n* **Conformance = Prediction vs Trace.** Fit, residuals, drift.\n* **Keep promises separate.** Services are promises; Dynamics informs them but does not replace them.\n\n**Memory hook:** **Method decides - Dynamics predicts - Work reveals.**\n",
        "a.3.3:end": "### A.3.3:End\n"
      },
      "content": "### A.3.3:End\n",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.4",
      "title": "Temporal Duality & Open‑Ended Evolution Principle",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.4 - Temporal Duality & Open‑Ended Evolution Principle\n\n*“A holon is born in design‑time, lives in run‑time,  \nand is reborn when the world talks back.”*\n",
        "problem": "### A.4:2 - Problem\n\n| Failure mode | Consequence |\n|--------------|-------------|\n| **Blueprint ≡ Reality** | “As‑built” discrepancies remain invisible; safety and validity claims become fiction. |\n| **Implicit magic updates** | Versions overwrite each other; provenance chains snap. |\n| **Observer special‑case** | Measurement treated as metaphysical rather than a normal, physically grounded transformation. |\n",
        "forces": "### A.4:3 - Forces\n\n| Force | Tension |\n|-------|---------|\n| **Stability vs Change** | Identify a holon across time ↔ allow radical redesigns. |\n| **Prediction vs Evidence** | Plan with intended specs ↔ respond to real telemetry. |\n| **Parsimony vs Expressiveness** | Keep the model lean ↔ respect the full lifecycle complexity. |\n\n",
        "solution": "### A.4:4 - Solution - Temporal Duality Model\n\nFPF assigns every holon state to one—and only one—of two **temporal\nscopes**:\n\n| Scope | Symbol | Definition | Typical contents |\n|-------|--------|------------|------------------|\n| **Design‑Time** | *Tᴰ* | Interval(s) during which the holon **may be structurally altered** by an *external* `Transformer` executing a `U.TransformationalMethod`. | Specs, CAD, theorem scripts, IaC SCRs. |\n| **Run‑Time** | *Tᴿ* | Interval(s) during which the holon **executes its own `OperationalMethod`s** and is assumed structurally stable (self‑maintenance allowed). | Telemetry, transaction logs, field data, physical wear. |\n\n**Temporal invariants**\n\n```text\nTᴰ ∩ Tᴿ = ∅                     (never overlap)\nTᴰ ∪ Tᴿ = worldline(holon)      (cover full existence)\nversion(n+1) created only in Tᴰₙ (monotonic lineage)\n````\n\n#### A.4:4.1 - Open‑Ended Evolution Principle\n\nA holon may repeat the cycle *ad infinitum*:\n\n```\n(H₀ in Tᴿ₀) → observe → Δspec in Tᴰ₁ → build → H₁ in Tᴿ₁ → …\n```\n\n*Observation itself is a transformation*:\nAn **External Transformer** (`U.System` playing `transformerRole ⊑ TransformerRole`)\nexecutes a **measurement method** whose *output* is an epistemic holon\ncontaining observations.  Thus the traditional “External Observer Pattern” collapses into\nthe universal external Transformer pattern.\n\n",
        "archetypal_grounding": "### A.4:5 - Archetypal Grounding\n\n| Phase                 | Pump‑v2 (`U.System`)                                                                         | Proof‑v2 (`U.Episteme`)                                                                 |\n| --------------------- | -------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------- |\n| **Design‑Time**       | 3‑D CAD + G‑code; stress‑sim config.                                                         | Lean/Coq script of theorem; dependency graph.                                           |\n| **Run‑Time**          | Pump circulates coolant under `OperatePump` method.                                          | Theorem cited & reused; runtime is “being relied on”.                                   |\n| **Run → Design loop** | Sensor data shows cavitation; anomaly report produced by monitoring server (`transformerRole`). | New experiment contradicts corollary; lab apparatus + scientists act as `transformerRole`. |\n| **Design → Run loop** | Engineers author Pump‑v3 spec, printer (`TransformerRole`) fabricates it.                    | Community revises proof, proof‑assistant (`TransformerRole`) verifies Proof‑v3.         |\n\n*(Diagrammatic lineage table omitted for brevity but included in annex.)*\n",
        "conformance_checklist": "### A.4:6 - Conformance Checklist\n\n| ID | Requirement | Purpose |\n|----|-------------|---------|\n| **CC‑A.4.1** | Every `U.Holon` **MUST** be tagged with its current temporal scope (*Tᴰ* or *Tᴿ*). | Eliminates blueprint/reality ambiguity. |\n| **CC‑A.4.2** | A transition from *Tᴰ* → *Tᴿ* **SHALL** be modeled as `executes(Transformer, U.TransformationalMethod)`. | Guarantees physical grounding of instantiation. |\n| **CC‑A.4.3** | A transition from *Tᴿ* → *Tᴰ* **SHALL** be modeled as `executes(transformerRole, U.TransformationalMethod)` producing an observational `U.Episteme`. | Ensures observation is treated as transformation. |\n| **CC‑A.4.4** | `Tᴰ ∩ Tᴿ = ∅` and the concatenated intervals **MUST** equal the holon’s worldline. | Guards against illicit overlap. |\n| **CC‑A.4.5** | Each new design version **MUST** reference (`refinesVersion`) exactly one predecessor or declare `firstVersion = true`. | Enforces monotonic lineage for auditability. |\n\n",
        "consequences": "### A.4:7 - Consequences\n\n| Benefits | Trade‑offs / Mitigations |\n|----------|--------------------------|\n| **Audit‑Ready engineering workflow** – Every state and change is explicitly typed, timed, and causally linked to a physical system/Tramsformer. | Additional metadata tagging; mitigated by templates in Authoring Guide (E 8). |\n| **Unified View of Build & Measure** – Observation, test, simulation, maintenance, and fabrication all share one mechanism. | Requires modelers to think in terms of Transformers even for “passive” sensing; mitigated by role libraries (`transformerRole`, `CalibratorRole`, etc.). |\n| **Foundation for Learning Loops** – Enables higher patterns (e.g., B 4 Canonical Evolution Loop, D 3 Trust Calculus) to reason over evidence accrual and version fitness, including self-modification. | None significant—temporal scoping is already needed for safety‑critical provenance. |\n\n",
        "rationale": "### A.4:8 - Rationale (extended)\n\n1. **Why separate scopes?**  \n   Real‑world artefacts SCR the *as‑intended* versus *as‑is* gap.\n   By formalising that gap, FPF prevents silent assumption of perfect\n   fidelity and allows quantified error (`U.Error`) to drive evolution.\n\n2. **Why treat observation as transformation?**  \n   Physics tells us measurement changes state (energy, information, even\n   quantum collapse).  Making the observer just another `Transformer`\n   means: no special metaphysics, full energy/provenance accounting,\n   seamless tie‑in with Constructor Theory (see A 3 Rationale §2).\n\n3. **Why insist on open‑endedness?**  \n   *Perfect* finality is unattainable outside mathematics mandates that holons must be *improvable* in principle; this pattern\n   encodes that mandate structurally: version n+1 is always possible.\n\n4. **Why no overlap (*Tᴰ* ∩ *Tᴿ*)?**  \n   The instant a holon is mutable (design) it ceases to be the “same”\n   operational asset relied upon for guarantees.  Overlap would break\n   trust calculations and violate A.7 Strict Distinction.\n\nThis pattern therefore realises three core principles in concert:\n\n* **Temporal Duality** – explicit tagging of states.  \n* **Open‑Ended Evolution** – guaranteed pathway for refinement.  \n* **Ontological Parsimony** – one mechanism (Transformer) for all\n  state changes, avoiding specialised “observer” or “installer” types.\n\n> *“Blueprints dream; instances speak.  \n> Evolution is the conversation between them.”*\n ",
        "a.4:end": "### A.4:End\n"
      },
      "content": "### A.4:End\n",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.5",
      "title": "Open‑Ended Kernel & Architheory Layering",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.5 - Open‑Ended Kernel & Architheory Layering\n",
        "problem": "### A.5:2 - Problem\n\nIf FPF were to let **domain‑specific primitives creep into its Kernel**, two pathologies would follow:\n\n| Pathology               | Manifestation                                                                                                                  | Breach of Constitution                                                     |\n| ----------------------- | ------------------------------------------------------------------------------------------------------------------------------ | -------------------------------------------------------------------------- |\n| **Kernel Bloat**        | Every new field (e.g. synthetic biology) adds bespoke `U.Type`s → Core size explodes, review surface becomes unscalable.       | Violates **C‑5 Ontological Parsimony**; erodes **P‑1 Cognitive Elegance**. |\n| **Conceptual Gridlock** | Conflicting axioms (deterministic thermodynamics vs. indeterministic econ‑metrics) must fight for space in the same namespace. | Breaks **C‑3 Cross‑Scale Consistency**; triggers chronic DRR deadlock.     |\n\nA *minimal, extensible* design is therefore mandatory.\n",
        "forces": "### A.5:3 - Forces\n\n| Force                            | Tension                                                                                                                  |\n| -------------------------------- | ------------------------------------------------------------------------------------------------------------------------ |\n| **Stability vs. Evolvability**   | Immutable core needed for trust ↔ constant domain innovation needed for relevance.                                       |\n| **Universality vs. Specificity** | Single kernel language ↔ rich idioms for fields as diverse as robotics, jurisprudence, metabolomics.                     |\n| **Parsimony vs. Coverage**       | Few primitives keep reasoning elegant ↔ framework must still model energy budgets, epistemic uncertainty, agentic goals. |\n",
        "solution": "### A.5:4 - Solution\n\nFPF adopts a **micro‑kernel hour‑glass** architecture consisting of a *strictly minimal* core plus an **infinite flat namespace of plug‑ins** called *architheories*. (The formal plug‑in Standard is defined in **A.6.A Architheory Signature & Realisation**.)\n\n**1. The Open‑Ended Kernel**\nThe Kernel’s *normative* content is frozen to three buckets only:\n\n* **Foundational Ontology:** `Entity`, `Holon`, `Boundary`, `Role`, `design‑/run‑time`, etc. (A‑cluster, Part A).\n* **Universal Reasoning Patterns:** Γ‑aggregation, MHT, Trust calculus, Canonical evolution loop, etc. (B‑cluster, Part B).\n* **Ecosystem Standards:** Guard‑Rails (E‑cluster) and the Architheory Signature schema (A.6.A).\n\nEverything else—physics, logic operators beyond minimal MODAL, resource semantics, agent decision calculus—is *expelled* to architheories.\n\n**2. Architheory Layering**\n\n+To manage this extensibility without creating chaos, FPF classifies all architheories into three mutually exclusive classes, each with a distinct role. This classification governs what an architheory is allowed to do.\n\n| Class | Mnemonic | Conceptual Mandate |\n| :--- | :--- | :--- |\n| **Calculus** | **CAL** - *The Builder* | Introduces a new composite holon type and **exactly one** aggregation operator `Γ_*` that *constructs* such holons from parts. |\n| **Logic** | **LOG** - *The Reasoner* | Adds rules of inference or proof patterns *about* existing holons. **It cannot create new composite holons** and thus exports no `Γ_*` operator. |\n| **Characterization**| **CHR** - *The Observer* | Attaches metrics or descriptive properties to existing holons. **It neither constructs nor infers new holons** and exports no `Γ_*` operator. |\n\nEach architheory (CAL / LOG / CHR):\n\n* **extends** the Kernel by *importing* its primitives and *exporting* new, *typed* vocabularies;\n* remains **self‑contained**—it must **not mutate** Kernel axioms (CC‑A.6.x);\n* is versioned, compared, and substituted entirely via its *Signature* (public Standard) while permitting multiple *Realizations* (private axiom-sets).\n\nArchitheories therefore form the **“fat top & bottom”** of the hour‑glass:\n\n```\n          ┌──────────────────────────┐\n          │  Unlimited Domain CALs   │  ← e.g. Resrc‑CAL, Agent‑CAL\n          ├──────────────────────────┤\n          │  Core CAL / LOG / CHR    │  ← Sys‑CAL, KD‑CAL, Method‑CAL …\n          ╞════════ Kernel (Part A+B) ╡\n          │  Γ, MHT, Trust, etc.     │\n          ├──────────────────────────┤\n          │  Unlimited Tooling Real. │  ← simulators, proof assistants …\n          └──────────────────────────┘\n```\n",
        "archetypal_grounding": "### A.5:5 - Archetypal Grounding (System / Episteme)\n\n| Element of the Pattern                 | **Archetype 1 – `U.System`**<br>(industrial water‑pump)                                                                                                                 | **Archetype 2 – `U.Episteme`**<br>(scientific theory of gravitation)                                                                                                           |\n| -------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n| **Kernel concepts used**               | `U.System`, `U.Holon`, `TransformerRole`                                                                                                                                | `U.Episteme`, `U.Holon`, `transformerRole`                                                                                                                                        |\n| **Domain CAL that extends the Kernel** | **Sys‑CAL** adds conservation laws, port semantics, resource/work hooks                                                                                                 | **KD‑CAL** adds F‑G‑R characteristics, provenance graph, trust metrics                                                                                                                    |\n| **Resulting instance**                 | A fully specified CAD model of the pump that can be aggregated by Γ\\_sys, analysed by LOG‑CAL, and costed by Resrc‑CAL – **without ever mutating the Kernel** | A fully formalised theory object that can be cited, aggregated, and challenged by KD‑CAL, validated by LOG‑CAL, scored by the Trust calculus – **again without Kernel change** |\n\nThis table demonstrates the *hour‑glass* architecture in action:\n*Wide variety of concrete instances* → **narrow, stable Kernel neck** → *wide variety of analysis & tooling*.\n",
        "conformance_checklist": "### A.5:6 - Conformance Checklist\n\n| ID           | Requirement                                                                                                                                                     | Purpose                                                          |\n| ------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------- |\n| **CC‑A.5.1** | The Conceptual Kernel **MUST NOT** declare any `U.Type` that is specific to a single scientific or engineering discipline.                                      | Prevents kernel bloat; enforces **Ontological Parsimony (C‑5)**. |\n| **CC‑A.5.2** | Every architheory **MUST** supply a `U.ArchitheorySignature` (see A.6.A) that lists all new types, relations, and invariants it introduces.                       | Enables plug‑in discoverability and versioned evolution.         |\n| **CC‑A.5.3** | A normative pattern or invariant defined in one architheory **MUST NOT** override a Kernel pattern, but **MAY** *refine* it by additional constraints.          | Preserves Kernel immutability while supporting specialisation.   |\n| **CC‑A.5.4** | Dependency edges between architheories **MUST** point *toward the Kernel* (acyclic, upward) as required by the **Unidirectional Dependency Guard‑Rail (E .5)**. | Prevents cyclic coupling and “middle‑layer” choke‑points.        |\n| **CC‑A.5.5** | Every architheory **MUST** declare its `classification` as one of `CAL`, `LOG`, or `CHR`. Only a `CAL` may export a `Γ_*` operator. | Enforces a clear separation of concerns between constructing, reasoning, and describing. |\n ",
        "consequences": "### A.5:7 - Consequences\n\n| Benefits                                                                                                                           | Trade‑offs / Mitigations                                                                                                                                                        |\n| ---------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **Kernel stability for decades:** small, conceptually elegant nucleus rarely changes; archival citations remain valid.             | **Extra discipline for authors:** every domain team must package work as a CAL/LOG/CHR plug‑in. *Mitigation:* E.8 style‑guide and pattern templates automate most boiler‑plate. |\n| **Unlimited, parallel innovation:** biology, economics, quantum computing can all add CALs without waiting on a central committee. | **Potential overlap of CALs:** two teams might publish competing resource calculi. *Mitigation:* coexistence is allowed; the Trust layer lets users choose.                     |\n| **Clear “API” boundary:** tool builders know the exact, minimal surface they must support – boosting interoperability.             | —                                                                                                                                                                               |\n",
        "rationale": "### A.5:8 - Rationale\n\n*Micro‑kernels* succeeded in operating‑system research because they separated **immutable primitives** (threads, IPC) from **replaceable servers** (file‑systems, network stacks).\nFPF adopts the same strategy:\n\n* **Immutable primitives** → the Part A Kernel (holons, roles, transformer quartet, temporal scopes, constitutional C‑rules).\n* **Replaceable servers** → architheories in Part C (each with its own calculus, logic, characterisation kit).\n\nThis delivers on **P‑4 (Open‑Ended Kernel)**, **P‑5 (Plugin Layering)** and keeps the framework aligned with modern proof‑assistant ecosystems (Lean’s *mathlib* vs. core).\n\nThe “hour‑glass” brings two further advantages:\n\n1. **Pluralism with auditability** – rival CALs can coexist; the Kernel’s Trust pipeline (B.3) quantifies their evidence base.\n2. **Future‑proofing** – if a genuinely new substrate (e.g., quantum knowledge objects) emerges, it plugs in at the bottom layer without touching Part A.\n",
        "relations": "### A.5:9 - Relations\n\n* **Instantiates:** P‑4, P‑5, and relies on Guard‑Rails E.5 (especially Unidirectional Dependency).\n* **Provides Standard for:** every entry in **Part C**; style enforced via **Architheory Signature & Realization (A .6)**.\n* **Feeds:** Trans‑disciplinary reasoning operators in **Part B** – Γ, MHT, Trust, Evolution Loop all treat each CAL uniformly through the Kernel neck.\n\n> *“A stable neck sustains an ever‑growing hour‑glass.”*\n",
        "a.5:end": "### A.5:End\n\n# **Cluster A.IV.A - Signature Stack & Boundary Discipline (A.6.\\*)**\n"
      },
      "content": "### A.5:End\n\n# **Cluster A.IV.A - Signature Stack & Boundary Discipline (A.6.\\*)**\n",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.6",
      "title": "Signature Stack & Boundary Discipline",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.6 - Signature Stack & Boundary Discipline\n\n> **Type:** Architectural (A)\n> **Status:** Stable\n> **Normativity:** Mixed (normative only where explicitly marked; routing semantics live normatively in A.6.B)\n> **Placement:** Part A → A.6.\\* (cluster overview; coordinates A.6.0 / A.6.1 / A.6.3 / A.6.B / A.6.A / A.6.5 / A.6.6 / A.6.7)\n> **Builds on:** E.8 (authoring template), A.6.B (Boundary Norm Square — quadrant semantics & link discipline), A.6.0 (U.Signature), A.6.1 (U.Mechanism), A.6.3 (U.EpistemicViewing — views as episteme-level projections under viewpoints), E.17.0 (U.MultiViewDescribing), E.17 (MVPK — fixed face kinds & “no new semantics” publication), A.7 (Object≠Description≠Carrier), F.18 (promise/utterance/commitment), E.10.D2 (I/D/S vs Surface), E.10/L‑SURF (Surface token discipline)\n> **Purpose (one line):** Keep boundary claims evolvable by routing each statement to the right layer of the Signature Stack and the right quadrant of the Boundary Norm Square (A.6.B).\n>\n> **Mint/reuse (terminology):** Mints “Signature Stack”, “Boundary Discipline Matrix”, and “Claim Register” as local authoring aids; reuses existing FPF meanings of `U.View`/`U.Viewpoint` (E.17.0/A.6.3) and reserves “Surface” for PublicationSurface/InteropSurface (L‑SURF). The labels **L/A/D/E** used below are *routing labels for statements*, not MVPK face kinds and not pattern IDs.\n>\n**Canonical companion.** The square itself (quadrant definitions, form constraints, and cross‑quadrant dependency discipline) is specified normatively in **A.6.B — Boundary Norm Square**. This overview only (i) maps quadrants onto the Signature Stack, and (ii) explains how MVPK faces project the canonical routed claim set. If anything in this overview conflicts with A.6.B, **A.6.B is authoritative**.\n\n**Conventions:** The key words **MUST**, **MUST NOT**, **SHOULD**, **SHOULD NOT**, **MAY**, and **SHALL** are to be interpreted as in RFC 2119/8174. Lower‑case “must/may/should” in explanatory prose is descriptive, not normative.\n\n**Statement identifiers (recommended):** Adopt the quadrant‑prefixed ID scheme from **A.6.B:0** for routable statements:\n`L-*` (law/definition), `A-*` (admissibility gate), `D-*` (deontic/commitment), `E-*` (effect/evidence).\nOther sections and faces **SHOULD** refer to these IDs instead of restating the same constraint in new words.\nIDs are intended to be “lintable” anchors (and are especially useful when D‑duties enforce A‑gates or E‑claims). Consider pairing IDs with a lightweight Claim Register (A.6.B:7) to reduce paraphrase drift across faces.\n**Non-collision note (informative):** The `A-*` prefix here is “Admissibility”, not Part‑A numbering and not MVPK’s `AssuranceLane` face kind. If this is a readability hazard in your program, prefer an explicit `G-*` (“Gate”) local convention while keeping the quadrant name “Admissibility”.\n\n**Claim Register (informative, recommended).** Use the Claim Register mini‑artifact in **A.6.B:7**. In this cluster the register is additionally used to record stack placement (Signature/Mechanism/Norms/Evidence) and the MVPK faces that cite each claim (`viewRef`/`viewpointRef`), so “no paraphrase drift” can be audited mechanically.\n",
        "problem": "### A.6.C:2 — Problem\n\nHow can an author write (or repair) contract-language so that:\n\n1. **Agency is not misattributed** to descriptions (signatures, docs, specs, “interfaces”),\n2. **Governance statements** (obligations/commitments) are distinguishable from **admissibility gates** and from **semantic laws**,\n3. **Operational “guarantees”** become adjudicable via explicit evidence expectations, without smuggling evidence into semantics,\n4. **Multi-view publication** (MVPK faces) does not create “multiple contracts” by paraphrase drift?\n",
        "forces": "### A.6.C:3 — Forces\n\n| Force                      | Tension                                                                                                                                           |\n| -------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------- |\n| Conversational convenience | People will keep saying “contract”; banning the term is unrealistic.                                                                              |\n| Ontological correctness    | “Contract” is a metaphor unless we explicitly locate who promises/commits and what can be evidenced.                                              |\n| Boundary diversity         | Software APIs, hardware connectors, protocols, and SLAs share the “contract” word but differ in what is adjudicated and how.                      |\n| Multi-view publication     | Faces are necessary for audience fit, but rephrasing easily creates new commitments.                                                              |\n| Adjudicability             | “Guarantee” claims must either be (i) semantic truths, (ii) deontic commitments, or (iii) evidenced properties—otherwise they are empty rhetoric. |\n| Minimality                 | The unpacking should be lightweight enough to apply during routine authoring and review.                                                          |\n",
        "solution": "### A.6.C:4 — Solution\n\nA.6.C introduces a **Contract Bundle** lens for boundary writing. It is not a new foundational entity kind; it is a disciplined way to interpret and rewrite contract-language so it becomes routable under A.6.B.\n\n#### A.6.C:4.1 — The Contract Bundle (four-part unpacking)\n\nWhenever a text uses “contract / guarantee / promise / SLA / interface agreement” language, unpack it into four parts:\n\n1. **Service Clause (Promise content)**\n\n   * The promised value/effect (the promise *content*) in the intended scope.\n * In FPF terms (A.2.3), **`U.ServiceClause` is promise content**—a **service clause**, not an execution event (`U.Work`) and not (by itself) an accountable deontic binding (`U.Commitment`). (`U.Service` is a legacy alias; do not mint it in new normative text.)\n * **Prose head rule (normative).** When referring to `U.ServiceClause` (legacy alias: `U.Service`) in normative prose, authors SHALL use the head phrase **service clause** (or **service promise clause**) and SHALL NOT rely on the bare head noun *service*. If the surrounding text also talks about endpoints/systems/operations, apply **A.6.8** to select facet‑typed phrases (service access point / service delivery system / service delivery work / …) rather than collapsing them into “service”.\n   * **Recommendation:** give the promise-content a stable local ID (e.g., `SVC-*`) so it can be cited from commitments, gates, evidence, and MVPK faces without paraphrase drift.\n * **Routing discipline:** keep the semantics/definitions of the promised behavior in **L**; express *who is accountable for satisfying the promise* as a **D** claim (`U.Commitment`) that **references** the `U.ServiceClause` (plus any `A-*`/`E-*` claims as needed).\n\n2. **Utterance Package (speech act + published descriptions)**\n\n   * The work occurrence of stating/publishing/approving (a `U.SpeechAct <: U.Work`, A.2.9) **and** the utterance descriptions it produces or updates (versioned **epistemes** on carriers) that host the routed claim set.\n   * A speech act **may** institute/update commitments, but only under an explicit context policy that recognizes that `actType` as having such institutional force.\n   * The published utterance descriptions (signature/mechanism spec + MVPK faces) host routed claims (L/A/D/E). The act is not “the contract”; it is the work occurrence that created/updated the descriptions and (when recognized) the associated commitments.\n   * **Default interpretation rule (normative).** A conformant boundary model **MUST NOT** infer or assume any `U.Commitment` objects solely from the presence of a `Publish`/`Approve` `U.SpeechAct`. Publication creates/updates utterance descriptions and MAY institute publication/status claims (e.g., “Published”, “Approved as Standard”, “Deprecated”), but commitments exist only when represented explicitly as `U.Commitment` records (A.2.8).\n   * If a bounded context defines a policy that maps certain publish/approve act types to commitment-instituting effects (e.g., a named `SpecPublicationPolicy@Context`), the model **MUST** cite that policy, and any resulting commitments **MUST** still be represented explicitly as one or more `U.Commitment` objects with accountable subjects (not inferred from publication alone).\n\n3. **Commitment (Deontic accountability relation)**\n\n   * The accountable agent/role bound to obligations/permissions/prohibitions (including being accountable for satisfying a service clause).\n   * This bundle part is the **D‑side commitment object**: by default, one or more `U.Commitment` records (A.2.8).\n   * **Default checklist (A.2.8 minimal structure):**\n     * `id` (stable; often the `D-*` claim ID),\n     * `subject` (accountable role/party; never an episteme),\n     * `modality` (normalized deontic token / BCP‑14 family),\n     * `scope` (`U.ClaimScope`) and `validityWindow` (`U.QualificationWindow`),\n     * `referents` (by reference/ID: service clause IDs like `SVC-*`, plus `L-*`/`A-*`/`MethodDescriptionRef(...)`/`ServiceRef(...)` as needed),\n   * `referents` (by reference/ID: service clause IDs like `SVC-*`, plus `L-*`/`A-*`/`MethodDescriptionRef(...)`/`ServiceClauseRef(...)` as needed),\n     * optional `owedTo` (beneficiary/counterparty),\n     * optional `adjudication.evidenceRefs` when the commitment is meant to be auditable (point to `E-*`),\n     * optional `source` when authority/provenance matters (issuer + instituting `speechActRef` + description reference),\n     * optional `notes` for explicitly informative commentary (not part of the binding).\n   * A commitment is not “the spec text”: utterance descriptions carry the statement, but the binding is the `U.Commitment` object (A.7 / A.2.8).\n4. **Work + Evidence (Adjudication substrate)**\n\n   * The executed work and the observable carriers/traces that can adjudicate whether a commitment was met.\n   * This is **E quadrant**: “what evidence is produced/exposed/retained, under what conditions, and how it is interpreted”.\n   * Work is not “the contract”; it is what makes any operational claim testable.\n   * In FPF terms, evidence is normally expressed as **carrier‑anchored `E-*` claims** (often backed by `U.EvidenceRole` assignments on epistemes with provenance from Work).\n\n#### A.6.C:4.2 — Routing recipe into A.6.B (L/A/D/E)\n\nAfter unpacking, route each **atomic** statement using the Boundary Norm Square as defined normatively in **A.6.B** (quadrant semantics + form constraints + cross‑quadrant reference discipline). A.6.C does not redefine `L/A/D/E`; it applies them to contract-language as follows:\n\n* **Service clause → L/A (promise semantics + eligibility).**\n  * Put meanings, invariants, and metric definitions for what is promised in **L** (`L-*` in signature laws/definitions).\n  * Put “eligible/covered/valid iff …” predicates as **A** (`A-*` admissibility/gate predicates), not as deontic obligations.\n* **Commitment → D (who is accountable).**\n  * Put “MUST/SHALL/commits to …” statements as **D** (`D-*`), preferably as `U.Commitment` payloads (A.2.8).\n  * If compliance requires satisfying/enforcing a gate, the commitment **MUST** reference the relevant `A-*` ID(s) (D→A).\n  * If the commitment is meant to be auditable, include evidence hooks by referencing `E-*` (D→E), preferably via `U.Commitment.adjudication.evidenceRefs`.\n* **Work + Evidence → E (how we can tell).**\n  * Put observable traces, audit records, measurement windows, and carrier semantics as **E** (`E-*`) with explicit carrier and observation/measurement conditions (A.6.B:5.4).\n**Keyword placement rule (canonical claim set).**\nWithin the canonical routed claim set, BCP‑14 norm keywords (RFC 2119 + RFC 8174)—and their common synonyms (e.g., SHALL, REQUIRED, RECOMMENDED, OPTIONAL)—belong in **D** claims only, expressed as `U.Commitment.modality` and normalized per **A.2.8**. Authors **SHOULD** avoid using these keywords in **L/A/E** claims; phrase **L** as definitions/invariants (“is defined as…”, “holds iff…”), **A** as predicates (“is admissible iff…”), and **E** as observable/evidenced properties. If a BCP‑14 keyword (or synonym) appears in an **L/A/E** claim, it **SHOULD** be rewritten into predicate/definition form (or explicitly marked informative) before publication.\n\nA helpful rewrite rule:\n\n> If a sentence mixes “when allowed” + “who must comply” + “how we can tell”, decompose it into an **A** predicate, a **D** duty referencing that predicate, and an **E** evidence claim referencing that predicate (per A.6.B triangle decomposition).\n\n#### A.6.C:4.3 — “Guarantee” disambiguation\n\nTreat “guarantee” as ambiguous until routed:\n\n* **Semantic guarantee** → **L** (“by definition / invariant”).\n* **Governance guarantee** → **D** (“provider commits / implementer must”).\n* **Operational guarantee** → **E** (measured property with evidence expectations; optionally referenced by D as the adjudication target).\n\nIf none of these fits, the statement is likely rhetorical and should be rewritten or explicitly marked as aspirational/informative.\n\n#### A.6.C:4.4 — MVPK faces are not second contracts\n\nA contract bundle has one canonical claim set. Publication faces are **views** of that set under viewpoints:\n\n* Faces may **select, summarize, and render** claims for audiences.\n* Faces must not **introduce new semantic commitments** beyond the underlying claim set.\n* Any face-level decision-relevant / normative-looking statement **SHOULD** cite the underlying claim ID(s). If it cannot be traced to claim IDs, it **MUST** be explicitly presented as informative commentary.\n\n**Keyword rule (faces).**\nIf a face contains BCP‑14 norm keywords (RFC 2119 + RFC 8174), including common synonyms (SHALL, REQUIRED, RECOMMENDED, OPTIONAL), then each such sentence MUST be a projection of an existing **D‑*** claim (`U.Commitment`) and MUST cite the underlying **D** claim ID(s).\nIf a sentence cannot be traced to **D‑*** claim IDs, it MUST be rewritten to remove BCP‑14 keywords (e.g., turn it into explanatory prose that cites the relevant claim IDs) or moved out of the face.\nTo avoid keyword‑evasion, equivalent deontic phrasings (e.g., “is required to…”, “is prohibited from…”) SHOULD follow the same trace-by-ID discipline even when no BCP‑14 keyword is present.\n\nProjection may be paraphrased for audience fit, but it **MUST NOT** change the deontic/semantic content; if exactness is critical or disputed, use verbatim.\n\nThis prevents faces from becoming “second contracts” by paraphrase drift.\n\n#### A.6.C:4.5 — Default artefact: Contract Claim Register (recommended)\n\nUse the **A.6.B Claim Register** (IDs + statements + quadrant + anchor). Add two optional columns that make A.6.C auditable without adding new ontology:\n\n* `bundleId: ContractBundleId` (local stable ID grouping the claims that constitute one boundary “contract bundle”)\n* `bundlePart ∈ {ServiceClause, Utterance, Commitment, WorkEvidence}`\n* `faceRefs = {PlainView|TechCard|InteropCard|AssuranceLane : …}` (where the claim is rendered)\n",
        "archetypal_grounding": "### A.6.C:5 — Archetypal Grounding (Tell–Show–Show)\n\n#### A.6.C:5.1 — Tell\n\nIf you use contract-language for a boundary, do not treat “the interface/spec” as an agent. Instead:\n\n1. Identify the **service clause** (promise content) being promised,\n2. Identify the accountable **Commitment** holder(s) (roles/agents),\n3. Identify the **Utterance** surfaces that publish the boundary (signature/mechanism + MVPK views),\n4. Identify the **Work + Evidence** carriers that could adjudicate whether commitments were met,\n5. Route each claim through **L/A/D/E** and reference across quadrants rather than paraphrasing.\n\n#### A.6.C:5.2 — Show (System archetypes)\n\n**(A) Software API boundary**\n\n*Draft wording (contract soup):*\n“The Payments API guarantees idempotency. Clients must provide `Idempotency-Key`. We log all requests. Availability is 99.9%.”\n\n**Unpack + route:**\n\n* **Utterance:** signature/mechanism publication for `PaymentsAPI` (MVPK faces: TechCard, InteropCard).\n* **L:** define idempotency and the uniqueness semantics of `Idempotency-Key`.\n  (“Idempotent” is a semantic property, not a duty.)\n* **A:** admissibility predicate: request is admissible iff `Idempotency-Key` is present and valid.\n  (Gate belongs to mechanism.)\n* **D:** client implementers are obligated to satisfy the gate; provider implementers are accountable for the idempotency behavior **as defined in L** when the gate holds; provider commits to the availability target (scoped by window/exclusions).\n  (Name the committing role; do not say “the API commits”.)\n* **E:** evidence expectations: audit/log carriers include request id, idempotency key, rejection reason; availability measurement uses defined window and signal definition.\n\n**(B) Hardware interface boundary**\n\n*Draft wording:*\n“The connector guarantees safe operation. Devices must not exceed 20V. Negotiation must succeed before power is applied.”\n\n**Unpack + route:**\n\n* **Utterance:** published interface spec (pinout, electrical ranges, handshake procedure).\n* **L:** electrical invariants / allowable ranges are definitions and invariants (truth-conditional).\n* **A:** admissibility predicate: power delivery is admissible only after handshake state reaches an agreed mode.\n* **D:** manufacturer/integrator obligations: implement handshake; enforce voltage constraints.\n* **E:** evidence: test-report carriers; measurement traces; observable negotiation logs (if exposed), or lab measurements under a declared method.\n\n#### A.6.C:5.3 — Show (Episteme archetypes)\n\n**(C) Multiparty protocol boundary (behavioural/session type motif)**\n\n*Draft wording:*\n“The protocol guarantees progress. Participants must follow the sequence.”\n\n**Unpack + route:**\n\n* **Utterance:** protocol description (could be a type/protocol spec plus explanatory views).\n* **L:** safety/progress properties as laws over the protocol model (truth-conditional, within the theory).\n* **A:** admissibility: when an interaction trace is considered valid/admissible (e.g., runtime checks; compilation checks; gating conditions for entering a session).\n* **D:** obligations on implementers/operators: implement the protocol; do not send messages outside the allowed state machine; publish conformance artefacts if required.\n* **E:** evidence: message trace carriers; conformance test run artefacts; audit trails for disputed interactions.\n\n**(D) Socio-technical “SLA + audit trail” boundary**\n\n*Draft wording:*\n“Provider shall respond within 4 hours for Severity‑1 incidents. Only Severity‑1 is covered. Evidence is provided by ticket logs.”\n\n**Unpack + route:**\n\n* **Service (promise):** responsiveness promise for a defined incident class and window.\n* **Utterance:** SLA publication (and its views for different audiences).\n* **A:** admissibility predicate for the promise: ticket qualifies iff severity classification meets stated conditions.\n* **D:** provider commitment to meet the target; client duties (e.g., provide required info); auditor duties if applicable.\n* **E:** evidence: ticket carriers, timestamps, classification records, and the measurement procedure binding “4 hours” to a time window and clock source.\n",
        "bias‑annotation": "### A.6:6 - Bias‑Annotation\n\nLenses tested: **Gov**, **Arch**, **Onto/Epist**, **Prag**, **Did**. Scope: **Universal** for boundary descriptions in A.6.\\*.\n\n* **Arch bias:** Strongly biases toward separation of concerns and explicit layering; mitigated by allowing multiple faces (views) so audiences are not forced into the same detail level.\n* **Onto/Epist bias:** Treats signatures/mechanisms as epistemes that must not be conflated with work; mitigated by explicit evidence surfaces and carriers.\n* **Gov bias:** Prefers auditable responsibility (viewpoint accountability and commitment unpacking); mitigated by keeping the stack conceptual and tool‑agnostic.\n",
        "conformance_checklist": "### A.6.C:7 — Conformance Checklist\n\nA boundary description conforms to A.6.C iff it satisfies all items below:\n\n1. **CC‑A.6.C‑1 (Unpacking when contract-language appears).**\n   If the text uses “contract/guarantee/promise/SLA” language, it **SHALL** explicitly disambiguate the statement as referring to at least one of: **Service clause (promise content)**, **Utterance (published description)**, **Commitment (deontic binding)**, **Work+Evidence (adjudication)**.\n\n2. **CC‑A.6.C‑2 (No agency to epistemes).**\n   The text **MUST NOT** attribute promising/committing/obligating agency to signatures, mechanisms, interfaces, or documents. Any duty/commitment **SHALL** name an accountable role/agent.\n\n3. **CC‑A.6.C‑3 (Route contract-bearing statements via A.6.B).**\n   Contract-bearing statements **SHALL** be routable as atomic claims to **L/A/D/E**, with dependencies expressed by explicit references rather than paraphrase.\n\n4. **CC‑A.6.C‑4 (Service clause ≠ Work discipline).**\n   Statements about what is executed/observed **SHALL** be expressed as **E** claims about work/evidence/carriers. Promise‑content language **SHALL** refer to the **service clause** (`U.ServiceClause`, A.2.3; legacy alias: `U.Service`) and its **L‑defined** semantics (and to explicit **D‑*** commitments represented as `U.Commitment`, A.2.8), not to execution events (`U.Work`) or runtime effects.\n   Unqualified head‑noun *service* (and the co‑moving cluster *service provider* / *server*) in normative boundary prose SHALL be unpacked per **A.6.8 (RPR‑SERV)**.\n\n5. **CC‑A.6.C‑5 (Evidence hook for operational guarantees).**\n   If a “guarantee” is operational (requires reality to decide), the text **SHALL** include an **E** claim that states what evidence would adjudicate it (even if the evidence surface is abstract/conceptual).\n\n6. **CC‑A.6.C‑6 (No second contracts via faces).**\n   MVPK faces **MUST NOT** add new commitments beyond the underlying routed claims; faces may only project/summarize/select from the canonical claim set under a viewpoint.\n\n7. **CC‑A.6.C‑7 (RFC‑keyword discipline inside faces).**\n   If an MVPK face contains BCP‑14 norm keywords, each BCP‑14 sentence **MUST** cite the underlying **D‑*** claim ID(s) (`U.Commitment`) it is projecting. If it cannot, the face is non‑conformant until rewritten (no BCP‑14 keyword) or moved out of the face.\n\n8. **CC‑A.6.C‑8 (No commitment-by-publication default).**\n   A `Publish`/`Approve` utterance (including publishing a `…Spec`) MUST NOT be treated as instituting `U.Commitment` objects by default. If a Context policy maps publication acts to binding effects, the policy SHALL be cited, and any resulting bindings SHALL still be represented explicitly as `U.Commitment` objects with accountable subjects.\n",
        "common_anti‑patterns_and_how_to_avoid_them": "### A.6:8 - Common Anti‑Patterns and How to Avoid Them\n\n| Anti‑pattern                   | Symptom                                                         | Why it fails                                                                     | How to avoid / repair                                                                        |\n| ------------------------------ | --------------------------------------------------------------- | -------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------- |\n| **Gate‑as‑law**                | Preconditions written as “laws” in the signature                | Breaks substitution; violates A.6.0’s separation of signature vs mechanism gates | Move predicates to Mechanism.AdmissibilityConditions; keep signature laws truth‑conditional. |\n| **RFC‑keywords in invariants** | “MUST” appears inside `Definition:` blocks                      | Confuses deontics with mathematical admissibility; undermines auditability       | Rewrite as declarative predicate; reference predicate IDs from CC when needed.               |\n| **Paraphrase drift**           | Same constraint restated in multiple faces with new wording      | Creates hidden divergence; breaks routing discipline and evidence accountability | Use `…-*` IDs + Claim Register; faces reference IDs rather than restating text.              |\n| **Interface‑as‑promiser**      | “The interface promises…” without identifying an agent          | Ontological category error; contracts are agent commitments                      | Apply **F.18:16.1** unpacking: who commits, via which published utterance, to what service clause.           |\n| **Evidence‑free guarantees**   | “Guaranteed latency” without measurement/evidence story         | Effects exist only in work; without carriers it’s non‑testable                   | Bind to carriers (metrics/traces) and specify the evidence surface (what gets logged).       |\n| **View without viewpoint**     | A “view” is published but no viewpoint accountability is stated | Readers cannot interpret omissions; multi‑view discipline collapses              | Require `viewpointRef` with every face; treat view as projection under viewpoint.            |\n| **System‑as‑agent deontics**   | “The system/service SHALL …” used where no accountable role is named | Blurs behavior semantics with enforcement; hides responsibility                   | Rewrite as (`E-*`) behavior/evidence semantics + (`D-*`) duty on implementers/operators.     |\n| **One‑doc monoculture**        | Same document mixes laws, gates, duties, and evidence           | Evolvability collapses; updates become all‑or‑nothing                            | Use the stack: separate Signature/Mechanism/Norms/Evidence faces; route by matrix.           |\n",
        "consequences": "### A.6.C:9 — Consequences\n\n**Benefits**\n\n* Category mistakes (“contract soup”) become systematically repairable.\n* Commitments become accountable (named roles) and adjudicable (evidence expectations).\n* Boundaries remain evolvable: laws, gates, governance, and evidence can evolve with controlled coupling.\n\n**Trade-offs / mitigations**\n\n* Additional authoring effort; mitigated by applying the unpacking only when contract-language appears or when a claim is used for decision/publication.\n* Some stakeholders prefer “one sentence contract”; mitigated by MVPK faces that present curated projections while keeping the underlying claim set coherent.\n",
        "rationale": "### A.6.C:10 — Rationale\n\nFPF already distinguishes signatures, mechanisms, and work/evidence layers. Contract-language is a high-frequency linguistic entry point that collapses these layers unless a disciplined unpacking is applied.\n\nF.18 provides the **naming** intuition (service/promise vs utterance vs commitment) via an NQD example; A.6.C makes that split **operational for boundaries** and extends it with the missing fourth part: **work+evidence as the adjudication substrate**. This keeps “contract” language routable under A.6.B and compatible with MVPK multi‑view discipline without relocating ontology into the naming chapter.\n",
        "sota‑echoing_(post‑2015_practice_alignment)": "### A.6:11 - SoTA‑Echoing (post‑2015 practice alignment)\n\n> **Informative.** Alignment notes; not normative requirements.\n\n* **Adopt — algebraic effects & handlers / effect systems.** Modern effect systems separate the *signature of operations* from handler semantics (e.g., Koka’s effect typing; mainstream effect handlers in OCaml 5 era). A.6 aligns by keeping the contract surface in `U.Signature` and placing execution semantics in `U.Mechanism`/Realizations, preserving substitution and evolvability.\n\n* **Adopt — session/behavioural types for protocol boundaries.** Post‑2015 practice in behavioural typing treats boundaries as typed interaction protocols with progress/safety properties. A.6’s routing matrix makes “protocol laws” (Quadrant L) explicit and separates entry gates (Quadrant A) from agent duties (Quadrant D) and runtime evidence (Quadrant E), reducing ambiguity.\n\n* **Adapt — categorical optics / lenses / bidirectional transformations.** Contemporary lenses treat boundaries as paired transformations with coherence laws; this mirrors the signature/mechanism split plus cross‑context view morphisms. In FPF, the “projection faces” (views) remain governed by viewpoints, and any cross‑context reuse must remain explicit (Bridge/CL discipline).\n\n* **Adapt — ISO/IEC/IEEE 42010 viewpoint discipline and views‑as‑queries (SysML v2 motif).** A.6 explicitly preserves viewpoint as a first‑class accountability handle: MVPK requires `viewRef` and `viewpointRef`, turning “views” into disciplined projections rather than informal screenshots.\n\n* **Adapt — DDD bounded contexts / microservice contracts.** Modern architecture practice keeps meaning local and makes crossings explicit. A.6’s stack and routing discipline provide a precise placement scheme for what is “inside the context contract” vs “at the entry gate” vs “governance duties” vs “observability evidence”.\n\n* **Adapt — observability as evidence discipline.** Post‑2015 observability practice treats traces/logs/metrics as first‑class evidence surfaces. A.6 places such claims in Quadrant E and ties them to carriers (A.7), preventing “guarantees without telemetry”.\n\n* **Adapt — Markov blankets / active inference as probabilistic boundary views.** Markov‑blanket thinking can help pick observables and diagnose “boundary leaks”, but it does not replace deontics, invariants, or admissibility gates; therefore it is a complementary *view* under a viewpoint, not the primary contract object.\n",
        "relations": "### A.6.C:12 — Relations\n\n* **Uses / is used by**\n\n  * Uses **A.6.B** for routing (L/A/D/E), atomicity, and cross-quadrant reference discipline.\n  * Used by **A.6** cluster conformance (“contract unpacking”) as the detailed, reusable form of that discipline.\n  * Complements **A.6.S** (signature engineering): contract unpacking is a common constructor step when turning prose boundaries into publishable signatures.\n  * Coordinates with **A.6.P** families: when an RPR pattern touches “contract/guarantee” language, apply A.6.C to avoid category errors. (A.6.C is **not** a specialization of A.6.P; A.6.P is relation‑precision, A.6.C is boundary‑contract disambiguation.)\n\n* **Coordinates with**\n\n  * **A.7** (Object≠Description≠Carrier) for correct placement of evidence claims.\n  * **F.12** (service acceptance) for structuring how promise-level commitments connect to evidence and acceptance windows.\n  * **E.17** MVPK “no new semantics” rule to prevent publication faces from becoming new contracts.\n",
        "a.6:end": "### A.6:End\n\n## A.6.B — Boundary Norm Square (Laws / Admissibility / Deontics / Work‑Effects)\n\n> **Type:** Architectural (A)\n> **Status:** Stable\n> **Normativity:** Normative (unless explicitly marked informative)\n> **Placement:** Part A → A.6.B (matrix module; referenced by A.6 cluster overview)\n> **Builds on:** E.8 (authoring template), A.6.0 (`U.Signature`), A.6.1 (`U.Mechanism`), A.6.3 (`U.EpistemicViewing`), E.17.0/E.17 (MVPK + “no new semantics” faces), A.7 (Object≠Description≠Carrier), F.18 (promise/utterance/commitment), E.10.D2 (I/D/S vs Surface), E.10/L‑SURF (Surface token discipline)\n> **Purpose (one line):** Provide a canonical 2×2 norm square that classifies boundary statements (L/A/D/E), constrains how each quadrant is written, and defines explicit cross‑quadrant reference rules so boundaries remain evolvable and audit‑ready.\n",
        "a.6.b:0_—_conventions": "### A.6.B:0 — Conventions\n\n**Keywords.** The key words **MUST**, **MUST NOT**, **SHOULD**, **SHOULD NOT**, **MAY**, and **SHALL** are to be interpreted as in RFC 2119/8174. Lower‑case “must/may/should” in explanatory prose is descriptive, not normative.\n\n**Quadrant labels.** This pattern uses the routing labels **L / A / D / E** as *statement quadrants*:\n\n* **L** — Laws & Definitions\n* **A** — Admissibility & Gates\n* **D** — Deontics & Commitments\n* **E** — Work‑Effects & Evidence\n\nThese labels are **routing labels for statements**, not MVPK face kinds and not pattern identifiers.\n\n**Statement identifiers (recommended).** Routable statements **SHOULD** be given stable IDs with a quadrant prefix: `L-*`, `A-*`, `D-*`, `E-*`. Other sections and views **SHOULD** reference these IDs rather than restating the same constraint in new words.\n\n**Non-collision note (informative).** The `A-*` prefix here is “Admissibility”, not Part‑A numbering and not MVPK’s `AssuranceLane` face kind. If this is a readability hazard in your program, prefer an explicit `G-*` (“Gate”) local convention while keeping the quadrant name “Admissibility”. Also avoid introducing single‑letter mnemonics for MVPK face kinds inside this cluster (MVPK has a legacy L,P,D,E mnemonic); spell face kinds in full to reduce collisions.\n\n**Atomic claim.** An **atomic claim** is a sentence (or bullet) that performs exactly one logical role and is routable to exactly one quadrant. If a sentence mixes roles, it is **not atomic** and **MUST** be split before it can be routed.\n\n**Adjudication substrate (for routing).** For the purposes of this square, an atomic claim is classified by the primary substrate that decides its satisfaction:\n\n* **In‑description / in‑theory**: satisfaction is decided from the description alone (e.g., proof/type validation), or the claim is itself a governance utterance whose content is fully determined by the text.\n* **In‑work / in‑execution**: deciding satisfaction requires observing executed work and/or inspecting carriers produced in work.\n\n**Note (important).** `D-*` claims are authored and interpreted in the description; whether they are met is typically established indirectly via referenced `E-*` claims (or other governance procedures). This does not move `D-*` into quadrant E; it clarifies the routing axis.\n\n**Modality family.** A claim is either:\n\n* **Truth‑conditional**: definitions, invariants, typing rules (“is”, “iff”, “∀”).\n* **Governance**: permissions, prohibitions, obligations, commitments (“MUST/SHOULD/MAY”, “is permitted”, “is forbidden”, “commits to”).\n",
        "a.6.b:5_—_quadrant_specifications": "### A.6.B:5 — Quadrant specifications\n\nThis section is the normative “API” of the square: what each quadrant is for, how it is written, and what it must not contain.\n\n#### A.6.B:5.1 — Quadrant L: Laws & Definitions\n\n**Intent.** State truth‑conditional content: definitions, invariants, typing/well‑formedness constraints, equational laws.\n\n**Adjudication.** In‑description: can be checked by inspection, proof, type validation, or model reasoning.\n\n**Canonical form.** `Definition:` / `Invariant:` / predicate‑style constraints using “is / iff / for all”.\n\n**Prohibitions.**\n\n* An `L-*` statement **MUST NOT** contain RFC deontic keywords (**MUST/SHALL/SHOULD/MAY**) as operators inside the law/definition itself.\n* An `L-*` statement **MUST NOT** encode runtime gate predicates (those are `A-*`).\n* An `L-*` statement **MUST NOT** assert evidence availability or measurement outcomes (those are `E-*`).\n\n**A.7 anchoring.** `L-*` claims are **Descriptions**: they specify semantics of the signature/mechanism description, not work.\n\n**Typical dependence.** `A-*` and `E-*` claims may reference `L-*` IDs for vocabulary, metric definitions, and invariants needed for interpretation.\n\n#### A.6.B:5.2 — Quadrant A: Admissibility & Gates\n\n**Intent.** Specify when a mechanism application is permitted/admissible: runtime entry predicates, authorization gates, validity gates, applicability checks that require context or execution environment.\n\n**Common mistake #0 — Applicability ≠ Admissibility (informative).** Signature `Applicability` scopes *intended use/bounded context*; it is not a runtime entry gate. Runtime entry checks and permission predicates belong in `U.Mechanism.AdmissibilityConditions` as `A-*`. If your prose reads like “clients must satisfy the applicability”, you almost certainly want a `D-*` duty + an `A-*` gate (linked by ID) instead.\n\n**Adjudication.** In‑work: evaluated at mechanism entry (or operationally at the point the mechanism is applied).\n\n**Canonical form.** Predicate style, e.g.:\n\n* “A request is admissible iff …”\n* `admissible(x) iff P(x)` (conceptual form; no particular syntax is required)\n\n**Prohibitions.**\n\n* An `A-*` statement **MUST NOT** be placed in `U.Signature.Laws`.\n* An `A-*` statement **MUST NOT** use RFC deontic keywords as if it were an agent obligation. (It is a gate predicate, not a duty.)\n* An `A-*` statement **MUST NOT** claim that evidence exists (that is `E-*`) or that someone must enforce the gate (that is `D-*`).\n\n**A.7 anchoring.** `A-*` claims are **Descriptions** of a mechanism gate. They are not “what a client must do”; they are “what the mechanism admits”.\n\n**Required references (explicit).** If an `A-*` predicate relies on defined terms or invariants, it **SHOULD** reference the relevant `L-*` IDs (or at minimum the signature that defines them).\n\n#### A.6.B:5.3 — Quadrant D: Deontics & Commitments\n\n**Intent.** State governance: obligations, permissions, prohibitions, commitments, publication duties, operational duties, contractual commitments—always with accountable agents/roles.\n\n**Adjudication.** In‑description (governance is stated in the spec); compliance may be audited via `E-*`.\n\n**Canonical form.** A deontic statement **MUST** have an accountable subject (agent/role), e.g.:\n\n* “Client implementers **MUST** satisfy `A-…`.”\n* “Operators **SHALL** retain carriers …”\n* “Provider **SHALL** meet `E-…` under exclusions …”\n\n**Canonical payload (recommended; lintable).** When a `D-*` claim is intended to be lintable/reusable, it **SHOULD** be representable as a `U.Commitment` record (A.2.8). Default fields to make explicit:\n\n* `id` (often the `D-*` claim ID),\n* `subject` (accountable role/party; never an episteme),\n* `modality` (BCP‑14/RFC keyword family normalized),\n* `scope` + `validityWindow`,\n* `referents` (by ID; e.g., `SVC-*`, `L-*`, `A-*`, `E-*`, `MethodDescriptionRef(...)`),\n* optional `adjudication.evidenceRefs` when the commitment is meant to be auditable,\n* optional `source` when authority/provenance matters.\n\n**Prohibitions.**\n\n* A `D-*` statement **MUST NOT** use “the system/service/interface/spec” as the grammatical subject unless the accountable role/party is explicitly named (so the statement is representable as a `U.Commitment` with an explicit `subject`, A.2.8). (**F.18** is a lexical anchor only.)\n* A `D-*` statement **MUST NOT** restate `L-*` or `A-*` predicates in new words when an ID exists; it **SHOULD** reference the ID.\n* A `D-*` statement **MUST NOT** pretend that commitments are laws. A commitment is an agent relation, not a truth‑conditional invariant.\n\n**A.7 anchoring.** `D-*` claims are primarily **about Objects** (roles/agents and their duties) or **about Carriers** (retention/exposure duties), but they are still written as **Descriptions**.\n\n**Required references (explicit).**\n\n* If a `D-*` statement imposes compliance with a gate, it **MUST** reference the relevant `A-*` ID(s).\n* If a `D-*` statement is meant to be auditable, it **SHOULD** reference the `E-*` claim(s) that provide evidence and the carrier classes involved.\n#### A.6.B:5.4 — Quadrant E: Work‑Effects & Evidence\n\n**Intent.** State what happens in work and how it can be evidenced: observed effects, emitted events, traces/logs/metrics, produced reports, measurement outcomes.\n\n**Adjudication.** In‑work: checked by running/operating and inspecting carriers produced in work.\n\n**Canonical form.** An `E-*` statement **SHOULD** include the minimum fields needed for adjudication:\n\n1. **Observation/measurement conditions** (when/where/how observed; workload/window; triggers)\n2. **Carrier class/schema reference** (A.7 Carrier) that bears the evidence\n3. **Viewpoint/consumer** (who uses this evidence and why; ties to `viewpointRef` discipline)\n\n**Prohibitions.**\n\n* `E-*` statements **SHOULD NOT** use RFC deontic keywords (they are not obligations; they describe adjudicable effects/evidence).\n* An `E-*` statement **MUST NOT** hide a gate predicate; gate predicates are `A-*`.\n* An `E-*` statement **MUST NOT** assign agency (“the interface guarantees …”); if enforceability/commitment is intended, express it as `D-*` referencing the `E-*`.\n\n**A.7 anchoring.** `E-*` claims are primarily **Carrier‑anchored**: they assert what carriers exist and how they relate to observed work.\n\n**Required references (explicit).**\n\n* If the effect/evidence is conditioned on a gate decision, the `E-*` statement **SHOULD** reference the relevant `A-*` ID(s).\n* If the evidence is interpreted using metric definitions or invariants, the `E-*` statement **SHOULD** reference relevant `L-*` ID(s).\n",
        "a.6.b:6_—_cross‑quadrant_link_discipline": "### A.6.B:6 — Cross‑quadrant link discipline\n\nThe square is not just classification; it is a **dependency discipline**. Claims often depend on each other; such dependencies **MUST** be explicit (by claim ID) rather than duplicated prose.\n\n#### A.6.B:6.1 — Explicit reference rule\n\nIf a claim’s meaning materially depends on another routed claim, that dependency **MUST** be represented as an explicit reference to the other claim’s ID (or to the canonical location where it lives), rather than by restating it.\n\n**Guideline (informative).** Treat this as “import hygiene” for prose: reuse by reference, not by copy.\n\n#### A.6.B:6.2 — Canonical cross‑quadrant dependency patterns\n\nThese patterns are allowed (and common). The square becomes operational when these links are used systematically.\n\n##### A.6.B:6.2.1 - (D → A) Duty-to-gate linkage\n\nWhen governance requires someone to comply with a gate:\n\n* `D-*`: “Role **MUST** satisfy/enforce `A-*`.”\n\nThis separates **what is admissible** (A) from **who is responsible** (D).\n\n##### A.6.B:6.2.2 - (E → A) Evidence-for-gate linkage\n\nWhen gate decisions must be observable:\n\n* `E-*`: “On rejection/acceptance due to `A-*`, carrier `C` is produced/observable under conditions …”\n\nThis separates **gate semantics** (A) from **evidence semantics** (E).\n\n##### A.6.B:6.2.3 - (D → E) Duty-to-evidence linkage\n\nWhen governance requires evidence production/retention/exposure or commits to measured properties:\n\n* `D-*`: “Role **MUST** retain/expose carrier class `C` used by `E-*` …”\n* `D-*`: “Provider **SHALL** meet `E-*` under exclusions …”\n\nThis separates **obligation/commitment** (D) from **adjudication** (E).\n\n##### A.6.B:6.2.4 - (A/E → L) Semantic grounding linkage\n\nWhen a gate predicate or measurement relies on definitions/invariants:\n\n* `A-*` / `E-*` references `L-*` that define terms/metrics.\n\nThis prevents “metric drift” and “definition drift” across views.\n\n##### A.6.B:6.2.5 - (D → L) Governance-to-definition linkage\n\nWhen an obligation/commitment relies on precise term or metric meanings:\n\n* `D-*` references `L-*` that define the terms/metrics it uses.\n\nThis keeps governance text from accidentally redefining semantics in prose.\n#### A.6.B:6.3 — The “triangle decomposition” for mixed sentences\n\n**Normative rule (decomposition).** A conforming boundary text **SHALL** decompose any mixed sentence that expresses (i) an entry condition, (ii) an obligation to satisfy/enforce it, and (iii) an observability expectation into the three quadrants:\n\n* **A:** admissibility predicate (`A-*`)\n* **D:** duty/commitment referencing the gate (`D-* → A-*`)\n* **E:** evidence binding referencing the gate (and carriers) (`E-* → A-*`)\n\nThis is the canonical repair for “contract soup” around validity, authorization, compliance, audit, and security boundaries.\n\n#### A.6.B:6.4 — Dependency direction (no “upward” imports)\n\nThe square is intended to preserve **layered modularity**: semantics should not depend on governance text, and evidence semantics should not depend on duties.\n\n**Normative rule (no upward dependencies).**\n\n* `L-*` claims **MUST NOT** depend on or reference `A-*`, `D-*`, or `E-*` claims (except for purely informative notes explicitly marked informative).\n* `A-*` claims **MUST NOT** depend on or reference `D-*` claims. (`A-*` may reference `L-*` for defined terms/invariants.)\n* `E-*` claims **MUST NOT** depend on or reference `D-*` claims. (`E-*` may reference `A-*` for conditioning and `L-*` for metric/term meanings.)\n* `D-*` claims **MAY** reference `L-*`, `A-*`, and/or `E-*` claims as needed, and **SHOULD** do so by ID rather than restating content.\n\n**Rationale (informative).** This keeps foundational meaning stable (L), keeps runtime gates independent of governance prose (A), and keeps evidence semantics independent of enforcement policy (E). Governance (D) is the place where “who must do what, using which gates and which evidence” is assembled.\n",
        "a.6.b:7_—_mini‑artifact:_claim_register_(informative,_recommended)": "### A.6.B:7 — Mini‑artifact: Claim Register (informative, recommended)\n\nA Claim Register is a drift‑control device that lists every routable statement verbatim with routing metadata. It is not a new semantic layer.\n\n| ID | Quadrant | Statement (verbatim) | Canonical location (section/artefact) | Stack layer | A.7 primary layer | viewRef | viewpointRef | References | Notes |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n\nGuidance (informative):\n* The **Statement** cell should contain the normative text as authored (copy/paste), not a paraphrase.\n* **Canonical location** should point to the one place the statement “lives” (e.g., `Signature.Laws`, `Mechanism.AdmissibilityConditions`, `TechCard.NormsCommitments`, `Evidence.Carriers`), so other faces can cite it by ID.\n* **Stack layer** should be one of `{Signature, Mechanism, Norms/Commitments, Evidence/Carriers}` to make routing auditable.\n* **A.7 primary layer** is the claim’s *primary referent* (`Object`, `Description`, or `Carrier`), even though the claim is always written as a Description.\n* Use **References** for explicit cross‑quadrant links (e.g., which `D-*` enforces which `A-*`, which `E-*` adjudicates which commitments, which `L-*` defines a metric used by `E-*`) and for external standards/policies where applicable.\n",
        "a.6.b:9_—_bias‑annotation": "### A.6.B:9 — Bias‑Annotation\n\nLenses tested: **Gov**, **Arch**, **Onto/Epist**, **Prag**, **Did**. Scope: **Universal** for boundary descriptions.\n\n* **Arch bias:** favors explicit separation and explicit references; mitigated by allowing narrative faces while keeping commitments routed and referenced by ID.\n* **Gov bias:** makes accountability explicit (D) and auditability explicit (E); mitigated by keeping evidence conceptual and carrier‑anchored rather than tool‑specific.\n* **Onto/Epist bias:** insists on Object≠Description≠Carrier and on work‑adjudicated effects; mitigated by providing clear cross‑quadrant link patterns so authors can still express real‑world governance needs.\n",
        "a.6.b:11___common_anti‑patterns_and_how_to_avoid_them": "### A.6.B:11 - Common Anti‑Patterns and How to Avoid Them\n\n| Anti‑pattern                 | Symptom                                            | Why it fails                                                | Repair (square‑consistent)                                                                  |\n| ---------------------------- | -------------------------------------------------- | ----------------------------------------------------------- | ------------------------------------------------------------------------------------------- |\n| **Gate‑as‑law**              | Preconditions written as “laws”                    | Collapses signature/mechanism boundary; breaks substitution | Move to `A-*` in Mechanism.AdmissibilityConditions; reference `L-*` terms.                  |\n| **Deontics in predicates**   | “MUST” inside definitions or gates                 | Confuses governance with truth/admissibility                | Rewrite as `L-*`/`A-*` predicate; add `D-*` duty referencing it.                            |\n| **Interface‑as‑promiser**    | “The API promises/guarantees …”                    | Category error (F.18): epistemes don’t promise              | Identify committing role (`D-*`), measured property (`E-*`), and metric definition (`L-*`). |\n| **Evidence‑free guarantees** | “Guaranteed p95 latency” with no measurement story | Unadjudicable; turns into marketing                         | Create `E-*` with carriers + conditions; link commitment as `D-* → E-*`.                    |\n| **Paraphrase drift**         | Same rule restated across faces                    | Divergence becomes invisible                                | Use IDs; faces cite IDs; optional Claim Register.                                           |\n| **View‑fork semantics**      | A face introduces new L/A/D/E content              | Violates “no new semantics” publication discipline          | Move new claim into canonical layer (L/A/D/E) or mark as informative only.                  |\n",
        "a.6.b:14_—_sota‑echoing_(post‑2015_practice_alignment)": "### A.6.B:14 — SoTA‑Echoing (post‑2015 practice alignment)\n\n> **Informative.** Alignment notes; not normative requirements.\n\n**Representative sources (post‑2015; illustrative).** See also A.6:11 for a fuller list.\n* ISO/IEC/IEEE 42010:2022 (view/viewpoint discipline).\n* Leijen (2017) / Hillerström & Lindley (2018) (effects & handlers).\n* OpenTelemetry Specification (v1.0+, 2021–) (evidence carriers as traces/logs/metrics).\n\n* **Effect systems & handlers:** clear separation between operation signature (L) and handler/runtime behavior (A/E), with governance duties (D) attached to accountable operators/implementers.\n* **Behavioural/session typing:** protocol laws (L) and admissibility (A) remain distinct from commitments (D) and runtime traces (E), improving interpretability of “progress/safety” style boundary guarantees.\n* **SRE/observability discipline:** treating traces/logs/metrics as evidence carriers (E) and separating evidence semantics from retention/exposure duties (D) mirrors contemporary operational practice while staying tool‑agnostic.\n",
        "a.6.b:end": "### A.6.B:End\n\n## A.6.C — Contract Unpacking for Boundaries\n\n> **Type:** Architectural (A)\n> **Status:** Stable\n> **Normativity:** Normative (unless explicitly marked informative)\n> **Placement:** Part A → **A.6 Signature Stack & Boundary Discipline**\n> **Builds on:** A.6 (stack + routing intent), **A.6.B** (L/A/D/E), **A.6.8 (RPR‑SERV)** (service‑cluster polysemy unpacking), **A.7** (Object≠Description≠Carrier), **A.2.3** (`U.ServiceClause` / service clause; legacy alias: `U.Service`), **A.2.4** (`U.EvidenceRole`), **A.2.8** (`U.Commitment`), **A.2.9** (`U.SpeechAct`), **A.15.1** (`U.Work`), E.10 (L‑SERV / LEX‑BUNDLE), E.17 (MVPK “no new semantics” faces), F.12 (service acceptance/evidence discipline)\n> **Lexical anchor:** **F.18** (NQD front for the *service (promise) / utterance / commitment* triad; naming, not ontology)\n> **Mint/reuse (terminology):** Reuses “contract / SLA / guarantee” as Plain-level boundary shorthand; mints **Contract Bundle** as an unpacking lens (not a new entity kind), plus optional register columns (`bundleId` / `bundlePart` / `faceRefs`). **NQD-front seeds (informative):** contract packet, agreement bundle, boundary bundle (chosen: *Contract Bundle* for low collision with existing “bundle” terms).\n> **Purpose (one line):** Prevent “contract soup” and agency misattribution by unpacking contract-language into distinct promise‑content, utterance package, commitment, and work+evidence (adjudication substrate) parts and routing each part into the Boundary Norm Square.\n",
        "bias_annotation": "### A.6.C:6 — Bias-Annotation\n\nLenses tested: **Gov**, **Arch**, **Onto/Epist**, **Prag**, **Did**. Scope: **Universal** for “contract talk” in boundary descriptions.\n\n* **Gov bias:** prefers explicit accountability and adjudication hooks; increases clarity but adds authoring overhead.\n* **Arch bias:** optimises evolvability by preventing hidden coupling (contract soup) across stack layers.\n* **Onto/Epist bias:** enforces Object≠Description≠Carrier separation; discourages “interface-as-agent” metaphors in Tech prose.\n* **Prag bias:** accepts that “contract” is common vocabulary; offers a disciplined rewrite rather than prohibition.\n* **Did bias:** aims to be teachable via repeated unpacking examples across boundary types.\n",
        "anti_patterns": "### A.6.C:8 — Common Anti-Patterns and How to Avoid Them\n\n| Anti-pattern                                        | Why it fails                                                   | Repair                                                                                      |\n| --------------------------------------------------- | -------------------------------------------------------------- | ------------------------------------------------------------------------------------------- |\n| **Interface-as-promiser** (“the API promises…”)     | Epistemes are descriptions; they do not commit                 | Name the committing role/agent; route as D claim; keep the signature as utterance substrate |\n| **Guarantee-without-substrate**                     | “Guarantee” is empty unless it is L, D, or E                   | Decide: semantic law (L), deontic commitment (D), or evidenced property (E)                 |\n| **SLA smuggled into laws**                          | Mixes governance with semantics; breaks substitution reasoning | Put SLA targets as D claims referencing L-defined metrics and E evidence                    |\n| **Gate written as obligation**                      | Confuses admissibility predicates with duties                  | Write predicate as A; write duty-to-gate as D→A reference                                   |\n| **Evidence as prose property** (“document proves…”) | Violates Object≠Description≠Carrier                            | State evidence as E claims about carriers produced/observed in work                         |\n| **Face-level paraphrase drift**                     | Creates multiple incompatible contracts                        | Faces should reference canonical claims; keep commitments centralized                       |\n| **Cross‑scale contract collapse**                   | Different agents claim incompatible “contracts” at different scales/contexts | Represent each as separate, scoped `D-*` claims (with accountable roles + Context); route conflicts to conflict/mediation patterns rather than collapsing them into one “contract”. |\n",
        "a.6.c:11_—_sota‑echoing_(informative;_post‑2015_alignment)": "### A.6.C:11 — SoTA‑Echoing (informative; post‑2015 alignment)\n\n> **Informative.** Alignment notes; not normative requirements.\n\n* **Adopt — BCP 14 (RFC 2119 + RFC 8174) norm keyword discipline for spec language.** Modern spec-writing practice treats these keywords as a disciplined modality family; A.6.C constrains where such modality belongs (D) versus where predicate-style constraints belong (A/L).\n* **Adopt — behavioural/session types for protocol boundaries (post‑2015 practice).** Protocols as typed interactions emphasize separating safety/progress properties (L) from runtime admission (A) and from implementer obligations (D), with trace-based evidence (E).\n* **Adopt/Adapt — algebraic effects & handlers / effect systems.** The “operation signature vs handler semantics” split mirrors “utterance substrate vs work/evidence”, preventing execution semantics from being conflated with contract surfaces.\n* **Adapt — ISO/IEC/IEEE 42010:2022 viewpoint discipline.** Multi-view publication is treated as viewpoints governing projections; A.6.C applies this to contract talk to avoid face-level semantic forks.\n",
        "a.6.c:end": "### A.6.C:End\n"
      },
      "content": "### A.6.C:End\n",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.6.0",
      "title": "U.Signature - Universal, law‑governed declaration for a SubjectKind on a BaseType",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.6.0 - U.Signature - Universal, law‑governed declaration for a SubjectKind on a BaseType\n\n**Status.** Architectural pattern, kernel‑level and universal.  \n**Placement.** Part A (Kernel), **before A.6.A** (“Architheory Signature & Realization”) and **A.6.1** (“U.Mechanism”).  \n**Builds on.** **A.2.6** (USM: context slices & scopes), **E.8** (authoring order), **E.10** LEX-BUNDLE (registers, naming, stratification), **E.10.D1** D.CTX (Context discipline).\n  \n**Coordinates with.** **A.6.A** (architheory specialisation of signatures), **A.6.1** (mechanism as law-governed signature), **A.6.5** (`U.RelationSlotDiscipline` for n-ary arguments), **Part F** (Bridges & cross-context transport; naming). Conformance keywords: RFC 2119.\n",
        "problem": "### A.6.0:2 - Problem\n\nIf each family (architheories, mechanisms, methods, disciplines) invents its own “signature”:\n\n1. **Tight coupling.** Private definitions leak as public standards, breaking substitutability.\n    \n2. **Lexical drift.** The same surface label (e.g., *scope*, *normalization*) hides different laws.\n    \n3. **Scope opacity.** Applicability (where the words mean what) remains implicit, violating D.CTX.\n    \n",
        "forces": "### A.6.0:3 - Forces\n\n| Force | Tension |\n| --- | --- |\n| **Universality vs. fitness** | One shape must fit **architheories**, **mechanisms**, **theories**, **methods**, **disciplines**, without over‑committing to any one of them. |\n| **Intension vs. specification (I/D/S)** | Signatures declare **what** and **the laws** (intension), not recipes or test harnesses (specification). |\n| **Simplicity vs. expressivity** | Keep the kernel small while leaving **normalized** slots for specialisations (e.g., Γ‑export in A.6.A; Transport in A.6.1). |  \n| **Locality vs. transport** | Meaning is context‑local (D.CTX), yet cross‑context use must be explicit and auditable via Bridges without smuggling implementation. |\n",
        "solution": "### A.6.0:4 - Solution — **Define `U.Signature` once, reuse everywhere**\n\n**Definition.** A **`U.Signature`** is a **public, law-governed declaration** for a named **SubjectKind** on a declared **BaseType**. Where quantification depends on context, the Signature **SHALL** expose an explicit **SliceSet** and **ExtentRule**. A Signature (i) introduces a **vocabulary** (types, relations, operators), (ii) states **laws** (axioms/invariants; no operational admissions), and (iii) records **applicability** (where and under which contextual assumptions the declarations hold). Dependencies (**imports**) are governed by specialisations (e.g., A.6.A) and are **not** part of the universal Block. **Discipline for argument-position typing is delegated to A.6.5 `U.RelationSlotDiscipline`: whenever the Vocabulary declares an n-ary relation or operator, SlotSpecs for its parameter positions SHALL be provided as in §4.1.1 and A.6.5.**\n\nWhere the **Vocabulary** introduces an **n‑ary relation or morphism**, the Signature **SHALL**, for each parameter position `i`, declare a `SlotSpec_i = ⟨SlotKind_i, ValueKind_i, refMode_i⟩` as defined in **A.6.5 `U.RelationSlotDiscipline`**. SlotSpecs live inside the per‑relation parameter block of the **Vocabulary** row and **MUST NOT** introduce additional rows beyond the four‑row Signature Block.\n\n**Arrow form (typing for MVPK).** Author a Signature as a **morphism**  \n`SigDecl : ⟨SubjectBlock⟩ → ⟨Vocabulary × Laws × Applicability⟩`  \nwhere `SubjectBlock = ⟨SubjectKind, BaseType, SliceSet, ExtentRule, ResultKind?⟩`. This makes `U.Signature` directly consumable by **E.17 MVPK** (publication of morphisms) without adding semantics on faces (no new claims; pins for any numeric content).\n\n*Guard clarification (normative).* **Operational guard predicates** (run‑time or admission guards) **BELONG ONLY** to **A.6.1 Mechanisms**. A Signature may express **domain/type constraints** intensionally (e.g., restricting an operator’s domain) but **SHALL NOT** encode operational admissions.\n\n*Guidance for deductive substrates.* Signatures that declare a **formal deductive substrate** (e.g., *FormalSubstrate*) MAY include, **as vocabulary elements**, an **EffectDiscipline** (algebraic/row/graded effect signatures) and **InferenceKind** enumerations; handler semantics are **out of scope** for Signatures (see §4.3). The universal block remains conceptual and contains **no** run‑time admissions or AdmissibilityConditions.\n\n**Naming discipline.** The `Subject` **MUST** be a **single‑sense** noun phrase; avoid synonyms/aliases within the same Signature.\n\nA `U.Signature` is **conceptual**: it contains **no implementation, no packaging/CI metadata, and no Γ‑builders**. Γ‑export, if any, is governed by **A.6.A** and only for architheories with `classification=CAL`.\n\n#### A.6.0:4.1 - The **Signature Block (universal form)**\n\nThe **four conceptual rows** (“SubjectBlock / Vocabulary / Laws / Applicability”) give a repeatable, holon‑stable pattern across mathematics → physics → engineering:  \n* **SubjectBlock** = *what it’s about + how quantified* (axiomatics + domain of interpretation),  \n* **Vocabulary/Laws** = *principles/laws* (postulates & constraints),  \n* **Applicability** = *where they hold in practice* (bounded context & time).\n\nEvery `U.Signature` **SHALL** present a **four‑row conceptual block** (names are universal; family‑specific aliases are mapped below):\n\n1. **SubjectBlock** — ⟨**SubjectKind**, **BaseType**, **SliceSet**, **ExtentRule**, **ResultKind?**⟩.  \n   *SubjectKind* names the intensional subject (C.3); *BaseType* is the `U.Type` the signature ranges over (CHR Spaces appear here **as types**, not as field names); *SliceSet* addresses the quantification domain (USM; e.g., **ContextSliceSet**); *ExtentRule* computes `Extension(SubjectKind, slice)` (C.3.2); *ResultKind?* (optional) is the intensional kind of outputs.  \n   **Editorial split (allowed).** Authors **MAY** render the **SubjectBlock** as two adjacent lines — **Subject** *(SubjectKind, BaseType)* and **Quantification** *(SliceSet, ExtentRule, ResultKind?)* — **without changing semantics**. Even when visually split, SubjectBlock counts as **one** conceptual row.\n\n   **Semantic roles of the SubjectBlock kinds (informative)**\n   * **SubjectKind (intent).** The intensional “describedEntity” of the signature (C.3.1), ordered by `⊑`. It carries no Scope.\n   * **BaseType (carrier).** The `U.Type` over which values/objects are ranged. In CHR regimes this may be a `U.CharacteristicSpace` **type**; elsewhere it is a set‑typed `U.Type`.\n   * **SliceSet (addressability).** The addressable set of `U.ContextSlice`s (USM). It identifies where **extent** is computed; it is not a “space” unless CHR.\n   * **ExtentRule (extent).** A rule yielding `Extension(SubjectKind, slice)` (C.3.2); this is the quantifier’s domain, computed per slice.\n   * **ResultKind? (outputs).** Optional: the intensional kind of the outputs of the operations declared in *Vocabulary* (use when outputs differ in kind from the SubjectKind).\n    \n2. **Vocabulary** — names and sorts of the public **types / relations / operators** this signature commits to (no handler semantics; no AdmissibilityConditions). For each **n‑ary relation or morphism** in the Vocabulary, parameters **SHALL** be declared via **SlotSpecs** `SlotSpec_i = ⟨SlotKind, ValueKind, refMode⟩` per **A.6.5 `U.RelationSlotDiscipline`**. SlotKinds and RefKinds **MUST** follow the `…Slot` / `…Ref` lexical discipline in **A.6.5** and **E.10 (LEX‑BUNDLE)**; ValueKinds **MUST** remain free of these suffixes. For each **n‑ary relation or morphism** in the Vocabulary, parameters **SHALL** be declared via **SlotSpecs**\n  \n3. **Laws (Axioms/Invariants)** — equations and order/closure laws that are context‑local truths under the stated Applicability (no proofs here). **Operational guard predicates belong to Mechanisms (A.6.1)**, not to Signatures.\n    \n4. **Applicability (Scope & Context)** — conditions under which the laws are valid (bounded context, plane, stance, time notions). Applicability **MUST** bind a **`U.BoundedContext`** (D.CTX). Cross‑context use **MUST NOT** be implicit; if intended, **name** the Bridge (conceptual reference only). When numeric comparability is implied, **bind** legality to **CG‑Spec/MM‑CHR** (normalize‑then‑compare; lawful scales/units).\n    \n*Mapping to existing families (normative aliases).*  \n— **A.6.1 (Mechanism).** *SubjectBlock* ↔ **SubjectKind/BaseType/…**; *Vocabulary* ↔ **OperationAlgebra**; *Laws* ↔ **LawSet**; *Applicability* remains contextual; **AdmissibilityConditions** — separate field of mechanism (not in the `U.Signature`).  \n— **A.6.A (Architheory).** A.6.A **adds** an adjacent **Architheory View** preserving **Imports / Derivations / Invariants / BelongsToAssurance**. The **universal Block remains the source-of-truth**; the view is a projection and **MUST NOT** introduce fields not derivable from the Block.  \n— **Task/Problem/Discipline signatures (C.22, G-cluster).** These **SHALL** be introduced as **species of `U.Signature`** that reuse the same four-row Block (SubjectBlock / Vocabulary / Laws / Applicability); any extra per-family views are projections only (no new conceptual rows).\n\n##### A.6.0:4.1.1 - SlotSpec for argument positions (normative; see A.6.5)\n\nFor every **n‑ary relation or operator** declared in the **Vocabulary** row, the Signature **SHALL** assign, to each argument position, a **SlotSpec** triple:\n\n```text\n+SlotSpec_i := ⟨SlotKind_i, ValueKind_i, refMode_i⟩\n```\n\nwhere:\n* **SlotKind_i** is a named position in the relation/operator (Tech name with `…Slot` suffix) whose semantics are documented (see A.6.5).\n* **ValueKind_i** is the FPF type (`U.Kind` or kernel‑level type) of admissible occupants at that position.\n* **refMode_i** is either `ByValue` or a **RefKind** (e.g., `U.EntityRef`, `U.HolonRef`), indicating whether the episteme stores values directly or references/identifiers.\n\nFull discipline and lexical rules for **SlotKind/ValueKind/RefKind** are given in A.6.5 `U.RelationSlotDiscipline` and E.10 (§8.1). A.6.0 requires that every vocabulary‑level relation or operator that takes arguments **declare** these SlotSpecs; downstream patterns MAY provide templates for common shapes (e.g., episteme slots in C.2.1).\n\n**Mini‑example (informative).** For an episteme kind `ModelEvaluationResultKind`, a simplified episteme might expose:\n* `describedEntityRef : U.MethodRef`\n* `datasetRef : U.EntityRef`\n* `metricRef : U.CharacteristicRef`\n* `groundingHolonRef : U.HolonRef`\n* `claimGraph : U.ClaimGraph`\n\nAn authorial SlotSpec table then reads:\n\n| Parameter (episteme field)   | SlotKind              | ValueKind          | refMode                |\n| ---------------------- | --------------------- | ------------------ | ---------------------- |\n| `describedEntityRef`   | `DescribedEntitySlot` | `U.Method`         | `U.MethodRef`          |\n| `datasetRef`           | `DatasetSlot`         | `U.Entity`         | `U.EntityRef`          |\n| `metricRef`            | `MetricSlot`          | `U.Characteristic` | `U.CharacteristicRef`  |\n| `groundingHolonRef`    | `GroundingHolonSlot`  | `U.Holon`          | `U.HolonRef`           |\n| `claimGraph`           | `ClaimGraphSlot`      | `U.ClaimGraph`     | `ByValue`              |\n\nThis example illustrates the intended reading: **parameters are typed twice**—once by their **ValueKind** (what sort of thing occupies the position) and once by **refMode** (by‑value or which RefKind). SlotKinds (with `…Slot` suffix) give stable names for substitution laws and describedEntity statements across patterns.\n\n#### A.6.0:4.2 - Profile specialisations (normative; structure‑preserving)\nTo enable first‑principles layers without minting new Kernel kinds, apply **profiles** to `U.Signature`:\n\n* **`profile = FormalSubstrate`** — *formal‑deductive layer*  \n  **Vocabulary:** `TermRegister` (ref‑only), **InferenceKinds** (ref‑only), **EffectDiscipline** (operation/effect signatures).  \n  **Laws:** equational/structural axioms of the calculus; **no handler semantics**.  \n  **Applicability:** binds a `U.BoundedContext` at the **concept‑plane**; **no units/ReferencePlane/Transport** on faces.  \n  **MVPK pins:** **`No‑Realization` pin (mandatory)** on `PlainView`/`TechCard` asserting that handler semantics live only in **A.6.1 `U.Mechanism::U.EffectRealization`**.  \n  **Faces:** On MVPK faces, **`InferenceKindsAllowed`** MAY present a **ref‑only subset** of the enumerated **`InferenceKinds`**; Signatures do not add handler semantics.\n\n* **`profile = PrincipleFrame`** — *postulates + measurability intent (CHR‑binding)*  \n  **Vocabulary:** **PostulateSet** (in the calculus imported), **CHR‑Binding presence** (ref‑only to characteristics/observation profiles), **Ontology anchors** (ref‑only to substrate types/morphisms used to name subject‑matter entities).  \n  **Laws:** timeless/order‑free invariants; **no operational admissions**.  \n  **Applicability:** binds a `U.BoundedContext`; **Signatures SHALL NOT publish units/ReferencePlane/ComparatorSet/Transport** (first mention is in **UNM**). ** \n  **MVPK pins:** **`NoReferencePlaneOnSignature`** (alias: **`NoReferencePlaneOnPF`**) and **`UNM‑priority`** (units/planes/comparators/Transport are declared only by **`U.ContextNormalization`** and cited by edition/ref‑id where needed).\n\n**Profile morphism discipline.** See §4.6 for the **structure‑preserving morphism** requirements for profile application.\n\n#### A.6.0:4.3 - Effect‑discipline vs handler semantics (normative split)\n\nIf a Signature’s **Vocabulary** includes an **EffectDiscipline** (operation/effect signatures), the Signature **SHALL NOT** declare **handler semantics** or any **EffectRealization**. Such realizations are authored only under **A.6.1 `U.Mechanism`** and cited by **ref‑id** on faces where needed. This mirrors the modern algebraic‑effects separation between *operation signatures* and *handlers* while keeping A.6.0 purely conceptual.\n\n#### A.6.0:4.4 - Authoring rules (I/D/S‑aware; lexically disciplined)\n\n* **I/D/S separation.** A signature **states intension and laws**; Realizations (if any) carry **specifications**. Do not mix tutorial text or operational recipes into the Block. Do **not** include **AdmissibilityConditions** or run‑time admissions here.\n* **Context discipline.** Bind Applicability to a **`U.BoundedContext`**. If cross‑context use is intended, **name** the crossing and **reference** the Bridge (Part F/B); A.6.0 does **not** prescribe **compatibility/loss tables (CL, including `CL^plane`)** or penalty formulas.\n* **Stratification.** Use LEX‑BUNDLE registers and strata; do not redefine Kernel names in lower strata (no cross‑bleed).  \n* **Imports location.** If your family requires an explicit **imports** list (e.g., A.6.A Architheory), place it in the **Signature header** or the **family‑specific view**, not inside the universal four‑row Block.\n\n* **Token hygiene.** Do **not** mint new `U.*` tokens inside a Signature without a **DRR**; prefer referencing existing Kernel/Architheory `U.Type`s. \n\n*MVPK publication discipline for Signatures (normative).* When publishing a `U.Signature` via MVPK (E.17), faces **SHALL** be typed projections that add **no new claims**; any numeric/comparable statement **MUST** pin unit/scale/reference‑plane/**EditionId** to **CG‑Spec/MM‑CHR** where applicable. For deductive substrates, faces **MUST** carry a **No‑Realization pin** (handlers/realizers absent). For Principle‑level signatures, faces **MUST NOT** introduce units/ReferencePlane/Transport (first mention occurs in UNM).\n\n#### A.6.0:4.5 - Specialisation knobs (for downstream patterns)\n\nA.6.0 exposes **three** conceptual knobs; specialisations (A.6.A, A.6.1, method/discipline specs) may **tighten** them:\n\n1. **Builder policy.** Whether a signature may commit to a builder `Γ_*` is not decided here; **A.6.A** governs this for architheories (`classification=CAL` only).\n    \n2. **Transport clause.** If cross‑context/plane use is part of the design, the signature **may declare** a conceptual Transport clause; **A.6.1** gives a concrete schema (Bridge, **CL/CL^k/CL^plane**—Bridges per **F.9**, penalties per **B.3**, **CL^plane** per **C.2.1**), but A.6.0 remains agnostic about penalty shapes.\n    \n3. **Morphisms.** Families may define `SigMorph` (refinement, conservative extension, equivalence, quotient, product) to relate signatures; **A.6.1** instantiates this for mechanisms. Where such morphisms, or downstream **substitution / retargeting** laws (e.g., **A.6.2–A.6.4**), act on **n‑ary relations or morphisms**, they **SHALL** express their read/write/retargeting discipline in terms of **SlotSpecs**  (SlotKind / ValueKind / RefKind) rather than unnamed parameter indices, using **A.6.5 `U.RelationSlotDiscipline`** as the normative slot calculus.\n\n#### A.6.0:4.6 - Profile‑specialisation as a structure‑preserving morphism (normative)\nProfile application `ι_profile : U.Signature → U.Signature(profile=…)` **SHALL** be a **structure‑preserving morphism**:\n— **SubjectBlock** is preserved up to α‑renaming (SubjectKind/BaseType unchanged; ResultKind? only added when it exists in the universal intent).  \n— **Vocabulary** is **monotone** (adds or refines names/sorts without contradicting existing ones).  \n— **Laws** are **monotone** (add/strengthen axioms; never weaken).  \n— **Applicability** is **restrictive** (binds or tightens `U.BoundedContext`; never widens implicitly).  \n— No **AdmissibilityConditions**, **operational guards**, or **handler semantics** are introduced by the profile (those live under **A.6.1**).  \nThis makes `profile=FormalSubstrate` and `profile=PrincipleFrame` *morphisms* in the sense of kernel specialisation and supports SigMorph reasoning (refinement/conservative extension).\n   ",
        "archetypal_grounding": "### A.6.0:5 - Archetypal Grounding (Tell–Show–Show)\n\n| quartet Element | `U.System` Example — **Grammar of Motions** | `U.Episteme` Example — **Normalization Family** |\n| --- | --- | --- |\n| **SubjectBlock** | **Subject:** SubjectKind=`MotionGrammar`; BaseType=`U.System:TrajectorySpace`. **Quantification:** SliceSet=`U.ContextSliceSet`; ExtentRule=`admissible motion words per slice (kinematics & domain restrictions)`; ResultKind?=`Language[Segment]`. | **Subject:** SubjectKind=`NormalizationMethod‑Class`; BaseType=`U.Episteme:ChartFamily` (one `U.BoundedContext`). **Quantification:** SliceSet=`U.ContextSliceSet`; ExtentRule=`admissible method instances per slice (edition+validity)`; ResultKind?=`NormalizedChart`. |\n| **Vocabulary** | Types: `Pose`, `Segment`; Operators: `concat`, `reverse`, `sample` (any Γ‑builder is governed by A.6.A). | Operators: `apply(method)`, `compose`, `quotient(≡)`. |\n| **Laws (Invariants/Constraints)** | Closure of `concat`; associativity; time‑monotone sampling; **`reverse` is declared only for holonomic arms (domain restriction)**. | Ratio→positive‑scalar; Interval→affine; Ordinal→monotone; Nominal→categorical; LUT(+uncertainty). |\n| **Applicability (Scope & Context)** | Context: *industrial robotics*; stance: design; time notion: discrete ticks. Cross‑context transport not declared. | Context: *clinical metrics*; stance: analysis; validity windows declared; cross‑context transport via Bridge (concept only; details per A.6.1). Numeric comparability bound to CHR/CG‑Spec. |\n\n*Why these two?* E.8 requires pairs from **U.System** and **U.Episteme** to demonstrate trans‑disciplinary universality.\n",
        "a.6.0:6___bias‑annotation_(lenses_&_defaults)": "### A.6.0:6 - Bias‑Annotation (lenses & defaults)\n\n* **Local‑first meaning.** Laws are **local** to the named Context; cross‑context use must be explicit (Bridge), never implicit.\n    \n* **No illicit scalarisation.** If numbers appear, legal comparability follows **CG‑Spec/MM‑CHR**; **no ordinal means**, **partial orders return sets**; unit/scale alignment is explicit.\n    \n* **Register hygiene.** Keep Tech vs Plain register pairs; avoid tooling/vendor talk in Kernel prose (E.10).\n  ",
        "conformance_checklist": "### A.6.0:7 - Conformance Checklist (normative)\n\n| ID | Requirement |\n| --- | --- |\n| **CC‑A.6.0‑1** | A conformant text labelled **`U.Signature`** **SHALL** expose the **four‑row Signature Block**: *SubjectBlock; Vocabulary; Laws; Applicability*. A visual split of SubjectBlock into **Subject**/**Quantification** lines is allowed; it still counts as **one** conceptual row. |\n| **CC‑A.6.0‑2** | The Block is **conceptual only** (no packaging/CI metadata, no machine schemas, **no Γ**). |\n| **CC‑A.6.0‑3** | Applicability **binds** a `U.BoundedContext`; if cross‑context use is intended, a **Transport clause** is *named* (Bridge reference) without re‑stating Part F/B.3 details (including any **CL^plane**). |\n| **CC‑A.6.0‑4** | Where numeric comparability is implied, Applicability **binds** to **CG‑Spec/MM‑CHR** legality (normalize‑then‑compare; scale/unit alignment). |\n| **CC‑A.6.0‑5** | Families that specialise A.6.0 (e.g., **A.6.A**, **A.6.1**) **MAY** add constraints (e.g., Γ‑export policy; penalty routing) and **MAY** add a family‑specific view (e.g., the Architheory View) but **MUST NOT** contradict A.6.0’s separation of intension vs specification. |\n| **CC‑A.6.0‑6** | Under E.10/E.8, tokens respect strata/registers; Kernel names are not redefined in Architheory/Context prose (Part F naming discipline applies). |\n| **CC‑A.6.0‑7** | The **Laws** row contains **axioms/invariants** only; **AdmissibilityConditions** and operational admissions **MUST** appear only in **A.6.1 Mechanisms** that consume this Signature. |\n| **CC‑A.6.0‑8 (No‑Realization on Signatures with EffectDiscipline).** | If **EffectDiscipline** appears in **Vocabulary**, faces **MUST** carry a **`No‑Realization` pin** and **MUST NOT** publish handler semantics; any **EffectRealization** is referenced (A.6.1) by id only. |\n| **CC‑A.6.0‑9 (CHR‑binding without units/Transport).** | Signatures that declare **measurability intent** (e.g., PrincipleFrame) **SHALL NOT** publish **units, ReferencePlane, ComparatorSet, or Transport**; those are declared only by **UNM** and cited by edition/ref‑id where consumers require numeric comparability. |\n| **CC‑A.6.0‑10 (UNM‑priority on faces).** | Any numeric/comparable claim on a Signature face **pins** **CG‑Spec/ComparatorSet edition ids** and, where scale/plane conversion occurs, **UNM.TransportRegistry edition** with **CL/CL^plane policy‑ids**; **penalties route to R/R_eff only**. |\n| **CC‑A.6.0‑11 (Bridge‑only crossings).** | Cross‑context/plane reuse of Signature claims **MUST** name a **Bridge** (UTS row) and **MUST NOT** imply implicit equivalence by label; losses are recorded via **CL** (penalties → **R**). |\n| **CC‑A.6.0‑12 (Profile conformance).** | If the Signature declares `profile=FormalSubstrate` or `profile=PrincipleFrame`, the corresponding **profile pins** in §4.2 are **mandatory**; failure to emit them makes the Signature **non‑conformant** for that profile. |\n| **CC‑A.6.0‑13 (Profile morphism discipline).** | Applying a profile **SHALL** satisfy §4.6 (structure‑preserving morphism: SubjectBlock preserved, Vocabulary/Laws monotone, Applicability restrictive, no admissibility/handlers). |\n| **CC‑A.6.0‑14 (SlotSpec for argument positions).** | Any `U.Signature` whose **Vocabulary** declares n‑ary relations or operators **SHALL** provide, for each argument position, a **SlotSpec** triple `⟨SlotKind, ValueKind, refMode⟩` (with `refMode ∈ {ByValue \\| RefKind}`) as per A.6.5 `U.RelationSlotDiscipline`. |\n| **CC‑A.6.0‑15 (Slot/Ref lexical discipline on signatures).** | Names of SlotKinds and RefKinds used in SlotSpecs **MUST** obey E.10/A.6.5 lexical guards: tokens ending with **`…Slot`** denote SlotKinds only; tokens ending with **`…Ref`** denote either RefKinds or episteme fields whose type is a RefKind; no ValueKind ends with these suffixes. |\n| **CC‑A.6.0‑16 (SlotSpecs for n‑ary relations).** | Any `U.Signature` whose **Vocabulary** declares an **n‑ary relation or morphism** **SHALL** assign to each parameter position a `SlotSpec_i = ⟨SlotKind, ValueKind, refMode⟩` as defined in **A.6.5 `U.RelationSlotDiscipline`**; SlotSpecs live inside the Vocabulary row’s per‑relation parameter block and **MUST NOT** introduce additional rows beyond the four‑row Block. |\n| **CC‑A.6.0‑17 (SlotSpec‑based substitution laws).** | Specialisations of A.6.0 that define **substitution, retargeting, or profile application** over n‑ary relations/morphisms (e.g., **A.6.2–A.6.4**) **SHALL** phrase their rules in terms of **SlotSpecs** (SlotKind / ValueKind / RefKind) rather than unnamed parameter indices and **SHALL** obey the `…Slot` / `…Ref` lexical discipline in **A.6.5** and **F.18**. |\n",
        "consequences": "### A.6.0:8 - Consequences\n\n* **Uniform kernel shape.** Authors can define **architheory**, **mechanism**, **method**, **discipline**, or **theory** signatures without inventing new templates.\n    \n* **Hard decoupling.** A.6.A can continue to guarantee substitutable Realizations behind a stable Signature; A.6.1 can continue to guarantee law‑governed operations with explicit guard surfaces.\n    \n**Didactic cohesion.** Readers see the same four conceptual rows across the spec, satisfying E.8’s comparability goal.\n",
        "rationale": "### A.6.0:9 - Rationale\n\n**Why “SubjectBlock”?** A.6.1 showed that making the **carrier explicit** (here: *BaseType* — the carrier type) avoids category mistakes when moving between domains (e.g., *set‑algebra on context slices* vs *equivalence‑classes of normalisations*). A.6.0 lifts this to the kernel so every signature can declare **what it is about** before saying **what it provides**.\n**Why one universal Block?** A.6.A already proved the value of a compact **Signature Block** (Imports/Derivations/Invariants/Assurance). A.6.0 factors out the **conceptual core**—rephrased as “SubjectBlock / Vocabulary / Laws / Applicability”—so A.6.A can **map** its four rows onto this universal frame without changing existing architheories.\n\n**Informative echoes (post‑2015 SoTA).**  \n— **Algebraic effects & handlers** (OCaml 5, Koka, Effekt, Links): *operation signatures + handler laws* mirror **Vocabulary + Laws** while keeping implementations separate.  \n— **Session/behavioural types** (2016–2024): protocol/admissibility laws parallel the **Laws** row (at mechanism level).  \n— **Graded/row‑polymorphic effects** (Granule, row‑effects): inform the **EffectDiscipline** vocabulary and equational laws.\n\n**Profiles rationale (informative).**  \n— **FormalSubstrate.** Captures *mathematical language + inference kinds + effect signatures* at the **concept plane**, ensuring the calculus stays independent from handler/realization choices; consuming mechanisms (A.6.1) provide **EffectRealization** only by reference.  \n— **PrincipleFrame.** Captures *postulates/invariants + measurability intent (CHR binding)* without committing to **units/planes/Transport**, which are authored centrally in **UNM** so that comparisons remain lawful and edition‑pinned.\n",
        "relations": "### A.6.0:10 - Relations\n\n* **Specialises / is specialised by:** **A.6.A** (adds Γ‑export policy; imports DAG; architheory layering) and **A.6.1** (adds **OperationAlgebra/LawSet/AdmissibilityConditions/Transport** for mechanisms).  \n* **Constrained by:** E.10 LEX‑BUNDLE (registers, strata); D.CTX for Context binding; **Part F** (Bridges & cross‑context transport; naming).\n* **Consumed by (profiles):** **`U.FormalSubstrate`** and **`U.PrincipleFrame`** specialisations of `U.Signature` on the principled path; **UNM** (Context Normalization) remains the **single source of truth** for **CG‑Spec/ComparatorSet/Transport** editions that Signature consumers pin on faces.\n\n* **Enables:** uniform authoring and comparison of signatures across Part C families, methods, and discipline glossaries (Part F).\n  ",
        "a.6.0:end": "### A.6.0:End\n"
      },
      "content": "### A.6.0:End\n",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.6.A",
      "title": "Architheory Signature & Realization",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.6.A - Architheory Signature & Realization\n",
        "problem": "### A.6.A:2 - Problem\n\nWhen Signatures (interface) leak implementation, the ecosystem becomes brittle: (1) substitutability breaks, (2) imports entangle, (3) cross‑context use becomes implicit and unauditable.\n",
        "forces": "### A.6.A:3 - Forces\n| Force | Tension |\n| --- | --- |\n| **Stability vs. evolution** | Keep public promises stable while allowing private Realizations to evolve. |\n| **Universality vs. fitness** | One Signature shape across CAL/LOG/CHR vs architheory‑specific vocabularies. |\n| **Intension vs. specification** | Signatures state *what & laws*; Realizations carry *how/tests*. |\n| **Locality vs. transport** | Context‑local semantics vs explicit, auditable Bridge‑only crossings (R‑only penalties). |\n ",
        "solution": "### A.6.A:4 - Solution\n\n#### A.6.A:4.1 - `U.ArchitheorySignature` — *the public Standard*\n\nA **Signature** states **what** an architheory offers—its vocabulary, laws, and applicability—**without** embedding implementation or build metadata. It is the stable unit that other architheories import.\n\n#### A.6.A:4.2 - `U.ArchitheoryRealization` — *the private implementation*\n\nA **Realization** satisfies the Signature while remaining opaque. Multiple Realizations may co‑exist; they **may tighten** (never relax) the Signature’s laws (Liskov‑style substitutability).\n\n#### A.6.A:4.3 - Signature Block — **A.6.0 alignment** and **Architheory View**\n\nEvery architheory **SHALL** publish **two adjacent views** of its public contract:\n1) the **universal** A.6.0 `U.Signature` Block (*SubjectBlock; Vocabulary; Laws; Applicability*), and  \n2) an **Architheory View** that preserves the pass interface used across Part C: **Imports / Derivations / Invariants / BelongsToAssurance**.\nThis ensures both cross‑family uniformity **and** compatibility with existing architheory architecture. The **universal Block remains the source‑of‑truth**; the **Architheory View is a projection** that MUST NOT introduce fields not derivable from the Block (e.g., no hidden AdmissibilityConditions; no Γ in LOG/CHR).\n\n| `U.Signature` row (A.6.0)          | A.6.A alias / where to author it                                           |\n|------------------------------------|---------------------------------------------------------------------------|\n| **SubjectBlock**            | One‑line declaration above the block (**SubjectKind + BaseType**; may be visually split into **Subject/Quantification**; avoid “governed” wording) |\n| **Vocabulary**                     | **Derivations** (public types/relations/operators that the theory contributes) |\n| **Laws (Invariants/Guards)**       | **Invariants** (law statements; proofs live in Realizations)             |\n| **Applicability (Scope & Context)**| **BelongsToAssurance** + context note in the header; bind a `U.BoundedContext` where relevant; numeric comparability **binds** to **CG‑Spec/MM‑CHR** (normalize‑then‑compare; lawful units/scales). |\n\n**Architheory View (mandatory alongside the universal view):**\n* **Imports** — required `U.Type`s/relations already present or produced by earlier passes.  \n* **Derivations** — new `U.Type`s/relations/operators the architheory contributes.  \n* **Invariants** — law statements (proofs in Realizations).  \n* **BelongsToAssurance** — {Typing | Verification | Validation}.\n \n*Prohibition.* The Signature block is **conceptual**: no packaging/CI/tooling metadata (LEX firewall), no Γ‑builders (except as permitted below for CAL).\n\n#### A.6.A:4.4 - Γ‑export policy and layering\n\n* A **CAL** architheory **SHALL** export **exactly one** aggregation/builder `Γ`. The **`Γ` identifier MUST be namespaced** under the architheory `id` (e.g., `ArchitheoryId.Γ`) to avoid collisions.\n* **LOG** and **CHR** architheories **SHALL NOT** export `Γ`.  \n* Import layering **SHALL** respect the holonic stack: **LOG/CHR may import CAL; CAL may import CAL**; import graphs are **acyclic** and respect **LEX‑BUNDLE** strata (Kernel → Architheory → Context → Instance); no cross‑bleed.\n\n#### A.6.A:4.5 - Signature header\n\nEach Signature begins with:  \n`id` (PascalCase), `version` (SemVer), `status` (draft/review/stable/deprecated), `classification` (CAL/LOG/CHR), `imports` (list), `provides` (list, including Γ if CAL).  \nIf **SubjectBlock** are non‑trivial, add a one‑liner in the header (or immediately above the block).\n",
        "a.6.a:5___transport_&_cross‑context_use_(coordination_with_a.6.1)": "### A.6.A:5 - Transport & Cross‑Context Use (coordination with A.6.1)\n\nSignatures **SHALL NOT** restate Bridge/CL mechanics. If cross‑context/plane use is intended, the Signature **names** the Bridge conceptually. Semantics are governed by **A.6.1 `U.Mechanism`**; **Bridges** are specified in **F.9**; **CL/CL^k** and **Φ/Ψ** penalty calculus live in **B.3**; **CL^plane** follows **C.2.1 CHR:ReferencePlane**. No implicit “latest”; time‑sensitive guards require an explicit **Γ_time** policy in the consuming mechanism.\n",
        "relations": "### A.6.A:12 - Relations\n\n*Specialises / is specialised by*: **A.6.0 `U.Signature`**, **A.6.1 `U.Mechanism`**.  \n*Constrained by*: LEX‑BUNDLE (registers/strata), D.CTX (Context), Part F (Bridges & cross‑context transport; naming).\n",
        "archetypal_grounding": "### A.6.A:7 - Archetypal Grounding\n\nProvide a brief pair of examples (Work/System; Knowledge/Episteme) that name SubjectBlock, show Vocabulary and Laws, and state Applicability/Context. Keep proofs out of the Signature.\n",
        "conformance_checklist": "### A.6.A:8 - Conformance Checklist\n\n| ID | Requirement |\n|----|-------------|\n| **CC‑A6.1** | Every architheory **MUST** declare exactly one `Signature`. |\n| **CC‑A6.2** | Every architheory **MUST** provide ≥ 1 `Realization` consistent with its Signature. |\n| **CC‑A6.3** | The global graph of `imports` **MUST** be acyclic. |\n| **CC‑A6.4** | Realizations **MUST NOT** reference internals of other architheories; only their Signatures. |\n| **CC‑A6.5** | A Signature’s `provides` **MUST NOT** redeclare `U.Type`s already exported by transitive `imports`. |\n| **CC‑A6.6** | Realizations **MAY tighten** but **MUST NOT relax** Signature laws (Liskov‑style). |\n| **CC‑A6.7** | If multiple Realizations exist, authors **SHOULD** provide a short trade‑off rationale. |\n| **CC‑A6.8** | The Signature **MUST** include an explicit **A.6.0 alignment** mapping (table or one‑liners). |\n| **CC‑A6.9** | Where numeric comparability is implied, **bind** legality to **CG‑Spec/MM‑CHR** (normalize‑then‑compare; lawful units/scales; no ordinal means). |\n| **CC‑A6.10** | Any intended cross‑context/plane use **MUST** name the Bridge and defer semantics to **A.6.1**/**Part F**; penalties route to **R/R_eff** only. |  \n| **CC‑A6.11** | If `classification = CAL` and a `Γ` is exported, its identifier **MUST** be namespaced under the architheory `id`. |\n| **CC‑A6.12** | **Both views** of the Signature are present: the universal A.6.0 Block **and** the **Architheory View (Imports/Derivations/Invariants/BelongsToAssurance)** placed adjacently. |\n\n**Author-facing:**\n* [ ] The **two** Signature views are present (A.6.0 Block **and** Architheory View).  \n* [ ] If `classification = CAL`, **exactly one** Γ is named.  \n* [ ] Imports point **down** the layering and remain **acyclic**.  \n* [ ] Any referenced artefacts are anchored by SCR/RSCR identifiers (A.10).  \n* [ ] An **A.6.0 alignment note** is provided (table or one‑liners as above).\n",
        "consequences": "### A.6.A:9 - Consequences\n\n* **Hard decoupling** — Kernel stability is preserved; swapping a Realization never breaks dependents.  \n* **In‑framework competition** — Alternative logics, physics, economic models can co‑exist under the same interface.  \n* **Machine‑checkable composition** — Because imports form a DAG and `provides` are explicit, automated loaders can detect conflicts early.\n",
        "a.6.a:10___didactic_addendum_—_benefits_&_trade‑offs_(informative)": "### A.6.A:10 - Didactic Addendum — Benefits & Trade‑offs (informative)\n\n| Benefit | What you get | Trade‑off / Guard |\n| --- | --- | --- |\n| **Universal shape (A.6.0 alignment)** | One 4‑row block across architheories, mechanisms, methods, disciplines. | Maintain **Intension vs. Specification** separation; no Γ in Signatures except CAL per A.6. |\n| **Substitutability** | Multiple Realizations behind one Signature; safe swaps; Liskov‑style tightening allowed. | Relaxing laws is forbidden; otherwise mint a refined Signature or use **U.MechMorph** (A.6.1). |\n| **Transport discipline** | **Bridge‑only** crossing; CL penalties route to **R/R_eff**; **F/G invariant**. | Crossings are **named**; no implicit “latest”; **Γ_time** where relevant. |\n| **Numeric comparability sanity** | **normalize‑then‑compare** via **CG‑Spec/MM‑CHR**; explicit unit/scale alignment. | **Partial orders return sets**; illegal scalarisation (e.g., ordinal means) is blocked. |\n| **Layering predictability** | Exactly **one Γ** for **CAL**; **LOG/CHR** export none; **imports acyclic; no cross‑bleed across strata**. | Some constructs belong as **Mechanisms (A.6.1)**, not as architheories. |\n",
        "rationale": "### A.6.A:11 - Rationale\n\nWhy “Signature”? Familiar to engineers (function/type signatures) and to logicians (algebraic signatures). It is concise, neutral, and keeps the Kernel slim while enabling competing world‑views to co‑exist behind the same interface.\n",
        "a.6.a:end": "### A.6.A:End\n"
      },
      "content": "### A.6.A:End\n",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.6.1",
      "title": "U.Mechanism - Law‑governed application to a SubjectKind over a BaseType",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.6.1 - U.Mechanism - Law‑governed application to a SubjectKind over a BaseType\n\n**One‑line summary.** A `U.Mechanism` is a specialisation of `U.Signature` (A.6.0): its **Vocabulary** is an explicit **OperationAlgebra** whose operators publish **SlotSpecs** (A.6.5), its **Laws** are a **LawSet**, and it adds **AdmissibilityConditions** (operational guards) plus a named **Transport** clause for cross‑context use. Transport is **Bridge‑only** (per **F.9**) with penalties routed to the **Reliability** channel only (**R**, or **R_eff** when distinguished) (per **B.3**); **F/G** remain invariant; **CL^plane** follows **C.2.1 CHR:ReferencePlane**. Realizations **MAY** be published under **A.6.A** (Signature→Realization; **one Γ only if `classification=CAL`**; acyclic imports; opacity).\n\n**Status.** Normative \\[A\\] in **Part A (Kernel)**.  \n\n**Placement.** Immediately **after A.6.A** as **A.6.1**. **USM (A.2.6)** and **UNM (A.19/C.16)** become **instances conforming to A.6.1** (no semantic change to either).\n\n**Mint vs reuse.** This pattern mints the Kernel lexemes `U.Mechanism`, `U.MechMorph`, and `U.MechAuthoring`, plus the descriptive record names `MechanismDescription`, `MechFamilyDescription`, and `MechInstanceDescription`. It reuses `U.Signature` (A.6.0), `U.Type`, `U.BoundedContext`, and Part F Bridge/CL/ReferencePlane terms without changing them; it does **not** mint new `U.Type` core types.\n\n**Type.** Architectural pattern (kernel‑level; notation‑independent).\n\n**LEX.TokenClass (E.10).** Declared here for the tokens minted by this pattern (see **E.10:7.1**).\n* `LEX.TokenClass(U.Mechanism) = KernelToken`\n* `LEX.TokenClass(U.MechMorph) = KernelToken`\n* `LEX.TokenClass(U.MechAuthoring) = KernelToken`\n* `LEX.TokenClass(MechanismDescription) = KernelToken`\n* `LEX.TokenClass(MechFamilyDescription) = KernelToken`\n* `LEX.TokenClass(MechInstanceDescription) = KernelToken`\n",
        "problem": "### A.6.1:2 - Problem\n\nWithout a kernel abstraction, scope/normalization/comparison constructs proliferate with incompatible algebras and guard surfaces; cross‑context reuse lacks visible **Bridge/CL routing**; comparability drifts into **illegal scalarisation** (e.g., ordinal means). FPF already curbs this via **A.6.A** (Signature discipline), **USM** (scope algebra & Γ_time), **UNM** (normalize‑then‑compare), and **CG‑Spec** (lawful comparators/ScoringMethods)—but lacks a **common meta‑slot** for “mechanism.”\n",
        "forces": "### A.6.1:3 - Forces\n\n**Locality vs transport.** Semantics are **context‑local**; crossing contexts is **Bridge‑only** (Part F/B.3); penalties hit **R/R_eff**; **F/G** invariant.\n\n**Expressivity vs legality.** Rich operators vs **CHR legality** and **CG‑Spec** (no ordinal averages; lawful unit alignment).\n\n**Time determinacy.** Explicit **Γ_time**; no implicit *latest*. (Required in USM’s `ContextSlice`.)\n\n**Slot clarity vs specialisation depth.** Multi‑level specialisations require explicit **SlotSpecs** (A.6.5) and monotone refinement of **ValueKinds**; SlotKinds are stable across levels (no implicit positional parameters).\n\n**Signature hygiene.** Obey **A.6.A** (exactly one Γ from CAL, LOG/CHR export none; imports acyclic; realizations opaque).\n",
        "solution": "### A.6.1:4 - Solution\n\n#### A.6.1:4.1 - **Mechanism Intension**\n\nA `U.Mechanism` **publishes**  \n        `U.Mechanism.Intension := ⟨IntensionHeader, Imports,\n                SubjectBlock := ⟨SubjectKind, BaseType, SliceSet, ExtentRule, ResultKind?⟩,\n                SlotIndex, OperationAlgebra, LawSet, AdmissibilityConditions,\n                Applicability, Transport, Γ_timePolicy, PlaneRegime, Audit⟩`  \nand admits Realizations (kernel‑level or architheory‑level) that respect it. The shape is **notation‑independent** and **conceptual** (no tooling, storage, or CI metadata).\n\n* **A.6.0 alignment (normative).** `U.Mechanism` is a specialisation of `U.Signature` (A.6.0). A mechanism publication **SHALL** include the universal four‑row Signature Block (*SubjectBlock / Vocabulary / Laws / Applicability*). The canonical mapping is:  \n  – **SubjectBlock** ↔ `SubjectBlock`  \n  – **Vocabulary** ↔ `OperationAlgebra` (including inline SlotSpecs per A.6.0:4.1.1 / A.6.5)  \n  – **Laws** ↔ `LawSet`  \n  – **Applicability** ↔ `Applicability`  \n  `SlotIndex` is a mechanism-only **index/projection** over SlotSpecs used by `OperationAlgebra` (and any extra SlotSpecs used only by `AdmissibilityConditions`); it does **not** introduce a fifth Signature row and does not relax A.6.0:4.1.1.\n  Mechanism‑only additions are `AdmissibilityConditions`, `Transport`, `Γ_timePolicy`, `PlaneRegime`, and `Audit`; they extend the Signature without contradicting its intension/specification split (A.6.0; CC‑A.6.0‑5).\n\n* **IntensionHeader.** `id` (PascalCase), `version` (SemVer), `status` (draft/review/stable/deprecated).  \n  If realized as an **Architheory**, add the **A.6.A** header with `classification ∈ {CAL|LOG|CHR}` and `imports/provides`; **only CAL may export exactly one Γ**; **LOG/CHR export none**. For **Kernel‑level** realizations, do **not** mint an A.6.A header.\n\n* **Imports.** Architheory Signatures / `U.Types` this mechanism requires (notation‑independent; **acyclic**). When realized as an Architheory, **LOG/CHR may import CAL; CAL may import CAL** (A.6.A layering).\n* **BaseType.** A `U.Type` the mechanism ranges over. CHR spaces (e.g., a `U.CharacteristicSpace`/chart family) appear here **as types**; outside CHR, use set‑typed `U.Type`s. A conformant `U.Mechanism` publication **MUST NOT** mint a new core type here; it **MUST** reference existing `U.Type`s. If planes differ, state the **ReferencePlane** policy (see *PlaneRegime*).\n* **SubjectKind / SliceSet / ExtentRule / ResultKind? / SlotIndex.**\n  • **SubjectKind.** The intensional kind acted upon (C.3.1/3.2), separate from quantification.\n  • **SliceSet.** The addressable set of Context slices (USM: **ContextSliceSet**).\n  • **ExtentRule.** A rule yielding `Extension(SubjectKind, slice)` (C.3.2), used as the quantifier’s domain.\n  • **ResultKind?** Optional intensional kind for outputs of `OperationAlgebra`.\n  • **SlotIndex.** A set (or map) of SlotSpecs `SlotSpec = ⟨SlotKind, ValueKind, refMode⟩` (A.6.0:4.1.1; A.6.5) covering every argument position used by **OperationAlgebra** and **AdmissibilityConditions**. SlotKinds are stable names for substitution and specialisation; parameter names/indices are presentation only.  \n    For **Vocabulary-level** operators, SlotSpecs remain declared **in each operator’s parameter block** (A.6.0:4.1.1). `SlotIndex` is an extracted index that **MUST** be mechanically derivable from those declarations (plus any guard-only SlotSpecs).\n    **Shorthand views (didactic only).** Authors MAY include a simple name→ValueKind list (a `ValueKindView`) as a didactic projection of SlotSpecs, but it SHALL NOT replace SlotSpecs (`SlotKind/ValueKind/refMode`) in normative Mechanism definitions. If present, it MUST be mechanically derivable from `SlotIndex` (e.g., `ValueKindView = π_value(SlotIndex)` by dropping `refMode`). The colloquial label **ParamKind** is permitted only in prose as a synonym for the `ValueKind` component of a SlotSpec; it MUST NOT be introduced as a field name, token, or type.\n* **OperationAlgebra.** Named operations whose signatures are expressed over SlotKinds from `SlotIndex` (A.6.5); **no implicit parameters**. For every n‑ary operator, its Vocabulary declaration **SHALL** publish SlotSpec triples per argument position (A.6.0:4.1.1); positional indices are presentation only. Examples:  \n  • **USM:** `∈, ⊆, ∩, SpanUnion, translate, widen, narrow, refit`.  \n  • **UNM:** `apply(method)`, `compose`, `quotient(≡_UNM)`; **normalize‑then‑compare**.\n\n* **LawSet.** Equations/invariants (no proofs here). **Admissions/eligibility tests belong under AdmissibilityConditions, not here.** Laws **MUST** be compatible with CHR legality where numeric comparison/aggregation is induced. Examples:\n  • **USM:** serial **intersection**; **SpanUnion** only where a **named independence assumption** is satisfied (state features/axes, validity window, evidence class); `translate` uses declared Bridges; **Γ_time** is mandatory.  \n  • **UNM:** **scale‑appropriate** transforms — ratio→positive‑scalar; interval→affine; ordinal→monotone; nominal→categorical; `tabular:LUT(+uncertainty)`.  \n  *(A conformant `U.Mechanism` publication **MUST NOT** mint a new Kernel token for “certificate”; if such a type is later required, it **MUST** follow DRR/LEX minting.)*\n\n* **AdmissibilityConditions.** Deterministic, **context‑local** *operational* guard predicates that **fail closed** (e.g., “Scope covers TargetSlice” with named **Γ_time**; “NormalizationMethod class + validity window named”). Predicate arguments **SHALL** be declared via SlotSpecs from `SlotIndex` (A.6.5), not as implicit positional parameters. Unknowns **→ {degrade | abstain}**; never coerce to 0/false.\n\n* **Applicability.** Binding to a **`U.BoundedContext`** with stance/plane/time notes and any **CG‑Spec/MM‑CHR** legality claims; cross‑context use is declared via **Transport** only.\n\n* **Transport.** **Bridge‑only** semantics for cross‑context / cross‑plane use: name the Bridge and channel (`Scope|Kind`) per **F.9**, and record **ReferencePlane**(src,tgt) per **C.2.1**. **Terminology:** this `Transport` clause is a declarative policy surface; it does **not** introduce a `U.Transfer` edge (see **E.18** term separation). The Transport clause **MUST NOT** restate CL ladders, `CL^plane`, or Φ/Ψ tables; it **MUST** reference the applicable policy ids / registries instead; penalties **route to R/R_eff only** and **never** mutate F/G (per **B.3**). Crossings are explicit; **no implicit crossings**. Where **USM** or **KindBridge** are used together, apply the **two‑bridge rule** (scope CL and kind `CL^k` penalties handled **separately** to the Reliability channel (**R**/**R_eff**)).\n\n* **Γ_timePolicy.** Point/window/policy; **no implicit “latest.”** Validity windows are **named**; **required** whenever guards reference time.\n* **PlaneRegime.** Declare `ReferencePlane` on values/paths; when planes differ, name **CL^plane** and apply a **Φ_plane** policy (Part F/B.3). Plane penalties **do not** change CL; route to **R/R_eff** only; **F/G** stay invariant.\n\n* **Audit.** Conceptual audit surface only (no data/telemetry workflows): crossings are publishable on **UTS**; surface **policy‑ids** rather than tables. Edition pins and regression hooks (if any) are referenced by id; operational details remain out of scope.\n* **SignatureBlock alignment (A.6.A).** When realized as an **Architheory**, map `U.Mechanism.Intension` to the **A.6.A Signature Block** — `Imports`, **Derivations**, **Invariants**, **BelongsToAssurance** — and include the **A.6.A header** with `classification/provides`. **CAL** Realizations MAY **provide exactly one Γ**; **LOG/CHR provide none**; **imports form a DAG**; internals **opaque**. SlotKinds and SlotSpecs in `SlotIndex` remain part of the **Vocabulary** row (A.6.0) and **MUST** obey A.6.5 in all Architheory renderings.\n\n**Compatibility with A.6.** If realized as an **architheory** (CAL/LOG/CHR), obey A.6.A (**one Γ for CAL only; acyclic imports; opacity**). Kernel‑level realizations remain notation‑independent and publish the same fields for auditability. LEX discipline applies to all minted tokens.\n\n#### A.6.1:4.2 - U.MechMorph - Refinement, Extension, Equivalence & Composition\n\n**Intent.** Provide structure‑preserving **relations & constructors** between mechanisms.  \n**Definitions.**\n\n* **Refinement** `M′ ⊑ M`: narrows the **SubjectBlock** and/or **SlotSpecs** (ValueKinds/refMode for inherited SlotKinds) and/or **strengthens** `LawSet`/`AdmissibilityConditions` (safe substitution; Liskov‑style). A Refinement **MUST NOT** rename SlotKinds or add new required arguments to inherited operations.\n* **Extension** `M ⊑⁺ M″`: **adds operations** (and any new SlotKinds used only by those new operations) without weakening existing Laws/Guards; old programs remain valid (conservative extension).\n* **Equivalence** `M ≡ M′`: there exists a bijective mapping between Subjects/ops preserving/reflecting **LawSet** (up‑to‑isomorphism on **BaseType** and **OperationAlgebra**).\n    \n* **Quotient** `M/≈`: factor by a **congruence** (e.g., **≡_UNM** for charts).\n\n* **Product** `M×N`: independent **BaseTypes**; ops are component‑wise; ensures **no illegal cross‑ops** (e.g., set‑algebra discipline for `SpanUnion`). Where independence is claimed, **name and justify** the assumption (do not mint new Kernel types here).\n\n##### A.6.1:4.2.1 - Multi-level specialisation ladders (normative)\n\nMany families need a **generic** mechanism at the top (e.g., “select anything”) and progressively **specialised** mechanisms below (e.g., “select a method by decision theory”, “select a telemetry pack”). To keep such ladders **modular** and to prevent cross‑level leakage:\n\n1. **Explicit parent + morphism kind.** Any mechanism that specialises another **MUST** name its parent and declare whether the step is a **Refinement** (`⊑`) or an **Extension** (`⊑⁺`). A specialisation family **MUST** be acyclic (a DAG), mirroring A.6.A import discipline.\n\n2. **SlotKind invariance across levels.** For every inherited operation/guard predicate, SlotKinds are invariant (A.6.5). A specialisation step **MUST NOT** rename an inherited SlotKind, change its documented semantics, or rely on positional re‑ordering instead of SlotKind identity.\n\n3. **ValueKind monotonicity.** A Refinement MAY narrow `ValueKind` (i.e., `ValueKind′ ⊑ ValueKind` in Kind‑CAL) and/or `refMode` for an inherited SlotKind, and MAY strengthen Laws/Guards. It **MUST NOT** widen ValueKinds or relax Guards; otherwise mint a new parent mechanism or publish an adapter mechanism.\n\n4. **No new mandatory inputs to inherited operations.** If a specialisation needs extra inputs, it **MUST** introduce a new operation (Extension) or an adapter mechanism; it **MUST NOT** retrofit new required parameters into an inherited operation signature.\n\n5. **No upward leakage.** A top‑level mechanism in a ladder **SHOULD** mention only the most general ValueKinds required by its SlotSpecs and Laws. Domain‑specific artefacts (e.g., decision‑theory policies, OEE generators, evaluation packs) belong in specialised mechanisms that refine slots and/or add operations.\n\n*Informative selector ladder sketch.* `SelectorMechanism` can declare a stable slot interface (`CandidateSetSlot`, `CriteriaSlot`, `ContextSlot`, `SelectionSlot`) with generic ValueKinds. `SelectorMethodMechanism ⊑ SelectorMechanism` then narrows `CandidateSetSlot.ValueKind` to `U.Method` and (by Extension) adds decision‑theory specific slots/ops; an OEE generator is authored as a separate mechanism that produces candidate/criteria packs consumed by the selector.\n**Transport** `Bridge⋅M`: lifts across Contexts/planes; names **CL/CL^k/CL^plane** regimes; penalties → **`R_eff` only**; **UTS row** recommended for publication; **ReferencePlane(src,tgt)** recorded. If mapping losses are material, **narrow** the mapped set or publish an **adapter** (best practice).\n\n**Passing example.** `USM′ = USM + “publish named independence‑assumption evidence for SpanUnion”` ⇒ **Refinement** (strengthened law; substitution‑safe).\n**Normalization quotient.** `UNM / ≡_UNM` exposes **compare‑on‑invariants** surfaces for UCPM/USCM (normalize‑then‑compare).\n\n#### A.6.1:4.3 - U.MechAuthoring - Instantiation template\n\n**MechanismDescription (E.8 Tell–Show–Show; I/D/S‑compliant):**\n`Mechanism: U.<Name>`  *(Kernel conceptual description; no tooling fields)*\n`Imports: <Signatures / U.Types>` - `SubjectBlock: <SubjectKind, BaseType, SliceSet, ExtentRule, ResultKind?>` - `SlotSpecs: <SlotIndex (A.6.5)>` - `OperationAlgebra: <operators with SlotKinds>` - `LawSet: <equations/invariants>` - `AdmissibilityConditions: <admission predicates with SlotKinds; Γ_time>` - `Transport: <Bridge channels; CL/CL^k/CL^plane named; ReferencePlane(src,tgt)>` - `PlaneRegime: <world|concept|episteme rules>`\n\n#### A.6.1:4.4 - MechFamilyDescription & MechInstanceDescription\n\n* **MechFamilyDescription**: `{Mechanism.Intension, Realizationα, Realizationβ, …}` — each Realization may **tighten** (never relax) Laws (Liskov‑style).\n\n* **MechInstanceDescription**: `{Mechanism.Intension@Context, Windows, named Φ/Ψ/Φ_plane regimes, BridgeIds}` — a **conceptual instance**; operational telemetry/workflows are out of scope.\n\n#### A.6.1:4.5 - Defaults\n\n* **Local‑first semantics.** All judgments are **context‑local**; crossings are **explicit** and **costed** (CL→R only).\n* **Compliance‑first comparability.** Numeric comparison/aggregation requires **CG‑Spec** (lawful **SCP**, Γ‑fold, MinimalEvidence); **partial orders return sets**; **no ordinal means**.\n* **Tri‑state discipline.** `unknown → {degrade|abstain}`; `sandbox/probe‑only` is a **LOG branch** with a policy‑id (no implicit `unknown→0/false`).\n* **R‑only penalties.** **Φ/Ψ/Φ_plane** are **monotone and bounded**; penalties route to **`R_eff` only**; **F/G invariant**.\n\n#### A.6.1:4.6 - Born‑via‑A.6.1 sketches (informative)\n\n**CPM — Unified Comparison Mechanism (parity‑grade orders)**  \n**BaseType:** typed traits/charts in a CG‑Frame. **OperationAlgebra:** lawful orders (≤, ≽, lexicographic) + **set‑returning** dominance (Pareto). **LawSet:** **no ordinal averaging**; **normalize‑then‑compare** when spaces/scales differ (UNM); editions pinned. **AdmissibilityConditions:** **CG‑Spec** bound; **ComparatorSet** explicit. **Transport:** Bridge+CL → **R/R_eff only**.  \n  \n**USCM — Unified Scoring Mechanism (SCP‑first)**  \n**BaseType:** `U.Measure` (CHR‑typed slots). **OperationAlgebra:** ScoringMethod(s) (Coordinate→Score) + admissible aggregators; **WeightedSum** only on interval/ratio with unit alignment; partial orders return sets. **Guards:** **MinimalEvidence** \\+ CG‑Spec legality. **Transport:** penalties → **R/R_eff**; UTS row.\n  \n**PTM — Publication & Telemetry Mechanism (informative)**\n**BaseType:** `SoTA‑Pack(Core)`, `PathId/PathSliceId`, `PolicyId`. **OperationAlgebra:** emit **selector‑ready** packs with parity pins and **telemetry stubs**; listen for edition/illumination bumps; trigger **slice‑scoped** refresh. \n**LawSet:** **no change of dominance defaults** unless CAL policy promotes; edition-aware refresh.  \n**Guards:** **GateCrossing visibility harness** blocks publication on missing crossing attestations (BridgeCard+UTS row, ReferencePlane, CL/CL^k/CL^plane, Φ/Ψ policy-ids), on lane-purity violations (CL→R only; F/G invariant), or on lexical SD violations (E.10). \n**Transport/Audit:** **G.10/G.11** publication & refresh semantics (CL routing to **R/R_eff**).\n\n*Informative SoTA:* telemetry hooks align with post‑2015 quality‑diversity families (CMA‑ME/MAE, DQD/MEGA) and open‑ended methods (POET‑class) when monitored via illumination telemetry rather than scored.\n\n#### A.6.1:4.7 - 60‑second didactic script\n\n> *“To mint a mechanism, fill a **Mechanism.Intension**: declare **SubjectBlock** (**SubjectKind**, **BaseType**, **SliceSet**, **ExtentRule**, **ResultKind?**) and **SlotSpecs**; then **OperationAlgebra/Laws/AdmissibilityConditions** and **Γ_time**; define **Transport** (Bridge/CL with penalties to R only), and **Audit** (UTS + Path pins). Realize it as CAL/LOG/CHR under **A.6.A**. USM and UNM are already such mechanisms; the same template births comparison, scoring, and publication mechanisms—safely bound to **CG‑Spec**—without leaving the kernel grammar.”*\n\n#### A.6.1:4.8 - Quick “builder’s” checklist (author‑facing)\n\n1. Draft a **run↔design charter**: why this Mechanism, which **guard surfaces** and **comparability** are in scope; which `DesignRunTag`/`CtxState.locus` boundary it mediates; is a **Γ_m (CAL)** builder needed?\n    \n* Fill **Mechanism.Intension** (**SubjectBlock**, **SlotSpecs**, **OperationAlgebra**, **LawSet**, **AdmissibilityConditions**, **Applicability**, **Transport**, **Γ_timePolicy**, **PlaneRegime**, **Audit**).\n    \n* Bind **CHR legality & CG‑Spec** when comparing/aggregating (ComparatorSet, ScaleComplianceProfile (SCP), MinimalEvidence, Γ‑fold).\n    \nShip **UTS + G.10**; wire **G.11** telemetry (PathSlice‑keyed); ensure penalties **route to `R_eff` only**.\n",
        "archetypal_grounding": "### A.6.1:5 - Archetypal Grounding\n\n#### A.6.1:5.1 - **U.Scope (Claim/Work/Publication) — USM as a U.Mechanism instance** (normative by reference)\n\n* **Imports:** `U.ContextSliceSet`; Part F.9 **Bridge**; **C.2.1 ReferencePlane** (noted for crossings); **C.2.2 F–G–R**; **C.2.3 U.Formality**.\n* **BaseType:** `U.ContextSliceSet`.\n* **SliceSet:** `U.ContextSliceSet` (addressable `U.ContextSlice`s).\n* **SubjectKind:** `U.Scope` with specializations `U.ClaimScope` (G), `U.WorkScope`, and `U.PublicationScope`.\n* **OperationAlgebra:** `∈, ⊆, ∩, SpanUnion, translate, widen, narrow, refit`.\n* **LawSet:** serial **intersection**; **SpanUnion** only where a **named independence assumption** is satisfied (state features/axes, validity window, evidence class); **translate** uses declared **Bridges**; **Γ_time** is **mandatory**.\n* **AdmissibilityConditions:** deterministic **“Scope covers TargetSlice”**; **fail‑closed**; `unknown → {degrade|abstain}` (no implicit `unknown→0/false`).\n* **Transport:** **Bridge‑only** with **CL**; penalties → **`R_eff`**; **F/G** invariant; publish UTS notes.\n* **Γ_timePolicy:** `point | window | policy`; **no implicit “latest.”**\n* **PlaneRegime:** *not applicable to scope sets* (scope is set‑valued over `ContextSlice`, no value‑plane); **CL^plane** N/A.\n\n#### A.6.1:5.2 - **U.Episteme (Knowledge) — UNM as a U.Mechanism instance** (normative by reference)\n\n* **Imports:** **A.17/A.18 (CSLC)**; **C.16 (MM‑CHR)**; `U.BoundedContext`; Part F.9 **Bridge**; **C.2.1 ReferencePlane**.\n* **BaseType:** chart/`U.CharacteristicSpace` family in a CN‑frame (one `U.BoundedContext`).\n* **SubjectKind:** **NormalizationMethod classes** with induced **≡_UNM** equivalence over charts.\n* **OperationAlgebra:** `apply(method)`, `compose`, `quotient(≡_UNM)`; **normalize‑then‑compare** (exposes compare‑on‑invariants surfaces to UCPM/USCM).\n* **LawSet:** scale‑appropriate transforms — `ratio:scale / interval:affine / ordinal:monotone / nominal:categorical / tabular:LUT(+uncertainty)`; **validity windows** per edition.\n* **AdmissibilityConditions:** `method ∈ declared class‑set` AND **validity window named**; **fail‑closed**; `unknown → {degrade|abstain}`.\n* **Transport:** **Bridge‑only** on cross‑Context; when **describedEntity changes**, declare **KindBridge (CL^k)**; penalties → **`R_eff` only**.\n* **Γ_timePolicy:** **named validity windows** for NormalizationMethod/instances (editioned).\n* **PlaneRegime:** values live on **episteme ReferencePlane**; on plane crossings apply **CL^plane** policy; penalties → **`R_eff` only**.\n\n*(No operational telemetry implied; publication remains conceptual.)*\n",
        "bias_annotation": "### A.6.1:6 - Bias-Annotation *(informative)*\n\nThis pattern intentionally biases Mechanism authoring toward explicit contracts, context-local semantics, and auditable reuse.\n\n* **Gov (governance).** Bias toward publishable obligations (Signature rows, CC items) and explicit policy-ids for crossings. Risk: perceived authoring overhead. Mitigation: reuse the `U.MechAuthoring` template; keep Realizations opaque and put operational details outside the Kernel.\n* **Arch (architecture).** Bias toward locality-first semantics and **Bridge-only** transport with costs routed to **R/R_eff**. Risk: reduced convenience for ad-hoc cross-context reuse. Mitigation: publish adapter mechanisms and make crossings explicit via `Transport` (CC‑UM.3/CC‑UM.4).\n* **Onto/Epist (ontology/epistemology).** Bias toward lawful comparability (CHR legality; CG‑Spec binding) and against illegal scalarisation (e.g., ordinal means). Risk: some heuristic scoring practices become non-conformant. Mitigation: represent uncertainty explicitly and use `unknown → {degrade|abstain}` rather than coercions (CC‑UM.7).\n* **Prag (practice).** Bias toward notation-independence and against tool/vendor tokens in the Kernel. Risk: teams may want to inline CI/telemetry fields. Mitigation: keep audit surfaces conceptual (`Audit`) and reference operational hooks by id only (CC‑UM.6).\n* **Did (didactic).** Bias toward explicit SlotKinds/SlotSpecs over positional parameters. Risk: steep learning curve. Mitigation: allow non-normative projections (`ValueKindView`) and include a “60‑second” script plus a builder’s checklist (A.6.1:4.7/4.8).\n",
        "conformance_checklist": "### A.6.1:7 - Conformance Checklist (normative)\n\n| ID | Requirement |\n|----|-------------|\n| **CC‑UM.0** | **A.6.0 alignment:** a conformant `U.Mechanism` publication **MUST** include the four‑row `U.Signature` Block (A.6.0). `OperationAlgebra` (including inline SlotSpecs per A.6.0:4.1.1/A.6.5) is the **Vocabulary** row, `LawSet` the **Laws** row, and `Applicability` the **Applicability** row; the universal block remains the comparability contract. Any `SlotIndex` is an index/projection and **MUST NOT** be treated as a fifth Signature row. |\n| **CC‑UM.1** | **Complete Mechanism.Intension:** a conformant `U.Mechanism` publication **MUST** publish: `IntensionHeader(id, version, status); Imports; SubjectBlock (SubjectKind, BaseType, SliceSet, ExtentRule, ResultKind?); SlotIndex (A.6.5); OperationAlgebra; LawSet; AdmissibilityConditions; Applicability; Transport (Bridge named; ReferencePlane); Γ_timePolicy; PlaneRegime; Audit`. `IntensionHeader.id` **MUST** be PascalCase; `version` **MUST** follow SemVer; `status ∈ {draft|review|stable|deprecated}`. Eligibility/admission tests **MUST** be expressed as `AdmissibilityConditions`, not as `LawSet`. |\n| **CC‑UM.2** | **A.6.A alignment (Realizations):** if realized as an Architheory (CAL/LOG/CHR), the Realization artifact **MUST** use the A.6.A header and obey A.6.A: it **MUST** `provide` exactly one Γ iff `classification=CAL`, it **MUST NOT** provide any Γ if `classification ∈ {LOG|CHR}`, and its imports **MUST** be acyclic. Realization internals **MUST** remain opaque. Realizations **MAY** tighten but **MUST NOT** relax `LawSet` or `AdmissibilityConditions`. Kernel‑level publications **MUST NOT** mint an A.6.A header. |\n| **CC‑UM.3** | **Bridge‑only transport:** for any cross‑context/plane use, `Transport` **MUST** name the BridgeId and channel (F.9) and **MUST** record `ReferencePlane(src,tgt)` (C.2.1); when planes differ it **MUST** name `CL^plane`. Implicit crossings **MUST NOT** occur. When typed reuse is involved, the two‑bridge rule **MUST** apply (scope CL and kind `CL^k` penalties routed separately to **R**/**R_eff**). `Transport` is a declarative policy surface and **MUST NOT** be used to introduce a `U.Transfer` edge (E.18 term separation). It **MUST NOT** restate CL ladders or Φ/Ψ/Φ_plane tables; it **MUST** reference policy ids / registries. |\n| **CC‑UM.4** | **R‑only routing:** any CL / `CL^k` / `CL^plane` penalties declared or incurred by `Transport` **MUST** reduce the Reliability channel only (**R**, or **R_eff** when distinguished) per **B.3**; they **MUST NOT** mutate **F/G**. |\n| **CC‑UM.5** | **CG‑Spec binding:** if the Mechanism defines or induces any numeric comparison or aggregation, it **MUST** bind to **CG‑Spec/MM‑CHR** (lawful **SCP**, Γ‑fold, MinimalEvidence; normalize‑then‑compare) and obey CHR legality: partial orders **MUST** return sets; ordinal means **MUST NOT** be computed; interval/ratio arithmetic **MUST** occur only with unit alignment (CSLC‑proven). |\n| **CC‑UM.6** | **E.8/E.10 compliance:** the A.6.1 publication **MUST** include Tell–Show–Show under **“Archetypal Grounding”** and **MUST** respect twin registers & I‑D‑S. Any new `U.*` token (including any new `U.Type`) **MUST** have a DRR and a `LEX.TokenClass` entry; `BaseType` **MUST** reference an existing `U.Type` (no in‑place minting), and any new `U.Type` required for that reference **MUST** be minted via DRR/LEX outside the mechanism definition. Non‑spec surfaces **MUST** end with **“…Description”**. Core narrative **MUST NOT** include tool/vendor tokens. |\n| **CC‑UM.7** | **Unknowns tri‑state:** guard predicates in `AdmissibilityConditions` **MUST** be deterministic, context‑local, and fail‑closed; they **MUST** define `unknown → {degrade|abstain}` and **MUST NOT** coerce unknowns to 0/false. Sandbox/probe branches **MUST** live in **SoS‑LOG** (not Acceptance). |\n| **CC‑UM.8** | **Multi‑level specialisation discipline:** if a Mechanism declares itself as `⊑` or `⊑⁺` of another Mechanism, it **MUST** satisfy A.6.1:4.2.1 (explicit parent+morphism kind; SlotKind invariance; monotone ValueKind narrowing; no new mandatory inputs to inherited ops). |\n| **CC‑UM.9** | **SlotIndex is a view:** `SlotIndex` **MUST** be mechanically derivable from (i) the per‑operator SlotSpecs in `OperationAlgebra` (A.6.0:4.1.1) plus (ii) any guard‑only SlotSpecs used by `AdmissibilityConditions`; it **MUST NOT** contradict those SlotSpecs. Any didactic `ValueKindView` (or “ParamKind” lists) are non‑normative projections only. |\n",
        "anti_patterns": "### A.6.1:8 - Common Anti-Patterns and How to Avoid Them *(informative)*\n\n| Anti-pattern | What it looks like | Remedy |\n| --- | --- | --- |\n| **SlotIndex treated as a 5th Signature row** | Reviews start comparing mechanisms by `SlotIndex` only; SlotSpecs disappear from operator declarations. | Keep SlotSpecs **inline per operator**; treat `SlotIndex` as a derived projection only (CC‑UM.0, CC‑UM.9). |\n| **Admission tests put in LawSet** | “Eligibility” and “coverage” checks appear as laws; implementations silently diverge. | Move operational guards to `AdmissibilityConditions` (CC‑UM.1). |\n| **Implicit crossings / hidden CL ladders** | A mechanism is reused across Contexts/planes without a declared BridgeId/ReferencePlane; CL/Φ/Ψ tables get copied into local prose. | Crossings must be explicit and **Bridge-only**; `Transport` references policy ids/registries (CC‑UM.3). |\n| **Penalties leak into F/G** | A plane/kind/scope mismatch is handled by mutating Formality or Guarantee claims. | Route penalties to **R/R_eff only**; keep **F/G invariant** (CC‑UM.4). |\n| **Illegal scalarisation** | Ordinal means or cross-unit arithmetic is performed “because we need a number”. | Bind numeric comparison/aggregation to CG‑Spec/MM‑CHR and CSLC; keep partial orders set-valued (CC‑UM.5). |\n| **Specialisation breaks SlotKind identity** | Refinements rename SlotKinds or add mandatory parameters to inherited operations. | SlotKinds are invariant; refinements only narrow ValueKinds/guards; add new ops via Extension (CC‑UM.8). |\n| **Unknown coerced to 0/false** | Guard failures silently become “false” or scores become 0. | Use tri-state discipline: `unknown → {degrade|abstain}`; probing lives in LOG branches (CC‑UM.7). |\n| **In-place minting of BaseType** | A mechanism definition introduces a new `U.Type` ad hoc. | `BaseType` references an existing `U.Type`; mint new types via DRR/LEX outside the mechanism (CC‑UM.6). |\n",
        "consequences": "### A.6.1:9 - Consequences (informative)\n\n* **Uniform kernel shape.** Scope, normalization, comparison families can be authored and compared without lexical drift.\n* **Auditable reuse.** GateCrossings are UTS-visible via **CrossingSurface** (**E.18**); penalties are transparent (**R only**), with **LanePurity** + **Lexical SD** (E.10) checks runnable (GateChecks in **A.21**; Bridge+UTS discipline **A.27**; BridgeCard **F.9**).\n* **Scalarisation avoids illegality.** Partial orders remain set‑valued; cross‑scale arithmetic is blocked by **CG‑Spec/CSLC**.\n",
        "rationale": "### A.6.1:10 - Rationale (informative)\n\nAnchoring mechanisms in **A.6.A Signature→Realization** provides a minimal, typed surface that preserves **USM** set‑algebra and **UNM** “normalize‑then‑compare” quotients while making **Part F (Bridges)** crossings explicit and costed on **R** (never **F/G**).\n",
        "sota_echoing": "### A.6.1:11 - SoTA-Echoing (post-2015 practice alignment) *(informative)*\n\n**Purpose.** To show how the FPF concept of a *Mechanism* (law-governed signature with guards and transport) aligns with, and improves upon, leading research and engineering practices after 2015.  \nAll comparisons are *informative*: they serve didactic continuity, not new normative force.\n\n#### A.6.1:11.1 - Contemporary references (post-2015 sources)\n\n**SoTA binding note (E.8:11).** No dedicated `SoTA‑Pack(Mechanisms)` (G.2) is registered at the time of writing; until one exists, this section cites primary post‑2015 sources directly and SHOULD later be reduced to ClaimSheet/CorpusLedger/BridgeMatrix ids (to avoid forking untracked SoTA narrative).\n\n1. **Algebraic effects and handlers** (post‑2015 effect systems and handler implementations) — **Adopt/Adapt.** They motivate the split “operation signature vs handling”; A.6.1 keeps `OperationAlgebra` explicit and adds `LawSet`, `AdmissibilityConditions`, and `Γ_time` so legality and time are not implicit. *(e.g., Hillerström & Lindley, 2018; Multicore/OCaml‑5 effect handlers, 2021–2022).*\n\n2. **Typed semantic translation frameworks** (institution‑style morphisms and functorial data migration) — **Adapt.** A.6.1 uses explicit refinement/extension/quotient structure (`U.MechMorph`) but requires cross‑Context transport to be **Bridge‑only** with penalties routed to **R/R_eff**. *(e.g., Spivak & Schultz, 2017; CQL practice, 2017–2023).*\n\n3. **Policy‑as‑Code** (declarative guard/risk rules) — **Adapt.** A.6.1 turns runtime policies into deterministic, fail‑closed `AdmissibilityConditions` with named Γ_time windows; evaluators and tool binding stay out of Core. *(e.g., Open Policy Agent / Rego, 2016+; UL 4600:2020; ISO 21448:2019).*\n\n4. **Session / typestate types** (post‑2015 protocol safety) — **Adapt.** Protocol constraints inform how guards can restrict legal operator sequences, but A.6.1 keeps the contract as signature+laws and surfaces sequencing constraints as explicit guard predicates rather than hidden state. *(e.g., Scalas & Yoshida, 2016–2018; mainstream session‑type toolchains, 2017–2024).*\n\n5. **Lawful measurement and calibrated uncertainty** (monotone and calibrated learning, conformal prediction) — **Adopt/Adapt.** Modern calibrated methods show why comparability must be explicit; A.6.1 binds induced numeric operations to **CG‑Spec/CSLC** and forbids illegal scalarisation (e.g., ordinal means). *(e.g., Romano et al., 2019; Angelopoulos & Bates, 2021).*\n\nEach source corresponds to a distinct *Tradition*: formal semantics, categorical algebra, compliance automation, protocol safety, and lawful AI.\n\n#### A.6.1:11.2 - Alignment with A.6.1 fields and concepts\n\n| A.6.1 construct (claim) | SoTA practice (post‑2015) | Primary sources (post‑2015) | Alignment delta encoded by A.6.1 | Adopt / Adapt / Reject |\n| --- | --- | --- | --- | --- |\n| **OperationAlgebra + LawSet** | Algebraic effects & handlers separate operation signatures from handlers. | Hillerström & Lindley (2018); OCaml‑5/Multicore OCaml effect handlers (2021–2022). | FPF keeps operator signatures explicit, adds an explicit `LawSet`, and treats admissibility/time as separate surfaces (no hidden context). | Adopt/Adapt |\n| **U.MechMorph** (Refine/Extend/Quotient) | Institution‑style morphisms / functorial data migration provide typed signature translations and quotients. | Spivak & Schultz (2017); CQL ecosystem papers/docs (2017–2023). | FPF reuses the morphism structure but requires cross‑Context use to be stated as `Transport` with an explicit `BridgeId` (F.9) and CL/CL^k/CL^plane regimes; penalties route → `R/R_eff` only (B.3). | Adapt |\n| **AdmissibilityConditions + Γ_timePolicy** | Policy‑as‑Code makes guard/risk predicates executable and reviewable. | Open Policy Agent / Rego (2016+); UL 4600:2020; ISO 21448:2019. | FPF treats policy predicates as deterministic, fail‑closed guards with named validity windows; it forbids implicit “latest” and avoids embedding evaluators in Core. | Adapt |\n| **AdmissibilityConditions** (sequencing) | Session/typestate disciplines constrain legal operation sequences. | Scalas & Yoshida (2016–2018); post‑2017 multiparty session type toolchains. | FPF uses guards to make sequencing constraints explicit and auditable, while leaving the kernel contract as signature+laws (no hidden automata). | Adapt |\n| **CG‑Spec / MM‑CHR binding** | Calibrated/monotone ML and conformal prediction make uncertainty and monotonicity explicit. | Romano et al. (2019); Angelopoulos & Bates (2021). | FPF requires scale legality (CSLC) and forbids ordinal averaging; partial orders remain set‑valued unless a lawful scorer is declared. | Adopt/Adapt |\n\n#### A.6.1:11.3 - Adopt / Adapt / Reject summary\n\n* **Adopt.** The “explicit operations + explicit laws” stance from modern semantics work, and the calibrated/monotone stance from lawful ML, because both reduce hidden assumptions.\n\n* **Adapt.** Typed translation ideas and policy‑as‑code idioms into a kernel form that is Context‑local by default, with explicit guards (`AdmissibilityConditions`) and explicit time windows (`Γ_timePolicy`) instead of implicit recency.\n\n* **Reject.** Tool‑bound semantics, automatic recency heuristics, and any cross‑scale arithmetic without CSLC proof; A.6.1 also rejects implicit cross‑Context/plane reuse.\n\n* **Cross‑Context/plane delta (E.8:11).** Whenever a SoTA practice would reuse semantics across Contexts/planes, A.6.1 requires an explicit `BridgeId` (F.9) plus CL / `CL^k` / `CL^plane` anchors and Φ/Ψ/Φ_plane policy‑ids (B.3), with penalties routed to `R/R_eff` only (never mutating `F/G`).\n\n#### A.6.1:11.4 - Holonic repeatability\n\nThe same correspondence holds at **every holonic level**:  \na part-holon declares its own `OperationAlgebra/LawSet/AdmissibilityConditions`; a whole-holon merges them via Bridges; a meta-holon re-binds mechanisms under a new Γ-closure. All penalties remain in **R / R_eff**, while **F / G** invariants propagate intact.\n",
        "relations": "### A.6.1:12 - Relations (quick pointers)\n\nBuilds on **A.6.A**; instantiates **A.2.6 USM** (ContextSlice, Γ_time, ∩/SpanUnion/translate) and **A.19/C.16 UNM** (classes, ≡\\_UNM, validity windows); uses **Part B** (Bridges, CL/CL^k/CL^plane; **no implicit crossings**); binds **CG‑Spec** for any numeric comparison/aggregation; telemetry/publication via **G.10/G.11**.\n",
        "a.6.1:end": "### A.6.1:End\n"
      },
      "content": "### A.6.1:End\n",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.6.2",
      "title": "`U.EffectFreeEpistemicMorphing` — Effect‑free morphisms of epistemes",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.6.2 - `U.EffectFreeEpistemicMorphing` — Effect‑free morphisms of epistemes\n\n**One‑line summary.** `U.EffectFreeEpistemicMorphing` (EFEM) is the universal class of **effect‑free, law‑governed morphisms between epistemes**. An EFEM morphism rewrites episteme components (ClaimGraph, `describedEntityRef`, optional `groundingHolonRef`, `viewpointRef`, `referenceScheme`, and—where C.2.1+ is in use—`representationSchemeRef` and related slots, plus meta) in a **conservative, functorial, reproducible** way, with an explicit mode for what happens to the **DescribedEntitySlot** (`DescribedEntityChangeMode ∈ {preserve, retarget}`) as defined by `C.2.1 U.EpistemeSlotGraph`.\n\n**Placement.** After **A.6.1 `U.Mechanism`** and before any specialisations (`A.6.3 U.EpistemicViewing`, `A.6.4 U.EpistemicRetargeting`).\n\n**Builds on.**\nA.6.0 `U.Signature` (subject/vocabulary/laws/applicability); A.6.1 `U.Mechanism`; A.6.5 `U.RelationSlotDiscipline`; C.2.1 `U.Episteme — Epistemes and their slot graph`; E.10.D2 (I/D/S discipline); C.3.* (Kind‑CAL / KindBridge for described‑entity classes).\n\n**Used by.**\nA.6.3 `U.EpistemicViewing`; A.6.4 `U.EpistemicRetargeting`; E.17.0 `U.MultiViewDescribing`; E.17 (MVPK); E.18 (E.TGA StructuralReinterpretation, Transduction graph).\n",
        "problem": "### A.6.2:2 - Problem\n\nConcretely, without EFEM:\n\n1. **No single place for “effect‑free” discipline.**\n   The distinction *“episteme‑only change”* vs *“Work in the world”* is already important (C.2.1 separates episteme components from Work and from presentation surfaces), but the laws for “episteme‑only” operations are scattered or implicit. \n\n2. **Described entity behaviour is unclear.**\n   Many transforms **intend** to keep “what this episteme is about” fixed (viewing), others **intend** to change it under an invariant (retargeting). Without a common *DescribedEntityChangeMode* discipline we get silent breaks in “describedEntity”: an operation that looks like a harmless format change may in fact surreptitiously change the entity‑of‑interest.\n\n3. **No functorial backbone.**\n   MVPK, KD‑CAL and E.TGA all implicitly assume that episteme transforms **compose** and respect identities, but the conditions for this (purity, conservativity, idempotence, scope) are not formulated once and reused. Different parts of the spec repeat subtly different sets of laws.\n\n4. **Slot/Ref confusion.**\n   With the new `U.EpistemeSlotGraph` and `U.RelationSlotDiscipline`, every episteme now has explicit **SlotKind / ValueKind / RefKind** discipline. Laws for “projection” or “retargeting” that are written against “fields” or unnamed tuple components are now out of alignment.\n\nThe result: engineers and tool builders can no longer tell **when they are allowed to transform epistemes without changing what is being claimed about the world**, nor what needs to be witnessed by Bridges and CL‑penalties when describedEntity does change.\n",
        "forces": "### A.6.2:3 - Forces\n\n* **Epistemic purity vs operational power.**\n  Effect‑free episteme transforms are attractive precisely because they can be reasoned about algebraically and composed freely. But the more operational power they are given (IO, solver calls, measurements), the less they remain “pure” and the more they belong under `U.Mechanism` / `U.WorkEnactment`.\n\n* **Preserve vs retarget.**\n  Viewing is describedEntity‑preserving; reinterpretation along a KindBridge is describedEntity‑retargenting. Both are important, but **they must be distinguished and witnessed differently**.\n\n* **Conservativity vs usefulness.**\n  EFEM should be **conservative**: no new intensional commitments beyond what input epistemes already entail. At the same time, we need transformations that can *factor*, *aggregate*, or *normalise* content, which may drop some information or change its representation.\n\n* **Locality vs reference planes and Bridges.**\n  Epistemes live on **reference planes** (C.2.1); cross‑plane and cross‑Context reasoning goes via Bridges and CL penalties (Part F/B.3). EFEM must respect this: it cannot smuggle plane changes or transport into “pure” content rewrites.\n\n* **I/D/S strict distinction.**\n  Intension (`I`) is not itself an episteme; `…Description` and `…Spec` are epistemes with a `DescriptionContext = ⟨DescribedEntityRef, BoundedContextRef, ViewpointRef⟩`. EFEM must support operations on D/S epistemes while keeping the I/D/S layering intact (A.7, E.10.D2).\n",
        "solution": "### A.6.2:4 - Solution — define `U.EffectFreeEpistemicMorphing` once\n\n#### A.6.2:4.1 - Informal definition\n\n> **Definition.** A `U.EffectFreeEpistemicMorphing` (EFEM) is a class of **episteme→episteme morphisms** that:\n>\n> * operate **only** on the components of an episteme as fixed in `C.2.1 U.EpistemeSlotGraph` (ClaimGraph, slots for described entity, grounding holon, viewpoint, representation/reference schemes, meta); \n> * are **effect‑free** (no Work, no Mechanism application, no mutation of systems or carriers);\n> * are **conservative** in what they claim about the described entity (no new intensional commitments beyond logical consequences under the declared ReferenceScheme);\n> * are **functorial** (identities and composition behave as expected on the category of epistemes);\n> * declare an explicit **DescribedEntityChangeMode ∈ {preserve, retarget}**, controlling how `DescribedEntitySlot` (and associated subjectRef) behaves.\n\nThe **objects** of the EFEM universe are epistemes of some `U.EpistemeKind` (typically realised as `U.EpistemeCard` / `U.EpistemeView` / `U.EpistemePublication`). The **arrows** are EFEM morphisms `f : X → Y` satisfying the P0–P5 laws below.\n\nSpecialisations:\n\n* `U.EpistemicViewing` (A.6.3) — EFEM with `DescribedEntityChangeMode = preserve`.\n* `U.EpistemicRetargeting` (A.6.4) — EFEM with `DescribedEntityChangeMode = retarget`, tied to KindBridges/ReferencePlanes.\n\n#### A.6.2:4.2 - Signature Block (A.6.0 alignment)\n\nAs a `U.Signature`, EFEM publishes the following **SubjectBlock** and the standard four‑row block (“SubjectBlock / Vocabulary / Laws / Applicability”) from A.6.0, specialised to episteme→episteme morphisms.\n\n**SubjectBlock**\n\n```\nSubjectBlock\n  SubjectKind   = U.EffectFreeEpistemicMorphing\n  BaseType      = ⟨X : U.Episteme, Y : U.Episteme⟩        // carrier pair (domain,codomain)\n  Quantification= SliceSet:=U.ContextSliceSet; \n  ExtentRule:=admissibleEpistemeMorphisms // Context slices & admissible EFEM per slice\n  ResultKind?   = U.Morphism                               // typed morphism f : X→Y\n```\n\nThis says: EFEM is “about” **morphisms between epistemes**, indexed by Context slices; its results are morphisms of a declared type `U.Morphism` in the `Ep` category.\n\n**Vocabulary (core operators & kinds)**\n\n* **Types**\n  * `U.Episteme` (as holon; realised via species `U.EpistemeCard`, `U.EpistemeView`, `U.EpistemePublication` under C.2.1).\n  * `U.EpistemeKind` (episteme n‑ary relation signature; slots per A.6.5 / C.2.1).\n  * `U.SubjectRef` (subject reference; for D/S epistemes this is `DescriptionContext = ⟨DescribedEntityRef, BoundedContextRef, ViewpointRef⟩` per IDS‑13 (DescriptionContext discipline; C.2.1 §6.1 / E.10.D2)).\n  * `U.Morphism` (arrow in `Ep`).\n  * `U.DescribedEntityChangeMode = {preserve, retarget}` (enumeration; no new Kernel type for “DescribedEntity”).\n\n* **Operators (arrow algebra)**\n\n  * `id_X : U.Morphism(X→X)` for any episteme `X`.\n  * `compose(g,f) : U.Morphism(X→Z)` where `f : X→Y`, `g : Y→Z`.\n  * `apply(f, x:U.Episteme) : U.Episteme`.\n  * `dom(f), cod(f) : U.Episteme`.\n  * `subjectRef(E) : U.SubjectRef`.\n  * `describedEntityChangeMode(f) : U.DescribedEntityChangeMode`  // EFEM‑level characteristic from C.2.1.\n\nEach operator that takes epistemes as arguments obeys **SlotSpec discipline** from A.6.5: in particular, laws below are phrased in terms of the **named SlotKinds** (`DescribedEntitySlot`, `GroundingHolonSlot`, `ClaimGraphSlot`, `ViewpointSlot`, `ReferenceSchemeSlot`, `ViewSlot`, and—when the C.2.1+ extension is used—`RepresentationSchemeSlot`) and their associated ValueKind/RefKind; we never speak of “field 1/2/3”.\n\n**Laws row** and **Applicability** are given by P0–P5 and the Scope clause below.\n\n#### A.6.2:4.3 - Laws P0–P5 (normative)\n\nAll laws below are **normative**: any morphism advertised as an instance of `U.EffectFreeEpistemicMorphing` SHALL satisfy them.\n\n##### A.6.2:4.3.1 - P0 — Typed signature & component profile (C.2.1‑grounded)\n\nFor any EFEM morphism `f : X→Y`:\n\n1. **Typed objects.** `X` and `Y` are epistemes of declared kinds `K_X, K_Y : U.EpistemeKind`, each with a SlotKind signature as per C.2.1 and A.6.5 (at least `DescribedEntitySlot`, `ClaimGraphSlot`, `ViewpointSlot?`, `RepresentationSchemeSlot?`, `ReferenceSchemeSlot?`; `GroundingHolonSlot?`, `ViewSlot?` where relevant).\n\n2. **Component projection.** For each episteme `E`, EFEM laws may refer to:\n   * `content(E) : U.ClaimGraph` — value of `ClaimGraphSlot` (stored **by value** in the minimal core);\n   * `describedEntityRef(E) : U.EntityRef` — value of the RefKind for `DescribedEntitySlot`;\n   * `groundingHolonRef?(E) : U.HolonRef` — if the episteme kind includes `GroundingHolonSlot`;\n   * `viewpointRef?(E) : U.ViewpointRef` — if `ViewpointSlot` is present;\n   * `referenceScheme?(E) : U.ReferenceScheme` — value of `ReferenceSchemeSlot` (stored **by value** in the minimal core);\n   * `representationSchemeRef?(E) : U.RepresentationSchemeRef` — only for episteme kinds that use the C.2.1+ `RepresentationSchemeSlot`;\n   * `meta(E)` — edition/provenance/status components (species‑level).\n\n3. **Declared `DescribedEntityChangeMode`.**\n   Each EFEM species **declares** a fixed `DescribedEntityChangeMode ∈ {preserve, retarget}`. At the level of individual morphisms:\n\n   * if `describedEntityChangeMode(f) = preserve`, then `describedEntityRef(Y) = describedEntityRef(X)` (and usually `groundingHolonRef(Y) = groundingHolonRef(X)` unless an explicit Grounding Bridge is declared);\n   * if `describedEntityChangeMode(f) = retarget`, then `describedEntityRef(Y) ≠ describedEntityRef(X)` in general and a **KindBridge** between the two described entities MUST be named (A.6.4 / F.9).\n\n4. **SubjectRef compatibility.**\n   For D/S epistemes (`…Description` / `…Spec`), `subjectRef(E)` is a `DescriptionContext = ⟨DescribedEntityRef, BoundedContextRef, ViewpointRef⟩` (E.10.D2). EFEM species SHALL state how `subjectRef` transforms in terms of these components (usually: preserve or explicitly adjust `ViewpointRef` while preserving `DescribedEntityRef` and `BoundedContextRef`).\n\n##### A.6.2:4.4.2 - P1 — Purity (no external effects)\n\nEFEM morphisms are **pure functions on epistemes**:\n* Applying `f : X→Y` **does not**:\n  * change any `U.System` or `U.Holon` state;\n  * execute Work (`U.WorkEnactment`) or run a `U.Mechanism` (A.6.1) with operational guards;\n  * mutate `U.PresentationCarrier` (files, databases, message buses, IDEs).\n* The **only** state change introduced by EFEM is the replacement of input epistemes by output epistemes according to `apply(f, X) = Y`, with all component changes governed by P2–P5.\n\nAny operation that requires **measurements, simulations, solver calls, or tool use with external side‑effects** SHALL be modelled as a `U.Mechanism`/`U.Work` that **produces new epistemes**, which may then be related by EFEM morphisms.\n\n##### A.6.2:4.3.3 - P2 — Conservativity (no new intensional commitments)\n\nLet `content_X = content(X)`, `content_Y = content(Y)`, with associated `referenceScheme_X`, `referenceScheme_Y`, `describedEntityRef_X`, `describedEntityRef_Y`, `groundingHolonRef_X`, `groundingHolonRef_Y`. Interpret each `content` via its `ReferenceScheme` and slots. Then:\n\n> The set of **claims about the described entities** that can be read from `Y` **SHALL NOT introduce new atomic commitments** beyond those that are logical consequences of the claims read from `X`, possibly after applying a declared correspondence between representation/reference schemes.\n\nIntuitively:\n\n* EFEM may:\n  * delete information (projection/abstraction);\n  * normalise or re‑express information (e.g., reordering ClaimGraph, changing notation via a ReferenceScheme/RepresentationScheme correspondence);\n  * add **meta‑claims about the episteme** itself (edition, source, status, witness entries).\n\n* EFEM may **not**:\n  * assert new atomic facts about the described entities or grounding holons beyond what is derivable from input ClaimGraphs under the declared ReferenceSchemes;\n  * silently widen the scope of claims (e.g., treating local facts as global, changing Context or ReferencePlane without a Bridge).\n\nWhere `describedEntityChangeMode(f) = retarget`, conservativity is understood **relative to a declared invariant** of the KindBridge (A.6.4): e.g., conservation of energy for a Fourier transform, or preservation of functional behaviour for a structural reinterpretation.\n\n##### A.6.2:4.3.4 - P3 — Functoriality (identity, composition, correspondence)\n\nWe work in the category **Ep** whose objects are epistemes (species of `U.Episteme`) and whose arrows are EFEM morphisms satisfying P0–P2, together with the functor\n\n```\n+α : Ep → Ref\n```\n\nthat maps each episteme to the object it describes (value of `DescribedEntitySlot`, i.e. `describedEntityRef(E)`) as in the mathematical layer for epistemes. EFEM instances with `describedEntityChangeMode(f) = preserve` are **vertical morphisms** for α (`α(f) = id`), while those with `describedEntityChangeMode(f) = retarget` reindex along a declared `KindBridge` in **Ref**.\n\n1. **Identities.** For each episteme `X`, there exists `id_X : X→X` such that:\n\n   ```text\n   apply(id_X, X) = X\n   compose(id_Y, f) = f = compose(f, id_X)\n   ```\n\n   `id_X` preserves all components (`content`, `describedEntityRef`, `groundingHolonRef`, `viewpointRef`, `representationSchemeRef`, `referenceScheme`, `meta`).\n\n2. **Composition.** For `f : X→Y`, `g : Y→Z`, the composite `h = compose(g,f)` is an EFEM morphism `X→Z` with:\n\n   ```\n   apply(h, X) = apply(g, apply(f, X))\n   describedEntityChangeMode(h) = combine(describedEntityChangeMode(f), describedEntityChangeMode(g))   // as per species-specific rules\n   ```\n\nand P0–P2 hold for `h`. For example, two `preserve` morphisms compose to `preserve`; `preserve` after `retarget` is `retarget` if the KindBridge composition exists.\n\n3. **Correspondence‑aware composition.**\n   When EFEM changes `RepresentationScheme` or `ReferenceScheme`, a **CorrespondenceModel** (as in C.2.1 §6 and E.17) may be needed to witness commutativity: composition MUST respect these correspondences up to declared isomorphism/oplax naturality (witness epistemes may be recorded in `meta`).\n\n##### A.6.2:4.3.5 - P4 — Idempotence & determinism (on fixed configuration)\n\nFor any EFEM morphism `f : X→Y` with fixed configuration (episteme kinds, `DescribedEntityChangeMode` characteristic, KindBridge/CorrespondenceModel where needed):\n\n1. **Determinism.**\n   For the same input episteme `X` (identical content, slots, meta), `apply(f, X)` yields the same output episteme `Y` up to declared structural equivalence (normal forms, alpha‑renaming etc.). There is no dependence on ambient time, randomness, network state, or solver heuristics unless these are **encoded as explicit inputs**.\n\n2. **Idempotence (up to declared equivalence).**\n   Re‑applying the same EFEM to its own output yields no further essential change:\n\n   ```text\n   apply(f, apply(f, X)) ≅ apply(f, X)\n   ```\n\n   where `≅` denotes the structural equivalence declared for the episteme kinds in question (e.g., ClaimGraph normalisation).\n\nSpecies MAY weaken idempotence to “idempotent after normalisation”; if so, the normalisation step MUST itself be specified as an EFEM morphism and the composite be idempotent.\n\n##### A.6.2:4.3.6 - P5 — Applicability, scope & compatibility\n\nEach EFEM species **publishes** an Applicability clause:\n\n* **EoI / described entity class.**\n  A constraint on the allowed ValueKind of `DescribedEntitySlot` (via `EoIClass ⊑ U.Entity`): e.g., “epistemes describing `U.Holon` that are systems of type X”.\n\n* **Grounding holon & Context.**\n  Constraints on `GroundingHolonSlot` and `U.BoundedContext`: where the morphism is valid (lab, runtime environment, organisational context).\n\n* **Representation/ReferenceSchemes.**\n  Enumerates supported `RepresentationScheme`/`ReferenceScheme` pairs and any required CorrespondenceModels.\n\n* **Viewpoint discipline.**\n  For Descr/Spec epistemes, EFEM SHALL specify which `U.Viewpoint`s (E.17.0) it supports and how it interacts with `U.MultiViewDescribing` families (e.g., “works only on engineering viewpoints from TEVB” or “viewpoint‑agnostic normalisation”).\n\nApplying EFEM **outside** its Applicability (e.g., wrong EoIClass, missing grounding holon, incompatible Viewpoint) is **non‑conformant**: a conformant implementation MUST reject such attempts or model them as different mechanisms/works, not as EFEM.\n\nCross‑Context or cross‑plane use (changing `U.BoundedContext` or `ReferencePlane`) is **not part of EFEM**; it is handled by Bridges (Part F) and A.6.1 transport, which then feed new epistemes into EFEM.\n",
        "archetypal_grounding": "### A.6.2:5 - Archetypal Grounding (Tell–Show–Show)\n\nThe examples below show how EFEM is intended to be used across I/D/S and Viewpoint/MVPK layers.\n\n#### A.6.2:5.1 - Typed formalisation `Specify_DS : D→S` (species of EFEM)\n\n*Context.* You have an informal `U.MethodDescription` for a safety check and want a more formal `U.MethodSpec` with test harness obligations, but **about the same method**.\n\n*Shape.*\n\n* Domain: `X = U.MethodDescription` episteme with\n  `describedEntityRef(X) : U.MethodRef`, `content(X) : U.ClaimGraph_D`, `viewpointRef(X)` an engineering viewpoint (TEVB), `ReferenceScheme_D`.\n* Codomain: `Y = U.MethodSpec` episteme with the **same** `describedEntityRef(Y) = describedEntityRef(X)`, `viewpointRef(Y) = viewpointRef(X)`, more structured `content(Y) : U.ClaimGraph_S`, stronger ReferenceScheme (explicit pre/post, obligations).\n\n`Specify_DS` is a species of EFEM:\n\n* `describedEntityChangeMode(Specify_DS) = preserve`.\n* P1 — effect‑free: it transforms epistemes only.\n* P2 — conservative: any behavioural claims in the Spec must be logically entailed by the informal Description and the underlying Method Intension; if the spec makes stronger claims, that is modelled as creating a **new Intension with its own D/S pair**, not as a valid EFEM instance.\n* P3–P5 — functorial and scoped: specs compose, applicability bound to the appropriate engineering context and Viewpoints.\n\nThis matches A.7/E.10.D2 strict distinction: I→D (`Describe_ID`) is not itself an episteme→episteme morphism, but `Specify_DS` is; EFEM supplies its laws.\n\n#### A.6.2:5.2 - Internal normalisation of a View (species of EFEM, `describedEntityChangeMode = preserve`)\n\n*Context.* In MVPK you compute a engineering view `V` of a system description; you then normalise the view (sort, factor, put equations into normal form) without changing what it says.\n\nLet `X = V_raw`, `Y = V_norm`, both `U.EpistemeView` instances with the same:\n\n* `describedEntityRef(X) = describedEntityRef(Y)` (same system);\n* `groundingHolonRef(X) = groundingHolonRef(Y)` (same environment);\n* `viewpointRef(X) = viewpointRef(Y)` (same Viewpoint);\n* `representationSchemeRef(X) = representationSchemeRef(Y)` (same notation).\n\nThe EFEM `NormalizeView : X→Y`:\n\n* has `describedEntityChangeMode(NormalizeView) = preserve`;\n* changes only `content` and maybe `meta` (e.g. “normalised at edition E”);\n* is idempotent and deterministic (P4);\n* is conservative (P2): no new claims, only re‑expression.\n\nMVPK can then **assume** functoriality of such normalisations without re‑stating the EFEM laws.\n\n#### A.6.2:5.3 - Retargeting sketch (bridge‑backed, `describedEntityChangeMode = retarget`)\n\n*Context.* E.TGA’s StructuralReinterpretation maps a physical layout view into a functional behaviour view, changing the described entity from “physical module assembly” to “functional graph” along a KindBridge.\n\nInside EFEM, this becomes a species with `describedEntityChangeMode = retarget`:\n* input episteme describes `S₁` (e.g. a component hierarchy holon);\n* output episteme describes `S₂` (e.g. a functional network holon);\n* a declared `KindBridge(S₁,S₂)` and invariant (e.g. behavioural equivalence) provide the semantic glue;\n* P2 conservativity is checked **w.r.t. that invariant**.\n\nThe details belong to A.6.4/E.TGA; EFEM provides the generic discipline.\n\n#### A.6.2:5.4 - Worked SlotSpec example (engineering SystemDescription episteme kind)\n*(informative)*\n\nTo make the SlotKind/ValueKind/RefKind discipline and EFEM laws concrete, consider a simple engineering `U.EpistemeKind` for system descriptions over `EoIClass ⊑ U.Entity` with `EoIClass = U.System` in a given Context. A minimal SlotSpec table for such a kind could be:\n\n| SlotKind              | ValueKind                                     | RefKind / refMode   | Notes                                                                 |\n| --------------------- | --------------------------------------------- | ------------------- | --------------------------------------------------------------------- |\n| `DescribedEntitySlot` | `U.Entity` (constrained by `EoIClass = U.System`) | `U.EntityRef`    | describes which system the episteme is about                          |\n| `GroundingHolonSlot`  | `U.Holon`                                     | `U.HolonRef`        | plant / runtime SoS grounding measurements and validation             |\n| `ClaimGraphSlot`      | `U.ClaimGraph`                                | ByValue             | KD‑CAL/LOG‑CAL ClaimGraph for the description or spec                 |\n| `ViewpointSlot`       | `U.Viewpoint`                                 | `U.ViewpointRef`    | engineering viewpoint (e.g. from TEVB) under which D/S are validated |\n| `ReferenceSchemeSlot` | `U.ReferenceScheme`                           | ByValue             | how the ClaimGraph is read against described entity and grounding     |\n\nThis table is an instance of A.6.5 `U.RelationSlotDiscipline`: each row is a SlotSpec triple ⟨SlotKind, ValueKind, refMode/RefKind⟩; no additional kernel types are introduced, and C.2.1’s constraints on `DescribedEntitySlot`/`GroundingHolonSlot` are preserved.\n\nTwo typical EFEM species over this kind are:\n* `Specify_DS_Sys : SystemDescription → SystemSpec` — a `DescribedEntityChangeMode = preserve` species that:\n  * **reads** `DescribedEntitySlot`, `GroundingHolonSlot`, `ViewpointSlot`, `ReferenceSchemeSlot` and **writes** a refined `ClaimGraphSlot` and possibly a strengthened `ReferenceSchemeSlot`;\n  * satisfies P2 by only adding claims that are logical consequences of the original description plus the fixed Intension (A.7/E.10.D2);\n  * satisfies CC‑C.2.1‑5 by explicitly declaring its slot profile and change mode.\n\n* `Normalize_EngView : EpistemeView → EpistemeView` — a view‑normalisation EFEM (again with `DescribedEntityChangeMode = preserve`) that:\n  * **reads** all slots and **writes** only `ClaimGraphSlot` (normal form) and `meta`;\n  * is idempotent and deterministic (P4) and pure (P1);\n  * is conservative (P2) by construction: it never introduces new atoms about the described system.\n\nIn later A.6.3/A.6.4/E.17.\\* patterns, concrete EpistemeKinds (for specific engineering description/specification idioms) are expected to provide SlotSpecs of this general shape and to state explicitly, per CC‑C.2.1‑5 / CC‑EFEM.\\*, which slots their EFEM species read and write.\n",
        "a.6.2:6___bias_&_defaults_(informative)": "### A.6.2:6 - Bias & Defaults (informative)\n\n* **Episteme‑first, world‑second.** EFEM is strictly about **epistemes as objects**; any world contact (measurements, executions) lives in `U.Mechanism`/`U.Work` and produces new epistemes that EFEM may subsequently relate.\n\n* **SlotKinds, not “fields”.** Laws talk about `DescribedEntitySlot`, `GroundingHolonSlot`, etc., and their ValueKind/RefKind, as per A.6.5 and C.2.1; they never use unnamed tuple positions or “role 1/2/3”. This keeps EFEM aligned with the slot discipline used for methods, roles, services, and other n‑ary relations.\n\n* **Local‑first semantics.** EFEM is **Context‑local**; crossings of Context or ReferencePlane are always delegated to Bridges / A.6.1 transport (with CL penalties to `R/R_eff` only). No “implicit cross‑Context EFEM” is permitted.\n\n* **I/D/S respect.** EFEM never collapses Intension with Description/Spec: I→D and D→S operations are typed explicitly and either (i) conform to EFEM laws where they are episteme→episteme, or (ii) remain separate morphism classes (A.7) while being described as EFEM‑conformant.\n",
        "conformance_checklist": "### A.6.2:7 - Conformance Checklist (normative)\n\n| ID                                                  | Requirement                                                                                                                                                                                                                                                                                                                                                                                           |\n| --------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **CC‑EFEM.1 (Typed episteme objects).**             | Every morphism advertised as `U.EffectFreeEpistemicMorphing` SHALL have domain and codomain epistemes whose kinds (`U.EpistemeKind`) publish SlotKinds/ValueKinds/RefKinds according to C.2.1 and A.6.5 (at least `DescribedEntitySlot` and `ClaimGraphSlot`; other slots as declared).                                                                                                               |\n| **CC‑EFEM.2 (Declared DescribedEntityChangeMode).** | Each EFEM **species** SHALL declare the `DescribedEntityChangeMode` characteristic `describedEntityChangeMode : U.Morphism → {preserve, retarget}` as per C.2.1. For every instance `f`, `describedEntityChangeMode(f)` MUST be either `preserve` (⇒ `describedEntityRef` unchanged) or `retarget` (⇒ a KindBridge and invariant are explicitly named; see A.6.4 / F.9).                                                                                         |\n| **CC‑EFEM.3 (Purity).**                             | EFEM morphisms SHALL be effect‑free: they MUST NOT directly perform Work or run mechanisms with operational guards; they only read input epistemes and construct output epistemes consistent with P2–P5. Any use of external solvers/measurements MUST be modelled as separate Mechanisms/Work that feed new epistemes into EFEM.                                                                     |\n| **CC‑EFEM.4 (Conservativity).**                     | Laws for EFEM species SHALL state their conservativity regime: claims in the output MUST be logical consequences of input claims under declared ReferenceSchemes and any CorrespondenceModels/KindBridges. If an operation may strengthen claims (e.g. add commitments not entailed by inputs), it is **not** EFEM and MUST be modelled separately.                                                   |\n| **CC‑EFEM.5 (Functoriality & idempotence).**        | EFEM species SHALL support identity and composition with the usual category laws, and SHALL specify any structural equivalence under which idempotence holds. Non‑deterministic or order‑sensitive behaviour (beyond declared structural equivalences) is non‑conformant.                                                                                                                             |\n| **CC‑EFEM.6 (Applicability & scope).**              | Each EFEM species SHALL publish Applicability in terms of: allowed EoI classes (ValueKind for `DescribedEntitySlot`), Context/BoundedContext and grounding holon constraints, supported Viewpoints and representation/reference schemes. Applying EFEM outside this Applicability (including cross‑Context or cross‑plane) is non‑conformant. Crossings MUST be delegated to Bridges/A.6.1 transport. |\n| **CC‑EFEM.7 (I/D/S & subjectRef discipline).**      | For any episteme that is a `…Description`/`…Spec` (E.10.D2), EFEM laws SHALL be phrased in terms of `DescriptionContext = ⟨DescribedEntityRef, BoundedContextRef, ViewpointRef⟩` and MUST respect the I/D/S discipline **and** DescriptionContext invariants (including IDS‑13 Viewpoint‑locality as defined in E.10.D2/C.2.1): `Describe_ID` lives in A.7; `Specify_DS` MAY be species of EFEM but MUST preserve Intension. |\n| **CC‑EFEM.8 (Slot‑level read/write declaration).**  | Any EFEM species that defines morphisms between epistemes SHALL also satisfy C.2.1 checkpoint CC‑C.2.1‑5: it MUST state whether it is a species of `U.EffectFreeEpistemicMorphing`/`U.EpistemicViewing`/`U.EpistemicRetargeting`, declare its `describedEntityChangeMode`, name which SlotKinds it reads and writes, and state its behaviour on `describedEntityRef`, `groundingHolonRef`, `viewpointRef`, and `referenceScheme`. |\n",
        "a.6.2:8___sota‑echoing_(informative,_lineage)": "### A.6.2:8 - SoTA‑Echoing (informative, lineage)\n\nEFEM is intentionally “thin”: it provides a **minimal categorical and slot‑based discipline** for episteme→episteme morphisms, making it easy to align with several post‑2015 lines of work:\n\n* **Categorical semantics & displayed categories.**\n  Treating `Ep` as a category over `Ref` via a functor `α : Ep → Ref` (mapping each episteme to its described entity) matches the *displayed categories* view on fibrations: EFEM arrows are those morphisms in `Ep` that are “vertical” (preserve α) or “structured reindexings” (retarget under a KindBridge). This is exactly the intended alignment with C.2.1’s subjectRef/ReferencePlane picture.\n\n* **Optics as universal projections.**\n  Viewing operations (`U.EpistemicViewing`) refine EFEM in a way analogous to **lenses/prisms/traversals** in the optics literature: effect‑free, compositional accessors for parts of a larger structure. EFEM captures the laws that underlie those projections (purity, conservation, functoriality); optics‑style constructions can then be used inside discipline packs without modifying the core.\n\n* **Structured cospans & correspondences.**\n  Many correspondence‑based multi‑view patterns (ISO 42010 correspondences, model synchronisation, traceability links) can be seen as spans/cospans between epistemes. EFEM ensures that the legs of such cospans are effect‑free and conservative, while CorrespondenceModels carry the extra structure needed for consistency management.\n\n* **Bidirectional transformations (BX).**\n  The “no new commitments” and “functorial & idempotent” constraints mirror modern BX practice around **consistency restoration**: EFEM is the universal core that BX‑like constructions (view updates, synchronisers) must respect when instantiated for epistemes.\n\nEFEM does *not* prescribe a specific calculus (deductive, probabilistic, latent‑space), nor a specific representation (symbolic vs distributed); those choices are captured in `U.ClaimGraph`, `U.RepresentationScheme` and discipline‑level architheories. EFEM only says what it means to transform epistemes **legally** in that chosen substrate.\n",
        "consequences": "### A.6.2:9 - Consequences\n\n* **Single place for episteme‑to‑episteme laws.**\n  All effect‑free transforms of knowledge artefacts, across KD‑CAL, MVPK, E.TGA, discipline packs, can now be defined as species of EFEM, instead of each family re‑inventing its own law set.\n\n* **Clear separation from mechanisms & work.**\n  Anything that touches the world (measurements, execution, simulation) is forced into `U.Mechanism` / `U.WorkEnactment`, with CL‑penalised Bridges and Γ_time; EFEM remains pure and compositional.\n\n* **Stable backbone for Viewing & Retargeting.**\n  A.6.3 and A.6.4 do not need to repeat P0–P5; they specialise EFEM with additional constraints (preserve/retarget). Other patterns (e.g. MultiViewDescribing, MVPK, E.TGA StructuralReinterpretation) can depend on EFEM as a stable base.\n\n* **Slot‑level clarity.**\n  By formulating EFEM laws in terms of SlotKinds/ValueKinds/RefKinds (A.6.5) and the EpistemeSlotGraph (C.2.1), it becomes much harder for Episteme to confuse “object of talk”, “slot in a relation”, and “reference to that object”.\n\n* **Better didactics.**\n  The old “semantic triangle” becomes a didactic projection of EFEM over the EpistemeSlotGraph: EFEM + C.2.1 explain precisely what the triangle was trying to gesture at (symbol, concept, object), while correctly foregrounding operations, viewpoints, grounding holons, and reference schemes.\n",
        "rationale": "### A.6.2:10 - Rationale\n\n**Why a separate EFEM pattern (A.6.2) instead of folding into A.6.1 or C.2.1?**\n\n* A.6.1 governs **Mechanisms** (operations with AdmissibilityConditions, Γ_time, transport and Bridges)—too operational for the pure episteme transforms we want here.\n* C.2.1 fixes the **ontology of epistemes** (slots, components, ReferencePlane), but does not talk about morphisms. EFEM is explicitly a **morphism‑level** pattern over that ontology.\n\nThis split mirrors how Signature (A.6.0) separates “what is declared” from “how it is realised”: C.2.1 says what an episteme is; A.6.2 says what a legal episteme→episteme transform is.\n\n**Why insist on DescribedEntityChangeMode?**\n\nBecause almost all subtle errors in multi‑view reasoning show up as **silent retargeting**: a transform that appears to keep the same object‑of‑talk actually changes it (e.g., from “component assembly” to “function bundle”) without naming the bridge or invariant. By forcing every species to declare `preserve` vs `retarget`, EFEM makes those decisions explicit and reviewable.\n\n**Why attach EFEM to SlotKinds instead of informal “fields”?**\n\nFPF already committed to a single SlotKind/ValueKind/RefKind discipline (A.6.5) across relations, methods, roles, and now epistemes. Re‑using that discipline here:\n\n* aligns episteme morphisms with the rest of the framework;\n* enables later mechanised checks (e.g., that a viewing only touches slots it promised to touch);\n* avoids minting yet another notion of “parameter” or “role in a relation”.\n",
        "relations": "### A.6.2:11 - Relations\n\n* **Specialises / is specialised by.**\n\n  * Builds on A.6.0 `U.Signature` and A.6.1 `U.Mechanism` for the uniform SubjectBlock/vocabulary/laws/applicability structure.\n  * Specialised by A.6.3 `U.EpistemicViewing` (describedEntity‑preserving EFEM) and A.6.4 `U.EpistemicRetargeting` (describedEntity‑retargering EFEM).\n\n* **Constrained by.**\n  A.6.5 `U.RelationSlotDiscipline` (SlotKind/ValueKind/RefKind); C.2.1 `U.EpistemeSlotGraph` (episteme components, ReferencePlane); E.10.D2 (I/D/S discipline); Part F (Bridges, CL, ReferencePlane crossings); E.10 (LEX‑BUNDLE naming rules, especially on `…Slot` / `…Ref` and ban on Subject/Object in episteme tech names).\n\n* **Consumed by.**\n  E.17.0 `U.MultiViewDescribing` (families of D/S epistemes under Viewpoints); E.17 (MVPK — publication as species of Viewing/EFEM); E.18 (E.TGA StructuralReinterpretation and other transductions over epistemes); KD‑CAL/LOG‑CAL rules that reason about episteme transforms categorically.\n",
        "a.6.2:end": "### A.6.2:End\n"
      },
      "content": "### A.6.2:End\n",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.6.3",
      "title": "`U.EpistemicViewing` — describedEntity‑preserving morphism**",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.6.3 - `U.EpistemicViewing` — describedEntity‑preserving morphism**\n\n**One‑line summary.** `U.EpistemicViewing` is the **describedEntity‑preserving** species of `U.EffectFreeEpistemicMorphing`: an effect‑free projection between epistemes that may change content and representation, but **never changes what the episteme is about** (the occupant of `DescribedEntitySlot` in C.2.1).\n\n**Placement.** After **A.6.2 `U.EffectFreeEpistemicMorphing`**, before **A.6.4 `U.EpistemicRetargeting`**.\n\n**Builds on.**\nA.6.0 `U.Signature`; A.6.2 `U.EffectFreeEpistemicMorphing`; A.6.5 `U.RelationSlotDiscipline`; A.7/E.10.D2 (I/D/S discipline, `DescriptionContext`); C.2.1 `U.Episteme — Epistemes and their slot graph`; C.2 (KD‑CAL/LOG‑CAL, `subjectRef`, ReferencePlane).\n\n**Used by.**\nE.17.0 `U.MultiViewDescribing`; E.17 (MVPK — Multi‑View Publication Kit); E.17.1/E.17.2 (Viewpoint bundle libraries, TEVB); B.5.3 (Role‑EpistemicViewing); discipline packs for architecture, safety, and ML/LLM‑based representations.\n",
        "problem": "### A.6.3:2 - Problem\n\nWithout a dedicated pattern for EpistemicViewing:\n1. **Views vs retargetings blur.**\n   Operations that *intend* to change only representation (viewing) are easily conflated with operations that change the **object‑of‑talk** (retargeting). A Fourier‑style transform or a StructuralReinterpretation in E.TGA can quietly drift from “view of S” into “view of a different S′”, without declaring a `KindBridge`.\n\n2. **“View” vs “viewpoint” vs “surface” collapse.**\n   In standards and tools, “view” is often used interchangeably to mean:\n   * the **viewpoint** (specification of concerns and conformance rules),\n   * the **episteme** produced under that viewpoint, and\n   * the **surface** (rendered document or GUI).\n     Without a clear episteme‑level notion of viewing, MVPK and E.17.0 cannot cleanly separate these layers.\n\n2. **No describedEntity guarantees.**\n   A projection that looks like a harmless slice of a system description may in fact:\n   * change `describedEntityRef` (switching to a subsystem or a function),\n   * change `groundingHolonRef` (different plant or runtime),\n   * or smuggle in new intensional claims.\n     Without explicit laws on C.2.1 components, “view” becomes an informal metaphor, not a reliable morphism class.\n\n4. **Multi‑view reasoning has no core discipline.**\n   Multi‑view patterns (ISO 42010 viewpoint libraries, SysML v2 view queries, TEVB, MVPK faces) need:\n   * **vertical** projections over the same described entity (`α : Ep → Ref` fixed),\n   * and **correspondence‑based** projections that rely on explicit cross‑episteme links.\n     If each family re‑invents its own notion of “view”, consistency and tool support degrade.\n",
        "forces": "### A.6.3:3 - Forces\n\n* **Same entity, different concerns.**\n  Stakeholders want different slices of the same description/specification, sometimes under different viewpoints, without re‑identifying the entity (system, method, role, service) being described.\n\n* **Internal vs cross‑episteme views.**\n  Some views depend only on a single episteme (direct viewing); others depend on a **CorrespondenceModel** (e.g. aligning requirements and design models). Both must be supported, but with **different obligations**.\n\n* **Conservativity vs expressivity.**\n  A view must not introduce new commitments about the described entity, but it may:\n\n  * aggregate or factor claims,\n  * change representation regime (diagrammatic vs symbolic vs latent),\n  * or shift to a different inference regime, **as long as this is conservative**.\n\n* **I/D/S strictness.**\n  `…Description` and `…Spec` are epistemes with `DescriptionContext = ⟨DescribedEntityRef, BoundedContextRef, ViewpointRef⟩`. Viewing must work over these **DescriptionContexts** without collapsing Intension (`I`) into episteme or confusing D/S with publication surfaces.\n\n* **Slot discipline and modularity.**\n  With C.2.1 and A.6.5, epistemes now have explicit `SlotKind`/`ValueKind`/`RefKind` triples. Viewing laws must be stated **at the slot level**, not in terms of ad‑hoc “fields”, so they can be reused across engineering, publication, and discipline packs.\n",
        "solution": "### A.6.3:4 - Solution — `U.EpistemicViewing` as EFEM profile (`describedEntityChangeMode = preserve`)\n\n#### A.6.3:4.1 - Informal definition\n\n> **Definition (informal).**\n> `U.EpistemicViewing` is the **describedEntity‑preserving species** of `U.EffectFreeEpistemicMorphing`.\n> A `U.EpistemicViewing v : X→Y`:\n>\n> * takes an input episteme `X` and produces an output episteme `Y`,\n> * preserves the occupant of `DescribedEntitySlot` (`describedEntityRef(Y) = describedEntityRef(X)`),\n> * may refine or re‑express `content : U.ClaimGraph`, `viewpointRef`, `representationSchemeRef`, and `referenceScheme`,\n> * is **effect‑free and conservative** (no new intensional claims about the same described entity),\n> * and composes functorially with other epistemic viewings.\n\nIn C.2.1 terms `U.EpistemicViewing` behaves like a **lens/optic over the episteme slot graph**: it focuses on some SlotKinds (typically `ClaimGraphSlot`, `ViewpointSlot`, `RepresentationSchemeSlot`, `ReferenceSchemeSlot`) while preserving `DescribedEntitySlot` (and usually `GroundingHolonSlot`).\n\n#### A.6.3:4.2 - Signature (A.6.0 / A.6.5 alignment)\n\n**Signature header.**\n`U.EpistemicViewing` is a **Morphism‑kind** under A.6.0:\n\n```\nSubjectBlock\n  SubjectKind    = U.EpistemicViewing\n  BaseType       = ⟨X:U.Episteme, Y:U.Episteme⟩      // carrier pair\n  Quantification = SliceSet := U.ContextSliceSet;\n                   ExtentRule := admissible view morphisms\n  ResultKind     = U.Morphism                        // an instance v\n```\n\n**Vocabulary (re‑uses A.6.2).**\n* **Types.** `U.Episteme`, `U.SubjectRef`, `U.Morphism`, `U.EpistemicViewing`.\n* **Operators.**\n  * `id    : U.Morphism(X→X)`\n  * `compose(g,f) : U.Morphism(X→Z)` where `f:X→Y`, `g:Y→Z`\n  * `apply(v, x:U.Episteme) : U.Episteme`\n  * `dom(v), cod(v) : U.Episteme`\n  * `subjectRef(-) : U.SubjectRef`\n**Slot‑level discipline.**\nDomain and codomain epistemes are instances of some `U.Episteme` species (typically `U.EpistemeCard`, `U.EpistemeView`, or `U.EpistemePublication`) whose episteme kinds each provide SlotSpecs (A.6.5) including at least:\n  * `DescribedEntitySlot` (ValueKind `U.Entity`, RefKind `U.EntityRef`),\n  * `GroundingHolonSlot?` (ValueKind `U.Holon`, RefKind `U.HolonRef`),\n  * `ClaimGraphSlot` (ValueKind `U.ClaimGraph`, by‑value),\n  * `ViewpointSlot?` (ValueKind `U.Viewpoint`, RefKind `U.ViewpointRef`),\n  * `ReferenceSchemeSlot` (ValueKind `U.ReferenceScheme`, by‑value),\n  * and, where C.2.1+ is in use, `RepresentationSchemeSlot`, `ViewSlot` and related slots.\n\nPractical species of EpistemicViewing will very often take `X` and `Y` from the same `U.EpistemeKind`, but the pattern itself only requires that the SlotSpecs of the domain and codomain kinds be **compatible** in the sense of A.6.5, not literally identical.\n\n**Relation to EFEM.**\n* Every `U.EpistemicViewing` is an **EFEM morphism** with `describedEntityChangeMode = preserve` in the sense of A.6.2/C.2.1.\n* It **inherits** P0–P5 from A.6.2, specialised to the case where the occupant of `DescribedEntitySlot` is unchanged.\n\n#### A.6.3:4.3 - Laws (EV‑0…EV‑6, over C.2.1 components)\n\nAll laws below are **in addition** to A.6.2’s EFEM laws P0–P5 and SHALL be read directly against C.2.1 components and A.6.5 SlotSpecs.\n\n**EV‑0 - Species & DescribedEntityChangeMode.**\n\n* Any morphism `v:X→Y` declared as `U.EpistemicViewing` **MUST**:\n  * be a species of `U.EffectFreeEpistemicMorphing` (A.6.2), and\n  * declare `describedEntityChangeMode(v) = preserve`.\n* Consequently:\n  * `DescribedEntitySlot` has the **same ValueKind and RefKind** in the episteme kind of `X` and `Y` (same `EoIClass ⊑ U.Entity`);\n  * `describedEntityRef(Y) = describedEntityRef(X)` **by definition** of the species.\n\n**EV‑1 - Typed domain/codomain & DescriptionContext behaviour.**\n\nFor any `v:X→Y` in `U.EpistemicViewing`:\n1. `X` and `Y` are instances of `U.Episteme` species whose episteme kinds both realise at least the core C.2.1 slots (`DescribedEntitySlot`, `GroundingHolonSlot?`, `ClaimGraphSlot`, `ViewpointSlot?`, `ReferenceSchemeSlot`) and obey A.6.5. Many practical species of EpistemicViewing will take `X` and `Y` from the **same** `U.EpistemeKind`, but the A.6.3 pattern only requires **SlotSpec compatibility** between domain and codomain kinds (in the sense of A.6.5), not literal kind equality.\n\n2. At the SlotKind level:\n   * `DescribedEntitySlot` is **read‑only** (no change in `describedEntityRef`).\n   * `GroundingHolonSlot`, if present, is:\n     * either preserved exactly, or\n     * changed only within an explicitly declared **grounding context** (e.g. normalising identifiers for the same plant or runtime), justified via a `Bridge` in the same ReferencePlane.\n   * `ViewpointSlot`, if present, is:\n     * either preserved (internal normalisation under the same viewpoint), or\n     * changed only to another `U.ViewpointRef` **within a declared `U.MultiViewDescribing` family** (E.17.0), with a `CorrespondenceModel` providing witnesses.\n3. For any episteme that is a `…Description`/`…Spec` (E.10.D2), `subjectRef` decodes to `DescriptionContext = ⟨DescribedEntityRef, BoundedContextRef, ViewpointRef⟩`. EpistemicViewing MUST:\n   * preserve `DescribedEntityRef`,\n   * preserve `BoundedContextRef` (unless a Bridge is explicitly cited),\n   * treat `ViewpointRef` as in (2) above.\n\n**EV‑2 - Effect‑free boundary (over EpistemeSlotGraph).**\nEpistemicViewing remains **pure** in the EFEM sense:\n* It may change **only C.2.1 components of the codomain episteme**:\n  * `content : U.ClaimGraph` (e.g. filtering, aggregation, normalisation),\n  * `viewpointRef` (under the constraints in EV‑1),\n  * `representationSchemeRef` and `ReferenceScheme` (within a fixed representation family or under a declared `CorrespondenceModel`),\n  * meta‑components (edition, provenance, status flags).\n* It **MUST NOT**:\n  * invoke `U.Mechanism` or `U.WorkEnactment` (measure, execute, actuate),\n  * create or modify `U.PresentationCarrier` (no direct publishing to surfaces),\n  * cross ReferencePlanes implicitly (plane crossings go through Bridges with CL penalties in Part F).\n\nAny operational machinery (e.g. SAT/SMT solving, simulation, LLM tool‑use) MUST be modelled as a **separate `U.Mechanism`** that produces input epistemes or auxiliary artefacts consumed by the EpistemicViewing morphism.\n\n**EV‑3 - No new intensional claims about the same DescribedEntity.**\n\nLet `X` and `Y = apply(v,X)` with:\n* `content_X`, `referenceScheme_X`,\n* `content_Y`, `referenceScheme_Y`,\n* shared `describedEntityRef` and (typically) `groundingHolonRef`.\n\nThen:\n* The set of claims about `<describedEntityRef, groundingHolonRef>` obtained by reading `content_Y` through `referenceScheme_Y` **MUST NOT strictly extend** what is already entailed, in KD‑CAL/LOG‑CAL, by `content_X` read through `referenceScheme_X` under the same ReferencePlane and context.\n* Admissible changes:\n  * re‑expression (changing representation, not truth conditions),\n  * aggregation (e.g. summarising multiple claims into an explicitly derivable macro‑claim),\n  * dropping some information (lossy projection), provided **no new atomic commitments** about the same described entity are introduced.\n* Any intended strengthening of behavioural or structural commitments about the same entity **is not a valid EpistemicViewing**; it must be modelled either as:\n  * a change in Intension (new D/S pair under A.7/E.10.D2), or\n  * an A.6.4 `U.EpistemicRetargeting` plus a new Intension.\n\n**EV‑4 - Functoriality & correspondence alignment.**\n\nEpistemicViewing **inherits EFEM functoriality** and specialises it:\n\n1. **Direct EpistemicViewing (same representation scheme).**\n   Where `representationSchemeRef` and `ReferenceScheme` of `X` and `Y` are the same (up to declared normal forms), EpistemicViewing acts as a **strict functor** on ClaimGraphs:\n   * `apply(id, X) = X`,\n   * `apply(g ∘ f, X) = apply(g, apply(f, X))`,\n   * `content` transformation corresponds to a structural ClaimGraph function.\n\n2. **Correspondence‑based EpistemicViewing (representation changes).**\n   When viewing relies on a `CorrespondenceModel` between epistemes or representation schemes:\n   * the viewing morphism MUST reference that `CorrespondenceModel`,\n   * compositions involving such viewings **MUST** publish witnesses (epistemes or proof objects) that squares commute **up to declared isomorphism** (oplax naturality is allowed, but corrections are deterministic and reproducible),\n   * `describedEntityRef` and `groundingHolonRef` remain as in EV‑1; any transfer across contexts/planes goes via Bridges, not via hidden behaviour of the viewing.\n\n**EV‑5 - Idempotency & determinism on fixed configuration.**\n\nFor any `v:X→Y` in `U.EpistemicViewing`, with fixed:\n* `describedEntityRef`,\n* `groundingHolonRef`,\n* `viewpointRef`,\n* `representationSchemeRef`,\n* `referenceScheme`,\n* and fixed `CorrespondenceModel` (if used),\n\nthe following MUST hold:\n* **Idempotency.** `apply(v, apply(v, X))` is **isomorphic** to `apply(v, X)`:\n  * same DescribedEntity and grounding holon,\n  * same viewpoint and representation scheme,\n  * ClaimGraphs differ, at most, by declared structural equivalence (e.g. normal form vs source form).\n* **Determinism.** For fixed input and configuration, the result is uniquely determined (modulo declared equivalence). Any source of non‑determinism (random seeds, timing, external service state) MUST either:\n  * be exposed as part of `content` / `meta` of `X`, or\n  * be moved into a Mechanism outside the viewing morphism.\n\n**EV‑6 - Applicability & MultiViewDescribing alignment.**\n\nEach species of `U.EpistemicViewing` MUST:\n1. Declare an **Applicability profile** (A.6.0) specifying:\n   * permitted `EoIClass ⊑ U.Entity` (ValueKind of `DescribedEntitySlot`),\n   * permitted `groundingHolonRef` classes and ReferencePlanes,\n   * admissible `viewpointRef` ranges (possibly a named `U.ViewpointBundle`),\n   * supported `representationSchemeRef` families.\n1. For D/S epistemes in a `U.MultiViewDescribing` family (E.17.0):\n   * preserve `DescribedEntityRef` of `DescriptionContext`,\n   * either preserve `ViewpointRef` or change it within the declared viewpoint bundle, with any additional constraints recorded in the family’s `CorrespondenceModel`,\n   * never widen `ClaimScope` beyond what EV‑3 permits.\n3. Treat **any change of DescribedEntity** (even if “intuitively minor”, such as moving from subsystem to system) as **out of scope** for A.6.3; such moves belong to A.6.4 `U.EpistemicRetargeting`.\n\n#### A.6.3:4.4 - Profiles: `U.DirectEpistemicViewing` and `U.CorrespondenceEpistemicViewing`\n\n`U.EpistemicViewing` is further structured into two important species; both inherit EV‑0…EV‑6.\n\n1. **`U.DirectEpistemicViewing` — self‑contained views.**\n   * Domain and codomain epistemes share:\n     * the same `representationSchemeRef` (up to declared normalisation),\n     * the same `ReferenceScheme` (or a refinement which is conservative and structurally documented).\n   * No external `CorrespondenceModel` is needed: the view is computed **solely from the input episteme** and, optionally, fixed configuration.\n   * Typical cases:\n     * internal normalisation (sorting, rewriting) of an engineering view;\n     * filtering `U.ClaimGraph` to keep only safety‑relevant claims;\n     * simplifying a proof‑oriented specification to a more operational form under the same semantics.\n\n1. **`U.CorrespondenceEpistemicViewing` — views relying on correspondence models.**\n   * Viewing depends on:\n     * one or more subject epistemes (e.g. requirements and design),\n     * an explicit `CorrespondenceModel` that relates their ClaimGraphs and representation schemes.\n   * The result is an episteme (often an `U.EpistemeView`) whose `describedEntityRef` matches that of the primary episteme, but whose content is computed **through** the correspondence links.\n   * Typical cases:\n     * ISO 42010‑style correspondences between architectural descriptions;\n     * cross‑model views in model‑based systems engineering (MBSE), where view content is computed from multiple model fragments;\n     * traceability‑based views aggregating requirements, design elements, and tests.\n\nIn both profiles:\n* `CorrespondenceModel` remains an **episteme‑level artefact**, not a new kernel‑type hidden inside A.6.3.\n* `U.EpistemicViewing` stays **view‑like**: it reveals what is already there under the correspondence; it does not perform Γ‑style constructions of new Intensions.\n",
        "archetypal_grounding": "### A.6.3:5 - Archetypal grounding (Tell–Show–Show)\n\n#### A.6.3:5.1 - Engineering system description → safety officer view (DirectEpistemicViewing)\n\n*Context.*\nA system team maintains a rich `SystemDescription` episteme for a plant holon `S` under an engineering viewpoint from TEVB. A safety officer needs a concise view showing only safety‑critical components, hazards, and mitigations.\n\n*Shape.*\n\n* **Domain `X`.**\n  `X : U.SystemDescription` with:\n  * `describedEntityRef(X) : U.SystemRef` (the plant `S`),\n  * `groundingHolonRef(X) : U.HolonRef` (runtime environment),\n  * `viewpointRef(X) : U.ViewpointRef` (engineering TEVB viewpoint),\n  * `content(X) : U.ClaimGraph` (full behavioural & structural claims).\n* **Codomain `Y`.**\n  `Y : U.EpistemeView` with:\n  * `describedEntityRef(Y) = describedEntityRef(X)`,\n  * `groundingHolonRef(Y) = groundingHolonRef(X)`,\n  * `viewpointRef(Y)` either equal to or a refinement of the original engineering viewpoint (TEVB safety sub‑viewpoint),\n  * `content(Y)` containing only safety‑relevant claims, plus explicit aggregation nodes (e.g. hazard summaries).\n\n`SafetyView : X→Y` is a **DirectEpistemicViewing**:\n* `describedEntityChangeMode = preserve`,\n* only `content`, `viewpointRef` (within TEVB) and `meta` change,\n* KD‑CAL/LOG‑CAL checks show that every hazard/mitigation claim in `Y` is entailed by `X`,\n* view is idempotent and deterministic given `X` and the selected safety profile.\n\nThis is the canonical “engineering view” archetype that later species in E.17.2/TEVB refer back to.\n\n#### A.6.3:5.2 - MVPK publication view normalisation (DirectEpistemicViewing)\n\n*Context.*\nMVPK emits a `TechCard` view `V_raw` for an arrow `f` in a morphism class (e.g. a **gate-checked, crossing-visible** service with `OperationalGate(profile)` + `DecisionLog`). The publication pipeline wants a normalised view `V_norm` where:\n* arrows are ordered canonically,\n* units and names follow a fixed naming discipline,\n* redundant cells are removed.\n\n*Shape.*\n\n* `X = V_raw`, `Y = V_norm`, both `U.EpistemeView` instances with:\n  * same `describedEntityRef` (the morphism’s arrow or capability),\n  * same `groundingHolonRef` (runtime/plant),\n  * same `viewpointRef` (publication viewpoint),\n  * same `representationSchemeRef` (TechCard schema).\n\n`NormalizeTechCard : X→Y` is a **DirectEpistemicViewing**:\n* changes only `content` and `meta` (e.g. “normalised at edition E”),\n* is pure and idempotent (two passes give the same normal form),\n* is conservative: no new claims about the arrow `f` appear; information is only reordered or discarded.\n\nMVPK can rely on this as an A.6.3‑conformant step without restating EFEM laws.\n\n#### A.6.3:5.3 - Cross‑model consistency view (CorrespondenceEpistemicViewing)\n\n*Context.*\nA system has:\n* a requirements episteme `R` (“what the system should do”), and\n* a design episteme `D` (“how the system does it”),\n\nboth with `describedEntityRef` pointing to the same system holon `S`, but living in different notations and contexts. A systems engineer wants a view that shows **only those requirements that currently have design coverage**.\n\n*Shape.*\n\n* `R : U.SystemRequirementsDescription` with ClaimGraph `C_R`.\n* `D : U.SystemDesignDescription` with ClaimGraph `C_D`.\n* `CM : U.CorrespondenceModel` relating requirements to design elements.\n* `Y : U.EpistemeView` with:\n  * `describedEntityRef(Y) = describedEntityRef(R) = describedEntityRef(D) = S`,\n  * `groundingHolonRef(Y)` inherited from `R`/`D` or declared via a Bridge,\n  * `content(Y)` aggregating only those requirements in `C_R` for which `CM` records coverage in `C_D`.\n\n`CoveredRequirementsView(R,D,CM) : X→Y` (with `X` a compound episteme or a bundle episteme over `R,D,CM`) is a **CorrespondenceEpistemicViewing**:\n* relies essentially on `CM` (without it, the view is undefined — fail‑closed),\n* must publish witnesses that two different ways of composing local correspondences give the same result up to declared equivalence,\n* remains conservative: it does not assert that any requirement is covered unless that fact is recorded in `CM` and justified in `D`.\n\nThis archetype mirrors post‑2015 work on model synchronisation and bidirectional transformations, but anchored in the EpistemeSlotGraph.\n",
        "consequences": "### A.6.3:6 - Consequences\n\n* **Clear separation of viewing vs retargeting.**\n  `U.EpistemicViewing` and `U.EpistemicRetargeting` (A.6.4) now **cleanly separate**:\n\n  * “view of the same entity” vs “description of a different entity under a bridge”, and\n  * vertical morphisms (`α` fixed) vs retargeting morphisms (α changes under KindBridge).\n\n* **Stable backbone for multi‑view patterns.**\n  Multi‑view description (E.17.0), viewpoint bundle libraries (E.17.1/E.17.2), and MVPK publication now share a **single notion of view morphism**, aligned with C.2.1 slots and the I/D/S discipline.\n\n* **Slot‑level discipline for tools.**\n  Tools implementing views (queries, projections, report generators, LLM‑based summarisation) must declare:\n\n  * which SlotKinds they read,\n  * which SlotKinds they may write,\n  * and that `DescribedEntitySlot` is preserved.\n    This removes ambiguity around “subject/object” changes and supports robust static checking.\n\n* **Alignment with modern view/query practices.**\n  The pattern aligns with:\n  * ISO 42010:2011/2022 and its focus on **viewpoints**, **views**, and **correspondences** over an entity‑of‑interest;\n  * SysML v2 “views‑as‑queries” paradigm, where views are queries over a stable model, not new models;\n  * post‑2015 work on **optics** and **displayed categories**, treating views as structured projections over a fibred category of epistemes.\n",
        "rationale": "### A.6.3:7 - Rationale & SoTA‑echoing  *(informative)*\n\n* **Optics and displayed categories.**\n  In categorical terms, epistemes form a category `Ep` fibred over a category of described entities `Ref` via `α : Ep → Ref`. EpistemicViewing corresponds to **vertical morphisms** that preserve α. Their behaviour closely tracks **profunctor optics**: the DescribedEntitySlot plays the role of the “focus index”, while ClaimGraphs and representation schemes act as the data being transformed. Recent work on optics (2018‑onwards) provides compositional laws that FPF leverages without committing to a specific optic calculus.\n\n* **Multi‑view modelling and viewpoint libraries.**\n  ISO 42010 and its successors, as well as MBSE practice from ~2015 onwards, have refined the separation between **viewpoints** (families of concerns, stakeholders, and notations) and **views** (instances under those viewpoints). `U.EpistemicViewing` gives FPF a substrate‑agnostic notion of “view” that can be instantiated for architecture descriptions, safety cases, or even research artefacts, while TEVB and E.17.0 specialise it to engineering holons.\n\n* **Bidirectional transformations and consistency management.**\n  Modern BX research treats views and consistency restoration as structured transformations between models, with consistency relations acting as correspondences. `U.CorrespondenceEpistemicViewing` echoes this practice but insists that:\n  * viewing is **non‑creative** in intensional terms (no new commitments),\n  * any strengthening or change of described entity is explicitly modelled as retargeting or Intension change.\n\n* **Hybrid symbolic/latent representations.**\n  Contemporary work on LLMs and neurosymbolic systems often toggles between:\n  * symbolic specifications (logical, tabular, diagrammatic), and\n  * distributed or latent representations used for computation.\n    By treating `U.RepresentationScheme` and `U.RepresentationOperation` as first‑class episteme components, FPF allows EpistemicViewing to range over:\n  * purely symbolic projections,\n  * latent‑space projections,\n  * or hybrids that invoke external mechanisms before applying a pure view, without changing the core laws.\n",
        "conformance_checklist": "### A.6.3:8 - Conformance checklist (normative)\n\n**CC‑A.6.3‑1 - EFEM species and DescribedEntityChangeMode.**\nAny pattern that claims to define `U.EpistemicViewing` **SHALL**:\n\n* declare itself a species of `U.EffectFreeEpistemicMorphing` (A.6.2),\n* fix `describedEntityChangeMode = preserve`,\n* and state its Applicability profile (EoIClass, contexts, viewpoints, representation schemes).\n\n**CC‑A.6.3‑2 - Slot‑level read/write discipline.**\nFor each species of EpistemicViewing, authors **MUST**:\n\n* list the SlotKinds it **reads** (typically `DescribedEntitySlot`, `GroundingHolonSlot`, `ClaimGraphSlot`, `ViewpointSlot`, `RepresentationSchemeSlot`, `ReferenceSchemeSlot`),\n* list the SlotKinds it **writes** (typically `ClaimGraphSlot`, optionally `ViewpointSlot`, `RepresentationSchemeSlot`, `ReferenceSchemeSlot`, and `meta`),\n* assert explicitly that `DescribedEntitySlot` is read‑only,\n* and state any constraints on `GroundingHolonSlot` / `ViewpointSlot` changes.\n\nThis satisfies A.6.5 and C.2.1 checkpoint CC‑C.2.1‑5.\n\n**CC‑A.6.3‑3 - DescriptionContext discipline (for D/S epistemes).**\nWhen domain/codomain epistemes are `…Description`/`…Spec`:\n* viewing laws SHALL be phrased in terms of `DescriptionContext = ⟨DescribedEntityRef, BoundedContextRef, ViewpointRef⟩`,\n* `DescribedEntityRef` MUST be preserved,\n* `BoundedContextRef` MUST be preserved unless a Bridge is explicitly cited,\n* `ViewpointRef` MUST either be preserved or changed within a declared `U.ViewpointBundle`.\n\n**CC‑A.6.3‑4 - Conservativity witness.**\nFor each species, authoring SHALL provide:\n* a clear statement of what counts as a **new intensional claim** in the relevant discipline,\n* and a sketch of how conservativity (EV‑3) is checked or approximated (e.g. via KD‑CAL entailment, proof obligations, or structural invariants).\n\n**CC‑A.6.3‑5 - Profile classification.**\n* Species that do not require a `CorrespondenceModel` MUST be marked as `U.DirectEpistemicViewing`.\n* Species that do require such a model MUST be marked as `U.CorrespondenceEpistemicViewing` and SHALL:\n  * document the shape of the `CorrespondenceModel`,\n  * describe how witness epistemes ensure oplax naturality of compositions.\n\n**CC‑A.6.3‑6 - Separation from Retargeting and Mechanisms.**\n* Any species that may change `describedEntityRef` is **not** a conformant EpistemicViewing; it MUST be treated as `U.EpistemicRetargeting` (A.6.4) or as a different pattern.\n* Any species that performs measurements, actuation, or other side‑effects MUST be declared as `U.Mechanism`/`U.WorkEnactment` and cannot be an EpistemicViewing.\n",
        "a.6.3:9___mini‑checklist_(for_authors)": "### A.6.3:9 - Mini‑checklist (for authors)\n\nWhen you introduce a new “view” in FPF, check:\n1. **Same described entity?**\n   Does `describedEntityRef` stay the same? If not, this is **Retargeting**, not Viewing.\n\n2. **Which slots move?**\n   Have you listed exactly which SlotKinds you read/write, and shown that `DescribedEntitySlot` is read‑only?\n\n3. **Conservative?**\n   Can you explain, in your discipline’s terms, why the view does not introduce new claims about the same entity?\n\n4. **Profile?**\n   Is this a self‑contained projection (`U.DirectEpistemicViewing`) or does it depend on a `CorrespondenceModel` (`U.CorrespondenceEpistemicViewing`)?\n\n5. **Context & viewpoint?**\n   Have you stated:\n   * the EoIClass for `DescribedEntitySlot`,\n   * the contexts/ReferencePlanes you assume,\n   * and the viewpoint bundle (if any) you operate under?\n\nIf all answers are crisp and the laws EV‑0…EV‑6 are satisfied, the pattern is a good candidate for `U.EpistemicViewing`.\n",
        "a.6.3:end": "### A.6.3:End\n"
      },
      "content": "### A.6.3:End\n",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.6.4",
      "title": "`U.EpistemicRetargeting` — describedEntity‑retargeting morphism",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.6.4 - `U.EpistemicRetargeting` — describedEntity‑retargeting morphism\n\n**One‑line summary.** `U.EpistemicRetargeting` is the **describedEntity‑retargetning** species of `U.EffectFreeEpistemicMorphing`: an effect‑free episteme→episteme morphism that **intentionally changes what the episteme is about** (the occupant of `DescribedEntitySlot` in C.2.1) under a declared `KindBridge` and invariant, while remaining conservative with respect to that invariant.\n\n**Placement.** After **A.6.3 `U.EpistemicViewing`**, before **A.6.5 `U.RelationSlotDiscipline`**. \n\n**Builds on.**\nA.6.0 `U.Signature`; A.6.2 `U.EffectFreeEpistemicMorphing`; A.6.3 `U.EpistemicViewing`; A.6.5 `U.RelationSlotDiscipline`; A.7/E.10.D2 (I/D/S discipline, `DescriptionContext`); C.2.1 `U.Episteme — Epistemes and their slot graph`; C.2/C.3 (KD‑CAL/LOG‑CAL, ReferencePlane, Kind‑level reasoning); F.9 (Bridges, `KindBridge`, CL/CL^plane, SquareLaw witnesses).\n\n**Used by.**\nE.18 (E.TGA StructuralReinterpretation and other reinterpretation nodes); discipline packs for signal/spectrum transforms, data↔model retargetings, abstraction/refinement under kind‑invariants; KD‑CAL/LOG‑CAL retargeting rules; future species for architecture and governance reinterpretations. \n",
        "problem": "### A.6.P:2 — Problem\n\nHow can FPF represent and evolve “relations in prose” that are structurally richer than they appear, so that:\n\n* the **relation kind** is explicit and reviewable,\n* missing positions can be made explicit **without semantic drift**,\n* changes to the relation can be narrated with **stable semantic change classes**,\n* multi‑view publication can exist **without creating multiple incompatible contracts**, and\n* cross‑Context/plane reuse cannot silently assume “sameness by label”?\n",
        "forces": "### A.6.P:3 — Forces\n\n| Force                                 | Tension                                                                                                |\n| ------------------------------------- | ------------------------------------------------------------------------------------------------------ |\n| Universality vs precision             | The repair must be reusable across domains, but must not hide the distinctions it is meant to recover. |\n| Prose convenience vs contract clarity | Humans want short verbs; engineering/assurance needs declared kinds, slots, and invariants.            |\n| Kernel minimality vs safety           | Few primitives are good; umbrella relations are cross‑Context safety hazards.                          |\n| Multi‑view reality vs coherence       | Viewpoints must be expressible without silent polarity flips or re‑typing.                             |\n| Evolution vs auditability             | Relations change; edits must not rewrite meaning invisibly.                                            |\n| Stack discipline                      | Laws, admissibility, deontics, and evidence/work must not be mixed (A.6 + A.6.B).                      |\n",
        "solution": "### A.6.P:4 — Solution — The RPR recipe (Lens → Slots → Change Lexicon → Guardrails), aligned to A.6 / A.6.B / A.6.S\n\nA.6.P defines a **suite recipe**. A pattern is a **RPR‑pattern** (member of A.6.P) iff it provides the ingredients below.\n\n#### A.6.P:4.0 — Trigger rule (when A.6.P applies)\n\nA relation mention is in-scope for A.6.P when **any** of the following holds:\n\n* the predicate/verb phrase is **lexically overloaded** (umbrella tokens such as “same/sync/link/connect/anchor/ground/align/map/depends”), OR\n* the statement implicitly relies on **scope / Γ_time / viewpoint-view / schemes** (reference, representation), OR\n* the relation is used for **assurance / admissibility / gating / publication** decisions, OR\n* the relation crosses **Contexts or planes** (requires Bridges + CL; no silent equivalence), OR\n* different stakeholders interpret endpoints differently (multi-view asymmetry and polarity fights).\n\n**So what? adoption test (review heuristic).** If a reviewer can reasonably ask any of: “Which kind is this?”, “What else participates?”, “Under what scope/time/view?”, “What changed?”, or “What makes this admissible?”, then authors SHOULD treat the mention as in-scope and rewrite it into explicit kind+slots form before using it for cross‑Context reuse or decision/publication claims.\n\n#### A.6.P:4.1 — Stable lens\n\nA RPR‑pattern SHALL name a stable mathematical “lens” that prevents re‑inventing roles per domain. Examples of lenses (illustrative):\n\n* **Kind‑labelled qualified hyperedge / record** (default A.6.P lens)\n* **n‑ary relation with distinguished positions** (A.6.5 style)\n* **kind‑labelled dependence arrow over a base** (A.6.6 style)\n* **span/cospan + declared loss/correspondence notes** (Bridge‑like families)\n* **correspondence relation + repair operations** (sync/consistency families)\n\nThe lens is a compression device: one stable abstraction that keeps the relation’s **arity and polarity** stable and makes invariants speakable.\n\n#### A.6.P:4.2 — Kind‑explicit relation tokens (no umbrella meaning‑surrogates)\n\nFor every in‑scope relational claim, authors SHALL select (or mint) an explicit **RelationKind token** as a declared vocabulary element.\n\nA RelationKind token SHALL be usable as a `U.Signature`‑level vocabulary element with explicit SlotSpecs for its participant and qualifier positions (SlotKind/ValueKind/refMode). \n\n**RelationKind contract skeleton (minimum, recipe-level).**\nFor each `RelationKind` token, the Context SHALL publish a vocabulary entry whose **signature-level definition** is paired with (or points to) a **routed claim bundle** (“contract skeleton”) that declares (at minimum):\n\nThe leading **(L)/(A)/(D)/(E)** tags below indicate the intended **A.6.B quadrant routing** for each element of the skeleton.\n\n* **(L) applicability** (A.6.0): the Context/planes where the kind is defined (local meaning is first-class).\n* **(L) polarity**, and (if needed) explicit **inverse tokens** (no silent role flips in Tech prose).\n* **(L) SlotSpecs** for all participant positions (`⟨SlotKind, ValueKind, refMode⟩`).\n* **(A) repair path for endpoint kind mismatches** (normative): allowed repairs are (i) explicit narrowing, (ii) a `KindBridge` (+ `CL^k` + loss notes), and/or (iii) explicit `retargetParticipant`. Renaming endpoints is not a repair.\n* **(L) qualifier expectations**: which qualifiers are required/optional/forbidden (scope, `Γ_time`, viewpoint/view, reference scheme, representation scheme).\n* **(D) qualifier placement discipline**: extra parameters belong in `scope` or explicit qualifier slots, not as adjectives attached to endpoint names.\n* **(A/E) witness discipline**: when witnesses are required as an admissibility gate and what carrier-anchored witness sets look like in this family.\n* **(L/A) admissible semantic change classes** (see §4.4) and whether they require a new edition.\n* **(A/E) cross‑Context/plane policy** when applicable (Bridge ids + CL + loss notes policy).\n\n**Important stack constraint (A.6 / A.6.S / A.6.B).**\nTreat “contract” as a routed set of claims, not a single magical object:\n\n* **L‑claims** (laws/invariants; polarity; SlotSpec typing) live in `Signature.Laws`.\n* **A‑claims** (admissibility gates) are authored as admissibility predicates (canonically placed in `Mechanism.AdmissibilityConditions` when an explicit mechanism exists) and may reference the RelationKind token by ID.\n* **D‑claims** (duties/commitments) name accountable roles/agents and may reference `L-*`/`A-*` by ID.\n* **E‑claims** (evidence/work effects) anchor to carriers and observation conditions and may reference `L-*`/`A-*` by ID.\n\n#### A.6.P:4.3 — Slot‑explicit qualified relation records (recover hidden arity)\n\nEach concrete occurrence of an A.6.P relation SHALL be representable as a **Qualified Relation Record** (a first‑class record/episteme in the relevant Context) that fills the relation’s slots.\n\nConceptual notation‑neutral shape:\n\n```\nQualifiedRelationRecord :=\n⟨ relationKind : RelationKind, // vocabulary token / registry entry (signature-level)\n\n  // participant positions (pattern-specific; contract fixes SlotSpecs)\n  p₁ : SlotContent(VK₁, refMode₁),\n  …,\n  pₙ : SlotContent(VKₙ, refModeₙ),\n\n  // qualifier kit (pattern-specific; contract selects subset)\n  scope?       : SlotContent(U.Scope, ByValue | RefKind),\n  Γ_time?      : SlotContent(U.GammaTimePolicy, ByValue), // time selector/policy; not an evidence freshness proxy\n  viewpoint?   : SlotContent(U.Viewpoint, ByValue | RefKind),\n  view?        : SlotContent(U.View, ByValue | RefKind),\n  refScheme?   : SlotContent(U.ReferenceScheme, ByValue | RefKind),\n  reprScheme?  : SlotContent(U.RepresentationScheme, ByValue | RefKind),\n\n  witnesses?   : SlotContent(VK_wit, ByValue | RefKind)\n⟩\n```\n\n**Slot naming guard.** `*Slot` suffix names positions (SlotKinds), not occupants; prose SHOULD use occupant names (`scope`, `witnesses`, `base`, `dependent`, …) for fillers. This is the same guard used in A.6.6 and A.6.5. \n\n**Well‑formedness principle.** The record is “typed by contract”: SlotSpecs are fixed by the selected RelationKind token, and missing slots are permitted only if the contract says they are optional. This mirrors A.6.6’s scoped/witnessed declaration move (SWBD): “shape + contract makes a concrete typed signature”.\n\n**Well‑formedness constraints (non‑deontic).**\n\n* **WF‑A6P‑QR‑1 (Required slots are present).** For any QualifiedRelationRecord `r` with `r.relationKind = k`, `r` provides values for every SlotSpec that `k` marks as required.\n* **WF‑A6P‑QR‑2 (No silent kind swap).** `relationKind` is part of a record’s identity/edition boundary. If the kind changes, the result is represented as a distinct record/edition linked by an explicit `changeRelationKind` (or an explicit withdrawal + re‑declaration), not as an in-place mutation that preserves identity.\n\n**Normative prose forms (Tech).**\nIn Tech/normative prose, an in‑scope relation instance SHALL be expressed in one of the following equivalent forms:\n\n* **Functional form:** `relationKind(p₁=…, …, pₙ=…, qualifiers…)`\n* **Arrow form (binary projection only):** `p_left --relationKind{qualifiers}--> p_right`\n\nPassive umbrella voice (“X is synced/linked/anchored …”) is permitted only as Plain gloss when immediately rewritten into one of the above forms.\n\n**Cross‑Context/plane note (recipe-level).**\nIf any participant/qualifier implies cross‑Context or cross‑plane reuse, the relation instance MUST cite the relevant Bridge ids + CL policy (and loss notes, when applicable) in the appropriate routed claims (typically `A-*` and/or `E-*`). Label identity is not an admissible substitute.\n\n#### A.6.P:4.4 — Change‑class lexicon (operations are not adjectives)\n\nA RPR‑pattern SHALL publish a **relation‑change lexicon**: a small set of semantic change classes used in normative prose to describe “what changed” without umbrella verbs.\n\nMinimum semantic change classes (conceptual; specialisations may add more):\n\n1. **declareRelation** — mint a new qualified relation record (slot‑explicit).\n2. **withdrawRelation** — retire a relation instance (or restrict its declared scope/time so downstream admissibility gates treat it as out-of-scope).\n3. **retargetParticipant(slotKind, newRef)** — change a RefKind slot-content while preserving SlotKind and ValueKind (conceptually corresponds to slot‑level **retarget**). \n4. **reviseByValue(slotKind, newValue)** — edit embedded by‑value content (conceptually corresponds to slot‑level assign/update or “by‑value edit”). \n5. **rescope(newScope)** — change scope explicitly (no “in our context” prose).\n6. **retime(newΓ_time)** — change `Γ_time` when time matters; not a substitute for witness freshness claims.\n7. **refreshWitnesses(newWitnessSet)** — update witness bindings to point at appropriate carriers; generating evidence is Work, not a constructor op. \n8. **changeRelationKind(newRelationKindToken)** — semantic change; MUST NOT be treated as an edit‑in‑place.\n\n**Edition fence rule (A.6.S / A.6.6 alignment).**\nIn decision/publication lanes, any semantic change that alters meaning SHALL be represented as a new edition and connected via explicit continuity/withdrawal, rather than mutating the old record in place. \n\n**Mapping note (informative, conceptual).**\nThese change classes are semantic; they may be realised by A.6.5 slot verbs (retarget vs by‑value edit) and, when the relation is a basedness family, by A.6.6 base‑change verbs. The semantic story must not collapse into “we edited something”. \n\n#### A.6.P:4.5 — Lexical guardrails (ban umbrella metaphors as meaning‑surrogates)\n\nA RPR‑pattern SHALL define **red‑flag umbrella tokens** for its ambiguity cluster, and SHALL provide canonical rewrite forms.\n\nNormative base rules (suite-level):\n\n* In **Tech / normative prose**, umbrella predicates (e.g., “same”, “synced”, “linked”, “connected”, “anchored/grounded”) MUST NOT substitute for an unnamed RelationKind token.\n* **“bind/binding” is reserved for name binding** (Identifier → SlotKind/slot‑instance) and MUST NOT be used as a synonym for declaring/changing a relation instance. Use the change‑class lexicon instead. \n* Pattern-defined carve‑outs MAY exist (reserved primitives elsewhere), but they remain review triggers to ensure the reserved sense is intended (as in A.6.6’s `anchor*` carve‑out rule). \n\n#### A.6.P:4.6 — Progressive elaboration (the “precision dial” rule)\n\nA.6.P supports a controlled escalation path that preserves meaning and prevents drift:\n\n1) Start with a minimal explicit **RelationKind token** + principal endpoints (a binary projection is allowed only if the missing slots are truly irrelevant for the use-case).\n\n2) When ambiguity emerges, **do one (or more) explicitly**:\n   * add missing participants as additional slots (turn the projection into n‑ary),\n   * add explicit qualifiers (scope / `Γ_time` / viewpoint-view / schemes / witnesses),\n   * refine the RelationKind token to a more specific one (new contract skeleton; `changeRelationKind`),\n   * introduce Bridges + CL (and loss notes) when crossing Contexts/planes.\n\n3) The transition MUST be monotone:\n   * no silent re‑typing,\n   * no implicit polarity flips,\n   * no “edit‑in‑place” that changes meaning (use edition fences + explicit continuity/withdrawal links).\n\n#### A.6.P:4.7 — Two‑view / polarity discipline (no silent role flips)\n\nA RPR‑pattern SHALL specify how the same relation is expressed from both “sides” without polarity flips:\n\n* Either keep both endpoints visible with the same polarity-preserving token, **or**\n* declare explicit inverse tokens and require them for inverse prose.\n\nImplicit role flips (“B validates A” without explicit inverse) are prohibited in Tech/normative prose. This is already a core rule for basedness patterns and is generalised here. \n\n#### A.6.P:4.8 — Disambiguation guide (rewrite/selection)\n\nA RPR‑pattern SHALL include an actionable guide:\n\n> “If the draft says *X*, decide between relation kinds A/B/C, expand missing slots, and rewrite into explicit kind+slots notation.”\n\nFor basedness families, A.6.6 provides an existence proof of such a guide (select baseRelation family; add scope/time/witnesses). A.6.P requires this move suite‑wide. \n\n#### A.6.P:4.9 — A.6.B routing template for RPR relation families\n\nAny RPR‑pattern that claims “contract-bearing” semantics SHALL route its normative content using **A.6.B**:\n\n* **L‑claims**: signature‑level structure and laws (SlotSpecs, polarity, invariants).\n* **A‑claims**: admissibility / “entry gate” rules for *using* relation instances in specified lanes (e.g., decision use requires witnesses; time dependence requires `Γ_time`; cross‑Context use requires Bridges/CL).\n* **D‑claims**: deontic obligations on authors/agents (lexical firewall; prohibited umbrella use; rewrite obligations).\n* **E‑claims**: work/evidence expectations and carrier anchoring (what counts as a witness; evidence freshness is a property of carriers, not prose). \n\nA.6.P does not mandate a particular claim‑ID format; it mandates the **separation and cross‑reference discipline**.\n\n**Atomicity + explicit references (normative, recipe-level).**\nPer A.6.B, mixed sentences MUST be decomposed into **atomic** claims so each claim routes to exactly one quadrant, and any dependencies MUST be expressed as explicit references (by claim ID or canonical location), not paraphrased duplicates.\n\n**No upward dependencies (normative, recipe-level).**\n`L-*` claims MUST NOT reference `A-*`, `D-*`, or `E-*`; `A-*` and `E-*` claims MUST NOT reference `D-*`. Where cross‑quadrant coupling is needed, link by explicit IDs in the allowed directions.\n\n#### A.6.P:4.10 — A.6.S compatibility note (ConstructorSignature is optional but canonical for engineered families)\n\nIf a RPR‑pattern is used as an engineered family (created/evolved over time), it SHOULD be expressible as:\n\n* a **TargetSignature**: declared relation kinds + SlotSpecs + laws, and\n* a minimal **ConstructorSignature**: effect‑free operations that rewrite under‑specified prose into the explicit form and evolve relation records using the change‑class lexicon (mapped to A.6.5/A.6.6 canonical verbs).\n\nIf a ConstructorSignature is provided, it SHOULD (conceptually) declare, for each constructor operator family:\n\n* whether it is a species of **A.6.2 / A.6.3 / A.6.4**, and\n* which **`U.EpistemeSlotGraph` slots** (C.2.1) it may read and write (SlotKind/ValueKind/RefKind profile).\n\n**Publication note (recommended).**\nIf the TargetSignature / relation-kind registry is published via MVPK, treat every face as a **view** (no new semantics), keep viewpoint accountability explicit, and prefer stable claim IDs (Claim Register) so downstream carriers cite claims rather than paraphrasing.\n",
        "archetypal_grounding": "### A.6.P:5 — Archetypal Grounding (System / Episteme)\n\nA.6.P requires Tell–Show–Show grounding in both System and Episteme lanes.\n\n#### A.6.P:5.1 — System archetype: “same system across environments”\n\n**Tell.**\nAn operations note says: “Staging is the same service as Production.” Months later, incident metrics are aggregated “because it’s the same thing”, and evidence across environments is mixed, producing an incorrect causal story.\n\n**Show.**\nTreat “same” as a red-flag umbrella token. Rewrite into an explicit cross-Context relation kind,\ntyped to the facet the draft actually uses (service delivery system sameness for actuals/evidence aggregation; not about service clauses).\n\n```\nsameDeliverySystemUnder(\n  leftDeliverySystemRef  = SystemRef(staging_delivery_system),\n  rightDeliverySystemRef = SystemRef(prod_delivery_system),\n  scope     = ClaimScope{SLO_family = X, signals = {latency, error_rate}},\n  Γ_time    = Window(2025-12-01..2026-01-31),\n  viewpoint = OpsViewpoint,\n  witnesses = {deploymentManifestPins, configPins, testRunPins}\n)\n\naggregationAdmissibleIff(\n  relationKind = sameDeliverySystemUnder@ed=…,\n  target       = deliveryWorkMetrics,                   // actuals\n  Γ_time       = Window(2025-12-01..2026-01-31),\n  witnesses    = {metricCarrierPins, incidentLogPins}   // evidence carriers for the actuals\n)\n```\n\n**Show.**\nNow the relation is auditable: aggregation is admissible only if the relation kind’s admissibility\nclaims say it preserves the needed characteristics under the declared scope/time, and if witnesses exist.\nCross-Context reuse is explicit and cannot piggyback on label identity.\n\n\n#### A.6.P:5.2 — Episteme archetype: “the models are synced”\n\n**Tell.**\nA draft says: “The simulation model is synced with the physical twin.” Reviewers ask what “synced” means. The authors respond with examples, but downstream users still cannot tell whether the claim is about parameters, structure, calibration, evidence freshness, or mapping quality.\n\n**Show.**\nRewrite “synced” as an explicit correspondence relation kind + explicit qualifiers + witnesses:\n\n```\nentityMatchedBy(\n  leftRef          = ModelRef(SimModel@ed=12),\n  rightRef         = SystemRef(PhysicalTwin@ed=7),\n  mappingArtifactRef = AlignmentModel_2025_11,\n  scope            = ClaimScope{signals = S, metrics = M},\n  Γ_time           = Snapshot(t),\n  referenceScheme  = RefScheme(CustomerIdRegistry#EU),\n  viewpoint        = DataEngineeringViewpoint,\n  witnesses        = {evalRunPins, calibrationPins, mappingArtifactPins}\n)\n```\n\n**Show (change narration).**\nTwo weeks later, the mapping artefact is replaced and the witness set is refreshed. In decision/publication lanes, represent this as a new edition and narrate the change via change classes (not via “re‑synced”):\n\n```\nwithdrawRelation( relationRef = RelationRef(entityMatchedBy, leftRef, rightRef, ed=12) )\n\ndeclareRelation(\n  entityMatchedBy(\n    leftRef           = ModelRef(SimModel@ed=12),\n    rightRef          = SystemRef(PhysicalTwin@ed=7),\n    mappingArtifactRef= AlignmentModel_2026_01,\n    scope             = ClaimScope{signals = S, metrics = M},\n    Γ_time            = Snapshot(t₂),\n    referenceScheme   = RefScheme(CustomerIdRegistry#EU),\n    viewpoint         = DataEngineeringViewpoint,\n    witnesses         = {evalRunPins_2026_01, calibrationPins_2026_01, mappingArtifactPins_2026_01}\n  )\n)\n```\n\n**Show.**\nDifferent “sync meanings” become different **RelationKind tokens** (e.g., `entityMatchedBy`, `schemaAlignedUnder`), not adjectives. Subsequent changes become narratable as `retargetParticipant`, `rescope`, `retime`, or `refreshWitnesses`, rather than “we updated the sync”. \n",
        "consequences": "### A.6.P:9 — Consequences\n\n**Benefits**\n\n* **Predictable precision upgrades.** Umbrella relational prose becomes systematically expandable into explicit structure.\n* **Viewpoint conflict becomes repairable.** Differences surface as explicit roles/kinds/qualifiers, not silent rewrites.\n* **Change becomes speakable.** “What changed?” is a named semantic change class, reducing folklore.\n* **Cross‑Context safety improves.** “Same/synced/linked” becomes contract‑bearing and auditable, not rhetorical.\n\n**Trade‑offs / mitigations**\n\n* **Higher authoring overhead.** Mitigated by progressive elaboration: expand only when invariants, reuse, or decisions require it.\n* **More explicit qualifiers.** Mitigated by keeping the lens stable and reusing slot templates (A.6.5/A.6.6).\n* **Perceived prescriptiveness.** Mitigated by allowing Plain-register glosses that are immediately mapped to Tech tokens (without creating new contracts).\n",
        "rationale": "### A.6.P:10 — Rationale\n\nUpper/foundational ontologies optimise for broad applicability via sparse commitments. FPF’s recurring, high-cost failures are often elsewhere: **under‑specified relations** in prose, where ambiguity hides in arity, kind selection, viewpoint, and change semantics.\n\nA.6.P is orthogonal to “add a global taxonomy”:\n\n* It provides a repeatable method to **restore relational precision** without requiring any external formalism or tooling.\n* It operationalises A.6’s boundary discipline by ensuring relation talk can be cleanly separated into laws, admissibility, deontics, and evidence/work (A.6.B), rather than becoming “contract soup”. \n",
        "conformance_checklist": "### A.6.P:7 — Conformance Checklist (CC‑A.6.P)\n\nA pattern P conforms to A.6.P (i.e., is an RPR‑pattern) iff:\n\n> **Note.** This checklist defines conformance for **RPR specialisations** (e.g., A.6.5, A.6.6, and future A.6.x patterns). A.6.P itself is the **suite recipe**.\n\n1. **CC‑A.6.P‑1 — Lens is explicit.**\n   P SHALL name the stable lens used to stabilise the ambiguity cluster and justify its fit.\n\n2. **CC‑A.6.P‑2 — RelationKind is explicit and its contract skeleton is published.**\n   Every in‑scope relation claim SHALL name an explicit RelationKind token, and that token SHALL resolve to a vocabulary entry whose contract skeleton publishes (at minimum): polarity (and explicit inverses if needed), participant SlotSpecs `⟨SlotKind, ValueKind, refMode⟩`, qualifier requirements, witness expectations for decision/publication lanes, admissible semantic change classes, and (when applicable) cross‑Context/plane policy (Bridge + CL + loss notes). Routed claims SHALL respect A.6.B.\n   The contract skeleton SHALL also declare admissible **repair paths for endpoint kind mismatches** (KindBridge / explicit narrowing / explicit retargeting) and enforce **qualifier placement discipline** (no adjective smuggling).\n\n3. **CC‑A.6.P‑3 — Slot‑explicit instances.**\n   Every in‑scope relation instance SHALL be expressible as a Qualified Relation Record filling all contract‑required participant slots (no hidden arity; see WF‑A6P‑QR‑1).\n\n4. **CC‑A.6.P‑4 — Qualifiers are explicit when required.**\n   If scope/time/viewpoint/reference-scheme assumptions matter (or the relation kind requires them), they SHALL be explicit; implicit “current/latest/in our context” SHALL NOT substitute.\n   When witness freshness/decay matters, it SHALL be expressed explicitly (evidence-role timespans, qualification windows, explicit freshness predicates), not by treating `Γ_time` as a proxy.\n\n5. **CC‑A.6.P‑5 — No silent polarity flips.**\n   If inverse wording is used, it SHALL use explicit inverse tokens or polarity‑preserving forms; implicit role flips are forbidden. \n\n6. **CC‑A.6.P‑6 — Change semantics use a change‑class lexicon.**\n   Normative prose about relation evolution SHALL use named semantic change classes (declare/withdraw/retarget/revise/rescope/retime/refreshWitnesses/changeKind), not generic “update/modify/sync/bind/anchor”.\n   Any mapping to lower-level slot verbs MUST preserve the A.6.5 retarget vs by‑value edit distinction. \n\n7. **CC‑A.6.P‑7 — “bind/binding” discipline.**\n   `bind/rebind` SHALL be reserved for name binding (Identifier → SlotKind/slot‑instance) and SHALL NOT be used as a synonym for relation edits. \n\n8. **CC‑A.6.P‑8 — Lexical firewall is normative.**\n   P SHALL list red‑flag umbrella tokens for the family and provide rewrite rules; umbrella tokens SHALL NOT function as meaning‑surrogates in Tech/normative prose. If legacy/Plain umbrella wording appears, it SHALL be immediately mapped to an explicit Tech form (`relationKind(…)` or `--relationKind-->`).\n\n9. **CC‑A.6.P‑9 — A.6.B atomicity, routing, and explicit references are respected.**\n   Normative text SHALL be decomposed into atomic claims routable to exactly one quadrant (L/A/D/E). Dependencies SHALL be expressed by explicit references (IDs or canonical locations), not paraphrase. No‑upward‑dependency constraints SHALL be preserved.\n\n10. **CC‑A.6.P‑10 — Evidence is carrier‑anchored (A.7 separation).**\n    Statements about witnesses/evidence/freshness SHALL be framed as properties/expectations of carriers and work, not as properties of prose. \n\n11. **CC‑A.6.P‑11 — A.6.S compatibility when engineered.**\n    If the pattern family is presented as engineered/evolving, it SHALL be compatible with A.6.S: distinguish TargetSignature vs ConstructorSignature; map constructor verbs to A.6.5/A.6.6 canonical verbs; keep constructor ops effect‑free; and (when a ConstructorSignature is present) declare the C.2.1 slot read/write profile and whether ops are A.6.2/A.6.3/A.6.4 species.\n\n12. **CC‑A.6.P‑12 — Cross‑Context/plane reuse is explicit (no “sameness by label”).**\n    If a relation instance crosses Contexts/planes (or requires translation), the carrier SHALL cite Bridge ids + CL policy (and loss notes, when applicable). Label identity or “same anyway” prose SHALL NOT substitute.\n\n13. **CC‑A.6.P‑13 — Disambiguation guide is actionable.**\n    P SHALL include an explicit rewrite/selection guide that maps each red‑flag umbrella cluster to candidate `RelationKind` tokens, required qualifiers, and canonical rewrite forms.\n\n14. **CC‑A.6.P‑14 — Grounding spans System and Episteme.**\n    P SHALL include at least one Tell–Show–Show vignette in a **System** lane and at least one in an **Episteme** lane (per E.8), demonstrating a real ambiguity repair and a relation‑change narration using the change‑class lexicon.\n\n15. **CC‑A.6.P‑15 — Trigger rule is explicit.**\n    P SHALL include an explicit trigger rule (or selection heuristic) stating when the family applies and what counts as “in-scope” umbrella relational prose.\n",
        "a.6.4:9___mini‑checklist_(for_authors)": "### A.6.4:9 - Mini‑checklist (for authors)\n\nWhen you think you need “retargeting” in FPF, ask:\n\n1. **Does `describedEntityRef` change?**\n   If no, this is Viewing (A.6.3), not Retargeting.\n\n2. **Is there a `KindBridge` between old and new entities?**\n   If not, you probably need to introduce one in Part F or rethink the Intension, not fudge a retargeting.\n\n3. **What invariant are you preserving?**\n   Write it down in KD‑CAL/LOG‑CAL terms. If you cannot, retargeting is underspecified.\n\n4. **How do `GroundingHolonRef`, context and viewpoint behave?**\n   Explicitly state whether they stay the same, move along Bridges, or are out of scope.\n\n5. **Can the operation be factored as Mechanism + pure retargeting?**\n   If the step needs computation (FFT, model fitting), separate the Mechanism from the EpistemicRetargeting.\n",
        "relations": "### A.6.P:12 — Relations\n\n**Specialised by**\n\n* **A.6.5 `U.RelationSlotDiscipline`** — slot precision restoration for n‑ary relations. \n* **A.6.6 `U.BaseDeclarationDiscipline`** — base‑dependence precision restoration (SWBD + base‑change lexicon + `anchor*` red‑flags). \n\n**Coordinates with**\n\n* **A.6.S `U.SignatureEngineeringPair`** — RPR rewrite operations can be packaged as a ConstructorSignature for engineered relation families; must preserve canonical verb mapping and effect‑free constructor semantics. \n\n**Intended future A.6.x specialisations (illustrative)**\n\n* Cross‑Context equivalence / “sameness” discipline (Bridge + loss notes families)\n* Correspondence/consistency + repair discipline (sync/alignment families)\n* Transfer/hand‑off discipline (multi‑party “give/assign/ownership” families)\n",
        "a.6.4:end": "### A.6.4:End\n\n## A.6.P — U.RelationalPrecisionRestorationSuite — Relational Precision Restoration (RPR) — Kind‑Explicit Qualified Relation Discipline\n\n> **Type:** Architectural (A)\n> **Status:** Stable\n> **Normativity:** Normative (Core)\n\n**Plain-name.** Relational precision restoration suite.\n\n**Intent.** Provide a family-level, reusable discipline for repairing a recurring defect in FPF texts: **under‑specified relational language** (often phrased as a seemingly binary verb) that actually hides **(i)** higher arity (missing participant positions), **(ii)** multiple semantic change classes, **(iii)** viewpoint/view asymmetry, and **(iv)** boundary obligations (laws vs admissibility vs deontics vs evidence/work).\nRPR patterns turn “umbrella relations” into **kind‑explicit, slot‑explicit, qualified relation records** with an explicit **change-class lexicon** and **lexical guardrails**, while respecting the **A.6 Signature Stack** and **A.6.B Boundary Norm Square** separation. \n\n**Placement.** Part A → cluster **A.6 Signature Stack & Boundary Discipline** → header pattern for the **relation‑precision restoration family** (A.6.5, A.6.6, and future A.6.x patterns). \n\n**Builds on.**\n\n* **A.6** (stack layering + boundary discipline requirements). \n* **A.6.B `U.BoundaryNormSquare`** (L/A/D/E routing; claim atomicity; cross‑quadrant references). \n* **A.6.S `U.SignatureEngineeringPair`** (TargetSignature vs ConstructorSignature; canonical constructor verb mapping; effect‑free constructor ops). \n* **A.6.0 `U.Signature`** (SlotSpec requirement for argument positions). \n* **A.6.5 `U.RelationSlotDiscipline`** (SlotKind/ValueKind/RefKind stratification + canonical slot verbs; `bind` reserved for name binding). \n* **E.8** (pattern authoring discipline; Tell–Show–Show; SoTA echoing hygiene).\n* **F.18** (promise vs utterance vs commitment; avoids “interface‑as‑promiser” category errors).\n* **E.10** (LEX‑BUNDLE discipline; I/D/S vs Surface; L‑SURF token discipline; reserved primitives; Tech↔Plain pairing). *(Referenced conceptually; no tooling implied.)*\n\n**Coordinates with.**\n\n* **A.2.4 `U.EvidenceRole`** (witness semantics: role/timespan/freshness metadata for decision‑relevant witness sets).\n* **A.2.6 scope + `Γ_time` discipline** (avoid implicit “current/latest”; make time selectors explicit when time matters). \n* **A.7 Strict Distinction** (Object≠Description≠Carrier; avoid treating evidence/logs as properties of prose). \n* **A.6.2–A.6.4** (effect‑free episteme morphisms, epistemic viewing/retargeting as disciplined slot writes). \n* **A.10 evidence discipline** (witnesses are carrier‑anchored; freshness is adjudicated in work/evidence lanes).\n* **C.2.1 `U.EpistemeSlotGraph`** (slot read/write profiles for constructor operators, when declared).\n* **C.3.3 `U.KindBridge` + `CL^k` discipline** (repairing endpoint kind mismatches; kind-level congruence + loss notes).\n* **E.17 MVPK / multi‑view publication** (faces are views; “no new semantics”; viewpoint accountability).\n* **E.19 pattern quality gates** (review/refresh discipline for guardrails and conformance lists).\n* **F.9 Bridges + CL** for cross‑Context/plane reuse (no silent sameness). \n\n**Specialisations already in Core.**\n\n* **A.6.5**: RPR for “putting something into a place” (explicit SlotKinds + ValueKind/RefKind + slot‑operation lexicon). \n* **A.6.6**: RPR for “relative‑to / basedness” claims (explicit `baseRelation` token + scoped, witnessed base declarations + base‑change lexicon; lexical red‑flags for `anchor*`). \n",
        "a.6.p:0_—_term/lex_token_guards_(local_first)": "### A.6.P:0 — TERM/LEX token guards (local-first)\n\nThis pattern reserves the following tokens on Tech (normative) surfaces:\n\n* **RPR** — *Relational Precision Restoration* (the suite recipe; not a new `U.Type`).\n* **RelationKind** — a Context-local vocabulary token (signature-level) that fixes polarity and SlotSpecs for participant/qualifier positions. It is a *registry entry/token*, not a relation instance.\n* **QualifiedRelationRecord** — the slot-explicit relation instance record kind (Context-local episteme/record kind); instances carry a `relationKind` token reference plus explicit participant/qualifier slots.\n\n**Mint-or-reuse note (recipe-level).** This pattern mints the suite label **RPR**, the role name **RelationKind**, and the generic shape name **QualifiedRelationRecord** as local-first terms for this family. It reuses existing FPF terms (`U.Signature`, SlotKind/ValueKind/RefKind, Bridges/CL, `U.Scope`, `Γ_time`, `U.View`/`U.Viewpoint`, evidence pins/carriers) without changing their meanings.\n\n**Definitions (recipe-level; non-deontic).**\n\n* **RelationKind token** — a declared vocabulary element (signature-level) whose *public surface* fixes polarity and SlotSpecs for participant/qualifier positions, and that is referenced by routed claims (L/A/D/E) that govern admissibility, duties/commitments, and evidence/work.\n* **QualifiedRelationRecord** — a Context-local episteme/record kind whose `relationKind` field points (by id/ref) to a RelationKind token and whose instance records make all contract-required participant/qualifier slots explicit.\n\nRename-guards (common collisions):\n\n* **contract** — Plain shorthand for “published boundary interface description”; it MUST NOT be read as a promise/obligation by an episteme. Promises, duties, and gates route via A.6.B.\n* **bind/binding** — reserved for **name binding** (Identifier → SlotKind/slot-instance) and MUST NOT be used as a synonym for relation instance edits.\n* **same/synced/linked/connected/anchored/grounded** — treated as umbrella tokens; allowed as Plain gloss only when immediately mapped to an explicit RelationKind token (Tech) via rewrite rules.\n",
        "a.6.p:6_—_bias‑annotation": "### A.6.P:6 — Bias‑Annotation\n\nLenses tested: **Gov**, **Arch**, **Onto/Epist**, **Prag**, **Did**. Scope: **Universal** for RPR‑style precision restoration in the A.6 cluster.\n\n* **Gov bias:** prefers explicit admissibility and evidence routing; increases auditability but raises authoring cost.\n* **Arch bias:** favours reusable structural lenses (records/hyperedges) over narrative prose.\n* **Onto/Epist bias:** pushes kind‑explicit relations and polarity discipline; discourages metaphor-first modeling.\n* **Prag bias:** reduces rework and cross-team misinterpretation; may feel heavy in exploratory notes.\n* **Did bias:** enforces teachable rewrite guides; can be perceived as prescriptive.\n",
        "a.6.p:8_—_common_anti‑patterns_and_how_to_avoid_them": "### A.6.P:8 — Common Anti‑Patterns and How to Avoid Them\n\n| Anti-pattern                                   | Why it fails                                                                | Repair                                                                              |\n| ---------------------------------------------- | --------------------------------------------------------------------------- | ----------------------------------------------------------------------------------- |\n| “Just define the umbrella word”                | Definitions don’t separate arity, operation classes, or viewpoint asymmetry | Replace umbrella use with explicit RelationKind + qualified record + change lexicon |\n| Keep the umbrella verb, add adjectives         | Adjectives are not contracts; invariants remain unstated                    | Mint/select distinct RelationKind tokens; enforce rewrite discipline                |\n| Ontology only, no lexical guardrails           | Prose re‑collapses meaning                                                  | Add red‑flag tokens + prohibited umbrella use in Tech/normative prose               |\n| Lexicon only, no structural lens               | Becomes subjective policing                                                 | Introduce stable lens + slot schema; then attach guardrails                         |\n| Solve viewpoint mismatch by renaming endpoints | Silent re‑typing breaks cross‑pattern reuse                                 | Keep roles stable; use explicit kind selection + explicit repair paths              |\n| Using “bind” to mean “edit relation”           | Collapses name-binding vs slot-writing layers                               | Reserve `bind/rebind` for names; use change lexicon / slot verbs properly           |\n| Implicit “current/latest”                      | Violates explicit time discipline                                           | Add explicit `Γ_time` where time matters                                            |\n| Treat `Γ_time` as witness freshness             | Time selection ≠ evidence freshness/decay; conflates time discipline with evidence lanes | Keep `Γ_time` for temporal scope; express freshness/decay via witness metadata and carrier-anchored E‑claims |\n",
        "a.6.p:11_—_sota‑echoing_(informative;_post‑2015_alignment)": "### A.6.P:11 — SoTA‑Echoing (informative; post‑2015 alignment)\n\n**Evidence binding note.** If your Context maintains a SoTA Synthesis Pack for relation/contract authoring or “qualified relations”, cite it here and keep this section consistent. Otherwise, treat the table below as a seed list (informative only).\n\nA.6.P echoes contemporary practice across independent traditions, while remaining notation‑neutral and Context-local:\n\n| SoTA practice (post‑2015) | Primary source (post‑2015) | Echo | What A.6.P adds | Adoption stance |\n| --- | --- | --- | --- | --- |\n| Constraint/shape validation over graph assertions | W3C **SHACL** Recommendation (2017) | Separates “assertions” from “constraints” | Couples structural contracts with **lexical guardrails** to prevent prose regression | **Adopt/Adapt** — adopt “explicit contracts”, adapt by binding to Tech↔Plain and rewrite discipline |\n| Qualified statements / reification patterns | **RDF‑star / SPARQL‑star** (2017+) practice family | Reification/qualification when hidden arity appears | Requires explicit **RelationKind** + change‑class lexicon (not just representational qualification) | **Adapt** — representation is not enough without kind selection + change semantics |\n| Architecture views & correspondences | ISO/IEC/IEEE **42010:2022** | Viewpoints and correspondences as first-class concerns | Forces viewpoint discipline inside relation qualification + prohibits silent polarity flips | **Adopt/Adapt** — adopt viewpoint accountability, adapt by embedding it into relation records |\n| Bidirectional transformations / optics | Pickering et al., **Profunctor Optics** (ICFP 2017) and successors | “Pairs of projections + laws” as stable lenses | Uses optics as conceptual stabilisers for multi‑view relations while keeping Core notation‑neutral | **Adapt** — use as a stabilising lens, not as mandated notation |\n| Compositional modelling (applied category theory) | Fong & Spivak, **Seven Sketches in Compositionality** (2019) | Stable abstract lenses reusable across domains | Embeds lens choice into an authoring discipline with explicit slots + guardrails | **Adapt** — keep the categorical lens didactic; operationalise via SlotSpecs + change lexicon |\n\nThese echoes justify why A.6.P is structured as: **stable lens → explicit slots → explicit change classes → lexical guardrails**, rather than “just define the verb”.\n",
        "a.6.p:end": "### A.6.P:End\n"
      },
      "content": "### A.6.P:End\n",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.6.5",
      "title": "U.RelationSlotDiscipline - SlotKind / ValueKind / RefKind discipline for n‑ary relations (with slot‑operation lexicon)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.6.5 -  U.RelationSlotDiscipline - SlotKind / ValueKind / RefKind discipline for n‑ary relations (with slot‑operation lexicon)\n\n**Plain‑name.** Relation slot discipline.\n\n**Status.** Normative (Core).\n**Placement.** Part A, cluster A.IV “Architheory Kernel”; directly under A.6.0 `U.Signature` and alongside A.6.1–A.6.4.\n**Depends on.**\n– A.1 `U.Holon` (holonic carrier model).\n– A.6.0 `U.Signature` (universal morphism/relationship signatures).\n– A.7 (Strict Distinction; I/D/S vs Surface).\n– E.8 (pattern authoring order & SoTA discipline).\n– E.10 (LEX‑BUNDLE: Tech/Plain registers, naming guards).\n\n**Coordinates with.**\n– C.2.1 `U.EpistemeSlotGraph` (episteme slots: DescribedEntity, GroundingHolon, ClaimGraph, Viewpoint, View, ReferenceScheme).\n– C.3.* Kind‑CAL (Kinds, KindSignature, KindBridge).\n– F.18 (name governance; twin‑register discipline).\n",
        "problem": "### A.6.5:2 - Problem (symptoms in FPF)\n\nTypical failure modes the pattern is designed to eliminate:\n\n1. **Slot vs value vs ref confusion.**\n   Episteme fields such as `DescribedEntityRef` are sometimes treated as:\n\n   * the **slot** (“the described entity position”),\n   * the **value kind** (“the described entity type”), and\n   * a **reference field** (“this is the pointer we store”).\n\n   Reasoning about substitution (“can I swap one described entity for another?”) then mixes three levels at once.\n\n2. **Kernel types misused as slot names.**\n   Kernel concepts like `U.Entity` or `U.Holon` are used directly as slot names (“the `U.Entity` of this episteme”), hiding the difference between:\n\n   * the abstract **Kind** (`U.Entity` as intensional universe), and\n   * the **place** where one such entity is used in a particular relation.\n\n3. **“Role” overloaded as slot.**\n   In relation signatures and structural calculi, “role” has crept in as a synonym for “argument position”: “the role of the subject”, “the role of the provider”. This clashes with `U.Role` in RoleEnactment and makes it hard to distinguish:\n\n   * **holonic role** (mask worn by a system), from\n   * **slot** (position in a relation).\n\n4. **Ref‑suffix drift.**\n   In the absence of a discipline, the suffix `…Ref` is attached to:\n\n   * entity kinds (`U.EntityRef` interpreted as “the entity itself”),\n   * episteme fields (`describedEntityRef`),\n   * sometimes even to slots (“DescribedEntityRefSlot”).\n\n   That makes it impossible to read signatures and know whether we talk about:\n\n   * a **conceptual value** (by‑value), or\n   * a **reference/identifier** (by‑reference via a handle).\n\n5. **Substitution rules not localisable.**\n   When the slot/value/ref layers are not separated:\n\n   * we cannot state “you may substitute **any instance of ValueKind V** in Slot S”, nor\n   * “this Bridge only changes RefKind, not ValueKind”.\n\n   This blocks clean use of A.6.0 `U.Signature` as a shared calculus for method/role/episteme signatures.\n\n6. **Episteme‑specific slots not standardised.**\n   For epistemes, the positions “what is this about?”, “in which holon is it grounded?”, “what ClaimGraph is inside?” re‑appear across patterns. Without a shared slot discipline, each pattern names these ad‑hoc, breaking the ability to state **universal laws** over episteme morphisms (A.6.2–A.6.4).\n\n7. **Operation‑lexicon drift (slot filling spoken as one verb).**\n   Extension prose introduces ad‑hoc words for “put something in a slot” and then imports unintended semantics. The most common mistakes are:\n\n   * using a single word (e.g. “fill”, “set”, “occupy”, “attach”) to cover **initialization**, **assignment**, **retargeting**, and **by‑value editing**;\n   * using person/role metaphors for slot content (“occupant”) that re‑introduce the “role ≈ slot” confusion;\n   * describing “early vs late binding” without stating **which link** is early/late (name→slot binding vs slot→content filling vs ref→referent resolution).\n\nThe result: **local convenience, global incoherence** — exactly what A.6.0 and E.10 are supposed to prevent.\n",
        "forces": "### A.6.5:3 - Forces\n\n* **F1 - Simplicity vs expressiveness.**\n  Engineers need a **small number of concepts** they can hold in mind while reading a signature; yet we must express:\n\n  * where a parameter sits,\n  * which kinds it can take,\n  * whether it’s by value/by reference,\n  * how substitution behaves,\n  * and (in prose) what kind of slot‑operation is being described.\n\n* **F2 - Cross‑disciplinary reuse.**\n  Slot discipline must work for:\n\n  * logical relations (KD‑CAL, LOG‑CAL),\n  * episteme structures (C.2.1),\n  * systems/roles/methods (A/B),\n  * services and APIs (including method/service interfaces and ports),\n  * cells in tables and databases,\n  * guards, bridges, and flows in E.TGA,\n  * and publication operations (E.17).\n\n  A scheme that is too domain‑specific (e.g. “database attributes only”) won’t scale; the same discipline must underlie **all** `U.Signature`d argument/port lists.\n\n* **F3 - Alignment with existing tooling.**\n  Tooling stacks already operate with:\n\n  * typed parameters and records,\n  * identifiers vs values vs references,\n  * and (in modern typed settings) explicit distinctions between *binding*, *store update*, and *mutation*.\n\n  FPF must line up with this practice enough that signatures can be implemented without inventing a parallel type system.\n\n* **F4 - I/D/S discipline.**\n  Strict distinction (A.7, E.10.D2) already separates **intensional objects**, their **descriptions**, and **specifications**. The same discipline is needed inside relations:\n\n  * slot ≠ value ≠ reference,\n  * system role ≠ slot name,\n  * describedEntity ≠ guard,\n  * and “change the reference” ≠ “change the thing referred to”.\n\n* **F5 - Didactic primacy and naming discipline.**\n  E.8 and E.10 demand patterns that are:\n\n  * teachable (Tell‑Show‑Show examples, explicit biases),\n  * lexically guarded (Tech/Plain split, explicit head‑nouns).\n\n  Slot discipline must integrate seamlessly with that.\n\n* **F6 - Binding‑time talk must be unambiguous.**\n  “Early binding / late binding” is meaningful only if the author states **what is being fixed when**. FPF needs a canonical way to speak about:\n\n  * early/late **slot filling**,\n  * early/late **reference resolution / dispatch**,\n  * and (where a language surface is in play) early/late **name binding**.\n",
        "solution": "### A.6.5:4 - Solution — SlotKind / ValueKind / RefKind triple (plus a slot‑operation lexicon)\n\n#### A.6.5:4.1 - Three layers for every argument position\n\n`U.RelationSlotDiscipline` extends `U.Signature` with a **three‑layer description** for every argument position (whether we call it “parameter”, “slot”, “coordinate”, or “port” in colloquial prose).\nIn **normative** text, the canonical word is **slot**, and the canonical carrier is a **SlotSpec** triple (A.6.0).\n\n1. **SlotKind (place in signature).**\n   *How this position is denoted in the Signature and what is fixed about it by the signature’s definition.*\n   – Examples: `DescribedEntitySlot`, `GroundingHolonSlot`, `ClaimGraphSlot`, `ViewpointSlot`, `ServiceEndpointSlot`, `CallerHolonSlot`, `MetricSlot`.\n   – SlotKind is **structural**: it picks out **one distinguished place** in the argument/port/field list of a given relation, operator, record, or other signatured bundle; it does **not** name a “role” played by whatever fills the slot.\n   – For an n‑ary relation/operator declared in a `U.Signature`, the pair *(Signature id, SlotKind)* identifies a **slot**; positional indices are merely a presentation‑level enumeration of these slots.\n   – What a filler “does” in that place (its contribution to laws, constraints, effects) is governed by the **laws over the Signature** and by the corresponding ValueKind, not by SlotKind‑as‑“role”.\n\n2. **ValueKind (kind of slot filler).**\n   *Which kinds of things may fill this position in principle (at the intensional level).*\n   – Examples: `U.Entity`, `U.Holon`, `U.Method`, `U.Episteme`, `U.ClaimGraph`, `U.Viewpoint`, `U.Characteristic`, `U.ReferenceScheme`.\n   – ValueKind is a **Kind** (C.3.\\*) or another kernel‑level type; it is **not** a slot and never carries `*Slot`/`*Ref` suffixes.\n\n3. **RefKind (how we store / refer).**\n   *What reference/identifier we actually store in episteme when we fill this slot.*\n   – Examples: `U.EntityRef`, `U.HolonRef`, `U.MethodRef`, `U.EpistemeRef`, `U.ViewpointRef`, `U.SurfaceRef`, (optionally) `U.ClaimGraphRef` if a Context chooses to reference claim graphs rather than store them by value.\n   – RefKind is **about references, not values**; it usually points to an editioned artifact (A.7, F.15) and carries the `.edition` field when pinning a phase.\n\n**Discipline:**\n\n* Each declared argument position in a `U.Signature` **MUST** be described by:\n\n  * a SlotKind (name and documentation),\n  * a ValueKind (type of permissible fillers),\n  * and either a RefKind or an explicit declaration “**by‑value**” (no RefKind; the value is embedded).\n* SlotKind and ValueKind are **intensional**; RefKind is **representational**. This mirrors I/D/S: *slot* describes structure, *value* describes what can sit there, *ref* describes how we point to concrete instances.\n\n#### A.6.5:4.2 - Naming discipline: `*Slot` and `*Ref`\n\nThis pattern introduces the following **lexical constraints**, aligned with E.10:\n\n1. **`*Slot` reserved for SlotKind.**\n\n   * Any Tech name ending with `…Slot` **MUST** denote a SlotKind: a named place in a relation/morphism signature.\n   * Examples:\n     – `DescribedEntitySlot`, `GroundingHolonSlot`, `ClaimGraphSlot`, `ViewpointSlot`, `ViewSlot`, `RepresentationSchemeSlot`, `ReferenceSchemeSlot`.\n   * `*Slot` **MUST NOT** appear in names of:\n     – ValueKind (e.g. `U.Entity`, `U.Holon`, `U.Method`),\n     – RefKind (e.g. `U.EntityRef`),\n     – concrete episteme fields (they may be named e.g. `describedEntityRef`, but not `describedEntitySlotField`).\n\n2. **`*Ref` reserved for RefKind and reference fields.**\n\n   * Any Tech name ending with `…Ref` **MUST** denote either:\n     – a **RefKind** (type of references/identifiers), or\n     – a **field** whose type is a RefKind (`describedEntityRef : U.EntityRef`).\n   * `*Ref` **MUST NOT** appear in names of:\n     – ValueKinds (e.g. `U.EntityRef` **cannot** mean “an entity”; it is a reference type),\n     – SlotKinds,\n     – Kinds themselves (`U.Kind`, `U.Entity`, `U.Holon`).\n\n3. **ValueKind names carry no `*Slot`/`*Ref`.**\n\n   * ValueKinds are named using standard FPF conventions (A/E/F, E.10), without `*Slot`/`*Ref`.\n   * Examples: `U.Entity`, `U.Holon`, `U.Method`, `U.ClaimGraph`, `U.ReferenceScheme`, `U.Viewpoint`, `U.View`.\n\n4. **No “Role” as SlotKind head.**\n\n   * In the context of relation signatures, **do not** use “Role” as the head noun for SlotKinds (to avoid conflict with `U.Role`).\n   * Use “Slot” or a neutral description: e.g. `EnactorHolonSlot` (ValueKind `U.Holon`) rather than `EnactorRoleSlot`.\n\nThese rules become part of the **LEX‑BUNDLE guards** and are enforced by F.18 / name‑acceptance harnesses.\n\n#### A.6.5:4.3 - Integration with `U.Signature` (A.6.0)\n\n`U.Signature` already provides a generic pattern for declaring morphism/relationship signatures (SubjectKind, BaseType, Quantification, ResultKind, Vocabulary, Laws).\n\n`U.RelationSlotDiscipline` refines this by adding a **SlotSpec** layer:\n\n*For each parameter position `i` in a signature*:\n\n```\nSlotSpec_i = ⟨name: SlotKind, value: ValueKind, refMode: {ByValue | RefKind}⟩\n```\n\n* **SlotKind** — Tech name with `*Slot` suffix, plus documentation.\n* **ValueKind** — a `U.Type` (often a `U.Kind` or kernel type) declaring the intensional universe of admissible fillers.\n* **refMode**:\n\n  * `ByValue` — the actual value of ValueKind is embedded (typical for small structured values like `U.ClaimGraph` inside an episteme card).\n  * `RefKind` — a **type** of references/identifiers for that ValueKind; e.g. `U.EntityRef` for `U.Entity`, `U.HolonRef` for `U.Holon`. Substitution then operates on references, not directly on the underlying values.\n\nIn practice, a `U.Signature` that follows this pattern:\n\n* becomes **self‑documenting**: each parameter has a clear “slot vs value vs ref” story;\n* supports **typed substitution**: replacing content within the same SlotKind requires only ValueKind compatibility;\n* aligns with **tool signatures** in implementation languages (row‑typed records, dependently typed parameters, effect‑typed arguments). ([13])\n\n#### A.6.5:4.4 - Typed substitution discipline\n\nGiven a relation or morphism `R` with signature Σ and SlotSpecs `{SlotSpec_i}`:\n\n* A **substitution** at slot `i` is a change of the **slot content** that fills SlotKind_i, within or across episteme entries.\n* `U.RelationSlotDiscipline` enforces:\n\n1. **SlotKind invariance.**\n   A substitution **never** changes SlotKind — only the slot content (Value/Ref).\n   – “We put a different dataset into the `DatasetSlot`.”\n   – “We switch the grounding holon in `GroundingHolonSlot`.”\n\n2. **ValueKind compatibility.**\n   The new content **MUST** be of the same ValueKind (or a declared subkind) as `SlotSpec_i.value`; Kind‑CAL governs this (`⊑` in C.3.1–C.3.2). If a Context uses EoIClass species constraints (C.3.2), those act as additional guards but do **not** change the SlotKind.\n\n3. **RefKind correctness.**\n   If `refMode=RefKind`, the stored field is of that RefKind; substitutions operate on references, not on underlying values. Edition pinning is handled as usual by `.edition` fields in F‑patterns (F.15, etc.).\n\n4. **By‑value vs by‑ref awareness.**\n   Substitutions at by‑value slots (e.g. `ClaimGraphSlot`) are **content edits** to the episteme or relation instance; they may affect formality F or assurance lanes. Substitutions at ref slots are **retargetings** of describedEntity or context, and their legality is governed by A.6.2–A.6.4 and Bridge/CL rules. Tooling SHOULD surface this difference explicitly in authoring surfaces (e.g. separate “Ref” vs “embedded content” columns).\n\nThese rules give a uniform way to say:\n\n> “You may swap component X with Y in this slot, because they share ValueKind and pass the relevant Kind/Bridge constraints.”\n\n#### A.6.5:4.5 - Slot operation lexicon (binding / filling / assignment / retargeting / mutation)\n\nThis subsection standardises **how Core and extensions talk about operations over slots**, without committing FPF to any particular programming language semantics. It is a *lexical* and *didactic* guardrail that preserves the SlotKind/ValueKind/RefKind stratification in prose.\n\n##### A.6.5:4.5.1 - Four‑way separation: Identifier vs Slot vs Slot‑content vs Referent\n\n*Diagram is illustrative; the term distinctions are normative.*\n\nTo avoid conflating “binding / assignment / passing / mutation”, FPF authors SHALL keep the following separation in mind:\n\n```\n(1) Identifier/Name  ──binds-to──>  (2) SlotKind  ──in an instance──>  (2′) Slot‑instance  ──filled-with──>  (3) Slot‑content (Value | Ref)\n                                                              └─(if Ref) resolves-to──> (4) Referent value / artifact\n```\n\n**Normative terms**:\n\n* **Identifier** (Surface): a name used in a syntax, table column, record field, port label, or parameter label.\n* **SlotKind** (I‑plane): the signature‑level label for a distinguished place in a relation.\n* **Slot‑instance** (S‑plane / representation): the actual location/cell/position corresponding to a SlotKind inside a specific relation instance, record, port bundle, or episteme card.\n* **Slot‑content** (representation): what is stored in a slot‑instance. It is either:\n\n  * a **by‑value value** of ValueKind, or\n  * a **reference handle** of RefKind.\n* **Referent**: the intensional thing the RefKind points to when resolved (often an editioned artifact).\n\nThis separation is the anchor for all “binding time” talk in A.6.5:4.6.\n\n##### A.6.5:4.5.2 - Canonical verbs (Tech register) for slot operations *(normative)*\n\nWhen a pattern, bridge, or operator description discusses a change or action “with respect to a slot”, it SHALL use (or explicitly map to) the following verbs. Each verb is tied to **which link/layer it affects**.\n\n1. **bind / rebind** (Identifier → SlotKind/slot‑instance).\n   *Use when the subject is an Identifier/Name and the effect is changing what that name designates.*\n   – **bind**: establish a new association of an Identifier to a SlotKind/slot‑instance (or to a value in a language surface).\n   – **rebind**: change an existing association of an Identifier to designate a different slot‑instance or different value.\n   **Guard:** do not use “bind” to mean “write into a slot”. Binding is about *names*, not slots.\n\n2. **fill** (Slot‑instance ← Slot‑content).\n   *The generic, cross‑domain verb meaning “provide slot‑content for a slot‑instance”.*\n   – Fill does **not** by itself imply first‑time vs update, nor by‑value vs by‑ref.\n   – Use **fill** when discussing hardware slots, tuple coordinates, ports, record fields, or parameters uniformly.\n\n3. **initialize** (first fill).\n   *Use when the slot‑instance previously had no content.*\n   – For `refMode=RefKind`: initialization sets the initial reference handle.\n   – For `ByValue`: initialization sets the embedded initial value.\n   **Guard:** do not call initialization “assignment” in normative text.\n\n4. **assign / set / write / update** (subsequent fill; slot‑content replacement).\n   *Use when a slot‑instance already has content and you replace it with new content.*\n   – These verbs are allowed as near‑synonyms, but **SHOULD** be used consistently within one pattern family.\n   **Guard:** when `refMode=RefKind`, prefer **retarget** (below) if the intent is “change what this ref points to”, not “edit content”.\n\n5. **retarget** (Ref slot update, same SlotKind/ValueKind).\n   *Use only for `refMode=RefKind` slots, when the operation replaces one reference handle with another, thereby changing the referent while preserving SlotKind and ValueKind.*\n   – “Retarget `DescribedEntitySlot` from `UserService#staging` to `UserService#prod`.”\n   Retargeting is the canonical FPF verb for “swap the referenced thing in this slot”.\n\n6. **substitute** (typed replacement with explicit compatibility claim).\n   *Use when the statement’s main point is the **compatibility law** (“allowed because ValueKind matches”).*\n   – Substitute is a **discipline word**: it signals that SlotKind is fixed and ValueKind compatibility is being asserted/checked.\n\n7. **resolve / dereference** (Ref → Referent).\n   *Use when a reference handle is mapped to the intensional referent.*\n   – This is where “late binding” often hides in runtime systems (dispatch, dynamic lookup, registry indirection).\n   **Guard:** resolving a reference is distinct from retargeting the reference.\n\n8. **mutate / modify** (Referent internal change; content unchanged).\n   *Use only when the referent itself changes while the slot‑content (the reference handle) does not.*\n   **FPF note:** In edition‑disciplined contexts, prefer to describe intentional change as **revise / re‑edition** + **retarget**, rather than “mutate”, because the Core treats editioned artifacts as stable per edition (A.7, F.15).\n\n9. **pass** (parameter slot filling).\n   *Use for method/service signatures when an argument fills a parameter slot at a call boundary.*\n   – Passing is a specialised instance of **fill**, typically realised as parameter binding + slot filling in implementation languages. In FPF text, “pass into SlotKind” is acceptable if SlotKind names the parameter position.\n\n##### A.6.5:4.5.3 - Canonical nouns *(normative)*\n\nTo prevent role metaphors from re‑entering slot talk:\n\n* Use **slot‑content** (preferred) or **slot filler** for “the thing currently in the slot”.\n* Avoid person/role metaphors such as **occupant** in normative writing. If a Context insists on using such a word in Plain register, it SHALL define it explicitly as a synonym for slot‑content and SHALL NOT derive role semantics from it.\n* Use **target**/**referent** for what a Ref points to; use **retargeting** for changing the target by changing the Ref.\n* Use **by‑value edit** (or **embedded content edit**) for changes to a `ByValue` slot such as `ClaimGraphSlot`.\n\n##### A.6.5:4.5.4 - Operator naming guidance for slot‑writing operators *(normative, but intentionally lightweight)*\n\nWhen naming an operator/morphism/bridge whose primary effect is a slot change, the Tech name SHOULD make two things legible:\n\n1. **Which SlotKind(s) it writes**, and\n2. **Which operation class it is**, using the canonical verbs above.\n\nRecommended patterns (examples only; Contexts may adopt their own naming style via F.18):\n\n* `Retarget<SlotQualifier>` for ref‑slot retargeting (e.g. `RetargetDescribedEntity`, `RetargetGroundingHolon`).\n* `Edit<SlotQualifier>` / `Update<SlotQualifier>` for by‑value content edits (e.g. `EditClaimGraph`).\n* `Substitute<SlotQualifier>` when the operator exists to enforce/declare ValueKind compatibility (e.g. `SubstituteDataset`).\n* `Resolve<SlotQualifier>` when the operator is about resolving a Ref to a referent (e.g. `ResolveServiceEndpoint`).\n\nThis rule is a lexical enforcement of A.6.5:4.4 (typed substitution discipline): the name should tell the reader whether the operator is a **retargeting** (ref change) or a **content edit** (by‑value change).\n\n#### A.6.5:4.6 - Binding time and “early vs late binding” *(normative framing, informative examples)*\n\nIn cross‑domain slot talk, “early binding / late binding” is meaningful only if the author states **which link is being fixed when**. Under A.6.5:4.5, there are three distinct “times” that writers must not conflate:\n\n1. **SlotSpec time (signature time).**\n   SlotKind / ValueKind / refMode are fixed when the `U.Signature` is declared. This is “early” by definition in FPF Core.\n\n2. **Slot filling time (initialization / assignment / retargeting).**\n   A particular relation instance / episteme card / parameter bundle acquires slot‑content for a SlotKind.\n   – *Early‑filled* means: chosen at authoring/spec time (e.g. configuration pins a specific `U.HolonRef`).\n   – *Late‑filled* means: chosen at runtime or late in a workflow (e.g. service endpoint selected by policy at deployment).\n\n3. **Resolution / dispatch time (resolve RefKind; select referent).**\n   Even if a ref handle is present, the referent may be resolved early or late.\n   – *Eager resolution* means: resolve now, cache/commit to a referent.\n   – *Lazy resolution* means: resolve on demand.\n   – *Dynamic dispatch* is a special case: the “method slot” is resolved at call time based on a receiver/context, rather than being statically selected.\n\n**Rule (lexical guard):**\nAny use of “early binding” / “late binding” in Core or extensions SHALL specify which of the above it refers to, using one of:\n\n* **early/late‑filled** (slot filling),\n* **eager/lazy‑resolved** (resolution),\n* **early/late name‑binding** (Identifier binding, if a language surface is being discussed).\n\nThis preserves the A.6.5 stratification and prevents importing accidental semantics from a specific programming language.\n",
        "archetypal_grounding": "### A.6.5:5 - Archetypal Grounding (Tell‑Show‑Show)\n\nFollowing E.7, we ground the pattern in a **System** example and an **Episteme** example.\n\n#### A.6.5:5.1 - System example — authentication pipeline signature\n\nConsider an `AuthPipelineSpecKind` (system‑level episteme describing an authentication pipeline for a microservice). Its key slots might be:\n\n* `DescribedEntitySlot` — “which holon the pipeline is about”\n  – ValueKind: `U.Holon` (EoIClass = “UserService system”).\n  – RefKind: `U.HolonRef` (e.g. `UserService#prod`).\n\n* `AuthProviderComponentSlot` — “which authentication provider component is selected”\n  – ValueKind: `U.Holon` (EoIClass = “AuthProviderSystem”).\n  – RefKind: `U.HolonRef` (e.g. `Auth_OIDC`, `Auth_LDAP`).\n\n* `ClaimGraphSlot` — “what is asserted about the pipeline”\n  – ValueKind: `U.ClaimGraph`.\n  – refMode: `ByValue` (ClaimGraph stored inside the episteme card).\n\nSubstitutions / retargetings:\n\n* **Retargeting** `AuthProviderComponentSlot` from `Auth_OIDC` to `Auth_LDAP`:\n  – SlotKind fixed (`AuthProviderComponentSlot`).\n  – ValueKind unchanged (`U.Holon`, `AuthProviderSystem ⊑ U.Holon`).\n  – RefKind unchanged (`U.HolonRef`).\n  – Semantically: “retarget the ref that fills the same slot”.\n\n* **Retargeting** `DescribedEntitySlot` from `UserService#staging` to `UserService#prod`:\n  – Same SlotKind and ValueKind.\n  – Different `U.HolonRef` slot‑content.\n  – May require different grounding and assurance episteme, but the slot discipline is identical.\n\n#### A.6.5:5.2 - Episteme example — model evaluation result\n\nConsider `ModelEvaluationResultKind` as an episteme kind:\n\n* `DescribedEntitySlot` — the model being evaluated\n  – ValueKind: `U.Method` (intensional ML model).\n  – RefKind: `U.MethodRef` (id of `Model_v3`).\n\n* `DatasetSlot` — the dataset on which it is evaluated\n  – ValueKind: `U.Entity` (EoIClass = “Dataset”).\n  – RefKind: `U.EntityRef` (e.g. `Dataset_A`, `Dataset_B`).\n\n* `TargetCharacteristicSlot` — the characteristic being measured\n  – ValueKind: `U.Characteristic` (`Accuracy`, `F1`, `AUROC`).\n  – RefKind: `U.CharacteristicRef`.\n\n* `GroundingHolonSlot` — evaluation environment\n  – ValueKind: `U.Holon` (e.g. `EvalCluster#1`).\n  – RefKind: `U.HolonRef`.\n\n* `ClaimGraphSlot` — evaluation result graph\n  – ValueKind: `U.ClaimGraph`.\n  – refMode: `ByValue`; the numeric thresholds and results live inside `content : U.ClaimGraph`.\n\nTypical moves:\n\n* `DatasetSlot`: **retarget** `Dataset_A` → `Dataset_B` to test generalisation.\n* `TargetCharacteristicSlot`: **retarget** `Accuracy` → `F1` to focus on class imbalance.\n* `ClaimGraphSlot`: **by‑value edit** thresholds from “`P95Latency ≤ 200 ms`” to “`≤ 150 ms`” — a `ByValue` content edit, not a ref retargeting.\n\nThe SlotKind/ValueKind/RefKind discipline makes these moves **local and explicit**: the pattern describes which moves are allowed where, and A.6.2–A.6.4 then constrain how episteme morphisms may change ClaimGraphs and references.\n\n#### A.6.5:5.3 - Didactic micro‑examples — substitution by SlotKind / ValueKind / RefKind *(informative)*\n\nThe following short examples are intended for a didactic guide or for cross‑references from A.6.0/A.6.x/C.2.1. In all of them:\n\n* **SlotKind** names the **place/position in the structure** (slot/field/coordinate in a tuple/record/port bundle).\n* **ValueKind** is the **kind of value** admissible at that place.\n* **RefKind** is the **reference/identifier type** used in episteme when that slot is filled (absent when the slot is by‑value).\n* `GroundingHolon` is **not** a separate kernel type: it is simply a `U.Holon` used as the ValueKind of `GroundingHolonSlot`.\n\nExample names like `FurnitureSafetyDescriptionKind`, `AuthPipelineSpecKind`, `ModelEvaluationResultKind`, `IncidentRunbookSpecKind`, `ServiceSLARequirementKind` are **context‑local** kinds, not new kernel tokens.\n\n##### A.6.5:5.3.1 - Mechanics — stool on a test rig\n\n*EpistemeKind:* `FurnitureSafetyDescriptionKind`.\n\n*SlotKind / ValueKind / RefKind:*\n\n* `DescribedEntitySlot` — SlotKind “what this description is about”; ValueKind `U.Entity` with EoIClass ⊑ `U.Holon` (stool as a furniture holon); RefKind `U.EntityRef` (identifier of a concrete stool `S_i`).\n* `GroundingHolonSlot` — SlotKind “where the test happens”; ValueKind `U.Holon` (test rig `LabRig_j`); RefKind `U.HolonRef`.\n* `ClaimGraphSlot` — SlotKind for the internal content; ValueKind `U.ClaimGraph`; refMode `ByValue` (graph embedded in the episteme).\n\n*Substitutions (all under the **same** SlotKinds):*\n\n* Episteme `E₁`: `describedEntityRef = S_1`, `groundingHolonRef = LabRig_A`.\n* Episteme `E₂`: `describedEntityRef = S_2`, `groundingHolonRef = LabRig_A` — **substitute another stool in the same `DescribedEntitySlot`** (different `U.EntityRef` slot‑content).\n* Episteme `E₃`: `describedEntityRef = S_1`, `groundingHolonRef = LabRig_B` — **substitute another test rig in `GroundingHolonSlot`** while keeping the same object‑of‑talk.\n\nIn all three cases the SlotKinds (and ValueKinds) are stable; only the **Refs that fill those slots** change. This matches the engineering idiom “drop another module into the same slot”.\n\n##### A.6.5:5.3.2 - Microservices — switching the authentication provider\n\n*EpistemeKind:* `AuthPipelineSpecKind`.\n\n*SlotKind / ValueKind / RefKind:*\n\n* `DescribedEntitySlot` — ValueKind `U.Holon` with EoIClass = “`UserService` holon”; RefKind `U.HolonRef` (e.g. `UserService#prod`).\n* `AuthProviderComponentSlot` — SlotKind “which auth provider component is used in this pipeline”; ValueKind `U.Holon` with EoIClass = “`AuthProviderSystem` holon”; RefKind `U.HolonRef` (e.g. `Auth_OIDC`, `Auth_LDAP`).\n* `ClaimGraphSlot` — ValueKind `U.ClaimGraph`; refMode `ByValue` (pipeline invariants and flow logic).\n\n*Substitutions / retargetings:*\n\n* Episteme `Spec_OIDC`: `describedEntityRef = UserService#prod`, `authProviderComponentRef = Auth_OIDC`.\n* Episteme `Spec_LDAP`: same `describedEntityRef = UserService#prod`, but `authProviderComponentRef = Auth_LDAP`.\n\nHere SlotKind is identical (`AuthProviderComponentSlot`); ValueKind is “any auth‑provider holon”; the episteme change is purely a **retargeting** of the `U.HolonRef` slot‑content.\n\n##### A.6.5:5.3.3 - Data/ML — swapping dataset or target characteristic\n\n*EpistemeKind:* `ModelEvaluationResultKind`.\n\n*SlotKind / ValueKind / RefKind:*\n\n* `DescribedEntitySlot` — ValueKind `U.Method`; RefKind `U.MethodRef` (e.g. `Model_v3`).\n* `DatasetSlot` — ValueKind `U.Entity` with EoIClass = “dataset”; RefKind `U.EntityRef` (`Dataset_A`, `Dataset_B`, …).\n* `TargetCharacteristicSlot` — ValueKind `U.Characteristic`; RefKind `U.CharacteristicRef`.\n* `GroundingHolonSlot` — ValueKind `U.Holon`; RefKind `U.HolonRef`.\n* `ClaimGraphSlot` — ValueKind `U.ClaimGraph`; refMode `ByValue`.\n\n*Substitutions / retargetings:*\n\n* `Eval_1`: `describedEntityRef = Model_v3`, `datasetRef = Dataset_A`, `targetCharacteristicRef = Accuracy`, `groundingHolonRef = EvalCluster#1`.\n* `Eval_2`: same model / characteristic / cluster, but `datasetRef = Dataset_B` — **substitute another dataset in `DatasetSlot`** (retarget the dataset ref).\n* `Eval_3`: same model and dataset, but `targetCharacteristicRef = F1` — **substitute another characteristic in `TargetCharacteristicSlot`**.\n\n##### A.6.5:5.3.4 - Operational practice — the same runbook in different operating centres\n\n*EpistemeKind:* `IncidentRunbookSpecKind`.\n\n*SlotKind / ValueKind / RefKind:*\n\n* `DescribedEntitySlot` — ValueKind `U.Method`; RefKind `U.MethodRef`.\n* `GroundingHolonSlot` — ValueKind `U.Holon`; RefKind `U.HolonRef`.\n* `ClaimGraphSlot` — ValueKind `U.ClaimGraph`; refMode `ByValue`.\n\n*Substitutions / retargetings:*\n\n* `Runbook_DC1`: `describedEntityRef = MajorIncidentRunbook`, `groundingHolonRef = DC1_NOC`.\n* `Runbook_DC2`: same `describedEntityRef`, but `groundingHolonRef = DC2_NOC`.\n\nThis is “one and the same method is specified and validated in two different operational environments”: SlotKind and ValueKind are stable; only the `U.HolonRef` slot‑content differs.\n\n##### A.6.5:5.3.5 - SLO/SLA requirements — changing the target characteristic vs changing the threshold\n\n*EpistemeKind:* `ServiceSLARequirementKind`.\n\n*SlotKind / ValueKind / RefKind:*\n\n* `DescribedEntitySlot` — ValueKind `U.Holon`; RefKind `U.HolonRef` (e.g. `CheckoutService#prod`).\n* `TargetCharacteristicSlot` — ValueKind `U.Characteristic`; RefKind `U.CharacteristicRef`.\n* `ClaimGraphSlot` — ValueKind `U.ClaimGraph`; refMode `ByValue`. Numeric thresholds live **inside the ClaimGraph as literals**, not as RefKinds.\n\n*Moves:*\n\n* `SLA_latency_200`: `describedEntityRef = CheckoutService#prod`, `targetCharacteristicRef = P95Latency`; ClaimGraph contains `P95Latency ≤ 200 ms`.\n* `SLA_latency_150`: same refs, but ClaimGraph threshold is `P95Latency ≤ 150 ms`. This is a **by‑value edit** of `ClaimGraphSlot`.\n* `SLA_availability_99_9`: same `describedEntityRef`, but `targetCharacteristicRef = Availability`; ClaimGraph states `Availability ≥ 99.9%`. This is a **retargeting** of `TargetCharacteristicSlot`.\n",
        "a.6.5:6___bias‑annotation": "### A.6.5:6 - Bias‑Annotation\n\n**Lenses tested and scope.** This pattern was read through all five Principle‑Taxonomy lenses (`Gov`, `Arch`, `Onto/Epist`, `Prag`, `Did`) and is intended as a **universal** discipline for n‑ary relation and morphism signatures across Parts A/B/C/E. It leans toward the `Arch` and `Onto/Epist` lenses (typed signatures, explicit kinds), but mitigates this by (a) keeping the discipline notation‑agnostic, (b) aligning with existing tooling rather than prescribing any, and (c) grounding the rules in System/Episteme examples with clear didactic intent. No domain‑specific scope limitation is claimed.\n\n* **Typed‑language bias.**\n\n  * The pattern leans on intuitions from typed programming languages (parameter types, records, references). This is intentional: it aligns FPF signatures with mainstream tooling and with post‑2015 typed effect/row systems. The pattern remains **notation‑agnostic** and does not commit to any specific PL or logic.\n\n* **Slot‑first bias.**\n\n  * We treat *slot* as the primary abstraction and discourage role‑style or object‑style naming for argument positions. This favours structural clarity over conversational metaphors (“subject/object/role”) and keeps `U.Role` free for RoleEnactment rather than param‑slots.\n\n* **By‑value/by‑ref honesty.**\n  We explicitly separate ValueKind and RefKind instead of hiding “by‑reference” behind the type system. This increases verbosity but makes reasoning about edition pinning, caching, and re‑targeting more robust, and keeps I/D/S distinctions visible inside signatures.\n\n* **Lexicon bias (precision over metaphor).**\n  We standardise the slot‑operation lexicon (bind/fill/initialize/assign/retarget/resolve/mutate) and discourage metaphors that smuggle role semantics back into SlotKinds. This increases didactic load, but directly reduces cross‑pattern ambiguity, especially in “binding time” discussions.\n\n* **Episteme‑first describedEntity.**\n  The examples and cross‑references prioritise episteme use‑cases (C.2.1, A.6.2–A.6.4) where describedEntity and retargeting are subtle. System‑only usages (e.g. method signatures) are absolutely allowed but not the driving case; they inherit the same discipline without additional obligations.\n",
        "conformance_checklist": "### A.6.5:7 - Conformance Checklist (normative)\n\n**CC‑A.6.5‑1 - SlotSpec for every parameter.**\nEvery `U.Signature` that declares an n‑ary relation or morphism **SHALL** assign to each parameter position a SlotSpec triple: `⟨SlotKind, ValueKind, refMode⟩`.\n\n**CC‑A.6.5‑2 - `*Slot` discipline.**\nAny Tech name ending with `…Slot` **MUST** denote a SlotKind; SlotKinds **MUST NOT** be used as ValueKinds or RefKinds.\n\n**CC‑A.6.5‑3 - `*Ref` discipline.**\nAny Tech name ending with `…Ref` **MUST** denote either a RefKind or a field whose type is a RefKind. ValueKinds and SlotKinds **MUST NOT** end in `…Ref`.\n\n**CC‑A.6.5‑4 - ValueKind purity.**\nValueKinds **MUST** be declared without `*Slot`/`*Ref` suffixes and **MUST** be FPF types (often `U.Kind` or kernel‑level types). Any existing type whose name violates this rule must be either:\n\n* reclassified as a RefKind, or\n* renamed to drop the suffix.\n\n**CC‑A.6.5‑5 - Episteme core SlotKinds.**\nFor episteme kinds (`U.EpistemeKind`), the following SlotKinds **SHALL** be used (or their documented refinements) in C.2.1 / C.2.x:\n\n* `DescribedEntitySlot` with ValueKind `U.Entity` **or a declared subkind** (e.g. `U.Method`, `U.Holon`) via Kind‑CAL (EoIClass ⊑ `U.Entity` at species level);\n* `GroundingHolonSlot` with ValueKind `U.Holon`;\n* `ClaimGraphSlot` with ValueKind `U.ClaimGraph` and `ByValue` mode in the minimal core;\n* `ViewpointSlot` with ValueKind `U.Viewpoint`;\n* `ViewSlot` with ValueKind `U.View` (`U.EpistemeView`);\n* `ReferenceSchemeSlot` with ValueKind `U.ReferenceScheme` and `ByValue` mode in the minimal core.\n\n**CC‑A.6.5‑6 - No “Role” as SlotKind head.**\nSlotKinds **MUST NOT** use “Role” as their head noun; use “Slot” with a neutral qualifier instead (e.g., `EnactorHolonSlot`). `U.Role` remains reserved for RoleEnactment patterns.\n\n**CC‑A.6.5‑7 - Substitution checks.**\nAny pattern that describes substitution or replacement of arguments **MUST** phrase its rules in terms of SlotKinds and ValueKinds (and, where relevant, RefKinds), not in terms of unstructured parameter indices or ad‑hoc labels.\n\n**CC‑A.6.5‑8 - Cross‑pattern consistency.**\nWhen the same conceptual position is used across patterns (e.g. “describedEntity target”, “grounding holon”, “caller system”), the **same SlotKind name** and ValueKind **SHALL** be reused, unless a documented Bridge declares a different discipline or the pattern explicitly scopes itself to a distinct calculus.\n\n**CC‑A.6.5‑9 - Migration of legacy `…Ref`/`…Slot` usage.**\nContexts adopting this pattern **MUST** maintain a migration table for legacy types/fields whose names contain `Ref` or `Slot` but do not comply with the new discipline. Each entry shall state:\n\n* old name and role,\n* new SlotKind/ValueKind/RefKind,\n* whether the old name becomes an alias (deprecated) or is removed.\n\n**CC‑A.6.5‑10 - Pattern integration.**\nNew or revised patterns in Part A/B/C/E that introduce n‑ary relations, morphisms, or signatures **SHALL** reference A.6.5 in their Relations section and attest that they follow SlotKind/ValueKind/RefKind discipline.\n\n**CC‑A.6.5‑11 - Slot‑content terminology.**\nNormative text that refers to “what is in a slot” **SHALL** use **slot‑content** (or **slot filler**) and **SHALL NOT** rely on role/person metaphors (e.g. “occupant”) unless explicitly defined as a strict synonym for slot‑content with no added semantics.\n\n**CC‑A.6.5‑12 - Slot‑operation verb discipline.**\nAny normative description of a change “to a slot” **MUST** specify which operation class it is (initialize vs assign/set vs retarget vs by‑value edit vs resolve vs mutate/revise), using the canonical verbs in A.6.5:4.5.2 or explicitly mapping local terms to them.\n\n**CC‑A.6.5‑13 - Binding‑time clarity.**\nAny use of “early binding / late binding” (or equivalent) **MUST** specify whether it refers to:\n\n* Identifier binding (name‑binding),\n* Slot filling (early/late‑filled),\n* Reference resolution / dispatch (eager/lazy‑resolved).\n",
        "consequences": "### A.6.5:8 - Consequences\n\n**Benefits**\n\n* **Uniform language for arguments and for operations.**\n  Any n‑ary relation (episteme, role, method, service, guard) can be described with the same SlotKind/ValueKind/RefKind triple **and** with a stable operation lexicon (fill/initialize/assign/retarget/resolve).\n\n* **Safer substitutions.**\n  Substitution, retargeting, and viewing laws (A.6.2–A.6.4) can be stated in terms of *which SlotKinds* they read/write and *which ValueKinds* they preserve or retarget, without accidentally collapsing into “just replace the thing”.\n\n* **Cleaner naming and migration.**\n  Misuses of `*Ref`, `*Slot`, “Role”, “Subject”, “Object” in signatures become guard‑detectable; migration strategies can be described as re‑factoring SlotKinds and ValueKinds rather than ad‑hoc renames.\n\n* **Tool alignment.**\n  Implementation languages with **row‑typed records, dependent types, and algebraic effects** map naturally to the SlotKind/ValueKind/RefKind layers, easing code generation and static analysis. ([13])\n\n**Trade‑offs / mitigations**\n\n* **Extra metadata in signatures.**\n  Every parameter now has three pieces of information instead of one. Mitigation: template support in authoring tools; pattern‑guided macros for common shapes (episteme, role, method, service).\n\n* **Stricter lexical rules.**\n  Some legacy names will need migration (`EpistemicObject`, ad‑hoc `…Ref` types). Mitigation: migration notes in F.18 and dedicated anti‑pattern sections; transitional aliases allowed but marked deprecated.\n\n* **Learning curve.**\n  Authors must learn to think “SlotKind/ValueKind/RefKind” *and* distinguish “retarget vs edit vs resolve” before writing `id` or `subject`. Mitigation: Tell‑Show‑Show examples and a didactic micro‑guide on slot operations referenced from A.6.0/C.2.1/E.17.0.\n",
        "rationale": "### A.6.5:9 - Rationale\n\n**Why a SlotKind/ValueKind/RefKind triple at all.**\nAt architheory level, this pattern makes `U.Signature` behave like a lightweight dependently‑typed record discipline: SlotKind plays the role of an index or label, ValueKind is the family of admissible fillers at that position, and RefKind captures the representation choice (by‑value or via a handle). This mirrors the way post‑2015 work on row‑polymorphic data and effect rows treats labels and field kinds as first‑class, while keeping the Core notation‑neutral.\n\n**Why separate ValueKind from RefKind.**\nIn practice, “Ref” types tend to be quietly used as if they were values, eroding the I/D/S split and making edition discipline invisible. By insisting that ValueKind is always the conceptual kind (“what sort of thing is this about?”) and RefKind is always the reference/identifier kind (“how do we point at it in Episteme?”), the pattern aligns with E.10.D2’s intension/description/specification discipline and with modern resource‑aware logics that keep values and resources distinct.\n\n**Why add a slot‑operation lexicon.**\nThe triple only buys safety if authors and tools can see it at a glance **and** can narrate changes without collapsing layers. A.6.5:4.5 makes the common “put something in a slot” moves explicit: initialization vs assignment vs retargeting vs by‑value editing vs resolution. This directly reduces ambiguity in episteme morphism descriptions (A.6.2–A.6.4) and prevents accidental imports from a specific PL’s terminology.\n\n**Why standardise episteme SlotKinds.**\ndescribedEntity and grounding recur across epistemes; standard SlotKinds (`DescribedEntitySlot`, `GroundingHolonSlot`, `ClaimGraphSlot`, etc.) let A.6.2–A.6.4 and C.2.1 talk about substitutions and retargetings once, instead of re‑defining “what this is about” in every pattern.\n\n**Why lexical rules (`*Slot`, `*Ref`, operation verbs, no “Role” heads).**\nThe discipline must be cheap to apply. Reserving `*Slot` for SlotKinds and `*Ref` for RefKinds/fields gives a syntax‑level guard against conflating places, kinds, and handles. Standardising operation verbs (initialize/retarget/resolve) prevents prose from re‑introducing the same conflation by different words.\n",
        "a.6.5:10___sota‑echoing_(post‑2015_practice_alignment)": "### A.6.5:10 - SoTA‑Echoing (post‑2015 practice alignment)\n\n**Purpose.** To situate SlotKind/ValueKind/RefKind discipline with respect to contemporary typed and relational approaches, without importing any external calculus into the Core. All items are used as conceptual comparators; concrete reuse in a `U.BoundedContext` would happen only via explicit Bridges (F.9) with declared CL penalties.\n\n1. **Row‑typed, extensible data / effect rows (adopt/adapt).**\n   Post‑2015 work on row polymorphism and extensible data/effect rows treats records and variants as labelled collections of fields whose presence and type can evolve independently.\n   **Adopted:** the idea that **positions** (labels) are first‑class and carry their own typing discipline.\n   **Adapted:** instead of row kinds, FPF uses SlotKind/ValueKind/RefKind triples for n‑ary relations and epistemic slots; the pattern is notation‑agnostic and applies equally to episteme structures, role relations, and service signatures. ([13])\n\n2. **Dependent type systems engineered via macros (adopt/adapt).**\n   Macro‑based dependent type systems such as Turnstile+ separate structural indices, value‑level types, and evidence, while allowing them to be related by construction.\n   **Adopted:** the separation between **indices/labels** and **values**, and the intuition that signatures should expose both explicitly.\n   **Adapted:** SlotKind corresponds to a structural index, ValueKind to the ordinary type of fillers, and RefKind to runtime‑level identifiers; the discipline is phrased at the architheory level and kept independent of any particular PL.\n\n3. **Relational models of types‑and‑effects (adapt).**\n   Relational models for types‑and‑effects distinguish value positions from effect/resource annotations and track substitution separately across these layers.\n   **Adopted:** the insistence that reasoning about **substitution and equality** must be stratified (values vs additional structure).\n   **Adapted:** A.6.5 stratifies *slot / value / reference* instead of *value / effect*, and applies the discipline not only to programs but also to epistemes, roles, methods, and services. ([15])\n\n4. **Optics / lenses as disciplined projections (echo).**\n   Profunctor optics formalise get/put pairs where a fixed “focus” position within a larger structure is manipulated under composition laws.\n   **Echoed:** SlotKind plays the role of the focus coordinate; ValueKind is the focus type; RefKind determines whether the focus is stored by value or via a handle. This perspective informs later use of SlotKind discipline in EpistemicViewing (A.6.3) and multi‑view publication (E.17). ([16])\n\n**Cross‑Context reuse and Bridges.** When a `U.BoundedContext` chooses to adopt a concrete row‑typing discipline, relational logic, or optics library, it **SHALL** do so via explicit Bridges (F.9) with CL and (for plane crossings) `Φ(CL)`/`Φ_plane` policy‑ids, keeping numerical policies and notations Context‑local. A.6.5 only constrains the **slot discipline** that such Bridges must respect.\n",
        "relations": "### A.6.5:11 - Relations (with other patterns)\n\n**Specialises A.6.P `U.RelationalPrecisionRestorationSuite`.**\nA.6.5 is the RPR specialisation for “n‑ary relation as slots”: it restores hidden arity by making participant positions explicit as SlotKinds, and stabilises change semantics via the slot‑operation lexicon + lexical guards.\n\n\n**Builds on A.6.0 `U.Signature`.**\nRefines parameter declarations with SlotSpec triples `⟨SlotKind, ValueKind, refMode⟩` while leaving the rest of the signature structure (SubjectKind, BaseType, Quantification, ResultKind, Laws) unchanged. SlotKinds become the canonical labels for argument positions.\n\n**Constrains C.2.1 `U.EpistemeSlotGraph`.**\nFixes core episteme SlotKinds (`DescribedEntitySlot`, `GroundingHolonSlot`, `ClaimGraphSlot`, `ViewpointSlot`, `ViewSlot`, `ReferenceSchemeSlot`) and their ValueKinds/`ByValue` vs Ref discipline. C.2.1 and its extensions SHALL use these SlotKinds (or documented refinements) so that episteme morphisms can be expressed uniformly over slots.\n\n**Supports A.6.2–A.6.4 (episteme morphisms and viewing).**\nDescribedEntity‑preserving vs describedEntity‑retargeting morphisms can now be stated as constraints on which SlotKinds’ ValueKinds/RefKinds they may change. Retargeting becomes “retargeting at `DescribedEntitySlot` under a Kind‑Bridge” rather than an ad‑hoc parameter tweak. The operation lexicon in A.6.5:4.5 makes “retarget vs edit vs resolve” explicit in these morphism descriptions.\n\n**Coordinates with B.5.* (RoleEnactment).**\nRole/assignment relations may declare SlotKinds such as `HolderHolonSlot`, `RoleSlot`, `ContextSlot`, `WindowSlot` with clear ValueKinds/RefKinds, instead of overloading “role” for both holonic roles and relation positions. This keeps `U.Role` semantics (A.2, F.6) separate from slot discipline.\n\n**Coordinates with E.17 `U.MultiViewDescribing`.**\n`Viewpoint` and `View` positions are governed by SlotKind/ValueKind/RefKind; view‑changing operations can be described as substitutions at specific SlotKinds that preserve ClaimGraph content while re‑indexing viewpoints and views.\n\n**Feeds F.18 (LEX‑BUNDLE) and E.10 (LEX).**\nProvides lexical guards for `*Slot` and `*Ref`, and (via A.6.5:4.5) for operation verbs:\n\n* `*Slot` reserved for SlotKinds only;\n* `*Ref` reserved for RefKinds and reference fields;\n* ValueKinds and Kind names MUST NOT carry either suffix;\n* slot‑operation verbs must not collapse retargeting into “editing”.\n\n**Used by A.19 `CharacteristicSpace` and measurement patterns.**\nCharacteristic‑space slots already behave as positions with attached kinds; slot discipline in A.6.5 gives a uniform story for how such slots appear inside relation signatures, episteme cards, and service definitions, and how substitution over those slots is checked.\n\n[13] https://dl.acm.org/doi/pdf/10.1145/3290325\n[14] https://www.williamjbowman.com/resources/wjb2019-depmacros.pdf\n[15] https://iris-project.org/pdfs/2017-popl-effects-final.pdf\n[16] https://arxiv.org/pdf/1809.00738\n",
        "a.6.5:end": "### A.6.5:End\n"
      },
      "content": "### A.6.5:End\n",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.6.6",
      "title": "U.BaseDeclarationDiscipline - Kind-explicit, scoped, witnessed base declaration discipline (with base-change lexicon)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.6.6 - U.BaseDeclarationDiscipline - Kind-explicit, scoped, witnessed base declaration discipline (with base-change lexicon)\n\n**Plain-name.** Scoped witnessed base declaration discipline.\n\n**Status.** Normative (Core).\n\n**Placement.** Part A, cluster A.IV “Architheory Kernel”; adjacent to A.6.5 `U.RelationSlotDiscipline`.\n\n**Depends on.**\n– A.6.0 `U.Signature` (universal signature carrier).\n– A.6.5 `U.RelationSlotDiscipline` (SlotKind/ValueKind/RefKind stratification + slot-operation lexicon).\n– A.2.6 (Scope discipline; explicit `Γ_time`; implicit “latest/current” is forbidden).\n– A.2.4 `U.EvidenceRole` (timespan + evidence-role discipline for decision-relevant witness sets).\n– A.7 (Strict Distinction; I/D/S vs Surface).\n– E.8 (pattern authoring order & SoTA discipline).\n– E.10 (LEX‑BUNDLE discipline; D.CTX lexical guardrails).\n\n**Coordinates with.**\n– A.10 Evidence–Provenance DAG discipline (`verifiedBy`, `validatedBy`).\n– A.14 per-edge constructive grounding (`tv:groundedBy`) and `validationMode` discipline.\n– C.2.1 `U.EpistemeSlotGraph` grounding slots (`GroundingHolonSlot`, `describedEntity`).\n– A.6.3 `U.EpistemicViewing` (describedEntity-preserving view operators; base-relative “how” without retargeting).\n– A.6.4 `U.EpistemicRetargeting` (base-change along `KindBridge`; retargeting lexicon and continuity rules).\n– C.3.3 `U.KindBridge` & `CL^k` (explicit repair/translation when endpoint kinds or Contexts differ; no silent re-typing).\n– E.18 assurance-operations on `U.Transfer` (`CalibrateTo`, `CiteEvidence`, `AttributeTo`, `ConstrainTo`, …).\n– F.9 Bridges & CL (cross-context / cross-plane base declarations cite Bridge ids + CL policy).\n– F.15 F‑Suite validation harness (SCR/RSCR pins and refresh governance).\n– F.18 naming governance (surface rules for Tech/Plain twins).\n\n**Aliases (informative; discouraged for normative prose).**\n– “anchoring / anchor” (legacy umbrella colloquial; a red‑flag token for *under-described dependence*). **Prohibited in Tech register** as a meaning‑surrogate; treat it as a defect to be rewritten into an explicit `baseRelation(dependent, base)` form. Allowed only when referring to a **pattern-defined primitive** that already reserves the word (e.g., E.10 MG‑DA *Domain Anchoring*; evidence/pin “anchors” where the term is explicitly reserved), or inside quoted legacy text that is immediately followed by a conformant rewrite.\n– “Qualified statement / attributed edge” (knowledge-graph colloquial).\n– “Pinning” (when witnesses are edition pins).\n\n**Mint‑or‑Reuse note (informative).**\nThis pattern **mints** the record shape name `U.ScopedWitnessedBaseDeclaration` (SWBD) and the **base‑change lexicon** operation class names (`declareBase`, `rebase`, `retime`, …) as canonical labels for semantic change classes.\nIt **reuses** A.6.5 SlotSpec discipline (SlotKind/ValueKind/RefMode), A.2.6 Scope discipline (`U.Scope`, explicit `Γ_time` when time matters), and A.2.4 witness semantics (`U.EvidenceRole`) as the enforcement substrate.\n",
        "problem": "### A.6.6:2 - Problem\n\nTypical failure modes this pattern is designed to eliminate:\n\n1. **Relation-kind elision.**  \n   One verb phrase is used to cover: ID-to-registry reference, claim-to-evidence admissibility, calibration-to-standard, property-to-object attribution, policy gating, etc. Rules and invariants cannot be stated because the relation family is unspecified.\n\n2. **Perspective flip (dependent-view vs base-view).**  \n   The same situation is described alternately as “X is anchored/grounded” and “Y is an anchor/ground”, with incompatible naming, hidden directionality, and silent re-typing of the ends.\n\n3. **Base–witness confusion.**  \n   Evidence, pins, certificates, or proofs are treated as “the base”, even when they are only witnesses for a base relation (or conversely: a true base is treated as a mere witness).\n\n4. **Scope/time collapse.**  \n   Based declarations are treated as timeless truths; time dependence is smuggled in via “current/latest/recently”, violating explicit `Γ_time` discipline.\n\n5. **`Γ_time` used as a proxy for freshness.**  \n   Authors treat `Γ_time` as “freshness” or “evidence decay”, collapsing TimePolicy with witness-timespan/freshness predicates.\n\n6. **Decision use without witnesses.**  \n   Declarations that gate work, publication, or assurance are asserted without a witness/pin, breaking auditability and enabling folklore.\n\n7. **Grounding conflation.**  \n   “Grounding” is used as if it were one relation, while FPF already distinguishes at least:\n   * constructive grounding of a model-edge by a trace (`tv:groundedBy`),\n   * situational/empirical grounding of an episteme via a grounding holon (C.2.1),\n   * semantic meaning assignment (SenseCell/ConceptSet lane; not a base declaration).\n\n8. **Slot/basing conflation.**  \n   A.6.5 disambiguates positions in n-ary relations (SlotKind) vs fillers (ValueKind) vs stored references (RefKind). Umbrella basing language reintroduces confusion at the next layer: “why this link exists” (BaseRelation) is missing, and slot-edit operations are conflated with base-declaration edits.\n\n9. **Anchor relapse (Context/meaning surrogate).**  \n   “Anchor/anchoring” is used to mean “the context”, “the meaning”, “the global reference”, or “the thing that makes this true”. This collapses D.CTX + SenseCell/ConceptSet lanes into a metaphor and makes review/tooling impossible.\n",
        "forces": "### A.6.6:3 - Forces\n\n| Force | Tension |\n| --- | --- |\n| **Universality vs precision** | One discipline must cover calibration, evidence linking, reference selection, attribution, gating, etc., without collapsing them into one pseudo-relation. |\n| **Minimal kernel vs decision auditability** | Few primitives are preferred, but decision-relevant declarations must carry witnesses/pins and explicit time selectors where needed. |\n| **Two perspectives, one reality** | Dependent-view and base-view must both be expressible without renaming roles or flipping meaning. |\n| **Compatibility with A.6.5** | Base declarations introduce slots and edits; they must remain SlotKind/ValueKind/RefKind disciplined and must not collapse slot edits with semantic re-declarations. |\n| **Lexical guardrails** | Without strict wording rules, umbrella metaphors will return and erase the structure. |\n| **Cross-context integrity** | When dependent and base cross Contexts or planes, the declaration must remain explicit and reviewable; no silent semantic drift. |\n",
        "solution": "### A.6.6:4 - Solution — The `U.ScopedWitnessedBaseDeclaration` object and its lexicon\n\n#### A.6.6:4.1 - Canonical object\n\n**Definition.** A **`U.ScopedWitnessedBaseDeclaration`** (SWBD) is a first-class base-declaration record *shape* (a signature in the A.6.0/A.6.5 sense): it reifies “dependent is usable relative to base via baseRelation, under scope/time, witnessed by pins”.\n\n```\nU.ScopedWitnessedBaseDeclaration ::=\n  〈 * DependentSlot     : SlotContent(VK_dep,  refMode_dep),\n    * BaseSlot          : SlotContent(VK_base, refMode_base),\n    * BaseRelationSlot  : SlotContent(U.NameToken, ByValue),     // contract-bearing token; not free text; not U.Surface*\n    * ScopeSlot         : SlotContent(U.Scope, ByValue),         // concretely: ClaimScope | WorkScope | PublicationScope\n    * GammaTimeSlot?    : SlotContent(U.GammaTimePolicy, ByValue)?,\n    * WitnessSetSlot?   : SlotContent(VK_wit,  refMode_wit)? 〉\n ```\n\nWhere:\n\n* **`DependentSlot`** is the dependent content whose admissibility/usability/interpretation is being constrained.\n* **`BaseSlot`** is the base (reference frame / target / object / standard / policy / evidence-carrier) that the dependent is declared relative to.\n* **`BaseRelationSlot`** is a **declared relation/predicate/operator token** (a vocabulary element with a signature/contract) that states the precise kind of dependence. It is not a prose metaphor and is not a `U.Surface`/publication carrier.\n* **`ScopeSlot`** is an explicit USM scope object (`U.Scope`): Claim scope (**G**), Work scope, or Publication scope.\n* **`GammaTimeSlot`** is an explicit time selector/policy when time-dependent assumptions exist.\n* **`WitnessSetSlot`** is a set of witness references/pins establishing justification or enforcement when the declaration is used for decisions.\n\n**Notation.** `SlotContent(VK, refMode)` is a compact shorthand for “a slot whose SlotSpec declares `ValueKind=VK` and `refMode ∈ {ByValue | RefKind}` (A.6.5)”.\n\n**SlotSpec note.** `VK_*` / `RK_*` / `refMode_*` above are **not** “anything goes”: they are fixed by the chosen `BaseRelationSlot` contract and must be declared as SlotSpecs (A.6.5). In other words, SWBD is a reusable *shape*, but each Context’s baseRelation family makes it a concrete, typed signature.\n\n**Instance/prose notation note (convention).** In the prose and examples below, the *occupants* are written as `dependent`, `base`, `baseRelation`, `scope`, `Γ_time`, `witnesses` (no `*Slot` suffix). The `*Slot` suffix is reserved for SlotKinds/positions only (A.6.5 / E.10).\n\n**Well-formedness constraints.**\n* **WF‑BD‑1 (No kind-elision).** A base declaration is well-formed only if `BaseRelationSlot` is present and points to a declared vocabulary element with a known signature.\n* **WF‑BD‑2 (No silent re-typing).** `DependentSlot` and `BaseSlot` type-check against the `baseRelation` contract (ValueKinds + `refMode`). If the intended endpoint kinds do not match, the repair path is explicit (Bridge / narrowing / explicit retargeting), rather than a rename.\n* **WF‑BD‑3 (Time explicit when time matters).** If the declaration’s interpretation depends on time, `GammaTimeSlot` is explicit; “latest/current” is not a substitute.\n* **WF‑BD‑4 (Decision use requires witnesses).** If the declaration is used for assurance, gating, or admissibility decisions, `WitnessSetSlot` is non-empty and resolvable.\n* **WF‑BD‑5 (Edition fence for decision/publication).** An SWBD that is cited by PublicationScope or used for decision is immutable per edition: any permitted change class is represented as a new declaration linked via explicit continuity/withdrawal, not as an in-place rewrite.\n* **WF‑BD‑6 (No silent cross-context reuse).** An SWBD that relates dependent and base across Contexts/planes (or requires scope translation) is admissible only if it cites the Bridge ids + CL policy that make the reuse admissible (F.9). No “it’s the same thing anyway” prose is an admissible substitute.\n\nThis is the discipline-level analogue of A.6.5’s move: disambiguation is achieved by making the missing structural component explicit and non-optional in decision-relevant contexts.\n\n#### A.6.6:4.2 - Underlying mathematical lens\n\nSWBD reifies a **kind-labelled dependence arrow over a base**:\n\n* a dependence edge **(dependent → base)**,\n* labelled by a declared **relation token** (`baseRelation`),\n* qualified by explicit **scope** and (when time matters) explicit **`Γ_time`**,\n* optionally supported by a **witness set** (mandatory for decision use).\n\nThis “object over a base” lens is stable across disciplines:\ncalibration is “measurement over standard”, admissibility is “claim over evidence”, attribution is “property over object”, and constructive grounding is “edge over trace”.\n\n#### A.6.6:4.3 - Slot discipline for SWBD\n\nAny signature that introduces SWBD (or SWBD-like relations) SHALL define SlotSpecs per A.6.5: every position declares **SlotKind / ValueKind / RefKind-or-ByValue**.\n\nRecommended canonical SlotKinds for SWBD:\n\n* `DependentSlot`\n* `BaseSlot`\n* `BaseRelationSlot`\n* `ScopeSlot`\n* `GammaTimeSlot`\n* `WitnessSetSlot`\n\n**Slot vs filler guard.** `*Slot` names the **position** (SlotKind), not the occupant. In prose, say “fills `BaseSlot` with …” rather than calling the base itself “a BaseSlot”. (`Slot` suffix is structural; E.10.)\n\n**Slot-level invariants (derived from WF‑BD‑1..4; testable).**\n* **Invariant (SlotSpec completeness).** In any SWBD signature, the SlotSpec for `DependentSlot` and `BaseSlot` declares admissible `ValueKind` and `refMode` explicitly (A.6.5). If those types cannot be stated, the `baseRelation` contract is not yet defined.\n* **Invariant (Relation tokenness).** `BaseRelationSlot` holds a declared `U.NameToken` that resolves to a vocabulary entry with a known signature/contract (A.6.0 + A.6.5). It is not free text and is not typed as a publication surface (`U.Surface*`).\n* **Invariant (Scope objectness).** `ScopeSlot` holds a `U.Scope` object (ClaimScope/WorkScope/PublicationScope) and is not replaced by “where it applies” prose.\n* **Invariant (Time gating).** If time-dependent assumptions exist, the SWBD includes `GammaTimeSlot` carrying a `U.GammaTimePolicy` (WF‑BD‑3).\n* **Invariant (Witness gating).** If the declaration participates in assurance/gating/admissibility decisions, the SWBD includes a non-empty, resolvable `WitnessSetSlot` (WF‑BD‑4).\n\n**Field naming guard (implementation; informative).** When materialising SWBD as a record/card, implementations SHOULD avoid naming data fields with the `*Slot` suffix. Prefer `dependentRef`, `baseRef`, `baseRelationRef`, `scope`, `gammaTime`, `witnesses` (or Context‑local equivalents). `*Slot` remains reserved for SlotKinds/SlotSpecs (A.6.5).\n\n#### A.6.6:4.4 - BaseRelation contract\n\nA `baseRelation` token is not “just a label”. For each baseRelation declared in a Context, its definition SHALL include:\n\n* **Role polarity.** Which end is dependent and which end is base (or declare symmetry explicitly).\n* **Typing expectations.** Admissible ValueKinds and `refMode` for `DependentSlot` and `BaseSlot`.\n* **Token discipline (LEX).** The token SHALL satisfy E.10 token-class morphology for relations/verbs; it SHALL NOT use metaphor heads (`Anchor*`, `Ground*`, `Attach*`) as a meaning-surrogate. If a legacy synonym exists, record it as an alias but keep the contract-bearing token specific.\n* **Repair path for mismatches.** If an endpoint’s self-kind does not match the expected ValueKind, the allowed repairs are declared (KindBridge, explicit narrowing, or explicit retargeting); “renaming the endpoint” is not a repair.\n* **Parameter placement.** Any additional qualifiers required by the relation kind (ranges, metrics, reference planes, policies) SHALL be represented either inside `scope` (preferred) or as explicit additional slots in an extended base-declaration signature; they MUST NOT be smuggled as adjectives on the endpoints.\n* **Scope class.** Whether the declaration is claim-scoped (**G**), work-scoped, or publication-scoped.\n* **Time discipline.** Whether `Γ_time` is required, optional, or forbidden for this relation kind.\n* **Witness discipline.** Whether witnesses are always required vs required only for decision use, and what witness classes are admissible (`U.EvidenceRole`, edition pins, calibration cert pins, proof artefacts, policy pins).\n* **Admissible change classes.** Which base-change operations are permitted (below) and what continuity requirements apply.\n* **Cross-context / cross-plane policy.** Whether this baseRelation family may cross Contexts/planes at all; if yes, what Bridge ids/CL thresholds must be cited and what loss notes are required (F.9 / C.3.3).\n\nThis mirrors A.6.5: a SlotKind without ValueKind/RefMode is underspecified; a baseRelation without its contract is equally underspecified.\n\n#### A.6.6:4.4.1 - Perspective/voice discipline (dependent-view vs base-view)\n\n**Normative rule.** In Tech / normative prose, authors SHALL express a based declaration in one of the following explicit forms:\n\n* `baseRelation(dependent, base)` (functional notation), or\n* `dependent --baseRelation--> base` (arrow notation).\n\nAuthors SHALL NOT use passive/umbrella voice (“X is anchored/grounded/attached”) as a substitute for an explicit `baseRelation(dependent, base)` form, because it invites direction flips and silent re-typing.\n\n**Base-view is allowed only if the polarity is preserved.** If authors use base-view wording (“B validates X”), they SHALL either (i) keep both endpoints visible using the same polarity-preserving token (e.g., `validatedBy(X,B)`), or (ii) use an explicit inverse token that is declared in the baseRelation contract. Authors SHALL NOT flip roles implicitly in prose.\n\n#### A.6.6:4.5 - Lexical discipline\n\n**Normative lexical rule.** In Tech / normative prose and Tech register naming, authors MUST NOT use umbrella metaphors (“anchor/anchoring”, “attach/attachment”, “ground/grounding”) as substitutes for an explicit `baseRelation` token.\n\n**Red-flag rule (`anchor*` as dependence metaphor).**\n* In **Tech / normative** prose: authors MUST treat `anchor*` as **prohibited** as a meaning-surrogate for an unnamed dependence kind. Authors SHALL rewrite into explicit `baseRelation(dependent, base)` form (or move to the correct reserved primitive lane).\n* In **Plain / legacy** commentary only: authors MAY quote `anchor*` as a legacy umbrella *only if* it is immediately paired with an explicit baseRelation token (e.g., “legacy ‘anchored’ ⇒ `validatedBy(...)`”) and does not introduce a new contract-bearing token.\n\n**Carve-outs (pattern-defined primitives).** This red-flag rule does **not** ban uses where “anchoring” is already a *pattern-defined primitive* elsewhere in the spec (e.g., E.10 MG‑DA “object‑of‑talk anchoring”, or A.10 evidence “anchors”). It still acts as a review trigger: confirm you are using the reserved sense, not smuggling a basedness meaning.\n\n**Naming guard for baseRelation tokens.** Do not mint new baseRelation tokens whose head noun is a metaphor (`Anchor*`, `Ground*`, `Attach*`). If you are tempted to do so, you either (i) have not named the relation kind yet, or (ii) are introducing a legacy alias that must map onto an existing, more specific relation family.\n\nInstead:\n1) Name the **BaseRelation token** (declared vocabulary element), and\n2) Use a **relation-specific verb phrase** that corresponds to that token.\n\n**Lane guard for meaning.** If the intent is “attach meaning to a term”, do not introduce a baseRelation named `Anchor…` or `Ground…`. Use SenseCell/ConceptSet discipline; semantic meaning assignment is not expressed by SWBD.\n\n**Grounding disambiguation rule.** If the prose says “grounded”, it MUST be rewritten into one of:\n* constructive grounding (`tv:groundedBy`, base is a trace),\n* situational/empirical grounding (base is a grounding holon or experimental setup),\n* meaning lane (SenseCell/ConceptSet; not SWBD).\n\n**Bind deconfliction note.** Authors MUST NOT use the verb “bind/binding” as a synonym for declaring/refreshing/changing a base declaration. “bind/binding” is reserved for **name binding** (LEX discipline). For SWBD edits, authors SHALL use the base‑change lexicon (below) instead.\n\n#### A.6.6:4.6 - Base-change operation lexicon\n\nAs A.6.5 distinguishes slot operations by whether they change a stored reference, resolve a reference, or replace a value, A.6.6 distinguishes **base declaration changes** by which component changes and what semantics are affected.\n\nOperation classes (conceptual):\n\nThese names denote **semantic change classes**. In decision/publication lanes, implementations MUST represent these changes by minting a new SWBD (new id/edition) and linking it to the prior one via explicit continuity/withdrawal (WF‑BD‑5 / CC‑BD‑10), rather than mutating the old record.\n\n1. **declareBase** — create a new base declaration with explicit `dependent`, `base`, `baseRelation`, `scope`, and, when applicable, `Γ_time`, plus witnesses when decision-relevant.\n2. **withdrawBaseDecl** — retire a declaration (or render it inapplicable by scope narrowing or time restriction, depending on baseRelation contract).\n3. **rebase** — change `base` while keeping the same `dependent` and `baseRelation` (legality depends on the baseRelation contract; often requires witness refresh).\n4. **repointDependent** — change `dependent` while keeping the same `base` and `baseRelation`.\n5. **rescope** — change `scope` (widen/narrow/translate) under the baseRelation’s scope contract; widening often triggers witness refresh.\n6. **retime** — change `Γ_time` selector/policy when time matters; not a substitute for witness-timespan/freshness predicates.\n7. **refreshWitnesses** — add/refresh witnesses/pins when decision use continues across time advances, scope widening, or evidence refresh.\n8. **changeBaseRelation** — not an edit-in-place. Changing `baseRelation` changes meaning; mint a new declaration and relate them via an explicit continuity relation (F.13 discipline), rather than silently rewriting the kind.\n\n**Relation to A.6.5 slot operations (non-normative mapping).** These are *semantic change classes*; an implementation may realise them using A.6.5 slot operations on the SWBD record fields. Example: a **rebase** may be implemented as a `retarget` of `baseRef` on a *new* SWBD edition. The point of A.6.6 is that “we retargeted a ref” is not the semantic story; “we rebased the declaration” is.\n\n**Relation to E.18 assurance ops (informative).** On `U.Transfer`, the allowed ops (`ConstrainTo/CalibrateTo/CiteEvidence/AttributeTo`) can be viewed as Context-approved specialisations of `declareBase/rescope/rebase/refreshWitnesses` for specific baseRelation families, with stricter contracts and lintability.\n\n#### A.6.6:4.7 - Disambiguation guide for selecting a baseRelation\n\nWhen a draft uses an umbrella phrase (“anchored”, “attached”, “grounded”), replace it by selecting a baseRelation family:\n\n| Colloquial intent | BaseRelation family (illustrative) | Dependent | Base | Typical witnesses |\n| --- | --- | --- | --- | --- |\n| “This ID refers to that thing” | **Identification / indexing** (`identifies`, `indexedBy`, `registeredIn`) | entity-ref / slot-content | identifier / registry entry | issuance record, registry pin |\n| “Make measurements comparable” | **Calibration / datum** (`calibratedTo`, `datumOf`, `normalisedTo`) | instrument/model/output | standard / datum | calibration work + certificate pin |\n| “This claim is admissible because …” | **Evidence admissibility** (`validatedBy`, `verifiedBy`) | claim | evidence carrier / proof | SCR/RSCR pins, proof artefacts |\n| “This edge is grounded in construction” | **Constructive grounding** (`tv:groundedBy`) | WM edge | constructor trace (`Γ_m`) | trace pins, edition pins |\n| “This description is about X under a view” | **Viewing / retargeting (specialised)** (`viewedVia`, `retargetedAlong`) | episteme/view | described entity | view operator pins, Bridge ids (if retargeting) |\n| “Allowed only under policy P” | **Constraint / policy** (`constrainedBy`, `permittedUnder`) | work-step / publication item | policy/rule | policy pin, waiver/work ref |\n| “Property belongs to object” | **Attribution / aboutness** (`attributedTo`, `aboutEntity`, `characterises`) | property/abstraction | object | observation/derivation witnesses |\n| “Meaning of this term is …” | **Meaning lane** (SenseCell/ConceptSet) | term occurrence | SenseCell/Concept row | definition/usage witnesses |\n\nThis table is illustrative; the discipline requirement is that the chosen baseRelation be explicit, declared, and contract-bearing. The “Meaning lane” row is included only as a **do-not-model-with-SWBD** reminder.\n\n*Note.* The `viewedVia` / `retargetedAlong` families are defined by the A.6.3/A.6.4 viewing/retargeting operators; this table only classifies them as “relative-to-base” cases.\n",
        "archetypal_grounding": "### A.6.6:5 - Archetypal Grounding\n\n#### A.6.6:5.1 - System archetype: calibration to a standard\n\n**Tell.** A lab instrument channel `TC‑17` is described as “anchored to ITS‑90”. Later, the reference standard is swapped, the phrase “still anchored” is kept, and the applicability window silently expands. Downstream work disagrees and nobody can reconstruct what changed.\n\n**Show.** Express it as a base declaration:\n\n```\nBD#Calib_TC17_v5 :=\n〈 dependent    = ThermocoupleChannelRef(TC-17),\nbase         = StandardRef(ITS-90 / CalStd-2025-09),\nbaseRelation = calibratedTo,\nscope        = WorkScope{rig=R3, range=[0..200]°C},\nΓ_time       = interval[2025-09-01, 2026-03-01],\nwitnesses    = { WorkRef(CalibrationRun#8841), CertRef(CalCert@edition=5) } 〉\n```\n\n**Show.** Disambiguate edits by operation class:\n\n* New standard ⇒ **rebase** + **refreshWitnesses**.\n* Wider applicability window ⇒ **retime** and likely **refreshWitnesses**.\n* Relation-kind change (“not calibration, just normalisation”) ⇒ **changeBaseRelation** is not an edit; mint a new declaration and relate via continuity.\n\n#### A.6.6:5.2 - Episteme archetype: claim admissibility via evidence relations\n\n**Tell.** A report asserts: “Model M improves accuracy by 4%.” The team says the claim is “anchored in an experiment”, but dataset version, evaluation harness, and time selector are unclear, and no resolvable evidence is linked.\n\n**Show.**\n\n```\nBD#AccGainClaim_2025Q4 :=\n〈 dependent    = ClaimRef(CG:Claim#acc_gain_4pct),\nbase         = EvidenceCarrierRef(Work:EvalRun#2025-10-12),\nbaseRelation = validatedBy,\nscope        = ClaimScope{dataset=BenchX@v3, metric=Top1, hardware=A100},\nΓ_time       = snapshot(2025-10-12),\nwitnesses    = { SCRRef(EvalLog@edition=12), ComparatorSetRef@edition=7 } 〉\n```\n\nWhat becomes explicit is not “anchoring”, but:\n* the relation kind (`validatedBy`),\n* the scope slice,\n* the time selector,\n* the witness carriers that make the declaration admissible for decision use.\n\n#### A.6.6:5.3 - Structural archetype: constructive grounding of a model edge\n\n**Tell.** A structural edge is published (“A componentOf B”) without a constructor trace. It becomes treated as “obvious”, while the construction chain is not recoverable.\n\n**Show.**\n\n```\nBD#EdgeGrounding_ComponentOf_17 :=\n〈 dependent    = WMEdgeRef(Edge:componentOf#17),\nbase         = TraceRef(Γ_m:ComposeCAL#c17),\nbaseRelation = tv:groundedBy,\nscope        = PublicationScope{view=WMCardLite, system=S, line=L3},\nΓ_time       = snapshot(2025-11-02),\nwitnesses    = { WorkRef(AssemblyRun#7712), EditionPin(Γ_m:ComposeCAL@edition=4) } 〉\n```\n\nThis example shows why “grounding” must be disambiguated: here it is a declared constructive relation with an explicit base (trace), not a vague claim of “stability”.\n",
        "bias_annotation": "### A.6.6:6 - Bias-Annotation\n\n| Lens | Bias introduced by this pattern |\n| --- | --- |\n| **Governance / assurance** | Prefers explicit witnesses and explicit time selectors for decision-relevant declarations; increases auditability but adds authoring overhead. |\n| **Architecture** | Encourages reifying “relative-to” facts as first-class records rather than implicit prose. |\n| **Onto-epistemic** | Treats “kind of base relation” as first-order; pushes authors to mint explicit baseRelation tokens instead of hiding semantics in adjectives. |\n| **Didactic** | Introduces a new stable vocabulary (“dependent/base/baseRelation”) and requires authors to maintain it consistently across views. |\n",
        "conformance_checklist": "### A.6.6:7 - Conformance Checklist\n\nA carrier (pattern, spec, schema, code artefact, or publication) conforms to A.6.6 iff:\n\n1. **CC‑BD‑1 — Base relation kind is explicit.**  \n   Every base-declaration-like statement SHALL name an explicit `baseRelation` token (a declared vocabulary element). No umbrella metaphor SHALL substitute for a relation kind.\n\n2. **CC‑BD‑2 — Dependent and base are explicit and typed.**  \n   Every based declaration SHALL make both `dependent` and `base` explicit, and SHALL be SlotKind/ValueKind/RefMode disciplined per A.6.5.\n\n3. **CC‑BD‑3 — Scope is explicit.**  \n   Every based declaration SHALL include an explicit `scope` (Claim scope (**G**) / Work scope / Publication scope).\n\n4. **CC‑BD‑4 — `Γ_time` is explicit when time matters.**  \n   If any time-dependent assumption exists, the based declaration SHALL include an explicit `Γ_time`; implicit “latest/current” SHALL NOT be used as a substitute.\n\n5. **CC‑BD‑5 — Decision use is witnessed.**  \n   If a base declaration participates in assurance, gating, or admissibility decisions, it SHALL include a non-empty, resolvable `witnesses` set (pins).\n\n6. **CC‑BD‑6 — No silent kind edits.**  \n   Changing `baseRelation` SHALL be treated as a semantic change: it SHALL be represented as a new declaration plus explicit continuity, not as an edit-in-place.\n\n7. **CC‑BD‑7 — Grounding is disambiguated.**  \n   Any use of “grounding/grounded” SHALL be disambiguated to a specific declared relation kind or moved to the meaning lane (SenseCell/ConceptSet).\n\n8. **CC‑BD‑8 — Cross-context use is explicit.**  \n   If dependent and base reside in different Contexts (or scope translation is required), the declaration’s reuse SHALL cite Bridge ids plus CL policy (no silent reuse across Contexts/planes).\n\n9. **CC‑BD‑9 — `Γ_time` is not treated as freshness.**  \n   When witness freshness/decay matters, it SHALL be expressed explicitly (evidence-role timespans, qualification windows, explicit freshness predicates), not by treating `Γ_time` as a proxy.\n\n10. **CC‑BD‑10 — Edition fence for decision/publication.**  \n   If a base declaration is used for decision or cited in PublicationScope, it SHALL be immutable per edition: updates SHALL mint a new declaration and connect it via explicit continuity/withdrawal.\n\n11. **CC‑BD‑11 — Slot suffix discipline is respected.**  \n   The `*Slot` suffix SHALL be used only for SlotKinds/positions, never for endpoint values or references.\n\n12. **CC‑BD‑12 — No “anchor” relapse.**  \n   `anchor*` / `ground*` / `attach*` SHALL NOT be used as surrogates for Context/SenseCell/ConceptSet or for an unnamed dependence kind. Authors SHALL either use the reserved primitive sense (where explicitly defined elsewhere) or rewrite into explicit `baseRelation(dependent, base)` form. Metaphor-head tokens SHALL NOT be minted as new contract-bearing `baseRelation` vocabulary entries (record them only as legacy aliases that map onto a specific, non-metaphor token).\n\n13. **CC‑BD‑13 — BaseRelation contracts are explicit.**  \n    Every `baseRelation` token used in an SWBD SHALL resolve to a vocabulary entry whose contract declares (at minimum): polarity; typing expectations (ValueKind + `refMode`) for `DependentSlot`/`BaseSlot`; admissible repair paths (KindBridge / narrowing / explicit retargeting); scope class; time discipline (`Γ_time` required/optional/forbidden); witness discipline; admissible change classes; and cross-context / cross-plane policy (Bridge ids + CL threshold + loss notes where applicable).\n\n14. **CC‑BD‑14 — Authoring voice is explicit.**  \n    In Tech / normative prose, based declarations SHALL be written as `baseRelation(dependent, base)` or `dependent --baseRelation--> base`. Base-view prose SHALL be used only if polarity is preserved via explicit inverse-token use; implicit role flips SHALL NOT be used.\n\n15. **CC‑BD‑15 — Meaning lane separation.**  \n    Semantic meaning assignment SHALL be modeled via SenseCell/ConceptSet lane constructs (E.10 D.CTX), not via SWBD. SWBD SHALL be used only for non-semantic base-dependence (admissibility, calibration, attribution, policy gating, constructive grounding, viewing/retargeting specialisations).\n\n16. **CC‑BD‑16 — Reserved “bind” discipline.**  \n    `bind/binding` SHALL be reserved for **name binding** (LEX discipline) and SHALL NOT be used as a synonym for declaring/refreshing/changing a base declaration. Authors SHALL use the base‑change lexicon (`declareBase`, `rebase`, `rescope`, `retime`, `refreshWitnesses`, …) and explicit continuity/withdrawal relations instead.\n",
        "anti_patterns": "### A.6.6:8 - Common Anti-Patterns and How to Avoid Them\n\n| Anti-pattern | Why it fails | Repair |\n| --- | --- | --- |\n| **Umbrella “anchored/attached/grounded” with no baseRelation** | Hides relation kind; cannot state invariants | Introduce a declared baseRelation token and rewrite prose to use it |\n| **Perspective flip without role names** | Directionality and typing become ambiguous | Use `dependent/base` roles consistently; declare polarity in baseRelation contract |\n| **Treating evidence as “the base”** | Confuses base with witnesses | Make evidence/pins witnesses unless the relation kind’s base is explicitly an evidence carrier |\n| **Implicit “current/latest”** | Violates explicit time discipline | Declare `Γ_time` explicitly and use witness timespans for freshness where needed |\n| **Decision gating without witnesses** | Becomes folklore; not reviewable | Add resolvable witnesses (`U.EvidenceRole`, SCR/RSCR pins, cert pins, proof artefacts) |\n| **Semantic meaning expressed as a base declaration** | Confuses meaning lane with admissibility lane | Use SenseCell/ConceptSet; keep SWBD for non-semantic basedness |\n| **Change baseRelation in place** | Semantic shift masquerades as update | Mint a new declaration and connect via continuity |\n| **Using `*Slot` to name an endpoint/value** | Confuses SlotKind with ValueKind/RefKind; breaks substitution and tooling | Keep `*Slot` for positions; use `base`/`dependent` for values and `*Ref` for stored references |\n| **Typing `baseRelation` as a `U.Surface*` carrier** | Confuses a contract-bearing relation token with a publication surface; invites “free text as relation kind” | Store `baseRelation` as a declared `NameToken` that resolves to a vocabulary entry with an explicit signature/contract |\n",
        "consequences": "### A.6.6:9 - Consequences\n\n**Benefits**\n* Disambiguation by construction: base-dependence becomes explicit via `baseRelation`.\n* Cross-domain reuse: one stable record shape works for calibration, evidence admissibility, attribution, policy gating, and constructive grounding.\n* Determinism where required: explicit scope and `Γ_time` prevent silent “latest/current” assumptions.\n* Reduced “grounding” confusion: multiple grounding senses become distinguishable relation kinds.\n\n**Trade-offs / mitigations**\n* More explicit metadata and vocabulary: mitigated by defining baseRelation families once per Context and reusing them.\n* Authoring overhead for witnesses in decision contexts: mitigated by pointing to already-existing artefacts (Work refs, pins) instead of creating new documents.\n\n**Adoption test (informative).**\nA team has adopted A.6.6 if, for any decision-relevant “relative-to” statement, it can produce a resolvable tuple\n`〈dependent, base, baseRelation, scope, Γ_time?, witnesses?〉`\nand can classify any update as one of:\n`declareBase / withdrawBaseDecl / rebase / repointDependent / rescope / retime / refreshWitnesses / changeBaseRelation`.",
        "rationale": "### A.6.6:10 - Rationale\n\n**Why focus on base declaration rather than a metaphor.**  \nThe recurring ambiguity is not “how to attach”, but “what is the declared base, and what kind of dependence is being asserted”. Naming the baseRelation token makes the dependence explicit and reviewable.\n\n**Why separate base from witnesses.**  \nBases are semantic reference frames; witnesses are justifiers/enforcers for decision use. Conflating them makes both reasoning and audit impossible.\n\n**Why include scope and `Γ_time`.**  \nA declaration is never “everywhere forever” by default in FPF. Scope makes applicability explicit; `Γ_time` prevents hidden time dependence (“recent”, “current”, “latest”).\n\n**Why prohibit kind edits.**  \nChanging the relation kind changes meaning; treating it as an update erases history and breaks continuity discipline.\n\n**Why the base-change lexicon.**  \nWithout explicit change classes, prose collapses distinct edits (rebase vs retime vs rescope vs witness refresh) and recreates the same ambiguity A.6.5 removed at the slot layer.\n",
        "sota_echoing": "### A.6.6:11 - SoTA-Echoing\n\n1. **RDF-star and statement qualification.**  \n   **Adopt/Adapt.** RDF-star/SPARQL-star continues the semantic-web tradition of attaching qualifiers/provenance to statements and edges. We adopt the “qualified statement” intuition, but adapt it by requiring an explicit relation kind token and by tying time and scope discipline to FPF’s explicit `Γ_time` and USM scopes rather than leaving them implicit or purely notational.  \n   *Primary source:* Hartig et al., “Foundations of RDF* and SPARQL*” (2017+).\n\n2. **Wikidata-style statements with qualifiers and references.**  \n   **Adopt/Adapt.** The Wikidata model popularised practical “statement + qualifiers + references” structures at scale. We adopt the separation of the core statement from its qualifiers/references, and adapt it by making decision-relevant witness requirements explicit via `U.EvidenceRole` and by requiring explicit scope/time where time-dependent assumptions exist.  \n   *Primary sources:* Wikidata statement model documentation and design lineage (post‑2015 practice).\n\n3. **Metrology traceability and calibration competence.**  \n   **Adopt/Adapt.** Laboratory competence standards treat calibration as traceability to standards with documented evidence and bounded validity. We adopt the expectation that calibration-to-standard is not timeless, and adapt it by representing the validity window via explicit `Γ_time` plus witnesses as pinned calibration artefacts.  \n   *Primary source:* ISO/IEC 17025:2017.\n\n4. **Assurance case metamodels for claim–evidence structure.**  \n   **Adopt/Adapt.** SACM formalises claim/evidence structures and emphasises structured support relations. We adopt the idea that decision-relevant admissibility links should be explicit, and adapt it by using FPF’s scope/time discipline and by treating relation-kind elision as a first-order defect.  \n   *Primary sources:* OMG Structured Assurance Case Metamodel (SACM), 2018+.\n\n5. **Objects over a base as a stable mathematical lens.**  \n   **Adopt/Adapt.** Modern category-theory texts make “objects over a base” (slice categories) a reusable pattern for “X relative to B”. We adopt that lens as the stable abstraction behind base declarations, and adapt it with explicit scope/time and witness semantics needed for engineering governance.  \n   *Primary source:* Riehl, *Category Theory in Context* (2016).\n\n**SoTA binding note (informative).** This pattern’s “qualified statement + explicit relation kind + references” move aligns with RDF*/Wikidata practice (items 1–2); the explicit time-window + witness semantics in decision use align with metrology traceability and assurance-case structures (items 3–4); the “object over a base” lens is the abstraction used to keep the pattern stable across domains (item 5).\n",
        "relations": "### A.6.6:12 - Relations\n\n**Specialises A.6.P `U.RelationalPrecisionRestorationSuite`.**\nA.6.6 is the RPR specialisation for “basedness / relative‑to” claims: it makes the relation kind explicit via `baseRelation`, qualifies it with scope/`Γ_time`/witnesses, and standardises evolution via a base‑change lexicon plus lexical red‑flags (`anchor*`).\n\n\n**Builds on A.6.5 `U.RelationSlotDiscipline`.**  \nSWBD introduces a structured record with slots; those slots must be SlotKind/ValueKind/RefKind disciplined, and its change classes must not be confused with slot-edit operations (A.6.5) or name-binding terminology (E.10 / L‑BIND).\n\n**Constrains A.10 evidence admissibility links.**  \n`verifiedBy` and `validatedBy` are treated as baseRelation tokens; their scope/time and witnesses become explicit when used for decisions.\n\n**Aligns with A.2.4 `U.EvidenceRole`.**  \nDecision-relevant witness sets should be representable as EvidenceRoles with explicit timespans and provenance discipline, not as ad‑hoc prose references.\n\n**Aligns with A.14 constructive grounding (`tv:groundedBy`).**  \nConstructive grounding is one specific baseRelation family: dependent is a model edge, base is a constructor trace; witnesses pin the trace and work artefacts.\n\n**Coordinates with C.2.1 grounding holons.**  \nSituational/empirical grounding via `GroundingHolonSlot` is treated as a distinct baseRelation family; it must not be collapsed with `tv:groundedBy` or with semantic meaning assignment.\n\n**Coordinates with A.6.3–A.6.4 viewing/retargeting.**  \nViewing and retargeting are specialised “relative-to-base” moves (preserve describedEntity vs change it along a declared bridge). They should reuse SWBD vocabulary where an explicit base declaration is required (scope/time/witness), without collapsing into generic “anchoring” prose.\n\n**Coordinates with A.2.6 and `Γ_time`.**  \nBase declarations inherit the rule that time-dependent assumptions require explicit `Γ_time`; “current/latest” is not admissible.\n\n**Feeds E.10 / F.18 lexical governance.**  \nUmbrella metaphors are disallowed as substitutes for baseRelation tokens; prose must name explicit relation kinds and keep the meaning lane separate (SenseCell/ConceptSet).\n",
        "a.6.6:end": "### A.6.6:End\n"
      },
      "content": "### A.6.6:End\n",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.6.7",
      "title": "`MechSuiteDescription` — Description of a set of distinct mechanisms",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.6.7 - `MechSuiteDescription` — Description of a set of distinct mechanisms\n\n> **Type:** Architectural pattern.\n> **Status:** Stable.\n> **Normativity:** Normative [A] (Core).\n\n**One-line summary.** A `MechSuiteDescription` is a Kernel **Description** token that names a **set of distinct** `U.Mechanism.Intension` (different mechanisms, not realizations of one mechanism) and declares **suite-level obligations**, **required contract pins**, and **allowed usage protocols**, without conflating this with `MechFamilyDescription` or with publication `Pack`s.\n\n**Plain-name.** mechanism suite description; mechanism suite passport.\n**Placement.** Part A → cluster A.IV (A.6.A), immediately after A.6.5.\n\n**Builds on.** E.8 (pattern template discipline), A.6.1 (`U.Mechanism.Intension` canonical form), A.6.5 (slot/ref discipline), E.10 (lexical + ontological rules; strict distinction; minimal specificity; kind suffixes), E.19 (conformance checks), E.18 (TGA / P2W graph discipline; crossing visibility), A.21 (OperationalGate(profile) and gate-level decisions).\n\n**Used by.** Any framework area that needs a stable “universal kernel” shared across multiple mechanisms (notably the universalization of Part G patterns, including but not limited to G.5), and any “mechanism stack” whose correctness is defined by **shared legality + transport + audit obligations** rather than by a single shared `BaseType`.\n\n**Mint vs reuse.**\n\n* **Mints:** `MechSuiteDescription` (KernelToken, Description) and the record names used by its canonical form: `MechSuiteId`, `SuiteObligation`, `SuiteObligations`, `SuiteContractPins`, `SuiteProtocol`, `ProtocolStep`, `SuiteAuditObligations`.\n* **Reuses (by reference):** `U.Mechanism.Intension` (members), `MechFamilyDescription` / `MechInstanceDescription` (optional citations), existing contract surfaces such as `CN‑Spec` / `CG‑Spec` (as pins), and E.TGA/P2W notions (as obligations/pins), without introducing new `U.*` kernel types.\n\n**LEX.TokenClass.**\n* `LEX.TokenClass(MechSuiteDescription) = KernelToken.`\n* `LEX.TokenClass(MechSuiteId) = KernelToken.`\n* `LEX.TokenClass(SuiteObligations) = KernelToken.`\n* `LEX.TokenClass(SuiteContractPins) = KernelToken.`\n* `LEX.TokenClass(SuiteProtocol) = KernelToken.`\n* `LEX.TokenClass(SuiteAuditObligations) = KernelToken.`\n\n**I/D/S.** Description (D); Tech name ends with `…Description`.\nLexical note: do **not** prefix this token with `U.` — `U.*` is reserved for Kernel **types**, while `MechSuiteDescription` is a Kernel **descriptor** (Description token).\n",
        "problem": "### A.6.7:2 - Problem\n\nWe need a Kernel-level descriptor that can:\n\n1. represent a **set of distinct mechanisms** (distinct `U.Mechanism.Intension`),\n2. declare **shared obligations** that must hold across the set (e.g., crossing visibility, legality citation discipline, guard decision format, penalty routing),\n3. provide **shared contract pins** (e.g., “this suite is contract-bound by CN‑Spec + CG‑Spec”), without duplicating those contract contents,\n4. constrain **allowed protocols** of use (allowed pipelines / permitted ordering), without turning the suite into a mechanism, and\n5. preserve strict distinction among:\n\n   * a suite of mechanisms (`MechSuiteDescription`),\n   * a family of realizations of one mechanism (`MechFamilyDescription`),\n   * a publication bundle (`Pack`, e.g., G.10).\n",
        "forces": "### A.6.7:3 - Forces\n\n1. **Strict distinction (level hygiene).**\n   *“many mechanisms”* must not be encoded as *“many realizations of one mechanism”*.\n   Violating this blurs specialization laws, SlotKind invariance expectations, and audit/crossing responsibilities.\n\n2. **Minimal specificity + kind suffix discipline (E.10).**\n   The token name should encode only what is essential: it is a description, it is about mechanisms, it is a suite.\n   It must not capture a particular domain (e.g., CHR) in the Kernel name.\n\n3. **Contract-surface centrality (CN‑Spec / CG‑Spec).**\n   Suites must cite contract surfaces as pins, not duplicate their internals, otherwise multiple competing “centers of legality” arise.\n\n4. **Transport and crossing visibility discipline.**\n   Cross-context and cross-plane steps must be visible and bridge-only; penalties must route to `R/R_eff` only; suites must not embed CL/Φ/Ψ/Φ_plane tables. Visibility is mediated via E.TGA / P2W (crossing surfaces + UTS/Path pins), not by “implicit semantics”.\n\n5. **Guard vs gate separation.**\n   Mechanisms can output tri-state guard outcomes and explanations; **gate decisions** (including `block`) and `DecisionLog` remain gate-level (`OperationalGate(profile)`). A suite must not collapse these layers.\n\n6. **FPF is conceptual.**\n   The suite is a conceptual descriptor: no implementation fields, no “lint rules”, no machine governance. The suite expresses obligations as conceptual constraints and required pins/anchors.\n",
        "solution": "### A.6.7:4 - Solution\n\nIntroduce a new Kernel description token:\n\n#### A.6.7:4.1 `MechSuiteDescription` (data model)\n\n`MechSuiteDescription` declares:\n\n1. **Suite identifier:** a stable identifier for downstream citation.\n2. **Membership:** a finite set of distinct mechanism intensions.\n3. **Suite obligations:** shared invariants that every member (and any permitted composition of members) must respect.\n4. **Suite contract pins:** required citations/pins to contract surfaces and other “anchor” references.\n5. **Suite protocols:** allowed pipelines of use (permitted ordering and optional steps), expressed at the descriptive level.\n6. **Suite audit obligations:** required audit/pin visibility for downstream uses (UTS/Path pins, crossing pins, guard pins), expressed as required anchors (not run-time values).\n7. **Notes:** didactic boundaries and anti-pattern warnings.\n\nA minimal canonical form:\n\n```\nMechSuiteId := Identifier  // PascalCase; stable citation handle. Versioning MAY be carried externally.\n\nSuiteObligation := one of {\n   * bridge_only_crossings,\n   * two_bridge_rule_for_described_entity_change,\n   * transport_declarative_only,\n   * penalties_route_to_r_eff_only,\n   * guard_decision_tristate(pass|degrade|abstain),\n   * unknown_never_coerces_to_pass,\n   * gate_decision_separation,\n   * guard_lexeme_reservations,\n   * cg_spec_cite_required_for_numeric_ops,\n   * no_silent_scalarisation_of_partial_orders,\n   * no_silent_totalisation,\n   * no_thresholds_in_suite_core,\n   * crossing_visibility_required,\n   * planned_slot_filling_in_work_planning_only,\n   * finalize_launch_values_in_work_enactment_only,\n   * implementation_export_discipline_when_cited\n  +}\n\nSuiteObligations := { SuiteObligation[*] } // clause set; duplicates-free.\n\nMechSuiteDescription := ⟨\n  mech_suite_id: MechSuiteId ,\n  mechanisms: U.Mechanism.IntensionRef[+] ,     // distinct members; references preferred\n  suite_obligations: SuiteObligations ,\n  suite_contract_pins: SuiteContractPins ,\n  suite_protocols?: SuiteProtocol[*] ,\n  suite_audit_obligations?: SuiteAuditObligations ,\n  suite_notes?: DidacticNotes\n⟩\n```\n\n**Norms.**\n\n* **Suite identifier.**\n  `mech_suite_id` MUST be present and stable: it is the citation handle for downstream planning and `U.Work.Audit`.\n\n**Well-formedness constraints (admissibility; non-deontic).**\n\n* **WF‑MS‑1 (Membership set semantics).** `mechanisms` denotes a duplicates‑free set; order carries no semantics.\n* **WF‑MS‑2 (Protocol closure).** If `suite_protocols` is present, then for every `ProtocolStep` in every `SuiteProtocol`, `step.mechanism ∈ mechanisms`.\n* **WF‑MS‑3 (Suite ≠ Pack).** `MechSuiteDescription` does not carry shipping/publication payloads; publication remains the role of `Pack` patterns.\n* **WF‑MS‑4 (Suite ≠ Mechanism).** `MechSuiteDescription` contains no `OperationAlgebra`/`LawSet`/execution semantics and is not admissible where a `U.Mechanism.*` node is required.\n\n* **Membership is by mechanism intension (order-free).**\n  `mechanisms` MUST denote a duplicates-free set of distinct `U.Mechanism.Intension` members. Membership order has no semantics; any intended ordering is expressed only in `suite_protocols`. A suite is **not** defined by a shared `BaseType`.\n\n* **No substitution by `MechFamilyDescription`.**\n  A suite MUST NOT be encoded as a `MechFamilyDescription`.\n  If desired, a suite MAY additionally **cite** `MechFamilyDescription` / `MechInstanceDescription` for particular members (e.g., “preferred realization for this context”), but such citations do not redefine membership.\n\n* **Implementation citation discipline (A.6.A-level export hygiene).**\n  If a suite cites realizations/implementations (e.g., CAL/LOG/CHR realizations of a member mechanism), such citations MUST remain referential and MUST preserve the underlying mechanism’s export/import discipline:\n  LOG/CHR realizations MUST NOT export Γ; CAL realizations MUST export exactly one Γ; and realization imports MUST remain acyclic.\n\n* **No “Pack” meaning.**\n  A suite MUST NOT be named or treated as a publication pack. `Pack` remains reserved for publication/shipping bundling (e.g., G.10).\n\n* **No mechanism semantics in the suite.**\n  A suite is a **Description**, not a mechanism: it does not define `OperationAlgebra`, it does not execute, and it does not absorb gate logic.\n\n#### A.6.7:4.2 SuiteObligations (canonical obligation vocabulary)\n\n`MechSuiteDescription` MAY declare any obligations, but the following obligation vocabulary is **canonical** and is intended to be reused across the universalization of Part G and legality-gated characterization stacks.\n\n`SuiteObligations` SHOULD be written as an explicit clause set, e.g.:\n\n```\nSuiteObligations := {\n  bridge_only_crossings,\n  two_bridge_rule_for_described_entity_change,\n  transport_declarative_only,\n  penalties_route_to_r_eff_only,\n  guard_decision_tristate(pass|degrade|abstain),\n  unknown_never_coerces_to_pass,\n  gate_decision_separation,\n  guard_lexeme_reservations,\n  cg_spec_cite_required_for_numeric_ops,\n  no_silent_scalarisation_of_partial_orders,\n  no_silent_totalisation,\n  no_thresholds_in_suite_core,\n  crossing_visibility_required,\n  planned_slot_filling_in_work_planning_only,\n  finalize_launch_values_in_work_enactment_only,\n  implementation_export_discipline_when_cited\n}\n```\n\n**Obligation meanings (normative).**\n\n1. **`bridge_only_crossings`.**\n   Well-formedness constraint: cross-context / cross-plane reuse performed by any member mechanism is represented via that member’s published `Transport` as Bridge-only (no implicit crossings). A suite does not create transport exceptions.\n\n1.1. **`two_bridge_rule_for_described_entity_change`.**\n\n * If a suite member’s lawful use requires changing the described entity (kind/identity change, `CL^k`), the crossing MUST be explicit and MUST satisfy the two-bridge rule: plane/context transfer and kind transfer are distinct, both are Bridge-mediated, and both remain penalty-routed to `R/R_eff` only.\n \n1.2. **`transport_declarative_only`.**\n * Well-formedness constraint: suite obligations do not add transfer edges or embed CL/Φ/Ψ/Φ_plane tables. Any transport-related obligation is expressed only as referenced pins/anchors whose realization is mediated by E.TGA / gate surfaces.\n \n2. **`penalties_route_to_r_eff_only`.**\n   Well-formedness constraint: CL/Φ/Ψ/Φ_plane penalties associated with crossing discipline route to `R/R_eff` only; suites do not define transport penalties that alter `F/G`.\n\n3. **`guard_decision_tristate(pass|degrade|abstain)` and `unknown_never_coerces_to_pass`.**\n   Well-formedness constraint: admissibility/eligibility outcomes use a tri-state guard result `GuardDecision := {pass|degrade|abstain}`. Unknown/insufficient evidence is not coerced to `pass`; it resolves to `{degrade|abstain}` under declared failure behavior (e.g., probe-only as a SoS‑LOG branch id, not as a new decision value).\n\n4. **`gate_decision_separation`.**\n   Well-formedness constraint: suites do not define or use `GateDecision` values (including `block`) as part of mechanism/suite semantics. Gate-level outcomes and `DecisionLog` remain on `OperationalGate(profile)`.\n\n5. **`guard_lexeme_reservations`.**\n   Well-formedness constraint: `USM.CompareGuard` and `USM.LaunchGuard` denote gate-owned guard events/pins; member mechanisms and suite protocols use `…Admissibility` / `…Eligibility` for guard predicates, not the reserved gate lexemes.\n\n6. **`cg_spec_cite_required_for_numeric_ops`.**\n   Well-formedness constraint: any member operation that performs numeric comparison/aggregation/legality-sensitive scoring cites the applicable `CG‑Spec` (and relevant subrefs) as contract pins, rather than embedding equivalent “local legality” content.\n\n7. **`no_silent_scalarisation_of_partial_orders` and `no_silent_totalisation`.**\n   Well-formedness constraint: if a member mechanism induces a partial order, it preserves set-/relation-valued semantics; it does not silently reduce to a scalar/total order. Any totalization is explicit and policy-bound.\n\n8. **`no_thresholds_in_suite_core`.**\n   Well-formedness constraint: suite core does not publish acceptance thresholds (“passing scores” / hidden cutoffs). Thresholds belong to acceptance clauses / task signatures / gate profiles.\n\n9. **`crossing_visibility_required`.**\n   Well-formedness constraint: any GateCrossing relevant to suite use publishes a `CrossingSurface` (E.18) and can be cited as an audit anchor.\n   GateCrossing includes (at minimum) cross-context, cross-plane, and cross-kind/described-entity changes, entry into `U.WorkEnactment` (LaunchGate), and any `edition_key` change of pinned `editions{…}` vectors.\n   Suites may require `CrossingSurfaceRef` / UTS / Path pins and policy-id pins as anchors, and MUST NOT embed CL/Φ/Ψ/Φ_plane tables.\n\n10. **`planned_slot_filling_in_work_planning_only`.**\n   Well-formedness constraint: any planned slot filling used as a baseline for suite use is authored in `WorkPlanning` as a planned baseline (no run-time slot instances; no launch values).\n\n11. **`finalize_launch_values_in_work_enactment_only`.**\n   Well-formedness constraint: `FinalizeLaunchValues` (and any witness of actual launch values) occurs only in `U.WorkEnactment`; neither the suite nor any planned-baseline artifact is a place for launch values.\n\n12. **`implementation_export_discipline_when_cited`.**\n* Well-formedness constraint: if a suite cites realizations/implementations, citations preserve the A.6.A export/import discipline (LOG/CHR: no Γ export; CAL: exactly one Γ; imports acyclic). This constrains citations; it does not redefine mechanism membership.\n\n#### A.6.7:4.3 SuiteContractPins\n\nA `MechSuiteDescription` MUST be able to declare required contract pins as references, not as duplicated content. Canonically:\n\n```\nSuiteContractPins := ⟨\n  required_spec_refs?: {CNSpecRef?, CGSpecRef?, ...},\n  required_edition_pins?: EditionPin[*],\n  required_policy_id_pins?: PolicyIdPin[*],\n  required_planned_baseline_ref?: PlannedBaselineRef?\n⟩\n```\n\n**Norms.**\n\n* If the suite is legality-gated for characterization, `CNSpecRef` and `CGSpecRef` MUST be required (as references/pins).\n* Contract pins are citations and anchors. They do not replace the underlying `…Spec` objects.\n* A suite MAY require the presence of a planned-baseline artifact in P2W (e.g., a WorkPlanning plan item such as `…SlotFillingsPlanItem` that pins chosen refs/editions), but MUST treat it as a **reference/pin requirement**, not as a place to store launch values or gate decisions.\n  When required, the planned-baseline artifact is authored in `WorkPlanning` and is citeable by downstream `U.Work.Audit`; any `FinalizeLaunchValues` witness remains `U.WorkEnactment`-only.\n* A suite MAY serve as `TargetSlotOwnerRef` for a planned-baseline plan item (planned slot filling owner role), but this does not make the suite a mechanism and does not create run-time slot instances.\n \n#### A.6.7:4.4 SuiteProtocols\n\nA suite MAY describe allowed protocols (pipelines) as descriptive constraints on how suite members are intended to be composed. A protocol description:\n\n* MUST name the member mechanisms it uses (explicitly; no “implicit use”),\n* MAY mark steps as optional,\n* MUST NOT introduce hidden crossings or hidden legality steps,\n* MUST treat “publish/telemetry” as an external protocol step that is realized through existing publication surfaces (e.g., Part G shipping), rather than as a hidden tail inside a mechanism.\n\nA canonical shape for protocols:\n\n```\nSuiteProtocol := ⟨\n  steps: [ ProtocolStep₁, …, ProtocolStepₙ ],\n  invariants?: ProtocolInvariant[*],\n  notes?: DidacticNotes\n⟩\n\nProtocolStep := ⟨\n  mechanism: U.Mechanism.IntensionRef,\n  operation: OperationName,\n  optionality: {required|optional},\n  requires_pins?: PinRef[*]\n⟩\n```\n\n#### A.6.7:4.5 SuiteAuditObligations\n\nA suite MAY require that downstream use provide certain audit anchors. These are **requirements**, not run-time values. A suite audit obligation MAY include:\n\n* required `UTS` + `Path` pins,\n* required crossing-surface visibility pins for any crossing relevant to suite use,\n* required presence of `USM.CompareGuard` and/or `USM.LaunchGuard` **pins** (not gate checks),\n* required declaration of guard ownership (e.g., a `GuardOwnerGateSlot` anchor),\n* required expression of guard violations as `GuardFail` events aggregated by the guard-owning gate (per `GuardOwnerGateSlot`), not as extra mechanism/suite states,\n* required policy-id pins for any degrade/sandbox/probe-only branches (SoS‑LOG branch id anchors).\n* required parity/selection-grade pins when applicable (e.g., when suite use claims parity-grade comparison/selection surfaces downstream).\n\n**Norm.** A suite must never publish a `DecisionLog` or `GateDecision`. If the suite requires guard pins, it requires their **presence** as anchors so that the gate-level owner can aggregate `GuardFail`s and decide `degrade|block` per gate profile.\n\n#### A.6.7:4.6 Examples (tell–show–show discipline)\n\n**Example 1 (conformant).** A characterization legality suite:\n\n```\nCHRMechanismSuiteDescription : MechSuiteDescription :=\n  mech_suite_id = CHRMechanismSuiteId\n  mechanisms = { UNM, UINDM, USCM, ULSAM, CPM, SelectorMechanism }\n  suite_obligations includes:\n    bridge_only_crossings,\n    penalties_route_to_r_eff_only,\n    guard_decision_tristate(pass|degrade|abstain),\n    gate_decision_separation,\n    cg_spec_cite_required_for_numeric_ops,\n    no_silent_scalarisation_of_partial_orders,\n    crossing_visibility_required,\n    planned_slot_filling_in_work_planning_only,\n    finalize_launch_values_in_work_enactment_only\n  suite_contract_pins requires: {CNSpecRef, CGSpecRef}\n  suite_protocols includes:\n    normalize → indicatorize → score → (fold_Γ?) → compare → select → publish/telemetry\n```\n\nThis description is not a `MechFamilyDescription` (because it contains multiple distinct mechanisms), and it is not a `Pack` (because it does not ship artifacts; it only declares membership and shared obligations/pins/protocols).\n\n**Example 2 (non-conformant).** Misusing a family as a suite:\n\n```\nCHRMechanismFamily : MechFamilyDescription := { UNM, UINDM, USCM, ... }\n```\n\nThis is a level error: `MechFamilyDescription` is reserved for realizations of a single mechanism intension.\n\n**Example 3 (non-conformant).** Turning a suite into a hidden gate:\n\n* The suite declares `GateDecision` values or embeds a `DecisionLog`.\n* The suite defines acceptance thresholds (“pass score ≥ 0.7”) as part of suite obligations.\n* The suite embeds Φ/CL tables or invents ad-hoc “transfer edges”.\n\nAll violate the separation between mechanism/suite descriptions and gate-level operational control.\n",
        "archetypal_grounding": "### A.6.7:5 - Archetypal Grounding\n\nA suite is an archetypal “passport” or “capability bundle descriptor”:\n\n* It answers **what mechanisms exist in the bundle** and **what shared invariants** make their composition lawful.\n* It provides **shared contract anchors** (pins) that downstream planning and work must cite.\n* It remains descriptive: it does not execute, it does not contain run-time outputs, and it does not replace the E.TGA subgraph that actually connects nodes by `Uses` and manages crossings.\n",
        "bias_annotation": "### A.6.7:6 - Bias-Annotation\n\nCommon biases this pattern guards against:\n\n* **Overloading “family”.** Treating “many different mechanisms” as “many realizations of one mechanism” destroys level hygiene and encourages semantic drift across members.\n* **Publication conflation.** Using “pack” semantics to smuggle publication/shipping obligations into the meaning of a mechanism bundle.\n* **Gate conflation.** Treating suite-level obligations as gate decisions (“block”) instead of keeping `block` at the gate layer.\n* **Convenience totalization.** Collapsing partial orders into scalars “for ease of selection”, which undermines set-return semantics and legality gating.\n",
        "conformance_checklist": "### A.6.7:7 - Conformance Checklist\n\nA `MechSuiteDescription` is conformant iff all applicable items hold:\n\n**CC‑A.6.7‑1 (Correct level).** The suite’s `mechanisms` enumerate **distinct** `U.Mechanism.Intension` members. The suite is not encoded as `MechFamilyDescription`.\n\n**CC‑A.6.7‑2 (Description token, not `U.*`).** The suite token is a Description token and MUST NOT be introduced under `U.*`. Its name ends with `…Description`.\n\n**CC‑A.6.7‑3 (No execution semantics).** The suite MUST NOT define mechanism blocks (`OperationAlgebra`, `LawSet`, etc.) and MUST NOT be used as a mechanism node.\n\n**CC‑A.6.7‑4 (No gate decisions).** The suite MUST NOT define `GateDecision`, MUST NOT publish `DecisionLog`, and MUST preserve gate/mechanism separation.\n\n**CC‑A.6.7‑5 (Contract pins, not duplication).** If the suite is legality-gated for numeric comparison/aggregation/scoring, it MUST require `CG‑Spec` citation pins (and SHOULD require `CN‑Spec` pins where applicable). It MUST NOT duplicate contract content as “local CG‑Spec”.\n\n**CC‑A.6.7‑5a (CN+CG pins for legality-gated characterization).** If the suite is legality-gated for characterization, it MUST require both `CNSpecRef` and `CGSpecRef` as pins (references), consistent with A.6.7:4.3.\n\n**CC‑A.6.7‑6 (Transport discipline preserved).** The suite MUST NOT introduce transport exceptions. Any crossing obligations must remain Bridge-only and must route penalties to `R/R_eff` only.\n\n**CC‑A.6.7‑7 (Tri-state guard discipline when used).** If the suite declares admissibility/eligibility semantics, it MUST use `GuardDecision := {pass|degrade|abstain}` and MUST NOT coerce unknown to pass.\n\n**CC‑A.6.7‑8 (No thresholds in core).** The suite MUST NOT publish acceptance thresholds or “passing scores”. Thresholds must remain in acceptance clauses / task signatures / gate profiles.\n\n**CC‑A.6.7‑9 (Crossing visibility anchors).** If suite use depends on crossings (context/plane/kind, entry into `U.WorkEnactment` (LaunchGate), or edition-key changes), the suite MUST require crossing visibility anchors (BridgeId/channel, ReferencePlane, CL mode, policy-id pins, UTS/Path pins) as audit obligations, without embedding the tables.\n\n**CC‑A.6.7‑10 (Suite id present).** The suite MUST declare `mech_suite_id: MechSuiteId` so that downstream planning/audit can cite it stably.\n\n**CC‑A.6.7‑11 (Two-bridge discipline preserved).** If suite obligations claim cross-kind/described-entity validity, they MUST require explicit `CL^k` handling (two-bridge rule) and MUST NOT allow implicit described-entity changes.\n\n**CC‑A.6.7‑12 (Implementation export hygiene when cited).** If the suite cites realizations/implementations, the citations MUST preserve export/import discipline (LOG/CHR: no Γ export; CAL: exactly one Γ; imports acyclic).\n\n**CC‑A.6.7‑13 (No Pack conflation).** The suite MUST NOT be introduced, named, or used as a publication/shipping `Pack`.\n\n**CC‑A.6.7‑14 (Protocol closure & explicitness).** If `suite_protocols` is present, every `ProtocolStep.mechanism` MUST be a member of `mechanisms` (WF‑MS‑2) and the protocol MUST NOT rely on implicit mechanism steps or implicit crossings.\n\n**CC‑A.6.7‑15 (P2W split preserved when applicable).** If the suite requires a planned-baseline pin (e.g., a planned slot-fillings artifact), that baseline MUST be a `WorkPlanning` artifact and MUST NOT contain launch values or `FinalizeLaunchValues` witnesses; such witnesses remain `U.WorkEnactment`-only.\n",
        "anti_patterns": "### A.6.7:8 - Common Anti-Patterns and How to Avoid Them\n\n1. **Anti-pattern: “Family-as-suite”.**\n   Using `MechFamilyDescription` to list multiple distinct mechanisms.\n   **Fix:** use `MechSuiteDescription` for “many mechanisms”, and keep `MechFamilyDescription` for “many realizations of one mechanism”.\n\n2. **Anti-pattern: “Pack-as-suite”.**\n   Naming/using the suite as a `Pack`.\n   **Fix:** reserve `Pack` for publication/shipping bundling; use `Suite` for mechanism bundles.\n\n3. **Anti-pattern: “Suite contains legality tables”.**\n   Duplicating CG‑Spec or embedding CL/Φ/Ψ tables in suite obligations.\n   **Fix:** publish pins and references only; keep legality content in `…Spec` and policy registries; keep crossing realization in E.TGA/gate surfaces.\n\n4. **Anti-pattern: “Suite is a hidden gate”.**\n   Introducing thresholds, `block`, or `DecisionLog` in the suite.\n   **Fix:** suite declares guard formats and required pins; the gate owns decisions.\n\n5. **Anti-pattern: “Implicit calls”.**\n   A protocol implies “normalize happens somewhere” without explicit member and pin visibility.\n   **Fix:** protocols enumerate steps and required pins; E.TGA `Uses` edges remain explicit.\n",
        "consequences": "### A.6.7:9 - Consequences\n\n**Benefits.**\n\n* Eliminates level confusion between “family of realizations” vs “bundle of mechanisms”.\n* Provides a Kernel home for universal obligations reused across multiple patterns (notably Part G universalization).\n* Makes legality/transport/audit obligations shared and explicit, reducing semantic drift across member mechanisms.\n\n**Costs.**\n\n* Introduces an additional descriptive artifact that must be maintained as suites evolve.\n* Requires discipline: suites must remain descriptive and must not become “meta-mechanisms” or “hidden gates”.\n",
        "rationale": "### A.6.7:10 - Rationale\n\nCharacterization and legality-gated selection pipelines are not unified by a single shared `BaseType`; they are unified by:\n\n* shared contract surfaces (e.g., CN‑Spec / CG‑Spec),\n* shared transport and crossing discipline (Bridge-only; penalties to `R_eff`),\n* shared guard semantics (tri-state, no coercion),\n* and explicit protocol constraints (allowed pipelines).\n\nEncoding this unity as “one mechanism” or “one family” forces false commonality and invites hidden semantics. A dedicated **suite descriptor** preserves modularity and keeps the level separation clean.\n",
        "sota_echoing": "### A.6.7:11 - SoTA-Echoing\n\nThis pattern echoes post‑2015 best practice in modular reasoning systems: separation of **contract surfaces** from **operators**, explicit composition protocols, and strong boundaries between **decision procedures** and **gating/acceptance control**.\n\nIn modern multi-step evaluation pipelines (e.g., calibrated scoring, uncertainty-aware comparison, portfolio/pareto selection, and quality-diversity archives), correctness typically relies more on explicit contracts and lawful composition than on a single monolithic “universal metric”. `MechSuiteDescription` provides the Kernel representation that allows such pipelines to be described with stable obligations while keeping domain methods and architheory generators outside the universal core.\n",
        "relations": "### A.6.7:12 - Relations\n\n* **Relates to A.6.1:** suite members are `U.Mechanism.Intension`; the suite does not replace the mechanism definition.\n* **Relates to A.6.5:** suites must not weaken slot/ref discipline; any suite protocol assumes member mechanisms follow A.6.5 invariants (SlotKind stability, correct refMode, no semantic meaning in SlotIndex).\n* **Relates to E.18 / P2W:** suite protocols describe intended composition; actual composition and crossings are expressed in E.TGA subgraphs and P2W flow.\n* **Relates to E.19:** suite-level conformance is a conceptual review checklist; suites require pins/anchors rather than procedural validation.\n* **Relates to G.10:** suites are not packs; publication/shipping is handled via G.10 and MVPK faces.\n",
        "a.6.7:end": "### A.6.7:End\n"
      },
      "content": "### A.6.7:End\n",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.6.8",
      "title": "Service Polysemy Unpacking (RPR‑SERV)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.6.8 - Service Polysemy Unpacking (RPR‑SERV)\n\n**Plain-name.** Service situation unpacking.\n**One-liner:** “service” ⇒ clause | promised work‑kind | provider principal/system | access point | access spec | commitment | promise act | delivery method/work\n\n> **Type:** Architectural (A) — A.6.P specialisation (RPR)\n> **Status:** Stable\n> **Normativity:** Normative\n> **Placement:** Part A → A.6 (Precision restoration / stack discipline)\n> **Builds on:** A.6.P (RPR recipe), A.6.5 (slot discipline), A.6.B (routing), A.2.3 (`U.ServiceClause`), A.2.8 (`U.Commitment`), A.2.9 (`U.SpeechAct`), A.15 (`U.Work`), E.10 (LEX, incl. L‑SERV, LEX‑BUNDLE & PTG stances), F.17 (UTS — Unified Term Sheet), F.18 (Name Cards / NQD‑front; promise ≠ utterance ≠ commitment).\n> **Coordinates with:** A.6.C (contract bundle unpacking), A.7 (Object≠Description≠Carrier), G.* evidence discipline (EvidenceGraph / SCR), Context/Bridge policy for cross‑Context reuse, F.8 (Mint/Reuse), E.15 (LEX‑AUTH when refactoring existing prose at scale).\n> **Delta-Class:** Δ‑3 (new normative pattern; corpus‑wide lexical refactor expected when adopted in Core)\n> **Impact radius:** Any normative prose that uses the “service” cluster (`service`, `service provider`, `server`); LEX rules (L‑SERV / LEX‑BUNDLE); UTS blocks (F.17); contract/boundary patterns that already talk about services (esp. A.6.C); any automated repair/lint pipeline used for bulk refactors (E.15 / LEX‑AUTH).\n **Mint vs reuse:** Mints the `serviceSituation(…)` QRR lens id and the facet headphrase set defined in §4.3. Reuses `U.ServiceClause` (legacy alias: `U.Service`, deprecated), `U.Commitment`, `U.SpeechAct`, `U.System`, `U.Work`, `U.MethodDescription`, and the A.6.P/QRR recipe.\n **DRR pointer:** **REQUIRED before Core admission.** `DRR‑SERV‑POLYSEMY‑<id>` (TBD in draft; must cite the PQG run + refactor/harness plan).\n\n**Intent.** Prevent category errors and metonymic drift caused by the borderline word “service” by forcing every normative mention to name the **facet** (promise content vs promised work‑kind/effect vs accountable principal vs realization system vs access object vs interface vs binding vs act vs run‑time work/evidence) and by providing a stable “service situation” lens that keeps those facets related without collapsing them.\n\n**Non‑goal (modularity guard).** This pattern does **not** redefine the semantics or field structure of the promise‑content object (the **service clause**). That kernel meaning is defined in **A.2.3 (`U.ServiceClause`)**. A.6.8 is a precision‑restoration + lexicon discipline that (i) forces facet‑typed head phrases and (ii) provides an optional QRR lens to bind already‑defined kinds without collapsing them. Contract‑talk unpacking is handled by **A.6.C**, which invokes this pattern when contract language contains the service cluster.\n",
        "problem": "### A.6.8:2 - Problem\n\nUnqualified “service” in normative prose causes **referent ambiguity** that cannot be repaired by reader intuition, because the ambiguity is structural:\n\n1. **Addressability mismatch:** you can *call/visit* an access point, but you cannot call a clause.\n2. **Type mismatch:** work/telemetry/incidents are properties of **work + carriers**, not of promise content.\n3. **Deontic mismatch:** “must/shall/guarantee” binds **actors/roles** via commitments, not abstract clauses.\n4. **Speech‑act mismatch:** “promise/offer/accept” are **events/acts**, not the promise content itself.\n5. **Evolution mismatch:** changing an API endpoint or deployment is not “changing the service” unless you declare which facet changed and narrate that change with stable change classes.\n\nResult: reviewers can’t apply A.6.B routing, and engineers are incentivized to preserve ambiguity (“service” as a convenient metonym) because it avoids committing to a model.\n",
        "forces": "### A.6.8:3 - Forces\n\n| Force                                   | Tension                                                                                                 |\n| --------------------------------------- | ------------------------------------------------------------------------------------------------------- |\n| Precision vs readability                | Always‑unpacking improves auditability, but increases wordiness.                                        |\n| Kernel minimality vs safety             | Avoid introducing new core primitives; still prevent category errors.                                   |\n| Everyday language vs normative contract | Teams naturally say “service is down”; normative text must point to *what* is down.                     |\n| Cross‑domain applicability              | Must work for microservices, human services, public services, and physical services.                    |\n| Evolution vs continuity                 | Service facets evolve at different rates; prose must narrate changes without silently shifting meaning. |\n",
        "solution": "### A.6.8:4 - Solution\n\n#### A.6.8:4.0 — UTS + LEX preparation (mandatory for authoring/repair)\n\n“Service” is a **polysemy cluster**, not a single token. Therefore, before applying the rewrite rules below to normative prose, the author/editor SHALL create or update a **thread‑local UTS block** (F.17) and its paired **LEX‑BUNDLE entries** (E.10) for the **service cluster** (Tech/Plain twins and PTG stance).\n\n**Required cluster coverage (minimum).** The UTS block MUST cover, at minimum, the co‑moving surface forms:\n\n* `service` / `services`\n* `service provider` (and the corresponding provider term in the domain: team/shop/department/vendor, etc.)\n* `server` (including “daemon”, “host”, “endpoint host” where those appear)\n* `microservice` / `microservices` (and spelling variants such as “micro-service”) **when they appear in the source prose** as a stand‑in for the addressable system facet (“the thing you can call/deploy”) or as a collapsed bundle token\n* “API service” / “service interface” / “service access” (when present in the source prose)\n* “SLA/SLO/service level” language (when present)\n\n**Context selection (universality guard).** The UTS block MUST cite **ContextName@Edition** in each SenseCell (F.17), and the cited contexts SHOULD span at least **three** distinct “service traditions” reflected in this pattern’s SoTA‑Echoing set (e.g., ITSM/service management, EA/modelling, speech‑act/coordination, microservices/SRE practice). This prevents a “FPF‑only” meaning loop and keeps facet names portable.\n\n**Headphrase governance (no ad‑hoc synonyms).**\n\n* Each facet head phrase used by this pattern (e.g., “service clause”, “service access point”) SHALL appear as a **UTS twin** (Tech/Plain) in the local UTS block, not as an author‑invented one‑off.\n* Both the **Tech** and **Plain** twin for a facet head phrase SHALL carry an explicit **head kind word** that signals the facet category (**clause / role / principal / system / access point / spec / method / commitment / act / work**). Plain synonyms are permitted only if they preserve the head kind (e.g., “endpoint” as an access‑point head kind; “API spec” as an access‑spec head kind). This is the readability guard that prevents “mathematician renamings”.\n* A conforming **normative Tech** text SHALL treat the bare word **service** (unqualified) as **PTG=Guarded** (E.10): it is allowed only under this pattern’s rewrite rules and only as part of a qualified head phrase.\n* If a new facet head phrase must be introduced, it SHALL be treated as a **LexicalAct** with an explicit **Mint/Reuse** decision (F.8), and its **CandidateSet + rationale** SHOULD be recorded via a Name Card (F.18 / NQD‑front) to avoid “clever” but unstable vocabulary.\n\nThis preparation step is intentionally “linguistic”: it binds the pattern to how engineers actually write (service/provider/server), rather than to an isolated kernel token.\n\n**SoTA binding (informative audit anchor).** The major disambiguation rules in §4.4–§4.7 are aligned with the SoTA‑Echoing rows in §11:\n* “offering / promise content” vs “delivery operations” split → ITIL 4 + EA modeling,\n* “interface/access” vs “realization/implementation” split → ArchiMate + SRE practice,\n* “promissory act” vs “promise content” split → ISO 24617‑2 dialogue acts,\n* “actuals/telemetry” vs “targets/obligations” split → SRE evidence discipline.\n(These anchors are informative; they do not assert cross‑Context identity and require Bridges when imported as terms.)\n\n#### A.6.8:4.1 — Trigger rule\n\nThis pattern applies whenever **“service”** appears in **Tech/normative prose** as a head noun (including compounds like “X service”, “the service”, “our service”, “this service”), **even when the intended referent is `U.ServiceClause`**.\n\nIt also applies to the adjacent cluster terms **“service provider”** and **“server”** when they are used as stand‑ins for the same collapsed bundle (clause/access/provider/work). The rewrite outcome for those terms is facet‑typed (see §4.3 and §4.9).\n\n**Carve‑out (informative, narrow):** quotations of external material may retain “service”, but SHALL be followed immediately by an unpacking rewrite in the surrounding normative text.\n\n#### A.6.8:4.2 — Stable lens: the Service Situation Bundle\n\nDefine a stable, kind‑labelled qualified record (hyperedge lens) that makes the bundle explicit **without introducing a new core entity kind**. This record binds already‑defined referents so prose can talk about multiple facets without collapsing them:\n\n**`serviceSituation(…)` — Qualified Relation Record (QRR) lens id**\n\nParticipant slots (principal facets). The slot names are intentionally *prose-facing* (engineer-readable): they are meant to make it hard to “silently collapse” clause/principal/system/access/work.\n\n* `serviceClauseRef : ServiceClauseRef`\n  *Promise content* — the `U.ServiceClause` referent (A.2.3; legacy alias: `U.Service`). **Plain head:** *service clause* / *service promise clause*.\n* `promisedWorkKindRef? : WorkRef`\n  The **promised work‑kind / effect‑kind** described by the clause (A.15 lens). This is *not* a concrete run; it is the “what is to be delivered” in kind‑form (template/type).\n\n  **Invariant: SERV‑INV‑1 (WorkKindness).**\n  `promisedWorkKindRef` denotes a work‑kind/template, not a concrete run/episode.\n  (If the kernel distinguishes `WorkKind` vs `WorkEpisode`, use `WorkKind`; otherwise the local UTS/LEX cell for this slot SHALL mark it as *kind‑labelled*.)\n* `providerRoleRef : RoleRef`\n  The provider **role kind** named by the clause (typically `clauseRef.providerRole`).\n* `providerAssignmentRef? : RoleAssignmentRef`\n  The concrete **role enactor assignment** that holds `providerRoleRef` in the relevant Context/window (E.10 / A.2.1). This is what everyday talk calls “the service provider” (team/shop/vendor/system).\n* `providerPrincipalRef? : EntityRef`\n  Convenience alias: the **accountable principal** extracted from `providerAssignmentRef` (when you need to name the accountable party explicitly).\n  - Normative default: commitments attach here (or to the relevant role assignment), not to the access point.\n* `consumerRoleRef? : RoleRef`\n  The consumer **role kind** named by the clause (typically `clauseRef.consumerRole`, if present).\n* `consumerAssignmentRef? : RoleAssignmentRef`\n  The concrete **role enactor** of `consumerRoleRef` (when needed for accountability/evidence narratives).\n* `accessSpecRef? : MethodDescriptionRef`\n  The **service access spec** / request‑facing interface description (API signature, OpenAPI, endpoint contract, intake SOP, desk procedure). This is typically `serviceClauseRef.accessSpec` (A.2.3) and is a `U.MethodDescription`.\n* `accessPointRef? : SystemRef`\n  The **service access point** — an addressable system/facility/desk/endpoint host through which requests arrive. In lived language this is often called “the service” or “the server”.\n* `deliverySystemRef? : SystemRef`\n  The **service delivery / realization system** that actually performs the delivery work. In software, this is usually the deployed application + dependencies (and may be behind gateways); in human services, this is the socio‑technical organisation + tooling that does the work.\n* `deliveryMethodRef? : MethodDescriptionRef`\n  The **service delivery method** / internal procedure/runbook/workflow used to fulfil the clause. This is distinct from `accessSpecRef` (request‑facing access).\n* `commitmentRef? : CommitmentRef`\n  Deontic binding to deliver the clause (required when the prose uses must/shall/guarantee/SLA force).\n* `promiseActRef? : SpeechActRef`\n  The instituting/promissory act (offer/promise/accept/agree/publish) when relevant.\n\n  **Invariant: SERV‑INV‑2 (Responsibility alignment).**\n  When the surrounding passage is normative about responsibility (D‑quadrant language), the promissory actor/authorizer of `promiseActRef` aligns with `providerPrincipalRef` (or the corresponding `providerAssignmentRef`), rather than being silently shifted to `accessPointRef`.\n* `deliveryWorkRef? : WorkRef`\n  The delivery / fulfillment work episode(s) (including incidents, runs, requests) when relevant.\n* `adjudication? : AdjudicationHooks`\n  Evidence anchors (e.g., `evidenceRefs`, `carrierRefs`) used for acceptance/breach evaluation when the passage asserts actuals.\n\nQualifier slots (as needed per A.6.P/A.6.B):\n\n* `scope? : ClaimScope`\n* `Γ_time?` (explicit Γ_time selector per A.2.6; time windows are explicit when the surrounding passage is time‑sensitive)\n* `viewpoint? : ViewpointRef`\n* `referenceScheme? / representationScheme?` (only when needed)\n\n**Guidance (didactic).** In normative prose, prefer facet‑explicit predicates: if a predicate targets a specific facet (addressability, deontic force, actuals, mechanism), apply it to the corresponding slot rather than to an untyped “service” noun phrase. (Enforced by CC‑A.6.8‑3/4/6/9.)\n\n**Agency + grounding clarifications (normative).**\n\n* The **service clause** (`serviceClauseRef`) is *promise content*; it does not act, deploy, crash, or guarantee. It can be **published** (via a carrier) and **used as payload** of a commitment.\n* The **promisor / commitment‑holder** is the **provider principal** (or its role assignment) unless the Context explicitly models a system as an agent with standing. *(See CC‑A.6.8‑8.)*\n* The **access point** and **delivery system** are typically *instruments/realizers*. The linkage to the accountable principal is expressed via an explicit relation kind (e.g., operated‑by / owned‑by / authorized‑by / fronts / routes‑to). *(See SERV‑WF‑1.)*\n\n**Well‑formedness constraint: SERV‑WF‑1 (Explicit relation typing in bundles).**\nWhen a `serviceSituation(…)` binds a principal/role assignment to systems (access point / delivery system), the relation kinds are explicit (prefer A.6.6 base relations when available). **Implicit “system implies provider” readings are invalid.**\n* Mechanism/process claims target `deliverySystemRef` and/or `deliveryMethodRef` (and sometimes `accessSpecRef` if the claim is strictly about interface signature), not `serviceClauseRef`. *(See CC‑A.6.8‑9.)*\n\n**Well‑formedness constraint: SERV‑WF‑2 (Accountable subject present when binding is asserted).**\nIf `serviceSituation(…)` includes `commitmentRef` and/or `promiseActRef`, then it also includes an accountable subject slot:\n`(commitmentRef ∨ promiseActRef) ⇒ (providerAssignmentRef ∨ providerPrincipalRef)`.\nThis prevents “floating” commitments/acts that can’t be routed to a holder/authorizer.\n\n**Facet→Kind map (didactic, normative).** The bundle exists precisely because these facets are **different kinds** and therefore admit different predicates:\n\n| Facet (slot) | Canonical FPF object | Kind family (A.7 / I‑D‑S) | Typical predicates that *belong* here |\n| --- | --- | --- | --- |\n| `serviceClauseRef` | `U.ServiceClause` | **Episteme** (promise content) | states preconditions/outcomes; defines acceptance criteria; constrains what counts as fulfilment |\n| `promisedWorkKindRef` | `U.Work` (kind‑labelled) | **Described entity / kind** (work‑kind) | is requested; is fulfilled; has outcome constraints; can be decomposed into sub‑work kinds |\n| `providerAssignmentRef` | `U.RoleAssignment` | **Role assignment** (who is accountable) | is accountable; is the provider; bears duty; is authorized to promise |\n| `providerPrincipalRef` | (derived from role assignment) | **Agent / principal** (responsible party) | holds commitments; is liable; delegates; authorizes carriers/systems |\n| `deliverySystemRef` | `U.System` | **System** (realizer) | implements/realizes; contains components; has failure modes; produces operational evidence |\n| `accessPointRef` (“server”) | `U.System` | **System** (addressable) | call/invoke/restart/down/latency |\n| `accessSpecRef` | `U.MethodDescription` | **Episteme** (interface/spec) | versioned; published; compatible |\n| `deliveryMethodRef` | `U.MethodDescription` | **Episteme** (procedure/runbook) | steps/controls; escalation; timing model; safety constraints |\n| `commitmentRef` | `U.Commitment` | **Deontic object** (binding) | must/shall/obligated; breachable; has holder and counterparty |\n| `promiseActRef` | `U.SpeechAct` | **Work event** (communicative) | promised/accepted/announced |\n| `deliveryWorkRef` | `U.Work` | **Work event** (operational) | executed; incident occurred; evidence produced |\n\n#### A.6.8:4.3 — Facet headwords (mandatory lexical rule)\n\nIn normative prose, **replace the head word “service”** with one of the following facet head phrases:\n\n1. **service clause** (or **service promise clause**) — promise content (`serviceClauseRef : ServiceClauseRef`, i.e., `U.ServiceClause`; legacy alias: `U.Service`)\n2. **promised service work‑kind** (or **promised work‑kind**) — what is promised as a kind/template (`promisedWorkKindRef`)\n3. **service provider role** — the provider role kind (`providerRoleRef : RoleRef`) when the text is about role structure (not about actuals)\n4. **service provider principal** (or **service provider (role enactor)**) — the accountable provider that can hold commitments (`providerAssignmentRef` / `providerPrincipalRef`)\n5. **service delivery system** (or **service realization system**) — the system that performs/realizes delivery (`deliverySystemRef : SystemRef`)\n6. **service access point** (or **service endpoint**) — addressable entrypoint (`accessPointRef : SystemRef`); this is the “thing you can call/visit”\n7. **service access spec** (or **service interface spec**) — request‑facing interface/method description (`accessSpecRef : MethodDescriptionRef`)\n8. **service delivery method** (or **service runbook / procedure**) — internal procedure for fulfilment (`deliveryMethodRef : MethodDescriptionRef`)\n9. **service commitment** — deontic binding (`commitmentRef : CommitmentRef`)\n10. **service promise act** (or **promissory speech act**) — speech act (`promiseActRef : SpeechActRef`)\n11. **service delivery work** (or **service run / fulfillment work**) — execution episode (`deliveryWorkRef : WorkRef`)\n\n**SERV‑LEX‑3 (Family‑name modifier + shorthand, normative).**\nThe facet head phrases above are **canonical** for RPR‑SERV. In normative prose, authors SHALL use these phrases (including the family‑name modifier **service**) as the primary surface forms for the facets.\nThe modifier **service** inside these phrases is not an “unqualified service” use and does not itself trigger further unpacking.\nFor readability, a local shorthand MAY be introduced by parenthetical declaration immediately after the canonical phrase, and then used consistently within that declared scope (for example: “service delivery system (delivery system)”). A conforming text SHALL NOT introduce multiple shorthands for the same facet, and SHALL NOT reuse a shorthand for a different facet.\nIn code identifiers, slot names (e.g., `deliverySystemRef` in `serviceSituation(…)`), and diagrams/tables, the modifier MAY be omitted without an explicit shorthand declaration, because the surrounding construct already binds the facet.\n\n**Cluster note (server/provider) — heuristics (informative).**\n* If the draft uses **server** as a synonym for “the service”, it usually denotes the **service access point** (or host system), unless the domain’s “server” is explicitly a person (e.g., restaurant).\n* If the draft uses **service provider** but then predicates deployment/restart/latency, it usually denotes a **service delivery system** or **service access point**, not an accountable principal.\n* If the draft uses **service provider** but then predicates “guarantees / obligated”, it usually denotes the **service provider principal** plus an explicit **service commitment**.\n* If a passage attributes promissory agency to a machine (“the server promises”), treat the machine as a carrier/witness unless the Context explicitly grants it standing as an agent.\n\n(Normative enforcement is via CC‑A.6.8‑1 and CC‑A.6.8‑8.)\n\n#### A.6.8:4.4 — Addressability rule (the “can you call it?” test)\n\nIf the draft sentence implies *addressability* (verbs like **call/invoke/request/visit/go to/connect to/route to/deploy/restart/scale**), then the referent MUST be a **service access point** (`accessPointRef : SystemRef`) or a **work episode** (`deliveryWorkRef`), never the service clause.\n\n#### A.6.8:4.4b — Method/mechanism rule (the “how does it work?” test)\n\nIf the draft sentence asserts or explains *how the service works* (verbs like **implement/realize/work by/uses/consists of/pipeline/algorithm/workflow/runbook/process steps**) then the referent MUST be a **service delivery system** (`deliverySystemRef`) and/or a **service delivery method** (`deliveryMethodRef`).\n\nIf the draft sentence is specifically about the **externally visible signature/shape** (endpoints, request/response schema, SOP steps visible to consumers), route it to **service access spec** (`accessSpecRef`).\n\nA conforming text **SHALL NOT** attach mechanism/process predicates to the **service clause**; the clause may constrain outcomes or acceptance criteria, but mechanism claims belong to design/method artefacts. *(See CC‑A.6.8‑9.)*\n\n#### A.6.8:4.5 — Deontic rule (the “must/shall” test)\n\nIf the sentence contains deontic force (**must/shall/guarantee/obligated/SLA**), the referent MUST include a **service commitment** slot, and the deontic language MUST attach to the commitment/holder, not to the clause or to the access point.\n\nWhen the prose needs a subject, prefer: **“the service provider principal SHALL … under commitment C”** rather than “the service SHALL …”.\n\n**No hidden agency rule (normative):** A conforming text **SHALL NOT** use an access object (e.g., endpoint/access point) as the grammatical subject of an RFC‑keyword sentence. It **SHALL** use the accountable principal (or role assignment) as subject and then state the operational condition on the access point as a predicate/evidence claim. *(See CC‑A.6.8‑4 and CC‑A.6.8‑8.)*\n\n#### A.6.8:4.6 — Speech‑act rule (the performative verb test)\n\nIf the sentence uses performatives (**promise/offer/accept/agree/commit/announce/publish**), the referent MUST include a **service promise act** (`promiseActRef`) and must not collapse the act into the clause.\n\nIf a server/webpage/API response is involved, a conforming text **SHALL** treat it as a **carrier/witness** of the promise act unless the Context explicitly grants it standing as an agent. A conforming text **SHALL** keep the promissory actor/authorizer aligned with the provider principal.\n\n#### A.6.8:4.7 — Runtime/telemetry rule (the “actuals” test)\n\nIf the sentence asserts actuals (**down/slow/99.9% last week/latency is X/incident occurred**), the claim MUST be routed to **work + carriers/evidence** (deliveryWorkRef + witnesses), not to the clause.\n\nWhen needed, also name whether the actual is about the **access point** (entrypoint symptoms) or the **delivery system** (realizer symptoms). “Down” can be about the gateway even when the backend is fine; the pattern forbids collapsing those.\n\n#### A.6.8:4.8 — Change‑class lexicon (service‑specific narrations)\n\nWhen the draft describes “service changes”, narrate changes using stable change classes (A.6.P), specialized to the serviceSituation lens:\n\n* `declareRelation(serviceSituation(…))` (introduce the bundle)\n* `withdrawRelation(serviceSituation@ed=k)` (retire the bundle)\n* `retargetParticipant(accessPointRef := …)` (move the access point / endpoint host)\n* `retargetParticipant(deliverySystemRef := …)` (change the realizing delivery system; e.g., re‑platforming)\n* `retargetParticipant(providerAssignmentRef := …)` (change provider role‑enactor; outsourcing / org change)\n* `reviseByValue(accessSpecRef := …)` (edit interface description content)\n* `reviseByValue(deliveryMethodRef := …)` (edit runbook/workflow/procedure)\n* `reviseByValue(serviceClauseRef := …)` (edit promise content; typically new edition)\n* `changeRelationKind` is not applicable here unless splitting the family (rare)\n* `rescope`, `retime(Γ_time)`, `refreshWitnesses(witnesses := …)` as required\n\n#### A.6.8:4.9 — Disambiguation guide (rewrite/selection)\n\nIf the draft says:\n\n* “**the service** is deployed/restarted/scaled/called” → rewrite as **service access point** (system) or **service delivery work** (deployment work), and (optionally) attach it to a `serviceSituation`.\n* “**the service** promises/guarantees X” → rewrite as **service clause** (promise content), and if “guarantees” is deontic, also introduce **service commitment** held by the **service provider principal**.\n* “**the service** is down/slow/has 5xx” → rewrite as **service access point** (down) and/or **service delivery work** (incident/run), with evidence.\n* “we **promised** the service” / “we **agreed** the service” → rewrite as **service promise act** + **service clause** (+ commitment if binding).\n* “**the service provider** guarantees X” → rewrite as **service provider (role enactor)** + **service commitment** (+ service clause as payload).\n* “**the server** is down / slow / restarted” → rewrite as **service access point** (server/host system) and/or delivery work, not as clause.\n* “**the service** is implemented by / realized by / works by doing Y” → rewrite as **service delivery system** and/or **service delivery method** (and keep the clause separate as the outcome constraint).\n* “**the service** API signature / endpoint schema / request format is …” → rewrite as **service access spec**.\n* “the service ticket / service request” → rewrite as **ticket** / **request work item**; “service” is adjectival legacy and must be eliminated or mapped via LEX.\n",
        "archetypal_grounding": "### A.6.8:5 - Archetypal grounding\n\n**Tell.** A “service” is not a single thing. In normative prose you MUST name which facet you mean, and (when needed) tie facets together via a `serviceSituation(…)` record so readers can follow accountability, access, deontics, and evidence without guessing.\n\n#### Show 1 — System archetype (microservices + SRE)\n\n**Draft (ambiguous):**\n“Payments service is down; the service guarantees 99.9% uptime; we will restart the service.”\n\n**Unpacked (facet‑explicit):**\n\n* “The **Payments service access point** (the Payments API ingress/endpoint host) is down.”\n* “The **Payments service delivery system** (the Payments backend realizer) is degraded (symptom attribution is explicit).”\n* “The **Payments service access spec** (e.g., OpenAPI/endpoint contract) defines the request/response interface.”\n* “The **Payments service clause** states target availability `SLO=99.9%` over `Γ_time=30d` (promise content).”\n* “The **service commitment** held by the **service provider principal** binds them to that clause.”\n* “The **service delivery work** `Incident#2025‑…` records outage evidence and the restart action; the runbook used is the **service delivery method**.”\n\n**Optional `serviceSituation` bundle (sketch):**\n\n* `serviceSituation( serviceClauseRef=PaymentsAvailabilityClause, providerRoleRef=PaymentsPlatform#ServiceProviderRole, providerPrincipalRef=PaymentsPlatformTeam, accessSpecRef=PaymentsAPIv2, accessPointRef=PaymentsAPIIngressProd, deliverySystemRef=PaymentsBackendProd, deliveryMethodRef=PaymentsIncidentRunbook@ed=…, commitmentRef=AvailabilityCommitment@ed=…, deliveryWorkRef=Incident#…, Γ_time=Rolling30d, witnesses={SLOReport#…, IncidentLog#…} )`\n\n#### Show 2 — Episteme archetype (physical/human service)\n\n**Draft (ambiguous):**\n“The auto service accepts walk‑ins and promises repair in 2 days.”\n\n**Unpacked (facet‑explicit):**\n\n* “The **service access point** is the *Auto Repair Shop front desk* (an addressable facility).”\n* “The **service access spec** is the *intake procedure* (how to request/submit a car).”\n* “The **service clause** promises ‘repair completed within 2 business days’ given stated preconditions.”\n* “The **service delivery method** is the *shop workflow* (inspection → parts ordering → repair → QA → handover).”\n* “The **service provider principal** is the shop entity that can hold a commitment (not the front desk as an access point).”\n* “If advertised as binding, introduce a **service commitment** held by the shop’s provider role.”\n* “Each repair job is **service delivery work** with evidence (work order, timestamps, acceptance sign‑off).”\n",
        "bias_annotation": "### A.6.8:6 - Bias-Annotation\n\nLenses tested: **Gov**, **Arch**, **Onto/Epist**, **Prag**, **Did**.\n\n* **Gov bias:** favors explicit accountability (provider role + commitment) and audit surfaces (witnesses); increases enforceability but raises authoring burden.\n* **Arch bias:** encourages bundle/record lenses and explicit interfaces; may feel heavyweight for informal notes.\n* **Onto/Epist bias:** strongly separates clause vs system vs work vs deontic; prevents category errors but reduces metaphor-friendly storytelling.\n* **Prag bias:** optimizes for cross-team readability and reduced rework; may require refactoring existing prose at scale.\n* **Did bias:** enforces teachable tests (“can you call it?”, “is it deontic?”, “is it actuals?”); can appear prescriptive but improves onboarding.\n",
        "conformance_checklist": "### A.6.8:7 - Conformance Checklist (CC‑A.6.8)\n\n0. **CC‑A.6.8‑0 — UTS/LEX block exists for the service cluster.**\n   Any document that applies this pattern (or that introduces normative “service” language) SHALL publish:\n   (a) a local **UTS block** (F.17), and\n   (b) paired **LEX‑BUNDLE entries** (E.10) for the Tech/Plain twins and PTG stances used here.\n   +   Minimum cluster coverage SHALL include: `service`/`services`, `service provider`, `server`, `microservice`/`microservices` **when present in the source prose**, plus the chosen facet head phrases. If the document uses “API service / service interface / service access” or SLA/SLO/service‑level language, the local UTS/LEX block SHALL include those surface forms as well.\n   Each SenseCell SHALL cite ContextName@Edition; cited contexts SHOULD not be “FPF only”.\n   Any newly introduced facet head phrase SHALL have an explicit Mint/Reuse decision (F.8) and SHOULD have a Name Card rationale (F.18).\n\n1. **CC‑A.6.8‑1 — Unqualified “service” (and cluster stand‑ins) is forbidden in normative prose.**\n   A conforming boundary/spec text SHALL NOT use **service** as an unqualified head noun, and SHALL NOT use **server** or bare **service provider** as untyped stand‑ins for the same collapsed bundle.\n   Every such occurrence SHALL be rewritten to a facet head phrase (service clause / promised work‑kind / service provider role or principal / service delivery system / service access point / service access spec / service commitment / service promise act / service delivery work) or replaced with the correct underlying FPF object (team, ticket, workflow, system, etc.).\n   The facet head phrases in §4.3 are **canonical**; using **service** as the family‑name modifier inside those phrases is permitted and does not itself trigger further unpacking. Any local shorthand that drops the modifier is allowed only under SERV‑LEX‑3.\n   *Exception:* direct quotations may retain the original surface form, but the surrounding normative prose SHALL immediately provide an unpacking rewrite.\n\n2. **CC‑A.6.8‑2 — `U.ServiceClause` is referred to as a “service clause” in prose.**\n   When the intended referent is `U.ServiceClause` (legacy alias: `U.Service`), authors SHALL use “service clause” (or “service promise clause”) as the head phrase and SHALL NOT rely on the bare word “service”.\n\n3. **CC‑A.6.8‑3 — Addressability implies `accessPointRef` (system), not clause.**\n   Any statement implying invocation/connection/deployment/restart SHALL target a service access point (`SystemRef`) and/or delivery work, never a service clause (`U.ServiceClause`).\n\n4. **CC‑A.6.8‑4 — Deontic language requires a commitment.**\n   Any normative “must/shall/guarantee/SLA” statement about service delivery SHALL introduce (or reference) a `U.Commitment` and attach the deontic force to that commitment/holder.\n   In addition, a conforming text SHALL NOT use a service access point / server as the grammatical subject of an RFC‑keyword sentence; the subject is the accountable provider principal (or role assignment), with access‑point conditions stated as predicates/evidence.\n\n5. **CC‑A.6.8‑5 — Performative verbs require a speech act.**\n   Any statement using “promise/offer/accept/agree/announce/publish” about the service SHALL reference a `U.SpeechAct` (promise act) and SHALL NOT collapse it into the clause.\n\n6. **CC‑A.6.8‑6 — Actuals require work + evidence.**\n   Any claim about runtime state/telemetry/incidents SHALL be routed to `U.Work` plus carrier/evidence references; it SHALL NOT be stated as a property of the service clause.\n\n7. **CC‑A.6.8‑7 — Bundle lens is used when multiple facets are in play.**\n   When a passage simultaneously discusses two or more facets (e.g., clause + endpoint + SLA + incident), the author SHOULD provide a `serviceSituation(…)` record (or equivalent explicit slot binding) so readers can track the linkage without guesswork.\n   When a `serviceSituation(…)` record is provided, it SHALL satisfy SERV‑INV‑1, SERV‑INV‑2, and SERV‑WF‑1 from §4.2.\n   When a `serviceSituation(…)` record is provided and it includes `commitmentRef` and/or `promiseActRef`, it SHALL also satisfy SERV‑WF‑2.\n\n8. **CC‑A.6.8‑8 — Commitments and promises have an accountable principal.**\n   Any statement that introduces a **service commitment** or **service promise act** SHALL name (directly or via role assignment) the **service provider principal** who is the holder/authorizer. A conforming text SHALL NOT attribute commitments/promises to a bare access point/server unless the Context explicitly models it as an agent with standing (and that modelling is declared).\n\n9. **CC‑A.6.8‑9 — “How it works” claims route to method/system, not to the clause.**\n   Any statement about implementation, mechanism, workflow, runbook, or process SHALL target **service delivery system** and/or **service delivery method** (or **access spec** if it is strictly interface‑signature). It SHALL NOT be stated as a property of the service clause.\n",
        "anti_patterns": "### A.6.8:8 - Common Anti-Patterns and How to Avoid Them\n\n* **Anti‑pattern:** “The service is deployed on Kubernetes.”\n  **Fix:** “The **service access point** (deployment) is deployed on Kubernetes.”\n\n* **Anti‑pattern:** “The service guarantees X.”\n  **Fix:** “The **service clause** states target X; the **service commitment** guarantees X.”\n\n* **Anti‑pattern:** “The service provider guarantees X.”\n  **Fix:** “The **service provider (role enactor)** holds a **service commitment** that guarantees X; the **service clause** is the promise content.”\n\n* **Anti‑pattern:** “The server provides the service (as if server=promise).”\n  **Fix:** “The **service access point** (server/host system) provides access; the **service clause** is promise content; any ‘must/shall’ binds via **service commitment**.”\n\n* **Anti‑pattern:** “The service works by doing Y / is implemented with Z.”\n  **Fix:** “The **service delivery system** works by doing Y / is implemented with Z; the **service delivery method** (runbook/workflow) is …; the **service clause** constrains outcomes/acceptance.”\n\n* **Anti‑pattern:** “We promised the service.”\n  **Fix:** “We performed a **service promise act** that published the **service clause** (and instituted a commitment if binding).”\n\n* **Anti‑pattern:** “Service is down (therefore contract violated).”\n  **Fix:** “The **service access point** is down (actual). Contract breach evaluation is a separate claim comparing actuals (work/evidence) to the clause + commitment.”\n\n* **Anti‑pattern:** “Service and API are used interchangeably.”\n  **Fix:** Use **service access spec** for the API description; use **service access point** for the addressable system; use **service clause** for promise content.\n",
        "consequences": "### A.6.8:9 - Consequences\n\n* **Pros:**\n\n  * Removes the incentive to keep “service” conveniently vague.\n  * Enables A.6.B routing: clause (L), commitment (D), acts/work/evidence (E), mechanisms/interfaces (A/L depending on placement).\n  * Makes incident/SLO/SLA discourse structurally sound and reviewable.\n\n* **Cons:**\n\n  * Increases verbosity and requires refactoring existing prose.\n  * Requires authors to learn (and consistently apply) facet headwords.\n\n**Adoption test (1 minute).**\nAfter refactoring any normative section that contains ≥ 10 occurrences of the “service” cluster, you can answer “yes” to all of:\n1) Unqualified head‑noun “service” occurrences in normative prose are **0** (CC‑A.6.8‑1).\n2) Every deontic (“must/shall/guarantee/SLA”) sentence about service delivery references a **service commitment** / `U.Commitment` (CC‑A.6.8‑4).\n3) Every runtime/telemetry “service is down/slow/…” claim is routed to **work + evidence** and, when relevant, distinguishes access‑point symptoms from delivery‑system symptoms (CC‑A.6.8‑6 + §4.7).\n",
        "rationale": "### A.6.8:10 - Rationale\n\nThe ambiguity here is not a simple synonym problem; it is a **bundle‑collapse problem**. “Service” routinely stands in for different ontological categories (episteme content, system, event, deontic binding). Since the word is too entrenched to ban entirely, the least‑surprising stable repair is:\n\n* keep “service” only as a *family name* in informal discussion, but\n* in normative prose always name the **facet** and, when needed, explicitly bind facets via a stable bundle lens.\n\nThis aligns with A.6.P’s requirement to replace umbrella tokens with explicit kind+slots forms and to provide rewrite guides and guardrails.\n",
        "sota_echoing": "### A.6.8:11 - SoTA-Echoing\n\n> **Informative.** Alignment notes; not normative requirements. This section is written to satisfy the SoTA‑Echo obligations for Architectural patterns (post‑2015, multi‑Tradition; adopt/adapt/reject with reasons).\n\n**Bridge hygiene note.** This section makes **no cross‑Context identity claims** (no implicit “same thing across traditions”). If a later edit wants cross‑Context reuse of terms or structures from external traditions, it must be mediated by explicit Bridges with declared CL (and plane policy where relevant), per the general SoTA/Bridge discipline.\n\n| Tradition (Context) | What this pattern uses | Stance | Primary sources (post‑2015) | Notes / divergence |\n|---|---|---|---|---|\n| IT service management (ITSM) | Separates promise/value proposition (“offering”) from delivery/operations talk; motivates forcing facet headwords instead of letting “service” float. | Adapt | ITIL 4 Foundation (AXELOS, 2019) | FPF diverges by treating bare “service” as an always‑unpack token in **normative** prose, because ITSM vocabulary is intentionally managerial and polysemous. |\n| Enterprise architecture modeling | Distinguishes “service” from “interface” and from “realization/implementation”; motivates the access‑spec vs access‑point vs delivery‑system split. | Adopt/Adapt | The Open Group ArchiMate® 3.1 Specification (2019) | FPF adapts the split by making **promise content** (`U.Service`) explicit as “service clause” and by making “addressability” a first‑class disambiguation test. |\n| Dialogue‑act / speech‑act operationalization | Treats promissory moves as explicit act types; motivates separating promise‑act from promise‑content. | Adopt | ISO 24617‑2:2020 (Dialogue Act Annotation) | FPF diverges by requiring that binding effects are represented as explicit `U.Commitment` objects rather than being inferred from the act alone. |\n| SRE / modern operations practice | Keeps interface specs, SLO targets, deployments/endpoints, and incident evidence as separate artefact families; motivates the “actuals → work+evidence” rule and the “access point vs delivery system” split. | Adopt/Adapt | *Site Reliability Engineering* (Beyer et al., 2016); *The Site Reliability Workbook* (Beyer et al., 2018) | FPF adapts SRE practice by routing deontics to commitments (D) and keeping telemetry/incidents as evidence (E), rather than letting “SLO/SLA” prose collapse into the word “service”. |\n\n**Pack binding (status).** No dedicated SoTA Synthesis Pack is cited here yet for the “service polysemy” cluster; if/when such a pack is published, this section SHOULD be updated to cite the relevant ClaimSheet IDs / CorpusLedger entries (and Bridge ids where reuse is asserted) as the auditable anchors for the alignment statements above.\n",
        "relations": "### A.6.8:12 - Relations\n\n* **Specialises:** A.6.P (RPR) for the lexical/semantic ambiguity cluster around “service”.\n* **Operationalises + extends:** the lexical disambiguation intent of L‑SERV by making “service” **always‑unpack** in normative prose (and by expanding the cluster to include *service provider* and *server* as co‑moving stand‑ins).\n* **Requires (authoring discipline):** a local UTS block (F.17) and published Tech/Plain twins (E.10) for the service/provider/server cluster; this is the “anti‑FPF‑only loop” guard.\n* **Coordinates with:** A.6.C (contract bundle unpacking). When contract-language includes *service* tokens, apply RPR‑SERV first to select **service clause** vs **commitment** vs **access point/system** vs **work/evidence**, then route the resulting atomic statements through A.6.C → A.6.B (L/A/D/E).\n* **Enables:** safe deprecation of the legacy kind name `U.Service` in favour of `U.ServiceClause`, because normative prose is already forced to use the facet head phrase **service clause** (not bare “service”).\n",
        "a.6.8:end": "### A.6.8:End\n"
      },
      "content": "### A.6.8:End\n",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.6.S",
      "title": "U.SignatureEngineeringPair - Signature engineering via a ConstructorSignature and a TargetSignature",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.6.S - U.SignatureEngineeringPair - Signature engineering via a ConstructorSignature and a TargetSignature\n\n> **Type:** Architectural (A)\n> **Status:** Stable\n> **Normativity:** Mixed (normative where RFC 2119 keywords appear; quadrant routing is governed by A.6.B)\n> **One-liner:** **explicitly modelling signature engineering as a two‑signature arrangement** (TargetSignature + ConstructorSignature), with strict separation between **operator description** and **enactment as Work by transformer Systems**.\n",
        "a.6.s:0___pcp_term/lex_token_guards_(local_first)": "### A.6.S:0 - PCP-TERM/LEX token guards (local-first)\n\nThis pattern reserves the following tokens on Tech (normative) surfaces:\n\n* **TargetSignature** — the engineered signature episteme (and its editions) under construction/stabilisation (**not** the described entity, and **not** a Bridge “target Context”).\n* **ConstructorSignature** — the enabling signature that describes constructor operations for TargetSignature evolution (do **not** mint a second Tech token such as `EnablingSignature`).\n\nRename-guards (common collisions):\n\n* **enabling** — Plain adjective meaning “producing/maintaining the TargetSignature”; it is not a `U.*` token.\n* **constructor** — MUST be disambiguated as one of: `ConstructorSignature` (episteme), `constructor op` (EFEM), or `constructor System`/`enactor` (transformer). If the physics term is intended, spell **“Constructor Theory”** explicitly.\n* **target** — avoid bare “target” in Tech clauses; use `TargetSignature` or qualify the target (e.g., “Bridge target Context”, “target holon”).\n* **contract** — Plain shorthand for “published boundary interface description”; it MUST NOT be read as a promise/obligation. Promises, duties, and gates route via A.6.B.\n",
        "problem": "### A.6.S:2 - Problem\n\nFPF needs a pattern for **engineering signatures as boundary artifacts**: a disciplined way to construct, revise, and publish a target `U.Signature` from partial input, while maintaining:\n\n* separation between *signature* and *mechanism* (A.6.0 vs A.6.1),\n* separation between *laws*, *admissibility*, *deontics*, and *work evidence* (A.6.B),\n* explicit multi‑view publication without semantic drift (E.17),\n* reproducible evolution across editions without silent mutation.\n",
        "forces": "### A.6.S:3 - Forces\n\n* **Stability vs evolution.** Boundary contracts must be stable enough to coordinate, yet change as understanding improves.\n* **Explicitness vs overhead.** Unpacking slots/bases/views increases clarity but also increases authoring effort.\n* **Effect‑free operators vs enacted work.** The construction/change language should be expressible as effect‑free epistemic morphisms (no measurement/actuation),\n  yet the act of applying them to artifacts is still Work done by transformer Systems and must be auditable.\n* **Multi‑view richness vs semantic coherence.** Views help stakeholders, but they risk becoming divergent “versions of truth”.\n* **Local meaning vs cross‑context reuse.** Signatures should keep meaning local to a context; reuse across contexts requires explicit bridges and declared loss/penalty policy.\n* **Contract talk vs ontology.** “Contract” language invites mixing promises, norms, and invariants; FPF requires quadrant discipline.\n* **No epistemic agency.** It is tempting to phrase “the ConstructorSignature constructs…”. In FPF, only Systems act; epistemes do not.\n",
        "solution": "### A.6.S:4 - Solution — two signatures and a small constructor vocabulary\n\n#### A.6.S:4.0 - Ontology and effect profile — constructor operators are epistemes; enactment is Work by transformer Systems\n\nThis pattern relies on **Strict Distinction** (A.7) and the **transformer quartet** (A.3):\n\n* **ConstructorSignature (operator description; intensional, D/S-plane).**\n  The ConstructorSignature is an **Episteme** (typically a Description/Spec) that *describes* a small family of constructor operations for signature evolution.\n  The ConstructorSignature SHALL specify each constructor operation family as an instance/species of `U.EffectFreeEpistemicMorphing` (EFEM; A.6.2) or a declared sub‑species (e.g., A.6.3/A.6.4): **episteme→episteme** morphisms over the `C.2.1 U.EpistemeSlotGraph` positions (`ClaimGraphSlot`, `DescribedEntitySlot`, `GroundingHolonSlot`, `ViewpointSlot`, `ViewSlot`, `ReferenceSchemeSlot`) plus attached meta/edition fields.\n  As EFEM, constructor ops are **effect‑free** in the strict A.6.2 sense: **no Work, no Mechanism application, and no mutation of systems or carriers**.\n  Concretely: an EFEM step *derives* a successor episteme (often a new edition) and its structured delta; the physical act of materialising that successor on carriers (files, repos, registries, releases, SCR/RSCR pins) is **Work** enacted by a transformer System.\n\n  Slot discipline alignment requirement (A.6.5 / C.2.1:7.1): a conforming ConstructorSignature SHALL state (for each constructor operator family) which `C.2.1` slots it may read and which it may write, expressed in SlotKind/ValueKind/RefKind terms, and SHALL declare whether the operator family is a species of A.6.2 / A.6.3 / A.6.4.\n\n* **Enactor (capability) vs enactment (world-contact).**\n  A **System** in a transformer role bears a **Method** that realises the constructor operations (A.3), and it enacts particular steps as **Work / WorkEnactment** on carriers (repos, releases, pins, SCR/RSCR references).\n  This is where traces, review records, evidence bindings, and publication artifacts appear.\n\nTherefore:\n\n* A ConstructorSignature **describes** how a TargetSignature may be constructed/evolved; it MUST NOT be written as if it *performs* the construction.\n* Any step that performs measurements, actuation, validation runs, or other side‑effects is **not** an EFEM; model it as Work/Mechanism and route resulting claims via A.6.B.\n\n#### A.6.S:4.1 - Core move: model signature engineering as a separate boundary\n\nIn a conforming design, model **two signatures**:\n\n1. **TargetSignature.**\n   The *target* boundary contract you want to stabilize. It is a `U.Signature` per A.6.0: `SubjectBlock`, `Vocabulary`, `Laws`, `Applicability`. It does **not** contain admissibility gates, deontic obligations, or evidence claims (those are routed per A.6.B).\n\n2. **ConstructorSignature.**\n   A *separate* `U.Signature` whose purpose is to describe the **engineering operations** used to construct and evolve the SoI. Intuitively: it is the “interface” of the enabling activity that produces the target interface.\n\nA.6.S names this pairing discipline **U.SignatureEngineeringPair**: a signature engineering arrangement where a ConstructorSignature is explicitly defined for (at least) one Signature‑of‑Interest.\nA.6.S names this pairing discipline **U.SignatureEngineeringPair**: a signature engineering arrangement where a ConstructorSignature is explicitly defined for (at least) one TargetSignature.\n\nMinimal definition (informative): a `U.SignatureEngineeringPair` binds exactly two signature artifacts in the same Context: a **TargetSignature** (the contract under stabilization) and a **ConstructorSignature** (the enabling signature describing the constructor operations used to build/evolve the TargetSignature).\n\n**Terminology note (C.2.1 alignment + twin discipline).**\nThis pattern uses `TargetSignature` as the **Tech role label** for “the signature artifact under construction / stabilisation”.\nIf a Context wants an explanatory alias, it MAY use **“signature of interest (SoI)”** as a **Plain twin** for `TargetSignature`, but Plain twins are didactic only and MUST NOT appear in conformance/acceptance clauses.\n\nDo not conflate:\n* the **TargetSignature** (an episteme artifact that is engineered and published), with\n* the TargetSignature’s **`DescribedEntitySlot`** (C.2.1), which refers to the boundary/entity the signature is *about* (a.k.a. “object‑of‑talk / entity‑of‑interest / describedEntity” in C.2.1 commentary).\n\nIn C.2.1 terms:\n* the TargetSignature is the **episteme** (and its editions) that we engineer and publish;\n* the TargetSignature’s `DescribedEntitySlot` refers to the **entity‑of‑interest / object‑of‑talk** (the boundary in the world or model);\n* the TargetSignature’s `GroundingHolonSlot` anchors where/how that boundary description is grounded.\n\nIf the “SoI” phrasing risks confusion with C.2.1 “entity‑of‑interest” talk, keep it out of Tech/normative prose and use **TargetSignature** vs **ConstructorSignature** consistently.\n\n**Mint-or-Reuse note (informative).**\nThis pattern introduces the following **Tech role labels** in the A.6 cluster:\n* **TargetSignature** — the target boundary contract episteme being stabilised;\n* **ConstructorSignature** — the enabling signature (episteme) describing constructor operations for TargetSignature evolution;\n* **U.SignatureEngineeringPair** — the two‑signature arrangement (TargetSignature + ConstructorSignature).\n\nIf any Plain twins are used (e.g., “signature of interest”), they MUST follow the E.10/F.* twin discipline (1:1 mapping per Context, registry entry, and no use on normative surfaces).\n\nThe intended shape is:\n\n* TargetSignature is the boundary contract used by downstream design and realization work.\n* ConstructorSignature is the boundary contract used by authors/reviewers to produce and revise the SoI in a disciplined, reproducible way.\n\nThis directly operationalises the idea already hinted in the A.6 cluster relations: A.6.5 and A.6.6 can be read as constructor/enabling operations for building well‑formed signatures. The new step is to **bundle those operations into an explicit ConstructorSignature** rather than leaving them as implicit editorial practice.\n\n#### A.6.S:4.2 - Minimal constructor operation vocabulary\n\nA conforming ConstructorSignature **SHALL** (conceptually) expose a *small, composable* set of operations. At minimum, include two groups of constructor operations, drawn from existing A.6 subpatterns:\n\n**(A) Slot‑level constructor operations** (from A.6.5)\n\nUse the canonical slot verbs to express “what changed” without ambiguity:\n\n* `bind` / `rebind` (Identifier → SlotKind/slot‑instance; name binding only)\n* `fill`\n* `initialize` (first fill)\n* `assign` / `set` / `write` / `update` (subsequent fill; by‑value replacement)\n* `retarget` (Ref slot update; same SlotKind/ValueKind)\n* `substitute` (typed replacement with explicit compatibility claim)\n* `resolve` / `dereference` (Ref → referent)\n* `pass` (parameter filling at call boundaries)\n\n**Avoid “mutate” as a generic edit verb.**\nIn Core, `mutate/modify` denotes **referent‑internal change while the slot‑content (Ref handle) stays the same**.\nIn edition‑disciplined contexts, prefer “revise / re‑edition + retarget” rather than “mutate”.\n\nGuidance for naming (by slot qualifier) is inherited from A.6.5: e.g., `Edit<SlotQualifier>` for by‑value changes, `Retarget<SlotQualifier>` for ref changes, and avoid collapsing retargeting into generic “editing”.\n\n**(B) Base‑level constructor operations** (from A.6.6)\n\nMake base declarations and their evolution explicit via base‑change verbs such as:\n\n* `declareBase`\n* `withdrawBaseDecl`\n* `rebase`\n* `repointDependent`\n* `rescope`\n* `retime`\n* `refreshWitnesses`\n* `changeBaseRelation`\n\nA ConstructorSignature does not need *all* of these in every use, but it must provide enough to express “what changed” when the SoI’s grounding base, scope, or anchoring assumptions shift.\n\n**Witness refresh note.**\n`refreshWitnesses` is an **edit of witness bindings**, not the generation of new evidence: producing/collecting new witness carriers is **Work**; `refreshWitnesses` only updates the base declaration to reference them.\n\n**Optional but common: view construction operations (A.6.3)**\n\nIf the TargetSignature is published via MVPK (recommended), include constructor operations that produce views as **EpistemicViewing** (A.6.3) of the TargetSignature:\n\n* “Emit MVPK faces” as views (PlainView, TechCard, InteropCard, AssuranceLane), explicitly treated as views and governed by E.17 “no new semantics”.\n  In particular:\n  * `PlainView` / `TechCard` / `InteropCard` MUST add no new claims beyond the underlying TargetSignature/Mechanism claim set.\n  * `AssuranceLane` MAY include procedural adjudication guidance and carrier pointers, but any normative pass/fail criteria MUST live canonically in `E-*` claims and be cited by ID.\n\nThese are best modeled as view‑producing operations whose output is an MVPK face, with the explicit constraint that the face is a view and therefore does not introduce new claims about the described entity.\nPublishing those faces (commits, releases, registry writes) is Work on carriers; it is not “the signature doing things”.\n\n#### A.6.S:4.3 - Change discipline: Viewing vs Retargeting vs editing\n\nTo connect signature engineering to A.6.2–A.6.6, treat changes in four buckets:\n\n1. **Viewing (A.6.3).**\n   Use when you change *presentation* (views, stakeholder cards, projections) while preserving the described entity.\n\n2. **Slot/base construction edits (A.6.5 / A.6.6).**\n   Use when you unpack and make explicit what was implicit (slot kinds, ref modes, base declarations), or when you adjust the SoI’s internal structure without changing what it is “about”.\n\n3. **Editioning + reference retargeting (A.6.5).**\n   Use when the contract meaningfully changes and you need a **new SoI edition** for downstream coordination. In that case, do not silently mutate the existing edition: mint a successor edition and **retarget references** (`Retarget<…>` in the relevant Ref slots) to the new edition.\n\n4. **Epistemic retargeting / Structural reinterpretation (A.6.4; rarer).**\n   Use only when `DescribedEntityRef` itself changes under an explicit `KindBridge` and stated invariants (e.g., reinterpretation across kinds/planes). This is distinct from ordinary “new version of the same contract”.\n\nRule of thumb:\n\n* If the change can be defended as “same contract, clearer surface”, prefer slot/base construction plus viewing.\n* If the change is “new contract version for consumers”, require a new edition plus explicit reference retargeting.\n* If the change is “different described entity / different kind”, use A.6.4 retargeting under `KindBridge` with explicit invariants.\n\n**EFEM discipline.**\nEvery constructor operation family declared as an EFEM MUST declare `describedEntityChangeMode ∈ {preserve, retarget}` (A.6.2).\n**Editioning is orthogonal**: you MAY mint a new edition even under `preserve`, but if you do, downstream references MUST be updated explicitly via slot discipline (A.6.5).\nAny operation that performs measurements/actuation/side‑effects MUST be modeled as Work/Mechanism, not as a constructor op.\n\n#### A.6.S:4.4 - Publication and claim discipline for reproducibility\n\nA conforming signature engineering arrangement **SHOULD** include two publication‑adjacent constraints:\n\n1. **MVPK publication for the TargetSignature (E.17).**\n   Publish the TargetSignature through MVPK faces as `U.View` projections with viewpoint accountability (`viewRef` + `viewpointRef`). Each face must be explicitly treated as a view and must not introduce new semantic commitments beyond the underlying signature/mechanism claim set (per E.17 “no new semantics”).\n\n2. **Claim Register for boundary discipline (A.6.B).**\n   Maintain a claim register that assigns stable identifiers to atomic claims and routes them into the correct quadrant (L/A/D/E). The engineering benefit is that changes to the SoI can be tracked as changes to specific claims rather than as unstructured prose diffs.\n\nThis keeps signature engineering aligned with A.6.B’s separation:\n\n* **Laws** live in the SoI (L‑claims).\n* **Admissibility** and operational gate conditions live in mechanisms (A‑claims).\n* **Deontics** are about agents (D‑claims), not about epistemes.\n* **Evidence/work effects** are recorded as outcomes of work (E‑claims), not smuggled into signatures.\n\n#### A.6.S:4.5 - Construction flow as a transduction graph fragment (informative)\n\nIf a team already models workflows as E.TGA transduction graphs, the “constructor graph” of A.6.S is a special case:\n\n* EFEM constructor steps can be represented as `U.Transduction(kind=Signature)` vertices (A.6.0), because they are intensional episteme→episteme morphisms (A.6.2).\n* Concrete carrier writes (commits, releases, registry writes, SCR/RSCR pinning) are `U.Transduction(kind=Work)` / `U.WorkEnactment` vertices (world‑contact).\n* Validations/admission checks live at `U.Transduction(kind=Check)` nodes realised as `OperationalGate(profile)` with a `DecisionLog`.\n* Any `DescribedEntityRef`/kind change is a `StructuralReinterpretation` vertex (E.TGA’s use of A.6.4), with explicit `KindBridge` + invariants/witnesses.\n\nThis mapping is optional; A.6.S stays usable as a lightweight discipline even without adopting E.TGA structure.\n\n#### A.6.S:4.6 - State during construction (informative)\n\nDo not mint a new kernel “signature state” unless you need it.\nIn most cases, use:\n\n* **edition** + explicit continuity/withdrawal links for semantic evolution, and\n* a coarse **status** (`Draft`/`Review`/`Stable`/`Deprecated`) for process signalling.\n\nIf a Context needs a finer lifecycle (e.g., “proposed → reviewed → published → frozen”), model it as Work policy in the ConstructorSignature’s Applicability or as a Context‑local workflow episteme; keep the TargetSignature semantics unchanged.\nWhere lifecycle is normative, prefer expressing it as a **role-state graph** (A.2.1) borne by the relevant episteme role, rather than minting a new core “signature state”.\n",
        "archetypal_grounding": "### A.6.S:5 - Archetypal Grounding — Tell–Show–Show\n\n**Tell.** A boundary contract becomes stable and evolvable when you model both the *target signature* and the *engineering signature* that constructs it, and you force every change to be expressed as either (a) a view, (b) a disciplined slot/base construction step, or (c) an explicit retargeting to a new edition.\n\n#### A.6.S:5.1 - Show — System archetype\n\n**Context.** A payments microservice exposes an external boundary used by multiple client systems.\n\n**Half‑signature input (what arrives).**\n“Service binds a `User` to a `PaymentMethod`, anchors charges to the `Ledger`, and guarantees idempotency.”\n\n**Constructed artifacts.**\n\n* **TargetSignature:** `PaymentBoundarySignature`\n\n  * **Vocabulary:** operations like `Authorize`, `Charge`, `Refund`; slots made explicit (e.g., `UserRefSlot`, `PaymentMethodRefSlot`, `LedgerEntryRefSlot`).\n  * **Laws (examples):** “Charge is idempotent under IdempotencyKey”; “Refund does not increase net balance”.\n  * **Applicability:** bounded context = “Payments”, scope = “External API”.\n\n* **ConstructorSignature:** `PaymentSignatureEngineering`\n\n  * Transformer system (enactor): `PaymentSignatureEngineeringPipeline` (team + repo + linters + review protocol).\n    It enacts the constructor operations as Work and produces new editions and publication carriers.\n\n  * Slot operations used (as operator descriptions; enacted via Work):\n\n    * `bind/rebind` to bind API field names (e.g., `userId`, `paymentMethodId`) to SlotKinds (`UserRefSlot`, `PaymentMethodRefSlot`) where a language surface exists,\n    * `initialize` / `edit<…>` to introduce SlotSpecs and to by‑value edit Vocabulary/Laws in the TargetSignature,\n    * `resolve<…>` to disambiguate overloaded prose markers (e.g., “idempotency”) into explicit SlotKinds + laws,\n    * `retarget<LedgerRefSlot>` when switching the referenced ledger holon/edition (ref change, not by‑value editing).\n  * Base operations used:\n\n    * `declareBase` to ground “Ledger” via an explicit baseRelation and scope,\n    * `rescope` when moving from “internal ledger view” to “external client view”,\n    * `refreshWitnesses` when decision‑relevant evidence/pins must be updated for continued use.\n\n* **Publication.**\n  MVPK faces published as views of the TargetSignature: a PlainView for non‑specialists, a TechCard for implementers, and an InteropCard for integrators, all derived without adding new claims beyond the canonical claim set.\n\n**What A.6.S prevents here.** The phrase “guarantees idempotency” does not silently become a deontic promise or an operational gate. It becomes: (a) an L‑claim (law) in the SoI; (b) if needed, a mechanism‑level admissibility condition for when the guarantee holds; and (c) evidence claims in work logs when validated.\n\n#### A.6.S:5.2 - Show — Episteme archetype\n\n**Context.** A research group publishes a “signature” for a boundary concept used across multiple theories (a common “interface” between models).\n\n**Half‑signature input.**\n“We define correspondence between model A and model B; parameters are anchored to a reference dataset.”\n\n**Constructed artifacts.**\n\n* **TargetSignature:** `ModelCorrespondenceSignature`\n\n  * **Vocabulary:** relation `Corresponds(A_model, B_model, Φ_bridge)` with explicit slot kinds and ref/value modes.\n  * **Laws:** invariants about correspondence preservation (“observable X is preserved up to tolerance ε”).\n  * **Applicability:** bounded context = “Model alignment”.\n\n* **ConstructorSignature:** `CorrespondenceSignatureEngineering`\n\n  * Transformer system (enactor): `CorrespondenceSignatureWorkbench` (authors + toolchain) enacts constructor ops as Work.\n\n  * Slot operations used: `resolve` to unpack “correspondence” into an explicit bridge slot; `edit<Laws>` (by‑value) to make tolerance explicit; `retarget<ModelRefSlot>` when moving from a draft model edition to a published edition.\n* Base operations used: `declareBase` to ground “reference dataset” as an explicit base with scope/time policy; `retime` when updating the reference window.\n\n* **Publication.**\n  The SoI is published in multiple viewpoints (e.g., a mathematical view and an engineering view). Differences are handled as views, not as semantic drift.\n\n**What A.6.S prevents here.** “Anchored to a dataset” does not remain a vague metaphor. It becomes a declared base and, when the dataset changes, an explicit base‑change operation rather than a silent reinterpretation.\n",
        "bias_annotation": "### A.6.S:6 - Bias-Annotation\n\nLenses tested: **Gov**, **Arch**, **Onto/Epist**, **Prag**, **Did**. Scope: **Universal** for signature engineering within the A.6 cluster.\n\n* **Architecture bias (Arch):** pushing a two‑signature structure can feel heavy for small boundaries.\n  *Mitigation:* keep the ConstructorSignature minimal; reuse A.6.5/A.6.6 verb sets; treat views as optional unless publication demands them.\n\n* **Onto/Epist bias (Onto/Epist):** treating “editing the signature” as harmless can hide semantic change.\n  *Mitigation:* use the Viewing vs Retargeting rule; material meaning changes become explicit retargetings.\n\n* **Pragmatic bias (Prag):** increasing discipline may slow down exploratory work.\n  *Mitigation:* allow lightweight ConstructorSignatures early, and tighten conformance as assurance requirements rise.\n",
        "conformance_checklist": "### A.6.S:7 - Conformance Checklist\n\n|             ID | Requirement                                                                                                                                                                                                                                                               | Purpose                                                               |\n| -------------: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------- |\n| **CC‑A.6.S‑1** | A conforming boundary description **SHALL** identify a **TargetSignature** and (when the boundary is being actively constructed or evolved) a **ConstructorSignature** that describes how the TargetSignature is produced and revised.                                     | Prevents conflating the target contract with the engineering process. |\n| **CC‑A.6.S‑2** | The ConstructorSignature **SHALL** use (or explicitly map to) the canonical **slot operation verbs** from A.6.5 and the **base‑change lexicon** from A.6.6 (`declareBase`, `rebase`, `rescope`, `retime`, …). It **MUST NOT** use umbrella metaphors (e.g., `anchor*`) or “bind/binding” as substitutes for explicit baseRelation/base‑change talk, and it **MUST NOT** collapse distinct meanings (e.g., using “edit” for both by‑value updates and ref retargeting). Context‑specific shorthands MAY exist, but they MUST have an explicit mapping entry to the canonical verb classes and be registered per LEX discipline. | Keeps change semantics explicit and reviewable.                       |\n| **CC‑A.6.S‑3** | Any TargetSignature change that alters contract meaning **SHALL** mint a **new TargetSignature edition** and downstream references **SHALL** be updated via explicit **ref retargeting** (A.6.5), not by silent in‑place mutation. Use A.6.4 retargeting only when `DescribedEntityRef` changes under a `KindBridge`. | Makes semantic evolution explicit without confusing editioning with described‑entity retargeting. |\n| **CC‑A.6.S‑4** | If MVPK is used, each published face (`U.View`) **SHALL** be constructed as a **view** of the canonical routed claim set and **MUST NOT** introduce new semantic commitments. `AssuranceLane` MAY add procedural adjudication guidance and evidence pointers, but any normative criteria MUST live in canonical `E-*` claims and be cited by ID. | Prevents “multiple contracts” emerging from views.                    |\n| **CC‑A.6.S‑5** | Claims about laws, admissibility, deontics, and work evidence **SHALL** be routed using A.6.B’s quadrant discipline and (where used) recorded with stable claim IDs in a claim register.                                                                                  | Prevents quadrant mixing and “contract soup”.                         |\n| **CC‑A.6.S‑6** | The TargetSignature **SHALL NOT** contain operational gate predicates or deontic obligations; such constraints belong to mechanisms and agent norms respectively (A.6.1, A.6.B).                                                                                         | Preserves the signature/mechanism boundary.                           |\n| **CC‑A.6.S‑7** | Constructor operations described by the ConstructorSignature **SHALL** be expressible as **effect‑free epistemic morphisms** (A.6.2). For each EFEM constructor operation family, the ConstructorSignature **MUST** declare `describedEntityChangeMode` and the `C.2.1` slot read/write profile. Any step that performs measurements, actuation, validation runs, or other side‑effects **MUST** be modeled as Work/Mechanism and cannot be a constructor op. | Prevents smuggling mechanisms/work into “signature editing”.          |\n| **CC‑A.6.S‑8** | Any concrete change to a TargetSignature edition or its MVPK faces **SHALL** be represented as Work enacted by a transformer System (A.3/A.12); normative text **MUST NOT** ascribe agency to epistemes (“the signature constructs/validates itself”).              | Aligns with “no epistemic agency” and the external transformer principle. |\n",
        "a.6.s:8___common_anti‑patterns_and_how_to_avoid_them_—_failure_modes": "### A.6.S:8 - Common Anti‑Patterns and How to Avoid Them — Failure Modes\n\n| Anti-pattern                                    | Symptom                                                                                                   | Why it fails                                                                | How to avoid / repair                                                                       |\n| ----------------------------------------------- | --------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------- |\n| **One artifact tries to be contract + process** | The same doc mixes “what the interface is” with “how we built it”, reviewer notes, and operational gates. | Collapses SoI and ConstructorSignature; quadrant mixing becomes inevitable. | Split into SoI + ConstructorSignature; route gates to mechanisms; route duties to deontics. |\n| **Silent semantic edits**                       | A law or applicability quietly changes; consumers discover it through breakage.                           | Treats a new contract as the same contract.                                 | Require retargeting to a new SoI edition for semantic changes.                              |\n| **Retargeting disguised as “editing”**          | Ref changes and by‑value edits are described with the same verb.                                          | Loses the slot discipline stratification and review clarity.                | Use A.6.5 canonical verbs and `Edit<SlotQualifier>` vs `Retarget<SlotQualifier>`.           |\n| **Views become “alternative truths”**           | PlainView says one thing, TechCard says another, and nobody knows which is canonical.                     | A view gained semantics rather than projecting them.                        | Treat MVPK faces as viewings; put canonical semantics in the SoI and reference it.          |\n| **Contract talk without quadrant discipline**   | “The interface promises…” is used to state invariants, obligations, and entry conditions interchangeably. | Blends laws, deontics, admissibility, and evidence.                         | Use A.6.B tags and claim register entries; rewrite claims into the proper quadrant.         |\n| **Episteme‑as‑actor**                           | Text says “the ConstructorSignature builds/validates/publishes the SoI”.                                 | Violates “no epistemic agency”; hides the transformer System and the Work.  | Rewrite: constructor ops are described by epistemes; enactment is Work by a transformer System; publish traces/pins explicitly. |\n",
        "consequences": "### A.6.S:9 - Consequences\n\n| Benefits                                                                                                                                | Trade-offs / Mitigations                                                                                                                             |\n| --------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **Reproducible signature evolution.** Changes are expressed as explicit constructor operations and, when needed, explicit retargeting.  | **More artifacts.** You now maintain two signatures. *Mitigation:* keep ConstructorSignature minimal; treat it as a thin “change vocabulary” early.  |\n| **Boundary discipline becomes teachable.** Reviewers can ask “which constructor op happened here?” instead of arguing over prose diffs. | **Upfront cost.** Slot/base unpacking requires attention. *Mitigation:* reuse A.6.5/A.6.6 templates and canonical verbs.                             |\n| **Cleaner separation of concerns.** Signatures stay free of gates and obligations; mechanisms and norms stay explicit.                  | **Temptation to over‑formalize.** Some contexts do not need deep formality. *Mitigation:* apply assurance‑appropriate depth; keep views lightweight. |\n| **Multi‑view publication stays coherent.** Views are projections, not semantic forks.                                                   | **Discipline enforcement needed.** Without review habits, teams regress. *Mitigation:* make CC items part of boundary review checklists.             |\n\n**Adoption test (informative).** A Context is “A.6.S‑ready” when, for every TargetSignature change, reviewers can point to (i) the constructor verb(s) used (A.6.5/A.6.6), (ii) the EFEM metadata (`describedEntityChangeMode`, slot read/write profile), and (iii) the Work artefacts that enacted publication (A.3/A.12).\n",
        "rationale": "### A.6.S:10 - Rationale\n\nThe two‑signature move mirrors a recurring engineering insight: stable interfaces often require an explicit description of the *enabling* interface that produces and maintains them. Without this, “engineering the contract” happens implicitly, and the project loses semantic accountability.\n\nA.6.S treats A.6.5 and A.6.6 as *constructor primitives* and makes them explicit in a ConstructorSignature. This yields a compositional change language: reviewers reason about a boundary’s evolution as sequences of named operations, instead of reverse‑engineering intent from prose.\n\nConnecting signature engineering to A.6.2–A.6.4 provides a principled way to separate:\n\n* **Viewing**: change the view, keep the described entity.\n* **Construction edits**: unpack structure without silently changing meaning.\n* **Retargeting**: acknowledge a new contract and make the transition explicit.\n\nFinally, routing claims through A.6.B makes “contract” talk ontologically safe: laws, gates, norms, and evidence stop competing for the same paragraph.\n\n**SoTA binding note (informative).** The separation between an operation surface and its effectful realization is adopted from modern algebraic effects/handlers; the view/viewpoint responsibility discipline is adapted from ISO/IEC/IEEE 42010; and the “preservation under change” intuition is adapted from categorical optics (see A.6.S:11).\n",
        "sota_echoing": "### A.6.S:11 - SoTA-Echoing\n\n* **Adopt: algebraic effects and effect systems separate operation signatures from handler semantics.**\n  Contemporary effect systems emphasise that an operation surface can be described independently of how effects are handled. A.6.S adopts the same separation at the signature‑engineering level: the SoI remains the conceptual boundary surface, while construction work and operational enforcement are handled elsewhere (mechanisms, realizations, work evidence). This echoes row‑typed algebraic effects and modern handler formulations (Leijen 2017; Hillerström & Lindley 2018).\n\n* **Adapt: categorical optics treat “focus” and “round‑trip laws” as a disciplined interface for bidirectional structure.**\n  Optics offer a compact mathematical language for “what is preserved” under a transformation and when updates are coherent. A.6.S adapts this mindset to boundary evolution: viewing corresponds to projection, and retargeting corresponds to an explicit transition with stated preservation claims. Profunctor optics provide a post‑2015 reference point for this style of interface reasoning (Pickering, Gibbons & Wu 2017).\n\n* **Adapt: architecture description standards formalise viewpoint/view responsibility and reduce semantic drift across representations.**\n  ISO/IEC/IEEE 42010 treats views as products of viewpoints, with explicit stakeholder concerns and responsibility. A.6.S adapts that discipline to signature publication: MVPK faces are explicit views derived from the SoI, and the ConstructorSignature makes “how we got this view” part of the engineering surface (ISO/IEC/IEEE 42010:2022).\n\n* **Adopt in spirit: behavioural protocol disciplines treat boundaries as safe interaction contracts.**\n  Session and behavioural type practice treats boundaries as protocols with progress and safety properties, which matches the A.6 split between signature laws and mechanism entry gates. A.6.S does not import tooling or typechecking, but it adopts the practice of making boundary interactions explicit and law‑governed (e.g., modern MPST practice as cited in A.6.1).\n",
        "relations": "### A.6.S:12 - Relations\n\n* **Depends on:**\n\n  * A.3 — Transformer quartet (MethodDescription / Method / Work / WorkEnactment separation)\n  * A.7 — Strict Distinction (object ≠ description ≠ carrier; Face ≠ Surface)\n  * A.6 — Signature Stack & Boundary Discipline\n  * A.6.0 — `U.Signature`\n  * A.6.2 — `U.EffectFreeEpistemicMorphing` (constructor ops are EFEM species)\n  * A.12 — Transformer role (enactment is by Systems, not epistemes)\n  * C.2.1 — Episteme slots (`DescribedEntitySlot`, `ViewpointSlot`, `ViewSlot`) and naming deconfliction\n  * (optional) E.18 — E.TGA, if the constructor flow is represented as a transduction graph fragment\n  * E.10 / LEX discipline — if the Context uses Plain twins (“SoI”) or shorthands, they must be registered and kept off normative surfaces\n  * A.6.3 — `U.EpistemicViewing`\n  * A.6.4 — `U.EpistemicRetargeting`\n  * A.6.5 — `U.RelationSlotDiscipline`\n  * A.6.6 — `U.AnchorAndBaseDiscipline`\n  * A.6.B — Boundary Norm Square & Claim Register discipline\n  * E.17 / E.17.0 — MVPK and multi‑view describing\n\n* **Strengthens:** A.6.5 and A.6.6 by making their operation vocabularies first‑class as constructor operations.\n\n* **Constrains:** Any signature evolution narrative: semantic changes must be explicit new editions + reference retargeting; publication faces must be viewings.\n\n#### A.6.S:12.1 - Integration pointers (informative)\n\nGrounding pointers in the current FPF draft (for alignment while integrating):\n\n* Canonical pattern template order and section requirements (E.8).\n* SoTA‑Echoing requirements and avoidance of data governance/tool binding (E.8:11, E.8:8).\n* A.6 cluster explicitly treats A.6.5/A.6.6 as constructor/enabling operations (motivation for A.6.S).\n* A.6.2 “effect‑free episteme morphisms” boundary (constructor ops are EFEM; work/mechanisms are separate).\n* A.3 transformer quartet (MethodDescription vs Method vs Work) for “constructor described vs enacted”.\n* A.7 strict distinction and Face/Surface separation (no object–description–carrier soup).\n* A.12 external transformer / transformer role discipline (enactment is by Systems; no epistemic agency).\n* Slot operation lexicon and naming guidance (A.6.5).\n* Base‑change operation lexicon (A.6.6).\n* MVPK faces as fixed view kinds with “no new semantics” intent (E.17).\n* Claim register and quadrant separation discipline (A.6.B).\n",
        "a.6.s:end": "### A.6.S:End\n\n# Cluster A.V - Constitutional Principles of the Kernel\n"
      },
      "content": "### A.6.S:End\n\n# Cluster A.V - Constitutional Principles of the Kernel\n",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.7",
      "title": "Strict Distinction (Clarity Lattice)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.7 - Strict Distinction (Clarity Lattice)\n",
        "intent": "### A.7:1 - Intent\n\nProvide a **single, didactically clear lattice of distinctions** that keeps models free from category errors. This pattern is the guard‑rail that prevents four recurrent confusions:\n\n1. **Role vs Function** (mask vs behaviour),\n2. **MethodDescription vs Method vs Work** (description vs capability vs occurrence),\n3. **Holon vs System vs Episteme** (what can act and what cannot),\n4. **Episteme vs Carrier** (knowledge vs its material signs).\n\nIt harmonizes A.12 (External Transformer), A.13 (Agential Role & Agency Spectrum), A.14 (Advanced Mereology), and A.15 (Role–Method–Work Alignment).\n",
        "problem": "### A.7:3 - Problem\n\nWhen documents blur the above lines, three classes of defects appear:\n\n1. **Category collapse.** People write “function/role/process” interchangeably; teams then disagree whether they are changing a plan, a capability, or reporting an actual occurrence.\n2. **Agency misplacement.** Epistemes (documents, models) are treated as doers; collectives as raw sets; or a “holon” is used where **only a system** makes sense.\n3. **Audit failures.** A MethodDescription is cited as if it were evidence; or Work has no anchors (no carriers, no time span), making trust impossible (B.3).\n",
        "forces": "### A.7:4 - Forces\n\n| Force                                        | Tension                                                                                                                             |\n| -------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------- |\n| **Didactic brevity vs conceptual precision** | Teams want short words (“process”, “function”) ↔ the framework must keep five distinct layers apart.                                || **Universality vs domain idioms**            | We support engineering idioms (procedure, SOP, algorithm, workflow) ↔ internally we must map them unambiguously.                    |\n| **Parsimony vs completeness**                | Minimal concept set ↔ enough distinctions to avoid the classic traps (role/function; plan/capability/occurrence; episteme/carrier). |\n",
        "solution": "### A.7:5 - Solution — The **Clarity Lattice** (normative distinctions & safe vocabulary)\n\n#### A.7:5.1 - **Terminology (normative): orthogonal characteristics**\n• **senseFamily** — the categorical characteristic, used by F.7/F.8/F.9: {Role | Status | Measurement | Type‑structure | Method | Execution}. Rows must be **sense‑uniform**. \n• **ReferencePlane** — the referent mode per CHR: {world/external | conceptual | epistemic}. \n• **I/D/S layer** — the Intension/Description/Specification layer (E.10.D2). Not an I/D/S “plane” or \"stance\", and not a bare \"layer\".\n• **DesignRunTag** — the design vs run DesignRunTag. Not a temporal “plane” or \"layer\", and not a bare \"stance\".\n• **PublicationSurface** — the *didactic projection* of a Description/Specification into a **bundle of views** (ISO 42010 sense). **Surfaces are not the thing described**. Under L‑SURF, Core allows only **PublicationSurface** and **InteropSurface** tokens; faces SHALL be named **…View / …Card / …Lane** rather than inventing new `…Surface` kinds. The canonical didactic set for architectural patterns in FPF is:\n  {**PlainView** (explanatory prose), **TechCard** (typed cards/IDs), **NormsCard** (TechCard profile for checklists/SHALL‑clauses), **AssuranceLane** (evidence bindings/lanes)}. *Surfaces are orthogonal to I/D/S and to design/run.*\n• **Typed describing/formalising morphisms (I→D, D→S)** — total morphisms that *project* along I/D/S (they are **not** mechanisms):\n  `Describe_ID : I → D` (describe an intensional object into the world of descriptions; historical alias `Publ_ID`) and\n  `Specify_DS`/`Formalize_DS : D → S` (refine a description into a specification). Composition `Describe_IS := Specify_DS ∘ Describe_ID : I → S` is allowed but both stages MUST remain visible and auditable.\n  **Laws (normative):** (ID‑1) *Non‑extensibility of content*; (ID‑2) *Identity & meaning‑preserving composition*; (DS‑1) *Monotonic refinement* under ≤₍ref₎; (DS‑2) *Pin editions & measurable anchors* per **MM‑CHR** (C.16) via **CHR‑Pins**; (DS‑3) *No retro‑effects*.\n\nA.7 establishes the following **pairs and triplets**. Use their **names** and **scope** exactly as below.\n\n#### A.7:5.2 - Role vs Function (behaviour)\n\n* **Role (role‑object, mask).** A contextual **position** a holon can bear (A.2, A.15). A role is **not behaviour**; it is the **mask** under which behaviour may be enacted. Example: **Cooling‑CirculatorRole** in a thermal loop.\n* **Function = behaviour = Method under a role.** What a **system** actually does **when bearing a role**. In Transformer context, this behaviour is the **Method** (design‑time capability) that can be executed as **Work** (run‑time).\n\n  * Safe rewrite for earlier “Holonic Duality (Substance ⧧ Function)”: **Holonic Duality (Substance ⧧ Role).** A `U.System` keeps its identity (substance) while **switching roles**; each role may entail a **Method** (behaviour) and its possible **Work** (occurrence).\n\n**Normative guard:** Use “**Role**” for the mask; use “**Method/Work**” for behaviour/occurrence. Do **not** call the role itself a function.\n\n#### A.7:5.3 - MethodDescription vs Method vs Work (design vs capability vs occurrence)\n\n* **MethodDescription** — the **description** (algorithm / SOP / recipe / script) at design‑time. Anchored via **SCR** (A.10).\n* **Method** — the **order‑sensitive capability** the **system bearing TransformerRole** can enact, composed with **Γ\\_method** (B.1.5). A Method is a **timeless semantic capability**; **concrete values** are **bound at `U.Work` creation**. Outside executions we **refer to it via MethodDescription** (see A.3.1 CC‑A3.1‑5/‑9; A.15 §2.2, §4.1). \n* **Work** — the **dated run‑time occurrence** (what actually happened), with resource spend (Γ\\_work) and temporal coverage (Γ\\_time).\n\n**Normative guard:** Never use MethodDescription as evidence of Work; never present Method as if it had happened.\n\n#### A.7:5.4 - Holon vs System vs Episteme (who can act)\n\n* **System** — the only holon kind that can **bear behavioural roles** and enact **Method/Work**.\n* **Episteme** — **cannot act**; it is **changed via its carriers** by a system. Epistemes **may bear non‑behavioural roles** (e.g., **ReferenceRole**, **ConstraintSourceRole**).\n* **Holon** — umbrella term; **do not** use it where only **system** is meaningful (e.g., “holon bearing TransformerRole” is **invalid**; write “**system bearing TransformerRole**”).\n\n**Normative guard:** Behavioural roles (including TransformerRole) have **domain = system**. Epistemes may bear purely **classificatory** roles only.\n\n#### A.7:5.5 - Episteme vs Symbol Carrier (SCR/RSCR)\n\n* **Episteme** — the knowledge content (claim, model, requirement set).\n* **Symbol Carrier** — the physical/digital sign that carries the episteme (file, volume, dataset item), tracked in **SCR**; remote sets in **RSCR**.\n* **Use:** Evidence, provenance, and reproducibility address **carriers**; arguments and validity address **epistemes**.\n\n**Normative guard:** When you say “we updated the spec”, detail **which carriers** changed (A.10).\n\n#### A.7:5.6 - Collective vs Set, and MemberOf vs Component/Constituent/Portion/Phase (A.14)\n\n* **Set / Collection (MemberOf)** — **mathematical or catalog** grouping; **no joint behaviour** implied.\n* **Collective System** — a **system** with boundary and coordination Method (e.g., a team).\n* **Use relations correctly:**\n\n  * **ComponentOf** — mechanical/structural part in systems.\n  * **ConstituentOf** — logical/content part in epistemes.\n  * **PortionOf** — quantitative portion with conserved extensives.\n  * **PhaseOf** — temporal part/state across a continuous identity.\n  * **RoleBearerOf** — a **system** is the **bearer** of a **Role**.\n\n**Normative guard:** If the grouping is expected to **act**, model a **collective system** (not a set) and provide its role and Method/Work.\n\n#### A.7:5.7 - Operator alignment (names you MUST use)\n\n* **Γ\\_sys** — composition of **system** properties (physical/systemic).\n* **Γ\\_method** — composition of **Method** (order, branching).\n* **Γ\\_time** — composition of **Work** histories and temporal parts.\n* **Γ\\_work** — composition of **resource spend** and yields tied to Work. Do not track costs with Γ\\_method; costs (resources/yield) belong to Γ\\_work.\n\n**Normative guard:** Avoid generic “process” for these operators. Reserve “process” for domain idioms; map internally to **Method** (design) and **Work** (run).\n\n#### A.7:5.8 - I/D/S vs PublicationSurface (orthogonal, normative)\n* **I/D/S governs the model.** What the thing *is* vs how it is *described/tested* lives in I/D/S (E.10.D2).\n* **PublicationSurface governs the didactic projection.** How D/S are **presented** lives on **PublicationSurface/InteropSurface** only; concrete faces SHALL be **PlainView / TechCard / InteropCard / AssuranceLane**. Cards/views are **conceptual views over D/S**, not the intensional object **and not symbol carriers**; physical/digital **carriers** stay in **SCR/RSCR** (A.10).\n* **Surface field pins.** When D/S are shown on **TechCard**, pin the minimal **CHR‑Pins** = {**UnitType**, **ScaleKind**, **ReferencePlane**, **EditionId**}. \n* **Bridge routing.** Cross‑Context or cross‑plane reuse **MUST** cite **Bridge id + CL**; **Φ(CL)**/**Φ_plane** penalties route to **R (trust)** only; **F/G invariant**. \n\n#### A.7:5.9 - Typed describing/formalising morphisms (I→D→S, normative)\n\n**What `Describe_ID` / `Specify_DS` mean in A.7.** For any intensional object `X ∈ I`, *describing X* is the morphism application `Describe_ID(X) : D` (historical alias `Publ_ID(X)` in earlier drafts); *formalising that description* is `Specify_DS(Describe_ID(X)) : S` (alias `Formalize_DS`). The collapsed arrow `Describe_IS(X)` MAY be referenced, but **implementations SHALL expose and audit both steps**.\n\n**Invariants (restate of the A.6.2/A.6.3 laws, audit‑oriented):**\n1. **Non‑extensibility (ID‑1).** `Describe_ID` MUST NOT introduce new epistemic commitments. If a claim `c` is absent in `X`, it is absent in `Describe_ID(X)`; any added structure is representational only (formatting, indexing, cross‑references).\n2. **Identity & meaning preservation (ID‑2).** If `f : X → Y` is a meaning‑preserving map in I, then `Describe_ID(f)` is defined and preserves identity, and where meaningful composition exists, `Describe_ID(f ∘ g) = Describe_ID(f) ∘ Describe_ID(g)`.\n3. **Monotonic refinement (DS‑1).** If `D₁ ≤₍ref₎ D₂`, then `Specify_DS(D₁) ≤₍ref₎ Specify_DS(D₂)` (equivalently `Formalize_DS(D₁) ≤₍ref₎ Formalize_DS(D₂)`). Also `D ≤₍ref₎ Specify_DS(D)` holds when S merely adds testable structure.\n4. **Pinning of editions & anchors (DS‑2).** `Specify_DS`/`Formalize_DS` MUST pin: **edition id**, **unit/scale types**, **ReferencePlane**, and **measurable anchors** (CG‑Spec/CHR). Pins are visible on **TechCard/NormsCard** faces and recorded in **SCR**; edition governance follows **U.EditionSeries**.\n5. **No retro‑effects (DS‑3).** Applying `Specify_DS` yields a *new* `S` and *new* carriers (new SCR ids); earlier carriers remain valid in their scope; **no retro‑mutation** of prior I/D carriers.\n6. **Separation from Γ.** `Describe_ID`/`Specify_DS` (`Publ_ID`/`Formalize_DS` in legacy text) do **not** compose with **Γ\\_method**, **Γ\\_time**, or **Γ\\_work**; I/D/S describing/formalising is *not execution* and accrues no resource/time semantics.\n7. **Ontology preservation.** Describing any object (Calculus/Signature/Mechanism/…) via `Describe_ID` does **not** change its ontology; it yields a D/S projection by A.7 rules. *Describing/formalising is not a subtype of mechanism*; publishing to surfaces is handled separately in E.17 (MVPK).\n",
        "archetypal_grounding": "### A.7:6 - Archetypal Grounding (Tell–Show–Show; System / Episteme)\n\n#### A.7:6.1 - System and Episteme example\n**System archetype — “Digital‑twin vs asset”.**  \n*Claim:* *The twin (episteme) does not “act”; the **system** bearing TransformerRole enacts Work on the asset; evidence binds to carriers.*  \n*Show:* A maintenance **MethodDescription** (tech card) lives at design‑time; a **Work** record (assurance face) lists Γ_time, Γ_work, PathId and **carrier** ids for telemetry. The twin’s update is **Work on the carrier**, not the asset; CL^plane penalties are disclosed when twin–asset crossings are analysed.\n\n**Episteme archetype — “Peer‑review vs manuscript”.**  \n*Claim:* *A review is Work by a **system** (the reviewer) **on carriers** of an episteme (the manuscript).*  \n*Show:* The **MethodDescription** is the review SOP; the **Work** cites carrier ids (file/edition) and the *describedEntity* episteme; arguments/rebuttals live on epistemes; acceptance gating lives in CAL, not in CHR cards.\n\n#### A.7:6.2 - Didactic examples\n\n**Example 1 — Pump in a cooling loop**\n\n* **Substance (system):** Centrifugal pump P‑12.\n* **Role:** **Cooling‑CirculatorRole**.\n* **MethodDescription:** “Loop Circulation v3” (**TechCard**, anchored in SCR).\n* **Method:** ordered capability: start → ramp → hold → stop (Γ\\_method).\n* **Work:** run on 2025‑08‑09 10:00–10:45; energy ledger via Γ\\_work; log via Γ\\_time.\n* **Safe phrasing:** *“The **system** playing **Cooling‑CirculatorRole** (via the P‑12 control unit as **Transformer**) executed the **Method** described by **MethodDescription**, producing **Work** …”*\n* **What not to write:** “The pump’s function is the role” (role ≠ behaviour).\n\n**Example 2 — Standard document cited in a design**\n\n* **Episteme:** “Safety Standard S‑174”.\n* **Carriers:** PDF (SCR id: scr://std/S‑174/2025‑07), printed volume (scr://print/S‑174/2e).\n* **Role:** **ReferenceRole** in the valve selection activity.\n* **System bearing TransformerRole:** design team’s selection service.\n* **MethodDescription:** “Valve Selection SOP v5”.\n* **Method/Work:** capability and dated selection session that **used** the standard; the episteme did **not** act.\n\n**Example 3 — Set vs team**\n\n* **Set (MemberOf):** {Alice, Bob, 3.14} — a collection; **no behaviour** implied.\n* **Collective system (team):** boundary, coordination **Method**, supervision **Work**; can bear **AgentialRole** (A.13).\n* **Safe phrasing:** *“Team T plays **Cooling‑MaintenanceRole** and executed Work W…”*\n",
        "conformance_checklist": "### A.7:7 - Conformance Checklist (normative)\n\n| ID                                       | Requirement                                                                                                                                                                                                                                                                                    | Practical test                                                                                                                            |\n| ---------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------- |\n| **CC‑A7.1 (Role/Behaviour split)**       | A **Role** must be modelled as a contextual **mask** borne by a holon; **behaviour** must be expressed as **Method** (design‑time capability) and **Work** (run‑time occurrence).                                                                                                              | In any sentence, if “role” is used as if it *does* something, rewrite: the **system bearing TransformerRole** does it **by Method/Work**. |\n| **CC‑A7.2 (Transformer domain)**         | **TransformerRole SHALL be borne only by a system.**                                                                                                                                                                                                                                           | Type‑check: bearer ∈ `U.System`. “holon bearing TransformerRole” is invalid.                                                              |\n| **CC‑A7.3 (Episteme non‑agency)**        | An **episteme SHALL NOT** be described as acting. All changes to epistemes must be routed to their **symbol carriers** (A.10) by a **system bearing TransformerRole**.                                                                                                                         | Text contains the acting system + carriers (SCR ids).                                                                                     |\n| **CC‑A7.4 (MethodDescription ≠ Method ≠ Work)** | **MethodDescription** (description), **Method** (capability), and **Work** (occurrence) **SHALL** be kept distinct in wording and modelling.                                                                                                                                                          | Ask: is there a design artefact? a capability? a dated occurrence? Each must be named separately.                                         |\n| **CC‑A7.5 (Operator fit)**               | Use **Γ\\_method** only for composing **Method**; **Γ\\_time** only for **Work** histories; **Γ\\_work** only for resource spend/yields; **Γ\\_sys** for systemic properties of systems.                                                                                                           | No sentence should use a single generic “process operator” for all three.                                                                 |\n| **CC‑A7.6 (SCR anchoring)**              | Any knowledge claim that references documents/data **SHALL** anchor **carriers** via **SCR/RSCR** on first mention in the subsection.                                                                                                                                                          | First mention expands as “Symbol‑Carrier Register (SCR)”; references list carrier ids.                                                    |\n| **CC‑A7.7 (Collective vs set)**          | If a grouping is expected to **act**, it **MUST** be modelled as a **collective system** (boundary + coordination Method + Work), not as a **MemberOf** set.                                                                                                                                   | Presence of boundary, Method, Work for the group.                                                                                         |\n| **CC‑A7.8 (Diagram legend)**             | When domain idioms use **“process”**, diagrams/text **MUST** map them to FPF terms on first occurrence: *process (domain) ≡ Method (design‑time) / Work (run‑time).*                                                                                                                           | Legend or parenthetical present at first use.                                                                                             |\n| **CC‑A7.9 (Substance ⧧ Role wording)**   | The safe formula is **“System (substance) plays Role; under that Role it has Method; its execution is Work.”**                                                                                                                                                                                 | Sentences follow this order; “function” used only as synonym for **behaviour**, never for the **role**.                                   |\n| **CC‑A7.10 (Quartet clarity)**           | Any “triad” picture **MAY** be used only as a **design‑time stand‑in** (Transformer + MethodDescription + Method) and **MUST** be accompanied by an explicit **Work** lane elsewhere in the same section. “quartet of quartets” headings **SHALL** be avoided; use **“Quartet backbone”** instead. | Diagram has a visible **Work** lane/timeline or separate box within the same section.                                                    \n| **CC‑A7.11 (Terminology hygiene)**       | Ban **“actor”** in core text. Use **“system bearing TransformerRole”**; bind local shorthand **“Transformer”** only per A.12 rules.                                                                                                                                                            | Plain text scan: no “actor”; shorthand is locally bound.                                                                                  |\n| **CC‑A7.12 (Role domain guards)**        | Behavioural roles’ domain = **system**. Epistemes may bear **non‑behavioural** roles (e.g., ReferenceRole, ConstraintSourceRole) only.                                                                                                                                                         | Role declarations name their domain.                                                                                                      |\n| **CC‑A7.13 (I→D→S visibility)**          | I/D/S morphisms MUST be **explicit**; do not conflate them with MVPK or TGA steps. If a flow shows only surfaces, the underlying `Describe_ID`/`Specify_DS` steps MUST be recoverable.       | Both steps are visible in text/diagrams; audit shows two distinct operations.                                                             |\n| **CC‑A7.14 (Describe_ID / Specify_DS laws)** | Any implementation of `Describe_ID` MUST enforce **ID‑1/ID‑2**; `Specify_DS`/`Formalize_DS` MUST enforce **DS‑1/‑2/‑3**. Violating systems are considered out‑of‑model.                                                                                                              | Diff check between I and D shows no new claims; mapping table shows preserved composition.                                                |\n| **CC‑A7.15 (Formalize_DS laws)**         | `Formalize_DS` obeys **DS‑1/DS‑2/DS‑3**: monotonic refinement; pins edition/unit/scale/ReferencePlane/anchors; produces new **S** + **SCR** carriers without retro‑mutation.                                     | Presence of **CHR‑Pins** and pinned anchors; new SCR ids; no edits to prior carriers.                                                     |\n| **CC‑A7.16 (Γ‑separation)**              |  Both I/D/S describing/formalising morphisms (`Describe_ID`/`Specify_DS`) and publication‑to‑surface morphisms (MVPK) SHALL NOT carry cost/time semantics; **Γ\\_method**, Γ\\_time and Γ\\_work belong to **Method/Work/System**, not to description/specification or publication. Any aggregate on a card must cite the Γ operator and policy.   | No ledger/time fields attached to `Describe_ID`/`Specify_DS` or MVPK publication steps; any “publication cost” is Work in a separate publication service.             |\n| **CC‑A7.17 (**Surface tokens only)**     |  Only **PublicationSurface/InteropSurface** tokens are allowed; faces are **…View/…Card/…Lane**. Use only `PlainView`, `TechCard`, `InteropCard`, `AssuranceLane` (and their tech aliases) unless a DRR extends the set. New `…Surface` kinds require a DRR and L‑SURF revision.                                                 | Token scan shows no ad‑hoc `…Surface` kinds.                                                       |\n| **CC‑A7.18 (Bridge+CL on crossings)**    | Any cross‑Context or cross‑plane content on a face **MUST** cite **Bridge id + CL** and **Φ policy‑ids**; penalties route to **R** only.                                                                         | Presence of Bridge ids and **Φ(CL)**/**Φ_plane** on TechCard/AssuranceLane.                        |\n| **CC‑A7.19 (UTS anchoring)**             | Public names shown on faces **SHALL** point to **UTS rows** with twin labels (Tech/Plain), edition pins, and SCR carrier ids.                                                                                    | Face carries UTS row ids + edition pins.                                                          |\n",
        "canonical_rewrites_(didactic_library)": "### A.7:8 - Canonical rewrites (didactic library)\n\n| Instead of (ambiguous)                           | Write (canonical)                                                                                                                               | Why                                                       |\n| ------------------------------------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------- |\n| “The process enforced the rule.”                 | “The **system bearing TransformerRole** enforced the rule by executing the **Method**; the **Work** is anchored to carriers ⟨ids⟩.”             | Processes don’t act; systems do. Evidence via Work + SCR. |\n| “The specification decided to tighten limits.”   | “The **design‑control service (system bearing TransformerRole)** updated the **carriers** of the spec (SCR ids), producing **Work** at ⟨time⟩.” | Epistemes are changed via carriers by systems.            |\n| “Our role is pump; the role circulates coolant.” | “The **system** plays **Cooling‑CirculatorRole**; under this role its **Method** circulates coolant; **Work** was executed ⟨when⟩.”             | Role = mask; behaviour = Method/Work.                     |\n| “We followed the blueprint, so it’s done.”       | “We have a **MethodDescription** and a **Method**; completion is evidenced by **Work** with ⟨timestamps, outcomes⟩.”                                   | Description/capability ≠ occurrence.                      |\n| “Team = set of members; it performed repair.”    | “The **team** is a **collective system** (boundary + coordination **Method**); it executed **Work** ⟨…⟩.”                                       | Acting groups must be systems, not sets.                  |\n| “Process cost is tracked by Γ\\_method.”          | “**Work** cost is tracked by **Γ\\_work**; **Γ\\_method** composes the **Method** (order/branching).”                                             | Operator alignment.                                       |\n| “Holon bearing TransformerRole.”                 | “**System bearing TransformerRole**.”                                                                                                           | Only systems can bear behavioural roles.                  |\n| “Publication is a special mechanism.”            | “Publication = **typed projection** from existing Descriptions/Specifications onto **PublicationSurface/InteropSurface** (MVPK); **describing/formalising** are `Describe_ID`/`Specify_DS`, and any execution around them is separate **Work** by a **system** on **carriers**.” | Publication is not behaviour; it is a D/S→Surface projection in the model. |\n",
        "anti‑patterns_(with_fixes)": "### A.7:9 - Anti‑patterns (with fixes)\n\n1. **Role‑as‑behaviour** — calling the **role** “the function”.\n   **Fix:** Name the **role** + **Method/Work** pair explicitly.\n\n2. **Episteme‑as‑system** — “the model routed traffic”.\n   **Fix:** Name the **system** (or Transformer as a system bearing AgentialRole) that used the model; list **carriers** touched.\n\n3. **Triad everywhere** — omitting **Work** entirely.\n   **Fix:** Add the Work lane: timestamps, outcomes, Γ\\_time coverage.\n\n4. **Operator blur** — using one “process operator” for everything.\n   **Fix:** Choose among **Γ\\_method**, **Γ\\_time**, **Γ\\_work**, **Γ\\_sys**.\n\n5. **Set‑as‑collective** — a MemberOf set “decides”.\n   **Fix:** Model a **collective system** with coordination Method.\n\n6. **Unanchored evidence** — citing ideas without carriers.\n   **Fix:** Add **SCR/RSCR** ids; tie claims to carriers.\n\n7. **Holon/system drift** — “holon maintains temperature”.\n   **Fix:** Say **system**; reserve “holon” for neutral mereology.\n\n8. **Function/role swap in tables** — columns labelled “Function” but entries are roles.\n   **Fix:** Rename column to **Role**; add a separate **Behaviour (Method/Work)** column.\n\n9. **Process‑word leakage** — domain “process” used as FPF operator.\n   **Fix:** Add parenthetical mapping at first use (Method/Work).\n\n10. **Carrier/episteme swap** — “we versioned the model” meaning a file was renamed.\n   **Fix:** State whether the **episteme content** changed; if only a carrier was renamed, say so.\n\n11. **Publication‑as‑mechanism** — modelling “publication” as if it were a Method/Mechanism.\n   **Fix:** Separate **describing/formalising** (`Describe_ID`/`Specify_DS`) from **publication** (MVPK D/S→Surface). If there is operational toil (build, render, upload), model it as **Work** by a **system** on **carriers**; do not change the ontology of the described object or the D/S episteme being surfaced.\n",
        "consequences": "### A.7:10 - Consequences\n\n| Benefit                      | Why it matters                                    | Trade‑off / Mitigation                             |\n| ---------------------------- | ------------------------------------------------- | -------------------------------------------------- |\n| **Category safety at scale** | Prevents silent logic bugs across holarchies.     | Slight verbosity → use local shorthand per A.12.   |\n| **Trustworthy evidence**     | Work + SCR anchoring makes claims auditable.      | Requires discipline → provide checklists.          |\n| **Operator determinism**     | Correct Γ‑flavour selection preserves invariants. | A bit more modelling → reusable templates.         |\n| **On‑ramp for managers**     | Canonical rewrites give immediate phrasing fixes. | Team training → this pattern is the training page. |\n\n| Benefits | Trade‑offs / Mitigations |\n|---------|---------------------------|\n| **Category‑error firewall.** Clear separation of System/Episteme; I/D/S vs Surface orthogonality removes recurring modeling defects. | Authors must tag surfaces explicitly; mitigated by a minimal **SurfacePack** template in E.8. |\n| **Audit and pedagogy align.** SCR/RSCR point to carriers; Normative face houses checklists; Plain face teaches; Tech face types. | Slight increase in pattern length; offset by predictable navigation and machine‑checkable CC. |\n| **Cross-Context safety.** Bridge+CL discipline is now visible even on surfaces. | Authors must cite CL policy-ids; tooling can assist (GateCrossing visibility harness), but text remains notation-independent. |\n",
        "sota‑echoing_(post‑2015_practice_alignment)": "### A.7:11 - SoTA‑Echoing (post‑2015 practice alignment)\n\n* **Digital Twins (ISO 23247, 2021→):** separates the asset (system) from its **digital representation** (episteme) and prescribes governance of twins without attributing *agency* to the twin itself — matching A.7’s “episteme ≠ actor” and carrier discipline. **Adopt.** \n* **Observability (OpenTelemetry, 2019→2025):** codifies **semantic conventions** as a *publication layer* over traces/metrics/logs; semantics live in descriptions, not exporters — echoing our **PublicationSurface** orthogonality. **Adapt** (terminology). \n* **Active Inference (2017→2024):** separates a **generative model** (episteme) from **actions** by the agent (system), with explicit perception–action cycles — mirroring A.7’s “who can act” and stance separation. **Adopt** \n* **Constructor Theory (2016→):** frames knowledge and work as **possible transformations** enacted by constructors (systems), not by informational states — reinforcing “episteme ≠ actor”. **Adopt** \n* **Quality‑Diversity (MAP‑Elites family, 2015→2024):** archives are **sets on typed spaces** (descriptions) whose **occurrences** are runs; selection returns **sets** under lawful orders — consonant with A.7 and A.15’s set‑returning discipline. **Adopt/Adapt**. \n* **Refinement‑typed specs (2016→):** modern stacks (e.g., Liquid Haskell, Dafny’s post‑2017 refinements, Rust’s `uom` type‑level units) treat formalization as **monotonic refinement with pinned units/scales** — echoing **Formalize_DS** and **Surface field pins**. **Adapt** (terminology; pinning discipline).\n",
        "rationale": "### A.7:12 - Rationale (informal)\n\n* **Engineering cognition:** Large programmes fail less from equations than from category slips (“process vs procedure vs execution”). A.7 eliminates these slips by a small, repeatable grammar.\n* **Compatible with ISO/BORO practice:** Distinguishing artefacts (specs), capabilities (procedures), and occurrences (operations) mirrors established systems‑engineering discipline while keeping FPF’s holonic rigor.\n* **Didactic primacy:** Managers can approve sentences by spotting five tokens: **system bearing TransformerRole** / **Role** / **Method** / **Work** / **SCR**.\n* **Why bring “PublicationSurface” into A.7?** Strict Distinction already guards **what a thing is (I)** from **how we describe/specify it (D/S)**. In practice, **misreadings happen at the publication layer**: cards and tables are mistaken for objects; governance words leak where physics/logic should stand. By making **PublicationSurface** *explicit and orthogonal*, A.7 closes that gap without entangling semantics with any tool or notation. This preserves **C‑1 universality** and **P‑1 Cognitive Elegance**, while giving E.8 a crisp home for multi‑face presentation rules.\n",
        "relations": "### A.7:13 - Relations\n\n **Builds on:** A.1 (Holon), A.2 (Roles), A.3 (Transformer Quartet), A.10 (Evidence & SCR), A.12 (External Transformer), A.14 (Advanced Mereology), A.15 (Role–Method–Work Alignment).  \n* **Constrains:** A.13 (Agency sits on systems only; epistemes non‑behavioural), Part B operators (**Γ_method**/**Γ_time**/**Γ_work**/**Γ_sys**) and their choice points; **publication is not a Γ‑operator**.  \n* **Extends:** E.8 (Authoring conventions), E.10 (LEX‑BUNDLE incl. **L‑SURF**), **Part F/G (UTS & CG‑Spec/CHR pinning)**, B.3 (Assurance routing), C‑cluster (selection/archives) — by enforcing I/D/S vs Surface orthogonality, System/Episteme separation, and typed I→D→S describing/formalising discipline (**publication = D/S→Surface in E.17**).  \n* **Coordinates with:** **E.18 (E.TGA - GateCrossing / OperationalGate(profile))** for crossing visibility & publication gating, **A.21/A.27** for check/pinning discipline, **E.10** for lexical SD checks, and **Part F (Bridges/CL)** for explicit cross-Context identity — without embedding any notation dependence.\n  ",
        "manager’s_one‑page_review_(copy‑paste)": "### A.7:14 - Manager’s one‑page review (copy‑paste)\n\n**Approval sentence template**\n\n> “The **system bearing TransformerRole** ⟨name⟩ plays ⟨Role⟩; it has **Method** ⟨M⟩ (from **MethodDescription** ⟨S⟩) and executed **Work** ⟨W⟩ on ⟨time⟩, anchored to ⟨SCR ids⟩; resources accounted via **Γ\\_work**.”\n\n**Five binary checks**\n\n1. **Actor ban:** No “actor” token; canonical phrasing present.\n2. **Clear trio:** MethodDescription / Method / Work are all named (as applicable) and not conflated.\n3. **Right Γ:** Γ\\_method for capability; Γ\\_time for occurrence; Γ\\_work for resources; Γ\\_sys for system properties.\n4. **Episteme handled:** Epistemes do not act; carriers listed (SCR).\n5. **Group clarity:** Acting group is a **collective system**, not a MemberOf set.\n\n**Diagram legend stub**\n\n* “process (domain)” ⇒ Method (design‑time) / Work (run‑time).\n* Role column lists masks (e.g., Cooling‑CirculatorRole).\n* Behaviour column shows Method/Work, not the role itself.\n",
        "a.7:end": "### A.7:End\n"
      },
      "content": "### A.7:End\n",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.8",
      "title": "Universal Core Principle (C‑1)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.8 - Universal Core Principle (C‑1)\n\n*“A principle that works in only one world is local folklore; a first principle architects every world.”*\n",
        "problem": "### A.8:2 - Problem\n\n| Pathology                 | Manifestation                                                                                       |\n| ------------------------- | --------------------------------------------------------------------------------------------------- |\n| **Parochial Drift**       | A “universal” `U.Resource` works for ERP bills of materials but collapses for ATP in cell biology.  |\n| **Alienated Communities** | Subject‑matter experts recognise the bias and abandon the framework, fracturing knowledge silos.    |\n| **Kernel Bloat**          | Competing “almost‑universal” types are added to patch gaps, violating Ontological Parsimony (A 11). |\n\n",
        "forces": "### A.8:3 - Forces\n\n| Force                           | Tension                                                                              |\n| ------------------------------- | ------------------------------------------------------------------------------------ |\n| **Generality vs Specificity**   | Primitives must stretch across physics ↔ social science yet keep actionable meaning. |\n| **Rigor vs Pragmatism**         | Proof of universality must be checkable, not philosophical hand‑waving.              |\n| **Inclusivity vs Coherence**    | Welcoming new ideas should not swamp the kernel with domain jargon.                  |\n| **Cognitive Load vs Grounding** | Examples help readers, but too many examples obscure the essence.                    |\n\n",
        "solution": "### A.8:4 - Solution — *The Three‑Domain Falsification Test*\n\n> **Normative Rule (C‑1)** A `U.Type` **enters the kernel only if** it is shown to play the **same Role** in **at least three foundationally distinct domains**.\n\n **Heterogeneity & QD‑triad guarantee (C‑1.QD).**\n In addition to distinct **domain‑families** (choose from: *Exact Sciences - Natural Sciences - Engineering & Technology - Formal Sciences - Social & Behavioural Sciences*), the **triad** SHALL demonstrate **quality diversity**:\n(a) **Hetero‑test.** Each projection adds at least one non‑trivial **DescriptorMap** signal or Bridge path not subsumed by the other two (no aliasing by mere renaming).\n(b) **QD evidence.** Publish **Creativity‑CHR / NQD‑CAL** evidence for the triad: `Diversity_P` (set‑level) and its **IlluminationSummary** telemetry metric with ≥3 non‑empty cells and `occupancyEntropy > 0` under the declared grid.\n(c) **Policy disclosure.** Declare the Context‑local `QD_policy` (binning/grid, kernel, time‑window) used to compute the telemetry metrics.\n(References: **C.17** `Diversity_P` & illumination Summary as telemetry metric; **C.18** `U.DescriptorMap`, `U.IlluminationSummary`.)\n\nImplementation steps (Domain Families): \n\n1. source domain‑families from the active F1‑Card (taxonomyRef/embeddingRef edition). The five coarse families {Exact, Natural & Life, Engineering & Tech, Formal, Social & Behavioural} are informative only; if used for pedagogy, publish an explicit mapping to the F1‑Card taxonomy. The triad gate is measured by MinInterFamilyDistance ≥ δ_family (per F1‑Card), not by labels alone.\n\n2. **Role‑Projection Records** For each domain, author a short **`Role‑Projection`** tuple: `{domain, indigenous term, Role, exemplar}`.\n   *Example:* `{physics, \"Free Energy\", extremum driver, closed gas system}`.\n\n3. **Congruence Check** All three exemplars must satisfy the **same abstract intent**; superficial analogy is rejected.\n\n4. **Living Index** Track the ratio\n\n   $$\n     U\\text{-Index}=\\frac{\\text{\\# kernel types lacking 3 projections}}{\\text{\\# kernel types}}\n   $$\n\n   as a health signal; target ≤ 0.05 (not a bureaucratic gate).\n\n*Rule of thumb for busy managers:* “**One idea, three worlds.** If you can’t point to the trio, park it in a plug‑in.”\n\n",
        "archetypal_grounding": "### A.8:5 - Archetypal Grounding (System / Episteme)\n\n| Universal `U.Type` | **Domain 1 - Physics**                  | **Domain 2 - Life Sci.**            | **Domain 3 - Tech & Soc.**       | Congruent Role                |\n| ------------------ | --------------------------------------- | ----------------------------------- | -------------------------------- | ----------------------------- |\n| `U.Objective`      | *Free Energy* minimum in thermodynamics | *Fitness* maximisation in evolution | *Loss* minimisation in ML        | Extremum driver of change     |\n| `U.System`         | Thermodynamic control volume            | Biological organism (cell membrane) | Cyber‑physical system (IoT edge) | Bounded interacting whole     |\n| `U.Resource`       | Joules of energy                        | ATP molecules                       | Budget dollars                   | Conserved, spendable quantity |\n\nThese juxtapositions give engineer‑managers an immediate sense of *why* each primitive is worth learning.\n",
        "conformance_checklist": "### A.8:6 - Conformance Checklist\n\n| ID          | Requirement                                                                                                                            | Purpose                                                 |\n| ----------- | -------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------- |\n| **CC‑UC 1** | A proposed `U.Type` **SHALL** include ≥ 3 Role‑Projection records, each taken from a *different* domain family.                        | Enforces the Three‑Domain Test.                         |\n| **CC‑UC 2** | Each Role‑Projection **MUST** explain in ≤ 30 words how the domain notion fulfils the *same Role* as the proposed `U.Type`. | Blocks superficial analogies.                           |\n| **CC‑UC 3** | No single artefact may serve as exemplar for more than one domain projection.                                                          | Prevents contrived “triple duty” examples.              |\n| **CC‑UC 4** | A **specialised** `U.SubType` inherits its parent’s projections **and** adds ≥ 1 new domain projection, never fewer.                   | Keeps refinements as universal as their parents.        |\n| **CC‑UC 5** | While the U‑Index > 0.05, authors **SHALL** prioritise supplying missing projections over adding new core concepts.                    | Maintains kernel health without procedural bureaucracy. |\n| **CC‑UC‑2‑QD‑triad.** | The three Role‑Projections come from **different domain‑families** AND the triad PUBLISHES: `{FamilyCoverage, MinInterFamilyDistance, Diversity_P, IlluminationSummary}` with `MinInterFamilyDistance ≥ δ_family` (per **F1‑Card** DistanceDef & edition). + Provenance MUST cite `DescriptorMapRef` (incl. `DistanceDef`/edition), `F1‑Card id+edition`, and the grid/binning policy used for `IlluminationSummary`.  | quality diversity of domains\n",
        "consequences": "### A.8:7 - Consequences\n\n| Benefit                                                                                                    | Trade‑off                                     | Mitigation                                                 |\n| ---------------------------------------------------------------------------------------------------------- | --------------------------------------------- | ---------------------------------------------------------- |\n| **Lean, trusted kernel** – every primitive earns its place by real work in three worlds.                   | Authoring effort for projections.             | Patterns A 5/A 6 provide templates and exemplar libraries. |\n| **Cross‑disciplinary uptake** – physicists, managers, and biologists see their own language reflected.     | Some novel ideas wait to gather evidence.     | They live safely in plug‑ins until mature.                 |\n| **Resilience to domain drift** – if one field’s jargon changes, the other two anchors preserve continuity. | Possible oversimplification of niche nuances. | Domain‑specific elaborations belong in architheories.      |\n\n",
        "rationale": "### A.8:8 - Rationale\n\nDeep research over the last decade shows *structural homologies* across domains:\n\n* Free‑energy minimisation ↔ negative log‑likelihood ↔ Bayesian surprise (Friston 2023).\n* Conservation laws in physics mirror budget balancing in economics (Rayo 2024).\n\nBy demanding three independent manifestations, FPF captures these convergences *without privileging* any single vocabulary.  The principle operationalises **Popperian falsifiability** for universality: a concept that cannot survive a three‑domain cross‑examination is, by definition, not a first principle.  This guards Pillars **P‑1 (Cognitive Elegance)** and **P‑4 (Open‑Ended Kernel)** simultaneously.\n\n",
        "relations": "### A.8:9 - Relations\n\n| Relation             | Linked Pattern                       | Contribution                                                          |\n| -------------------- | ------------------------------------ | --------------------------------------------------------------------- |\n| **Supports**         | A 11 Ontological Parsimony           | Filters candidates before sunset reviews.                             |\n| **Prerequisite for** | A 9 Cross‑Scale Consistency          | Only universal types can propagate invariants up and down holarchies. |\n| **Complementary**    | A 7 Strict Distinction               | Together provide clarity (A 7) and breadth (A 8).                     |\n| **Enables**          | B 1 Universal Algebra of Aggregation | Γ‑operators rely on domain‑agnostic operands.                         |\n\n",
        "known_uses": "### A.8:10 - Known Uses\n\n* **Energy ↔ Budget ↔ Attention** – Engineering teams reused `U.Resource` to reason about battery charge, project funds, and user‑attention minutes with one algebra, cutting integration effort by half (2024 pilot).\n* **Objective unification** – An AI lab mapped *loss functions*, a bio‑lab mapped *Darwinian fitness*, and a factory mapped *scrap‑rate* all to `U.Objective`, enabling shared optimisation tooling.\n\nThese cases validated that the Three‑Domain Test is achievable in practice, not theoretical paperwork.\n\n",
        "open_questions": "### A.8:11 - Open Questions\n\n1. **Domain taxonomy stability** – Should the five domain families be versioned as science evolves (e.g., quantum‑bio‑tech)?\n2. **Automated congruence checks** – Can category‑theoretic tooling semi‑automate the functional‑role equivalence test?\n3. **Edge‑case hybrids** – How are bio‑cyber‑physical chimera systems counted: a new domain or a composite projection?\n",
        "a.8:end": "### A.8:End\n"
      },
      "content": "### A.8:End\n",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.9",
      "title": "Cross‑Scale Consistency (C‑3)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.9 - Cross‑Scale Consistency (C‑3)\n\n> *“The logic of a bolt must still be the logic of the bridge.”*\n",
        "context": "### A.9:1 - Context\n\nFPF models reality as a **nested holarchy**: parts → assemblies → systems → supra‑systems; axioms → lemmas → theorems → paradigms. Designers and analysts must zoom freely without logical whiplash. Classical mereology and modern renormalisation theory both warn: if rules mutate across scales, predictions and audits collapse. FPF therefore mandates a single, scale‑invariant Standard.\n\n",
        "problem": "### A.9:2 - Problem\n\n| Failure Mode              | Real‑World Symptom                                         |\n| ------------------------- | ---------------------------------------------------------- |\n| **Invalid extrapolation** | Unit‑tested module fails once integrated.                  |\n| **Brittle dashboards**    | Portfolio KPI “green” hides a red supplier averaged away.  |\n| **Compositional chaos**   | Different teams’ roll‑ups yield non‑deterministic results. |\n\nThese pathologies derail safety cases and budget decisions across disciplines.\n\n",
        "forces": "### A.9:3 - Forces\n\n| Force                                  | Tension                                                      |\n| -------------------------------------- | ------------------------------------------------------------ |\n| **Local autonomy vs Global coherence** | Free optimisation of parts ↔ predictable behaviour of whole. |\n| **Simplicity vs Fidelity**             | Single rule‑set ↔ non‑linear, emergent effects.              |\n| **Determinism vs Emergence**           | Stable roll‑ups ↔ need to legitimise genuine synergy jumps.  |\n| **Didactic clarity vs Formal rigour**  | Managers grasp intent quickly ↔ analysts can prove it.       |\n\n",
        "solution": "### A.9:4 - Solution — Invariant Quintet + Meta‑Holon Transition\n\n#### A.9:4.1 - Invariant Quintet\n\nAny aggregation operator `Γ` that claims FPF conformance **MUST** preserve these five invariants :\n\n| Code     | Invariant             | One‑line Intuition                               |\n| -------- | --------------------- | ------------------------------------------------ |\n| **IDEM** | *Idempotence*         | Folding a singleton changes nothing.             |\n| **COMM** | *Local Commutativity* | Order of independent folds is irrelevant.        |\n| **LOC**  | *Locality*            | Worker or partition choice cannot affect result. |\n| **WLNK** | *Weakest‑Link Bound*  | Whole never outperforms its frailest part.       |\n| **MONO** | *Monotonicity*        | Improving a part cannot worsen the whole.        |\n\n*Mnemonic:* **S‑O‑L‑I‑D** (Same - Order‑free - Location‑free - Inferior cap - Don’t‑regress).\n\n**Inter‑Layer Standard note**\nWhen holons are composed as a Layered‑Control stack, each Planner ↔ Regulator pair MUST publish an inter‑layer Standard: {referenceSignal, guaranteedTrackingError, cycleTime}.  Matni 2024 (https://arxiv.org/abs/2401.15185) prove such Standards satisfy COMM + LOC invariants, giving a constructive instance of the Quintet.\n\n#### A.9:4.2 - Meta‑Holon Transition (MHT)\n\nIf empirical data show a true violation (e.g., redundancy raises WLNK limit), the modeller **declares an MHT**: the collection becomes a new holon tier, and the quintet applies anew at that scale .\n\n",
        "archetypal_grounding": "### A.9:5 - Archetypal Grounding\n\n| Invariant  | **`U.System` — Pump Skid**                    | **`U.Episteme` — Meta‑Analysis**                |\n| ---------- | --------------------------------------------- | ----------------------------------------------- |\n| IDEM       | One‑pump skid ≅ that pump.                    | Single‑study review ≅ that study.               |\n| COMM / LOC | Pumps welded in any order / yard → same spec. | Labs contribute in any order → same statistics. |\n| WLNK       | Pressure rating ≤ weakest pump.               | Reliability ≤ least‑replicated study.           |\n| MONO       | Stronger motor never lowers flow.             | Larger sample size never lowers confidence.     |\n\n",
        "conformance_checklist": "### A.9:6 - Conformance Checklist\n\n| ID          | Requirement                                                                                                                                                                                      | Purpose (manager‑friendly)                                |\n| ----------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | --------------------------------------------------------- |\n| **CC‑A9‑1** | Every calculus that defines an aggregation operator `Γ` **SHALL** provide a plain‑language note and a formal argument for how `Γ` upholds **all five invariants** (IDEM, COMM, LOC, WLNK, MONO). | Makes the Standard both human‑readable and checkable.     |\n| **CC‑A9‑2** | A *singleton fold* (` card (parts) = 1 `) **MUST** return the part unaltered (IDEM). | Locks the recursion base case. |\n| **CC‑A9‑3** | Folding two independent sub‑graphs in any order or on any compute site **MUST** yield equal results (COMM + LOC).                                                                                | Enables safe parallel work and reproducible analytics.    |\n| **CC‑A9‑4** | No aggregate metric **MAY** exceed the minimum of that metric across parts unless an **MHT** is declared (WLNK).                                                                                 | Prevents stealth inflation of reliability or truth.       | \n| **CC‑A9‑6** | A declared **Meta‑Holon Transition** **SHALL**: (a) name the new supervisory holon; (b) cite the data triggering the transition; (c) restate how the quintet holds at the new scale.             | Ensures emergence is captured explicitly, not hand‑waved. |\n\n",
        "consequences": "### A.9:7 - Consequences\n\n| Benefit                      | Why it matters                                                   | Trade‑off / Mitigation                                                           |\n| ---------------------------- | ---------------------------------------------------------------- | -------------------------------------------------------------------------------- |\n| **Stable roll‑ups**          | Summaries and reports remain faithful as parts evolve.          | Requires early agreement on `Γ`; offer reference libraries.                      |\n| **Visible risk floor**       | WLNK blocks “averaging away” critical weaknesses.                | Can look overly conservative; redundancy, when real, lifts the minimum honestly. |\n| **Parallel progress**        | COMM + LOC allow distributed teams to integrate without re‑work. | Needs explicit independence assumptions; templates guide authors.                |\n| **Objective emergence flag** | Quintet failure becomes a measurable R\\&D signal.                | Teams must learn to document MHTs instead of ignoring anomalies.                 |\n\n",
        "rationale": "### A.9:8 - Rationale\n\n*Post‑2015 evidence across domains*\n\n* **Physics** ‑ Renormalisation coherence echoes IDEM, COMM, LOC.\n* **Distributed data platforms** rely on COMM + LOC for deterministic aggregations.\n* **Safety engineering** ‑ Fault‑tree analyses hinge on WLNK; aviation failures (2018‑24) confirm its necessity.\n* **Lean improvement** ‑ MONO underpins Kaizen: fix a bottleneck, never worsen the plant.\n\nPackaging these insights as one memorisable quintet → **Cognitive Elegance** with formal bite.\n\n",
        "relations": "### A.9:9 - Relations\n\n| Relation           | Linked Pattern                       | Contribution                                              |\n| ------------------ | ------------------------------------ | --------------------------------------------------------- |\n| **Builds on**      | A 1 Holonic Foundation               | Supplies part/whole semantics.                            |\n| **Reinforces**     | A 7 Strict Distinction               | Prevents layer‑mixing during folds.                       |\n| **Enabled by**     | A 8 Universal Core                   | Guarantees operands share truly universal meaning.        |\n| **Foundation for** | B 1 Universal Algebra of Aggregation | B‑section implements operators that satisfy this pattern. |\n| **Triggers**       | B 2 Meta‑Holon Transition            | When invariants fail through synergy, an MHT is invoked.  |\n\n",
        "known_uses_(2018‑2025)": "### A.9:10 - Known Uses (2018‑2025)\n\n* **Spacecraft avionics** ‑ Applying WLNK exposed a sub‑grade connector, saving a \\$40 M launch window.\n* **Global vaccine meta‑reviews** ‑ COMM + LOC let five epidemiology teams merge data independently; results converged within 0.1 % effect size.\n* **Distributed ML training** ‑ MONO guaranteed optimiser swaps never reduced accuracy, cutting iteration time by 20 %.\n\n",
        "open_questions_for_expert_panel": "### A.9:11 - Open Questions for expert panel\n\n1. **Order‑sensitive physics** – Should quantum‑circuit folds live in a plug‑in with a relaxed invariant set?\n2. **Synergistic redundancy** – Can WLNK be reframed using an “effective minimum” when true redundancy lifts the floor?\n3. **Didactic tooling** – Which visual cues best alert non‑formal audiences to an approaching Meta‑Holon Transition?\n4. **Layer depth** — In an LCA (layered control architectures, https://arxiv.org/abs/2401.15185) stack every Planner is external to its Regulator; should FPF limit the number of nested layers, or is indefinite chaining acceptable?\n",
        "a.9:end": "### A.9:End\n"
      },
      "content": "### A.9:End\n",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.10",
      "title": "Evidence Graph Referring (C‑4)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.10 - Evidence Graph Referring (C‑4)\n\n*“A claim without a chain is only an opinion.”*\n",
        "context": "### A.10:1 - Context\n\nFPF is a holonic framework: wholes are built from parts (A.1, A.14), and reasoning travels across scales via Γ‑flavours (B.1). To keep this reasoning honest and reproducible, every **published assertion** must be *anchored* in concrete **symbol carriers** and **well‑typed transformations** performed by an **external TransformerRole** (A.12, A.15). **Publication** itself is the typed projection **I→D→S** (`Publ_ID`, `Formalize_DS`) per A.7 and is **not execution**; any physical/digital release, rendering, or upload is **Work** by an external transformer **on carriers**, cited in SCR.\n\nManagers can read this as a simple rule of thumb:\n> **Claim → (Proof or Test) → Confidence badge**\n> …where the proof/test is traceable to real carriers and to an external system/Transformer who executed an agreed method.\n\nThis pattern defines the **Evidence Graph Referring Standard** common to all Γ‑flavours (Γ\\_sys — formerly Γ\\_core, Γ\\_epist, Γ\\_method, Γ\\_time, Γ\\_work) and clarifies:\n(a) the difference between **mereology** (part‑whole; builds holarchies) and **provenance** (why a claim is admissible; does *not* build holarchies);\n(b) the run‑time / design‑time separation (A.4) across **Role–Method–Work** (A.15).\n\n",
        "problem": "### A.10:2 - Problem\n\nWithout a uniform anchor, models drift into five failure modes:\n\n1. **Weightless claims.** Metrics or arguments appear in the model with no link to their **symbol carriers** (files, datasets, lab notebooks, figures).\n2. **Collapsed scopes.** Design‑time method specs are silently mixed with run‑time traces; results cannot be reproduced because “what was planned” and “what actually ran” are conflated.\n3. **Self‑justifying loops.** A holon attempts to evidence itself (violates A.12 externality), producing cyclic provenance and unverifiable conclusions.\n4. **Source loss during aggregation.** As Γ combines parts, some sources “fall out”; later audit cannot reconstruct why a compound claim was accepted.\n5. **Temporal ambiguity.** Time‑series are aggregated without interval coverage or dating source; gaps/overlaps invalidate comparisons and trend claims.\n\nThe business effect is predictable: confidence badges cannot be defended, cross‑scale consistency (A.9) is broken, and iteration slows because every review re‑litigates “where did this come from?”.\n\n",
        "forces": "### A.10:3 - Forces\n\n| Force                           | Tension                                                                                                                                           |\n| ------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **Universality vs. burden**     | One Standard must fit systems and epistemes ↔ Authors should not drown in paperwork.                                                              |\n| **Externality vs. reflexivity** | Evidence must be produced by an external TransformerRole (A.12) ↔ Some systems adapt themselves (need reflexive modelling without self‑evidence). |\n| **Atemporal vs. temporal**      | Many claims are state‑like ↔ Many others are histories; evidence must respect order and coverage (Γ\\_time).                                       |\n| **Rigor vs. flow**              | Formal proofs and controlled tests raise confidence ↔ Engineering cadence needs lightweight, incremental anchors.                                 |\n| **Mereology vs. provenance**    | Part‑whole edges build holarchies ↔ Evidence edges never do; the two graphs must interlock without leaking semantics.                             |\n\n",
        "solution": "### A.10:4 - Solution — The Evidence Graph Referring Standard\n\nThe Standard is a small set of primitives applied uniformly, with **manager‑first clarity** and **formal hooks** for proof obligations.\n\n#### A.10:4.1 - EPV‑DAG (Evidence–Provenance DAG).\nA **typed, acyclic** graph disjoint from mereology. Node types: **SymbolCarrier** (a `U.System` in **CarrierRole**, A.15), **TransformerRole** (external Transformer, A.12), **MethodDescription** (design‑time blueprint of a method, A.15), **Observation** (a dated assertion/result), **U.Episteme** (knowledge holon). Edge vocabulary is small and normative: `evidences`, `derivedFrom`, `measuredBy`, `interpretedBy`, `usedCarrier`, `happenedBefore` (temporal), etc.\n*Manager view:* it is the *“because‑graph”*: every claim answers “because of these carriers, by this Transformer, using that method, then.”\n\n#### A.10:4.2 - Anchors (two relations, two flavours).**\n\n* `verifiedBy` — links a claim to **formal** evidence (proof obligations, static guarantees, model‑checking artefacts).\n* `validatedBy` — links a claim to **empirical** evidence (tests, measurements, trials, observations).\n  Both anchors terminate in the EPV‑DAG, not in the mereology graph.\n\n#### A.10:4.3 SCR / RSCR (Symbol Carrier Registers).\nEvery `Γ_epist` aggregation **SHALL** emit an **SCR**: an exhaustive register of **symbol carriers** materially used in the aggregate, with id, type, version/date, checksum, source/conditions and optional `PortionOf` (A.14) for sub‑carriers.\nEvery `Γ_epist^compile` **SHALL** emit an **RSCR**: SCR specialised to a **bounded context** (vocabularies, units) with publication‑grade identifiers and hashes.\n*Why this matters:* it prevents “lost sources” during composition and underwrites reproducibility without mandating any specific tool.\n\n#### A.10:4.4 Scope alignment (A.4) across Role–Method–Work (A.15).\n\n* **Design‑time**: **MethodDescription** lives here; methods are blueprints; anchors reference what *would* constitute proof or test.\n* **Run‑time**: **Work** (actual execution) lives here; traces reference which MethodDescription they instantiate and record `happenedBefore`.\n  Bridging edges are explicit (“this run trace instantiates that spec”), so scopes never silently mix.\n\n#### A.10:4.5 External TransformerRole (A.12).\nThe system that produces or interprets evidence is **external** to the holon under evaluation. If true reflexivity is essential, model a **meta‑holon** (A.12): the self‑updating holon becomes the *object* of a higher‑level external transformer (the “mirror”), restoring objectivity.\n\n#### A.10:4.6 Γ‑flavour hooks (how each flavour anchors).\n\n* **Γ\\_sys (formerly Γ\\_core)**: physical properties are anchored by measurement models, boundary conditions, calibration carriers, and dated observations.\n* **Γ\\_epist**: always outputs SCR/RSCR; every provenance/evidence node resolves to an SCR/RSCR entry.\n* **Γ\\_method**: order‑sensitive composition; at design‑time a **Method Instantiation Card (MIC)** states `Precedes/Choice/Join` and guards; at run‑time traces record `happenedBefore` and point to the MethodDescription they instantiate.\n* **Γ\\_time**: temporal claims state interval coverage; **Monotone Coverage** (no unexplained gaps/overlaps) is required.\n* **Γ\\_work**: resource spending and yield are evidenced by instrumented carriers (meters, logs) and their MethodDescriptions; keep **resource rosters** separate from SCR/RSCR.\n\n> **Manager’s shortcut:** If you can answer *what carriers, which system, which method, when*, the anchor is likely sufficient; if any of the four is missing, it is not.\n\n",
        "archetypal_grounding": "### A.10:5 - Archetypal Grounding\n\n| Aspect                       | `U.System` — Autonomous Brake                                                                       | `U.Episteme` — Meta‑analysis                                                                                             |\n| ---------------------------- | --------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------ |\n| **Claim**                    | “Stop within 50 m from 100 km/h.”                                                                   | “Drug A outperforms control on endpoint E.”                                                                              |\n| **Anchor**                   | `verifiedBy`: static‑analysis proof of no overflow; `validatedBy`: instrumented track tests.        | `verifiedBy`: power‑analysis proof of sample size; `validatedBy`: pooled effect sizes with bias checks.                  |\n| **Carriers (SCR/RSCR)**      | Scale logs, calibration certificates, test track telemetry; SCR lists all; RSCR adds context units. | PDFs of studies, data tables, analysis code; SCR lists carriers; RSCR adapts vocabularies/units for the target audience. |\n| **External TransformerRole** | Independent test team / metrology lab.                                                              | Independent synthesis team / statistician.                                                                               |\n| **Temporal**                 | Dated runs; `happenedBefore` between setup → test → teardown.                                       | Publication dates; dataset versions; monotone coverage of included studies.                                              |\n",
        "conformance_checklist": "### A.10:6 - Conformance Checklist\n\n| ID                                      | Requirement                                                                                                                                                                                                                             | Purpose (what it prevents)                                 |\n| --------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------- |\n| **CC‑A10.1 (EPV‑DAG Presence)**         | Every published claim MUST have a path in the Evidence–Provenance DAG (EPV‑DAG) to concrete **SymbolCarrier** nodes and to the **external** `TransformerRole` that produced or interpreted the evidence.                                | Stops “weightless claims” and self‑justifying text.        |\n| **CC‑A10.2 (SCR)**                      | Any `Γ_epist^synth` operation SHALL output an **SCR** listing all symbol carriers materially used in the aggregate `U.Episteme`.                                                                                                        | Prevents source loss during aggregation.                   |\n| **CC‑A10.3 (RSCR)**                     | Any `Γ_epist^compile` operation SHALL output an **RSCR** adapted to the target bounded context (vocabularies, units) with publication‑grade identifiers/hashes; SCR→RSCR MUST preserve carrier identity/integrity.                      | Keeps releases auditable and context‑consistent.           |\n| **CC‑A10.4 (Resolution)**               | Every provenance/evidence node in the dependency graph MUST be resolvable to an SCR/RSCR entry. Unresolved links invalidate the claim.                                                                                                  | Eliminates dangling references and unverifiable citations. |\n| **CC‑A10.5 (Scope Separation)**         | A single EPV‑DAG instance SHALL NOT mix design‑time MethodDescription nodes with run‑time Work traces. Bridges (“this run trace instantiates that spec”) MUST be explicit.                                                                     | Avoids conflating intent and execution.                    |\n| **CC‑A10.6 (Externality)**              | The evidencing `TransformerRole` MUST be **external** to the holon under evaluation (A.12). Reflexive cases require modelling a meta‑holon and an external mirror.                                                                      | Prevents self‑creation/self‑evidence paradoxes.            |\n| **CC‑A10.7 (Temporal Coverage)**        | For `Γ\\_time` claims, interval coverage MUST be monotone and fully specified; gaps/overlaps require explicit justification or rejection.                                                                                                 | Stops invalid time‑series aggregation.                     |\n| **CC‑A10.8 (Integrity & Immutability)** | SCR/RSCR entries MUST include version/date and checksums; published SCR/RSCR are immutable—updates create a new revision id with a pointer to the prior one.                                                                            | Guards against silent drift and tampering.                 |\n| **CC‑A10.9 (Holarchy Firewall)**        | EPV‑DAG MUST use provenance edges only; mereological edges (`ComponentOf`, `MemberOf`, `PortionOf`, `PhaseOf`, etc.) MUST NOT appear in EPV‑DAG; conversely, provenance edges MUST NOT be used to build holarchies.                     | Keeps part‑whole and evidence semantics disjoint.          |\n| **CC‑A10.10 (Γ\\_sys Anchors)**          | Physical claims aggregated by `Γ_sys` MUST reference measurement models (quantity, unit, uncertainty), boundary conditions, and calibration carriers.                                                                                   | Ensures physical plausibility and comparability.           |\n| **CC‑A10.11 (Γ\\_method Anchors)**       | For order‑sensitive composition, design‑time MUST include a **Method Instantiation Card (MIC)** (Precedes/Choice/Join, guards, exceptions); run‑time traces MUST record `happenedBefore` and reference the MethodDescription they instantiate. | Preserves order semantics and reproducibility.             |\n| **CC‑A10.12 (Γ\\_work Anchors)**         | Resource spending/yield claims MUST be evidenced by instrumented carriers (meters, logs) and their MethodDescriptions; resource **rosters** MUST NOT be conflated with SCR/RSCR.                                                               | Distinguishes cost accounting from knowledge carriers.     |\n\n**Manager’s audit (non‑normative, quick):** For any claim, ask **What carriers? Which system? Which method? When?** If any answer is missing, A.10 is not satisfied.\n\n",
        "consequences": "### A.10:7 - Consequences\n\n| Benefit                           | Why it matters                                                                  | Trade‑off / Mitigation                                                                                                                |\n| --------------------------------- | ------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------- |\n| **Cross‑scale reproducibility**   | Any composite metric or argument can be walked back to its carriers and method. | **Overhead** of maintaining SCR/RSCR. *Mitigation:* keep entries minimal but complete; use checklists from the pedagogical companion. |\n| **Design/run clarity**            | Intent (MethodDescription) is cleanly separated from execution (Work traces).          | **Discipline** needed at boundaries. *Mitigation:* MIC templates; explicit “instantiates” bridges.                                    |\n| **Objective evidence**            | External `TransformerRole` eliminates self‑evidence loops.                      | **Reflexive systems** require a mirror meta‑holon. *Mitigation:* provide a “reflexive modelling” appendix with examples.              |\n| **Comparable numbers over time**  | Temporal coverage invariants prevent “trend” claims built on gaps.              | **Extra dating work** for legacy data. *Mitigation:* allow provisional labels until dating is completed.                              |\n| **Safe composition of knowledge** | SCR/RSCR keep sources intact as Γ\\_epist composes epistemes.                    | **Initial friction** in teams new to carrier thinking. *Mitigation:* start with “top‑10 carriers per claim” rule, expand as needed.   |\n| **Feeds Trust Calculus (B.3)**    | Anchors provide the inputs (R, CL, etc.) needed to score confidence.            | —                                                                                                                                     |\n\n",
        "rationale": "### A.10:8 - Rationale (SoTA alignment, reader‑friendly)\n\n* **Metrology & assurance.** The requirement to name quantities, units, uncertainty, calibration carriers reflects long‑standing metrology practice and modern assurance cases: numbers are only comparable when their **measurement models** are stated.\n* **Knowledge provenance.** The EPV‑DAG and SCR/RSCR embody post‑2015 best practices in provenance for knowledge artefacts: keep a complete, machine‑checkable trail from claims to carriers; separate provenance from part‑whole.\n* **Temporal reasoning.** Monotone coverage (no unexplained gaps/overlaps) aligns with temporal knowledge graph practice and avoids “impossible histories.”\n* **Holonic parsimony.** By drawing a firewall between **mereology** (A.14) and **provenance**, A.10 prevents semantic leakage and keeps the holarchy well‑typed.\n* **Role–Method–Work clarity.** Anchoring explicitly rides on A.15: **roles** act via **methods** specified at design‑time and produce **work** observed at run‑time. This keeps agency, policy, and execution disentangled yet connected.\n\n",
        "relations": "### A.10:9 - Relations\n\n* **Builds on:** A.1 Holonic Foundation; A.4 Temporal Duality; **A.12 Transformer Externalization**; **A.14 Advanced Mereology**; **A.15 Role–Method–Work Alignment**.\n* **Constrains / Used by:** B.1 (all Γ‑flavours: `Γ_sys`, `Γ_epist`, `Γ_method`, `Γ\\_time`, `Γ_work`); B.1.1 (Dependency Graph & Proofs).\n* **Enables:** **B.3 Trust Calculus** (R/CL inputs, auditability); B.4 Canonical Evolution Loop (clean design/run bridges).\n",
        "migration_(practical_and_brief)": "### A.10:10 - Migration (practical and brief)\n\nApply these text edits:\n\n1. **Terminology**\n\n   * `manifest` → **“Symbol Carrier Register (SCR)”**; `release manifest` → **“Release SCR (RSCR)”**.\n   * `creator` / `observer` (as internal evidencer) → **`TransformerRole (external)`**.\n   * “symbol register” (ambiguous) → **“Symbol Carrier Register (SCR)”**.\n   * Keep **resource rosters** in `Γ_work` separate from SCR/RSCR.\n\n3. **Boilerplate inserts**\n\n   * In **A.10** (this pattern): retain definitions of **EPV‑DAG**, **SCR/RSCR**, and the flavour‑specific anchors.\n   * In **B.1.3 (`Γ_epist`)**: add the **Obligations — SCR/RSCR** block (“`Γ_epist^synth` SHALL output SCR… `Γ_epist^compile` SHALL output RSCR…”).\n   * In **B.1.5 (`Γ_method`)**: ensure **MIC** is referenced (Precedes/Choice/Join, guards, exceptions) and run‑time traces reference the **MethodDescription** they instantiate.\n   * In **B.1.6 (`Γ_work`)**: say “resource rosters are not SCR/RSCR; anchor meter/log readings via EPV‑DAG.”\n",
        "a.10:end": "### A.10:End\n"
      },
      "content": "### A.10:End\n",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.11",
      "title": "Ontological Parsimony (C‑5)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.11 - Ontological Parsimony (C‑5)\n\n*“Add only what you cannot subtract.”*\n",
        "context": "### A.11:1 - Context\n\nThe FPF kernel aspires to remain **small enough to learn in a week** yet **broad enough** to model engines, proofs and budgets alike. Unchecked growth of primitives—well‑known from earlier “enterprise ontologies”—bloats diagrams, stalls tooling and intimidates new adopters. C‑5 therefore demands *minimal‑sufficiency*: a new core concept enters the kernel **only** when all routes of composition, refinement or role‑projection fail to express it without semantic loss.\n\n",
        "problem": "### A.11:2 - Problem\n\n| Pathology         | Real‑world symptom                                                                 |\n| ----------------- | ---------------------------------------------------------------------------------- |\n| **Concept creep** | Near‑synonyms proliferate (`U.Worker`, `U.Employee`, `U.Staff`), breaking queries. |\n| **Zombie types**  | Legacy primitives linger unused yet block name space.                              |\n| **Tool churn**    | Every fresh primitive forces IDE, validator and dashboard updates.                 |\n\nResult: steep learning curves, fragile integrations, eroded trust in “first‑principles” promises.\n\n",
        "forces": "### A.11:3 - Forces\n\n| Force                            | Tension                                                            |\n| -------------------------------- | ------------------------------------------------------------------ |\n| **Expressiveness vs Simplicity** | Fine granularity helps static checks ↔ fewer nouns aid cognition.  |\n| **Inclusivity vs Purity**        | New domains want vocabulary ↔ kernel must not be a dumping ground. |\n| **Evolution vs Stability**       | Framework grows ↔ users depend on a stable core.                   |\n| **Prestige vs Utility**          | Authors enjoy naming things ↔ every name tcharacteristics everyone else.      |\n\n",
        "solution": "### A.11:4 - Solution — Four‑Gate **Minimal‑Sufficiency Protocol**\n\nA proposal to add a `U.Type` or core relation **MUST** clear **all four gates** before admission and survives under a **Sunset Timer** thereafter.\n\n| Gate                      | Test question                                                                                         | Rationale                                             |\n| ------------------------- | ----------------------------------------------------------------------------------------------------- | ----------------------------------------------------- |\n| **G‑1 Composition**       | *Can existing primitives + roles/attributes express the concept without material loss?*               | Follows “composition over creation.”                  |\n| **G‑2 Non‑Redundancy**    | *Does the proposal overlap ≥ 80 % with anything already live?*                                        | Blocks synonyms.                                      |\n| **G‑3 Functional Naming** | *Does the chosen name state **what the thing does**, not what it *is made of*?*                       | Prevents vague catch‑alls; supports didactic clarity. |\n| **G‑4 Sharp Boundary**    | *Is there a one‑sentence litmus test that unambiguously includes or excludes any candidate instance?* | Ensures crisp taxonomy edges.                         |\n\n**Lifecycle — Sunset Timer**\nA cleared type enters the kernel **provisionally** with a timer (default = 4 quarters). If usage count remains zero at expiry, the type faces *Sunset Review*: delete, demote to plug‑in, or renew with fresh evidence.\n\n> *Manager’s mnemonic:* **“Compose, Unique, Functional, Crisp — or sunset.”**\n\n",
        "archetypal_grounding": "### A.11:5 - Archetypal Grounding\n\n| Gate    | **Rejected candidate** (why)                                                                                                                                                                               | **Accepted approach**           |\n| ------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------- |\n| **G‑1** | `U.CoolantPump` – expressible as `U.System:Pump` + `CoolingCirculatorRole`.                                                                                                                                | Composition via Role.           |\n| **G‑2** | `U.Actuator` vs existing `U.Transformer` (90 % overlap).                                                                                                                                                   | Retain broader `U.Transformer`. |\n| **G‑3** | `U.MiscellaneousObject` – name signals no function.                                                                                                                                                        | Reject; unclear purpose.        |\n| **G‑4** | `U.SmallPart` – boundary depends on subjective size.                                                                                                                                                       | Reject; fails crisp test.       |\n| —       | **`U.ProvenanceChain`** – required to record immutable evidence lineage; cannot be composed; functionally named; crisp membership rule (*“ordered list of Evidence Graph Ref with forward integrity hash”*). | Accepted, timer started.        |\n",
        "conformance_checklist": "### A.11:6 - Conformance Checklist\n\n| ID          | Requirement                                                                                                                                               | Didactic aim                                                 |\n| ----------- | --------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------ |\n| **CC‑OP 1** | A *Minimal‑Sufficiency Form* (≤ 1 page) **MUST** accompany every new kernel‑type proposal, documenting answers to Gates G‑1…G‑4 and a draft Sunset‑Timer. | Forces authors to think compositionally before adding nouns. |\n| **CC‑OP 2** | Kernel inventory tooling **SHALL** stamp each admitted type with `sunset_due: <date>` (default = +4 quarters).                                            | Schedules later pruning; no forgotten zombies.               |\n| **CC‑OP 3** | A quarterly *Usage Scan* **MUST** flag any core type with reference‑count = 0; flagged items enter Sunset Review automatically.                           | Turns parsimony into a living maintenance loop.              |\n| **CC‑OP 4** | Renaming, aliasing, or splitting an existing type **REQUIRES** re‑passing all four gates and documenting a migration note.                                | Prevents redundancy re‑entering via back door.               |\n| **CC‑OP 5** | Architheories **SHOULD** favour `Role` + attributes over proposing new domain types; proposals rejected when Gate G‑1 answer is “yes.”          | Extends parsimony culture beyond the kernel.                 |\n\n",
        "consequences": "### A.11:7 - Consequences\n\n| Benefit                            | Impact for engineer‑managers                                                   | Trade‑off / Mitigation                                                                   |\n| ---------------------------------- | ------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------- |\n| **Lean kernel**                    | Fewer primitives → faster onboarding & clearer mental map.                     | Initial author effort to fill Minimal‑Sufficiency Form; template wizard auto‑fills 70 %. |\n| **Reduced tool churn**             | Stable set of nouns keeps dashboards, linters, reasoners in sync for years.    | Occasionally slows acceptance of niche concepts; plug‑in layer absorbs urgency.          |\n| **Automatic house‑cleaning**       | Sunset cycle prevents accrual of deadwood.                                     | Rare risk of deleting a sleeper hit; renewal path allows appeal.                         |\n| **Encultured composition mindset** | Teams default to roles & attributes, boosting reuse and cross‑domain dialogue. | Requires role libraries and attribute taxonomies; provided in Part C.                    |\n\n",
        "rationale": "### A.11:8 - Rationale\n\n**Cognitive science** shows working memory tops out around 4 ± 1 unfamiliar chunks (Cowan 2021). Combining that with Gate discipline keeps kernel size tractable (≈ 40 primitives). **Software metrics** from lean DSLs (Rust traits, Kubernetes CRDs) reveal that compositional modelling reduces change propagation cost by \\~30 %. The Sunset Timer borrows from Kubernetes feature gate “alpha/beta/GA” progression model — proved effective at pruning half‑baked APIs.\n",
        "relations": "### A.11:9 - Relations\n\n| Relation          | Pattern                 | Interaction                                               |\n| ----------------- | ----------------------- | --------------------------------------------------------- |\n| **Builds on**     | A 8 Universal Core      | A candidate must already pass the Three‑Domain Test.      |\n| **Supports**      | A 7 Strict Distinction  | Prevents near‑duplicate roles that blur layer boundaries. |\n| **Feeds**         | B 5 Kernel Change‑Log   | Records admissions, renames, sunsets.                     |\n| **Complementary** | A 10 Evidence Graph Referring | Proposals cite evidence of irreducibility.                |\n\n",
        "illustrative_uses_(2022_–_2025)": "### A.11:10 - Illustrative Uses (2022 – 2025)\n\n* **Robotics CAL 2023** – `U.LiDARSensor` rejected (Gate G‑1 passed via role composition), saving three schema migrations.\n* **Green‑Finance CAL 2024** – `U.CarbonCredit` admitted provisionally, but Sunset Review (usage = 0) demoted it to sector plug‑in, avoiding kernel noise.\n* **Neuro‑informatics 2025** – `U.ProvenanceChain` accepted; by Q3 its heavy reuse in three architheories lifted timer and marked it *established*.\n\n",
        "open_questions": "### A.11:11 - Open Questions\n\n1. **Hard size cap** — should the kernel enforce an absolute limit (e.g., 64 live types) beyond which any new entry forces retirement of an old one?\n2. **Semantic similarity tooling** — can embedding models automate Gate G‑2 overlap detection reliably across domains?\n3. **Gate calibration** — is default Sunset Timer (4 quarters) optimal for research‑oriented architheories with slower uptake?\n",
        "a.11:end": "### A.11:End\n"
      },
      "content": "### A.11:End\n",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.12",
      "title": "External Transformer & Reflexive Split",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.12 - External Transformer & Reflexive Split\n",
        "intent_&_context": "### A.12:1 - Intent & Context\n\nThe principle of causality is the bedrock of engineering and scientific reasoning: every change has a cause. In FPF, this translates to a strict architectural rule: **no \"self-magic.\"** An action cannot happen without an actor. This pattern establishes the formal mechanism for modeling causality, ensuring that every transformation is attributed to an explicit, external agent.\n\nThis pattern operationalizes the **Agent Externalization Principle (C-2)**. It builds directly upon:\n*   **A.3 (Transformer Constitution):** Which defines the core quartet of action: the `Agent` (who acts), the `MethodDescription` (the recipe), the `Method` (the capability), and the `Work` (the event).\n*   **A.2 (Contextual Role Assignment):** Which provides the universal syntax `Holder#Role:Context` for defining agents.\n\nThe intent of this pattern is twofold:\n1.  To mandate that every transformation is modeled as an interaction between a distinct **Agent** (playing a `TransformerRole`) and a distinct **Target** across a defined **Boundary**.\n2.  To provide a rigorous pattern, the **Reflexive Split**, for modeling systems that appear to act upon themselves (e.g., self-calibration, self-repair) without violating the principle of external causality.\n",
        "problem": "### A.12:2 - Problem\n\nWithout a strict rule of agent externalization, models become ambiguous and untraceable, leading to critical failures in design and audit:\n\n1.  **Causality Collapse (\"Self-Magic\"):** Phrases like \"the system configures itself\" or \"the document updates itself\" create a causal black hole. It becomes impossible to answer the question, \"What *caused* this change?\" This makes debugging, root cause analysis, and assigning responsibility impossible.\n2.  **Audit Dead-Ends:** An auditor tracing a change finds that the system is its own justification. There is no external evidence, no log from an independent actor, and therefore, no way to verify the integrity of the transformation. This is a direct violation of **Evidence Graph Referring (A.10)**.\n3.  **Hidden Dependencies:** In a \"self-healing\" system, the healing mechanism (the regulator) and the operational part (the regulated) are modeled as a single monolithic block. This hides the critical internal dependency between them. A failure in the regulator might go unnoticed until the entire system collapses, because its role was never made explicit.\n",
        "forces": "### A.12:3 - Forces\n\n| Force | Tension |\n| :--- | :--- |\n| **Causal Clarity vs. Modeling Simplicity** | The need to explicitly model every cause-and-effect link vs. the desire to keep diagrams simple by representing self-regulating systems as single blocks. |\n| **Objectivity vs. Internal States** | The need for an external, objective observer/actor to ground all claims vs. the reality that many systems have internal feedback loops that control their own state. |\n| **Accountability vs. Automation** | In fully automated systems, it can be tempting to say \"the system did it,\" but for assurance and safety, we must always be able to trace an action back to a specific, responsible component. |\n",
        "solution": "### A.12:4. Solution\n\nThe solution is a two-part architectural mandate: **(1)** all transformations must be modeled with an external agent, and **(2)** apparent self-transformation must be modeled using the **Reflexive Split**.\n",
        "a.12:4.1___the_principle_of_the_external_transformer": "### A.12:4.1 - The Principle of the External Transformer\n\nEvery transformation in FPF is a `U.Work` event that is the result of an **Agent** acting upon a **Target**.\n\n*   **The Agent:** The agent is a **Contextual Role Assignment** of the form `System#TransformerRole:Context`. This is the cause, the \"doer.\"\n*   **The Target:** The target is the `U.Holon` being changed. This can be another `U.System` or the **symbol carrier** of a `U.Episteme`.\n*   **The Boundary:** The agent and the target are always separated by a `U.Boundary` and interact through a `U.Interaction`.\n\n**Crucial Rule:** The `holder` of the Agent's `U.RoleAssignment` **cannot** be the same holon instance as the Target.\n> `holder(Agent) ≠ Target`\n\nThis simple inequality is the core of the externalization principle. It constitutionally forbids self-magic.\n\n#### A.12:4.1.1 - Reflexivity vs cross‑reference (normative note)\n\nFPF distinguishes **reflexive transformation** from **episteme‑level reference**.  \n*Reflexive* cases (e.g., “self‑calibration”) MUST be modeled by the **Reflexive Split** (Regulator→Regulated) and remain within the **world** ReferencePlane.  \nWhen a claim **refers to** another claim/episteme, model it with **epistemeAbout(x,y)** and set **ReferencePlane(x)=episteme**. Such references **do not perform transformations** and **MUST NOT** be used to bypass the external‑agent rule. Evaluation of chains of episteme‑about relations MUST remain **acyclic within a single evaluation chain**; otherwise, abstain and request a split or external evidence.\n\n",
        "a.12:4.2___the_reflexive_split_pattern": "### A.12:4.2 - The Reflexive Split Pattern\n\nSo, how do we model a system that *does* act on itself, like a self-calibrating sensor? We use the **Reflexive Split**. We recognize that the system is not a monolith; it contains at least two distinct functional parts.\n\n**The Procedure:**\n\n1.  **Identify the Roles:** Decompose the system's function into two distinct roles: the part that *regulates* and the part that *is regulated*.\n2.  **Model as Two Holons:** Model these two parts as two distinct (though possibly tightly coupled) `U.System` holons, even if they share the same physical casing.\n3.  **Define the Internal Boundary:** Model the interface between them as an internal `U.Boundary` with a defined `U.Interaction` (e.g., a data bus, a mechanical linkage).\n4.  **Assign the Transformer Role:** The regulating part becomes the `holder` of the `TransformerRole`. The regulated part becomes the `Target`.\n\nNow, the \"self-action\" is modeled as a standard, external transformation that just happens to occur *inside* the larger system's boundary. Causality is restored, and the model becomes auditable.\n\n**Didactic Note for Engineers & Managers: The \"Two Hats\" Analogy**\n\nThink of the Reflexive Split like a manager who needs to review their own work. To do it properly, they must metaphorically wear \"two hats.\"\n*   **Hat 1: The Doer.** They perform the task.\n*   **Hat 2: The Reviewer.** They step back, put on their \"reviewer hat,\" and inspect the work *as if* it were done by someone else.\n\nThe Reflexive Split formalizes this. The \"Doer\" is the **Regulated** subsystem. The \"Reviewer\" is the **Regulator** subsystem, which plays the `TransformerRole`. By modeling them as two separate entities, we make the internal quality control loop explicit and prevent the logical error of a system magically grading its own homework.\n",
        "archetypal_grounding": "### A.12:5 - Archetypal Grounding\n\nThe principle of external causality and the Reflexive Split pattern are universal. They apply equally to physical systems, epistemic artifacts, and socio-technical organizations.\n\n| Scenario | Naive Description (\"Self-Magic\") | FPF Model with Reflexive Split | `Agent` & `Target` |\n| :--- | :--- | :--- | :--- |\n| **System Archetype** | \"The robot calibrates itself.\" | The robot is modeled as a composite holon containing two subsystems: <br> 1. **`CalibrationController`** (`U.System`) <br> 2. **`SensorSuite`** (`U.System`) <br> They interact across an internal data bus (`U.Boundary`). | **Agent:** `CalibrationController#TransformerRole:RobotInternals` <br> **Target:** `SensorSuite` |\n| **Episteme Archetype** | \"The document automatically updates its cross-references.\" | The \"document\" is a system comprising: <br> 1. **`UpdateScript`** (a `U.System` that executes code) <br> 2. **`DocumentFile.xml`** (a `U.System` acting as a symbol carrier) <br> They interact via the file system (`U.Boundary`). | **Agent:** `UpdateScript#TransformerRole:DocumentSystem` <br> **Target:** `DocumentFile.xml` (the carrier of the `U.Episteme`) |\n| **Socio-Technical Archetype** | \"The team reviews its own performance.\" | The team is modeled as a collective `U.System` that enacts two roles at different times: <br> 1. **`ExecutionTeam`** (doing the sprint work) <br> 2. **`ReviewTeam`** (conducting the retrospective) <br> The \"boundary\" is the formal separation created by the retrospective ceremony. | **Agent:** `Team#ReviewerRole:RetrospectiveContext` <br> **Target:** The `U.Work` logs and artifacts produced by the `Team#ExecutionRole`. |\n\n**Key takeaway from grounding:**\nThese examples demonstrate that there is *no such thing as self-action* in a well-formed model. Every action, even an internal one, can and must be decomposed into an external interaction between a distinct agent and a distinct target. This makes the causal chain explicit and auditable in all domains.\n",
        "conformance_checklist": "### A.12:6 - Conformance Checklist\n\nTo enforce the principles of externalization and causal clarity, all FPF models must adhere to the following normative checks.\n\n| ID | Requirement (Normative Predicate) | Purpose / Rationale |\n| :--- | :--- | :--- |\n| **CC-A12.1 (External Agent Mandate)** | Every transformation (`U.Work`) **MUST** be attributed to an Agent (`U.RoleAssignment`) whose `holder` is distinct from the target holon. | This is the core rule that forbids self-magic. It ensures every action has an identifiable, external cause. |\n| **CC-A12.2 (Reflexive Split for Self-Action)** | Any narrative of \"self-modification\" (e.g., self-repair, self-configuration) **MUST** be modeled using the Reflexive Split pattern. | Forces the modeler to make internal control loops explicit by identifying the distinct `Regulator` (Agent) and `Regulated` (Target) subsystems. |\n| **CC-A12.3 (Boundary Explicitness)** | The `U.Boundary` and `U.Interaction` between the Agent and the Target **MUST** be explicitly modeled. | Makes interfaces a first-class citizen of the model. Prevents hidden dependencies and ensures interactions are auditable. |\n| **CC-A12.4 (Episteme Carrier as Target)** | When a `U.Episteme` is modified, the `Target` of the transformation **MUST** be its **symbol carrier** (`U.System`), not the `U.Episteme` itself. | Reinforces **Strict Distinction (A.7)**. Knowledge doesn't change by magic; a physical agent must act on its physical representation. |\n| **CC-A12.5 (No Self-Evidence)** | The Agent that performs a transformation **cannot** be the sole source of evidence for the success or properties of that transformation. Evidence **MUST** be anchored via an independent `Observer`. | Prevents conflicts of interest in assurance. The `Transformer` does the work; a separate `Observer` (another RoleAssignment) validates it. This aligns with **A.10 (Evidence Graph Referring)**. |\n",
        "consequences": "### A.12:7 - Consequences\n\n| Benefits | Trade-offs / Mitigations |\n| :--- | :--- |\n| **Causal Traceability & Auditability:** Every change is linked to a specific agent and interaction, creating a complete and unambiguous audit trail. This is essential for root cause analysis and accountability. | **Increased Model Granularity:** The Reflexive Split requires creating more model elements than a simple monolithic block. *Mitigation:* This is not a bug, but a feature. The \"extra\" elements represent real, critical parts of the system's architecture that were previously hidden. FPF tooling can help manage this via views that can \"collapse\" a split system for high-level diagrams. |\n| **Architectural Honesty:** The pattern forces designers to be explicit about internal control loops, interfaces, and dependencies, leading to more robust and well-understood system architectures. | **Requires a Shift in Thinking:** Modelers accustomed to \"self-x\" narratives must learn to think in terms of external interactions. *Mitigation:* The \"Two Hats\" analogy and clear archetypes (Section 5) serve as powerful didactic tools to facilitate this shift. |\n| **Enables True Modularity:** By making interfaces explicit, the pattern supports modular design. A `Regulator` subsystem could potentially be swapped out for a different one as long as it respects the same `U.Interaction` Standard. | - |\n| **Unlocks Deeper Analysis:** Once an internal control loop is made explicit, it can be formally analyzed for stability, performance, and failure modes using tools like the Supervisor-Subsystem Feedback Loop pattern (B.2.5). | - |\n",
        "rationale": "### A.12:8 - Rationale\n\nThe principle of externalization is not an arbitrary rule imposed by FPF; it is a distillation of foundational concepts from multiple rigorous disciplines.\n\n*   **Cybernetics & Control Theory:** As Ashby's Law of Requisite Variety and modern control theory (e.g., Matni et al., 2024) demonstrate, regulation is fundamentally an **interaction across a boundary** between a controller and a plant. Conflating the two hides the causal structure and makes stability analysis impossible. The Reflexive Split is the FPF's implementation of this core cybernetic principle.\n*   **Physics (Constructor Theory):** As discussed in A.3, Constructor Theory recasts physics in terms of what transformations are possible. A transformation is always performed by a \"constructor\" (our `Transformer`) on a substrate. The theory does not contain \"self-constructing\" substrates. FPF's externalist stance is fully aligned with this physical worldview.\n*   **Philosophy of Science (Objectivity):** The scientific method is built on the principle of external observation and verification. A theory cannot validate itself; its predictions must be checked by an independent experiment. The `No Self-Evidence` rule (CC-A12.5) is the direct implementation of this principle in the FPF's assurance calculus.\n*   **Software Engineering (Dependency Inversion):** The principle that high-level modules should not depend on low-level modules, but both should depend on abstractions, is a form of externalization. It enforces clean separation and makes systems more modular and testable. The explicit `U.Boundary` in our pattern serves the same architectural purpose as a well-defined interface in software.\n\nBy mandating externalization, FPF is not adding bureaucratic overhead. It is enforcing a set of first principles that are demonstrably essential for building complex systems that are understandable, auditable, and trustworthy.\n",
        "relations": "### A.12:9 - Relations\n\n*   **Directly Implements:** `C-2 Agent Externalization Principle`.\n*   **Builds Upon:**\n    *   `A.1 Holonic Foundation`: Provides the `U.System` and `U.Episteme` holons that act as agents and targets.\n    *   `A.2 Role Taxonomy`: Provides the Contextual Role Assignment (`U.RoleAssignment`) mechanism to define the Agent.\n    *   `A.3 Transformer Constitution`: Defines the `TransformerRole` that the Agent plays.\n*   **Enables and Constrains:**\n    *   `A.10 Evidence Graph Referring`: Provides the causal structure (who did what) that evidence must be anchored to.\n    *   `B.2 Meta-Holon Transition (MHT)`: A Reflexive Split is often the first step in identifying an emergent supervisory layer that may later be promoted to a new meta-holon.\n    *   `B.2.5 Supervisor-Subsystem Feedback Loop`: This pattern provides the detailed architecture for the `Regulator-Regulated` interaction that the Reflexive Split reveals.\n",
        "a.12:end": "### A.12:End\n"
      },
      "content": "### A.12:End\n",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.13",
      "title": "The Agential Role & Agency Spectrum",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.13 - The Agential Role & Agency Spectrum\n\n> *“Agency is not a kind of thing; it is a way some systems operate.”*\n",
        "intent_&_context": "### A.13:1 - Intent & Context\n\nThe concept of \"agency\"—the capacity of an entity to act purposefully—is central to engineering, biology, and AI, yet it remains one of the most overloaded and ambiguous terms. Without a precise, falsifiable, and substrate-neutral definition, models of autonomous systems risk descending into \"self-magic,\" where actions have no clear cause and accountability is lost.\n\nThis pattern builds directly upon the foundations laid in the FPF Kernel to provide that definition. A.1 established that only a **`U.System`** can be the bearer (`holder`) of behavioral roles.  A.2.1 defined the universal `U.RoleAssignment` (`Holder#Role:Context`) as the canonical way to assign roles. A.3 and A.12 defined the `TransformerRole` and the principle of the external agent.\n\nThe intent of this pattern is to:\n1.  Formally define **agency** not as an intrinsic *type* of holon, but as a **contextual Role Assignment**.\n2.  Introduce a measurable, multi-dimensional **spectrum of agency** via a dedicated Characterization (`Agency-CHR`), moving beyond a simple binary \"agent/not-agent\" switch.\n3.  Provide a clear, **didactic grading system** that allows engineers and managers to assess and communicate the level of autonomy of any system in a consistent, evidence-backed manner.\n",
        "problem": "### A.13:2 - Problem\n\nIf agency is treated as a monolithic, intrinsic property or a mere label, four critical failure modes emerge, undermining the rigor of FPF:\n\n1.  **Episteme-as-Actor:** Models might incorrectly assign agency to knowledge artifacts (`U.Episteme`), leading to nonsensical claims like \"the specification decided to update the system.\" This is a direct violation of **Strict Distinction (A.7)**.\n2.  **Type Inflation:** Introducing a `U.Agent` as a new base type alongside `U.System` and `U.Episteme` would violate **Ontological Parsimony (C-5)** and create conflicts with the dynamic nature of roles. A system might act as an agent in one context and a passive component in another; a static type cannot capture this.\n3.  **Unfalsifiable Claims:** Without a measurable basis, \"agency\" becomes a subjective label. A team might call their system an \"agent\" for marketing purposes, but this claim has no verifiable meaning and cannot be audited, violating **Evidence Graph Referring (A.10)**.\n4.  **The Binary Trap:** A simple \"agent/not-agent\" classification is too coarse. It fails to distinguish between a simple thermostat, a predictive cruise control system, and a strategic, self-learning robotic swarm, even though their cognitive capabilities differ by orders of magnitude.\n",
        "forces": "### A.13:3 - Forces\n\n| Force | Tension |\n| :--- | :--- |\n| **Scientific Fidelity vs. Simplicity** | Contemporary science (e.g., Active Inference) models agency as a continuous, scale-free spectrum. FPF needs to honor this rigor while providing a simple, teachable model for practitioners. |\n| **Role vs. Type** | The intuition is to think of an \"Agent\" as a *type* of thing. FPF's architecture demands that it be modeled as a *role* to preserve dynamism and ontological hygiene. |\n| **Measurement vs. Label** | Engineers and managers need a quick, intuitive label (e.g., \"this is a Level 3 agent\"), while formal assurance requires a detailed, multi-dimensional, evidence-backed measurement. |\n| **System-only Action vs. Collective Action**| How does agency apply to groups like teams or swarms? This requires a clear link to the rule from A.1 that any *acting group* must be modeled as a `U.System`. |\n",
        "solution": "### A.13:4 - Solution\n\nFPF's solution is threefold: it defines an Agent via `U.RoleAssignment` (A.2.1), makes agency measurable with a dedicated Characterization, and provides a didactic summary via a graded scale.\n\n#### A.13:4.1 - The Core Definition: Agent as a Contextual Role Assignment\n\nAn **\"Agent\"** in FPF is not a fundamental type. It is a convenience term (a Register 1 / Register 2 label) for a specific kind of **Contextual Role Assignment (`U.RoleAssignment`)**:\n\n> `Agent ≍ U.RoleAssignment(holder: U.System, role: U.AgentialRole, context: U.BoundedContext)`\n\nThis means an Agent is simply a **`U.System`** that is currently playing an **`AgentialRole`** within a specific **`U.BoundedContext`**.\n\n*   **No `U.Agent` Type:** To be clear, there is **no `U.Agent` base type** in the FPF Kernel. This avoids type inflation and preserves the dynamic nature of roles.\n*   **Epistemes Cannot Be Agents:** As the `holder` must be a `U.System`, this definition constitutionally forbids `U.Episteme`s from being agents, preventing the \"episteme-as-actor\" category error.\n*   **Canonical Syntax:** The technical notation for an agent is `System#AgentialRole:Context`.\n\n#### A.13:4.2 - The `AgentialRole` and its Specializations\n\n*   **`U.AgentialRole`:** This is the abstract `U.Role` that grants a `U.System` the capacity for goal-directed action within a context. It is the \"license to act.\"\n*   **Specialized Roles:** More specific behavioral roles like `TransformerRole` and `ObserverRole` are considered **specializations or sub-roles** of `AgentialRole`. They describe *what kind* of agential action is being performed at a given moment.\n    *   A system playing `TransformerRole` is an Agent *that is currently modifying another holon*.\n    *   A system playing `ObserverRole` is an Agent *that is currently gathering information*.\n    This creates a clean hierarchy: a `Transformer` is always an `Agent`, but an `Agent` is not always a `Transformer` (it could be observing, planning, or idle).\n\n#### A.13:4.3 - Measuring Agency: The `Agency-CHR` and the Spectrum\n\nAgency is not a binary switch; it is a multi-dimensional spectrum of capabilities. FPF models this using a dedicated architheory, **`Agency-CHR` (C.9)**, which is a **Characterization** that attaches a set of measurable properties to a `U.RoleAssignment`.\n\nThe `Agency-CHR` profile is grounded in contemporary research (e.g., Active Inference, Basal Cognition) and includes the following key characteristics. Each is measured for a specific agent in a specific context and must be backed by evidence (A.10).\n\n1.  **Boundary Maintenance Capacity (BMC):** The ability of the system to maintain its structural and functional integrity against perturbations. *(How robust is it?)*\n2.  **Predictive Horizon (PH):** The temporal or causal depth of the agent's internal model. *(How far ahead can it \"see\"?)*\n3.  **Model Plasticity (MP):** The rate at which the agent can update its internal model (`U.GenerativeModel`) in response to prediction errors (`U.Error`). *(How quickly can it learn?)*\n4.  **Policy Enactment Reliability (PER):** The probability that the agent will successfully execute its chosen `U.Method` under operational conditions. *(How reliably does it do what it decides to do?)*\n5.  **Objective Complexity (OC):** A measure of the complexity of the `U.Objective` the agent can pursue, from simple set-points to abstract, multi-scale goals.\n\n#### A.13:4.4 - The Agency Grade (Didactic Layer)\n\nWhile the multi-dimensional `Agency-CHR` profile is essential for formal assurance, engineers and managers need a simpler, at-a-glance summary. The **Agency Grade** is a **non-normative, didactic** scale from 0 to 4 that synthesizes the CHR profile into an intuitive level of autonomy.\n\n| Grade | Label | Typical `Agency-CHR` Profile (Conservative Lower Bound) | Archetypal Example |\n| :--- | :--- | :--- | :--- |\n| **0** | **Non-Agential** | `BMC ≈ 0`, `PH ≈ 0`, `MP ≈ 0` | A rock, a document, a passive structural component. |\n| **1** | **Reactive** | `BMC > 0`, `PH ≈ 0`, `MP ≈ 0` | A thermostat; a simple feedback controller. Follows fixed rules. |\n| **2** | **Predictive** | `BMC > 0`, `PH > 0`, `MP ≈ 0` | A model-predictive controller with a fixed model; a chess engine that plans moves but doesn't learn new strategies. |\n| **3** | **Adaptive** | `BMC > 0`, `PH > 0`, `MP > 0` | A self-calibrating sensor system; a machine learning agent that updates its model with new data. |\n| **4** | **Reflective/Strategic** | High `BMC`, `PH`, `MP`, `PER`, and `OC`. Capable of meta-cognition (reasoning about its own reasoning) and pursuing abstract goals. | An autonomous R&D system; a cohesive, self-organizing DevOps team. |\n\n**Crucial Distinction:** The `Agency-CHR` profile is the **normative evidence**. The Grade is a **pedagogical shortcut**. An artifact cannot claim a grade without having a corresponding, auditable CHR profile to back it up.\n",
        "archetypal_grounding": "### A.13:5 - Archetypal Grounding\n\nThe universal pattern of agency, defined as a `Contextual Role Assignment` and measured by the `Agency-CHR`, manifests across all domains. The following table demonstrates its application to the FPF's two primary archetypes: a `U.System` and a collective `U.System` (a team), while explicitly showing why a `U.Episteme` cannot be an agent.\n\n| Archetype | Holder (`U.System`) | Role & Context (`#Role:Context`) | `Agency-CHR` Profile Sketch | Resulting Agency Grade |\n| :--- | :--- | :--- | :--- | :--- |\n| **Simple Controller** | `Thermostat_Model_T800` | `#AgentialRole:HomeHeatingSystem` | `BMC`: High (maintains temp). <br> `PH`: Zero (no prediction). <br> `MP`: Zero (fixed logic). <br> `PER`: Very High. <br> `OC`: Low (single set-point). | **Grade 1 (Reactive)** |\n| **Advanced Controller** | `PredictiveCruiseControl_v3` | `#AgentialRole:VehicleDynamics` | `BMC`: High. <br> `PH`: High (predicts traffic flow). <br> `MP`: Zero (fixed model). <br> `PER`: High. <br> `OC`: Medium (optimization). | **Grade 2 (Predictive)** |\n| **Learning System** | `SelfCalibratingSensorArray` | `#AgentialRole:IndustrialProcess` | `BMC`: High. <br> `PH`: High. <br> `MP`: Medium (learns drift). <br> `PER`: High. <br> `OC`: Medium. | **Grade 3 (Adaptive)** |\n| **Collective Agent** | `DevOpsTeam_Phoenix` (a collective `U.System`) | `#AgentialRole:ProjectPhoenix` | `BMC`: High (maintains velocity). <br> `PH`: High (sprint planning). <br> `MP`: High (retrospectives). <br> `PER`: Medium-High. <br> `OC`: High (abstract business goals). | **Grade 4 (Reflective/Strategic)** |\n| **Knowledge Artifact** | `ISO_26262_Standard.pdf` (`U.Episteme`) | **N/A** (Cannot be a holder of an `AgentialRole`) | N/A | **Grade 0 (Non-Agential)** |\n\n**Key takeaway from grounding:**\nThis table makes the abstract model concrete. It shows that the FPF agency model can precisely differentiate between simple controllers and complex learning systems. It also reinforces the **Strict Distinction** principle: the ISO standard (`U.Episteme`) is a crucial **justification (`justification?`)** for the actions of an agent (like the DevOps team), but it is never an agent itself.\n",
        "conformance_checklist": "### A.13:6 - Conformance Checklist\n\nTo ensure the agency model is applied rigorously and consistently, all FPF artifacts must adhere to the following normative checks.\n\n| ID | Requirement (Normative Predicate) | Purpose / Rationale |\n| :--- | :--- | :--- |\n| **CC-A13.1 (Holder Type)** | The `holder` of a `U.RoleAssignment` with `role: U.AgentialRole` **MUST** be a `U.System`. | Prevents the \"episteme-as-actor\" category error. Enforces **Strict Distinction (A.7)**. |\n| **CC-A13.2 (RoleAssignment Mandate)** | Any claim of agency **MUST** be represented by a complete `U.RoleAssignment` instance, including an explicit `holder`, `role`, and `context`. | Ensures that agency is always modeled as contextual and bound to a specific bearer, not as a free-floating property. |\n| **CC-A13.3 (CHR Evidence)** | Any claim about an Agent's grade or level of autonomy **MUST** be substantiated by an auditable `Agency-CHR` profile with Evidence Graph Ref (A.10). | Makes claims of agency falsifiable and prevents \"agency by marketing.\" |\n| **CC-A13.4 (Grade is Didactic)**| The **Agency Grade (0-4)** **SHALL NOT** be used as a normative input for formal reasoning. It is a didactic summary of the `Agency-CHR` profile. | Prevents oversimplification in formal models. The detailed profile, not the summary grade, must be used for assurance cases. |\n| **CC-A13.5 (Collective as System)** | To claim agency for a collective (e.g., a team, a swarm), the collective **MUST** first be modeled as a `U.System` with a defined `U.Boundary` and a coordination `U.Method`. | Prevents the error of assigning agency to a mere set or collection (`MemberOf`). Aligns with **A.1** and **A.14**. |\n| **CC-A13.6 (MHT for Emergent Agency)** | If a collection of systems, previously non-agential or at a lower grade, develops a new supervisory structure and crosses a documented `Agency-CHR` threshold, a **Meta-Holon Transition (MHT, B.2)** **MUST** be declared. | Makes the emergence of collective agency an explicit, auditable event, preventing \"magic\" emergence. |\n",
        "consequences": "### A.13:7 - Consequences\n\n| Benefits | Trade-offs / Mitigations |\n| :--- | :--- |\n| **Category Safety & Clarity:** The pattern provides a clear, unambiguous definition of agency that prevents common modeling errors and is consistent across all of FPF. | **Increased Modeling Granularity:** Requires modelers to think in terms of Role-assignments and contexts, which is slightly more complex than just labeling something an \"Agent.\" *Mitigation:* The `Holon#Role:Context` syntax and tooling support make this manageable in practice. |\n| **Falsifiable & Measurable Agency:** By grounding agency in the `Agency-CHR`, the framework transforms a vague philosophical concept into a set of concrete, evidence-backed engineering properties. | **Measurement Effort:** Populating the `Agency-CHR` profile requires real work (testing, analysis, data gathering). *Mitigation:* The profile can be built iteratively. An initial estimate can be used, with the understanding that its `Reliability (R)` score is low until backed by evidence. |\n| **Scalable Autonomy Model:** The graded scale provides a sophisticated language for describing and comparing different levels of autonomy, from simple automation to strategic intelligence. | **Risk of Misinterpreting Grades:** The simple 0-4 scale could be misused as a simplistic marketing label. *Mitigation:* The normative requirement (**CC-A13.4**) to always link a grade to its underlying CHR profile acts as a guardrail against this. |\n| **Elegant Handling of Collectives:** The pattern provides a clean way to model the agency of teams, swarms, and organizations without violating ontological principles. | - |\n",
        "rationale": "### A.13:8 - Rationale\n\nThis pattern's strength comes from its synthesis of contemporary, post-2015 research into a single, operational model.\n\n*   **Grounded in Science:** The move away from a binary, type-based view of agency towards a **graded, spectrum-based model** is directly aligned with modern research in Active Inference (Friston et al.), Basal Cognition (Fields, Levin), and evolutionary cybernetics. The `Agency-CHR` provides a direct, practical implementation of these ideas.\n*   **Ontologically Sound:** By defining an Agent as a **Contextual Role Assignment**, the pattern avoids the ontological pitfalls of creating a new base type. It fully embraces the FPF's core architectural principle of separating **substance (`holder`)** from **function (`role`)** within a **context**. This aligns with best practices from foundational ontologies (like UFO) and the principles of **Strict Distinction (A.7)**.\n*   **Pragmatic and Actionable:** The pattern is designed for engineers and managers. The `Agency Grade` provides a quick communication tool, while the underlying `Agency-CHR` provides the detailed, auditable data needed for formal assurance and risk management. This duality satisfies both **Didactic Primacy (P-2)** and **Pragmatic Utility (P-7)**.\n\nIn essence, this pattern does not *invent* a new theory of agency. It **distills and operationalizes** the emerging scientific consensus, packaging it into a rigorous, falsifiable, and practical tool for the FPF ecosystem.\n",
        "relations": "### A.13:9 - Relations\n\n*   **Builds on:**\n    *   `A.1 Holonic Foundation`: Establishes that only `U.System`s can be bearers of behavioral roles.\n    *   `A.2 Role Taxonomy`: Provides the universal  Contextual Role Assignment (`U.RoleAssignment`) mechanism.\n    *   `A.12 External Transformer`: The actions of an Agent are modeled using the external transformer principle.\n*   **Coordinates with:**\n    *   `B.2 Meta-Holon Transition (MHT)`: A significant jump in the `Agency-CHR` of a collective can trigger an MHT.\n    *   `B.3 Trust & Assurance Calculus`: The `Agency-CHR` profile provides crucial inputs for assessing the reliability and safety of an autonomous system.\n    *   `D.2 Multi-Scale Ethics Framework`: The Agency Grade is used to determine the level of moral responsibility and accountability assigned to a system.\n*   **Instantiates:**\n    *   The `Agency-CHR` (C.9) architheory, which provides the formal definitions for the characteristics (BMC, PH, etc.).\n",
        "a.13:end": "### A.13:End\n"
      },
      "content": "### A.13:End\n",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.14",
      "title": "Advanced Mereology: Components, Portions, Aspects & Phases",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.14 - Advanced Mereology: Components, Portions, Aspects & Phases\n",
        "context_—_why_an_advanced_mereology?": "### A.14:1 - Context — why an advanced mereology?\n\nFPF’s holonic world is built from **part–whole** relations. Early drafts distinguished structural vs. conceptual parthood (e.g., **ComponentOf**, **ConstituentOf**) but practical modelling kept hitting two recurrent gaps:\n\n1. **Quantities vs. parts.** Engineers routinely need “some of the fuel”, “the first 10 pages”, “a 30% subset of data”. This is not a component; it is a **portion** of a stuff‑like whole, governed by measures and conservation.\n\n2. **Change vs. replacement.** Authors need to say “the prototype **before calibration**”, “v2 of the spec”, “shift 1 vs. shift 2 of the same run”. That is not a new whole; it is a **phase** of the same carrier across time.\n\nThis section introduces two **normative** sub‑relations of `partOf` that close those gaps and lock them to the rest of the kernel:\n\n* **PortionOf** — metrical, measure‑preserving parthood of stuffs and other measurables.\n* **PhaseOf** — temporal parthood of the *same* carrier across an interval.\n\nIt also restates guard‑rails that keep **roles** and **recipes** outside mereology (A.15), and clarifies how **MemberOf** fits (preview: **collections** are grounded constructively in **C.13 Compose‑CAL** via `Γ_m.set`; **collective agency** is handled outside mereology in **A.15 Role–Method–Work**).\n\n**Publication note (Working‑Model first).** Read A.14 together with **E.14 Human‑Centric Working‑Model** and **B.3.5 CT2R‑LOG**: publish relations on the **Working‑Model** surface; when assurance is sought, **ground downward**. For structural claims that require extensional identity, use the **Constructive** shoulder via **Compose‑CAL Γ_m (sum | set | slice)**; order/time stay outside mereology (Γ_time / Γ_method).\n",
        "problem": "### A.14:2 - Problem — what breaks without these distinctions?\n\nIf we only have “generic partOf” (plus Component/Constituent), four classes of errors appear:\n\n1. **Conservation errors.** Treating “20 L of fuel from Tank A” as a component leads to nonsense: adding and removing such “components” does not respect quantities; Γ\\_sys proofs violate Σ‑balance.\n\n2. **Temporal smearing.** Flattening “before/after”, or “v1/v2” into one timeless whole collapses history; Γ\\_time and Γ\\_method cannot justify order‑sensitive properties; audits cannot reproduce conditions.\n\n3. **Identity confusion.** Modelling “new version” as “new component” either breaks identity (it is still the *same* holon evolving) or hides a **Meta‑Holon Transition** when identity really changes.\n\n4. **Role leakage.** Functional/organisational roles sneak into part trees (“the PumpRole is part of the plant”), violating A.15 and making structural reasoning brittle.\n\n",
        "forces": "### A.14:3 - Forces\n\n| Force                              | Tension                                                                                                         |\n| ---------------------------------- | --------------------------------------------------------------------------------------------------------------- |\n| **Expressiveness vs. Parsimony**   | We need new relations (Portion, Phase) ↔ we must keep the catalogue minimal and orthogonal.                     |\n| **Universality vs. Domain nuance** | One set of rules must serve physical systems and epistemes ↔ measurement and time behave differently by domain. |\n| **Identity vs. Change**            | Preserve “the same carrier through change” ↔ allow explicit re‑identification when invariants fail.             |\n| **Static structure vs. Histories** | Part trees should be simple ↔ real work requires phased histories and measured slices.                          |\n",
        "solution": "### A.14:4 - Solution — extend the mereology catalogue, keep it clean\n\n**A.14 defines two additional sub‑relations of `partOf`** and **re‑affirms the firewall** between mereology and the role/recipe layer:\n\n1. **PortionOf** — for *measured* parts of a whole (stuffs and other extensives).\n2. **PhaseOf** — for *temporal* parts of the same carrier.\n3. **No roles/recipes in mereology.** `U.Role`, `U.Method`, `U.MethodDescription` are **never** parts (A.15).\n4. **MemberOf stays, but constructive aggregation and agency live elsewhere.** `MemberOf` remains available to state collections and collectives; **their collection‑as‑whole may be constructed via Γ\\_m.set (Compose‑CAL, C.13)**, while **composition and agency are handled in B.1.7 Γ\\_collective** (not in A.14).\n\nThe classical pair **ComponentOf** (structural, discrete) and **ConstituentOf** (conceptual, logical/epistemic) remain as in the kernel; A.14 only clarifies **how to tell them apart from Portion/Phase** (§ 6).\n",
        "formal_cores_(normative_semantics)": "### A.14:5 - Formal cores (normative semantics)\n\n#### A.14:5.1 - PortionOf — metrical part of a measurable whole\n\n**Intent.** Capture “some of the same stuff/extent”, governed by a measure that adds up.\n\n**Applicability.** Any `U.Holon` that carries an **extensive** measure μ on the chosen scope\n(examples: mass, volume, length‑of‑text, byte size, wall‑time budget).\n\n**Primitive.** `PortionOf(x, y)` means: *x is the same kind of stuff/content as y, but less*.\n\n**Axioms (A14‑POR‑\\*)**\n\n* **POR‑1 (Partial order).** PortionOf is reflexive, antisymmetric, transitive on its domain.\n* **POR‑2 (Metrical dominance).** If `x ProperPortionOf y` then `0 < μ(x) < μ(y)` for the agreed μ.\n* **POR‑3 (Additivity on disjoint portions).** If `x ⟂ y` (no overlap) and both PortionOf y, then `μ(x ⊔ y) = μ(x)+μ(y)` and `x ⊔ y PortionOf y`.\n* **POR‑4 (Kind integrity).** x and y must share the same **measure kind** and **unit** (or a declared conversion).\n* **POR‑5 (Boundary compatibility).** For physical wholes, the whole’s boundary encloses the union of its portions; cross‑boundary “leaks” are interactions, not portions.\n\n**Didactic tests.**\n✔ “5 kg from a 20 kg billet” — PortionOf.\n✔ “Pages 1–10 of the report” — PortionOf (μ = page or token count).\n✘ “The pump module of the plant” — **ComponentOf**, not PortionOf.\n✘ “The Methods section of the paper” — **ConstituentOf**, not PortionOf.\n\n\n#### A.14:5.2 - PhaseOf — temporal part of the same carrier\n\n**Intent.** Capture “the same holon during a sub‑interval”, preserving identity through change.\n\n**Applicability.** Any `U.Holon` that persists across time with a recognised **carrier identity**.\n\n**Primitive.** `PhaseOf(x, y)` means: *x is y restricted to a proper time interval*.\n\n**Axioms (A14‑PHA‑\\*)**\n\n* **PHA‑1 (Partial order).** PhaseOf is reflexive, antisymmetric, transitive (on the same carrier).\n* **PHA‑2 (Coverage).** The whole is the union of its maximal, non‑overlapping phases over its lifetime interval.\n* **PHA‑3 (No paradoxical overlap).** Phases of the **same carrier** do not overlap in time; overlapping variants require `PhaseOf` on *aspects* or different carriers.\n* **PHA‑4 (Identity through change).** Properties may vary between phases, but the carrier’s identity criteria hold continuously (e.g., same serial number, same legal identity, same theorem statement).\n* **PHA‑5 (Escalation to MHT).** If identity criteria break (e.g., metamorphosis with new objectives), **declare a Meta‑Holon Transition (B.2)** rather than a PhaseOf.\n\n**Didactic tests.**\n✔ “PumpUnit\\#3 **before** calibration” — PhaseOf(Pump\\#3\\_pre, Pump\\#3).\n✔ “Spec v2” — PhaseOf(Spec\\_v2, Spec), on the **MethodDescription** artefact.\n✔ “Shift 1 of the same batch run” — PhaseOf(Work\\_shift1, Work).\n✘ “Prototype vs. production unit” — likely **different carriers**; use ComponentOf/ConstituentOf or MHT per criteria.\n\n#### A.14:5.3 - CT2R‑LOG & Compose‑CAL handshake *(normative link)*\n\n* **Structural claims** published on the Working-Model surface **SHALL** be justified, when assurance is required, by a **Constructive** grounding narrative using **Γ_m.sum | Γ_m.set | Γ_m.slice** and **linked with `tv:groundedBy`** (see **B.3.5**; **C.13**).  \n* **PhaseOf** is **temporal parthood**; it **SHALL NOT** be grounded via Γ\\_m. Its assurance follows identity‑through‑time criteria (CC‑PHA‑1..3) and Γ\\_time ordering (B.1.4).  \n* **MemberOf** remains **non‑mereological** (CC‑MEM‑2). When modelling a collection‑as‑whole for assurance purposes, the constructive basis is **Γ\\_m.set**; no **ComponentOf** inferences follow from **MemberOf**.\n",
        "choosing_the_right_relation_(decision_table)": "### A.14:6 - Choosing the right relation (decision table)\n\n| You want to say…                                             | Use                  | Why                                                                                |\n| ------------------------------------------------------------ | -------------------- | ---------------------------------------------------------------------------------- |\n| “This is a *piece* of the same stuff (lower amount/extent).” | **PortionOf**        | Governed by a measure μ and conservation (Σ‑additive).                             |\n| “This is a *discrete part* that sits *inside* the whole.”    | **ComponentOf**      | Structural parthood; boundary‑respecting, not measured by μ.                       |\n| “This is a *logical part* in a conceptual whole.”            | **ConstituentOf**    | Sections, lemmas, clauses, conceptual assembly.                                    |\n| “This is the *same thing* during a *sub‑interval*.”          | **PhaseOf**          | Temporal slicing with identity continuity.                                         |\n| “This *item belongs to that collection/collective*.”         | **MemberOf**         | Not a building block of the whole; composition handled in **B.1.7 Γ\\_collective**. |\n| “This system *plays a Role or position*.”          | **playsRole** (A.15) | Roles are contextual masks, never parts.                                           |\n\n> **Firewall reminder.** If your sentence contains “role”, “policy”, “process/workflow/SOP/script”, you are likely talking about **A.15** (roles/recipes/runs), **not** A.14.\n\n",
        "archetypal_grounding": "### A.14:7 - Archetypal grounding (System / Episteme)\n\n| Relation                       | `U.System` example                                     | `U.Episteme` example                                        |\n| ------------------------------ | ------------------------------------------------------ | ----------------------------------------------------------- |\n| **PortionOf**                  | 50 L from a 200 L fuel tank (μ = volume).              | Pages 1–10 from a 120‑page report (μ = page/token count).   |\n| **ComponentOf**                | Impeller **ComponentOf** PumpUnit.                     | Figure 2 **ComponentOf** Poster Layout (physical artefact). |\n| **ConstituentOf**              | Control law **ConstituentOf** Controller Design.       | Lemma A **ConstituentOf** Theorem Proof.                    |\n| **PhaseOf**                    | PumpUnit\\#3 *before*/*after* calibration (same serial). | Spec v1 → v2 (same document lineage).                       |\n| MemberOf (for reference) | “is an element of a collection/collective”; use when a grouping is explicitly treated as a whole set, without implying component integration. Not a building block of the whole; **constructive aggregation** is handled in **C.13 Compose‑CAL** (`Γ_m.set`). If the grouping is expected to **act**, model a **collective system** (A.15). |\n",
        "conformance_checklist": "### A.14:8 - Conformance Checklist & type guards (normative)\n\n#### A.14:8.1 - Global firewall and scope\n\n| ID            | Requirement                                                                                 | Purpose                                                 |\n| ------------- | ------------------------------------------------------------------------------------------- | ------------------------------------------------------- |\n| **CC‑A14‑0**  | No `U.Role`, `U.Method`, or `U.MethodDescription` **MAY** occur as a node in any `partOf` chain.   | Keeps parthood purely structural/conceptual (see A.15). |\n| **CC‑A14‑0b** | `MemberOf` **MUST NOT** imply, entail, or be auto‑rewritten into any `partOf` sub‑relation. | Separates collections/collectives from parthood.        |\n| **CC‑A14‑0c** | `SerialStepOf` / `ParallelFactorOf` **MUST NOT** appear in any `partOf` chain or table in A.14; model order via **A.15** (**Γ_ctx/Γ_method**). | Prevents the “order‑as‑structure” category error.       |\n\n#### A.14:8.2 - PortionOf guards\n\n| ID                                 | Requirement                                                                                                                                                               | Purpose                                 |\n| ---------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------- |\n| **CC‑POR‑1 (Domain)**              | `PortionOf(x,y)` is valid only if the modelling scope declares at least one **extensive measure** μ for y (mass, volume, token count, byte size, wall‑time budget, etc.). | Prevents “portion” without a measure.   |\n| **CC‑POR‑2 (Kind)**                | x and y **SHALL** share the same μ‑kind and compatible units (or an explicit conversion).                                                                                 | Prevents apples‑to‑oranges addition.    |\n| **CC‑POR‑3 (Monotone additivity)** | For disjoint portions `x ⟂ z` with `PortionOf(-,y)`: μ(x ⊔ z) = μ(x)+μ(z).                                                                                                | Secures Σ‑reasoning and Γ\\_sys proofs. |\n| **CC‑POR‑4 (Boundary)**            | For physical systems, the whole’s boundary encloses the union of portions; cross‑boundary flows are **not** portions.                                                     | Distinguishes stock vs flow.            |\n| **CC‑POR‑5 (Non‑replacement)**     | “Replacing 20% of y by v” **MUST** be modelled as **PortionOf** removal + **Component/Constituent** insertion, not as a single PortionOf rewrite.                         | Avoids silent identity change.          |\n\n#### A.14:8.3 - PhaseOf guards\n\n| ID                                    | Requirement                                                                                                                                                      | Purpose                                |\n| ------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------- |\n| **CC‑PHA‑1 (Carrier identity)**       | `PhaseOf(x,y)` requires an explicit **identity criterion** for y valid over the union of phases (e.g., serial number, legal identity, theorem statement).        | Prevents re‑identification by stealth. |\n| **CC‑PHA‑2 (Coverage & non‑overlap)** | The lifetime of y equals the union of its maximal, non‑overlapping phases (on the same aspect).                                                                  | Enables Γ\\_time composition and audit. |\n| **CC‑PHA‑3 (Aspect clarity)**         | If two temporal slices of y overlap, they **MUST** be phases of **different aspects** (e.g., mechanical‑state vs software‑state), or else be different carriers. | Avoids paradoxical overlaps.           |\n| **CC‑PHA‑4 (Escalation)**             | If identity criteria fail during change, declare a **Meta‑Holon Transition** (B.2) instead of PhaseOf.                                                           | Makes re‑identification explicit.      |\n| **CC‑PHA‑5 (MethodDescription & Work)**      | Versions of **MethodDescription** and slices of **Work** **SHALL** use `PhaseOf` (A.15); PhaseOf never applies to `U.Role`.                                             | Aligns with A.15 bindings.             |\n\n#### A.14:8.4 - Anchoring & validation (normative)\n\n| ID              | Requirement                                                                                                      | Purpose                                           |\n| ----------------| ---------------------------------------------------------------------------------------------------------------- | ------------------------------------------------- |\n| **CC‑ANCH‑1**   | Every `ut:StructPartOf` edge **MUST** carry a `tv:groundedBy` link to a valid `Γ_m` constructor trace (Compose‑CAL). | Makes A.10 executable; ensures extensional identity. |\n| **CC-ANCH-2**   | For **epistemic** edges (`ut:EpiPartOf` and its sub-types), `tv:groundedBy` is **OPTIONAL**; instead supply **`ev:evidence`** and set **`validationMode ∈ {axiomatic, postulate, inferential}`**. | Harmonises evidence treatment for epistemic edges. |\n| **CC‑ANCH‑3**   | The public query Standard remains `?x ut:PartOf+ ?y`; internally it is realised via CT2R‑aliases grounded by `Γ_m` traces. | Preserves the “one query” UX while tightening semantics. |\n\n*Note.* Property names and trace semantics are defined in the CT2R‑LOG / Compose‑CAL architheories.\n\n#### A.14:8.5 - MemberOf minimal semantics (non‑mereological)\n\n| ID           | Requirement                                                                                       | Purpose                               |\n| ------------ | ------------------------------------------------------------------------------------------------- | ------------------------------------- |\n| **CC‑MEM‑1** | `MemberOf` domain/range are open: any `U.Holon` may be a member of a collection/collective holon. | Allows mixed collections when needed. |\n| **CC‑MEM‑2** | From `MemberOf(x,C)` it is **forbidden** to infer any property of C to x via parthood rules.      | Prevents “set‑as‑whole” errors.       |\n| **CC‑MEM‑3** | **Constructive aggregation of collections** is provided by **C.13 Compose‑CAL** (`Γ_m.set`); **agency of collectives** is specified outside A.14 (see **A.15 Role–Method–Work**). | Keeps A.14 narrow and clean.          |\n\n\n#### A.14:8.5 - CT2R‑LOG handshake (Working‑Model → Assurance)\n\n| ID                 | Requirement                                                                                                                                                              | Purpose                                                                                 |\n| ------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | --------------------------------------------------------------------------------------- |\n| **CC-A14-10**      | For **structural** edges on the Working-Model surface, authors **SHALL** set `validationMode=axiomatic` and attach **`tv:groundedBy → Γ_m.sum|set|slice`**.      | Aligns A.14 with CT2R-LOG (**B.3.5**) and Compose-CAL (**C.13**); ensures extensional identity. |\n| **CC‑A14‑11**      | **PhaseOf** edges **SHALL NOT** use Γ\\_m for grounding. Authors **SHALL** provide identity criteria and non‑overlap per **CC‑PHA‑1..3** and reference **Γ\\_time** when ordering matters. | Keeps temporal parthood distinct from construction; preserves the plane firewall.       |\n",
        "validation_patterns_(author’s_decision_procedure)": "### A.14:9 - Validation patterns (author’s decision procedure)\n\n**Step 0 — Firewall check.**\nIf your sentence contains *role*, *policy*, *process/workflow/SOP/script*, or *execution/run/job*, you are **not** in mereology; go to **A.15** (Role–Method–Work).\n\n**Step 1 — Is it measured stuff?**\nIf yes, pick **PortionOf**. Confirm μ is declared (CC‑POR‑1/2). Test additivity on a toy split (CC‑POR‑3). If flows cross a boundary, remodel as interactions, not portions (CC‑POR‑4).\n\n**Step 2 — Is it a discrete inside part?**\nIf yes, pick **ComponentOf** (physical) or **ConstituentOf** (conceptual). Do **not** use PortionOf here.\n\n**Step 3 — Is it the same carrier at a time slice?**\nIf yes, pick **PhaseOf**. Verify identity criteria and non‑overlap (CC‑PHA‑1/2/3). If criteria break, escalate to **B.2** (CC‑PHA‑4).\n\n**Step 4 — Is it a membership statement?**\nUse **MemberOf** only; avoid any part‑inferences (CC‑MEM‑2). If you need a **collection as a whole**, use **C.13** (`Γ_m.set`) for constructive grounding. If you need **collective action**, defer to **A.15**.\n\n**Quick spot‑tests (repair kit).**\n\n| Smell                          | Likely error                      | Fix                                                                                                                          |\n| ------------------------------ | --------------------------------- | ---------------------------------------------------------------------------------------------------------------------------- |\n| “20% of the chassis”           | Treating structure as stuff       | Use **ComponentOf**; if truly laminar material, PortionOf applies to **material stock**, not the assembled chassis.          |\n| “Chapter 2 is 15% of the book” | Mixing measures and constituents  | Use **ConstituentOf**; the 15% is **length‑of‑text** as a separate statement.                                                |\n| “Spec v2 overlaps v1”          | Overlapping phases on same aspect | Use `PhaseOf(Spec_v2, Spec)` with non‑overlap; represent drafting as **Work** episodes (A.15) rather than overlapping specs. |\n| “Team is part of the project”  | Member vs part confusion          | Use **MemberOf(Team, ProjectCollective)**, not partOf.                                                                       |\n\n",
        "relations": "### A.14:10 - Interplay with Γ‑flavours (how these relations behave under aggregation)\n\n| Γ‑flavour                    | Mereological hooks (what A.14 supplies)                                                                                                                | Key effect                                                                                    |\n| ---------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------ | --------------------------------------------------------------------------------------------- |\n| **Γ\\_sys (B.1.2)**          | Treat **PortionOf** as Σ‑additive stocks; **ComponentOf** must respect boundary integration; **PhaseOf** is not aggregated here.                       | Conserves extensive measures and keeps structural WLNK (weakest‑link) on components.          |\n| **Γ\\_epist (B.1.3)**         | **PortionOf** of texts/data uses μ = token/byte count; **ConstituentOf** composes arguments/sections; **PhaseOf** versions MethodDescriptions/documents.      | Preserves provenance and avoids trust inflation by keeping constituents vs portions distinct. |\n| **Γ\\_ctx / Γ\\_time (B.1.4)** | **PhaseOf** provides the legal slicing for time and order; **PortionOf** is orthogonal (quantities inside steps).                                      | Ensures chronological consistency and monotone coverage.                                      |\n| **Γ\\_method (B.1.5)**          | Recipes are **MethodDescription** graphs (not parthood). When a recipe refers to stuff‑like inputs, those are **PortionOf** statements on resources.          | Separates recipe composition from structure.                                                  |\n| **Γ\\_work (B.1.6)**          | Only **Work** carries resource deltas; when logging “consumed 5 kg from Tank A”, model it as **PortionOf** relation to the stock prior to consumption. | Makes Σ‑balance explicit; aligns with CC‑POR‑3/4.                                             |\n",
        "consequences": "### A.14:11 - Consequences\n\n**Benefits**\n\n* **Predictable composition.** Σ‑additivity for portions and identity‑through‑time for phases make Γ‑proofs straightforward.\n* **History without confusion.** Temporal slicing is explicit and audit‑ready; no paradoxical overlaps.\n* **Cleaner integration with roles and recipes.** The firewall prevents “functional object” creep into structure.\n* **Compatibility with engineering practice.** Mirrors *product breakdown* (components) vs *functional breakdown* (roles) vs *material stocks* (portions) vs *versioning* (phases).\n\n**Trade‑offs / mitigations**\n\n* **Modelling energy.** Authors must pick μ and declare units; provide a short μ‑catalog per project.\n* **More relation names.** Two extra sub‑relations increase vocabulary; mitigated by the decision table (§ 6) and spot‑tests (§ 9).\n* **Escalation discipline.** Deciding PhaseOf vs MHT requires judgement; A.14 provides criteria, and B.2 captures true re‑identification.\n",
        "pedagogy_aids_(non‑normative)": "### A.14:12 - Pedagogy aids (non‑normative)\n\n**Two‑minute checklist for reviewers**\n\n1. Do I see “process/workflow/policy/script”? — then **A.15**, not mereology.\n2. Does every PortionOf have a declared μ and unit?\n3. Do phases cover a lifetime without overlap for the same aspect?\n4. Are any roles/recipes appearing as parts? If yes, stop and refactor.\n",
        "patch_map_(where_to_touch_in_the_working_file)": "### A.14:13 - Patch map (where to touch in the working file)\n\n1. **Kernel - Holonic Mereology (§ A.1 → A.14)**\n   *Add* sub‑sections “PortionOf” and “PhaseOf” with axioms (POR‑1..5, PHA‑1..5).\n   *Move* MemberOf note to a minimal semantics paragraph (no composition here).\n\n2. **A.15 (Role–Method–Work)**\n   *Cross‑link* firewall (CC‑A14‑0/0b) and reinforce that versioning uses **PhaseOf** only on MethodDescription/Work.\n\n3. **B.1.2 Γ\\_sys / B.1.3 Γ\\_epist / B.1.4 Γ\\_ctx/Γ\\_time / B.1.5 Γ\\_method / B.1.6 Γ\\_work**\n   *Insert* a one‑line “A.14 compliance” note: which A.14 sub‑relations each flavour relies on, as in § 10.\n\n4. **Examples & Annexes**\n   *Refactor* any “percentage as part” examples into PortionOf with declared μ;\n   *Split* any overlapping histories into PhaseOf sequences.\n\nEach edited heading should carry the badge **“► decided‑by: A.14 Advanced Mereology”**.\n",
        "rationale": "### A.14:14 - Rationale (state‑of‑the‑art alignment, post‑2015)\n\n* **Metrical mereology** advances (e.g., recent work on quantity‑based parthood and additivity) motivate **PortionOf** with explicit μ and Σ‑laws, preventing the classic “stuff as components” fallacy.\n* **Temporal parts & identity through change** (renewed treatments in analytic metaphysics and formal ontology) motivate **PhaseOf** with coverage/non‑overlap and escalation when identity criteria fail.\n* **Engineering ontologies (BORO lineage, Core Constructional practice, ISO 15926 family)** keep a strict separation between **functional breakdowns** (our Roles) and **product breakdowns** (our Components), with **stock/consumable** modelling (our Portions) handled by quantities, not by component trees.\n* **Knowledge artefact lifecycles** in contemporary MBSE and open‑science workflows use explicit versioning (our PhaseOf) and provenance‑preserving composition (our ConstituentOf).\n* The net effect is a **minimal‑sufficient** catalogue: two added sub‑relations close real modelling gaps while preserving **parsimony**, **didactic clarity**, and **Γ‑compatibility** across domains.\n",
        "a.14:end": "### A.14:End\n"
      },
      "content": "### A.14:End\n",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.15",
      "title": "Role–Method–Work Alignment (Contextual Enactment)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.15 - Role–Method–Work Alignment (Contextual Enactment)\n",
        "intent_&_context": "### A.15:1 - Intent & Context\n\nIn any complex system, from a software project to a biological cell, there is a fundamental distinction between **what something is** (its structure), **what it is supposed to do** (its role and specified capability), and **what it actually does** (its work). Confusing these layers is a primary source of design flaws, budget overruns, and failed projects. Teams argue about a \"process\" without clarifying if they mean the documented procedure, the team's ability to execute it, or a specific execution that happened last Tuesday.\n\nThis pattern provides the canonical alignment for modeling contextual enactment in FPF, serving as the ultimate implementation of the **Strict Distinction Principle (A.7)**. It weaves together several foundational concepts into a single, coherent model of how intention becomes action:\n*   **A.2 (Contextual Role Assignment):** Provides the `Holder#Role:Context` structure for assigning roles.\n*   **A.4 (Temporal Duality):** Provides the strict separation between `design-time` and `run-time`.\n*   **A.12 (External Transformer):** Ensures that all actions are attributed to an external agent.\n\nThe intent of this pattern is to establish a normative, unambiguous vocabulary and set of relations for describing the entire evolution of an action, from the specification of a capability to its concrete, resource-consuming execution.\n\nTo keep plan–run separation explicit, this pattern references **A.15.2 `U.WorkPlan`** for **schedules/calendars** and **A.15.1 `U.Work`** for **dated execution**. Ambiguous terms like “process / workflow / schedule” are constrained by **L‑PROC / L‑FUNC / L‑SCHED** (E‑cluster): a _workflow_ is a **Method/MethodDescription**, a _schedule_ is a **WorkPlan**, and what _happened_ is **Work**.\n\n**Terminology note (L‑ACT).** The words _action/activity_ are **not normative** in the kernel. When a generic “doing” is needed, we use the didactic term **enactment** (not a type). Normative references must be to **`U.Method` / `U.MethodDescription` / `U.Work` / `U.WorkPlan`**. See lexical rules **L‑PROC / L‑FUNC / L‑SCHED / L‑ACT**\n",
        "problem": "### A.15:2 - Problem\n\nWithout this formal framework, models suffer from a cascade of category errors:\n\n1.  **Role-as-Part:** A Role (e.g., `AuditorRole`) is incorrectly placed inside a structural bill-of-materials (`ComponentOf`), making the system's architecture brittle and nonsensical.\n2.  **Specification-as-Execution:** A `MethodDescription` (the \"recipe\") is treated as evidence that the work was done. This leads to \"paper compliance,\" where a system is considered complete simply because its documentation exists.\n3.  **Capability-as-Work:** A team's *ability* to perform a task (`Capability`) is conflated with the *actual performance* of that task (`Work`). This obscures the reality of resource consumption and actual outcomes.\n4.  **Work-without-Context:** An instance of work is logged without a clear link back to the role, capability, and specification that governed it, making the work unauditable and its results impossible to reproduce.\n5.  **Ambiguous \"Process/Activity\":** The overloaded term \"process\" is used indiscriminately to refer to all of the above, creating a fog of miscommunication that paralyzes decision-making. Activity/action terms must be resolved via L‑ACT to Method/MethodDescription (recipe), WorkPlan (schedule), or Work (run).\n",
        "forces": "### A.15:3 - Forces\n\n| Force | Tension |\n| :--- | :--- |\n| **Structure vs. Function** | The need to model the stable, physical structure of a system (`mereology`) vs. the need to model its dynamic, functional behavior (`roles` and `actions`). |\n| **Design vs. Run** | The need for a timeless, reusable description of a capability (`design-time`) vs. the need for a specific, dated record of its execution (`run-time`). |\n| **Clarity vs. Jargon** | The need for a precise, formal vocabulary to prevent ambiguity vs. the reality that teams use informal, domain-specific jargon like \"process\" or \"workflow.\" |\n| **Accountability vs. Complexity** | The need for a complete, end-to-end audit trail for every action vs. the desire to keep models simple and avoid excessive documentation. |\n",
        "solution": "### A.15:4 - Solution\nThe solution is a stratified alignment that cleanly separates the `design-time` and `run-time` for contextual **enactment**. The bridge between these worlds is the **`U.RoleAssignment`**.\n",
        "a.15:4.1___the_core_entities:_a_strict_distinction": "### A.15:4.1 - The Core Entities: A Strict Distinction\n\nFPF mandates the use of the following distinct, non-overlapping entities to model action. Using them interchangeably is a conformance violation.\n\n**A) Design-Time Entities (The World of Potential):**\n\n*   **`U.Role`:** A contextual \"mask\" or \"job title\" (e.g., `TesterRole`). It specifies a function but is not the function itself.\n*  **`U.Method`:** The **abstract way‑of‑doing** inside a context (paradigm‑agnostic; may be imperative, functional, logical, or hybrid).\n*  **`U.MethodDescription`:** A **`U.Episteme` describing a `U.Method`** (the SOP/algorithm/proof/recipe on a carrier).\n*   **`U.Capability`:** An **attribute** of a `U.System` that represents its **ability** to perform the actions described in a `MethodDescription`. This is the \"skill\" or \"know-how.\"\n* **`U.WorkPlan`:** An **`U.Episteme`** declaring **intended `U.Work` occurrences** (windows, dependencies, intended performers as role kinds, budgets) — see **A.15.2**.\n* \n**B) The Bridge Entity:**\n*   **`U.RoleAssignment`:** The formal assertion `Holder#Role:Context` that links a specific `U.Holon` to a `U.Role` within a `U.BoundedContext`. This binding is what \"activates\" the requirements associated with a role.\n\n**C) Run-Time Entity (The World of Actuality):**\n\n*   **`U.Work`:** An **occurrence** or **event**. It is the concrete, dated, resource-consuming **execution of a `U.MethodDescription`** by a `Holder` acting under a `U.RoleAssignment`; capability checks are evaluated at run time against the holder. This is the only entity that has a start and end time and consumes resources.\n\n**Kinds of Work and the primary target**\nEvery `U.Work` SHALL declare a `primaryTarget: U.Holon` and a `kind`.\nKinds:\n* Operational — transforms a `U.System` or its environment.\n* Communicative (SpeechAct) — transforms a deontic/organizational frame (e.g., commitments, permissions, approvals).\n* Epistemic — transforms a `U.Episteme` (e.g., curating a dataset).\nThe `primaryTarget` disambiguates enactment: what is being acted upon. Example: an approval is `kind=Communicative`, `primaryTarget = Commitment(change=4711)`. A deployment is `kind=Operational`, `primaryTarget = ServiceInstance(prod-us-eu-1)`.\n\n**Didactic Note for Managers: The \"Chef\" Analogy**\n\nThis model can be easily understood using the analogy of a chef in a restaurant.\n\n*   **`ChefRole`** is the **Role**. It's a job title with certain expectations.\n*   A **Cookbook (`U.MethodDescription`)** contains the **recipe** for a Soufflé. It's a piece of knowledge.\n*   The chef's **skill** in making soufflés is their **`U.Capability`**. They have this skill even when they are not cooking.\n*   The restaurant's rulebook (`U.BoundedContext`) states that anyone in the `ChefRole` *must* have the `Capability` to follow the recipes in the cookbook.\n*   The actual act of **making a soufflé** on Tuesday evening—using eggs and butter, taking 25 minutes, and consuming gas—is the **`U.Work`**.\n\nConfusing these is like mistaking the cookbook for the soufflé. FPF's framework simply makes these common-sense distinctions formal and mandatory.\n",
        "relations": "### A.15:9 - Relations\n\n*   **Directly Implements:** `A.7 Strict Distinction`.\n*   **Builds Upon:** `A.2 (U.Role)`, `A.2.1 (U.RoleAssignment)`, `A.4 (Temporal Duality)`, `A.12 (External Transformer)`.\n*   **Is Used By / Provides Foundation For:**\n    *   `C.4 Method-CAL`: Provides the formal definition of `U.MethodDescription` and the `Γ_method` operator for composing them.\n    *   `C.5 Resrc-CAL`: Provides the `U.Work` entity to which resource consumption is attached.\n    *   `B.1.6 Γ_work`: The aggregation operator for `U.Work`.\n    *   `B.4 Canonical Evolution Loop`: The entire loop is a sequence of `Work` instances that modify `MethodDescription`s.\n    *   `A.15.2 U.WorkPlan`: plan–run split, baselines and variance against `U.Work`.\n* **Constrains:** Any architheory that models actions or processes must use this framework to be conformant. It serves as the canonical alignment for **contextual enactment** in the FPF ecosystem.\n* **Coordinates with** L‑PROC / L‑FUNC / L‑SCHED (E‑cluster) for lexical disambiguation of _process / workflow / schedule_.\n",
        "archetypal_grounding": "### A.15:5 - Archetypal Grounding\n\nThe Contextual Action Framework is universal. It applies identically to the modeling of physical engineering processes, knowledge work, and socio-technical systems.\n\n| Archetype | **`U.System` Archetype (Manufacturing)** | **`U.Episteme` Archetype (Scientific Peer Review)** |\n| :--- | :--- | :--- |\n| **`BoundedContext`** | `FactoryFloor:ProductionLine_B` | `Journal:PhysicsLetters_A` |\n| **`Role`** | `WeldingRobotRole` | `ReviewerRole` |\n| **`Holder`** | `ABB_Robot_Model_IRB_6700` (`U.System`) | `Dr_Alice_Smith` (modeled as a `U.System`) |\n| **`U.RoleAssignment`** | `ABB_Robot#WeldingRobotRole:Line_B` | `Dr_Smith#ReviewerRole:PhysicsLetters_A` |\n| **`MethodDescription` (`U.Episteme`)**| `Welding_Procedure_WP-28A.pdf` (SOP) | `Peer_Review_Guidelines_v3.docx` |\n| **`Capability` (Attribute of Holder)** | `executeWeldingSeam(Type: 3F)` | `evaluateManuscript(Field: QuantumOptics)` |\n| **`Work` (`Occurrence`)** | Manufacturing Work: `Weld_Job_#78345` (15:32-15:34 UTC, consumed 1.2 kWh, 5g Argon) — **isExecutionOf** `Welding_Procedure_WP‑28A.pdf` | Peer‑review Work: `Review_of_Manuscript_#PL-2025-018` (Completed 2025-08-15, took 4 hours) — **isExecutionOf** `Peer_Review_Guidelines_v3.docx` |\n\n**Key takeaway from grounding:**\nThis side-by-side comparison reveals the power of the framework. A seemingly different activity like welding a car chassis and reviewing a scientific paper are shown to have the **exact same underlying causal structure**. Both involve a `Holder` (a system) acting in a `Role` within a `Context`, using a `Capability` described by a `MethodDescription` to produce a specific, auditable instance of `Work`. This universality is what allows FPF to bridge disparate domains.\n",
        "conformance_checklist": "### A.15:6 - Conformance Checklist\n\nTo ensure the integrity of action modeling, all FPF-compliant models must adhere to the following normative checks.\n\n| ID | Requirement (Normative Predicate) | Purpose / Rationale |\n| :--- | :--- | :--- |\n| **CC-A15-1 (Entity Distinction)** | The entities `U.Role`, **`U.Method`**, **`U.MethodDescription`**, `U.Capability`, **`U.WorkPlan`**, and `U.Work` **MUST** be modeled as distinct, non‑overlapping types. | This is the core enforcement of **Strict Distinction (A.7)**. It prevents the category errors outlined in the \"Problem\" section. |\n| **CC-A15-2 (Temporal Scope)** | `U.Method`/`U.MethodDescription`/`U.WorkPlan` exist in **design‑time**; `U.Work` exists in **run‑time**. Design artifacts are not mutated by operational events. | Enforces **Temporal Duality (A.4)**. Blueprints cannot be mutated by operational events. |\n| **CC-A15-3 (RoleAssignment Mandate)**| Every `U.Work` **MUST** be linked via `performedBy` to a valid `U.RoleAssignment`. | Guarantees that every action has a clearly identified, context-bound actor, ensuring accountability. |\n| **CC-A15-4 (Traceability Chain)**| For every `U.Work`, an unbroken chain **MUST** exist: `Work —performedBy→ RoleAssigning` and `Work —isExecutionOf→ MethodDescription —describes→ Method`. Capability checks are evaluated against the holder at run time. | Ensures end-to-end auditability from a specific action back to the \"recipe\" that governed it. |\n| **CC-A15-5 (No Roles in Mereology)** | A `U.Role` or `U.Capability` **SHALL NOT** be part of a mereological (`partOf`) hierarchy. | The \"Role-as-Part\" anti-pattern is a violation. Roles and capabilities are functional, not structural. Enforces **A.14**. |\n| **CC-A15-6 (Resource Honesty)** | Resource consumption (`U.Resource`) **MUST** only be associated with `U.Work`, never with `U.MethodDescription` or `U.Capability`. | Enforces that costs are tied to actual events, not to plans or potential. Aligns with **Resrc-CAL (C.5)**. |\n| **CC‑A15‑7 (Plan/Run Split)** | Schedules/calendars **MUST** be represented as `U.WorkPlan` (A.15.2). A WorkPlan SHALL NOT be used as evidence of execution; only `U.Work` carries actuals. | |\n| **CC‑A15‑8 (Lexical Sanity)** | Unqualified “process/workflow/schedule” **MUST** be interpreted per **L‑PROC/L‑FUNC/L‑SCHED**: workflow ⇒ `Method/MethodDescription`; schedule ⇒ `WorkPlan`; what happened ⇒ `Work`. | |\n| **CC-A15-9 (Realisation)** | A valid `U.Work` realises a `U.MethodDescription` under a `U.RoleAssignment`. Spontaneous physical evolution without a MethodDescription is modeled as `U.Dynamics`, not as `U.Work`. | |\n| **CC-A15-10 (GateSplit)** | A SpeechAct that changes a Role’s state (e.g., “Approve”, “Authorize”) MUST be modeled as a distinct `U.Work` step (kind=Communicative). It may open the Green‑Gate for a subsequent operational step, but it SHALL NOT be conflated with that step. | |\n| **CC-A15-11 (KindFit)** The `U.Role` named in the `performedBy` assignment SHALL be appropriate for the Work kind (e.g., ApproverRole for Communicative approvals; DeployerRole for Operational deployments). | |\n",
        "consequences": "### A.15:7 - Consequences\n\n| Benefits | Trade-offs / Mitigations |\n| :--- | :--- |\n| **Unambiguous Communication:** Provides a shared, precise vocabulary for teams to discuss roles, processes, and results, eliminating the ambiguity of terms like \"process.\" | **Initial Learning Curve:** Requires teams to learn and internalize the distinctions between the core entities. *Mitigation:* The \"Chef\" analogy and clear archetypes serve as powerful didactic tools. FPF tooling should guide users with templates. |\n| **End-to-End Auditability:** The framework creates a \"digital thread\" that links every operational event (`Work`) back to its authorizing role, context, and specification. This is critical for regulated industries and for root cause analysis. | **Increased Formality:** Requires more explicit modeling than informal approaches. *Mitigation:* This is a strategic investment. The upfront cost of formal modeling is offset by massive savings in debugging, re-work, and compliance efforts later. |\n| **Enables True Modularity:** By separating capability from execution, the framework allows for easier substitution. A `MethodDescription` can be updated without invalidating past `Work` records. A `Holder` can be replaced with another, as long as it possesses the same `Capability`. | - |\n| **Foundation for Governance:** The model makes it possible to build powerful governance rules. For example: \"Only an `Agent` with `AuditorRole` can execute `Work` that instantiates the `ApproveRelease` capability.\" | - |\n",
        "rationale": "### A.15:8 - Rationale\n\nThis pattern solves a problem that has plagued systems modeling for decades: the conflation of what a system *is* with what it *does*. Its rigor is not arbitrary but is grounded in several key intellectual traditions.\n\n*   **Ontology Engineering:** The pattern is a direct application of best practices from foundational ontologies (like UFO), which have long insisted on the distinction between *endurants* (objects like a `U.System`) and *perdurants* (events/processes like `U.Work`), and between intrinsic properties and relational roles. FPF makes these powerful distinctions accessible to practicing engineers.\n*   **Process Theory:** Formalisms like the Pi-calculus or Petri Nets model processes as dynamic interactions. The FPF Contextual Action Framework provides a higher-level, more semantically rich layer on top of such formalisms. The `U.Work` entity can be seen as an instance of a process, but FPF adds the crucial context of the `Role`, `Capability`, and `MethodDescription` that govern it.\n*   **Pragmatism and Practice:** The framework is deeply pragmatic. The distinctions it makes (e.g., between a `MethodDescription` and `Work`) are precisely the ones that matter in the real world of project management, compliance, and debugging. When a failure occurs, a manager needs to know: was the recipe wrong (`MethodDescription`), did the chef lack the skill (`Capability`), or did they just make a mistake this one time (`Work`)? This framework provides the vocabulary to ask and answer that question precisely.\n\nBy creating this clean, stratified alignment for enactment, FPF provides a stable and scalable foundation for all of its more advanced architheories, from resource management (`Resrc-CAL`) and decision theory (`Decsn-CAL`) to ethics (`Norm-CAL`).\n",
        "a.15:end": "### A.15:End\n\n"
      },
      "content": "### A.15:End\n\n",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.15.1",
      "title": "U.Work",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.15.1 - U.Work\n",
        "problem": "### A.15.1:2 - Problem (what breaks without a clean notion of Work)\n\n1. **Plan/run confusion.** Schedules and diagrams get mistaken for “the process,” so audits and KPIs become fiction.\n2. **Spec/run conflation.** A method description (code/SOP) is reported as if it were an execution; conversely, logs are treated as recipes.\n3. **Who/when leakage.** People and calendars are baked into specs; reuse and staffing agility collapse.\n4. **Resource dishonesty.** Energy/money/tool wear are booked to methods or roles, not to actual runs; costing and sustainability metrics drift.\n5. **Mereology muddle.** Teams hand‑wave over “sub‑runs,” retries, overlaps, or long‑running episodes; roll‑ups double‑count or miss work.\n",
        "forces": "### A.15.1:3 - Forces (what the definition must balance)\n\n| Force                              | Tension we resolve                                                                                    |\n| ---------------------------------- | ----------------------------------------------------------------------------------------------------- |\n| **Universality vs. domain detail** | One Work notion for surgery, welding, ETL, proofs, lab cycles—while letting each keep its vocabulary. |\n| **Granularity vs. aggregation**    | Atomic runs vs. composite operations; we need roll‑up without double‑count.                           |\n| **Concurrency vs. order**          | Parallel/overlapped activities need clear part/overlap semantics.                                     |\n| **Identity vs. retries**           | A failed attempt, a retry, and a resumed episode—what is “the same” work?                             |\n| **Time realism vs. simplicity**    | We need intervals and coverage but cannot bury users in temporal logic notation.                      |\n",
        "solution": "### A.15.1:4 - Solution — define `U.Work` as the accountable, dated occurrence\n\n#### A.15.1:4.1 - Definition\n\n**`U.Work`** is a **4D occurrence holon**: a **dated run‑time enactment** of a `U.MethodDescription` by a performer designated through a `U.RoleAssignment`, **executed within a concrete `U.System/SubSystem`**, inside a `U.BoundedContext`, that binds concrete parameters, consumes/produces resources, and leaves an auditable trace. \nEach `U.Work` is a **morphism** `Δ` on a declared **state‑plane** (`StatePlaneRef`), mapping ⟨**pre‑state**, **inputs**⟩ to ⟨**post‑state**, **outputs**⟩ for one or more **affected referents**.\n\n> **Memory aid:** *Work = “how it went this time”* (dated, resourced, accountable).\n\n#### A.15.1:4.2 - Core anchors (conceptual descriptors; not a data schema)\n\nWhen you describe a Work instance in a review, answer these prompts:\n\n1. **Window** — start/end timestamps (and, where relevant, location/asset).\n2. **Spec** — `isExecutionOf → U.MethodDescription` (the description actually followed; **edition pinned** if applicable).\n3. **Performer** — `performedBy → U.RoleAssignment` (which **holder#role\\:context** acted).\n4. **Parameters** — concrete values bound for this run (from the **MethodDescription** parameter declarations).\n5. **Inputs/Outputs** — material/information artifacts read/written, products/services delivered.\n6. **Resources** — energy, materials, machine time, money (the **only** place we book them).\n7. **Outcome** — success/failure classes, quality measures, acceptance verdicts (**map‑then‑compare** per **ComparatorSet** under **CG‑Spec**; pin editions).\n8. **Links** — predecessor/successor/overlap relations to other Work, and step/run nesting (if part of a bigger operation).\n9. **Context** — the bounded context(s) under which this run is judged (normally inherited from the MethodDescription and RoleAssigning; see A.15 for cross‑checks).\n10. **Effect (Δ)** — `affected → {referent(s)}` + **pre‑state anchor** and **post‑state anchor** (or a declared **Δ‑predicate** evaluated on evidence) on the declared state‑plane (**StatePlaneRef**).\n11. **System** — `executedWithin → U.System` (the operational system/sub‑system accountable for the occurrence; **mandatory**).\n12. **Evidence & Telemetry (optional)** — if the run feeds **G.11** refresh or QD/OEE archives, cite **PathId/PathSliceId** and the active **policy‑id** used for illumination; do not elevate telemetry into dominance without CAL policy.\n\n#### A.15.1:4.3 - Clear distinctions (the four‑slot grammar in action)\n\n| You are pointing at…                          | The right FPF concept  | Litmus                                                          |\n| --------------------------------------------- | ---------------------- | --------------------------------------------------------------- |\n| The **recipe/code/diagram**                   | **MethodDescription**         | Is it knowledge on a carrier?                                   |\n| The **semantic “way of doing”**               | **Method**             | Same Standard across notations?                                 |\n| The **assignment** (“who is being what”)     | **Role → RoleAssigning** | Can be reassigned without changing the system?                  |\n| The **ability** (“can do within bounds”)      | **Capability**         | Would remain even if not assigned?                             |\n| The **dated occurrence** with logs, resources | **Work**               | Did it happen at (t₀, t₁), consume resources, produce outcomes? |\n| The **state change caused this time**         | **Work.Δ**             | Did the referent move from pre→post on the declared state‑plane? |\n\n#### A.15.1:4.4 - Publication (MVPK guard‑rails for `U.Work`) — *normative*\nPublication of `U.Work` across MVPK faces **must** be a typed projection that does **not** mutate intensional semantics (A.7; E.17). Concretely:\n1. **No new claims.** Faces (**PlainView / TechCard / InteropCard / AssuranceLane**) **SHALL NOT** introduce properties beyond the `U.Work` intensional arrow; they **project** presence‑pins only (time window, performer, spec, parameter‑binding occurrence, resource ledger presence, acceptance verdict presence). Numeric/comparable content appears **only** with pins (see 4.4‑4.5 below); **“signature”** is banned on faces.\n2. **No Γ‑leakage.** Faces **MUST NOT** smuggle Γ semantics (union/hull/overlap policy, budget algebra) into prose; whenever aggregation is shown, the face **cites** the Γ‑operator and policy‑id used. Compute totals outside the face per B.1; faces carry **references**, not implied Γ rules.\n3. **No I/O re‑listing.** Per MVPK, faces **do not duplicate** intensional I/O lists. They show **presence‑pins** and **anchors** to carriers/lanes/editions only (E.17 §5.4).\n4. **Lawful orders (sets).** Where a `U.Work` face presents any **comparison or ranking across runs** (e.g., acceptance classes, parity/benchmark inserts), the face **must**: (i) compare **after mapping** via a declared **ComparatorSet**; (ii) **return sets** (Pareto/Archive) when order is partial; (iii) **forbid** hidden scalarization/ordinal means (cf. G.9).\n5. **Comparator/Transport edition pins.** Any numeric/comparable statement on a `U.Work` face **MUST** pin the **CG‑Spec**/**ComparatorSet** edition(s) and, where scale/plane conversion occurs, the **UNM.TransportRegistry** edition (**Φ**/**Φ^plane** policy‑ids). Cross‑context/plane crossings **route penalties to R‑lane only** (Bridge id + Φ) (cf. E.17; G.9).\n6. **Cross‑stance citations.** Any citation whose **stance** differs from the citing `U.Work` face (different `DesignRunTag`, `ReferencePlane`, or `CtxState.locus`) **MUST** carry **BridgeCard + UTS row** (with locus/plane notes and CL routing).\n7. **No surrogate‑run creation.** Faces **MUST NOT** synthesize “virtual runs” from reconstructed records alone; a face may reference only `U.Work` instances that meet Δ‑anchoring in §4.2/§8.\n\n#### A.15.1:4.5 - Crossing visibility & stance tags (work publication discipline) — *normative*\n* **Stance.** `U.Work` is a **run-time occurrence** (DesignRunTag = run). Any face that cites **design-time** or **architheory-time** artefacts (e.g., ComparatorSet, CG-Spec editions, TransportRegistryΦ) is making a **cross-stance/cross-Context** reference and therefore **MUST** publish a **BridgeCard + UTS row** and record **Φ(CL)/Φ^plane** policy-ids; **penalties reduce `R_eff` only**.  \n* **Binding discipline.** **Launch values bind only here** (occurrence). Plan-time proposals remain proposals; do not back-fill plan faces with run-time bindings. **Pre/post state anchors bind here** (pre at start; post at completion or at declared checkpoints).\n",
        "a.15.1:5___work_mereology_(how_runs_form_holarchies)": "### A.15.1:5 - Work mereology (how runs form holarchies)\n\nWe adopt a **4D extensional** stance for occurrences: a Work is identified primarily by its **spatiotemporal extent** and its execution anchors (spec used, performer, parameterization). This avoids double‑counting and keeps aggregation sound. FPF adapts insights from BORO/constructive ontologies to Work while staying practical.\n\n#### A.15.1:5.1 - Parts and wholes of Work (design‑neutral, run‑time facts)\n\n* **Temporal‑part (`TemporalPartOf_work`).** A proper **time‑slice** of a Work (e.g., the first 10 minutes of a 2‑hour run). Useful for monitoring and SLAs.\n* **Episode‑part (`EpisodeOf_work`).** A **resumption fragment** after an interruption (same run identity if policy deems it one episode; see 5.5).\n* **Operational‑part (`OperationalPartOf_work`).** A **sub‑run** that enacts a **factor** of the Method/Spec (e.g., “incision” run within “appendectomy” run), possibly **overlapping** with others in time.\n* **Parallel‑part (`ConcurrentPartOf_work`).** Two sub‑runs that **overlap** in their windows, coordinated by the same higher‑level run.\n\n**Didactic rule:** **Method composition ≠ proof of Work decomposition.** Sub‑runs often map to method factors, but retries, batching, pipelining, and failures make the mapping non‑isomorphic.\n\n#### A.15.1:5.2 - Key relations among Work\n\n* **`precedes/happensBefore`** — strict partial order on Work windows.\n* **`overlaps`** — intervals intersect but neither contains the other.\n* **`contains/within`** — one Work’s window contains another’s.\n* **`causedBy/causes`** — pragmatic causal links (e.g., a rework caused by a failed inspection run).\n* **`retryOf`** — a new Work instance re‑attempting the same MethodDescription with revised parameters.\n* **`resumptionOf`** — a Work episode that **continues** an interrupted run (policy decides identity; see 5.5).\n\nThese relations are **run‑time facts**, not design assumptions.\n\n#### A.15.1:5.3 - Operators for roll‑ups (Γ\\_time and Γ\\_work)\n\n* **Temporal coverage — `Γ_time(S)`**\n  For a set `S` of Work parts, returns a **coverage interval set** (union of intervals) or, when required, the **convex hull** `[min t₀, max t₁]`. Use **union** for utilization; use **hull** for lead time.\n  *Properties:* idempotent, commutative, monotone under set inclusion.\n\n* **Resource aggregation — `Γ_work(S)`**\n  For a set `S` of Work parts, returns the **aggregated resource ledger** (materials, energy, time, money) with de‑duplication rules for shared/overlapped parts (context‑declared).\n  *Properties:* additive on **disjoint** parts; requires **overlap policy** otherwise (e.g., attribute costs to the parent once, not to each child).\n\n**Manager’s tip:** Pick the coverage operator that matches your KPI: **union** for machine utilization; **hull** for calendar elapsed; never mix silently.\n\n#### A.15.1:5.4 - Identity of a Work (extensional criterion, pragmatically framed)\n\nTwo Work records refer to the **same Work** iff, in the relevant context:\n\n* their **time–space extent** is the same (within declared tolerance),\n* they link to the **same `MethodDescription`**,\n* they have the **same performer** (`U.RoleAssignment`), and\n* they bind the **same parameters** (or declared‑equivalent values).\n\nIf any of these differ (or the context declares equivalence absent), they are **distinct** Work instances (e.g., a retry).\n\n#### A.15.1:5.5 - Interruptions, retries, resumptions (episode policy)\n\n* **Retry:** **new Work** with its own window and parameters; link via `retryOf`.\n* **Resumption:** **same Work identity** split into **episodes** if the context’s **episode policy** declares so (e.g., “power loss under 5 minutes keeps identity”).\n* **Rework:** **new Work** caused by a failure in earlier Work; link via `causedBy`.\n\n**Why it matters:** plans, costs, and quality stats depend on whether you treat a disruption as **one episode** or **a new run**. Declare the policy **in the bounded context**.\n\n#### A.15.1:5.6 - Compositionality of effects (Δ)\n\nFor any Work with parts, the **effect of the whole** must be the **rules‑declared composition** of the effects of its parts plus any declared overheads/residuals. Composition must align with the overlap rules used by `Γ_work` (e.g., no double‑count of shared fixed costs, and consistent attribution of variable deltas).\n",
        "archetypal_grounding": "### A.15.1:6 - Archetypal grounding (parallel domains)\n\n#### A.15.1:6.1 - Surgical case (overlap and episodes)\n\n* **Top run:** `Appendectomy_Case#2025‑08‑10T09:05–11:42`.\n* **Spec:** `Appendectomy_v5` (MethodDescription).\n* **Performer:** `OR_Team_A#SurgicalTeamRole:Hospital_2025` (RoleAssigning).\n* **Operational parts:** `Incision` (09:15–09:22), `Exploration` (overlaps with monitoring), `Closure` (11:10–11:35).\n* **Episode:** brief power dip 10:02–10:07 → **resumptionOf** same run (per hospital policy).\n* **Γ\\_time:** union for OR utilization; hull for patient lead time.\n* **Γ\\_work:** totals consumables and staff time once (no double‑count for overlapping sub‑runs).\n\n#### A.15.1:6.2 - ETL pipeline (parallelism and retries)\n\n* **Top run:** `ETL_Nightly_2025‑08‑11T01:00–01:47`.\n* **Spec:** `ETL_v12.bpmn`.\n* **Performer:** `ETL_Runtime#TransformerRole:DataOps_2025`.\n* **Parallel parts:** `Extract_A` ‖ `Extract_B`; `Transform` starts when either completes (overlap).\n* **Retry:** `Load` failed at 01:36; retried with batch size ↓ — **new Work** linked via `retryOf`.\n* **Γ\\_time:** hull for SLA, union for cluster utilization.\n* **Γ\\_work:** sum compute minutes; attribute storage I/O once at the parent.\n\n#### A.15.1:6.3 - Thermodynamic cycle (work as a path)\n\n* **Run:** `Carnot_Cycle_Run#2025‑08‑09T13:00–13:06`.\n* **Spec:** `Carnot_Cycle_Spec` (MethodDescription with Dynamics model).\n* **Performer:** `LabRig_7#TransformerRole:ThermoLab`.\n* **Work identity:** the **path in state‑space** traced during the interval; outputs: heat/work tallies.\n* **Γ\\_time:** straightforward interval; **Γ\\_work:** integrates energy exchange; no “steps” required.\n\n",
        "a.15.1:7___bias‑annotation_(as_in_e‑cluster)": "### A.15.1:7 - Bias‑Annotation (as in E‑cluster)\n\n* **Lenses tested:** `Prag`, `Arch`, `Did`, `Epist`.\n* **Scope declaration:** Universal; temporal semantics and episode policy are **context‑local** via `U.BoundedContext`.\n* **Rationale:** Gives FPF a clean, actionable notion of **occurrence** compatible with `U.RoleAssignment` / **Role Enactment** (A.2.1; A.15) and with 4D extensional thinking, so that costing, quality, and audit rest on **runs**, not on plans or recipes.\n",
        "conformance_checklist": "### A.15.1:8 - Conformance Checklist (normative)\n\n**CC‑A15.1‑1 (Strict distinction).**\n`U.Work` is a **dated run‑time occurrence**. It is **not** a `U.Method` (semantic way), **not** a `U.MethodDescription` (description), **not** a `U.Role/RoleAssigning` (assignment), and **not** a `U.WorkPlan` (plan/schedule).\n\n**CC‑A15.1‑2 (Required links).**\nEvery `U.Work` **MUST** reference:\n(a) `isExecutionOf → U.MethodDescription` (the spec followed; **edition pinned**),\n(b) `performedBy → U.RoleAssignment` (the assigned performer in context), and\n(c) `executedWithin → U.System/SubSystem` (the operational system accountable for the occurrence).\n\n**CC‑A15.1‑3 (Time window).**\nEvery `U.Work` **MUST** carry a closed interval `[t_start, t_end]` (or an explicitly marked open end for in‑flight work) and, where relevant, location/asset.\n\n**CC‑A15.1‑4 (Context anchoring & judgement).**\nA `U.Work` **MUST** be judged inside a declared **`U.BoundedContext`** (the **judgement context**).\n\n* By default, the judgement context is **the context of the referenced MethodDescription**.\n* If `performedBy` references a RoleAssigning in a different context, there **MUST** exist an explicit **Bridge (`U.Alignment`)** or policy stating cross‑context acceptance. Otherwise, the Work is **non‑conformant** in that context.\n\n**CC‑A15.1‑4b (State‑plane anchoring).**\nEach `U.Work` **MUST** declare a `StatePlaneRef` for its Δ‑judgement.\n\n**CC‑A15.1‑5 (RoleAssigning validity).**\nThe `performedBy` RoleAssigning’s `timespan` **MUST** cover the Work interval. If it does not, the Work is **invalid** or must be re‑judged in a context that allows retroactive assignments.\n\n**CC‑A15.1‑6 (Parameter binding).**\nParameters declared by the **MethodDescription** **MUST** have concrete values bound **at Work creation/start** and recorded with the Work. Defaults in the spec do not satisfy this requirement.\n\n**CC‑A15.1‑7 (Capability check).**\nAll capability thresholds stated by the Method/MethodDescription **MUST** be checked against the **holder** in `performedBy` **at the time of execution** (or at defined checkpoints). Violations must be flagged on the Work outcome.\n\n**CC‑A15.1‑8 (Acceptance criteria).**\nSuccess/failure and quality grades **MUST** be determined by the acceptance criteria declared (or referenced) by the **MethodDescription**/**CG‑Spec** **in the judgment context**. The verdict is recorded on the Work.\n\n**CC‑A15.1‑9 (Resource honesty).**\nAll consumptions and costs (energy, materials, machine‑time, money, tool wear) **SHALL** be booked **only** to `U.Work` (not to Method, MethodDescription, Role, or Capability). Estimates may live in specs; **actuals** live in Work.\n\n**CC‑A15.1‑10 (Mereology declared).**\nIf a Work has parts, the chosen **part relation(s)** must be declared (temporal‑part, episode‑part, operational‑part, concurrent‑part). Ambiguous mixtures are forbidden.\n\n**CC‑A15.1‑11 (Γ\\_time selection).**\nFor any roll‑up, the judgement context **MUST** declare which temporal coverage operator applies: **union** (utilization) or **convex hull** (lead time). Silent mixing is prohibited.\n\n**CC‑A15.1‑12 (Γ\\_work aggregation).**\nAggregation of resource ledgers across Work parts **MUST** specify an **overlap policy** (e.g., “attribute shared machine‑time to parent only”) to prevent double‑counting.\n\n**CC‑A15.1‑13 (Identity & retries).**\nA retry **MUST** be modeled as a **new Work** linked via `retryOf`. Interruptions that are treated as the **same run** must be modeled as **episodes** (`resumptionOf`) per a context‑declared **episode policy**.\n\n**CC‑A15.1‑14 (Concurrency & ordering).**\nOverlaps and precedences among Work **MUST** use interval relations (`overlaps`, `precedes`, `contains/within`). Implicit “step order” claims are not admissible evidence.\n\n**CC‑A15.1‑15 (Cross‑context evidence).**\nIf a Work is to be accepted in multiple contexts (e.g., regulatory + operational), either:\n(a) re‑judge it in each context, or\n(b) provide Bridges that map acceptance criteria/units/roles; never assume cross‑context identity by name.\n\n**CC‑A15.1‑16 (Spec changes during run).**\nIf the MethodDescription version changes mid‑run, the Work **MUST** either:\n(a) split into episodes bound to respective specs, or\n(b) record an explicit **spec override** event in the judgement context. Silent substitution is forbidden.\n\n**CC‑A15.1‑17 (Distributed performers).**\nIf multiple RoleAssignings jointly perform the same top‑level Work (e.g., multi‑agent orchestration), the Work **MUST** either:\n(a) designate a **lead RoleAssigning** and list others as **concurrent parts**, or\n(b) be modeled as a **parent Work** with child Works per RoleAssigning.\n\n**CC‑A15.1‑18 (Logs ≠ Work by themselves).**\nLogs/telemetry are **evidence** for a Work; they **do not constitute** a Work unless bound to (spec, performer, time window) and judged in a context.\n\n**CC‑A15.1‑19 (Affected referent).** Each `U.Work` **MUST** name at least one affected referent (e.g., `U.Asset`, product/batch, dataset/document) via `affected → {…}`.\n\n**CC‑A15.1‑20 (State‑change witness).** Each `U.Work` **MUST** carry either (a) explicit **pre‑state**/**post‑state** anchors on the declared state‑plane or (b) a **Δ‑predicate** that can be evaluated on evidence. Trivial “no‑op” runs **MUST** be flagged as such.\n\n**CC‑A15.1‑21 (World anchoring vs. record‑handling).** A run whose only effect is copying/reformatting records **does not** qualify as `U.Work` unless the judgment context declares those records to be the **product referent** (e.g., data‑product manufacture).\n\n**CC‑A15.1‑22 (System anchoring).** Each `U.Work` **MUST** declare `executedWithin → U.System/SubSystem`; if different from the asset of change, keep `affected` explicit.\n\n**CC‑A15.1‑23 (Compositionality of Δ).** For composite Work, the parent effect **MUST** be the declared composition of child effects under the same overlap policy as `Γ_work`.\n\n**CC‑A15.1‑24 (No new claims on faces).** MVPK faces for `U.Work` **SHALL NOT** add properties/claims beyond the intensional arrow; numeric/comparable content **MUST** include unit/scale/reference‑plane/**EditionId** pins; the term **“signature”** is banned on faces.\n\n**CC‑A15.1‑25 (No Γ‑leakage).** Faces **MUST** reference Γ operators/policies by id when showing aggregates; they **MUST NOT** encode aggregation semantics in prose or imply defaults. Γ lives in Part B; faces carry **pinned references** only.\n\n**CC‑A15.1‑26 (No I/O re‑listing).** Faces **MUST NOT** restate intensional I/O; publish **presence‑pins** and anchors only (per MVPK §5.4).\n\n**CC‑A15.1‑27 (Lawful orders; return sets).** Any across‑run comparison presented on a `U.Work` face **MUST** use a declared **ComparatorSet** (map‑then‑compare), **return sets** when order is partial, and **forbid** hidden scalarization/ordinal means.\n\n**CC‑A15.1‑28 (Comparator/Transport pins).** Any numeric/comparable acceptance or KPI on a `U.Work` face **MUST** pin `ComparatorSet.edition`, `CG‑Spec.edition`, and (where conversions occur) `TransportRegistry.edition` with **Φ/Φ^plane** policy‑ids; Bridge ids are mandatory for cross‑context/plane reuse; **penalties → R only**.\n\n**CC‑A15.1‑29 (Telemetry hooks, when applicable).** If a Work instance feeds **G.11** or QD/OEE portfolios, it **SHALL** cite `PathId/PathSliceId` and the active **policy‑id** in its evidence; illumination remains **report‑only telemetry** unless CAL explicitly promotes it.\n",
        "a.15.1:9___temporal_&_aggregation_semantics_(normative_operators_&_invariants)": "### A.15.1:9 - Temporal & Aggregation Semantics (normative operators & invariants)\n\n#### A.15.1:9.1 - Temporal coverage `Γ_time`\n\n* **Input:** a finite set `S` of Work instances or Work parts.\n* **Output:** either (a) the **union** of their intervals, or (b) the **convex hull** `[min t_start, max t_end]`—**as declared by context** and KPI.\n* **Invariants:**\n\n  * **Idempotent:** `Γ_time(S ∪ S) = Γ_time(S)`\n  * **Commutative:** order of elements irrelevant\n  * **Monotone:** if `S ⊆ T` then coverage(S) ⊆ coverage(T) (for union) or hull(S) ⊆ hull(T) (for hull)\n* **Usage guidance:**\n\n  * Use **union** for **utilization/availability** (how much of the clock time the asset was actually busy).\n  * Use **hull** for **lead/cycle time** (elapsed from first touch to last release).\n  * **Manager’s tip:** Write the choice near the KPI; many disputes are just a hidden union‑vs‑hull mismatch.\n\n#### A.15.1:9.2 - Resource aggregation `Γ_work`\n\n* **Input:** a finite set `S` of Work instances or parts with resource ledgers.\n* **Output:** an **aggregated ledger** (materials, energy, machine‑time, money, tool wear) with explicit **overlap policy**.\n* **Invariants:**\n\n  * **Additivity on disjoint parts:** if intervals/resources are disjoint by policy, totals add.\n  * **No double‑count:** overlapping costs must follow the declared policy (e.g., count once at parent).\n  * **Traceability:** each aggregated figure must be reconcilable to contributing Work IDs.\n* **Typical policies:**\n\n  * **Parent‑attribution:** shared fixed costs at parent; variable costs at children.\n  * **Pro‑rata by wall‑time:** split overlaps by relative durations.\n  * **Driver‑based:** allocate by a declared driver (e.g., CPU share, weight, priority).\n",
        "a.15.1:10___cross‑context_checks_(methoddescription_↔_roleassigning_↔_work)": "### A.15.1:10 - Cross‑context checks (MethodDescription ↔ RoleAssigning ↔ Work)\n\nWhen a Work is recorded, perform these **three quick checks**:\n\n1. **Spec–Context Check.** Does `isExecutionOf` refer to a MethodDescription **defined in** the judgement context (or bridged to it)?\n\n   * If **no**, the Work is **out‑of‑context**; either change context or add a Bridge.\n\n1. **RoleAssigning–Context Check.** Is `performedBy`’s RoleAssigning **valid in** the same context (or bridged)?\n\n   * If **no**, the Work is **unassigned** for that context; remedy via a valid RoleAssigning or a policy exception.\n\n1. **Standard–Outcome Check.** Do the Work’s inputs/outputs and metrics satisfy the **acceptance criteria** from the spec **as interpreted in that context**?\n\n   * If **no**, the Work **fails** or is “conditionally accepted” per context policy.\n\n> **Manager’s mnemonic:** Context, assignment, Standard → **CAC**. Fail any → the Work is not acceptable *here* (perhaps acceptable elsewhere).\n\n",
        "a.15.1:11___anti‑patterns_(and_the_right_move)": "### A.15.1:11 - Anti‑patterns (and the right move)\n\n* **“The log is the process.”** Dumping telemetry without binding (spec, performer, context) → **Not Work**. Create a Work, link the log as evidence.\n* **Record‑only transforms.** ETL/replication of records with no declared affected referent (product/dataset as product) → **Not Work** in this context; either declare the dataset as the product referent or move it to `U.WorkPlan`/operations‑support.\n* **Silent cross‑context acceptance.** “Ops accepted it, so audit accepts it.” → Add a **Bridge** or re‑judge in audit context.\n* **Spec drift in mid‑run.** Swapping SOP v5→v6 without recording → Split into episodes or record override.\n* **Budget on the method.** Charging costs to Method or Role → Book **only** to Work; keep estimates in specs.\n* **Part ambiguity.** Mixing retries, episodes, and operational parts with no declared relation → Choose and declare the part relation.\n* **Union/hull confusion.** Changing KPI coverage silently between reports → Declare `Γ_time` policy per KPI.\n* **Double‑count in overlaps.** Summing child and parent resource ledgers → Declare and apply an overlap policy.\n\n",
        "a.15.1:12___migration_notes_(quick_wins)": "### A.15.1:12 - Migration notes (quick wins)\n\n1. **Backfill links.** For existing logs, create Work records and attach `isExecutionOf` and `performedBy`.\n2. **Name the context.** Pick the judgement context explicitly; add Bridges if multiple contexts must accept.\n3. **Publish the episode policy.** Decide when an interruption keeps identity vs forces a new run.\n4. **Choose Γ\\_time per KPI.** Put “union” or “hull” in the KPI definition; stop arguing in meetings.\n5. **Set an overlap policy.** Write one sentence on how shared costs are allocated; apply consistently.\n6. **Pull plans out.** Move calendars to `U.WorkPlan`; let Work record actuals.\n7. **Parameter blocks.** Make parameters explicit and bind them at start; your root‑cause analyses will get 10× easier.\n\n",
        "consequences": "### A.15.1:13 - Consequences\n\n| Benefits                                                                                                                 | Trade‑offs / mitigations                                                                   |\n| ------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------ |\n| **Auditable reality.** Costs, time, and quality attach to concrete runs; root‑cause analysis and accountability improve. | **More records.** You create Work instances; mitigate with templates and automation.       |\n| **Sound roll‑ups.** Γ\\_time/Γ\\_work turn roll‑ups from hand‑waving into declared policy; KPIs become comparable.         | **Policy discipline.** You must choose union vs hull and an overlap policy; write it once. |\n| **Cross‑context clarity.** CAC checks prevent silent model drift; bridges make acceptance explicit.                      | **Bridge upkeep.** Keep mappings short and focused; review at releases.                    |\n| **4D extensional coherence.** Parts/overlaps/retries stop double‑counting and identity confusion.                        | **Learning curve.** Teach episode vs retry; include examples in onboarding.                |\n\n",
        "relations": "### A.15.1:14 - Relations\n\n* **Builds on:** A.1 Holonic Foundation; A.1.1 `U.BoundedContext`; **U.System**; A.2 `U.Role`; A.2.1 `U.RoleAssignment`; A.2.2 `U.Capability`; A.3.1 `U.Method`; A.3.2 `U.MethodDescription`.\n* **Coordinates with:** A.15 Role–Method–Work Alignment (the “four‑slot grammar”); B.1 Γ (aggregation) for resource/time operators; E‑cluster lexical rules (L‑PROC/L‑FUNC).\n* **Informs:** Reporting/KPI patterns; Assurance/evidence patterns (Work as the anchor for audits); Scheduling patterns (`U.WorkPlan` ↔ `U.Work` deltas).\n\n",
        "a.15.1:15___didactic_quick_cards": "### A.15.1:15 - Didactic quick cards\n\n* **What is Work?** *How it went this time* → dated, resourced, accountable.\n* **Four‑slot grammar:** Who? **RoleAssigning**. Can? **Capability**. How? **Method/MethodDescription**. Did? **Work**.\n* **CAC checks:** **Context** (judgement), **assignment** (valid RoleAssigning), **Standard** (acceptance criteria).\n* **Roll‑ups:** `Γ_time = union` (utilization) or `hull` (lead time); `Γ_work` with a declared overlap policy.\n* **Episodes vs retries:** same run split vs new run; write the policy.\n* **Resource honesty:** actuals booked **only** to Work; estimates live in specs.\n",
        "a.15.1:end": "### A.15.1:End\n"
      },
      "content": "### A.15.1:End\n",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.15.2",
      "title": "U.WorkPlan",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.15.2 - U.WorkPlan\n",
        "a.15.2:1___context_(plain‑language_motivation)": "### A.15.2:1 - Context (plain‑language motivation)\n\nOperations live on **time**. Even with perfect roles, abilities, and methods, nothing ships unless we **decide when and by whom** concrete runs **should** happen, under what **constraints** and **budgets**. Teams need a first‑class concept for **plans and schedules** that does **not** get confused with:\n\n* the **semantic “way of doing”** (that is `U.Method`),\n* the **written recipe** (that is `U.MethodDescription`),\n* the **actual execution** (that is `U.Work`), or\n* the **state laws** (that is `U.Dynamics`).\n\n`U.WorkPlan` is that missing anchor.\n\n",
        "problem": "### A.15.2:2 - Problem (what breaks without `WorkPlan`)\n\n1. **“Workflow = schedule” conflation.** Flowcharts or code are used as calendars; resource clashes and SLA misses follow.\n2. **Plan/run blur.** Gantt bars or Kanban tickets are reported as if the work already happened; audits and costing degrade.\n3. **Spec/time leakage.** People and calendars creep into MethodDescriptions; reuse and staffing agility collapse.\n4. **No variance model.** Without planned baselines, deviations in time, cost, and quality cannot be explained or improved.\n5. **Structure entanglement.** BoM and org charts get baked into “process” views; plans become brittle and unmaintainable.\n\n",
        "forces": "### A.15.2:3 - Forces (what we must balance)\n\n| Force                              | Tension we resolve                                                                                      |\n| ---------------------------------- | ------------------------------------------------------------------------------------------------------- |\n| **Universality vs. domain idioms** | One plan concept that fits hospitals, fabs, data centers, and research labs—while honoring local terms. |\n| **Commitment vs. flexibility**     | Plans must be firm enough to coordinate, yet easy to update as reality changes.                         |\n| **Assignment vs. assignment**     | Plans may name intended performers; the actual assignment must still be checked at run time.           |\n| **Budgets vs. actuals**            | Plans carry targets and reservations; only Work carries actual spend.                                   |\n| **Decomposition vs. mapping**      | Plan tasks decompose conveniently; they do not force a shape on actual Work runs.                       |\n\n",
        "solution": "### A.15.2:4 - Solution — the `U.WorkPlan` as the time‑bound intention to execute Work\n\n#### A.15.2:4.1 - Definition\n\n**`U.WorkPlan`** is an **`U.Episteme`** that **declares intended `U.Work` occurrences** over a horizon, with **planned windows**, **dependencies**, **intended performers** (as **role kinds** or **proposed RoleAssignings**), **resource budgets/reservations**, and **acceptance targets**—**within a `U.BoundedContext`**.\n\n> **Strict distinction (memory aid):**\n> **Method** = *how in principle*. **MethodDescription** = *how it is written*.\n> **WorkPlan** = *when, by whom in intent, under which constraints*.\n> **Work** = *how it went this time*.\n\n#### A.15.2:4.2 - Plan Items (what a `WorkPlan` is made of)\n\nA `U.WorkPlan` **contains Plan Items** (think: scheduled tasks/ops), each of which typically states:\n\n1. **Target Method/Spec** — the **Method** to be enacted and the **MethodDescription** intended for enactment.\n2. **Planned window** — e.g., earliest start/latest finish, timebox, recurrence (cron‑like), blackout periods.\n3. **Role requirements** — **role kinds** required (not people), optional **proposed RoleAssigning(s)** if pre‑assignment is allowed in the context.\n4. **Capability thresholds** — minimal abilities required of the performer (checked at run time).\n5. **Resource budgets/reservations** — planned energy/materials/machine slots/money; reservations on assets.\n6. **Dependencies** — precedence/overlap permissions; gates/approvals.\n7. **Acceptance targets** — quality windows/SLA targets to be judged when Work completes.\n8. **Location/asset constraints** — where the run is expected to take place.\n9. **Links to Service promises** (if any) — external commitments that this plan aims to satisfy.\n\n> **Didactic guardrail:** **No logs or actuals** belong in a WorkPlan; **no step logic** or solver internals either—that’s the Method/Spec.\n\n#### A.15.2:4.3 - Clear distinctions (lexical sanity for “schedule/process/workflow”)\n\n| If you say…                                 | In FPF it is…                                        | Why                                               |\n| ------------------------------------------- | ---------------------------------------------------- | ------------------------------------------------- |\n| “The **schedule** for tomorrow’s surgeries” | **`U.WorkPlan`**                                     | Calendar of intended runs (who/when constraints). |\n| “The **workflow** for appendectomy”         | **`U.MethodDescription`** (and `U.Method`)                  | Recipe and semantic way, not a calendar.          |\n| “The **process** already ran at 10:00”      | **`U.Work`**                                         | A dated run with resources and outcomes.          |\n| “The **thermodynamic process** path”        | **`U.Work`** (occurrence) + **`U.Dynamics`** (model) | A realized trajectory plus its model, not a plan. |\n| “The **plan** assigns Dr. Lee”              | **WorkPlan** naming an **intended** RoleAssigning      | assignment is still validated at run time.       |\n| “The **budget** for Shift‑B”                | **WorkPlan** (planned ledger)                        | Actual costs land on **Work**, not on the plan.   |\n\n> **L‑SCHED (lexical rule).** In this document, words like **schedule**, **calendar**, **rota**, **Gantt**, **plan** point to **`U.WorkPlan`** unless explicitly redefined by a bounded context glossary.\n\n#### A.15.2:4.4 - Plan mereology (composition of plans ≠ composition of methods or runs)\n\nKeep three separations crystal‑clear:\n\n* **Method composition** (design‑time semantics) → produces **new Methods**.\n* **Work composition** (run‑time occurrences) → produces **parent/child runs** with overlaps/episodes.\n* **Plan mereology** (epistemic structure) → organizes **Plan Items** for coordination (phases, sprints, shifts), with **precedence** and **resource reservations**.\n\n**Common relations among Plan Items:**\n\n* **`Precedes_pl` / `DependsOn_pl`** — start/finish constraints and gates.\n* **`MayOverlap_pl` / `MutuallyExclusive_pl`** — allowed overlaps vs exclusive windows.\n* **`Refines_pl`** — a child plan item tightens windows/budgets of a parent.\n* **`Alternative_pl`** — planned alternatives (e.g., backup rig, backup team).\n\n**Didactic rule:** A Plan Item **does not force** an identical Work shape; mapping is via **fulfilment** and **variance** (see §6).\n\n#### A.15.2:4.5 - How `WorkPlan` meets `Work` (fulfilment & variance)\n\nWhen reality happens, each `U.Work` may:\n\n* **Fulfil** a Plan Item — link `plannedAs → PlanItem`.\n* **Partially fulfil** — multiple Work instances share one Plan Item (e.g., split run), or one Work fulfils several Plan Items (e.g., consolidated batch).\n* **Deviate** — execute with method/spec substitution, different window, different performer (still valid or policy‑exception).\n* **Be unplanned** — Work with no Plan Item (emergency, ad‑hoc); must be labeled as such.\n\n**Variance dimensions** the plan expects to report on:\n\n* **Schedule variance (Δt):** early/late vs planned window.\n* **Cost variance (Δc):** actual resource spend vs budget.\n* **Scope variance:** different Method/Spec than planned (with justification).\n* **Quality variance:** acceptance verdict vs target.\n* **Assignment variance:** intended vs actual RoleAssigning.\n\n> **Manager’s view:** A plan that cannot report variance is a calendar picture, not a management tool.\n\n",
        "a.15.2:5___what_a_good_`workplan`_states_(review_checklist)": "### A.15.2:5 - What a good `WorkPlan` states (review checklist)\n\nUse this as a human‑readable checklist (not a rigid schema):\n\n1. **Horizon & cadence** (e.g., “W36 surgeries, daily ETL”).\n2. **Plan Items** with: target Method/Spec, planned windows, dependencies.\n3. **Role requirements** (kinds) and **intended assignments** (optional, context‑lawful).\n4. **Capability thresholds** and **safety envelopes**.\n5. **Resource budgets** and **reservations** on assets.\n6. **Acceptance targets** (SLA/quality windows).\n7. **Bridges** if plan spans **multiple contexts** (operations ↔ audit/regulatory).\n8. **Baseline/version** and **change notes** (so variance is attributable).\n9. **Policy pointers** (episode policy, overlap policy for Work roll‑ups if needed for KPIs).\n10. **Exceptions path** (how ad‑hoc/emergency work is planned post‑factum).\n\n",
        "archetypal_grounding": "### A.15.2:6 - Archetypal grounding (parallel domains)\n\n#### A.15.2:6.1 - Hospital OR day plan (shift rota + cases)\n\n* **WorkPlan:** `OR_DayPlan_2025‑08‑12`.\n* **Plan Items:** `Case#1 Appendectomy`, `Case#2 Hernia`, with windows, Context assignments, and surgeon **role kinds**; anesthetist **intended RoleAssigning** provided.\n* **Budgets:** OR time blocks, consumables envelopes.\n* **Fulfilment:** Each surgery Work links to its Plan Item; variances computed (over‑run time, substitutions).\n\n#### A.15.2:6.2 - Fab maintenance weekend (asset reservations)\n\n* **WorkPlan:** `Fab_Maintenance_W36`.\n* **Plan Items:** `Tool_42 chamber clean`, `Tool_13 calibration`; **MutuallyExclusive\\_pl** with production slots.\n* **Reservations:** nitrogen, DI water, metrology window.\n* **Fulfilment:** Actual clean Work happens earlier; variance logged as **early** with cost underrun.\n\n#### A.15.2:6.3 - Data‑center rollout (multi‑context plan)\n\n* **WorkPlan:** `DC_Rollout_Phase‑2`.\n* **Bridges:** Ops context ↔ Security Audit context (different acceptance targets).\n* **Plan Items:** `Deploy Service A`, `Pen‑test A`; dependencies across contexts.\n* **Fulfilment:** Deployment Work passes ops targets; audit Work passes later—variance reported per context.\n\n",
        "a.15.2:7___bias‑annotation_(as_in_e‑cluster)": "### A.15.2:7 - Bias‑Annotation (as in E‑cluster)\n\n* **Lenses tested:** `Did`, `Prag`, `Arch`, `Epist`.\n* **Scope declaration:** Universal; meanings of windows/budgets/permissions are **context‑local** via `U.BoundedContext`.\n* **Rationale:** Elevates **planning/scheduling** to a first‑class episteme that coordinates Methods, RoleAssignings, and Work without conflation.\n",
        "a.15.2:end": "### A.15.2:End\n"
      },
      "content": "### A.15.2:End\n",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.17",
      "title": "Canonical “Characteristic” (A.CHR‑NORM)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.17 - Canonical “Characteristic” (A.CHR‑NORM)\n",
        "context": "### A.17:1 - Context\n\nEvery FPF architheory needs to **measure** various aspects of systems or knowledge artifacts. A dedicated measurement backbone (see **C.MM‑CHR**, Measurement & Metrics Characterization) already exists, prescribing the **CSLC discipline** – i.e. define a **Characteristic**, choose a **Scale** (with a **Unit** if applicable), record a **Level/Value**, and thus obtain a **Coordinate** on that scale, optionally mapping to a **Score** via a **ScoringMethod (USCM)**. However, historically multiple near-synonyms (“axis”, “dimension”, “property”, “feature”, \"metric\") have been used interchangeably for “what is being measured,” and often the _aspect itself_ gets conflated with _how it is expressed_ (units, ranges, labels). This pattern enters the FPF **Kernel lexicon** to **canonize a single term** for the measured aspect and enforce a clear separation between **what** is measured and **how** it is measured.\n",
        "problem": "### A.17:2 - Problem\n\nWhen measurement concepts are not kept rigorously distinct, several issues arise:\n\n-   **Polysemy at the anchor.** Teams say “dimension” or “feature” but mean slightly different things, so the very trait being measured is ambiguous.\n    \n-   **Arity mistakes.** A relational quality (e.g. similarity between two items) might be treated as if it were an intrinsic property of one item, or vice versa, leading to logical errors.\n    \n-   **Expression conflation.** The aspect being measured is often mixed up with its expression – for example, using “scale” or “axis” to mean both the quality _and_ its unit or range. This leads to **unsafe arithmetic** (averaging ordinal ranks, comparing raw numbers from incompatible scales, etc.) because values get interpreted out of context.\n    \n\nIn summary, projects lacking a canonical terminology for metrics risk miscommunication and pseudo-quantitative operations. Measurements of physical quantities, architectural attributes, or performance scores end up on **incommensurate rails** due to inconsistent naming and handling.\n",
        "forces": "### A.17:3 - Forces\n\n-   **F1 – Single anchor of meaning.** Any numeric value is meaningless unless one can ask “value of _what_?”. The measurement’s meaning must be anchored in a single clearly named aspect.\n    \n-   **F2 – Arity clarity.** Some characteristics apply to a single entity (e.g. its mass or length), while others inherently relate multiple entities (e.g. distance between two points, coupling between modules, agreement between judges). If arity isn’t explicit, claims and calculations become corrupted.\n    \n-   **F3 – Scale integrity.** Different kinds of scales permit different operations – e.g. you can average temperatures (ratio scale) but not ranks or grades (ordinal scale) without losing meaning. If one mixes values without regard to scale type or units, the result is nonsense (**pseudo-arithmetic**).\n    \n-   **F4 – Composition discipline.** In complex evaluations, multiple measurements may need to be combined. Without a disciplined approach, people might perform ad-hoc math on apples and oranges (adding scores from unrelated characteristics, etc.). A proper pattern must require any combination to go through a defined monotonic **ScoringMethod** (e.g. a weighted formula) instead of arbitrary aggregation.\n    \n-   **F5 – Transdisciplinarity.** The measurement framework should work for **any domain**. The same conceptual scaffold must serve physical science (e.g. lab temperature readings), software engineering (e.g. module cohesion ratings), and even subjective assessments (e.g. figure-skating scores) without bias. One vocabulary, many CG‑frames.\n    \n-   **F6 – Open-endedness.** As systems evolve, their performance or quality metrics also evolve. Rigid life-cycle stage labels (“Phase 1, Phase 2…”) don’t capture iterative improvement. The pattern should favor an **open-ended state-space** view (revisiting states via checklists, as in an RSG – **RoleStateGraph** with re-entry) over any fixed lifecycle with “terminal” stages.\n    ",
        "solution": "### A.17:4 - Solution\n\n**Establish “Characteristic” as the one canonical construct for “what is measured.”** In every FPF context, the _aspect or trait_ being measured MUST be referred to as a **Characteristic**. This term replaces “axis” or “dimension” in normative usage (those may appear _only_ as explanatory aliases in Plain register). By fixing a single name and schema, we cleanly separate a **Characteristic** from its **Scale** (and **Unit**), and from any observed **Value/Level** on that scale. The solution also differentiates single-entity vs multi-entity cases and binds all measurements to the standard CSLC sequence.\n\nTo enforce this solution, the following rules apply:\n\n-   **A17-R1 (Canonical term).** In all normative models and specifications, the measured aspect **SHALL** be referred to as a **Characteristic**. (Legacy terms “Axis” or “Dimension” are retired from technical vocabulary – see Part J Lexicon Update.)\n    \n-   **A17-R2 (Entity vs. relation subtype).** Each Characteristic **MUST** declare its intended _arity_. An **Entity-Characteristic** applies to exactly one bearer (e.g. _Temperature_ of a reactor, _Evolvability_ of a software module), whereas a **Relation-Characteristic** applies to an ordered tuple of two or more bearers (e.g. _Distance_ between two sensors, _Coupling_ between modules, _Agreement_ among reviewers). The arity is part of the definition and **must be explicit** wherever it’s not obvious from naming.\n    \n-   **A17-R3 (Characteristic space).** Any set of defined Characteristics spans a multi-dimensional **CharacteristicSpace**. Movement or evolution is then described as trajectories through this space (with states revisited or refined over time), rather than as a linear lifecycle through preset phases. This ensures measurements feed into open-ended state modeling rather than locking into “end states.”\n    \n-   **A17-R4 (Lexical guardrails).** Normative text **SHALL** use only the canonical measurement terms: **Characteristic, Scale, Level, Value, Coordinate, Score, Normalization, Unit**. Synonyms like _axis_, _dimension_, _metric_, _grade_, _property_, etc., are **forbidden in formal usage**. (They may appear in narrative explanations or user-facing documentation _only if_ clearly defined as aliases for the canonical terms.) Authors **MUST** not use deprecated terms in identifiers or formal statements, and any didactic alias should be introduced with an explicit mapping to the official term. These lexical rules uphold clarity and are further detailed in **E.10 LEX‑BUNDLE**. \n\n- **A17-R5 (Symbol policy).** **Γ** reserved for holonic composition; **𝒢 : Coordinate→Score** for metric‑level ScoringMethod; **MUST NOT** be conflated; documents **SHALL NOT** reuse Γ for ScoringMethod. **If an ordered Scale is declared, polarity SHALL be fixed; 𝒢 MUST be monotone** w.r.t. that polarity.\n\n- **A17-R6 (Declared polarity).** Every ordered Scale **SHALL** declare one of: **↑‑better**, **↓‑better**, or **non‑applicable** (for purely nominal scales). For interval/ratio scales, polarity fixes the intended order of comparison.\n\n- **A17-R7 (Monotonicity against polarity).** If a template declares an **ordering polarity** on its Scale (↑ better / ↓ better), then **𝒢 MUST be monotone** w\\.r.t. that polarity: higher‑is‑better (resp. lower‑is‑better) in coordinates **implies** ≥ (resp. ≤) in scores.\n\n- **A17-R8 (Arity declaration).** Authors **SHALL** mark a Characteristic as **`U.EntityCharacteristic`** (applies to exactly one bearer) or **`U.RelationCharacteristic`** (applies to a relation of cardinality ≥ 2). Examples: *Cohesion* → entity‑level; *Coupling* → relation‑level.\n\n- **A17-R9 (Relational scale anchors).** For relation‑level cases, the Scale’s admissible values **SHALL** be defined over the **tuple** domain (e.g., distances, similarities, inter‑role latencies). Ambiguity that re‑reads a relational Characteristic as unary is **forbidden**.\n\n- **A17-R10 (Intension vs Description).** The **Characteristic** remains the **intensional object**; any rubric, catalogue of levels, or examples are **descriptions**. Keep the intensional Characteristic distinct from its descriptive episteme (cf. `U.Episteme` roles: Object–Concept–Symbol).\n\n#### A.17:4.1 - CharacteristicSpace & Change Reasoning *(Normative/Clarifying)*\n\n**R17 — CharacteristicSpace declaration.** When an architheory reasons about **change**, it **SHALL** name the **CharacteristicSpace** (the set of Characteristics, with Scales, units, and topology assumptions) in which motion is considered.\n\n**R18 — RSG framing, not lifecycle.** Change narratives **SHALL** be framed as movement on a **reachable‑states graph (RSG)** with **checklists** that certify state acquisition; **“lifecycle”** staging is **deprecated**. *(A.17 conforms to the open‑ended evolution stance of the Kernel.)*\n\n**I7 — Vector interpretation.** A **U.Coordinate** vector may collect multiple coordinates for multi‑Characteristic reasoning; composition into a single Score, if desired, is an **explicit new 𝒢** on that vector.\n",
        "archetypal_grounding": "### A.17:5 - Archetypal Grounding (System & Episteme Examples)\n\n**In a physical system (`U.System`):** Consider a **Distance** Characteristic defined for a pair of physical objects. For example, two machines in a factory have a Distance of 3.5 meters between them. Here _Distance_ is a Relation-Characteristic (applies to the pair), with an associated Scale (e.g. a ratio scale in meters), and the measured 3.5 m is a **Coordinate** on that scale. If we instead look at an **Engine Temperature** Characteristic (unary), a particular engine might have a Temperature of 350 K at some moment – _Temperature_ (the Characteristic) is clearly separated from how it’s measured (Scale in Kelvin) and the reading (350, a Coordinate on that scale).\n\n**In an epistemic context (`U.Episteme`):** Consider a **Formality** Characteristic to rate a documentation artifact’s rigor. We might define an ordinal Scale with named Levels such as _Informal_, _Semi-formal_, _Formal_. A given specification document can then be said to have _High Formality_ – meaning it occupies the “Formal” **Level** on the Formality Scale. Here _Formality_ (Characteristic) captures _what_ we measure about the document, while the tiered Scale (with qualitative levels) expresses _how_ we categorize it. Because we use an ordinal scale, we can rank documents by Formality, but we would not average “Semi-formal” and “Formal” (avoiding meaningless arithmetic on an ordinal metric). In another knowledge context example, one could define a Characteristic **Reliability** for a knowledge source with a percentage Scale from 0 to 100%. An article’s reliability might be 85% – which is only interpretable by knowing it refers to “Reliability” on a 0–100% Scale (i.e. a specific Coordinate on that Characteristic’s scale).\n",
        "bias_annotation": "### A.17:6 - Bias-Annotation\n\nThis pattern is deliberately **domain-neutral** and introduces no bias toward any particular discipline or measurement type. By enforcing a uniform lexicon, A.17 actually mitigates bias: it prevents **disciplinary jargon** from creeping into core definitions (ensuring, for instance, that a software metric isn’t given a vague custom term when it’s fundamentally a Characteristic). The **Didactic lens** is strongly served: using one precise name per concept improves clarity for all audiences. There is a slight initial cost in re-labeling legacy terms (e.g. renaming “dimensions” to Characteristics), but this is offset by the long-term **Cognitive Elegance (P‑1)** – the framework becomes easier to learn and less prone to misinterpretation. No single domain’s terminology dominates, and the pattern explicitly supports both quantitative (physics-like) and qualitative (judgment-based) measurements, reflecting **Pragmatic neutrality**. The requirement of open-ended state-space thinking aligns with **P‑10 (Open-Ended Evolution)**, ensuring we don’t bake in lifecycle biases that assume development must terminate at a final stage. In summary, A.17 imposes a disciplined vocabulary that is broad enough for all fields and free of hidden assumptions, thereby avoiding subtle ontological or cultural biases in the measurement model.\n",
        "conformance_checklist": "### A.17:7 - Conformance Checklist\n\nWhen authoring or reviewing FPF-compliant metrics, use the following checklist to ensure **Characteristic normalization** is applied:\n\n1.  **Declared Characteristic:** Have you explicitly named a **Characteristic** for each aspect being measured, instead of using generic terms? (e.g. use _“Reliability”_ as a Characteristic name rather than saying “this dimension”).\n    \n2.  **Arity Explicit:** Is it clear whether the Characteristic is unary or relational? If a metric involves a relationship, are the participating entities (pair, tuple, etc.) identified in its definition?\n    \n3.  **Separate Scale/Unit:** For each Characteristic, have you defined the **Scale** (and **Unit**, if applicable) separately, rather than embedding units or ordinal terms in the name of the Characteristic? (e.g. _“Length (m)”_ should be captured as Characteristic = _Length_, Unit = _meter_).\n    \n4.  **Scale-appropriate operations:** Are you only performing comparisons or calculations that make sense for the declared scale type? (No averaging of ranks, no mixing of units – ensure **ordinal** Characteristics aren’t treated like numbers, and **interval/ratio** values respect zero and units.)\n    \n5.  **No implicit aggregation:** If multiple measurement readings are combined, is there a defined **ScoringMethod** (with monotonic logic) that produces a **Score**? Avoid any ad-hoc “overall score” that simply adds or averages raw values from different Characteristics.\n    \n6.  **Canonical terminology in use:** Are you using the terms _Characteristic_, _Scale_, _Level/Value_, _Coordinate_, _Score_, _ScoringMethod_, _Unit_ in all formal descriptions? Confirm that no deprecated synonyms (axis, dimension, etc.) appear in technical content or identifiers (they can appear in Plain explanations only with proper reference to the canonical term).\n    \n7.  **Open-ended progression:** (If applicable) When modeling progress or change using metrics, have you considered using a state-space of Characteristics rather than a fixed sequence of phases? This check is to encourage leveraging the open-ended nature of CharacteristicSpaces, especially in evolutionary or iterative processes.\n    \n_(Failure to satisfy the above indicates a violation of this pattern’s intent. The **LEX-BUNDLE** rules in E.10 provide automated checks for term usage, and MM-CHR templates enforce explicit Characteristic/Scale definitions.)_\n",
        "consequences": "### A.17:8 - Consequences\n\nBy instituting **Characteristic** as the single term and enforcing the CSLC structure, this pattern yields several positive outcomes:\n\n-   **Unambiguous metrics:** Every measurement has a single, well-defined anchor of meaning – the Characteristic – eliminating guesswork about “what is this number about?”.\n    \n-   **Separation of concerns:** We cleanly separate _what_ is measured from _how_ it’s represented. The Characteristic names the quality of interest, while the Scale/Unit defines the expression. A raw value now **means nothing by itself** – it must be read as “X units on the Y scale of Z Characteristic,” which greatly reduces misinterpretation.\n    \n-   **Unary vs. relational clarity:** The explicit distinction between Entity-Characteristic and Relation-Characteristic ensures that relational properties (like “distance between A and B” or “consistency among experts”) aren’t mistakenly treated as inherent properties of a single object. This guards against logical errors and data modeling mistakes.\n    \n-   **Cross-domain comparability:** All measurements, regardless of domain, follow the same **CSLC** rails. This means a temperature in Kelvin and a reliability score in percent can each be traced through Characteristic → Scale → Coordinate. They can’t be directly compared unless designed to be, which is _good_: any composite scoring must be done via an explicit **SCP** mapping to a common **Score** scale. The pattern thus enables interoperability (through well-defined Score bridges) while preventing illegitimate comparisons.\n    \n-   **Consistent evolution framing:** By retiring the idea of a bespoke “lifecycle” for every process and instead viewing changes as movement in a CharacteristicSpace, the pattern aligns metric thinking with state-based reasoning (e.g. as used in dynamic models). There is no artificial “final state” for improvement – a system can always evolve to a new coordinate without violating a lifecycle Standard. This open-ended view encourages continuous improvement and refinement, echoing FPF’s emphasis on evolutionary development.\n    \n\nThere are few downsides. One consequence is that modelers must learn the canonical terms and possibly refactor existing documentation (a short-term effort). Also, enforcing scale integrity means quick-and-dirty aggregate scores are not allowed unless justified via a SCP – this introduces a healthy “pause” to ensure composite metrics are well-founded. Overall, the benefits in clarity and correctness far outweigh the overhead. Teams gain a _lingua franca_ for metrics, and the risk of metric abuse (mixing apples and oranges) is significantly reduced.\n",
        "rationale": "### A.17:9 - Rationale\n\nThe Canonical Characteristic pattern is a direct response to recurring measurement pitfalls. By insisting on “one precise name per concept”, it upholds **Strict Distinction (A.7)**, ensuring that the framework never treats two different ideas as one. For instance, earlier practice might label both a requirement category and its score as “dimension,” causing confusion; with A.17, the _aspect_ is a Characteristic and its _score_ is separate, so each idea has its place. This clarity is pedagogically vital (**P‑2 Didactic Primacy**): readers and contributors immediately know what a term means and how to interpret any value associated with it.\n\nThe solution also draws on fundamentals of measurement theory (Stevens’ levels of measurement) to prevent misuse. By encoding scale types and unit handling into our patterns, we avoid the “pseudo-quantitative” fallacies – no more averaging things like _risk levels_ or adding up _grades_ as if they were true numbers. In effect, A.17 puts a safeguard around **P‑1 Cognitive Elegance and P‑7 Ontological Parsimony**: we use a minimal, universal set of measurement constructs, and we avoid bloating the conceptual space with domain-specific or redundant terms. One canonical set of terms also makes the framework more teachable and **composable across contexts**, since architheories and projects aren’t inventing new synonyms that others must decipher.\n\nImportantly, distinguishing Entity vs Relation Characteristics future-proofs the reasoning model. It enforces a modeling rigor seen in domains like physics (where properties vs. relations are carefully distinguished) and brings it to architecture and knowledge domains. This rigor supports advanced reasoning in FPF – for example, **A.3.3 (Dynamics)** can treat system state variables as a well-defined set of Characteristics, and assurance patterns can trace **evidence metrics** unambiguously to the exact aspect measured. It also means any attempt to compare or combine metrics has to be explicit (via ScoringMethods), which inherently improves **transparency and auditability** (a key FPF goal).\n\nFinally, retiring the “lifecycle” vocabulary in favor of state-space trajectories aligns with FPF’s **open-ended evolution** principle. It acknowledges that improvement is not a predefined path but a navigable space. This shift in mindset (from lifecycle stages to checklisted state transitions) removes an implicit bias that systems _ought_ to reach a “final” maturity stage – instead, it keeps the door open for perpetual refinement, which is philosophically aligned with continuous learning and adaptation.\n\nIn summary, A.17 is the linchpin that turns a loose collection of measurement practices into a **coherent, principle-driven system**. It rationalizes the language, thereby rationalizing thought: by speaking in one clear voice about measurements, FPF ensures that every number in the system can be trusted to answer “value of what, on what scale, relative to what context.” This rationale is reflected in improved model integrity and cross-domain trust in the meaning of metrics.\n",
        "relations": "### A.17:10 - Relations\n\n-   **Builds on / Elaborates:** _FPF Core Measurement Schema_ (as outlined in C.16). A.17 lifts the metric template concepts from C.16 into a kernel-level rule. It also reinforces **A.7 Strict Distinction**, by giving each measurement concept a unique name and forbidding overloaded terms.\n    \n-   **Constrains:** All other patterns and architheories that define or use metrics. For example, **A.3.3 `U.Dynamics`** (system dynamics) must name its state variables as Characteristics with proper scales (it cannot refer to them loosely as “KPIs” without context). Similarly, any **Service-level agreements (A.2.3 `U.ServiceClause`)** or **assurance calculations (B.3, D.3 patterns)** that involve measurements are governed by this canonical terminology (no unwarranted synonyms or unit confusion per ISO/IEC 80000, ISO/IEC 25024, QUDT, SOSA/SSN best practices). The pattern’s lexical rules are part of the **LEX-BUNDLE** (E.10) – any FPF-conformant context must adhere to these naming conventions.\n    \n-   **Coordinates with:** **A.18 (CSLC-KERNEL)**, which defines the minimal **Characteristic/Scale/Level/Coordinate** Standard in detail. A.17 provides the vocabulary and basic distinctions (what is a Characteristic, and its arity), while A.18 applies this to ensure each measurement template is well-formed. Also coordinates with **C.KD-CAL** and **C.CHR-CAL** (Knowledge Dynamics Calculus, Characterization Calculus) – those architheories use the Characteristic/Scale constructs to build domain-specific metrics (e.g. knowledge quality scores) and rely on A.17’s canon for consistency.\n    \n-   **Anticipates:** **E.10 Lexical Discipline** rules – A.17’s enforcement of a single term and controlled aliases is a concrete instance of the lexical uniformity mandated in E.10. It also paves the way for **F.7 Concept-Set Bridges** in Unification patterns, since external ontologies for quantities (ISO 80000, QUDT, etc.) can be mapped cleanly onto FPF Characteristics now that the term is fixed. In short, A.17 is a foundational lexicon pattern that a) ensures internal consistency and b) simplifies alignment with external standards for measurable properties.\n    ",
        "a.17:end": "### A.17:End\n"
      },
      "content": "### A.17:End\n",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.18",
      "title": "Minimal CSLC in Kernel (Characteristic ⟷ Scale ⟷ Level ⟷ Coordinate) (A.CSLC‑KERNEL)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.18 - Minimal CSLC in Kernel (Characteristic ⟷ Scale ⟷ Level ⟷ Coordinate) (A.CSLC‑KERNEL)\n\n**Aliases (for narrative use only):** _“Axis”_ (≈ Characteristic), _“Point”_ (≈ Coordinate). _(These colloquial aliases may be used in Plain language **explanations**, but never in formal identifiers or normative text.)_\n",
        "problem": "### A.18:2 - Problem\n\n**Uninterpretable values.** A raw number or label means nothing without knowing **what aspect it measures** and **how it is measured**. The string “4”, the label “High”, or the real number 9.81 convey no insight unless we know **which Characteristic** they pertain to and the **Scale** that gives them meaning. In cross-disciplinary work this ambiguity is magnified: a “5” could be a risk rank (ordinal), a length in meters (ratio), or a satisfaction score (perhaps interval). Common failure modes include:\n\n-   In **ordinal settings** (e.g. expertise levels _Novice < Skilled < Expert_), one can **rank** values but not meaningfully add or average them. Treating ordinal labels like numbers (e.g. averaging _Novice=1, Expert=3_) produces invalid results.\n    \n-   In **cardinal settings** (e.g. seconds, meters, degrees Kelvin), arithmetic operations do make sense – but only if units are respected and zero is meaningful (for ratio scales). If we strip away units or mix scales (seconds vs. minutes), we again get nonsense.\n    \n\nWithout a strict Standard, one team might treat “High” and “Medium” as having a numeric gap, another might average **4** (on a 5-star scale) with **4** (as 4 seconds) because both are “4”. **Inconsistent practices make cross-domain reasoning impossible.** We need a kernel-level solution that _fixes_: (a) the **aspect being measured**, (b) the **scheme by which it’s measured**, and (c) the **type of scale structure** (ordinal vs. metric), _and_ that ensures each reported value is bound to that scheme. At the same time, the Standard should _not_ force artificial numeric detail where it isn’t applicable (e.g. we shouldn’t assign meaningless numbers to purely qualitative tiers just to satisfy a structure).\n",
        "forces": "### A.18:3 - Forces\n\n-   **F1 – Transdisciplinarity.** The pattern must uniformly handle measurements in _physical domains_ (e.g. length, time, temperature), _system attributes_ (e.g. a module’s coupling or reliability), and _human judgments_ (e.g. user satisfaction scores). It needs to be neither overly quantitative (alienating softer domains) nor overly qualitative (lacking precision for hard science).\n    \n-   **F2 – Comparability vs. freedom.** We want to compare “like with like” – e.g. two readings of the same Characteristic on the same Scale – with absolute confidence. At the same time, the system should allow **different Scales for the same Characteristic** when necessary (for example, one project might measure Quality on a 0–5 star scale, another on a 0–100 percentage scale). The pattern must permit such flexibility _without_ letting those differing scales be conflated.\n    \n-   **F3 – Ordinal vs. cardinal integrity.** The Standard should preserve the nature of the data: **order-only vs order+distance**. If something is ordinal (ranks, grades), the framework should prevent unwarranted numeric operations on it. If it’s cardinal (real-valued with units), the framework should enable arithmetic but still keep track of units and zero. In essence, it must protect ordinal data from “leaking” into interval arithmetic.\n    \n-   **F4 – Named tiers vs. continuous magnitudes.** In many domains, **named Levels** (tiers or grades) are useful – e.g. Technology Readiness Levels or bond credit ratings – whereas in others, a continuous scale is needed. The pattern should support **optional Level labels** (for tiered scales) _without forcing_ every scale to have such labels. In other words, Levels are an add-on for discrete/tiered scales, not a requirement for truly continuous measures.\n    \n-   **F5 – Method agnosticism.** The kernel Standard should say _what_ must be defined (Characteristic, Scale, etc.) but **not prescribe how measurements are obtained**. Whether a value comes from a sensor reading, a simulation, or an expert judgment is up to the respective architheory (e.g. Sys-CAL vs. KD-CAL). The pattern must not bake in any process or scoring methodology; it only ensures that once a measurement exists, it’s well-formed and comparable. This avoids locking in any particular assessment method.\n    \n",
        "solution": "### A.18:4 - Solution\n\n**Adopt a minimal “one characteristic – one scale – one coordinate (value)” Standard for all measurements.** In the FPF kernel, any metric must bind **exactly one Characteristic to exactly one Scale**, and any observation produces **one Coordinate (value)** on that Scale (with an optional **Level** name if the scale has discrete tiers). We nickname this the **CSLC clause**:\n\n> **Exactly one Characteristic + exactly one Scale ⇒ one Coordinate (value), with an optional Level.**\n\nConcretely, the parts of this clause are defined as follows:\n\n-   **Characteristic:** the aspect or feature being measured (the “CG‑frame” along which comparison is made). It answers “_What are we measuring?_” – e.g. _Distance, Temperature, Quality, Reliability_.\n    \n-   **Scale:** the organized set of possible values that the Characteristic can take, including the type of scale (_ordinal_, _interval_, or _ratio_), the measurement **Unit** (if applicable), and any bounds or structure. The Scale defines “_How do we measure it?_” – e.g. “meters on a linear scale from 0 up to 1000” or “ratings 1 through 5 with ordering only”.\n    \n-   **Coordinate:** a concrete measured value that locates the subject on the chosen scale. This could be a number (for a numeric scale) or a category label (for an ordinal scale). It answers “_What is the result?_” – e.g. 7.4 (meters), or _Expert_ (level).\n    \n-   **Level (optional):** a named **tier or category** on the scale, used only if the scale is tiered or discretized. For example, an ordinal scale might have Levels _Low, Medium, High_. A Level is essentially a human-friendly label for certain coordinates or ranges. On purely continuous scales, **Level** is not used.\n    \n\nUsing this **CSLC structure**, every measurement is unambiguous and self-contained: the Characteristic tells us the context, the Scale tells us how to interpret the value, and the Coordinate is the outcome on that scale (with a Level label if appropriate). Notably, this pattern _forbids bundling multiple characteristics into one metric_ – each metric template is one-characteristic-per-template to keep semantics crisp. If something needs to assess multiple factors, it should be modeled as multiple CSLC metrics or a higher-level composite (see §8 below). This one-aspect-one-scale rule is what allows unambiguous comparison and prevents hidden complexity.\n\nFinally, the solution ensures **tier optionality**: If a domain uses named Levels, we include them; if not, we don’t force it. For example, one can have a _Bug Severity_ Characteristic with Levels {Minor, Major, Critical} on an ordinal scale, whereas a _Length_ Characteristic would have a continuous scale (no predefined levels, just units). Both fit the pattern.\n",
        "archetypal_grounding": "### A.18:5 - Archetypal Grounding (System & Episteme Examples)\n\n**In a physical scenario (`U.System`):** Consider an athlete’s long jump. We define a Characteristic **Jump Distance** with a Scale “meters (m)” ranging from 0 upward (ratio scale with meters as the unit). When the athlete jumps and lands at 7.45 m, we record a **Coordinate** of _7.45 m_ for the Jump Distance Characteristic. Here, Jump Distance is the Characteristic, the meter-scale is the declared Scale, and _7.45 m_ is the value (Coordinate). Because this is a cardinal measurement, we can meaningfully say one jump is 1.5 m longer than another, etc. Now consider another metric in the system: **Battery Health** of a device, which might be categorized qualitatively. We could define an ordinal Scale with Levels like _Good, Fair, Poor_ for the Battery Health Characteristic. If a particular device is rated “Poor”, that is a Coordinate on the Battery Health scale (with _Poor_ as the Level name). No arithmetic is done on these labels, but we can order devices by health (Good > Fair > Poor). Both examples illustrate the one-characteristic-one-scale rule: the jump’s distance is not combined with any other aspect; the battery’s health is evaluated on its own defined scale.\n\n**In a knowledge context (`U.Episteme`):** Consider measuring an author’s expertise in a certain domain. We introduce a Characteristic **Expertise Level** for a person, with an ordinal Scale defining tiers such as _Novice, Competent, Expert_. Alice might be assessed at _Expert_ level in software engineering – that’s a **Coordinate** on the Expertise Level scale for the Characteristic “Software Engineering Expertise”. Bob might be at _Competent_. We cannot average Alice’s and Bob’s levels, but we can say the scale is ordered (_Expert_ > _Competent_ > _Novice_). For a more quantitative episteme example, consider a Characteristic **Hypothesis Confidence** for a scientific claim, with a Scale 0–1 (or 0–100%) representing probability or confidence level (ratio scale). One hypothesis might have a confidence of 0.95, another 0.7; these are Coordinates on the Confidence scale. We can compare them numerically (0.95 is higher than 0.7, and 0.95 _implies_ a stronger belief), and we could even combine multiple confidence values through Bayesian formulas (if justified) – but crucially, we would only do so in a way that respects their scale (probabilities combined properly, not treated as arbitrary scores). The Expertise Level and Hypothesis Confidence examples show how the CSLC pattern accommodates both an ordinal qualitative measure and a continuous quantitative measure in the knowledge domain, each with one Characteristic and one defined Scale.\n",
        "bias_annotation": "### A.18:6 - Bias-Annotation\n\nThe CSLC-Kernel pattern is crafted to be **maximally inclusive of different measurement types** while imposing just enough structure to ensure consistency. It does not privilege any particular domain or modality of measurement: a subjective 5-star rating is treated with the same formal rigor as a physical length in meters. In terms of the FPF principle lenses, this pattern consciously balances the **Architectural/Ontological** needs (clear structure for data) with the **Pragmatic/Didactic** needs (flexibility and clarity for users). There is little risk of cross-domain bias here because the pattern explicitly supports both extremes (ordinal and ratio, qualitative and quantitative). By remaining **method-agnostic**, it avoids bias toward certain validation techniques – e.g. it doesn’t assume every measurement comes from an instrument (it could come from expert judgment just as well). One might argue the pattern enforces a somewhat formal approach to what could be informal measures (forcing definition of scale and characteristic), but this formalism is lightweight and is precisely what makes the metric interpretable. In summary, A.18 embodies **neutrality**: it’s a container that fits any content as long as that content is well-labeled. It reinforces **P‑2 (Didactic Primacy)** by making all metrics self-explanatory in terms of what and how, and respects **P‑1 (Cognitive Elegance)** by using a minimal, uniform scheme. No cultural or disciplinary assumptions are baked in – an anthropologist’s “Cultural Significance” scale can live alongside an engineer’s “Voltage” scale with equal status. The pattern’s requirement for declaring polarity (“higher is better” vs “lower is better” vs target range) further avoids bias in interpretation – it prevents the assumption that “more is always better,” which might be untrue in many contexts (e.g. for error rates, lower is better). All these considerations ensure that A.18 introduces no hidden skew; it merely provides a fair playing field for all metrics.\n",
        "conformance_checklist": "### A.18:7 - Conformance Checklist\n\nWhen defining a new metric template or using measurements, practitioners **SHALL** verify the following:\n\n1.  **One characteristic, one scale:** Each metric **template** binds exactly **one Characteristic** to exactly **one Scale**. If you find a metric trying to cover multiple things at once, split it into separate metrics.\n    \n2.  **Polarity declared:** For any **ordered** Scale (ordinal/interval/ratio), the **polarity** (“higher‑is‑better”, “lower‑is‑better”, “targeted optimum (symmetric or asymmetric around a declared target)”) **SHALL** be declared at the **template** that binds a Characteristic to a Scale. State whether higher values are better, lower are better, or if an optimal range/target exists. (For example: \\*“higher is better” for a performance score, \\*“lower is better” for error count, or _“target 37 °C” for body temperature where deviation in either direction is worse_.) This ensures that anyone comparing two values knows which way is “up.”\n    \n3.  **Unit and level clarity:** If the Scale is quantitative, specify the **Unit** (e.g. _seconds, meters, %_) and make sure all values include or assume that unit. If the Scale has named Levels, list them clearly and use them consistently. Do **not** use the same label to mean different things on different scales, and avoid using unit terms in Characteristic names (the unit belongs with the scale).\n    \n4.  **Scale-appropriate operations only:** Only perform those comparisons or calculations that are valid for the given scale type. For a nominal scale, you can check equality but not order. For an ordinal scale, you can order or rank values but not do math like “A minus B.” For interval scales, addition/subtraction is OK (with unit conversion if needed), but ratio comparisons (A is twice B) might not make sense without a true zero. For ratio scales, all arithmetic operations are allowed _with proper attention to units_. This check prevents logical errors (e.g. averaging “High” (3) and “Medium” (2) and getting 2.5 — which is meaningless).\n    \n5.  **No bare numbers:** Never present a raw number or value without its context of Characteristic and Scale. If someone sees “42” in your output, they should _also_ see or know “42 of what, measured how.” A reader who is not aware of the metric’s template should not be left guessing what a given value signifies. In practice, this means labeling reports and data with the metric name or identifier so that values can be traced back to their meaning.\n    \n6.  **Template bridges for cross-metric comparison:** If you intend to compare or aggregate measurements from **different templates** (different Characteristics/Scales), ensure an explicit **ScoringMethod** or conversion is defined. For example, if you need to combine a “usability score” (0–5 stars) with a “security score” (0–100%), you might define a new **Score** that maps both onto a common 0–10 scale via monotonic functions. Without such a bridge, do not directly mix metrics – keep them separate in analysis. This guarantees that any cross-metric reading has a well-founded basis.\n    \n7.  **Level optionality respected:** If your Characteristic doesn’t naturally have tiers, don’t force it to have **Level** names (you can leave the Level concept unused). Conversely, if your Characteristic is commonly described in categories, it’s fine to define Levels for clarity. The key is to use the Level field intentionally: either not at all (for truly continuous measures) or in a fixed, **non-overlapping** way (for discrete categories). Do not use “Level” for something that behaves like a continuous value (it would be confusing to assign a label where a number would do, or vice versa).\n8. **Comparability test:** Two Coordinates are comparable iff same Characteristic+Scale (incl. unit, polarity). Otherwise — Score‑level only after a declared SCP to a bounded range.\n\n_(The above serve as normative checkpoints. Many of these are automatically supported by using the standard metric templates in software: e.g. the system will enforce one Characteristic per template, require a unit for ratio scales, etc. The **Lexical rules** from A.17/E.10 are assumed: use canonical names and notations for all parts of the metric.)_\n",
        "consequences": "### A.18:8 - Consequences\n\nAdopting the minimal CSLC Standard in the kernel yields a number of benefits:\n\n-   **Universal interpretability:** Every measurement is intrinsically self-describing. One cannot have a “mystery number” floating around; by design you must know it’s _X (Coordinate) on Y Scale of Z Characteristic_. This dramatically reduces miscommunication in reports and data exchange. An engineer and an analyst can share a metric knowing they interpret it the same way, because the context travels with the value. Level is optional when scale is tiered or discreet. \n    \n-   **Safe comparison and aggregation:** Values can only be compared when they belong to the same Characteristic and Scale (or when an authorized SCP converts them). This prevents the common error of comparing apples to oranges. When cross-comparison is needed, the pattern funnels us into creating a proper normalization, which improves the soundness of composite scores. Essentially, it’s now impossible to accidentally average an uptime percentage with a user satisfaction rating, for example, without explicitly defining how to map one to the other.\n    \n-   **Flexibility across domains:** The pattern is **transdisciplinary**. It doesn’t matter if the measurement is temperature in Kelvin, length in inches, code complexity in “abstract points,” or user satisfaction on a five-level Likert scale – all are handled uniformly. This makes it easier to plug new architheories or domains into FPF, since they don’t need special rules for their metrics; they just instantiate the CSLC template in their context.\n    \n-   **Ordinal and cardinal handled with equal rigor:** By explicitly classifying scales, the pattern gives ordinal data the respect it deserves (no pretending it’s numeric) and gives ratio data the formal context it needs (units, zero, etc.). This balance means both qualitative assessments and quantitative measurements live side by side, each with their constraints respected. Domains that lean heavily on categorical ratings benefit from the **Level** concept (with no pressure to assign fake numbers), and domains that use real measurements benefit from unit enforcement and type-aware computations.\n    \n-   **Clarity in multi-factor scoring:** The prohibition of implicit multi-characteristic measures means that any “overall” score or index has to be constructed out of known pieces. This tends to improve the transparency of complex scoring schemes. If an organization wants to create a single index from 5 different metrics, A.18 forces them to introduce a defined ScoringMethod function that combines those 5 Coordinates into one Score, with declared monotonicity and bounds. The consequence is that composite metrics become auditable and debatable (you can examine the weighting or formula) rather than opaque sums.\n    \n-   **Methodological neutrality (and innovation):** Because the kernel imposes no method for obtaining the values – only how to frame them once obtained – architheories and tool builders are free to innovate in how they measure things. The Standard just ensures that once they do, everyone else can understand and use the results correctly. This separation of concerns (what vs. how) accelerates multi-disciplinary collaboration: a social scientist’s observational scale can feed into a systems model without any confusion, as long as it’s couched in the CSLC terms.\n    \n\nOn the downside, **users must do a bit more upfront work** to define their metrics. The pattern’s requirements (declare Characteristic, define Scale, etc.) mean one cannot simply say “we’ll track a risk score” without further detail. In practice, this is a _desirable_ trade-off: the extra effort (perhaps a few minutes to set up a metric template) prevents far greater confusion down the line. Another possible trade-off is **multiplicity of scales** – the pattern allows the same Characteristic to have multiple scales (in different contexts or versions), which might fragment data if not managed (e.g. two teams measuring “Performance” on different scales). However, it also provides the remedy: make the difference explicit and, if needed, build a conversion ScoringMethod. This explicitness is actually beneficial, as it highlights when “Performance (0–5)” is not directly comparable to “Performance (Percentage)”. In short, any fragmentation is out in the open and can be dealt with via alignment or bridging.\n\nOverall, A.18’s consequences are overwhelmingly positive: **measurements become first-class, well-understood citizens of the model.** The cost is a slight increase in definition effort and discipline, which is a small price for coherence. Once this pattern is in place, higher-level patterns (in Parts B, C, D) that reason about metrics can rely on it. For example, trust calculations (Part D) can assume that any metric they consume has a known scale and meaning, and knowledge dynamics algorithms (Part B or C) can safely combine evidence knowing the comparisons are valid. The minimal CSLC Standard is thus a foundational enabler for robust, cross-domain assurance in FPF.\n",
        "rationale": "### A.18:9 - Rationale\n\nThe rationale behind A.18 is to enforce _semantic clarity_ at the data level, thereby solving a host of downstream problems. Without this pattern, one must constantly ask, “What does this number mean? Can I combine these two values?” – questions that have led to many project errors. By building the answers into the framework (“every number knows its unit, scale, and aspect”), we front-load the work and eliminate ambiguity. The solution directly addresses each force:\n\n-   **Transdisciplinarity:** We include both ordinal and cardinal mechanisms so that no discipline’s metrics are left out. This was informed by observing multi-disciplinary teams: e.g., in a single project, a human factors specialist might rate usability (ordinal) while an engineer measures throughput (ratio). A.18 gives them a common language and prevents one from misusing the other’s data. It embodies the idea that _universal structure enables local freedom_: everyone’s metric can plug in, as long as they specify it properly.\n    \n-   **Comparability vs. freedom:** The pattern strikes a balance by tying comparability to explicit commonality. If two metrics truly measure the same thing in the same way, then of course you can compare them – they’ll share Characteristic and Scale. If they differ, the framework doesn’t stop you from defining them (freedom), but it does stop you from _conflating_ them inadvertently. The introduction of **polarity** declarations is a direct response to this tension: it adds a tiny burden (must declare “higher is better” etc.) but yields big pay-off in avoiding mis-ordered interpretations and enabling safe composite scoring (monotonic ScoringMethods).\n    \n-   **Ordinal vs. cardinal separation:** The rationale here is guided by measurement theory: we want to preserve information content. Treating ordinal data with only order operations preserves all its information; doing more (like adding them) injects false information. The pattern’s strictness on scale types forces modelers to be honest about what their data can and cannot do. This not only prevents errors but also encourages **best practices** (e.g. if you find you desperately want to average an ordinal score, perhaps you should refine it into an interval scale in your methodology). The outcome is a framework that respects both the **qualitative** and **quantitative** realms appropriately, aligning with **FPF’s Pillar of Pragmatism** – use formalism where it’s justified, but not beyond its limits.\n    \n-   **Optional Levels:** Requiring Levels in every case would have been too rigid (not everything has named tiers), but not supporting them would fail domains that rely on them (like maturity models or grading systems). The rationale for making Level _optional_ is to accommodate both. We saw in practice that many metrics naturally form tiers (e.g. technology readiness levels TRL 1–9) and giving them a slot in the model (instead of burying them in definitions) makes those metrics much easier to work with and integrate. Meanwhile, continuous metrics carry no baggage of unused fields. This design was checked against existing standards (like ISO 25024 for quality measures) to ensure we aren’t deviating from industry expectations: indeed, separating the concept (Characteristic) from the scheme (Scale) aligns well with standards, and including an optional categorization aligns with common practice in capability maturity models, etc.\n    \n-   **Method neutrality:** The decision to _not_ include any measuring procedures in A.18 (no specific formulas, no mandated evidence type) comes from the principle of separation of concerns. The kernel should provide the _what_ and _how (structurally)_, while architheories provide the _how (procedurally)_. This keeps the kernel lean (**P‑1 Cognitive Elegance**) and allows domain experts to implement whatever method is appropriate, merely committing to wrap their results in the CSLC form. By doing so, we avoid any bias toward empirical vs analytical, or manual vs automated measurements – FPF welcomes all, as long as they conform to the schema. This was rationalized by examining case studies: e.g., some reliability metrics come from formal proofs (analysis), others from testing (empirical) – the kernel can host both results identically, requiring only that each result says what it measured and on what scale.\n    \n\nIn essence, A.18 is the _infrastructure of meaning_ for metrics. It may appear as a simple template, but it’s profoundly enabling. It forces clarity at creation time, so we don’t have to infer or debate meaning at usage time. The pattern’s strength lies in preventing errors that _don’t have to happen_. It encodes lessons from both metrology (the science of measurement) and everyday data science (where unit errors and mis-comparisons are infamous issues). The rationale is backed by these lessons: **fix the interpretation rules in the design, and you eliminate entire classes of confusion and mistakes.** By having this in the kernel, every architheory – from knowledge scoring to system performance – benefits immediately, and their results become interoperable to a degree that would be impossible without a common structure.\n",
        "relations": "### A.18:10 - Relations\n\n-   **Extends/Uses:** **A.17 (CHR-NORM)** – A.18 explicitly builds on the canonical terminology established in A.17. It uses the term **Characteristic** as defined there (and no other synonyms) and carries forward the edict that “axis/dimension” be treated as mere narrative aliases. It also leverages the Entity-vs-Relation Characteristic distinction from A.17: Section 7.4 of this pattern references tests for disambiguating relational metrics. Essentially, A.17 provides the **lexical and conceptual groundwork** (what a Characteristic is, and the basic vocabulary), while A.18 provides the **structural and normative rules** for linking Characteristics to measurements.\n    \n-   **Core foundation for metrics:** This pattern underpins the **Measurement & Metrics Characterization spec (C.MM‑CHR)** – the architheory that implements metric storage and computation. In MM-CHR, every `U.DHCMethodRef` and `U.Measure` follows the CSLC format defined by A.18. By lifting CSLC rules to the kernel, we ensure all architheories (like **KD-CAL** for knowledge dynamics, **Sys-CAL** for systems, or any custom CAL/CHR) share a common approach to metrics. A.18 also informs the design of **CHR-CAL (Characterisation Calculus)**, which generalizes measurable property templates: CHR-CAL relies on the one-Characteristic-per-metric assumption and the comparability rules set here to compose higher-level characterizations.\n    \n-   **Enables dynamic reasoning:** A.18’s insistence on well-defined Scales allows patterns like **A.3.3 `U.Dynamics`** (system dynamics models) to incorporate measurement dimensions as state variables without ambiguity. For example, a `stateSpace` in a dynamics model can be explicitly defined as a set of Characteristics (each with units and ranges), making simulations and traces dimensionally consistent. If A.18 were not in place, one model might treat “performance” as a 1–5 score and another as a probability – combining them would be incoherent. With A.18, such differences must be reconciled via a ScoringMethod or kept separate, preserving coherence in multi-model analyses.\n    \n-   **Coordinates with assurance patterns:** Many patterns in Part B and D (for trust, assurance, and ethics) involve **scores** and **metrics**. For instance, **B.3** (Assurance Levels) computes overall assurance from evidence scores; A.18 ensures those input scores are well-defined and comparable (e.g. all are 0–1 or all are percentages, with polarity noted). **D.4** (Trust-Aware Calculus) might combine trust metrics across domains – again, A.18 provides the common ground so that a “trust score” coming from an operational metric and one coming from a social rating can be normalized and compared meaningfully. In summary, any pattern that aggregates or uses measurements is constrained (in a positive way) by A.18’s rules. They “plug into” this framework.\n    \n-   **Constrained by lexical rules:** This pattern’s content is part of the formal lexicon governance. It works within **E.10 LEX-BUNDLE**, which means the terms _Characteristic, Scale, Coordinate, Level,_ etc., are controlled vocabulary. A.18 localizes some generic requirements from A.17 (for example, A.17 mandates polarity in principle; A.18 requires it be declared per template in practice). It also aligns with external standards: by having explicit scale types and units, it dovetails with ISO/IEC measurement terminology and allows straightforward mapping to frameworks like **ISO 80000 (quantities and units)** and **Stevens’s scale types**. This relation to standards is deliberate – it eases **F.9 (Alignment Bridge)** construction to external ontologies by having a clean internal schema (A.18 provides that schema). In effect, A.18 is where FPF’s internal consistency meets external compatibility, ensuring our measurement semantics can relate to those outside FPF when needed.\n",
        "a.18:end": "### A.18:End\n"
      },
      "content": "### A.18:End\n",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.19",
      "title": "CharacteristicSpace & Dynamics Hook (A.CHR‑SPACE)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.19 - CharacteristicSpace & Dynamics Hook (A.CHR‑SPACE)\n\n**Non‑duplication note.** This pattern reuses the canonical measurement concepts (`U.Characteristic`, **CSLC** terms) from **A.17/A.18** and relies on **C.16 (MM‑CHR)** for **normalization evidence**. It **does not redefine** units or normalization semantics. **UNM** *names admissible re‑parameterizations within one `U.BoundedContext`* and thereby **induces a context‑local congruence** over charts, written **≡_UNM**, which is a **specialization of the framework’s congruence notion** used in **B.3** (and instantiated for epistemes in **B.1.3**). A **NormalizationFix** selects a canonical representative of an **≡_UNM** class. Timebases and laws remain out of scope (see **A.3.3**).\n**Locality & governance.** A **UNM** is *context‑local*: it is declared within a single `U.BoundedContext` for a given CharacteristicSpace (or family of charts) and **enumerates** (a) the **admissible classes of NormalizationMethod**, (b) the **invariants** they must preserve, (c) **closure** under composition (and inverses where defined), and (d) **validity/versioning rules** (editions, windows). Semantics and evidence backing remain under **C.16**; A.19 constrains how UNM artifacts are *named and used* in state/comparability logic. **UNM is a `U.Mechanism` instance** (A.6.1) and therefore any cross‑context or cross‑plane reuse **MUST** be declared in the mechanism’s **Transport** clause: **name the BridgeId and channel** (`Scope|Kind`), **record** `ReferencePlane(src,tgt)`, and **declare** any `CL^plane` regime. **No implicit crossings.** When the *describedEntity* changes, declare a **KindBridge (CL^k)** (two‑bridge rule); penalties **route to `R/R_eff` only** and never mutate **F/G**.\n\n**Terminology update (Normalization) — replaces legacy κ‑notation and generic “map” wording**\n**UNM — Unified Normalization Mechanism.** A mechanism that packages admissible re‑parameterizations for a CharacteristicSpace so that values can be normalized for safe comparison **within one `U.BoundedContext`**.\n**NormalizationMethod.** A concrete method within UNM (intensional definition of how to normalize a slot or a vector of slots). **Method classes SHALL be scale‑appropriate:** ratio → positive‑scalar conversion; interval → affine transform; ordinal → order‑preserving monotone map; nominal → categorical re‑map; lookup table (**LUT**) with uncertainty annotations (where declared). These classes are **named consistently** across the spec as: `ratio:scale`, `interval:affine`, `ordinal:monotone`, `nominal:categorical`, `tabular:LUT(+uncertainty)`.\n**NormalizationMethodDescription.** The **epistemic** description of a NormalizationMethod (documentation/spec with bounds, validity window, Evidence Graph Ref).\n**NCV — NormalizedCharacteristicValue.** The **result** of applying a NormalizationMethod to a **coordinate value** (or vector) in a CharacteristicSpace. *Note:* **Characteristics** themselves are **not** normalized; **values** (coordinates) are.\n**NormalizationMethodInstance.** A concrete, editioned **use** of a NormalizationMethod in a CN‑frame or embedding (binds method → `slot_id`(s) (basis keys), edition, validity window). Use this term when referring to stored/ID’d artifacts (e.g., in logs), to avoid overloading **map**.\n**UNM‑congruence (≡_UNM).** Context‑local equivalence relation over **charts** generated by the admissible **NormalizationMethods** declared in the UNM; two charts are **≡_UNM** iff they are related by a chain of admissible, **scale‑appropriate** transformations that preserve the declared invariants.\n**IndicatorChoicePolicy.** Principles/rules for selecting which Characteristics (or their NCVs) become Indicators for decisions.\n**Indicator.** The result of applying an IndicatorChoicePolicy to a set of Characteristics/NCVs; an Indicator is **not** a target value by itself and **not** any normalized value by default.\n**Indicatorization (policy step).** Selecting Indicators is a **separate**, policy‑governed step; producing NCVs alone **does not** yield Indicators.\n**Removal of κ‑notation.** The previous κ symbol and derived phrases (e.g., “κ‑operator”) **for normalization** are retired in favor of explicit names: *Normalization, NormalizationMethod, NCV, UNM*. This retirement does **not** affect unrelated uses of κ as a generic metavariable in logic or requirements schemas elsewhere in the spec.\n**Lexical note (map vs Map).** In this document, lowercase **map** denotes a mathematical function only. Capitalized **Map** (e.g., `DescriptorMap`) retains its Part‑G meaning as a **method type** that encodes subjects into a declared Space; it is **disjoint** from **NormalizationMethod/UNM**. Do **not** use “map/Map” as a synonym for **NormalizationMethod**, **NormalizationMethodInstance**, or **NCV**.\n",
        "intent_&_scope_(normative)": "### A.19:1 - Intent & Scope (Normative)\n\n**Intent.** Establish a **kernel‑level state‑space type**—`U.CharacteristicSpace`—so that any holon’s **state changes** (e.g., a system’s condition or a role’s readiness) can be formalized as **trajectories in a space of declared Characteristics with chosen Scales**. For **epistemes**, state is governed by **ESG**; **F–G–R** are **assurance coordinates**, not a state space. This gives every `U.Dynamics` model a well‑typed `stateSpace` and enables formal state certification (using RoleStateGraph checklists) instead of narrative stage transitions.\n\n**Scope.** Pattern A.19 **defines**:\n\n-   the **type** `U.CharacteristicSpace` as a finite product of **slot value sets** (per A.18),\n-   the **slot** construct for each factor (a pairing of a **Characteristic** with a chosen **Scale**),\n    \n-   minimal **structural overlays** (optional **order**, **topology**, **metric** hooks) that downstream architheories _may_ attach to a space, and\n    \n-   the **hook** `U.Dynamics.stateSpace : CharacteristicSpace` – i.e. the requirement that any dynamics model declare a CharacteristicSpace for its state space (typing only).\n    \n\nA.19 **does not** introduce any new measurement aspects, composite metrics, or **normalization semantics** (those are provided by **C.16 (MM‑CHR)** under **UNM**), and it does not define how dynamics evolve over time or any predictive laws (see **A.3.3** for dynamics semantics). The focus here is purely on the _structure of state spaces_ and their comparability.\n\n**Lexical guard (“map”).** In normative text, lowercase **map** refers only to a mathematical function; it MUST NOT be used as a synonym for **NormalizationMethod**, **NCV**, or **UNM**. Capitalized **Map** keeps its suffix‑family meaning (e.g., `DescriptorMap`) and is unrelated to normalization. Use **NormalizationMethod** for the transform and **NCV** for its output.\n\n**Lexical guard (“carrier”).** In kernel prose, **Carrier** (capitalized) names `U.Carrier` (a **symbol bearer**). Do **not** use “carrier” for set‑theoretic supports; prefer **ValueSet**/**underlying set**. A.19 therefore uses **ValueSet(slot)** for the set that supplies values to a slot.\n",
        "context_(informative)": "### A.19:2 - Context (Informative)\n\nFPF’s kernel already standardizes **what** is measured (a **Characteristic**, per A.17) and **how** it is measured (a **Scale** with units, via the **CSLC** Standard in A.18). We also have a measurement substrate (`U.DHCMethodRef`, `U.Measure`) to handle individual observations. What has been missing for modeling **dynamics** is a canonical “Context” in which **multiple Characteristics** can co-exist so that complex **states** (with many aspects) and their **trajectories** are well-typed and comparable. Without a formal CharacteristicSpace, teams either hard-code ad-hoc vectors (often with inconsistent assumptions) or fall back to informal lifecycle stories (“phases” or stages) that contradict the kernel’s open-ended, non-linear evolution paradigm. The Architectural patterns (A-cluster) expect that `U.Dynamics.stateSpace` will be a set of **declared Characteristics each with a declared Scale**. Pattern A.19 delivers exactly this capability, leveraging the CSLC measurement discipline without reinventing any arithmetic or unit-handling logic.\n",
        "problem": "### A.19.D1:2 - Problem\n\nAbsent a governance layer, four failure modes recur:\n\n1. **Chartless numbers.** Measures move between teams without units, reference states, or declared normalization → **illusory comparability**.\n2. **Hidden normalization flips.** Re‑parameterisations (e.g., normalising by batch size) silently alter meaning; trend lines lie.\n3. **CN‑frame sprawl.** Every initiative mints a new “dashboard dimension”; semantics diverge; assurance collapses.\n4. **Un‑bridgeable reports.** Cross‑team roll‑ups average **incongruent** CN‑frames, violating the **weakest‑link (WLNK)** discipline from Γ and B.3.\n",
        "forces": "### A.19.D1:3 - Forces\n\n| Force                         | Tension we must balance                                                              |\n| ----------------------------- | ------------------------------------------------------------------------------------ |\n| **Universality vs nuance**    | One Standard for robotics, safety, finance — yet leave each context’s idioms intact. |\n| **Speed vs audit**            | Light ceremony for on‑ramp; hard guarantees for assurance and SoD.                   |\n| **Local truth vs federation** | Keep CN‑frames meaning‑local; still enable **explicit** bridging across Contexts.          |\n| **Minimalism vs safety**      | Few mandatory slots; enough structure to forbid silent normalization drift.                  |  \n\n",
        "solution": "### A.19.D1:4 - Solution — **The CN‑Spec** (CN‑Spec) + **Registry** + **Bridges**\n\n#### A.19.D1:4.1 - The **CN‑Spec** (comparability & normalization specification per CN‑frame, in one `U.BoundedContext`)\n\nA **CN‑frame** is governed by a compact, notation‑free card:\n\n```\nCN‑Spec {\n  name              : CN‑frameName                  // local to Context\n  context           : U.BoundedContext              // edition/version included\n  cs_basis          : [{\n    slot_id         : <tech-token>,                 // stable slot id (basis name)\n    characteristic  : <U.Characteristic>,          // per A.17 / A.18\n    scale           : { type: nominal|ordinal|interval|ratio, unit?: <U.Unit>, bounds?: <… > },\n    polarity        : up|down|target-range,        // comparison orientation\n    // if needed: missingness?, admissible_domain? (MM‑CHR‑consistent metadata)\n  }]\n  chart             : { reference_state, coordinate_patch, measurement_protocol_ref }\n  normalization     : {\n    UNM_id?,                                 // A.6.1 `U.Mechanism` (UNM) id, scoped to this Context/Edition\n    methods: [NormalizationMethodId],         // admissible (intensional) methods in that UNM\n    instances?: [NormalizationMethodInstanceId], // editioned uses referenced in logs/gates\n    method_descriptions: [NormalizationMethodDescriptionRef],\n    admissible_reparameterizations,\n    invariants,\n    fix?: <NormalizationFixSpec>\n  }\n  comparability     : { mode ∈ {coordinatewise, normalization-based}, minimal_evidence }\n  indicator_policy? : { IndicatorChoicePolicyRef, scope, edition }\n  acceptance        : { checklist_for_admission, window, evidence_anchors } // gates RSG state checks\n  aggregation       : { Γ_fold, WLNK/COMM/LOC/MONO choices, time_policy }   // safe roll-up recipe\n  alignment?        : { bridges_to_other_contexts, CL_levels, loss_notes }  // optional\n  lifecycle         : { owner_role, DRR_links, deprecation_plan }\n}\n```\n\n**Reading:** *A CN‑frame is a context‑local lens with declared characteristics, units, a chart to read them, a **UNM/Normalization** that states what “doesn’t matter,” explicit rules for when a datum counts and how many can be safely folded, and (optionally) an **IndicatorChoicePolicy** to select Indicators. Not every Characteristic (even with an NCV) is an Indicator; Indicators arise from policy.*\n\n`NormalizationKinds`, `MetricSpec` and `QuotientSpec` are **CN‑frame‑level** governance metadata; per **A19‑CS‑5** the kernel `CharacteristicSpace` carries **no NormalizationMethods** or composition; normalization lives in **MM‑CHR**. In A.6.1 terms, `UNM_id` points to a **`U.Mechanism`**; the CN‑Spec **references** that mechanism and does **not** introduce implicit **Transport**.\n\n**L‑CN‑Spec‑NORM‑IDs**: where stored artifacts are referenced (e.g., in assurance logs), use **NormalizationMethodId**/**NormalizationMethodInstanceId**; avoid generic “map” nouns. If you introduce reference-typed fields, obey **A.6.5** (`*Ref` reserved for reference fields; `*Slot` reserved for SlotKinds).\n\n#### A.19.D1:4.2 - **CN‑frame Registry** (per Context)\n\nEach `U.BoundedContext` keeps a **CN‑frame Registry** (VR):\n\n* **canonical names** and **editions**;\n* **SoD hooks** (who can edit CN‑Spec, who can certify admission);\n* **deprecation map** (what replaces what, when).\n\n#### A.19.D1:4.3 - **Bridges** (across contexts)\n\nCross‑context reuse occurs **only** via explicit **Alignment Bridges** (F.9) between CN‑Specs:\n\n```\nBridge CN‑frameA@Context1  →  CN‑frameB@Context2\n  channel: {Scope|Kind}                 // F.9 (and A.6.1 Transport)\n  planes: ReferencePlane(src,tgt)       // C.2.1 (must be recorded)\n  CL: {3|2|1|0}\n  CL_plane?: {3|2|1|0}                  // only when planes differ\n  kept_characteristics: [… ]\n  lost_characteristics: [… ]\n  transform: {pullback | pushforward | re-scaling | re-binning}\n  extra_guards: {additional evidence / reviewer role / waiver speech-act}\n```\n\n**CL policy (reference).** **CL levels and the penalty Φ(CL) are defined in B.3** (CL is **ordinal**; do not average). In A.6.1 terms, any cross‑context (or cross‑plane) reuse is declared **only** via a mechanism’s **Transport** clause: **name the BridgeId and channel** (`Scope|Kind`) and **record** `ReferencePlane(src,tgt)`; if planes differ, declare the `CL^plane` regime. **Transport is declarative** (it does not introduce a `U.Transfer` edge and does not restate CL ladders or Φ tables). When both scope and *describedEntity* change, apply the **two‑bridge rule** (Scope bridge + **KindBridge (CL^k)**). Penalties from scope/kind/plane **route to `R/R_eff` only** (never to **F/G**). This CN‑Spec may **add operational guards** per level (e.g., “extra reviewer at CL=1”, “waiver at CL=2”), but it **does not redefine** the scale or Φ. For episteme‑specific frames, see also **B.1.3**.\n",
        "conformance_checklist": "### A.19.D1:5 - Conformance Checklist (normative)\n\n> **Pass these and your CN‑frames are fit for assurance and cross‑team composition.**\n\n**CC‑A19.D1‑1 (Local scope).** Every CN‑frame **MUST** live inside a declared `U.BoundedContext` (with edition). Names are **local**; same label in another Context ≠ same CN‑frame.\n\n**CC‑A19.D1‑2 (Units & polarity).** Each characteristic in `cs_basis` **MUST** declare **unit/scale** and **polarity** (↑ better / ↓ better / target range). No unlabeled magnitudes.\n\n**CC‑A19.D1‑3 (Chart).** `chart` **MUST** name the **reference state**, **coordinate patch** and **measurement protocol** (`U.MethodDescription`) to make numbers reproducible.\n\n**CC‑A19.D1‑4 (Normalization).** `normalization` **MUST** list the **admissible transforms** (e.g., affine rescale, monotone map) **and** the **invariants** they preserve (what comparability means).\n\n**CC‑A19.D1‑5 (Comparability mode).** `comparability.mode` **MUST** be either **coordinatewise** (same chart & units) or **normalization‑based** (after normalization by the declared **UNM** into the **same ≡_UNM class**). Mixed/implicit modes are prohibited.\n\n**CC‑A19.D1‑6 (Admission checklist).** `acceptance.checklist_for_admission` **MUST** be observable and time‑bounded; each datum admitted to the CN‑frame **SHALL** cite a **StateAssertion** or equivalent `U.Evaluation`.\n\n**CC‑A19.D1‑7 (Aggregation discipline).** `aggregation.Γ_fold` **MUST** specify WLNK/COMM/LOC/MONO choices and the **time policy** (e.g., average of rates vs integral of counts). **No free‑hand averages.**\n\n**CC‑A19.D1‑8 (Bridge‑only reuse).** Cross‑context consumption **MUST** cite a **Bridge** with: (i) `channel ∈ {Scope|Kind}`, (ii) recorded `ReferencePlane(src,tgt)`, (iii) CL (and `CL^plane` when planes differ), and (iv) **loss notes**; coordinate‑by‑name without a Bridge **fails**. If the data participate in **gating/assurance**, apply **Φ(CL) per B.3**; this CN‑Spec does not restate Φ.\n\n**CC‑A19.D1‑9 (SoD & roles).** Editing CN‑Spec and admitting data **MUST** be performed by **different** roles (⊥ enforced): `CN‑frameStewardRole ⊥ CN‑frameCertifierRole` inside the same context.\n\n**CC‑A19.D1‑10 (Lifecycle & DRR).** Every CN‑Spec **MUST** carry an **owner role**, a **deprecation plan**, and links to **DRR** entries for rationale and changes (Part E.9).\n\n**CC‑A19.D1‑11 (Anchors & lanes for comparability).** Any **admission** into a CN‑frame that is later **used for comparison/aggregation** **SHALL** cite the corresponding **A.10 EvidenceRole** anchors for each characteristic, with **assuranceUse lane** tags {TA, VA, LA} and **validity windows** (where applicable), so that the **SCR** can report lane‑separated contributions and freshness (B.3). Absence of anchors for a required characteristic renders items **incomparable**.\n\n**CC‑A19.D1‑12 (Notation independence).** CN‑Spec content **MUST NOT** depend on a tool or file format; semantics precede notation (E.5.2 Notational Independence).\n\n**CC‑A19.D1‑13 (Lexical guard‑rails).** characteristic names and role labels **MUST** follow the Part E lexical discipline (registers, twin labels; no overloaded “process/service/function”).\n",
        "anti‑patterns_→_safe_rewrites": "### A.19:7 - Anti‑patterns → safe rewrites\n\n_The following are common modeling mistakes (“anti-patterns”) related to measurement spaces, and how to correct them:_\n\n-   **“Same label ⇒ comparable.”**  \n    ✗ _Assuming_ **Ready@contextA ≥ Ready@contextB** _just because both states are called \"Ready\"._  \n\t✓ **Explicitly normalize and bridge contexts:** Define an Alignment **Bridge (B→A)** and appropriate **NormalizationMethods** for the underlying metrics. Then compare by first translating one state’s coordinates (compute **N(x)** as NCVs in the target space) and using `≼_coord` on the result.\n    \n-   **“Compare before landing.”**  \n    ✗ Comparing values directly across different scales, e.g. _Drift\\_A = 5°C vs Drift\\_B = 5°F_ as if they were the same.  \n\t✓ **Normalize to common units first:** e.g., apply the Fahrenheit‑to‑Celsius **NormalizationMethod** _m_(T_F) = (T_F − 32) × 5/9 to convert all data to °C, **then** compare the drift values. Always **normalize into one space** before comparing magnitudes.\n    \n-   **“Checklist = workflow.”**  \n    ✗ Defining a state’s checklist with an implied sequence: _“State ‘Ready’ requires doing Step 1 then Step 2…”_  \n    ✓ **Keep checklists declarative:** A **Checklist** should represent a state of the system (a condition) – essentially **state evidence** – not a sequence of actions. If order or process matters, model that explicitly via a **MethodDescription** or by using a **Γ** (Gamma) aggregator for process logic. In other words, state = “Ready” might require conditions A and B to be true (regardless of how you got there), whereas the procedure to get ready (do Step1 then Step2) should be a separate method or playbook.\n    \n-   **“Retro-fix past assertions.”**  \n    ✗ Going back to edit or reinterpret old StateAssertions after changing a threshold or NormalizationMethod (e.g. “We updated the criteria, let’s ‘fix’ last quarter’s records to match”).  \n    ✓ **Never alter historical assertions:** **Leave history as‑is.** If criteria change, issue new assertions under the new criteria going forward, and if needed, explicitly **version** the **NormalizationMethod/UNM** or checklist. Past assertions remain valid for the old version and their time; new ones apply henceforth. This ensures auditability and avoids erasing or rewriting what was true under earlier standards.\n",
        "a.19:end": "### A.19:End\n\n## A.19.D1 - CN‑frame (comparability & normalization)\n\n> **Scope.** This CN‑frame Algebra & Normalization Discipline **extends A.19** by fixing the **governance Standard** for CN‑frames, defining a **conformance checklist** and **regression harness**, and providing **didactic one‑pagers** and **anti‑patterns** so teams can introduce CN‑frames without tool lock‑in. The mandatory pattern structure and authoring discipline from **Part E** (Style Guide, Tell‑Show‑Show, checklists, DRR, guard‑rails) are applied throughout.\n",
        "a.19.d1:1___context": "### A.19.D1:1 - Context\n\nA.19 established a substrate‑neutral picture:\n\n* a **CN‑frame** = *(Context‑local)* **CharacteristicSpace (CS)** + **chart** (coordinate patch + units) + **UNM/Normalization** (admissible re‑parameterizations that preserve meaning and generate **≡_UNM** over charts);\n* **operators** (subspace, product, pullback/pushforward) and **comparability** (coordinatewise vs **normalization‑based (normalize‑then‑compare)**);\n* **RSG touch‑points**: role readiness (**RSG** states) are **certified** against CS via **checklists** over observable characteristics;\n* **entity/relational mixtures** across CN‑frames via minimal schemas and bridges.\n\n**Terminology guard.** *CN‑frame* is the **lens** (I); *CN‑Spec* is the **governance card** (S) that fixes admissible charts/**normalizations**/comparability/Γ‑fold for that lens **in one `U.BoundedContext`**; *CN‑Description* is the didactic surface (D) with worked examples and anti‑patterns.\n\n**Lexical guard (map/Map).** Lowercase **map** is a mathematical function; capitalized **Map** (e.g., `DescriptorMap`) is a Part‑G method type (encoder) and is **not** a NormalizationMethod or NormalizationMethodInstance.\n\nA.19.D1 makes this *operational and auditable*.\n",
        "consequences": "### A.19.D1:6 - Consequences (informative)\n\n| Benefit                           | Why it matters                                                                                                        |\n| --------------------------------- | --------------------------------------------------------------------------------------------------------------------- |\n| **Auditable comparability**       | Chart + declared normalization (UNM + NormalizationMethods) make “same number” meaningful; silent re‑basings become explicit, reviewable choices.                   |\n| **Safe roll‑ups**                 | Γ‑folds with WLNK/COMM/LOC/MONO stop optimistic averaging and preserve invariants.                                    |\n| **Pluralism without incoherence** | Bridges with CL and loss notes allow federation without pretending to global sameness.                                |\n| **RSG‑ready**                     | Admission checklists let **RSG** states reference **CN‑frame‑backed** facts (e.g., *Ready* requires characteristics within bounds). |\n",
        "rationale": "### A.19.D1:7 - Rationale (informative)\n\nThe CN‑Spec aligns A.19.D1 with **Part E**: it packages Tell‑Show‑Show, Conformance Checklists, and DRR‑backed change, while honouring **DevOps Lexical Firewall**, **Unidirectional Dependency**, and **Notational Independence** so that semantics never depend on tooling.  It also operationalises B.3 **Trust & Assurance** by making CL penalties and WLNK folds first‑class.\n\n",
        "archetypal_grounding": "### A.19.D1:8 - Archetypal Grounding *(Tell‑Show‑Show)*\n\n> **Same slots, three arenas; no tooling implied.**\n\n#### A.19.D1:8.1 - **Industrial line** — *Weld‑quality CN‑frame* (`AssemblyLine_2026`)\n\n* `cs_basis`: *BeadWidth\\[mm] (target 6.0±0.2)*, *Porosity\\[ppm] (↓)*, *SeamRate\\[1/min] (↑ until limit)*\n* `chart`: reference jig, fixture ID, torch type; `MethodDescription#Weld_MIG_v3`\n* `normalization`: affine rescale on gray‑level calibration → invariant = physical porosity\n* `comparability`: **normalization‑based (UNM)** (calibration tables applied)\n* `aggregation`: WLNK on quality (min‑bound), COMM on counts, time = per‑shift histograms\n* **RSG hook**: `WelderRole.Ready` requires *Porosity ≤ 500 ppm* & *BeadWidth within ±0.2 mm* admitted by this CN‑frame.\n\n#### A.19.D1:8.2 - **Software/SRE line** — *Latency CN‑frame* (`SRE_Prod_Cluster_EU_2026`)\n\n* `cs_basis`: *P50Latency\\[ms] (↓)*, *P99Latency\\[ms] (↓)*, *Load\\[req/s]*\n* `chart`: client vantage, trace sampler v4; `MethodDescription#HTTP_probe_v4`\n* `normalization`: monotone time‑warp compensation for collector skew; invariant = percentile order\n* `comparability`: **normalization‑based (UNM)** with declared normalization\n* `aggregation`: MONO on latency (max of mins), WLNK across services\n* **RSG hook**: `DeployerRole.Active` gated if **P99** < declared SLO over the admission window.\n\n#### A.19.D1:8.3 - **Clinical/episteme line** — *Trial‑outcome CN‑frame* (`Cardio_2026`)\n\n* cs_basis:\n  - slot_id: ΔBP\n    characteristic: BloodPressureChange\n    scale: { type: ratio, unit: mmHg }\n    polarity: down\n  - slot_id: AdverseRate\n    characteristic: AdverseEventRate\n    scale: { type: ratio, unit: \"%\" }\n    polarity: down\n  - slot_id: Age\n    characteristic: Age\n    scale: { type: ratio, unit: years }\n    polarity: neutral\n* `chart`: cohort definition; `MethodDescription#TrialProtocol_v5`\n* `normalization`: case‑mix adjustment (propensity score); invariant = adjusted ΔBP\n* `comparability`: **normalization‑based (UNM)** (post‑adjustment)\n* `aggregation`: LOC on subcohorts; WLNK on safety outcomes\n* **RSG hook**: `EvidenceRole.Validated` admission requires CN‑frame acceptance; **Assurance** pulls CL from any Bridge used.\n\n#### A.19.D1:8.4 - Worked mini-schemas (entity/relational mixtures across CN‑frames, informative)\n\nTo illustrate how CharacteristicSpace is used in practice, below are simplified schema snippets for three typical **CN‑frames**: an **Operations** view (run-time state and action gating), an **Assurance** view (evidence and cross-context comparison), and an **Alignment** view (design-time consistency across contexts). These examples mix entity-based and relational Characteristics and demonstrate how state spaces, NormalizationMethodInstances, and bridges appear in a model. (The notation is mix of a graph/entity diagram and a relational table outline for clarity. **PK** = primary key, **FK** = foreign key.)\n\n##### A.19.D1:8.4.1 - Operations CN‑frame — Run-time gating & enactment\n\n_Entity graph view:_\n\nHolder (System) ── playsRoleOf ──> Role@Context ── has ──> RCS (slots…)\nRSG (Role@Context) ── owns ──> State (◉ status)\nChecklist (of State) ── testedBy ──> Evaluation ── yields ──> StateAssertion\nWork ── performedBy ──> RoleAssignment\nWork ── isExecutionOf ──> MethodDescription\n\nIn the above, a **Holder** (a system instance) plays a **Role** in some Context, which has an attached **RCS** (a set of slots defining its characteristic space). That Role’s **RSG** owns various possible **State** entries (each state could be, e.g., Ready, Waiting, Degraded, etc.). Each State has a **Checklist** which is **tested by** an Evaluation process, resulting in a **StateAssertion** (pass/fail) at runtime. Meanwhile, **Work** instances (concrete operations) are performed by the RoleAssignment and correspond to some MethodDescription (procedure). The “gate” for Work is that a StateAssertion for an enactable state must exist.\n\n_Relational stub:_ (illustrating how data might be stored)\n\n| Table | Key Columns (essential) |\n| --- | --- |\n| **ROLE\\_ASSIGNMENT** | `RA_ID` (PK); `HOLDER_ID`; `ROLE_ID`; `CONTEXT_ID`; `WINDOW_FROM`, `WINDOW_TO` |\n| **RCS\\_SNAPSHOT** | `SNAP_ID` (PK); `RA_ID` (FK to ROLE\\_ASSIGNMENT); `WINDOW_FROM`, `WINDOW_TO`; `CHAR_ID`; `VALUE`; `UNIT`; `SCALE_TYPE` |\n| **RSG\\_STATE** | `STATE_ID` (PK); `ROLE_ID`; `CONTEXT_ID`; `NAME`; `ENACTABLE` (bool) |\n| **CHECKLIST** | `CHK_ID` (PK); `STATE_ID` (FK to RSG\\_STATE); `PREDICATE_TYPE`; `PREDICATE_SPEC` |\n| **STATE\\_ASSERTION** | `SA_ID` (PK); `RA_ID` (FK); `STATE_ID` (FK); `CHK_ID` (FK); `WINDOW_FROM`, `WINDOW_TO`; `VERDICT` (pass/fail); `NORMALIZATION_INSTANCE_ID`?; `BRIDGE_ID`? |  \n| **WORK** | `WORK_ID` (PK); `RA_ID` (FK); `METHODDESC_ID` (FK to MethodDescription); `WINDOW_FROM`, `WINDOW_TO`; _(other fields like results or references)_ |\n\nIn this schema: an RCS snapshot table might log individual coordinate values (`VALUE`) for each Characteristic (`CHAR_ID`) in a given RoleAssignment, with their units and scale type noted (to ensure we know what the number means). The StateAssertion ties a RoleAssignment to a state checklist and says whether it passed, including references to any **NormalizationMethodInstance** or **Bridge** if cross-context or cross-scale comparisons were involved. The gate logic for enactment can then be a query like: “Is Work W admissible now?” – which joins through ROLE\\_ASSIGNMENT to find the latest StateAssertion for that RA where `ENACTABLE=true` and `VERDICT=pass`.\n\n##### A.19.D1:8.4.2 - Assurance CN‑frame — Evidence freshness & mapped comparisons\n\n_Entity graph view:_\n\nNormalizationMethodInstance ── appliesTo ──> Characteristic   (each instance is a scale‑appropriate, monotone transform within UNM)\nBridge (ContextB → ContextA)   (Alignment Bridge between contexts, with CL and loss notes)\nStateAssertion ── uses ──> {NormalizationMethodInstance, Bridge}   (if a state comparison crossed contexts)\n\nThis view highlights that in the assurance context, we keep track of how we mapped or compared states:\n\n* A **NormalizationMethodInstance** represents a monotone, scale‑appropriate mapping from one Characteristic’s scale to another’s under **UNM** (editioned, with validity window).\n* A **Bridge** between Context B and Context A (for corresponding roles or states) carries a CL rating and possibly notes on what is “lost in translation.”\n* A **StateAssertion** may **use** a NormalizationMethodInstance or a Bridge, meaning that assertion was reached by translating data via that instance or comparing across that bridge.\n\n_Relational stub:_\n\n| Table                | Key Columns (essential)                                                                                                               |\n| -------------------- | ------------------------------------------------------------------------------------------------------------------------------------- |\n| **NORMALIZATION\\_METHOD** | `NORMALIZATION_METHOD_ID` (PK); `CLASS` (ratio:scale | interval:affine | ordinal:monotone | nominal:categorical | tabular:LUT); `DESCRIPTION_REF` |\n| **NORMALIZATION\\_INSTANCE** | `NORMALIZATION_INSTANCE_ID` (PK); `NORMALIZATION_METHOD_ID` (FK); `SRC_CHAR_ID`; `TGT_CHAR_ID`; `FORMULA_SPEC|LUT_REF`; `MONOTONE` (bool); `VALIDITY_WINDOW`; `EVIDENCE_REF` |\n| **BRIDGE**           | `BRIDGE_ID` (PK); `FROM_ROLE@CTX`; `TO_ROLE@CTX`; `CL` (congruence-loss level, e.g. 0–3); `NOTES` (description of losses/adjustments) |\n| **ASSURANCE\\_EVENT** | `AE_ID` (PK); `SA_ID` (FK to StateAssertion); `EFFECT` (enum: penalty\\_applied, evidence\\_refreshed, etc.); `DETAILS`                 |\n\nIn this stub, **NORMALIZATION\\_INSTANCE** defines each cross-scale mapping that has to be accounted for (with `FORMULA_SPEC` describing how to compute the target value from the source). The Bridge table enumerates official Bridges between contexts (for example, bridging a “Ready” state in an engineering context to “Ready” in an operations context, with CL indicating how fully comparable they are). An ASSURANCE\\_EVENT log could record when a penalty was applied due to a low-CL Bridge or when an assertion was refreshed or invalidated due to new evidence or time lapse. (For instance, policy might say if a critical state assertion uses a Bridge with CL < 2 in a safety context, a special waiver or secondary approval is needed – that could be represented as an event requiring a **Waiver** action.)\n\n##### A.19.D1:8.4.3 Alignment CN‑frame — Design-time reuse of states across Contexts\n\n_Entity graph view:_\n\nChecklist(ContextA.State)   ← pull(N) —   Checklist’(ContextB.State’)   (pull a checklist via **NormalizationMethodInstance** N)\nRefinement π : RSG(Role' ≤ Role)   (RSG refinement mapping, e.g. Role' is a subtype of Role)\n\nThis view covers how _design-time_ alignment happens:\n\n-   A **Checklist’** for a state in Context B can be **pulled** via a **NormalizationMethodInstance** into Context A to become a derived Checklist for a state in Context A. This is effectively what we described in the pull operation: using another context’s criteria in your own space.\n    \n-   A **Refinement π** is shown between RSGs indicating Role’ is a specialized role of Role (e.g. a sub-role or a scenario-specific role) and how their states relate (Role’ might have extra states or more granular distinctions). This refinement should maintain that for each state in Role’ that maps to a state in Role, the entails/implication relation holds for enactability.\n    \n\n_Relational stub:_\n\n| Table               | Key Columns                                                                                                                                                                                       |\n| ------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **RSG\\_REFINEMENT** | `MAP_ID` (PK); `ROLEPRIME_ID` (FK to Role' in Context B); `ROLE_ID` (FK to Role in Context A); `STATEPRIME_ID` (FK to state in Role' RSG); `STATE_ID` (FK to state in Role RSG); `ENTAILS` (bool) |\n| **CHECKLIST\\_PULL** | `PULL_ID` (PK); `SRC_STATE_ID`; `TGT_STATE_ID`; `NORMALIZATION_INSTANCE_ID` (FK to NormalizationMethodInstance used); `VERSION`? /\\* and perhaps timestamp \\*/                                     |\n\nIn this stub, RSG\\_REFINEMENT maps states of a sub-role to states of a super-role, with an `ENTAILS` flag indicating if being in the sub-state guarantees being in the super-state. **Every refinement mapping should ensure at least one enactable state in the sub-role corresponds to an enactable state in the super-role** (or else the sub-role would allow something the super-role doesn’t – that’s an alignment lint check). The CHECKLIST\\_PULL table records that a state from one context has had its checklist pulled into another context via a **NormalizationMethodInstance** (identified by `NORMALIZATION_INSTANCE_ID`). This is a design artifact saying “State X in context A is defined by applying normalization instance N to State Y in context B’s criteria.” A version or validity field might ensure we know which edition of the checklist or normalization instance was used.\n\n",
        "a.19.d1:9___anti‑patterns_(and_the_fix)": "### A.19.D1:9 - Anti‑patterns (and the fix)\n\n| Anti‑pattern            | Symptom                                   | Why it hurts                 | Fix (CN‑Spec slot)                           |\n| ----------------------- | ----------------------------------------- | ---------------------------- | --------------------------------------- |\n| **Chartless number**    | “Latency = 120”                           | No unit/vantage → untestable | Fill `cs_basis` + `chart`                          |\n| **Normalization smuggling**     | Quiet “per‑unit” normalisation mid‑stream | Trend reversal               | Declare `NormalizationMethod`/**NormalizationMethodInstance** + keep invariant        |\n| **Bridge‑by‑name**      | Reusing labels across Contexts               | False comparability          | Author **Bridge** with CL + loss        |\n| **Free‑hand averaging** | Arithmetic mean on bounded risks          | Violates WLNK                | Declare `Γ_fold` with WLNK              |\n| **CN‑frame sprawl**        | Ten nearly‑identical CN‑frames               | Cognitive debt               | Use Registry + DRR; prefer reuse        |\n| **Role conflation**     | Same person edits CN‑Spec & certifies data     | SoD breach                   | Enforce `CN‑frameSteward ⊥ CN‑frameCertifier` |\n",
        "a.19.d1:10___didactic_quick_cards_(one‑liners_teams_reuse)": "### A.19.D1:10 - Didactic quick cards (one‑liners teams reuse)\n\n1. **Numbers travel with their Context.** Always cite `Context@Edition`.\n2. **If the normalization is not declared, the trend is fiction.**\n3. **WLNK beats wishful means.** Use weakest‑link folds for safety.\n4. **Admit → Assert → Act.** (CN‑frame admission → RSG StateAssertion → Method step).\n5. **Bridge or bust.** Cross‑context = Bridge with CL and loss notes.\n6. **Steward writes, Certifier admits.** (SoD by design.)\n7. **Charts are recipes.** Name the `MethodDescription` that made the number.\n8. **Deprecate in the open.** CN‑frame cards carry DRR & retirement plans.\n9. **Keep characteristics few, meanings sharp.** Prefer ≤ 7 characteristics per CN‑frame.\n10. **No tooling names in Core.** Semantics first; notation later.\n11. **Use method/instance IDs; avoid generic “map” nouns.** Prefer `NormalizationMethodId`/`NormalizationMethodInstanceId`.\n",
        "a.19.d1:11___scr_/_rscr_harness_(acceptance_&_regression)": "### A.19.D1:11 - SCR / RSCR Harness (acceptance & regression)\n\n> **These are concept‑level checks; notation‑agnostic.**\n\n#### A.19.D1:11.1 - **SCR — Acceptance (first introduction)**\n\n* **SCR‑A19.4‑S01 (Completeness).** **CN‑Spec has **all** mandatory slots; `cs_basis` include **unit/scale/polarity**; `chart` references a `MethodDescription`.\n* **SCR‑A19.4‑S02 (Normalization clarity).** `normalization` lists UNM/NormalizationMethod(s) with validity windows, method descriptions, **and** named invariants.\n* **SCR‑A19.4‑S03 (Comparability test).** Provide one worked example showing **coordinatewise** or **normalization‑based** comparison end‑to‑end (with Evidence Graph Ref).\n* **SCR‑A19.4‑S04 (Γ‑fold audit).** Aggregation rule spells out WLNK/COMM/LOC/MONO choices; reviewer reconstructs result on a toy set.\n* **SCR‑A19.4‑S05 (SoD).** Distinct `RoleAssignments` for `CN‑frameStewardRole` and `CN‑frameCertifierRole` exist; windows do not overlap.\n* **SCR‑A19.4‑S06 (describedEntity & anchors surfaced).** For each CN‑Spec characteristic used in the worked example, cite the corresponding CHR Characteristic name and the evidence anchor(s) (A.10) that make the reading observable in this Context.\n\n#### A.19.D1:11.2 - **RSCR — Regression (on change)**\n\n* **RSCR‑A19.4‑R01 (UNM edit).** On changing `normalization` (UNM/NormalizationMethod), flag **all** downstream Bridges for CL re‑assessment; re‑run example comparisons.\n* **RSCR‑A19.4‑R02 (Slot surgery/Basis surgery).** Adding/removing/renaming slot/basis requires a **new edition**; old data remain valid **for their edition**.\n* **RSCR‑A19.4‑R03 (Chart drift).** Updating measurement protocol bumps edition; **historic Work** keeps old edition link.\n* **RSCR‑A19.4‑R04 (Fold change).** Any change to `Γ_fold` invalidates cached roll‑ups; re‑compute or mark as superseded.\n* **RSCR‑A19.4‑R05 (Bridge health).** After either side’s edition change, **re‑validate** Bridge CL and loss notes before accepting Cross‑context data.\n* **RSCR‑A19.4‑R06 (Deprecation rule).** On deprecating a CN‑frame, Registry lists its successor; bridges re‑targeted or retired.\n",
        "a.19.d1:12___interaction_summary_(wiring_to_the_rest_of_the_kernel)": "### A.19.D1:12 - Interaction summary (wiring to the rest of the kernel)\n\n* **A.2 / A.2.5 (Roles / RSG).** RSG **checklists** quote **CN‑Spec.acceptance**; enactment gates rely on **admitted** CN‑frame data.\n* **B.1 (Γ‑algebra).** CN‑Spec’s `Γ_fold` instantiates Γ\\_ctx/Γ\\_time/WLNK/MONO choices explicitly.\n* **B.3 (Assurance).** Bridge CL enters the **R** term; WLNK protects safety roll‑ups.\n* **C.6 / C.7 (LOG‑CAL / CHR‑CAL).** Units, scales, and measurement templates come from CHR; proofs about folds live in LOG‑CAL.\n",
        "a.19.d1:13___minimal_cn‑spec_template_(copy/paste,_informational)": "### A.19.D1:13 - Minimal CN‑Spec template (copy/paste, informational)\n\n```\nCN‑frame: <Name>      Context: <Context/Edition>\ncharacteristics:\n  - <CharacteristicName> : <Unit/Scale>  [Polarity: up|down|target-range]\nChart:\n  reference_state: <text>\n  coordinate_patch: <domain/subset>\n  measurement_protocol_ref: <MethodDescriptionId>\nNormalization:\n  UNM: <UNMId?>\n  methods: [<NormalizationMethodId>… ]\n  method_descriptions: [<NormalizationMethodDescriptionRef>… ]\n  invariants: [<property>… ]           # what ≡_UNM preserves\n  fix?: <NormalizationFixSpec>          # canonical representative of the ≡_UNM class\nIndicators (optional):\n  policy_ref: <IndicatorChoicePolicyRef>\n  resulting_indicators: [<IndicatorId>… ] // selection is policy‑defined; NCVs alone do not make an Indicator\nComparability:\n  mode: coordinatewise | normalization-based\n  minimal_evidence: <what must be observed to compare>\nAggregation:\n  fold: <Γ_fold expr>   time_policy: <window, statistic>\n  WLNK/COMM/LOC/MONO: <declared choices>\nAcceptance:\n  checklist: [<observable criterion>… ]\n  window: <ISO 8601 interval>\n  evidence_anchors: [<Observation/Evaluation ids>… ]\nAlignment (optional):\n  bridges: [<BridgeId, CL, kept/lost characteristics, extra guards>… ]\nLifecycle:\n  owner_role: <Role>\n  DRR_links: [<DRR ids>… ]\n  deprecation_plan: <short note>\n```\n\n** Certification data Standard (minimal).** (For implementation completeness, not a user-facing concern.) At minimum, any state certification function should take as input: a specific holon (holder) in a given Role and Context and a time window, and it should have access to a **snapshot** of all relevant RCS coordinates for that Role (plus any other needed observations or speech‑act logs in that window). It should output a **StateAssertion** object that includes: the target state’s identifier, the checklist (or checklist ID) used, the verdict (pass/fail); `evidence_kind ∈ {observation, prediction}`; the **window** `[t_from, t_to]`; for `prediction` also the **horizon Δt** and the **normalization** snapshot used; and references to the supporting observations. If any **NormalizationMethods** or cross‑context Bridges were used, those **MUST** be referenced (IDs) so that any **CL** penalty (B.3) can be applied deterministically. This is to ensure traceability and to apply any assurance penalties. Invariants for this process include: no “secret” criteria (all checklist conditions must be based on observable data, not insider knowledge), versioning of checklists (if a checklist changes version, new assertions are tagged to the new version; old assertions aren’t retroactively modified), and immutability of past assertions (once recorded, a StateAssertion isn’t edited after the fact – if it was wrong or conditions changed, a new assertion is issued instead of altering history).\n",
        "a.19.d1:close": "### A.19.D1:Close\n\nA.19.D1 gives A.19 some **teeth**: a *CN‑Spec* you can put on one page, a **Registry** that stops sprawl, **Bridges** that carry explicit loss, and a **checklist + harness** that make comparability **auditable**. It obeys the **mandatory pattern structure** of Part E (style, checklists, DRR, guard‑rails) while remaining tool‑agnostic and context‑local.\n",
        "a.19.d1:end": "### A.19.D1:End\n"
      },
      "content": "### A.19.D1:End\n",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "A.20",
      "title": "U.Flow.ConstraintValidity — Eulerian",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## A.20 - U.Flow.ConstraintValidity — Eulerian\n\n**Tech‑name.** `U.Flow.ConstraintValidity` (`U.Flow` genus)\n**Plain‑name.** Flow constraint validity (Eulerian interpretation)\n**Type / Status.** Architectural pattern — **normative** for flows hosted by E.TGA (E.18) under the Eulerian operational interpretation\n",
        "intention": "### A.20:0 - Intention\n\n**One‑liner** Defines cross‑cutting **ConstraintValidity** rules for all `U.Flow` instances. `U.TransductionFlow` inherits these rules and may refine **CV class specializations** for transduction‑specific semantics (species‑binding only; genus rules remain unchanged). The CV core is **kind‑agnostic** and assumes an **open‑world** catalogue of node **species**; the enumeration of node **kinds** in E.TGA is a **minimal roles baseline**.\n**Operational interpretation.** **Eulerian** stance: **flow = valuation** over `U.Transfer`; **CV is attached to transformations (steps)** and evaluated **before any GateFit**; edges carry **assurance‑only operations**; no token‑passing semantics are assumed.\n",
        "problem": "### A.21:2 - Problem\n\nWithout a unified GateFit core:\n\n* Gate admissibility becomes ad-hoc, **order-dependent**, and hard to audit (especially with multiple independent checks). \n* Gate logic leaks into CV (planes/comparators/freshness/roles appear “inside steps”), collapsing the CV/GF separation. \n* “Unknown / timeout / error” behavior becomes implicit and inconsistent across transitions, undermining reproducibility and safety. \n* Publication faces drift into “extra semantics” (computed scalars / tool encodings) rather than pins + refs, breaking MVPK discipline. \n",
        "forces": "### A.21:3 - Forces\n\n* **Separation vs convenience.** Keeping CV internal and GF profile-bound avoids leakage, but demands a crisp activation boundary. \n* **Determinism vs incompleteness.** Gates must remain deterministic even when evidence is missing or partial (`unknown`). \n* **Safety vs throughput.** Some profiles must treat ambiguity as `block`, others as `degrade`. \n* **Human comprehension vs formal minimality.** Optional narratives help readers, but must never masquerade as decisions. \n* **Reuse vs freshness.** Decisions may be reusable only under explicit equivalence; otherwise re-aggregation is mandatory. \n* **Scope granularity vs complexity.** Checks are declared with scopes (`lane|locus|subflow|profile`) and merged; duplicates must preserve evidence rather than overwrite it. \n",
        "solution": "### A.21:4 - Solution\n\n#### A.21:4.1 - Gate = microkernel of checks\n\n\n> **Note (guards are not GateChecks).** `USM.CompareGuard` / `USM.LaunchGuard` are **not** `GateCheckKind`s; they may emit `GuardFail` events which are **aggregated by the owner gate** under the active profile (`degrade|block`) and recorded in `DecisionLog` (details in A.24). \n`OperationalGate(profile)` is treated as a microkernel: checks are **pluggable** `GateCheck`s; the gate core **aggregates** their outputs **conceptually**, without procedural semantics and without mutating the transduction graph. \n\n#### A.21:4.2 - Publication lexemes and register discipline\n\n**Per-check reference lexeme.**\n`GateCheckRef := { aspect, kind, edition, scope }`, where:\n* `aspect ∈ {ConstraintValidity, GateFit}`,\n* `scope ∈ {lane|locus|subflow|profile}`.\n\n**Authoring shorthand (deprecated; MUST NOT be surfaced).**\nIf a short form `GateCheckRefLegacy := { kind, edition, scope }` appears in prose as a local shorthand, it SHALL be interpreted only as a projection of the normative record with `aspect` supplied explicitly at the point of surfacing. Any published face or `DecisionLog` entry MUST use the full `GateCheckRef` with `aspect`.\n\n**Decision terminology separation.**\n\n* `GateDecision` is the published lattice value.\n* `GateDecisionRationale` is the minimal structured support of that decision (check outcomes, folds, witness refs).\n* `GateDecisionExplanation` is optional, human-readable, derived from the rationale; it **does not carry decision status** and MUST NOT be used as one.  \n\n**Register discipline.** Tech labels are ASCII and twin-labeled where the plain form uses symbolic notation. \n(Example: use `CLPlane` / “CL^plane”, `CLKind` / “CL^k”, `UNM.TransportRegistryPhi` / “UNM.TransportRegistryΦ”, `GammaTimeRule` / “Γ_timeRule”.)\n\n#### A.21:4.3 - CV⇒GF activation predicate (counterfactual boundary)\n\nGateFit checks are *defined* as inactive unless the CV aspect is `pass`:\n* Let `CV.Status` be the join-aggregate of all `GateCheckRef` with `aspect=ConstraintValidity`.\n* For any `GateCheckRef` with `aspect=GateFit`:\n  **If `CV.Status ≠ pass`, the GateFit check outcome is `abstain`.** \n* While `CV.Status ≠ pass` **(or the active profile suppresses narratives)**, any GateFit-oriented `GateDecisionExplanation` **does not apply**. \n\nThis keeps the boundary crisp: CV explains internal lawfulness; GF explains profile-fit **only in the counterfactual world where CV passed**. \n\n**LaunchGate pre‑run barrier (work‑boundary special case).**\n\nFor the unique `LaunchGate` at the entry of each `U.Work`/`U.WorkEnactment`, let `Prev.CV.Status` denote the aggregated `ConstraintValidityStatus` of the **immediately preceding** step on the same `PathSlice`.\n\n* If `Prev.CV.Status ≠ pass`, then (i) all GateFit-scoped LaunchGate checks return `abstain` by activation, and (ii) the **overall LaunchGate** decision is forced to `block` (pre‑run barrier). The rationale MUST record the predecessor CV status and the forced-block rule in `DecisionLog`.\n\nThis is a publication-level safety invariant: it constrains what may be admitted at the work boundary without specifying evaluation order or execution scheduling.\n\n#### A.21:4.4 - Decision algebra: join-semilattice (“worst wins”)\n\n\n**Decision domain.** `GateDecision ∈ {abstain, pass, degrade, block}`.\n\n**Aggregation rule.** Aggregation over all applicable checks is the **idempotent, commutative, associative join** on\n`abstain ≤ pass ≤ degrade ≤ block`, with **neutral = `abstain`** and **absorbing = `block`**. \n\nPublications surface only:\n\n1. the aggregated `GateDecision`, and\n2. its `GateDecisionRationale` recorded in the `DecisionLog`. \n\n#### A.21:4.5 - Profile-bound folds for `error|timeout|unknown`\nA check may encounter `error`, `timeout`, or evidence-level `unknown`. These do **not** become new decision values; they are folded into the decision lattice **by profile and check policy**.\n**Normative minimum folds (tri-state).**  \n\n> **Naming note.** Some conformance tables use **Lean** as a label for the `GateProfile=Lite` gating posture. Treat this as an alias only, and do not confuse it with `PublishMode=Lite` (a publication-face reduction mode).\n\n| Active `GateProfile` | `error` fold | `timeout` fold | `unknown` fold (evidence-level) |\n| -------------------- | -----------: | -------------: | ------------------------------: |\n| `Lite`               |    `degrade` |      `degrade` | per `GateCheck` policy (`abstain` or `degrade`) |\n| `Core`               |    `degrade` |      `degrade` | per `GateCheck` policy (`abstain` or `degrade`) |\n| `SafetyCritical`     |      `block` |        `block` | per `GateCheck` policy (safety-default: `degrade`) |\n| `RegulatedX`         |      `block` |        `block` | per `GateCheck` policy (safety-default: `degrade`); X identity/edition are surfaced in `DecisionLog` |\n| `RegulatedX`         |      `block` |        `block` | per `GateCheck` policy (safety-default: `degrade`); X identity/edition are surfaced in `DecisionLog` |\n\nWhere a `GateCheck` declares an evidence-level `unknown` strategy, that strategy is part of the check’s intensional definition; the fold applied and its justification are recorded in `DecisionLog`.  \n\n#### A.21:4.6 - GateProfiles: binding only (full spec in A.26)\n\nA.21 binds the following *functional role* of `GateProfile`:\n\n> **Terminology (avoid `Lite`/`Lean` confusion).** `GateProfile=Lite|Core|SafetyCritical|RegulatedX` is the **gating posture** that determines the effective GateCheck set and fold policies. `PublishMode=Lite` is a **publication-face reduction mode** (AssuranceLane‑Lite / TechCard‑Lite) and MUST NOT be interpreted as a weaker `GateProfile`.\n\n* A `GateProfile` is an attribute of a **branch / `PathSlice`**; the default is `Core`. \n* Local overrides may change the active profile for the transition and below **but cannot reduce** the already-effective set of `GateCheckKind`s; only additions are allowed. Weakening requires a new `PathSlice` via sentinel. \n* `PublishMode=Lite` affects *faces only* and does **not** weaken the check set or aggregation rule. \n\n#### A.21:4.7 - Scope and merge semantics (`lane|locus|subflow|profile`)\n\n* Each `GateCheckRef` declares its scope; `subflow` scope is bounded by a sentinel bridge (restart / refresh boundary). \n* The effective check set is formed by **union across all declared scopes**; duplicates by `kind` merge by the same join rule (“worst wins”), and **all rationales are preserved** in `DecisionLog`.\n  * For `RegulatedConformance(X)`, the identity of **X** and its rule/edition reference are part of the rationale surface; multiple `RegulatedConformance(X{…})` may coexist in one gate.\n* A check outside its scope reports `abstain`. \n\n#### A.21:4.8 - Publication repeatability, caching, and re-aggregation triggers\n**Repeatability (publication-level).** Gate decisions MUST be replayable from declared pins/refs: no implicit “latest/now”. Any time basis is made explicit via `Γ_time` (or a `Γ_timeRule` that resolves to a concrete basis), and the resolved basis is recorded in `DecisionLog`.\n\n**Caching constraint (publication-level).** A gate decision may be cached **only** per\n`{PathSliceId, GateProfile, GateChecks.editions, editions{…}}`, where `GateChecks.editions` denotes the canonicalized, order-independent listing of the **effective** `GateCheckRef{aspect,kind,edition,scope}` (including their `edition`s) for this gate instance. Cache reuse is valid only while the declared freshness/evidence window remains valid under the active profile.\n\n**Re-aggregation triggers (non-exhaustive, normative).** Re-aggregation is required if any of the following changes (slice-local; no execution procedure implied):\n\n\n* any component of `editions{…}` changes (any `edition_key ↦ EditionId` bump),\n* any `GateCheckRef.edition` changes (including regulator X editions for `RegulatedConformance(X)`),\n* the declared `Γ_time` basis changes or resolves differently,\n* a relevant `FreshnessTicket` expires/changes or TOCTOU window constraints change,\n* a sentinel-bounded `subflow` refresh introduces a new RSCR carrier affecting the rationale surface,\n* any input breaks the declared equivalence witness (A.41).\n\nDecision stability is under the equivalence relation of A.41; a witness is surfaced on the `DecisionLog` (see §4.10). A.21 constrains equivalence + invalidation conditions but does not fix key formats.\n\n#### A.21:4.9 - MVPK faces for `OperationalGate(profile)` (minimum pins)\n\nThe gate publishes faces to record **what is declared**, not “how it executes”. Faces remain **pins + refs** (no new numeric claims; no I/O re-listing).\n\n**Minimum pins (PlainView / TechCard / AssuranceLane where applicable).**\n\n* View scope: `PublicationScopeId` (with MVPK profile: `Min|Lite|SetReady|Max`)\n* Identity: `GateId`, `BridgeId`, `PathId`, `PathSliceId`\n* Temporal: `DesignRunTagFrom`, `DesignRunTagTo`\n* Profile: `GateProfile` (PublishMode affects only face reduction)\n* Checks: list of `GateCheckRef` (`aspect`, `kind`, `edition`, `scope`)\n* CV: aggregated `ConstraintValidityStatus` and optional `ConstraintValidityWitnessRef` (refs only)\n* Editions: `editions{…}` vector + `EditionPins{CGSpec, ComparatorSet, UNM.TransportRegistryPhi}`\n  * **Gate-requirement on edition refs.** Any face that cites `CGSpec` / `ComparatorSet` / `UNM.TransportRegistryΦ` editions MUST also include `BridgeCard + UTS row` (A.27); otherwise downstream consumption is non-conformant.\n* ReferencePlane & CL: source/target `ReferencePlane` pins; `CLPlane` / “CL^plane” (for non-crossings `CL^plane = none` is allowed, but pins are still explicit); any Φ penalties are surfaced as rule refs and route to the **R-channel only**\n* Freshness: declared `GammaTime` / “Γ_time” pin and presence/absence of `FreshnessTicket` (refs)\n* Evidence: SCR/RSCR carrier anchors (refs) + VALATA (VA/LA/TA) presence on AssuranceLane\n* Guards: `USM.CompareGuard` / `USM.LaunchGuard` applicability pins (presence-only; GuardFail is handled by the owner gate per A.24)\n* Decision: aggregated `GateDecision` and `DecisionLogRef`\n\n**Lean face (PublishMode=Lite).** It MAY fold to `GateProfile / GateChecks / EditionPins / GateDecision + DecisionLogRef`, but:\n\n* it MUST keep `GateProfile` and `DecisionLogRef`,\n* it MUST not weaken GateChecks or the aggregation algebra, and\n* if `EditionPins` are present, it MUST still include `BridgeCard + UTS row` (A.27) and preserve the “red lines” on crossings (explicit `ReferencePlane`, `CLPlane`, and Φ → R-channel only).\n\n#### A.21:4.10 - DecisionLog (minimum composition)\n\n`DecisionLog` is an append-only record of reasons and references: \n\n* gate identity + `PathSliceId` (+ `PublicationScopeId` when the log is surfaced via a face bundle)\n* each `GateCheckKind`, its `GateCheckRef.edition`, and its folded outcome (`pass|degrade|block|abstain`) including the applied `error|timeout|unknown` fold\n* rule anchors / evidence anchors (SCR/RSCR carriers + VALATA bindings); where relevant, mismatched pins (SquareLaw) are called out explicitly\n* policy-id dependencies used by checks (as `PolicyIdRef` bundles per F.8:8.1), including `Φ(CL)`, `Φ_plane`, and `Ψ(CL^k)` where relevant, plus any gate-local policy-ids consulted by the active profile\n* `GuardFail` events (from `USM.Guards`) aggregated by the owner gate with the applied profile rule (`degrade|block`)\n* `EquivalenceWitness` (or `EquivalenceWitnessRef`) as a publication surface per A.41, minimally: `{ keys, E⃗, Γ_time(basis), PathSliceId?, ReturnShapeClass, ComparatorSetRef?, profile }`\n* the declared publish reaction for `degrade|block` (including any local “degrade mode” notes when permitted by profile)\n* for `RegulatedConformance(X)`: the identity of X and the rule/edition references used\n\n#### A.21:4.11 - GateChecks admissibility (GateFit-only catalog boundary)\n\n**Mandatory on LaunchGate.** `FreshnessUpToDate`, `DesignRunTagConsistency`.  \n**Allowed GateFit checks (non-exhaustive, normative minima).** \n\n* `DesignRunTagConsistency` (mandatory on LaunchGate; may appear elsewhere)\n* `FreshnessUpToDate` (mandatory on LaunchGate; may appear elsewhere)\n* `ReferencePlaneCrossing`\n* `ComparatorConstraintRules (CSLC)`\n* `EvidenceCompleteness`\n* `SafetyEnvelope`\n* `RegulatedConformance(X)` (X identity + edition/rule refs are surfaced in `DecisionLog`)\n* `Role/ChannelFit` (roles are Kernel `U.Role` tokens, not alias strings)\n* `EquivalencePreservation`\n* `OutflowAudit`\n* `SnapshotConsistency`\n\n**Forbidden (hard boundary).**\n\n* Modeling CV classes “as GateFit” (CV classes remain CV; GF remains GF). \n* Any “LEX gate checks” or lexical pseudo-checking (lexical views do not participate in decisions).  \n\n#### A.21:4.12 - SquareLaw compatibility at crossings\nFor every GateCrossing, the SquareLaw constraint must hold:\n`gate_out ∘ transfer = transfer' ∘ gate_in`. \n\nProfile selection/inheritance does not weaken this requirement; inconsistency yields `block|degrade` within the active profile and is recorded in the DecisionLog. LaunchGate is a work-boundary GateCrossing case, so SquareLaw is mandatory there as well.\n\n#### A.21:4.13 - Lexical mediation (optional trace, non-decisional)\n\nA gate MAY publish a `LexicalResolutionRef` / `LexicalView` for traceability of alias resolution, but:\n\n* it does **not** participate in aggregation, and\n* it does **not** influence `GateDecision`.  \n",
        "archetypal_grounding": "### A.21:5 - Archetypal Grounding\n\n#### A.21:5.1 - System vignette — “Regulated release gate”\n\n**Tell.** A flow reaches a `LaunchGate` just before a `U.WorkEnactment` that can finalize binding. The active profile is `RegulatedX`. The gate publishes a single `GateDecision` and a `DecisionLog` that explains *why* the release is admissible (or not), without encoding any execution procedure.\n\n**Show A (CV ✔, GF ✖).** CV checks are `pass`, activating GateFit. `RegulatedConformance(X)` is present but evidence anchors are incomplete (`EvidenceCompleteness` folds to `degrade` under `Core/RegulatedX` policy), so the join yields `degrade`. The DecisionLog records which `GateCheckRef` caused the fold and the declared publish reaction for degraded release. \n\n**Show B (CV ✖, GF n/a).** CV aggregate is `degrade`. All GateFit checks return `abstain` by activation, and any GateFit-oriented explanation is inapplicable. The gate’s published decision is driven by CV; the DecisionLog shows CV status and the “inactive GF” boundary rather than a fabricated GF narrative.  \n\n#### A.21:5.2 - Episteme vignette — “Cross-plane comparability gate”\n\n**Tell.** A flow transitions into a comparability-critical step (CSLC). The gate must surface `BridgeId + UTS + CLPlane` and edition pins for downstream consumers, and must remain stable under A.41 equivalence.\n\n**Show A (Core, clean crossing).** The gate publishes `EditionPins{CGSpec, ComparatorSet, TransportRegistryPhi}`, `ComparatorSetRef`, `CL/CLPlane`, and a `GateDecision=pass` with a rationale that cites the relevant `GateCheckRef`s and editions. \n\n**Show B (SquareLaw mismatch).** A crossing attempts to change plane pins without the commutative-square witness; the SquareLaw check yields `block` (or `degrade` under a weaker profile), and the DecisionLog records the mismatched pins as the reason.  \n",
        "bias‑annotation": "### A.20:6 - Bias‑Annotation\n\nThe pattern constrains *how* internal constraints are surfaced; it does not encode profile‑bound thresholds or Role/Channel fit — those sit in GateFit. This separation reduces leakage of profile concerns into mechanism semantics.\n",
        "conformance_checklist": "### A.21:7 - Conformance Checklist\n\nMinimum unified conformance for A.21 (and any flow that claims GateFit discipline): \n\n#### A.21:7.1 - Core gate semantics\n\n* [ ] **CC‑TGA‑06**: all GateCrossings (CtxState changes, and work-boundary crossings via LaunchGate) are mediated by `OperationalGate(profile)` and have a `DecisionLog`. \n* [ ] **CC‑TGA‑07**: CV⇒GF activation predicate holds (`CV≠pass ⇒ GF=abstain`). \n* [ ] **CC‑TGA‑21**: decision stability witness is present on the `DecisionLog` surface (A.41 `EquivalenceWitness`). \n* [ ] **CC‑TGA‑21a**: aggregation is the join on `abstain ≤ pass ≤ degrade ≤ block`; `GateDecisionExplanation` is optional and non-decisional. \n* [ ] **CC‑TGA‑22**: `error|timeout` folds are profile-bound; `unknown` folds per GateCheck policy. \n\n#### A.21:7.2 - LaunchGate discipline (pre-run barrier)\n\n* [ ] **CC‑TGA‑08**: every `U.WorkEnactment` has exactly one `LaunchGate` with mandatory `FreshnessUpToDate` + `DesignRunTagConsistency`; **pre‑run barrier:** if the immediately preceding aggregated `ConstraintValidityStatus ≠ pass`, then all LaunchGate GateFit checks are `abstain` and the overall LaunchGate decision is `block` (logged). \n* [ ] **Pre‑Run barrier** is satisfied for any `U.Work` where `FinalizeLaunchValues` is possible. \n\n#### A.21:7.3 - Publication and evidence\n\n* [ ] **CC‑TGA‑20**: `PublishMode=Lite` affects faces only; required GateChecks remain intact. \n* [ ] **CC‑TGA‑25**: AssuranceLane surfaces `GateProfile`, `GateCheckRef` list, edition pins, `GateDecision`, and `DecisionLogRef` with the two-layer evidence scheme (SCR/RSCR + VALATA). \n\n#### A.21:7.4 - Cross-boundary additions (when the gate is a crossing)\n\n* [ ] **CC‑TGA‑11**: crossings publish `BridgeId + UTS + CLPlane/CL^plane`, penalties route to the R-channel only. \n* [ ] **CC‑TGA‑23**: SquareLaw holds on crossings; mismatch yields `block|degrade` per profile and is logged. \n\n#### A.21:7.5 - Lexical norms (E.10 discipline)\n\n* [ ] Tech names are ASCII and twin-labeled; required token classes are registered under LEX (including `GateProfile`, `GateCheckKind`, `GateCheckRef`, `DecisionLog`). \n* [ ] Any lexical alias view is trace-only and does not affect decisions. \n",
        "consequences": "### A.21:8 - Consequences\n\n**Benefits**\n\n* **Deterministic gating.** Join-semilattice aggregation makes decisions order-independent and idempotent (modulo declared equivalence), enabling consistent audit and replay. \n* **Clean CV/GF separation.** Activation boundary prevents profile concerns from leaking into mechanism validity. \n* **Profile clarity.** Fold policies (`error|timeout|unknown`) are explicit and profile-bound, making safety posture reviewable. \n* **Publication hygiene.** MVPK faces remain pins+refs (no new numeric claims), and DecisionLog captures rationale without procedural commitments. \n\n**Trade-offs**\n\n* **More artifacts to publish.** Decisions are not “just pass/fail”: they require rationales, pins, and logs. \n* **Two-stage reasoning.** Users must internalize “GF does not apply until CV passes”; mitigated by explicit inapplicability rules and optional narratives only when applicable. \n* **Scope complexity.** Multi-scope merge semantics can feel heavy; mitigated by union + worst-wins + preserved rationales. \n",
        "rationale": "### A.21:9 - Rationale\n\n* The microkernel framing preserves a single graph semantics: checks are nodes and publications, not an external pipeline; this blocks the emergence of a “second ladder” of hidden processes. \n* The join lattice provides a minimal, monotone aggregation that supports:\n\n  * early absorption at `block` without specifying execution strategy, and\n  * deterministic publication semantics (commutative + associative + idempotent). \n* CV⇒GF activation is the mechanism that keeps orthogonality strict while still publishing a single gate decision surface: GF results never “mask” CV failures. \n* Explicit folds for `error|timeout|unknown` make safety posture reviewable and profile-specific without inventing new decision values. \n",
        "sota‑echoing_(post‑2015)": "### A.20:10 - SoTA‑Echoing (post‑2015)\n\n* **Algebraic effects & handlers** (Koka, Effekt): signatures vs. handlers as a model for CV vs. GF.\n* **Reproducible pipelines** (Bazel, Nix): hermetic builds ≈ CV; release/deploy gates ≈ GF.\n* **Optics/profunctors; open/hypergraph categories** (2017–2019+): composition over open graphs without extra face semantics.\n* **Quality‑Diversity / MAP‑Elites / CMA‑ME / DQD (2015–2022):** set‑return with lawful partial orders; no hidden scalarization.\n  These anchors justify the separation and the set‑return discipline (CSLC) embedded in the flow family.\n",
        "relations": "### A.21:11 - Relations\n\n* **E.TGA →hosts→ A.21.** GateFit-scoped GateChecks are aggregated by `OperationalGate(profile)`; enumeration and publication shape of GateChecks live here. \n* **A.20 →couples_to→ A.21 via CV⇒GF.** CV is evaluated inside transformations; while CV≠pass, GF is `abstain` and GF explanations do not apply. \n* **A.26 →fully_specifies→ GateProfile.** A.21 binds to A.26 for the profile matrix, inheritance rules, and detailed mandatory check sets. \n* **A.25 (Sentinel/SubFlow) →provides→ scope boundaries.** `subflow` scope is bounded and restartable; weakening check sets requires new `PathSlice`. \n* **A.27 (Bridge+UTS) →required_by→ any edition-citing face.** Whenever gate faces cite editions, the compatibility surface (BridgeCard + UTS + `CL/CLPlane`) is required for downstream consumption. \n* **A.41 →defines→ equivalence for decision stability.** Gate decisions are stable only under the declared equivalence witness; breaking equivalence implies re-aggregation. \n",
        "a.20:appendix_a_—_cv_class_gloss_(normative)": "### A.20:Appendix A — CV Class Gloss (normative)\n\n* **MechanismUnitsCoherence.** Internal unit/scale coherence within the step; no declarations or translations of units/planes (GateFit scope).\n* **LawSetInvariants.** Mechanism‑declared invariants hold (e.g., mass/energy balance in a model, determinism under fixed editions).\n* **AdmissibilityConditionsSatisfaction.** Inputs lie within admissible windows/guards declared by the mechanism’s **AdmissibilityConditions**; failure yields `degrade` or `abstain` per class policy.\n  **Minimum declaration (normative):**\n  `AdmissibilityDecl := { domains: {name: set/poset}+, guards: [predicate_id]*, windows: {Γ_time: snapshot|interval|policy}, observables: [signal_id]*, edition: EditionId }`.\n  The declaration is surfaced on MVPK as references only; it introduces no arithmetic on faces.\n* **LipschitzBounds / stability.** Bounded sensitivity to perturbations as declared by mechanism; optional where meaningful.\n  **Method binding (normative):**\n  `LipschitzBoundRef := { method ∈ {spectral_norm|CROWN|IBP|rand_smoothing|other}, metric_space: {X: norm_id, Y: norm_id}, bound: value_or_interval, units/plane: P, validity_window: Γ_time(basis), edition: EditionId }`.\n  The bound is **edition‑pinned** and **plane/units‑declared**; proofs/witness artefacts are referenced (no new numeric claims on faces).\n  **Minimal declaration template (normative):**  \n  `AdmissibilityConditions := { Domains[]{var, type, range, units, plane}, Guards[]{predicate, editionRefs}, ObservationWindows[]{Γ selector, freshness window}, ObservableSigns[]{name, detection rule}, Editions{… } }`  \n  — **No authoring of units/planes** here; only references. — Γ selectors must be explicit.\n* **TypeDomainRange.** Type/domain/range compliance of inputs/outputs (ref‑only to definitions).\n* **ReinterpretationEquivalence.** Mechanism’s reinterpretation preserves internal meaning on a **PathSlice**.  \n  **Witness (normative):** **ReinterpretationEquivalenceWitness** (see §4.7) with: `(i)` `PathSliceId`, `PublicationScopeId`, `(ii)` bidirectional mapping (iso/optic) with Put‑Get/Get‑Put obligations, `(iii)` commuting squares for adjacent raw transfers, `(iv)` **NoHiddenScalarization** assertion (if comparable), `(v)` definedness region.  \n  — **No plane/unit change**; any describedEntity change must have `KindBridge (CL^k)` on UTS.\n* **LipschitzBounds / stability.** Bounded sensitivity of the mechanism under a declared metric.  \n  **Certificate (normative):** `LipschitzCertificate := { metricId (with units/plane), bound L, methodId, methodRef (e.g., spectral estimate / cert. robustness bound), validity region (inputs/state), proof sketch/ref }`.  \n  — The **method** MUST be cited; **units/plane** of the metric MUST be explicit; bounds are **ref‑only** at CV; any acceptance action remains GateFit.\n* **TypeDomainRange.** Well‑typedness and domain/range consistency for the transformation signature.\n  (Enumeration mandated by A.20; GF matters excluded).\n* **ReinterpretationEquivalence (StructuralReinterpretation).** Existence of a correspondence/reversibility witness between source and retarget projections; preservation of `⟨L,P,E⃗,D⟩`; no comparator/plane/unit declaration or translation at CV. The witness is **PathSlice‑local** and supports **idempotence & reversibility** within the addressed slice. The normative record is `ReinterpWitness` (see §4.7).\n\n#### A.20:Appendix B — LEX discipline (summary)\n\nRegister token classes (Tech) include: `U.TransductionFlow`, `U.TransductionGraph`, `OperationalGate`, `GateProfile`, `GateCheckKind`, `GateCheckRef`, `DecisionLog`, `FreshnessTicket`, `FinalizeLaunchValues`, `SubflowRef`, `FlowEmbed`, `SentinelId`, `PathSliceId`, `SliceRefresh`, `VALATA`; discriminators use `Base__P2W`, `Base__EvaluatingAndRefreshing`; Tech names are ASCII; aliases `GammaTimeRule/Plane`, `CLPlane`, `Phi` follow E.10. A.20 references these tokens; it does not introduce additional LEX classes. **For each surfaced CV check, `GateCheckRef.aspect` is fixed to `ConstraintValidity`.** *MVPK minima for CV faces also include `PathId/PathSliceId` where slice‑local refresh applies (A.22).*\n",
        "a.20:end": "### A.20:End\n\n## A.21 — GateProfilization: `OperationalGate(profile)` (GateFit core)\n\n**ID:** A.21\n**Type:** Architectural pattern\n\n**One-liner.** A single microkernel-style gate aggregates **GateChecks (CV + GF)** into an **order-independent** `GateDecision` via the join-semilattice `abstain ≤ pass ≤ degrade ≤ block`, enforces the **CV⇒GF activation predicate** (and the LaunchGate pre‑run barrier), applies profile-bound folds for `error|timeout|unknown`, and publishes replay-grade traces (MVPK + `DecisionLog` + `EquivalenceWitness`). \n",
        "bias_annotation": "### A.21:6 - Bias-Annotation\n\nThis pattern’s built-in biases are stated across the five Principle-Taxonomy lenses (Gov, Arch, Onto/Epist, Prag, Did). \n\n* **Gov.** Bias toward auditability and explicit responsibility (DecisionLog + profile-bound folds). Risk: gate owners become de facto governors; mitigation: keep profiles explicit, inheritable, and pinned to `PathSliceId` for reviewable replay. \n* **Arch.** Bias toward a microkernel of checks (pluggable GateChecks + join aggregation). Risk: “check sprawl”; mitigation: scope discipline + forbidden LEX pseudo-checking + CC-based profile minima. \n* **Onto/Epist.** Bias toward a 4-value admissibility lattice and explicit “does not apply” boundaries. Risk: oversimplifying nuanced epistemic uncertainty; mitigation: preserve structured rationales and allow check-level `unknown` policies rather than inventing new global decision values. \n* **Prag.** Bias toward determinism and replayability (cache invalidation by pinned vectors). Risk: higher publication overhead; mitigation: PublishMode=Lite for faces (never for weakening checks). \n* **Did.** Bias toward explicit separation (CV vs GF) and “what is published” clarity. Risk: more concepts to learn; mitigation: archetypal grounding + stable minimal pins across faces. \n",
        "sota_echoing": "### A.21:10 - SoTA-Echoing\n\nAnchors (post-2015) that this pattern **adopts/adapts/rejects**, consistent with the assignment’s intent (assured lanes, open graphs/hypergraph categories, join-semantics). \n\n* **Adopt.** *Join-semilattice aggregation as deterministic, order-independent merge* (distributed systems / CRDT literature, e.g., Kleppmann 2017; Kleppmann & Beresford 2017): A.21 reuses the algebraic idea to make gate outcomes commutative/associative/idempotent without prescribing evaluation order.\n* **Adapt.** *Compositional reasoning with commuting diagrams* (applied category theory, e.g., Fong & Spivak 2019): A.21 adapts the intuition by making SquareLaw a gate-audited invariant on crossings, while keeping publications human-first and pin-based.\n* **Adapt.** *Supply-chain provenance / policy gating via attestations* (software supply-chain security, e.g., in-toto 2019; SLSA 2021+): A.21 adapts the “attestation + policy check + logged decision” structure, but expresses it as MVPK pins + `DecisionLog`, not tool-specific workflows.\n* **Reject.** *Narrative-as-authority.* Any approach where human-readable explanations function as decision-bearing artifacts is rejected; in A.21, narratives remain optional derivatives of structured rationales and are explicitly non-decisional. \n",
        "a.21:end": "### A.21:End\n\n# Part B – Trans‑disciplinary Reasoning Cluster\n"
      },
      "content": "### A.21:End\n\n# Part B – Trans‑disciplinary Reasoning Cluster\n",
      "metadata": {},
      "part": "A",
      "cluster": null
    },
    {
      "id": "B.1",
      "title": "Universal Algebra of Aggregation (Γ)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## B.1 - Universal Algebra of Aggregation (Γ)\n",
        "problem": "### B.1:2 - Problem\n\nIf each discipline (or project team) invents its own way of “adding things up”, four lethal pathologies appear:\n\n1. **Compositional Chaos** — identical parts aggregated by two tools yield different wholes; parallel work becomes impossible.\n2. **Brittle Dashboards** — system‑level KPIs lie because the roll‑up silently hides the weakest component.\n3. **Invalid Extrapolation** — proofs that hold locally break globally; safety cases collapse on integration day.\n4. **Emergence as Magic** — genuine synergy (“whole > sum parts”) is indistinguishable from a modelling error.\n\nAll four are witnessed in post‑2015 incidents, from micro‑service outages to meta‑analysis retractions.\n\n",
        "forces": "### B.1:3 -  Forces\n\n| Force                           | Tension                                                                                    |   |\n| ------------------------------- | ------------------------------------------------------------------------------------------ | - |\n| **Universality vs Specificity** | One algebra must work for pumps, proofs and policies ↔ each domain owns quirky edge‑cases. |   |\n| **Determinism vs Emergence**    | Predictable, order‑free folds ↔ need to legitimise authentic novelty.                      |   |\n| **Safety vs Synergy**           | Conservative *Weakest‑Link* bound ↔ modelling genuine redundancy wins.                     |   |\n| **Simplicity vs Fidelity**      | Five rules managers can remember ↔ enough depth for formal proof.                          |   |\n| **Auditability vs Overhead**    | Machine‑checkable Standard ↔ authors must show their invariants.                           |   |\n\n",
        "solution": "### B.1:4 - Solution — **The Invariant Quintet Standard**\n\n> *FPF freezes one universal operator, **Γ**, and binds it to five non‑negotiable invariants. Compliance with the quintet is the ticket that lets any calculus, in any future discipline, plug into the holarchy.*\n\n#### B.1:4.1 - The Universal Aggregation Operator\n\n```\nΓ : (D : DependencyGraph, T : U.TransformerRole) → U.Holon\n```\n\n* **`D`** — a finite, acyclic graph of sibling holons at level *k*.\n* **`T`** — an external `U.TransformerRole` (not a node of `D`); see A.12.\n*Result:* a new holon at level *k + 1* whose boundary encloses every node of `D`.\n\nBecause Γ is *externalised* through `T`, the provenance chain stays intact, satisfying the **Transformer Principle**;\n\n#### B.1:4.2 - The Five Grounding Invariants\n\n| Code     | Invariant             | Plain‑English headline                            | Why it matters                               |   |\n| -------- | --------------------- | ------------------------------------------------- | -------------------------------------------- | - |\n| **IDEM** | *Idempotence*         | One part alone stays itself.                      | Anchors recursion; stops base‑case drift.    |   |\n| **COMM** | *Local Commutativity* | Swap independent parts, nothing changes.          | Enables divide‑and‑conquer builds.           |   |\n| **LOC**  | *Locality*            | Which worker or rack runs the fold is irrelevant. | Guarantees reproducible distributed runs.    |   |\n| **WLNK** | *Weakest‑Link Bound*  | No claim may exceed the frailest part.            | Keeps dashboards honest; caps hidden risk.   |   |\n| **MONO** | *Monotonicity*        | Improving any part never hurts the whole.         | Justifies “fix the bottleneck” optimisation. |   |\n\n*Mnemonic for managers:* **S‑O‑L‑I‑D** → Same, Order‑free, Location‑free, Inferior‑cap, Don’t‑regress.\n\n**Archetypal Grounding**\n\nThe Invariant Quintet is not an abstract mathematical construct; it is a formalization of common-sense physical and logical realities that manifest across all domains.\n\n| Invariant | `U.System` — Pump Skid Assembly | `U.Episteme` — Scientific Meta-Analysis |\n| :--- | :--- | :--- |\n| **IDEM** | An assembly of a single pump is just that pump, with its original specifications. | A review of a single study is just that study, with its original conclusions and evidence level. |\n| **COMM / LOC** | Welding two independent pump modules to the skid in a different order or in different assembly bays results in an identical final product. | The conclusions of a meta-analysis are independent of the order in which two unrelated studies were added to the evidence pool. |\n| **WLNK** | The maximum pressure rating of the entire pump skid is limited by the pressure rating of its weakest pump or connector. | The overall reliability of a synthesized theory is capped by the reliability of its least-supported foundational claim. |\n| **MONO** | Replacing a standard motor with a more powerful, efficient one can only improve or maintain the skid's overall performance; it cannot make it worse. | Adding a new, high-quality study to a meta-analysis can only strengthen or maintain the overall confidence in its conclusion, never weaken it (unless it introduces a conflict). |\n\n#### B.1:4.3 - Why only five?  (A didactic sidebar)\n\n* Post‑2015 physics shows that renormalisation flows stabilise if and **only if** idempotence, locality and monotone bounds hold (Goldenfeld & Ho 2018).\n* Distributed‑data research (Spark 3, Flink 1.19) proves COMM + LOC are prerequisites for deterministic sharding.\n* Safety cases in aviation and ISO 26262 rewrote their risk roll‑ups around *Weakest‑Link* after 2021 audit failures.\n\nThus the quintet is simultaneously **empirically vetted**, **mathematically minimal**, and **cognitively teachable**.\n\n#### B.1:4.4 - Emergence Without Cheating\n\nReal redundancy can push a system above the WLNK ceiling (e.g., RAID 6 survives two disk deaths). FPF treats this not as a rule break but as a **Meta‑Holon Transition (MHT)**: the redundant set is promoted to a fresh holon tier, and the quintet re‑applies there. The algebra stays pure; emergence becomes explicit, auditable design space. Details live in Pattern **B.2 Meta‑Holon Transition (MHT): Recognizing Emergence and Re‑identifying Wholes** (next in cluster).\n",
        "domain‑specific_“flavours”_of_γ": "### B.1:5 - Domain‑Specific “Flavours” of Γ\n\nThe core signature of Γ never changes, but each discipline supplies a **flavour** that instantiates the quintet with domain‑appropriate mathematics and measurement units.\n\n| Flavour      | Typical domain                                               | Dropped / relaxed invariants   | Added compensating rules                                                            | Canonical reference model (post‑2015)                                  |\n| ------------ | ------------------------------------------------------------ | ------------------------------ | ----------------------------------------------------------------------------------- | ---------------------------------------------------------------------- |\n| **Γ\\_sys**  | Physical & cyber‑physical systems                            | *None*                         | –                                                                                   | ISO 15926‑2024 *Plant Data* roll‑up; NASA 2023 Integrated Hazard Model |\n| **Γ\\_epist** | Knowledge graphs, meta‑analysis                              | *None*                         | Provenance weighting (PW‑1), Citation transparency (PW‑2)                           | OntoCommons 2024 audit trail                                           |\n| **Γ\\_time**  | Time‑series forecasting, digital twins                       | COMM → **partial**; LOC waived | Coverage completeness (TS‑1), Temporal alignment (TS‑2)                             | EU Battery Passport 2025 reliability stack                             |\n| **Γ\\_ctx**   | Order‑sensitive processes, quantum pipelines, social surveys | COMM & LOC waived              | Reproducibility hash (CTX‑1), Partial‑order soundness (CTX‑2), Observer log (CTX‑3) | CERN HL‑LHC workflow 2024                                              |\n\n> **Didactic hint for managers:** choose the flavour whose examples look like your own dashboards; then verify your tooling honours its extra rules.\n",
        "walkthrough_examples": "### B.1:6 - Walkthrough Examples\n\n#### B.1:6.1 - `Γ\\_sys` — Offshore Wind Farm (2025 build)\n\n1. **Parts**: 72 nacelles, 72 towers, 1 export cable set.\n2. **Graph**: acyclic; each nacelle depends on its own tower, all depend on cable.\n3. **Fold**: Any parallel assembly order is legal → COMM, LOC.\n4. **WLNK check**: weakest nacelle (load factor = 0.91) bounds farm output ≤ 0.91 × rated.\n5. **Upgrade test**: swapping one nacelle to 0.95 raises farm bound — satisfies MONO.\n\n*Result*: farm holon inherits predictable capacity curve; financiers can quote risk‑adjusted yield without bespoke simulation.\n\n#### B.1:6.2 - `Γ_epist` — Living Systematic Review on mRNA Therapies (2024–2025)\n\n1. **Parts**: 38 peer‑reviewed trials, 12 preprints.\n2. **Graph**: dependency edges encode shared cohorts; no cycles.\n3. **Fold**: trials merged irrespective of ingestion order → COMM; distributed evaluators may differ, but provenance hashes equalise weighting → LOC.\n4. **WLNK**: overall certainty cannot exceed the lowest GRADE score among included trials.\n5. **Emergence**: discovery of a consistent age‑interaction effect violates WLNK; reviewers declare **MHT**, elevating the combined dataset to a new holon “Evidence v2” with age‑stratified potency as a *novel attribute*.\n\n*Result*: regulators see a transparent promotion of evidence tier rather than a hidden statistical artefact.\n\n#### B.1:6.3 - `Γ\\_time` — National Grid Frequency Forecast (2025‑2030)\n\n*COMM* holds only across non‑overlapping windows; *LOC* is waived because regional sensors differ in latency.  Additional TS‑1/TS‑2 rules ensure gaps are filled before aggregation.  Engineers iterate locally yet obtain one coherent five‑year projection.\n\n",
        "conformance_checklist": "### B.1:7 - Conformance Checklist (for pattern adopters)\n\n| ID       | Check                                        | How to demonstrate (engineer‑manager view)                      | Typical evidence artefact                   |\n| -------- | -------------------------------------------- | --------------------------------------------------------------- | ------------------------------------------- |\n| **CL‑1** | **Declare flavour** (`Γ\\_sys`, `Γ_epist`, …) | Front‑page spec line                                            | Pattern header                              |\n| **CL‑2** | **Show quintet proof**                       | Table mapping each invariant → test or theorem                  | PDF appendix, automated notebook            |\n| **CL‑3** | **Graph acyclicity**                         | Static analysis or domain rule                                  | Screenshot of tool report / manual argument |\n| **CL‑4** | **External Transformer**                         | Name the role (Standardor, editorial board, orchestration node) | Organogram, RACI sheet                      |\n| **CL‑5** | **Emergence pathway**                        | State MHT trigger criteria                                      | Flowchart, decision table                   |\n\nA proposal that skips any line of the checklist **fails** pattern B.1 and must iterate before peer review.\n\n",
        "consequences": "### B.1:8 - Consequences\n\n| Benefit (managerial)                                     | Pay‑off path          | Trade‑off                       | Mitigation                            |\n| -------------------------------------------------------- | --------------------- | ------------------------------- | ------------------------------------- |\n| Clear *risk ceiling* at every roll‑up (WLNK)             | Faster go/no‑go gates | May look pessimistic            | Highlight redundancy, then invoke MHT |\n| **Parallel engineering** without merge hell (COMM + LOC) | Shorter critical path | Requires origin hash discipline | Provide reference script templates    |\n| **Continuous improvement** strategies justified by MONO  | Lean upgrade budgets  | Cannot model negative synergies | Attach incentive to detect MHT events |\n| **Audit trail** readable by non‑experts                  | Easier certification  | Extra documentation overhead    | Auto‑generate provenance footers      |\n\n",
        "rationale": "### B.1:9 - Rationale\n\nThe Invariant Quintet is the \"renormalisation law\" of FPF. It translates deep principles from physics, computer science, and engineering into a universal, algebraic Standard that governs composition in any domain.\n\n**Physics & Renormalisation:** The invariants mirror the laws of renormalisation group (RG) flows. IDEM, COMM, and LOC ensure that the aggregation is a well-behaved coarse-graining operation, while WLNK acts as a conservative bound on energy and risk, preventing \"free lunch\" synergies from appearing by mere arithmetic.\n*   **Distributed Systems:** The COMM and LOC invariants are the formal prerequisites for modern, large-scale distributed computing. Systems like Spark and Flink rely on the guarantee that data can be processed on independent workers in any order, and the final result will be deterministic.\n*   **Systems Engineering & Safety:** The WLNK and MONO invariants are cornerstones of safety-critical design. Fault-tree analysis and reliability engineering are built on the WLNK principle that a system is no stronger than its weakest link. The MONO principle provides the formal justification for iterative improvement (\"Kaizen\"): it guarantees that a local fix will not cause a global regression.\n\nBy elevating these cross-disciplinary insights to the level of a mandatory, constitutional Standard, FPF ensures that all composition within the framework is predictable, auditable, and physically plausible. It transforms aggregation from an ad-hoc, domain-specific art into a universal, repeatable science.\n ",
        "anti_patterns_&_conceptual_repairs": "### B.1:10 - Anti-Patterns & Conceptual Repairs\n\n| Anti-Pattern | Symptom | Conceptual Fix |\n| :--- | :--- | :--- |\n| **Averaging Risk** | A dashboard shows a high overall reliability score for a system by averaging a high-reliability component with a low-reliability one. | Enforce the **WLNK** invariant. The aggregate reliability must be `min(R_parts)`, not `avg(R_parts)`. |\n| **Order-Dependent Builds**| The same set of software architheories produces a different final build depending on the compilation order. | Enforce **COMM/LOC**. Identify the hidden dependency between the architheories and either remove it or make it explicit, moving to `Γ\\_ctx` if necessary. |\n| **Improvement Paradox** | A team replaces a component with a better one, but a system-level KPI gets worse. | Enforce **MONO**. This indicates a hidden, negative coupling. The model must be updated to make this coupling an explicit constraint or interaction. |\n| **Synergy by Narrative** | A claim is made that the whole is greater than the sum of its parts, without a formal mechanism. | This violates **WLNK**. If the synergy is real (e.g., due to redundancy or a new feedback loop), it must be modeled as a **Meta-Holon Transition** (Pattern B.2). |\n",
        "relations": "### B.1:11 - Relations\n\n* **Builds on:** *Holonic Foundation*, *Transformer Principle*, *Open‑Ended Kernel*.\n* **Enables:** *Meta‑Holon Transition* (B .2), *Calculus of Trust* (B .3), *Holonic Lifecycle Patterns* (Cluster C).\n* **Refined by:** Flavour sub‑patterns B .1.2 – B .1.4.\n* **Exemplifies:** Pillars *Cross‑Scale Consistency*, *State Explicitness*, *Ontological Parsimony*.\n\n> **Take‑home maxim:** *“Aggregation is never neutral; Γ makes its politics explicit and testable.”*\n",
        "b.1:end": "### B.1:End\n"
      },
      "content": "### B.1:End\n",
      "metadata": {},
      "part": "B",
      "cluster": null
    },
    {
      "id": "B.1.1",
      "title": "Dependency Graph & Proofs",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## B.1.1 - Dependency Graph & Proofs\n",
        "problem": "### B.1.1:2 - Problem\n\nWithout a disciplined `DependencyGraph`, four pathologies recur:\n\n1. **Relation drift:** Edges blur composition with mapping (e.g., “represents”), or confuse collections with parts. Aggregations then mix algebraic regimes (sums where mins are required, etc.).\n2. **Boundary blindness:** Cross‑holon influences are drawn as parts, bypassing explicit `U.Boundary` and `U.Interaction`. This corrupts locality (LOC) and defeats reproducible folding.\n3. **Temporal conflation:** `design‑time` and `run‑time` holons appear in one graph; simulations then “prove” facts about a blueprint using live telemetry.\n4. **Hidden cycles:** Self‑dependence enters through aliasing (e.g., a team is a member of itself via “units of units”). Γ cannot topologically fold such graphs.\n\n",
        "forces": "### B.1.1:3 - Forces\n\n| Force                              | Tension                                                                                                                             |\n| ---------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------- |\n| **Universality vs. Precision**     | One schema for systems and epistemes ↔ different composition logics (physical vs. conceptual) must be kept distinct but compatible. |\n| **Parsimony vs. Expressiveness**   | Keep the vocabulary small (A.11) ↔ include the minimal extra relations that engineers actually use (A.14).                          |\n| **Locality vs. Connectivity**      | Preserve boundary‑local reasoning (LOC) ↔ still allow explicit external influences via interactions, not parthood.                  |\n| **Static clarity vs. Dynamic use** | Graphs must be easy to read and verify ↔ also feed Γ\\_ctx, Γ\\_time, Γ\\_method, Γ\\_work without duplications or mismatches.            |\n\n",
        "solution": "### B.1.1:4 - Solution\n\n#### B.1.1:4.1 - The shape: a typed, scoped, acyclic graph\n\n**Definition.**\n\n```\nDependencyGraph D = (V, E, scope, notes)\n```\n\n* **V (nodes):** each `v ∈ V` is a `U.Holon` with:\n\n  * `holonKind ∈ {U.System, U.Episteme}`\n  * `DesignRunTag ∈ {design, run}` (A.4) — **single, uniform per D**\n  * a declared `U.Boundary` (A.14)\n  * optional characteristics (e.g., F–G–R, CL, Agency metrics) for use by downstream patterns (B.1.2/3; B.3; A.13)\n* **E (edges):** each `e ∈ E` is a **mereological** relation from the **normative vocabulary `V_rel`** (below).\n* **scope:** the uniform temporal scope of the entire graph (`design` or `run`).\n* **acyclicity:** `D` **MUST** be a DAG. Any cycle requires refactoring or elevation to a Meta‑Holon (B.2).\n\n> **Strict distinction (A.15).**\n> `DependencyGraph` encodes **part–whole** only. Order goes to Γ\\_ctx/Γ\\_method. Time evolution goes to Γ\\_time. Resource spending goes to Γ\\_work. Cross‑boundary influence goes to `U.Interaction` (not parthood).\n\n\n#### B.1.1:4.2 - Normative edge vocabulary `V_rel` (A.14 compliant)\n\nOnly the following **four** **mereological** relations are allowed in `E` (A.14):\n\n\n| Family               | Relation             | Short intent                                            | Where it belongs                   |\n| -------------------- | -------------------- | ------------------------------------------------------- | ---------------------------------- |\n| **Structural**       | **ComponentOf**      | physical/machined part in an assembly                   | Γ_sys                               |\n|                      | **ConstituentOf**    | logical/content part in a conceptual whole              | Γ_epist                             |\n| **Quantity & Phase** | **PortionOf**        | quantitative fraction of a homogeneous stock or carrier | Γ_sys / Γ_work                      |\n|                      | **PhaseOf**          | temporal phase/slice of the *same carrier*              | Γ_time / Γ_work                     |\n\n**Not in `V_rel` (by design):**\n* `SerialStepOf`, `ParallelFactorOf` — **order/concurrency** edges of Γ_method/Γ_ctx; **not** parthood; keep them out of `E` (see § 4.1 A.15 and Part B.1.5).\n* `MemberOf` — **non‑mereological** collective membership; model in Γ_collective (B.1.7), **not** in `E` (**see § 9**).\n * `RepresentationOf`, `MapsTo`, `Implements` — these are **mappings**, not parthood; model them at the value level (A.15) or as `U.Interaction` between holons.\n* `RoleBearerOf` — links a `U.System` to a `U.Role`; **not** parthood (see A.12, A.15).\n* Any “is‑a” (`subClassOf`) taxonomic relation — orthogonal to parthood.\n\n\n#### B.1.1:4.3 - Minimal axioms & type guards per relation\n\n| Relation             | Axioms (informal)                                                 | Guards / When to use                                                                                               |\n| -------------------- | ----------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------ |\n| **ComponentOf**      | anti‑symmetric; transitive; acyclic                               | Physical assemblies; interfaces compose via BIC (B.1.2). Do **not** use for collections or pipelines.              |\n| **ConstituentOf**    | anti‑symmetric; transitive; acyclic                               | Conceptual or formal wholes (papers, proofs, specifications). Do **not** use for material parts.                   |\n| **MemberOf** (**outside `V_rel`**) | not transitive; anti‑symmetric (w\\.r.t. same collection); acyclic | Sets/teams/libraries; the whole is a *collective* holon. **Not admissible in `E`**; model via **Γ_collective (B.1.7)**. Use `PortionOf` for homogeneous stocks. |\n| **PortionOf**        | anti‑symmetric; additive; acyclic                                 | Quantitative partitions of a *homogeneous* carrier (mass, volume, bytes). Requires an **extensive** attribute.     |\n| **PhaseOf**          | anti‑symmetric; covers a timeline; acyclic                        | Time‑slices of the *same* carrier identity. Use only with explicit carrier and non‑overlapping intervals.          |\n\n> **Carrier identity for `PhaseOf`.** The “same thing across phases” must be explicit (e.g., *this* frame across heat/dwell/quench; *this* theory across revisions). If identity changes, you are modelling a **Transformer** creating a **new** holon (A.12) — not a phase.\n\n\n#### B.1.1:4.4 - Selection guide (didactic, normative in spirit)\n\nUse this **one‑page decision** to pick the edge correctly:\n\n1. **Is it a part–whole relation at all?**\n   If it is mapping, influence, or reference → **not** parthood. Use `U.Interaction` or value‑level links (A.15).\n\n2. **Is it physical vs. conceptual composition?**\n   Physical assembly → **ComponentOf**.\n   Conceptual/content inclusion → **ConstituentOf**.\n\n3. **Is it a collection?**\n   If the “whole” is a collection/collective → **MemberOf** **(outside `E`, route to Γ_collective (B.1.7))**.\n   *Note:* a team’s *members* are `MemberOf` (**outside `E`**); the team’s *tools* are likely `ComponentOf`.\n\n4. **Is it order‑sensitive execution?**\n   If step order changes semantics → **route to A.15 (ordered relations)** and aggregate with **Γ_ctx / Γ_method**.\n   Do **not** encode order as parthood in this section.\n\n5. **Is it a quantitative fraction of a homogeneous stock?**\n   If yes → **PortionOf** (requires an extensive attribute; use in Γ\\_sys / Γ\\_work).\n\n6. **Is it the *same* carrier across time?**\n   If yes → **PhaseOf** (then aggregate with Γ\\_time / Γ\\_work).\n\n> **Common anti‑patterns and the fix**\n> • Using **MemberOf** for material stocks → replace with **PortionOf**.\n> • Drawing cross‑boundary “parts” → replace edge with **U.Interaction** plus `ComponentOf` *inside* each holon.\n> • Using **ConstituentOf** for a module cage or bracket → that is **ComponentOf**.\n> • Treating representation (file ↔ thing) as parthood → keep as value‑level mapping (A.15), not in `D`.\n\n#### B.1.1:4.5 - **Γ_m (Compose‑CAL)** — structural aggregators & trace shape\n\n**Purpose.** Provide a **minimal constructional generator** for **structural mereology** that keeps the kernel small (C-5), aligns with **A.14** (Portions/Phases/Components discipline), and feeds Working-Model layer publication in LOG without importing tooling or notations. \n\n**Operators (aggregators).**\n\nΓ_m.sum(parts : Set[U.Entity])       → W : U.Holon\n  // for each p ∈ parts assert internal U.KernelPartOf(p, W)\n\nΓ_m.set(elems : Multiset[U.Entity])  → C : U.Holon\n  // for each e ∈ elems assert internal U.KernelPartOf(e, C)\n  // outward **MemberOf** remains a non‑mereological signal per A.14 (does not build holarchies)\n\nΓ_m.slice(ent : U.Entity, facet : U.Facet) → S : U.Holon\n  // assert internal U.KernelPartOf(S, ent) and record facet label\n\n\n**Trace (conceptual, notation‑independent).**  \n`Trace = ⟨ op ∈ {sum, set, slice}, inputs, output, notes ⟩`  \nNotes capture boundary tags (A.14), scope (`design|run`), and any independence declarations used by the Quintet proofs (below).\n\n**Invariant footprint on Γ_m traces (inherits B.1 Quintet).**\n* **IDEM** — singleton fold returns the part unchanged.  \n* **COMM/LOC** — results are invariant under re‑order and local factorisation given an independence declaration (IND‑LOC).  \n* **WLNK** — aggregate cannot exceed the weakest limiting attribute among parts; synergy escalates via **B.2 Meta‑Holon Transition**.  \n* **MONO** — improving a part on a monotone characteristic cannot worsen the whole, ceteris paribus.\n\n**Exclusions and routing (A.15/A.14).**  \nNo `parallel` or `temporalSlice` constructor is introduced here; **sequence/parallelism** live in `Γ_ctx/Γ_method`, and **temporal parts** in `Γ_time`. This preserves the firewall between structure, order and time mandated by A.15/A.14.\n\n**Internal proof relation.**  \n`U.KernelPartOf` names the **constructional edges inside traces**; it is not part of the public `V_rel` and appears only in the trace/proof narrative (definitional didactic status).\n\n#### B.1.1:4.6 - Scope and boundary rules (make graphs foldable)\n\n1. **Single temporal scope:** all nodes in `D` share `design` **or** `run`. No mixing (“chimera” graphs are invalid).\n2. **Declared boundary:** every holon in `D` has a `U.Boundary`; any cross‑holon influence must be an explicit `U.Interaction`, not parthood.\n3. **Acyclicity:** if a cycle is detected, either (a) refactor (e.g., split a collective from an assembly), or (b) escalate to **Meta‑Holon Transition** (B.2) if a new “whole” with novel properties is intended.\n4. **Order & time routing:** do **not** encode sequence or history with structural edges; route to Γ\\_ctx / Γ\\_method / Γ\\_time explicitly.\n5. **Resource routing:** do **not** encode costs with structural edges; route to Γ\\_work (B.1.6) across declared boundaries.\n\n#### B.1.1:4.7 - What “Proofs” mean here (preview of Part 2)\n\nEach Γ flavour (Γ\\_sys / Γ\\_epist / Γ\\_method / Γ\\_time / Γ\\_work) **must** attach a small, reusable **Proof Kit** showing the Quintet on the given `D`:\n\n* **IDEM**: singleton fold = identity.\n* **COMM/LOC**: independence conditions + invariance under local reorder/factorisation.\n* **WLNK**: weakest‑link bound (e.g., critical input caps, weakest claim).\n* **MONO**: explicit monotone characteristics (what “cannot get worse” means here).\n",
        "b.1.1:5___didactic_mini‑examples": "### B.1.1:5 - Didactic mini‑examples\n\n* **System (assembly):** a motor **ComponentOf** a chassis; wiring harness **ComponentOf** the motor; a *crew* **MemberOf** a team holon (the crew is not a component of the chassis).\n* **Episteme (paper):** a lemma **ConstituentOf** a proof; appendices **ConstituentOf** the paper; three datasets **MemberOf** a curated collection; version v2 **PhaseOf** the *same* model.\n",
        "b.1.1:6___the_proof_kit_(ready‑made_templates_for_γ_on_d)": "### B.1.1:6 - The Proof Kit (ready‑made templates for Γ on D)\n\nThis section provides **small, reusable proof obligations** you attach to a `DependencyGraph D` when invoking any Γ‑flavour. Each obligation is minimal—just enough to guarantee the **Invariant Quintet** for the stated scope and edge set.\n\n#### B.1.1:6.1 - Independence declaration (for COMM/LOC)\n\n> **Obligation IND‑LOC.**\n> Provide a **partition of D** into subgraphs `{Dᵢ}` such that:\n>\n> 1. Their **node sets** are disjoint (no shared holon instances).\n> 2. Their **boundaries** are disjoint (no shared ports) or any shared internal stock is **lifted** to the parent boundary in notes.\n> 3. No edge in `E` crosses partitions except via explicit `U.Interaction` (not parthood).\n\n**Claim:** Under IND‑LOC, Γ’s fold result is **invariant to local fold order** within and across `{Dᵢ}`.\n\n#### B.1.1:6.2 - Weakest‑link cutset (WLNK)\n\n> **Obligation WLNK‑CUT.**\n> Enumerate a **critical set** `C ⊆ V ∪ E` (nodes/edges) such that **failure** (or insufficiency) of any element of `C` makes the aggregation invalid or unsafe in the chosen Γ‑flavour.\n\n**Claim:** For the target property, the result for the whole is bounded by the **minimum** (or tightest cap) across `C`.\nExamples:\n• Γ\\_sys → tensile strength cutset along a load path;\n• Γ\\_epist → weakest supported premise in a proof spine;\n• Γ\\_work → availability caps for required inputs across the boundary.\n\n#### B.1.1:6.3 - Monotone coordinates (MONO)\n\n> **Obligation MONO‑AX.**\n> Declare the **monotone characteristics** (attributes whose improvement cannot worsen the whole) **for this call**. Specify *how* “improvement” is recognized.\n\n**Claim:** If only monotone characteristics change in the direction of improvement while all else is fixed, the aggregate’s target value cannot degrade.\n\nExamples:\n• Γ\\_sys → increased component reliability, tighter tolerance;\n• Γ\\_epist → stronger evidence, higher formality;\n• Γ\\_method → reduced step duration, stronger step assurance;\n• Γ\\_time → added non‑overlapping coverage;\n• Γ\\_work → higher yield η, reduced dissipation.\n\n#### B.1.1:6.4 - Idempotence witness (IDEM)\n\n> **Obligation IDEM‑WIT.**\n> Provide the **singleton** case: a subgraph `D₁` with one node and no admissible composition edges.\n\n**Claim:** Γ(D₁) returns that node’s property unchanged.\n\n#### B.1.1:6.5 - Scope & boundary attestations\n\n> **Obligation SCOPE‑1.**\n> Affirm `DesignRunTag(D) ∈ {design, run}` and that all nodes share it.\n> **Obligation BOUND‑1.**\n> List the **U.Boundary** for each top‑level holon in `V` and record any **U.Interaction** edges that are relevant but not part of `E` (to show cross‑boundary influences were not mis‑typed as parthood).\n\n\n#### B.1.1:6.6 - Flavour‑specific summary table\n\n| Γ‑flavour            | Independence (IND‑LOC)                                             | WLNK‑CUT (what is “critical”)                         | MONO‑AX (what cannot make worse)                    | IDEM‑WIT                      | Notes                                                         |\n| -------------------- | ------------------------------------------------------------------ | ----------------------------------------------------- | --------------------------------------------------- | ----------------------------- | ------------------------------------------------------------- |\n| **Γ\\_sys**          | Disjoint subassemblies with disjoint interfaces (BIC respected)    | Structural cutset on load/flow paths                  | ↑ component reliability/capacity; tighter bounds    | Single module                 | Use **BIC** to keep interfaces explicit.                      |\n| **Γ\\_epist**         | Independent argument subgraphs; no premise reuse across partitions | Weakest premise/claim on entailment spine             | ↑ formality; ↑ reliability of sources; ↑ congruence | Single section/lemma          | Apply `Φ(CL_min)` penalty only where mappings/links are weak. |\n| **Γ\\_ctx / Γ\\_method** | Parallel branches truly independent (no hidden state)              | Slowest/least reliable step on the critical path      | ↓ duration; ↑ step assurance; ↑ join soundness      | Single step                   | COMM relaxed to partial orders (NC‑1..3).                     |\n| **Γ\\_time**          | Non‑overlapping time slices; same carrier identity                 | Missing slice creates a gap (temporal WLNK)           | ↑ coverage; ↑ timestamp precision                   | Single slice                  | Phases must cover the window without overlap.                 |\n| **Γ\\_work**          | Disjoint boundary partitions; shared stocks lifted to parent       | Availability caps for required inputs across boundary | ↑ yield; ↓ dissipation; ↑ availability              | Single resource with no delta | Keep **Boundary Ledger** with basis and time window.          |\n\nAttach the row(s) you use as the **Proof Kit** to the Γ call record.\n\n",
        "archetypal_grounding": "### B.1.1:7 - Archetypal grounding (worked micro‑examples)\n\n> Each row is self‑contained and can be used as a template.\n\n#### B.1.1:7.1 - U.System (assembly & production)\n\n| Aspect           | Example                                                                                                                                                    |\n| ---------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **Graph**        | `Motor ComponentOf Chassis`; `Harness ComponentOf Motor`; *(for method demo only, outside `D`)* `QC SerialStepOf Seal`; all nodes scope=`run`; BIC declares ports for power, data. |\n| **Independence** | Two subassemblies: `{Chassis, Motor, Harness}` and `{Cabin}` with disjoint interfaces.                                                                     |\n| **WLNK‑CUT**     | Tensile path through front mount + harness connector; weakest tensile rating caps assembly load rating.                                                    |\n| **MONO‑AX**      | Improving mount alloy or connector strain relief cannot reduce system load rating.                                                                         |\n| **IDEM‑WIT**     | Standalone chassis as singleton: Γ\\_sys returns chassis unchanged.                                                                                        |\n| **Routing**      | `SerialStepOf` belongs to Γ\\_method; Γ\\_sys ignores order and composes structure; Γ\\_work separately composes energy/material costs through boundary ports. |\n\n#### B.1.1:7.2 - U.Episteme (paper & dataset)\n\n| Aspect           | Example                                                                                                                                               |\n| ---------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **Graph**        | `Lemma1 ConstituentOf ProofA`; `DatasetX MemberOf CorpusQ`; `ProofA ConstituentOf PaperP`; scope=`design`.                                            |\n| **Independence** | Two argument branches that do not reuse premises: `{Lemma1 → ProofA}` and `{Background → Discussion}`.                                                |\n| **WLNK‑CUT**     | The least supported premise in the entailment path to the main theorem.                                                                               |\n| **MONO‑AX**      | Replacing a weak premise with a stronger one or raising CL of a mapping cannot reduce overall credibility.                                            |\n| **IDEM‑WIT**     | Single lemma as singleton: Γ\\_epist returns it unchanged.                                                                                             |\n| **Routing**      | `MemberOf` for CorpusQ is collection structure; not used to average “truth”. Γ\\_epist aggregates via min/penalty and produces a SCR for sources. |\n\n",
        "conformance_checklist": "### B.1.1:8 - Conformance Checklist (normative checklist)\n\n| ID             | Requirement                                                                                                                                                | Purpose                             |\n| -------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------- |\n| **CC‑B1.1.1**  | `D` **SHALL** be acyclic (DAG).                                                                                                                            | Ensure foldability.                 |\n| **CC‑B1.1.2**  | All nodes in `D` **SHALL** share a single `DesignRunTag ∈ {design, run}`.                                                                                 | Ban design/run chimeras.            |\n| **CC‑B1.1.3**  | All edges in `E` **SHALL** belong to the **normative `V_rel`** (**ComponentOf, ConstituentOf, PortionOf, PhaseOf** only). | Keep mereology crisp and finite. |\n| **CC‑B1.1.4**  | Cross‑holon influences **SHALL** be modelled as `U.Interaction`, **NOT** parthood.                                                                         | Preserve locality (LOC).            |\n| **CC‑B1.1.5**  | Every top‑level holon **SHALL** declare a `U.Boundary`; if Γ\\_work will be used, a Boundary Ledger **SHALL** be produced.                                  | Make results comparable/auditable.  |\n| **CC‑B1.1.6**  | If COMM/LOC is claimed, an **IND‑LOC** independence declaration **SHALL** be attached.                                                                     | Make locality explicit.             |\n| **CC‑B1.1.7**  | A **WLNK‑CUT** set **SHALL** be stated for the chosen Γ‑flavour.                                                                                           | Make caps explicit; avoid optimism. |\n| **CC‑B1.1.8**  | **MONO‑AX** **SHALL** enumerate the monotone characteristics used by the Γ‑flavour.                                                                                   | Avoid hidden regress.               |\n| **CC‑B1.1.9**  | A **IDEM‑WIT** singleton case **SHALL** be shown or referenced.                                                                                            | Ground identity.                    |\n| **CC‑B1.1.10** | Order/time/resource **SHALL NOT** be encoded via structural edges; they must be routed to Γ\\_ctx/Γ\\_method, Γ\\_time, Γ\\_work respectively.                   | Maintain A.15 Strict Distinction.   |\n| **CC‑B1.1.11** | If a cycle or a locality violation persists, the modeller **SHALL** either refactor or declare a **Meta‑Holon Transition (B.2)**.                          | Make emergence explicit.            |\n| **CC‑B1.1.12** | Any mapping edges (`RepresentationOf`, `Implements`, etc.) **SHALL** be kept outside `E` (value‑level), or recast as `U.Interaction` if cross‑boundary.    | Eliminate category errors.          |\n\n",
        "b.1.1:9___anti‑pattern_diagnostics_(before_→_after)": "### B.1.1:9 - Anti‑pattern diagnostics (before → after)\n\n| Anti‑pattern                     | Symptom                                                        | Replace with                                                                                                                                            |\n| -------------------------------- | -------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **Collection as stock**          | `Cell_i MemberOf Battery` then summing “capacity” via MemberOf | Use `PortionOf` for capacity partitions; use `ComponentOf` for physical pack assembly; keep MemberOf only for the *set of cells* as a collection holon. |\n| **External supplier as part**    | `PowerGrid ComponentOf Plant`                                  | Model `PowerGrid` as an external holon with `U.Interaction` at the plant boundary; keep plant internals as `ComponentOf`.                               |\n| **Order encoded as structure**   | `Step2 ComponentOf Step1`                                      | Use `SerialStepOf`/`ParallelFactorOf` and Γ\\_method.                                                                                                      |\n| **History encoded as structure** | `v2 ComponentOf v1`                                            | Use `PhaseOf` for time slices of the *same* carrier, or a Transformer creating a new holon (A.12) if identity changes.                                  |\n| **Mapping as parthood**          | `DigitalTwin ConstituentOf Turbine`                            | Keep the twin as a separate holon; link by `U.Interaction` and value‑level mapping; do not use parthood.                                                |\n| **Design/run chimera**           | Mix of CAD nodes and telemetry nodes                           | Split into two graphs (`design` vs `run`) and connect via a Transformer role if needed.                                                                 |\n\n",
        "consequences": "### B.1.1:10 - Consequences\n\n**Benefits**\n\n* **Predictable composition:** Γ‑folds are reproducible and auditable across domains.\n* **Cross‑scale clarity:** Resource and time additivity are preserved by routing to Γ\\_work and Γ\\_time.\n* **Safer modelling:** WLNK cutsets surface true constraints; emergence is not “smuggled in”.\n* **Didactic simplicity:** A small, fixed edge vocabulary makes reviews and onboarding faster.\n\n**Trade‑offs / mitigations**\n\n* **Up‑front discipline:** Declaring boundaries and independence requires effort.\n  *Mitigation:* reuse the Proof Kit templates; keep small, local graphs and compose.\n* **Refactoring legacy edges:** Replacing “generic part‑of” with precise relations can be noisy.\n  *Mitigation:* use the decision guide (4.4) and anti‑pattern table (9) as a script.\n\n",
        "rationale": "### B.1.1:11 - Rationale (informative)\n\nThis pattern operationalizes **A.14 (Mereology Extension)** and **A.15 (Strict Distinction)** for the universal algebra of B.1. +… By limiting `E` to **four** well‑formed **mereological** relations, we prevent the three recurrent category errors: **mapping≠parthood**, **order/time≠structure**, **collection≠stock**. The Proof Kit converts the Quintet from abstract slogans into concrete obligations that engineers can check in everyday models. Γ‑flavours then remain simple and domain‑appropriate, while proofs remain small and reusable.\n\n",
        "relations": "### B.1.1:12 - Relations\n\n* **Builds on:** A.1 **Holonic Foundation**; A.14 **Mereology Extension**; A.15 **Strict Distinction**; A.12 **Transformer Principle**.\n* **Constrained by:** B.1 **Universal Γ** and the **Invariant Quintet**.\n* **Used by:** B.1.2 **Γ\\_sys**, B.1.3 **Γ\\_epist**, B.1.4 **Γ\\_ctx/Γ\\_time**, B.1.5 **Γ\\_method**, B.1.6 **Γ\\_work**.\n* **Triggers:** B.2 **Meta‑Holon Transition (MHT): Recognizing Emergence and Re‑identifying Wholes** when cycles or WLNK violations indicate a new emergent whole.\n* **Feeds:** B.3 **Trust & Assurance Calculus (F–G–R with Congruence)** via explicit declaration of monotone characteristics and provenance.\n\n\n> **One‑page takeaway.**\n> Keep `D` a **DAG**, pick edges from **four** mereological relations, route **order/time/cost** to their Γ‑flavours, and attach the **four Proof Kit obligations** (IND‑LOC, WLNK‑CUT, MONO‑AX, IDEM‑WIT) with scope/boundary notes.\n> Do this, and the Quintet holds with minimal fuss.\n> ",
        "b.1.1:end": "### B.1.1:End\n"
      },
      "content": "### B.1.1:End\n",
      "metadata": {},
      "part": "B",
      "cluster": null
    },
    {
      "id": "B.1.2",
      "title": "System‑specific Aggregation Γ\\_sys",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## B.1.2 - System‑specific Aggregation Γ\\_sys\n\n**► decided‑by: A.14 Advanced Mereology**\n**A.14 compliance —** Treat **PortionOf** as Σ‑additive stocks; **ComponentOf** must respect boundary integration (BIC); **PhaseOf** is *not* aggregated here (handled by Γ\\_time); mapping/representations are *not* parthood.\n\n#### B.1.2:1 - Purpose\n\n`Γ\\_sys` is the **default flavour of the universal aggregation operator** for everything that engineers can touch, weigh or wire‑up: bridges, battery packs, data‑centre racks, container clusters.\nIt translates the abstract Invariant Quintet into three **physically meaningful fold rules**—*additive, limiting, boolean*—and a **Boundary‑Inheritance Standard** (BIC) that keeps external interfaces tidy. Together they guarantee that holons built with `Γ\\_sys` obey conservation laws, expose a clean API surface and pass safety audits without manual patching.\n\n\n#### B.1.2:2 - Context\n\nKernel § 6 defines `U.System` and states that only a **Calculus** may own an aggregation operator. *Sys‑CAL* (Part C.1) exports `Γ\\_sys` as its single builder; other CALs (KD‑CAL, Method‑CAL …) reuse the same quintet but swap in domain rules.\nDraft 20 Jul 25 already lists default fold policies (Σ, min, ∨/∧) and a cut‑stable axiom; this pattern turns those snippets into a teachable Standard for day‑to‑day system design.\n\n\n#### B.1.2:3 - Problem (seen on real projects)\n\n| Field failure                                                           | Algebraic root cause                                                 |\n| ----------------------------------------------------------------------- | -------------------------------------------------------------------- |\n| **“Phantom megawatts”** — energy sums higher than fuel input            | Temperatures averaged, masses summed; operator ignored conservation. |\n| **Interface Medusa** — hundreds of dangling ports after integration     | No rule for boundary promotion vs encapsulation.                     |\n| **Safety inversion** — upgraded actuator lowered SIL rating of the skid | Intensive property (safety) aggregated by average, not min.          |\n| **Audit hairball** — inspector cannot trace which crane load went where | Boundary cuts not stable; provenance leaks.                          |\n\nAll four break Pillars *Cross‑Scale Consistency* and *State Explicitness*.\n\n\n#### B.1.2:4 - Forces\n\n| Force                     | Pull                          | Push                                                         |\n| ------------------------- | ----------------------------- | ------------------------------------------------------------ |\n| **Physical plausibility** | Sum masses, conserve energy   | **Abstraction** — keep rules domain‑agnostic                 |\n| **Interface clarity**     | Present one clean API         | **Fidelity** — expose every critical port                    |\n| **Safety conservatism**   | Take worst‑case rating        | **Performance** — allow redundancy gains (via MHT later)     |\n| **Parallel build**        | Shard assembly, cache results | **Boundary realism** — stress must still balance across cuts |\n\n\n#### B.1.2:5 - Solution (conceptual core)\n\n##### B.1.2:5.1 - Operator signature\n\n```\nΓ\\_sys : (D : DependencyGraph\\[U.System\\], T : U.TransformerRole (plays `AssemblerRole`)) → E\\_eff : U.System\n```\n\n* **D** – finite acyclic graph whose nodes share one temporal scope and obey the four DG rules (Pattern B .1.1).\n* **T** – physically real external system playing `TransformerRole` (e.g., crane, welding rig).\n\n##### B.1.2:5.2 - Three attribute classes\n\n| Class                    | Fold rule                                  | Typical examples                        | Invariants touched       |\n| ------------------------ | ------------------------------------------ | --------------------------------------- | ------------------------ |\n| **Extensive**            | **Σ** (sum)                                | Mass, energy, cost                      | IDEM - COMM - LOC - MONO |\n| **Intensive / Risk**     | **min** (weakest‑link)                     | Temperature limit, SIL, encryption bits | WLNK - MONO              |\n| **Boolean / Capability** | **∨ / ∧** (OR for vuln, AND for must‑hold) | CVE exposure, “Has EmergencyStop”       | WLNK                     |\n\n*Rule of thumb for managers:* *If it adds up in your spreadsheet → Σ; if it caps the system → min; if it is yes/no → logic gate*. Defaults match kernel table “Additive flow / Capacity / Boolean capability” .\n\n##### B.1.2:5.3 - Boundary‑Inheritance Standard (BIC)\n\nFor **every external interaction** of every part, `Γ\\_sys` forces a deliberate choice:\n\n1. **Promote** — port becomes part of the new system boundary.\n2. **Forward** — port remains on the child but is namespaced by the parent.\n3. **Encapsulate** — port becomes internal and disappears from public view.\n\nBIC is the antidote to *Interface Medusa*: it prevents silent loss of obligations or explosion of unmanaged endpoints.\n\n##### B.1.2:5.4 - Cut‑Stable Boundary Axiom (reminder)\n\n> Given any declared boundary 𝔅, `Γ\\_sys(D,C)` **MUST** leave every across‑𝔅 interaction either identical or transformed by a rule that still satisfies the Quintet.\n\n#### B.1.2:6 - Step‑by‑Step Aggregation Recipe\n\n> **Audience:** lead engineer planning a multi‑team build; QA manager preparing an audit; analyst running a quick what‑if.\n> **Goal:** fold a ready Dependency Graph into one coherent system in **five repeatable moves**.\n\n| Step                             | What you do                                                                                                                  | Why it matters                                                                    |\n| -------------------------------- | ---------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------- |\n| **1 - Verify the graph**         | Run Pattern B .1.1 checklist (acyclic, typed edges, same scope, boundary tags).                                              | Avoid paradoxes before they snowball.                                             |\n| **2 - Label attributes**         | For every property in every node, mark it **Extensive**, **Intensive**, or **Boolean**. Defaults are in Sys‑CAL cheat‑sheet. | The fold rule depends on this label.                                              |\n| **3 - Decide the BIC**           | For each external port, pick **Promote / Forward / Encapsulate**. Record choice in the interface table.                      | Keeps APIs intentional and auditable.                                             |\n| **4 - Execute Γ\\_sys** | *Extensive* → parallel Σ; *Intensive* → propagate min; *Boolean* → ∧/∨ logic.                                                | Implements the Invariant Quintet.                                                 |\n| **5 - Run Cut‑Stable test**      | For each declared boundary 𝔅, compare across‑𝔅 interactions before & after fold.                                           | Confirms that sharding or outsourced work didn’t shift loads or responsibilities. |\n\nIf the min rule is exceeded by design (e.g., triple redundancy boosts SIL beyond any part), stop here and initiate **Meta‑Holon Transition** (Pattern B .2) to formalise emergence.\n\n\n#### B.1.2:7 - Worked Example — Battery‑Electric Bus Pack (2025 model year)\n\n| Step                | Snapshot                                                                                                                       |\n| ------------------- | ------------------------------------------------------------------------------------------------------------------------------ |\n| **Graph**           | 16 modules → 4 strings → pack. Edges `ComponentOf`. All nodes `scope=design`.                                                  |\n| **Attribute label** | *Extensive*: energy (kWh), cost; *Intensive*: cell voltage limit, fire rating (SIL 2); *Boolean*: “Has self‑heating”.          |\n| **BIC decisions**   | Main DC output ‑ Promote; per‑string fuse access ‑ Forward; cell balancing ports ‑ Encapsulate.                                |\n| **Fold**            | Σ energy = 628 kWh; min voltage limit = 4.25 V; ∧ self‑heating = true.                                                         |\n| **Cut‑Stable**      | Across‑string current same pre/post fold. Pass.                                                                                |\n| **Outcome**         | Pack spec delivered to vehicle OEM; audit shows WLNK bound 4.25 V, MONO intact; financial model reads energy Σ for range calc. |\n\n\n#### B.1.2:8 - Conformance Checklist (author‑facing)\n\n| ID           | Question                                          | Pass if…                           |\n| ------------ | ------------------------------------------------- | ---------------------------------- |\n| **CHK‑GC‑1** | All properties classified?                        | No “unknown” label remains.        |\n| **CHK‑GC‑2** | Any property violate its fold rule?               | None; else declare MHT.            |\n| **CHK‑GC‑3** | BIC table complete?                               | Every external port accounted for. |\n| **CHK‑GC‑4** | Cut‑Stable test green on all declared boundaries? | Yes.                               |\n| **CHK‑GC‑5** | Provenance hash stamped?                          | `E_eff.meta.provenance` populated. |\n\nFailing a line means the operator must **refactor the graph or escalate to Meta‑Holon** before reuse.\n\n\n#### B.1.2:9 - Consequences\n\n| Benefit for project leadership                                                                 | Secondary effect                                      |\n| ---------------------------------------------------------------------------------------------- | ----------------------------------------------------- |\n| **Plausible mass‑energy books** — no “phantom capacity” during tender negotiations.            | Vendor bids align faster; fewer change orders.        |\n| **Single‑page interface sheet** — the BIC doubles as hand‑over Standard to next tier supplier. | Interface churn caught early; legal exposure shrinks. |\n| **Safety‑first roll‑up** — weakest‑link bound surfaces brittle parts immediately.              | QA budget aimed at right module; no gold‑plating.     |\n| **Seamless parallel builds** — COMM + LOC proven once, reused by every subStandardor.          | Integration rehearsals shortened by weeks.            |\n\n\n#### B.1.2:10 - Rationale (link to modern practice)\n\n* **Model‑Based Systems Engineering (MBSE 2023‑2025):** Tools like Cameo Systems Modeler automated Σ/min logic via “Property Kind” stereotypes—Γ\\_sys formalises the same trick.\n* **Safety audits:** ISO 26262‑2 Ed 3 explicitly adopts “minimum of ASIL ratings” rule; our min fold embeds it by design.\n* **Interface control:** Aerospace ICDs (NASA‑7120.5E updates 2024) require a promotion/forward/encapsulate decision tree identical to BIC.\n* **Cloud operations:** Kubernetes 1.30 resource quotas implement additive CPU/memory and min PodDisruptionBudget—industrial proof that the schema scales.\n\nReal‑world convergence across steel, silicon and software shows the rules are not theory nice‑to‑haves; they are what successful projects already do—Γ\\_sys just makes it explicit, automatic and auditable.\n\n\n#### B.1.2:11 - Relations\n\n* **Builds on:** Dependency Graph (B .1.1); Transformer Principle (A.3).\n* **Enables:** Meta‑Holon Transition (B .2); Calculus of Trust (B .3).\n* **Refined by:** Γ<sub>epist</sub> (B .1.3) for knowledge artefacts; Γ<sub>time</sub> / Γ<sub>ctx</sub> (B .1.4) for temporal or context‑sensitive domains.\n* **Exemplifies:** Pillars P‑8 Cross‑Scale Consistency, P‑9 State Explicitness.\n\n> **Take‑away for engineering managers:** *“Classify, Standard, fold—then sleep easy knowing the numbers and the interfaces will still match tomorrow.”*\n",
        "b.1.2:end": "### B.1.2:End\n"
      },
      "content": "### B.1.2:End\n",
      "metadata": {},
      "part": "B",
      "cluster": null
    },
    {
      "id": "B.1.3",
      "title": "Γ_epist - Knowledge‑Specific Aggregation",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## B.1.3 - Γ_epist - Knowledge‑Specific Aggregation\n\n> **► decided‑by: A.14 Advanced Mereology**\n**A.14 compliance —** Use **ConstituentOf** for semantic parts; **PortionOf** only for quantitative splits of texts/data with declared μ (token/byte, etc.); **PhaseOf** for versions/revisions of MethodDescription/documents; no **ComponentOf** here.\n\n> **Plain‑English headline.**\n> **Γ\\_epist** composes **epistemic holons** (claims, models, datasets, arguments) into a **single episteme** while preserving **provenance**, applying **conservative trust bounds** (B.3 F/G/R), and penalizing **poor conceptual fit** via **congruence levels (CL)**. It is **not** a physical sum; it is a **semantic and evidential fold**.\n",
        "problem": "### B.1.3:2 - Problem\n\nNaive aggregation of knowledge holons causes recurring failures:\n\n1. **Trust inflation by averaging.** Averaging confidences of conflicting claims creates a falsely “reliable” whole; violates **WLNK** and **B.3** conservatism.\n2. **Provenance erasure.** Merges that drop sources, methods, or links break **A.10 Evidence Graph Referring** and make results unauditable.\n3. **Semantic drift.** Folding across mismatched concepts without explicit **mappings** (and their **CL**) yields incoherent composites that look formal but mean nothing.\n4. **Order blindness.** Arguments with essential **dependency order** (premise ⇒ lemma ⇒ conclusion) are treated as sets; non‑commutativity is lost and results become non‑reproducible.\n5. **Context chimeras.** Combining items across **bounded contexts** (different vocabularies/units/policies) without a **Context Reframe** (B.2) silently corrupts claims and inflates **R**.\n6. **Category errors.** Importing **Γ\\_sys** rules (e.g., “sum truth,” “avg formality”) into knowledge composition produces physically sounding but epistemically nonsensical models.\n\n",
        "forces": "### B.1.3:3 - Forces\n\n| Force                                      | Tension                                                                                                                      |\n| ------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------- |\n| **Conservatism vs. Synthesis**             | Keep **reliability** bounded by the weakest supported link ↔ allow genuine explanatory integration when it actually emerges. |\n| **Universality vs. Domain nuance**         | One operator across math, science, engineering specs ↔ domain‑specific semantics and evidence patterns differ.               |\n| **Provenance fidelity vs. Cognitive load** | Keep the **full trail** of sources and methods ↔ avoid overwhelming authors with bookkeeping.                                |\n| **Order/time discipline vs. Flow**         | Respect argument **order** and version **time** ↔ keep composition usable for day‑to‑day synthesis.                          |\n| **Parsimony vs. Fit**                      | Small rule set (A.11) ↔ explicit **congruence** penalties and **context** rebasing when needed.                              |\n\n",
        "solution": "### B.1.3:4 - Solution — **Terms, operator family, invariant Standard, core rules**\n\n#### B.1.3:4.1 - Terms (didactic recap)\n\n* **U.Episteme** — a knowledge holon. Internally we use a didactic triangle:\n  **Object** (what it is about), **Concept** (theory/model/claim structure), **Symbol** (SCR carriers: text, code, figures, datasets).\n* **Evidence/Provenance Graph** — edges like **evidences**, **derivesFrom**, **usesMethod**, **isMeasuredBy** with anchors (A.10).\n* **Mapping edge** — a typed relation between conceptual vocabularies (e.g., ontology alignment, unit conversion) with a **CL** score (0…3/4 per A.15/B.3 convention).\n* **SCR** — a `U.SCR` that lists all symbol carriers included in the aggregate; **never dropped**.\n* **Bounded context** — a modelling Standard (vocabulary/units/policy). Crossing it requires **Context Reframe** (B.2) or explicit mappings with CL.\n\n> **Didactic reminders.**\n> • Knowledge does **not** “act.” Transformers (A.12) **use** knowledge.\n> • **MemberOf** creates **collections**; it is not a semantic argument link. Use **ConstituentOf** for logical/evidential composition.\n> • **PhaseOf** is for **versions** of the same episteme; if identity, boundary, or context re‑anchor, declare **MHT**.\n\n\n#### B.1.3:4.2 - The operator family (companion flavours)\n\nTo keep **design vs run** clean (A.15), Γ\\_epist has two companion flavours that share the same algebra but serve different moments:\n\n1. **Synthesis (design‑time)** — fold epistemes into a **draft aggregate**\n\n```\nΓ_epist^synth : ( D_know : DependencyGraph< U.Episteme >,\n                  T      : U.TransformerRole ) → U.Episteme\n```\n\n* **Domain.** `D_know` uses **ConstituentOf**, **UsageOf/ReferenceTo**, **evidences/derivesFrom**, optional **MemberOf** for collections.\n * **Result.** A **composite episteme** whose Object/Concept/Symbol components are assembled; **provenance and SCR are preserved**; F/G/R/CL are provisionally computed for later assurance.   **Gating:** at **M‑mode** only tuple placeholders are required; numeric scoring may be omitted (**\\[M‑0/M‑1]**). At **F‑mode** the tuple **MUST** be computable in‑Context (**\\[F‑\\*,L1+]**).  # [M/F]\n\n2. **Compile (run‑time)** — produce the **released artifact** in a bounded context\n\n```\nΓ_epist^compile : ( E_synth : U.Episteme,\n                    Ctx     : BoundedContext,\n                    T       : U.TransformerRole ) → U.Episteme\n```\n\n* **Domain.** A synthesized episteme and a **target context** (journal, standard, program spec).\n* **Result.** A **context‑anchored** episteme (e.g., published paper/spec) whose **mappings to the context vocabulary** are explicit and carry **CL**; assurance will reference this context baseline (B.3).\n\n**Relationship to Γ\\_ctx / Γ\\_time.**\nIf the knowledge fold explicitly depends on **argument order** (e.g., derivation), the internal fold uses **Γ\\_ctx** for the sequence. If a **temporal storyline** (updates, retractions) is important, use **Γ\\_time** to slice versions; **Γ\\_epist** then composes the **current slice**. If composition yields **new explanatory closure** beyond WLNK/CL, declare **MHT** (B.2).\n\n\n#### B.1.3:4.3 - Invariant Standard (how the Quintet applies; **math by level**)\n\n* **IDEM (Idempotence).** Folding a single episteme returns itself; no accidental “upgrade.”\n* **COMM/LOC (Local commutativity / locality).** For **independent** subgraphs (no logical/evidential dependency), fold order/location is irrelevant; when dependencies exist, **Γ\\_ctx** controls order explicitly.\n* **WLNK (Weakest‑link bound).** Aggregate **Reliability (R)** is bounded by the **weakest supported link** along any justification path, **after** considering the **lowest CL** on mappings used by that path.\n* **MONO (Monotonicity).** Strengthening a part (raising **R** with valid evidence or raising **CL** on a needed mapping) cannot lower aggregate **R**. Adding **contradictory** evidence is **not** an improvement; it triggers conflict handling (below), not MONO.\n\n2. **Reliability fold.** Along any support spine, **R\\_raw = min\\_i R\\_i**; apply congruence penalty Φ(CL\\_min) → **R\\_eff = max(0, R\\_raw − Φ(CL\\_min))**.  *No averaging; weakest‑link.*  \n   **Math by level:**  \n   – **\\[M‑0/M‑1]** allow **ordinal** comparisons only (no arithmetic on R); Φ may be stated qualitatively (“low/med/high”).  \n   – **\\[M‑2/L1]** require numeric Φ table (default in §4.4) and reproducibility tag on empirical edges.  \n   – **\\[F‑\\*,L1/L2]** require formal derivability of the fold rules from LOG‑CAL; constructive mode annotates `proof.kind=constructive`.  # [M/F]\n\n#### B.1.3:4.4 - Core rules for epistemic aggregation (design‑time synthesis)\n\nWhen computing **Γ\\_epist^synth(D\\_know, T)**:\n\n1. **Provenance preservation.**\n   The **provenance/evidence graph** is **unioned with de‑duplication**; every claim in the aggregate remains traceable to its sources and methods. No source, method, or dataset that supports a retained claim may be dropped.\n\n2. **SCR construction.**\n   Build a **U.SCR** that lists all symbol carriers (texts, code, figures, datasets) that materially participate in the aggregate. Provenance nodes must be mappable to SCR entries.\n\n3. **Object alignment.**\n   Determine a **common Object** via domain taxonomy (e.g., **least common ancestor**) or create a `U.CompositeEntity` with explicit **mappings**. Record **CL** for each mapping; **do not** silently merge homonyms.\n\n4. **Concept integration with CL penalty.**\n   Compute provisional **F/G/R** of the aggregate:\n\n   * **F\\_eff** = min(F\\_i) (formality is as strong as the least formal constituent actually used).\n   * **G\\_eff** = function of coverage; typically **monotone** in included scope, capped by weakest definitional fit.\n   * **R\\_eff** = min over justification paths of { R\\_i along the path } **penalized** by the lowest **CL** used by that path: `R_eff := max(0, min_path( min_claimR(path) − Φ(CL_min(path)) ))`, where **Φ** is the normative penalty function defined below.\n      If a mapping with **CL < threshold** is essential to a path, mark the claim **provisional**.\n 5. **Normative Penalty Function Φ (v1.0)**\nThe penalty function `Φ` quantifies the loss of reliability due to poor conceptual alignment between parts.\n\n| Congruence Level `CL_min` | 0 | 1 | 2 | 3 |\n| :--- | :--- | :--- | :--- | :--- |\n| **Penalty Φ(CL_min)** | 1.5 | 1.0 | 0.5 | 0.0 |\n\n+*A domain profile **MAY** provide an alternative table but **MUST** preserve monotonic decrease (a lower `CL` cannot have a smaller penalty). The default values are derived from empirical fits in KD-CAL Bench 0.3.*\n\n 6. **Conflict detection (no averaging).**\n    Detect contradictions (e.g., `p` and `¬p` with overlapping scope). Do **not** average. Either (i) **separate** by context or scope (bounded contexts; Γ\\_time slices), (ii) mark **provisional** with explicit conflict edges, or (iii) if resolution yields **new closure**, consider **MHT**.\n\n7. **Handling of Axiomatic vs. Postulative Epistemes**\n   In alignment with ADR-028, the computation of `R_eff` depends on the episteme's declared `mode`.\n\n*   For an input episteme `E_i` with **`mode: axiomatic`**, empirical `R` is N/A; take `R_i_eff = F_i`. **Tag:** `line=formal`.  # [F‑\\*]\n*   For **`mode: postulative`**, use declared `R_i` with decay; **Tag:** `line=empirical`.  # [M‑1/M‑2/F]\n*   The aggregate `E_eff` **MUST** also declare a mode. If all inputs are `axiomatic`, the output is `axiomatic`. If any input is `postulative`, the output **MUST** be `postulative`.\n*   **Constructive note.** Under **F‑constructive**, equivalence claims use **isomorphism/equivalence** in the chosen UF library; **CL=2** means proof‑reconstructed alignment, not mere model‑theoretic appeal.  # [F‑constructive]\n \n7. **Order‑aware arguments (optional).**\n   If the argument requires premise ordering, embed a **Γ\\_ctx** fold inside Γ\\_epist; record the **OrderSpec** for reproducibility (NC‑1..3).\n   **Gating:** OrderSpec is **recommended** at **M‑1** and **required** at **M‑2/F**.  # [M‑1→F]\n\n8. **No costs here.**\n   Any compute/collection effort is **Γ\\_work**; attach references but do not mix costs into epistemic aggregation.\n\n#### B.1.3:4.5 - Core rules for compilation (run‑time context anchoring)\n\nWhen computing **Γ\\_epist^compile(E\\_synth, Ctx, T)**:\n\n1. **Context bindings.**  # [M‑1+]\n   Map all operative concepts/units/claims into **Ctx**; record mappings and their **CL**. If the rebase changes boundary/objective of the episteme (e.g., from descriptive compendium to explanatory theory with commitments), **declare Context Reframe (MHT)** per B.2.\n\n2. **Assurance baseline (gated).**  \n   Recalculate the **assurance tuple** (B.3) **in Ctx**: F and R may change with formalization and mapping penalties; G is re‑expressed in Ctx’s scope.  \n   **Gating:**  \n* **\\[M‑0]** narrative justification only;  \n* **\\[M‑1]** qualitative tuples allowed;  \n* **\\[M‑2/L1]** numeric tuple required;  \n* **\\[F‑*/L2]** tuple **and** proof obligations on weight/penalty model selection.  # [M/F]\n\n3. **Release SCR.**\n Produce RSCR with carrier hashes; at **L2** require independent re‑hash verification.  # [M‑1/L2]\n\n4. **Order/time hooks.**\n   If the compiled artifact includes an internal derivation, carry the **OrderSpec**; if it codifies a specific **time slice** of evolving knowledge, link back to the **Γ\\_time** slice used.\n",
        "archetypal_grounding": "### B.1.3:5 - Archetypal grounding (worked, didactic)\n\n#### B.1.3:5.1 - Episteme — **Meta‑analysis into a guidance statement**\n\n* **Inputs (U.Episteme):**\n  `E₁` randomized trial (R=0.84, F=3, G=medium), `E₂` observational study (R=0.55, F=2, G=wide), `E₃` mechanistic model (R=0.60, F=3, G=narrow).\n  Mappings: dosage units (mg ↔ IU), outcome definitions (pain scale variants), each with declared **CL** (e.g., unit mapping CL=3, outcome alignment CL=2).\n\n* **Γ\\_epist^synth:**\n\n  * **Provenance preservation:** all study protocols, datasets, analysis scripts listed in the **SCR**.\n  * **Object alignment:** “acute low‑back pain within 6 weeks” via taxonomy LCA; non‑aligned chronic cohorts excluded or mapped with low CL and flagged.\n  * **Concept integration:** compute provisional `R_eff` along each justification path, penalized by \\*\\*Φ(CL\\_min(path))`; aggregate `R\\_eff\\` = min over paths.\n  * **Conflict handling:** `E₂` contradicts `E₁` in a subgroup; kept as **provisional** with explicit conflict edge and scope note (different baseline severity).\n\n* **Γ\\_epist^compile (journal context):**\n  Map outcomes to journal’s required measure, recalc F/G/R with mapping penalties; produce release **SCR** (hashes, versions) and context baseline.\n  Result: “Guidance Statement v1.0” with conservative `R`.\n\n* **Why not averaging?**\n  Averaging would inflate `R` and hide low‑CL outcome mappings; Γ\\_epist enforces pathwise **min** + **CL** penalty.\n\n\n#### B.1.3:5.2 - Episteme — **Safety case from heterogeneous evidence**\n\n* **Inputs:** requirement spec (F=3, R=0.7), hazard analysis (F=2, R=0.6), test logs (F=1, R=0.8), formal proof of controller property (F=3, R=0.9).\n\n* **Γ\\_epist^synth:**\n\n  * Provenance union; **SCR** includes requirements, proof artifact, test datasets.\n  * Concept integration: controller proof applies only under assumptions A; test logs violate A in edge case → **CL** low for mapping “test scenario ≡ proof assumption.”\n  * `R_eff` bounded by the weakest justification path after **Φ(CL\\_min)**; claim on “system‑level safety” marked **provisional** until assumption alignment is demonstrated.\n\n* **Γ\\_epist^compile (certification context):**\n  Context re‑base to regulatory vocabulary; if the re‑base changes objective/boundary (e.g., from internal assurance to public certification), consider **MHT (Context Reframe)** per B.2.\n\n\n#### B.1.3:5.3 - Contrast (didactic)\n\n| Aspect          | **Γ\\_epist (Knowledge)**                                         | **Γ\\_sys (Physical)**                       |\n| --------------- | ---------------------------------------------------------------- | -------------------------------------------- |\n| What is folded? | Claims, models, datasets, arguments                              | Components, materials, assemblies            |\n| Conservatism    | **Pathwise min** of R + penalty **Φ(CL)**                        | WLNK via **weakest part** (strength, rating) |\n| Fit             | **Mappings** with declared **CL**                                | **Interfaces/BIC** compatibility             |\n| Order/time      | Optional **Γ\\_ctx** for argument order; **Γ\\_time** for versions | Γ\\_ctx for workflows; Γ\\_time for phases     |\n| Work/cost       | External in **Γ\\_work** (compute, curation)                      | External in **Γ\\_work** (energy, labour)     |\n\n",
        "b.1.3:6___proof_obligations_(normative)": "### B.1.3:6 - Proof obligations (normative)\n\n**At synthesis (Γ\\_epist^synth):**\n\n1. **PO‑SYN‑PROV.** The **provenance/evidence graph** MUST be preserved (union with de‑duplication); every retained claim is traceable to sources/methods in the **SCR**.\n2. **PO‑SYN‑OBJ.** The **Object** MUST be identified (single subject via LCA or explicit `U.CompositeEntity`) with declared **mappings** and their **CL**.\n3. **PO‑SYN‑CL.** All **mapping edges** that bridge semantics/units MUST carry **CL**; the chosen penalty **Φ** MUST be monotone in CL (lower CL ⇒ higher penalty). Thresholds for marking **provisional** MUST be stated.\n4. **PO‑SYN‑R.** `R_eff` MUST be computed as **min over justification paths** of (claim reliabilities along the path **minus** `Φ(CL_min(path))`). No arithmetic mean is allowed for reliability.\n5. **PO‑SYN‑CONFLICT.** Contradictions MUST be either (i) separated by context/scope, (ii) marked as **provisional** with explicit conflict edges, or (iii) escalated to **MHT** if resolution yields new explanatory closure.\n6. **PO‑SYN‑ORDER.** If order matters, the **OrderSpec** MUST be recorded and Γ\\_ctx **NC‑1..3** (determinism, context hash, partial‑order soundness) MUST hold.\n7. **PO‑SYN‑NOWORK.** Resource spending, yields, and dissipation MUST NOT be computed here; instead, attach references to the aligned **Γ\\_work** composition.\n\n**At compilation (Γ\\_epist^compile):**\n\n1. **PO‑COMP‑CTX.** The target **bounded context** MUST be declared; all active concepts MUST be mapped with **CL**; context vocabulary/units recorded.\n2. **PO‑COMP‑ASSUR.** The assurance tuple (F/G/R) MUST be recomputed **in the target context** with the applied **CL penalties**.\n3. **PO‑COMP‑REL.** A **release‑grade SCR** (hashes, versions, dates) MUST be produced.\n4. **PO‑COMP‑MHT.** If the compilation re‑anchors **boundary**, **objective**, or **identity** (e.g., from compendium to explanatory theory), an **MHT (Context Reframe)** MUST be declared with a Promotion Record (B.2).\n5. **PO‑COMP‑ORDER/TIME.** If derivational order or a specific time slice is essential, the **OrderSpec** and the **Γ\\_time** slice MUST be referenced.\n\n",
        "conformance_checklist": "### B.1.3:7 - Conformance Checklist (normative)\n\n| ID            | Requirement                                                                                                                                                         | Purpose                        |\n| ------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------ |\n| **CC‑B1.3.1** | Inputs to Γ\\_epist MUST be `U.Episteme` holons; **ComponentOf** is forbidden; use **ConstituentOf / UsageOf / ReferenceTo**; **MemberOf** only for **collections**. | Prevent category errors.       |\n| **CC‑B1.3.2** | Provenance and **SCR** MUST be preserved in the aggregate; dropping sources or methods is non‑conformant.                                                      | Enforce Evidence Graph Referring.    |\n| **CC‑B1.3.3** | Aggregate **R** MUST follow the **pathwise min** rule with **Φ(CL\\_min)** penalties; no averaging of reliability.                                                   | Guard conservatism (WLNK).     |\n| **CC‑B1.3.4** | Contradictions MUST NOT be smoothed by arithmetic; handle by **scope separation**, **provisional** status, or **MHT**.                                              | Keep incoherence visible.      |\n| **CC‑B1.3.5** | Every `U.Episteme` serving as an input to `Γ_epist` **MUST** declare its `mode` (`axiomatic` or `postulative`). An aggregate holon's mode **MUST** be `postulative` if any of its constituents is `postulative`. | Prevent category errors in reliability calculation. |\n| **CC‑B1.3.6** | Crossing bounded contexts requires either **explicit mappings with CL** or an **MHT (Context Reframe)**.                                                            | Make context explicit.         |\n| **CC‑B1.3.7** | If order matters, Γ\\_ctx **NC‑1..3** MUST hold; if versions matter, the **Γ\\_time** slice MUST be identified.                                                       | Preserve order/time integrity. |\n| **CC‑B1.3.8** | Design‑time **synthesis** and run‑time **compilation** MUST NOT be conflated; use the appropriate flavour.                                                          | Maintain A.15 separation.      |\n",
        "b.1.3:8___anti‑patterns_&_repairs": "### B.1.3:8 - Anti‑patterns & repairs\n\n| Anti‑pattern             | Symptom                                           | Repair                                                                                     |\n| ------------------------ | ------------------------------------------------- | ------------------------------------------------------------------------------------------ |\n| **Truth‑averaging**      | Averaging confidence of conflicting claims        | Apply **pathwise min** with **CL** penalties; separate scopes or mark **provisional**.     |\n| **Provenance amnesia**   | Sources/methods disappear in the aggregate        | Rebuild **SCR**; re‑run Γ\\_epist with provenance union.                               |\n| **Homonym merge**        | Different concepts with same name silently merged | Insert **mapping edges** with CL; if CL too low, split by context or mark **provisional**. |\n| **Context hop**          | Mixed units/vocabularies without declaration      | Declare **bounded context** and mappings; if purpose changes, use **MHT**.                 |\n| **Version soup**         | Mixed time slices without clarity                 | Use **Γ\\_time** to slice; compose current slice only; link others explicitly.              |\n| **Work stuffing**        | Compute/curation cost blended into reliability    | Move costs to **Γ\\_work**; keep R based on evidence, not spend.                            |\n| **Orderless proof**      | Derivation steps treated as a set                 | Add **OrderSpec**; compose with Γ\\_ctx inside Γ\\_epist.                                    |\n| **Synergy by narrative** | “New theory” claimed without BOSC evidence        | If closure/supervision actually emerges, declare **MHT**; otherwise lower claims.          |\n\n",
        "consequences": "### B.1.3:9 - Consequences\n\n**Benefits**\n\n* **Auditability by construction.** Every retained claim remains tied to its sources; **SCR** guarantees reconstructability.\n* **Safe synthesis.** **R** cannot be inflated; **CL penalties** make conceptual misfit explicit.\n* **Context‑aware releases.** Compiled artifacts are aligned with a declared context; cross‑context reuse is principled.\n* **Didactic clarity.** Separates **semantic folding** (Γ\\_epist) from **order** (Γ\\_ctx), **time** (Γ\\_time), **spend** (Γ\\_work), and **emergence** (B.2).\n\n**Trade‑offs**\n\n* **Mapping overhead.** Declaring mappings and **CL** costs time; it prevents silent incoherence.\n* **Conservative stance.** Results may look pessimistic; this is deliberate (WLNK). Use **MHT** only for genuine explanatory closure.\n\n",
        "rationale": "### B.1.3:10 - Rationale (informative)\n\n* **Epistemic composition is not physical addition.** Reliability must be bounded by the **weakest justified path**, not averaged; conceptual misalignment must **reduce** confidence, not be ignored.\n* **Provenance is part of meaning.** Dropping sources/methods changes what the episteme **is**; Γ\\_epist treats provenance and **SCR** as first‑class.\n* **Context matters.** Bounded contexts structure practice; formal **Context Reframe (MHT)** prevents quiet re‑interpretations of claims.\n* **Parsimony with power.** A small set of rules (provenance preservation, CL‑penalized pathwise min, order/time hooks, context discipline) is enough to model scientific and engineering knowledge without importing domain‑specific tool jargon.\n\n",
        "relations": "### B.1.3:11 - Relations\n\n* **Builds on:** A.12 (Transformer Role—compilers/editors enact), A.14 (Mereology Extension—ConstituentOf/MemberOf/PhaseOf usage), A.15 (Strict Distinction).\n* **Coordinates with:** B.1.1 (Proof kit), B.1.4 (Γ\\_ctx/Γ\\_time inside knowledge folds), B.1.6 (Γ\\_work for compute/collection spend).\n* **Triggers/Complements:** B.2 (MHT) when explanatory closure or context re‑base creates a **new whole** (theory, standard).\n* **Feeds:** B.3 (Assurance) — `F/G/R` and **CL** baselines computed here become inputs to trust calculations.\n\n> **One‑sentence takeaway.**\n> **Γ\\_epist** preserves provenance, penalizes poor conceptual fit, forbids reliability averaging, and makes context explicit—so that knowledge aggregates are conservative, auditable, and genuinely coherent.\n",
        "b.1.3:end": "### B.1.3:End\n"
      },
      "content": "### B.1.3:End\n",
      "metadata": {},
      "part": "B",
      "cluster": null
    },
    {
      "id": "B.1.4",
      "title": "Contextual & Temporal Aggregation (Γ\\_ctx & Γ\\_time)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## B.1.4 - Contextual & Temporal Aggregation (Γ\\_ctx & Γ\\_time)\n\n> **► decided‑by: A.14 Advanced Mereology**\n**A.14 compliance —** **Γ\\_ctx** relies on **SerialStepOf/ParallelFactorOf** (order semantics); **Γ\\_time** composes **PhaseOf** slices of the *same* carrier with coverage/no‑overlap; **PortionOf** is orthogonal (quantities within steps), mappings are not parthood.\n\n> **Plain‑English headline.**\n> Use **Γ\\_ctx** when *the order of steps changes meaning*.\n> Use **Γ\\_time** when *we are aggregating the same carrier across a timeline*.\n",
        "problem": "### B.1.4:2 - Problem\n\nForcing sequential or temporal phenomena through the default, order‑indifferent Γ leads to recurring failures:\n\n1. **Semantic erasure:** Treating `SerialStepOf` as if it were structural parthood flattens workflows; swapping steps silently changes meaning.\n2. **Causal paradoxes:** Aggregating time slices as if they were unordered parts lets effects precede causes, or hides missing epochs.\n3. **Locality violations:** Hidden shared state between “parallel” branches breaks reproducibility; independent branches were not actually independent.\n4. **Design/run conflation:** Mixing design‑time plans and run‑time histories in one fold produces “chimeras” that neither simulate nor audit reality.\n\n",
        "forces": "### B.1.4:3 - Forces\n\n| Force                                 | Tension                                                                                                          |\n| ------------------------------------- | ---------------------------------------------------------------------------------------------------------------- |\n| **Order fidelity vs. Simplicity**     | Preserve step order (non‑COMM) ↔ Keep reasoning lightweight and composable.                                      |\n| **Temporal coverage vs. Flexibility** | Ensure gap/overlap discipline across phases ↔ Allow rolling windows and partial histories.                       |\n| **Locality vs. Concurrency**          | Keep branches deterministic and independent ↔ Exploit parallelism where it is safe.                              |\n| **Universality vs. Fit**              | One pattern for systems and epistemes ↔ Different edge types (`SerialStepOf`, `PhaseOf`) and different carriers. |\n\n",
        "solution": "### B.1.4:4 - Solution — **Part 1: What these flavours are, and when to use them**\n\n#### B.1.4:4.1 - Two flavours at a glance (edge discipline)\n\n| Flavour                                      | You use it when…                                                      | Edge kinds in `D`                                         | Typical carrier                                                            |\n| -------------------------------------------- | --------------------------------------------------------------------- | --------------------------------------------------------------- | -------------------------------------------------------------------------- |\n| **Γ\\_ctx** *(Contextual / order‑sensitive)*  | The **sequence** of steps changes the outcome or meaning.             | `SerialStepOf`, `ParallelFactorOf` (no structural substitution) | `U.Method` (procedures, work processes), also order‑bound argument chains in `U.Episteme` |\n| **Γ\\_time** *(Temporal / phase aggregation)* | You reconstruct a **timeline** of the **same** holon (phases/slices). | `PhaseOf` of a single carrier (non‑overlapping)                 | Any `U.Holon` with identity across time (systems or epistemes)             |\n\n> **Strict Distinction (A.15) reminder.**\n> • Structural inclusion → **Γ\\_sys** (ComponentOf / ConstituentOf).\n> • Order of actions → **Γ\\_ctx** (and its specialisation **Γ\\_method**).\n> • History of the same thing → **Γ\\_time** (PhaseOf).\n> • Resource spending → **Γ\\_work**.\n> • Mappings / representations → value‑level links or `U.Interaction`, not parthood.\n\n\n#### B.1.4:4.2 - Operator signatures (normative)\n\n**Γ\\_ctx — Contextual / Order‑Sensitive Aggregation**\n\n```\nΓ\\_ctx : (D_ctx : DependencyGraph, σ : OrderSpec, T : U.TransformerRole) → H′ : U.Holon\n```\n\n* **D\\_ctx:** a DAG whose **edges are only** `SerialStepOf` / `ParallelFactorOf`.\n* **σ (OrderSpec):** an explicit **partial order** (or total order) compatible with `D_ctx` that disambiguates how branches compose and where joins occur.\n* **T:** the transformer that performs the material act of sequencing/combining steps (A.12).\n* **Output H′:** typically a `U.Method` holon, but may be any holon whose identity is defined by stepwise construction.\n\n**Γ\\_time — Temporal / Phase Aggregation**\n\n```\nΓ\\_time : (D_time : DependencyGraph, τ : TimeWindow, T : U.TransformerRole) → H′ : U.Holon\n```\n\n* **D\\_time:** a DAG whose **edges are only** `PhaseOf`, all phases referring to the **same carrier** identity.\n* **τ:** the declared time window to be covered by the aggregation.\n* **T:** the transformer that composes the timeline (A.12).\n* **Output H′:** the holon reconstructed over τ (system lifecycle, theory revision history, dataset growth, etc.).\n\n\n#### B.1.4:4.3 - Adapted invariants (what replaces COMM/LOC)\n\nBoth flavours **keep** IDEM, WLNK, MONO from B.1. They **replace** COMM/LOC by discipline specific to order and time.\n\n**For Γ\\_ctx (NC‑invariants):**\n\n* **NC‑1 — Determinism under σ.** Given the same `D_ctx` and `σ`, the fold yields the same result.\n* **NC‑2 — Context identifier.** The result **SHALL** record an unambiguous identifier of `σ` (e.g., a canonical text or digest) as part of the aggregation record.\n* **NC‑3 — Partial‑Order Soundness.** Any topological sort consistent with `σ` and with declared independence (below) yields the same result; independent branches may fold in parallel.\n\n**For Γ\\_time (T‑invariants):**\n\n* **T‑1 — Temporal Idempotence.** A single phase/slice folds to itself.\n* **T‑2 — Chronological Discipline.** Phases must be composed in non‑decreasing time consistent with carrier identity; reversing adjacent slices is forbidden.\n* **T‑3 — Coverage.** The union of phase intervals equals the declared `τ`, with **no overlaps** and **no unexplained gaps**. Gaps/overlaps require explicit justification (e.g., measurement resolution or MHT).\n\n> **Why we keep WLNK and MONO.**\n> Even with order/time, the whole cannot be safer or more reliable than the bottleneck step/phase (WLNK), and improving a step/phase on declared monotone characteristics cannot make the whole worse (MONO).\n\n\n#### B.1.4:4.4 - Guards that make the folds provable\n\n**For Γ\\_ctx**\n\n1. **Edge discipline:** only `SerialStepOf` / `ParallelFactorOf`.\n2. **OrderSpec σ:** explicit partial order; joins must have well‑typed inputs/outputs (see B.1.5 for join soundness).\n3. **Independence declaration:** if you claim parallel folds commute locally, declare **which branches are independent** (no hidden shared state or side‑effects).\n4. **Scope:** single `DesignRunTag` (design *or* run) for all nodes; do not mix plans with histories.\n5. **Boundary note:** if steps cross holon boundaries, record the relevant `U.Interaction`—do not recast it as parthood.\n\n**For Γ\\_time**\n\n1. **Same carrier:** all phases are `PhaseOf` the **same** holon identity; identity change implies a Transformer producing a *new* holon.\n2. **Non‑overlap / coverage:** phase intervals are disjoint and cover `τ`; if not, specify how resolution limits or business rules justify the pattern.\n3. **Scope:** single `DesignRunTag`; design‑time hypothetical timelines and run‑time actual logs are kept separate.\n4. **Boundary note:** if Work across boundaries is reported for phases, route resource statements to **Γ\\_work**; Γ\\_time itself does not invent costs.\n\n\n#### B.1.4:4.5 - Selection checklist (didactic quick guide)\n\n* **Does swapping two steps change meaning or safety?** → **Γ\\_ctx**.\n* **Is this the same entity evolving over time?** → **Γ\\_time**.\n* **Is it a physical assembly or conceptual inclusion?** → **Γ\\_sys**.\n* **Is it a “who belongs to this collective” question?** → **MemberOf** + (future) **Γ\\_collective**.\n* **Do you need durations, critical paths, and joins?** → **Γ\\_method** (specialisation of **Γ\\_ctx**).\n* **Do you need resource spending across a boundary?** → **Γ\\_work** (orthogonal; can be used together with Γ\\_ctx/Γ\\_time).\n\n\n#### B.1.4:4.6 - Didactic contrasts (one‑liners)\n\n* **Γ\\_sys vs Γ\\_ctx:** Γ\\_sys composes *what the whole is*; Γ\\_ctx composes *how it is done*.\n* **Γ\\_ctx vs Γ\\_method:** Γ\\_method is Γ\\_ctx **plus** step‑specific rules (durations, joins, capability typing).\n* **Γ\\_time vs Γ\\_ctx:** Γ\\_time composes *phases of the same carrier*; Γ\\_ctx composes *different steps that realise a procedure*.\n* **Γ\\_time vs Γ\\_work:** Γ\\_time composes *history*; Γ\\_work accounts *costs across a boundary* for each phase.\n",
        "b.1.4:5___proof_kit_(ready‑to‑reuse_obligations_for_γ\\_ctx_/_γ\\_time)": "### B.1.4:5 - Proof Kit (ready‑to‑reuse obligations for Γ\\_ctx / Γ\\_time)\n\nThis Proof Kit instantiates the generic obligations from **B.1.1 §6** for the order/time flavours. Attach these items whenever you call Γ\\_ctx or Γ\\_time on a `DependencyGraph D`.\n\n#### B.1.4:5.1 - Γ\\_ctx obligations\n\n* **CTX‑IND (Independence & Joins).**\n  Declare **which branches are independent** (no hidden shared state, no side‑effects that leak across branches). For every **join**, state a **join‑soundness condition** (compatible input/output types and pre/postconditions).\n  *Claim:* Under CTX‑IND, parallel folds of independent branches commute locally; any topological sort consistent with `σ` yields the same result (NC‑3).\n\n* **CTX‑ORD (OrderSpec).**\n  Provide the **OrderSpec `σ`** as a partial order (or total order) text, including where joins occur.\n  *Claim:* Given `D_ctx` and `σ`, the fold is deterministic (NC‑1) and carries a stable **context identifier** (NC‑2).\n\n* **CTX‑WLNK (Critical Path).**\n  Identify the **critical path** (or a cutset) whose weakest step caps the property of the whole: throughput, safety, assurance, etc.\n  *Claim:* The whole is bounded by the weakest element along the critical path (WLNK).\n\n* **CTX‑MONO (Monotone characteristics).**\n  List the characteristics that cannot degrade the whole when improved: e.g., ↓ step duration, ↓ error rate, ↑ step reliability, ↑ join soundness.\n  *Claim:* Improving only monotone characteristics cannot make the aggregated process worse (MONO).\n\n* **CTX‑IDEM (Singleton).**\n  Provide the one‑step singleton witness: Γ\\_ctx of a single `SerialStepOf`‑free node returns that step unchanged (IDEM).\n\n* **CTX‑SCOPE/BOUND.**\n  Affirm a **single DesignRunTag** (`design` or `run`) and list any **U.Interaction** that crosses a holon boundary (do not recast it as parthood).\n\n#### B.1.4:5.2 - Γ\\_time obligations\n\n* **TIME‑CARR (Carrier Identity).**\n  State explicitly the **carrier holon** whose history is being reconstructed.\n  *Claim:* All `PhaseOf` arcs refer to the same carrier; if identity changes, model a Transformer producing a new holon (A.12), not another phase.\n\n* **TIME‑COV (Coverage & Non‑overlap).**\n  Provide the target **TimeWindow τ** and the list of phases with intervals; justify any gaps or overlaps (resolution limits, business rules).\n  *Claim:* Phases cover τ without overlap; otherwise the fold is not admissible (T‑3).\n\n* **TIME‑ORD (Chronological Discipline).**\n  Assert that fold order is non‑decreasing in time; reversing adjacent slices is forbidden.\n  *Claim:* Temporal idempotence holds on a single slice, and chronological composition preserves consistency (T‑1, T‑2).\n\n* **TIME‑WLNK (Temporal Weakest‑Link).**\n  Identify time‑critical constraints: missing essential phases, minimal sampling resolution, minimal integrity of a crucial epoch.\n  *Claim:* The property of the whole (over τ) is capped by the weakest phase/epoch.\n\n* **TIME‑MONO (Monotone characteristics).**\n  List monotone improvements: ↑ coverage, ↑ timestamp precision, ↑ measurement accuracy, ↑ calibration quality.\n  *Claim:* Such improvements cannot degrade the aggregate.\n\n* **TIME‑SCOPE/BOUND.**\n  Keep design‑time hypothetical timelines and run‑time actual logs separate; route resource statements for phases to **Γ\\_work** (not Γ\\_time).\n\n",
        "archetypal_grounding": "### B.1.4:6 - Archetypal grounding (worked micro‑examples)\n\nUse these as templates; each fits on a page and references the obligations above.\n\n#### B.1.4:6.1 - **Γ\\_ctx — U.System (manufacturing route)**\n\n* **Graph:** `Prep SerialStepOf Weld SerialStepOf Paint`; `QC ParallelFactorOf Paint` with a join; scope=`run`.\n* **CTX‑IND:** `QC` is independent of `Prep/Weld` state; join requires “painted & inspected” flags aligned.\n* **CTX‑ORD:** `σ` is total: `Prep → Weld → Paint`; `QC` runs in parallel with `Paint`, joins at `Finish`.\n* **CTX‑WLNK:** Slowest/least reliable step on the critical path caps throughput and assurance.\n* **CTX‑MONO:** ↓ duration of `Weld`; ↑ join condition coverage → cannot reduce overall safety.\n* **Routing:** Costs/energy are handled per step with **Γ\\_work**; structure of subassemblies remains in **Γ\\_sys**.\n\n#### B.1.4:6.2 - **Γ\\_ctx — U.Episteme (order‑bound argument)**\n\n* **Graph:** `PremiseA SerialStepOf LemmaB SerialStepOf Conclusion`; `Background ParallelFactorOf PremiseA`.\n* **CTX‑IND:** `Background` does not alter `LemmaB` assumptions; join checks entailment preconditions.\n* **CTX‑WLNK:** Weakest premise on the entailment spine caps the argument’s reliability.\n* **SCR:** Γ\\_epist on the final `Conclusion` produces a SCR linking every source; Γ\\_ctx assures the order.\n\n#### B.1.4:6.3 - **Γ\\_time — U.System (asset lifecycle)**\n\n* **Carrier:** *This* turbine T‑17.\n* **Phases:** `Install [t0,t1)`, `Operate v1 [t1,t2)`, `Overhaul [t2,t3)`, `Operate v2 [t3,t4)`.\n* **TIME‑COV:** Intervals cover `[t0,t4)` with no overlap; a gap between `t2` and `t2+ε` is justified as clock resolution.\n* **TIME‑WLNK:** The weakest reliability epoch caps lifetime MTTF claimed for `[t0,t4)`.\n* **Routing:** Work/energy footprints per phase via **Γ\\_work**; structural upgrades (new rotor) are Transformers (A.12), not phases, if identity changes.\n\n#### B.1.4:6.4 - **Γ\\_time — U.Episteme (paper revisions)**\n\n* **Carrier:** *This* paper P.\n* **Phases:** `Draft v1`, `Review v2`, `Camera‑ready v3`.\n* **TIME‑ORD/COV:** Non‑overlapping versions covering the documented interval; v3 supersedes v2, not a parallel branch.\n* **TIME‑WLNK:** If v2 violated a key citation, overall reliability over `[v1,v3]` is capped by that epoch unless the violation is explicitly retracted and corrected in v3 (documented change).\n* **Routing:** Γ\\_epist aggregates the conceptual whole at each version; Γ\\_time composes the revision history.\n\n",
        "conformance_checklist": "### B.1.4:7 - Conformance Checklist (normative checklist)\n\n| ID            | Requirement                                                                                                                                                                     | Purpose                                       |\n| ------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------- |\n| **CC‑B1.4.1** | **Γ\\_ctx** input `D_ctx` SHALL use **only** `SerialStepOf` / `ParallelFactorOf` edges; **Γ\\_time** input `D_time` SHALL use **only** `PhaseOf` edges.                           | Keep flavours matched to A.14 edges.          |\n| **CC‑B1.4.2** | **OrderSpec `σ`** (for Γ\\_ctx) or **TimeWindow `τ`** (for Γ\\_time) SHALL be explicitly declared.                                                                                | Determinism and auditability (NC‑1/2, T‑2/3). |\n| **CC‑B1.4.3** | An **independence declaration** (Γ\\_ctx) or **coverage declaration** (Γ\\_time) SHALL be attached, with join‑soundness statements (Γ\\_ctx) and non‑overlap proof (Γ\\_time).      | Make replaced COMM/LOC discipline explicit.   |\n| **CC‑B1.4.4** | **WLNK cutset** SHALL be identified (critical path for Γ\\_ctx; critical epoch for Γ\\_time).                                                                                     | Conservative bounds.                          |\n| **CC‑B1.4.5** | **MONO characteristics** SHALL be listed and justified for the call.                                                                                                                       | Prevent hidden regress.                       |\n| **CC‑B1.4.6** | All nodes SHALL share the same `DesignRunTag` (`design` or `run`) in a single fold.                                                                                            | Ban design/run chimeras.                      |\n| **CC‑B1.4.7** | Structural inclusion, mappings, and resource spending SHALL NOT be encoded as order/time edges; route to **Γ\\_sys / Γ\\_epist**, value‑level links or **Γ\\_work** respectively. | Enforce A.15 Strict Distinction.              |\n| **CC‑B1.4.8** | If coverage breaks or identity changes, the modeller SHALL refactor the graph or declare a **Meta‑Holon Transition** (B.2).                                                     | Make emergence explicit.                      |\n\n",
        "b.1.4:8___anti‑patterns_and_their_fixes": "### B.1.4:8 - Anti‑patterns and their fixes\n\n| Anti‑pattern                         | Symptom                                                     | Fix                                                                                                                     |\n| ------------------------------------ | ----------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------- |\n| **Structure‑as‑sequence**            | `StepB ComponentOf StepA` to force an order                 | Use `SerialStepOf` (Γ\\_ctx) and an explicit `σ` with a join condition if needed.                                        |\n| **History‑as‑structure**             | `v2 ComponentOf v1`                                         | Use `PhaseOf`; if identity actually changed, model a Transformer (A.12) producing a new holon.                          |\n| **Parallelism without independence** | Declaring `ParallelFactorOf` but sharing hidden state       | Either declare the shared state as an interface and remove independence, or refactor so branches are truly independent. |\n| **Overlapping phases**               | Two `PhaseOf` intervals for the same carrier overlap        | Split the intervals or justify overlap as measurement resolution; otherwise fold is invalid.                            |\n| **Design/run chimera**               | Mixing run logs with design plan in one Γ\\_ctx/Γ\\_time fold | Split into two graphs by scope; relate through a Transformer or mapping at value level.                                 |\n| **Cost in Γ\\_time**                  | Trying to sum energy in Γ\\_time                             | Route costs to Γ\\_work per phase; Γ\\_time composes history, not expenditure.                                            |\n\n",
        "consequences": "### B.1.4:9 - Consequences\n\n**Benefits**\n\n* **Semantic fidelity:** Order and history are first‑class; no more flattening sequential logic or erasing temporal causality.\n* **Auditable determinism:** An explicit `σ`/`τ` and independence/coverage declarations make folds reproducible and reviewable.\n* **Safe parallelism:** Partial‑order soundness preserves determinism while exploiting concurrency where it is actually safe.\n* **Clean separation of concerns:** Structure (Γ\\_sys/Γ\\_epist), order (Γ\\_ctx/Γ\\_method), time (Γ\\_time), and cost (Γ\\_work) no longer interfere.\n\n**Trade‑offs / mitigations**\n\n* **Extra declarations:** Independence, joins, and coverage require up‑front articulation.\n  *Mitigation:* reuse the Proof Kit forms; adopt the decision checklist from Part 1 §4.5.\n* **Limited parallelism:** Where branches are not independent, concurrency must be curtailed.\n  *Mitigation:* regroup steps; elevate shared state to explicit interfaces.\n\n",
        "rationale": "### B.1.4:10 - Rationale (informative)\n\nThis pattern implements **A.15’s ordered relations** (`SerialStepOf`, `ParallelFactorOf`) and leverages **A.14’s `PhaseOf`** for timeline; consistent with **Strict Distinction**: order and time are not structure, and costs are not history. The adapted invariants (NC‑1..3 and T‑1..3) give precise replacements for COMM/LOC where these do not hold, while retaining WLNK and MONO. The result is a small, stable interface that matches how engineers and researchers already argue about procedures and histories, without importing domain‑specific notations into the kernel.\n\n",
        "relations": "### B.1.4:11 - Relations\n\n* **Builds on:** B.1 (Universal Γ), B.1.1 (Dependency Graph & Proofs), A.12 (Transformer), A.14 (Mereology Extension), A.15 (Strict Distinction).\n* **Specialises into:** **B.1.5 Γ\\_method** (adds duration, capability typing, join soundness rules).\n* **Works alongside:** **B.1.6 Γ\\_work** (resource accounting per step/phase).\n* **Triggers:** **B.2 Meta‑Holon Transition (MHT): Recognizing Emergence and Re‑identifying Wholes** when re‑ordering or re‑phasing produces genuinely new properties.\n* **Feeds:** **B.4 Canonical Evolution Loop** (time‑aware cycles that carry explicit costs and order).\n\n> **One‑page takeaway.**\n> If **order changes meaning**, use **Γ\\_ctx** with an explicit **OrderSpec** and independence/joins.\n> If you are **composing the same carrier across time**, use **Γ\\_time** with a **TimeWindow**, coverage, and identity.\n> Keep structure, mapping, and cost in their places, and the invariants will do the rest.\n",
        "b.1.4:end": "### B.1.4:End\n"
      },
      "content": "### B.1.4:End\n",
      "metadata": {},
      "part": "B",
      "cluster": null
    },
    {
      "id": "B.1.5",
      "title": "Γ_method — Order‑Sensitive Method Composition & Instantiation",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## B.1.5 - Γ_method — Order‑Sensitive Method Composition & Instantiation\n> **► decided‑by: A.14 Advanced Mereology**\n**A.14 compliance —** Methods compose over **SerialStepOf/ParallelFactorOf** on **MethodDescription/Method** graphs (order, not parthood); stuff‑like inputs are modelled via **PortionOf** on resources and accounted in **Γ_work**; method/version history uses **PhaseOf**; mapping quality is handled via **CL** (B.3).\n \n> **Plain‑English headline.**\n> **Γ\\_method** turns **ordered step‑methods** into a **single composite Method** (run‑time) and, dually, turns **ordered step specifications** into a **single MethodDescription** (design‑time). It reuses **Γ\\_ctx** for order, keeps **work/cost in Γ\\_work**, and makes **pre/post‑conditions and capability typing** explicit so models stay physically and logically sound.\n",
        "problem": "### B.1.5:2 - Problem\n\nWithout a dedicated, order‑aware method operator:\n\n1. **Design/run conflation.** Authors mix **MethodDescription** (blueprint) and **Method** (enactment), producing “methods” that have both planned and executed attributes.\n2. **Order erasure.** Sequences with crucial **pre/post‑conditions** get collapsed into sets; reordering breaks correctness while still “passing” naive aggregation.\n3. **Capability mismatches.** Step outputs do not match the next step’s required inputs, but this is hidden in untyped edges; composite methods become non‑executable.\n4. **Work leakage.** Costs and resource flows are **inlined** into method definitions; later models double‑count or violate conservation (Γ\\_work was created to prevent this).\n5. **Synergy by arithmetic.** Throughput or quality jumps caused by **proper joins** or **coordination** are misreported as simple sums or averages—violating WLNK and obscuring when a **Meta‑Holon Transition (B.2)** should be declared.\n",
        "forces": "### B.1.5:3 - Forces\n\n| Force                                    | Tension                                                                                                 |\n| ---------------------------------------- | ------------------------------------------------------------------------------------------------------- |\n| **Order fidelity vs. simplicity**        | Keep the **true sequence** (non‑commutative) ↔ Provide a **small** operator set.                        |\n| **Type safety vs. flexibility**          | Enforce **capability typing** and **pre/post** checks ↔ Allow modular reuse of steps across contexts.   |\n| **Design vs. run**                       | Compose **MethodDescription** for planning ↔ Instantiate **Method** for execution without mixing them.         |\n| **Parallelism vs. correctness**          | Maximise concurrency on **independent branches** ↔ Guarantee **sound joins** and reproducible outcomes. |\n| **Parsimony vs. separation of concerns** | Keep Γ small ↔ Keep **work** and **assurance** in their own lanes (Γ\\_work, B.3).                       |\n",
        "solution": "### B.1.5:4 - Solution\n\n#### B.1.5:4.1 - Terms (didactic recap)\n\n* **U.MethodDescription** — a design‑time description: ordered steps, **SerialStepOf/ParallelFactorOf**, step **capability types**, **pre/post‑conditions**, and required **external interactions**.\n* **U.Method** — a run‑time enactment by a **U.TransformerRole** (A.12): the same ordered pattern realised on concrete carriers, satisfying step pre‑conditions and producing post‑conditions.\n* **U.StepSpec / U.StepMethod** — step‑level counterparts of the above.\n* **Capability type** — the **state/action signature** a step requires and produces (not to be confused with resources; those belong to Γ\\_work).\n* **Method Interface Standard (MIC)** — the **order‑aware** analogue of BIC: a short, declarative statement of what **external interactions** of the steps are **Promoted / Forwarded / Encapsulated** at the composite method boundary.\n\n> **Separation reminder.**\n> Method composition ≠ resource spending. Keep **resource budgets, yields, dissipation** in **Γ\\_work**; **Γ\\_method** only checks and composes **order and capability**.\n\n\n#### B.1.5:4.2 - The operator family (two companion flavours)\n\nTo respect the design/run split, **Γ\\_method** is presented as two companion operators sharing the same semantics but acting at different scopes.\n\n1. **Planning (design‑time) — compose specifications**\n\n   ```\n   Γ_method^plan : ( D_spec : OrderedDependencyGraph< U.StepSpec >,\n                     σ       : OrderSpec,\n                     MIC_in  : optional boundary hints )\n                   → U.MethodDescription\n   ```\n\n   * **Domain.** `D_spec` contains step specifications linked by **SerialStepOf** / **ParallelFactorOf** (**A.15**).\n   * **Result.** A single **U.MethodDescription** whose **MIC** is computed from step interfaces using the **Promote / Forward / Encapsulate** quartet (cf. BIC in B.1.2).\n\n2. **Enactment (run‑time) — instantiate methods**\n\n   ```\n   Γ_method^run  : ( M_spec : U.MethodDescription,\n                     T      : U.TransformerRole,\n                     Bind   : carrier & parameter bindings )\n                   → U.Method\n   ```\n\n   * **Domain.** A previously composed **MethodDescription**, a **Transformer** that plays the method, and concrete **bindings** (carriers, parameters).\n   * **Result.** A **U.Method** (the real execution) provided that **capability checks** and **pre/post‑conditions** hold.\n\n**Relationship to Γ\\_ctx.**\nBoth flavours **reuse Γ\\_ctx** invariants for order (non‑commutative composition with **NC‑1..3** reproducibility). **Γ\\_method** specialises the **typing and boundary rules** for methods and introduces **MIC**.\n\n\n#### B.1.5:4.3 - Core aggregation rules (design‑time composition)\n\nWhen computing **Γ\\_method^plan(D\\_spec, σ)**:\n\n1. **Order preservation.**\n   Respect the **OrderSpec σ**; independent branches may be folded in any **topological sort** (Γ\\_ctx NC‑3). **SerialStepOf** enforces strict precedence; **ParallelFactorOf** allows concurrency with a **join**.\n\n2. **Capability continuity (typed joins).**\n   Every join must be **type‑sound**: the **post‑condition / output signature** of each incoming branch must **meet** the next step’s **pre‑conditions** (logical entailment or declared **adapter** steps). Missing adapters are **defects**, not assumptions.\n\n3. **MIC synthesis (boundary behaviour).**\n   For each external interaction of a step, decide **Promote / Forward / Encapsulate** into the composite **MIC**. This inherits the clarity of BIC (B.1.2) for methods.\n\n   * *Promote*: becomes a direct composite interaction (e.g., top‑level “start/stop”).\n   * *Forward*: remains step‑local but exposed under the composite boundary (namespaced).\n   * *Encapsulate*: becomes internal; callers cannot rely on it.\n\n4. **Assurance hooks (without computing assurance).**\n   Record where **B.3 assurance** will later hang: (i) the **cutset** steps that bound reliability/quality, (ii) the **integration edges** whose **CL** will penalise poor fit (mappings, fragile joins), and (iii) the **envelope** (G) intended for the method’s validity.\n\n5. **No costs here.**\n   If a step lists resources/yields, **do not** aggregate them here. Instead, add a pointer to the corresponding **Γ\\_work** composition to be executed with the same order/joins at run‑time.\n\n\n#### B.1.5:4.4 - Core aggregation rules (run‑time instantiation)\n\nWhen executing **Γ\\_method^run(M\\_spec, T, Bind)**:\n\n1. **Pre/post enforcement.**\n   Before each step, verify **pre‑conditions** against **Bind** and the evolving carrier state; after, check **post‑conditions** hold. Failing these means the **Method** cannot be enacted as specified.\n\n2. **Typed state flow.**\n   The **state/action types** produced by a step must make the next step **well‑typed**; if not, an **adapter method** (itself with a MethodDescription) must be present in the graph.\n\n3. **Order determinism (Γ\\_ctx).**\n   Respect `σ`. Parallel branches may execute independently **only if** they share no state that would break **NC‑1..3**; otherwise they must synchronise at the declared join.\n\n4. **MIC honouring.**\n   Interactions exposed by **MIC** are the **only** external commitments the composite method makes. Any additional ad‑hoc external interaction is a **model violation** (or requires updating the MIC and re‑planning).\n\n5. **Γ\\_work hand‑off.**\n   Invoke **Γ\\_work** to compute **spent resources, yields, dissipation** along the same order/join structure. The resulting work products **annotate** the Method but are **not** part of Γ\\_method’s aggregation.\n\n> **Invariant intuition.**\n>\n> * **IDEM:** a single step‑method composed alone yields the same method.\n> * **COMM/LOC:** replaced by Γ\\_ctx **NC‑1..3** (determinism given `σ`, context hash of `σ`, and partial‑order soundness).\n> * **WLNK:** quality/throughput of the composite is bounded by the **critical path** steps (identified for later B.3 assurance).\n> * **MONO:** strengthening a step (better pre/post, stronger type, improved adapter) **cannot** make the composite worse.\n\n\n#### B.1.5:4.5 - Didactic contrasts (to prevent common confusions)\n\n* **Method vs Work.**\n  Method = **what** ordered transformations are enacted; **Work** = **resources spent / yields / dissipation** when enacting them (Γ\\_work). Keep them distinct.\n\n* **Method vs Structure.**\n  Method composes **ordered steps**; structure composes **parts** (Γ\\_sys). Do not use **ComponentOf** where **SerialStepOf/ParallelFactorOf** are intended.\n\n* **Method vs Phase.**\n  Method composition is **order**; **PhaseOf** (Γ\\_time) is **temporal progression** of the **same carrier**. If a phase boundary also introduces **closure/supervision/context rebase**, that is **MHT** (B.2), not mere phasing.\n\n* **MethodDescription vs Method.**\n  Keep **planning** artefacts (MethodDescription) separate from **enactment** (Method). Γ\\_method provides operators for both but never fuses them.\n",
        "archetypal_grounding": "### B.1.5:5 - Archetypal grounding (worked, didactic)\n\n#### B.1.5:5.1 - System archetype — **Assemble‑Paint‑Test** as one Method\n\n* **Design‑time (Γ\\_method^plan).**\n  `D_spec` contains `StepSpec`s: `AssembleChassis`, `InstallPowertrain`, `PaintBody`, `RunFunctionalTest`.\n  Relations: `AssembleChassis → InstallPowertrain` (**SerialStepOf**), `PaintBody ∥ RunFunctionalTest` after a structural seal (**ParallelFactorOf**).\n  Capability typing:\n\n  * Output of `InstallPowertrain` **meets** input of `RunFunctionalTest` (functional harness attached).\n  * `PaintBody` requires sealed surfaces from `InstallPowertrain` (pre‑condition).\n    MIC outcome:\n  * **Promote:** `Start()`, `Abort()`, `CertificationReport`.\n  * **Forward:** `RunFunctionalTest.Diagnostics` (namespaced).\n  * **Encapsulate:** `PrimerMixingPort`, internal seal checks.\n\n* **Run‑time (Γ\\_method^run).**\n  `T` enacts the `MethodDescription` on concrete carriers. Pre/post checks gate each step; parallel branches run after pre‑conditions met; a join waits for both to finish.\n\n* **Assurance hooks (B.3).**\n  Cutset steps for WLNK: `InstallPowertrain` (torque tolerances) and `RunFunctionalTest` pass/fail; integration edges carry **CL** for harness mapping and paint/seal specification.\n  **Γ\\_work** is invoked to compute energy/material spend and dissipation; Γ\\_method does not tally costs itself.\n\n#### B.1.5:5.2 - Episteme archetype — **Evidence‑Synthesis‑Publish** as one Method\n\n* **Design‑time (Γ\\_method^plan).**\n  Steps: `CollectDatasets`, `NormalizeSchemas`, `EstimateModel`, `CrossValidate`, `DraftManuscript`.\n  Ordering: `CollectDatasets → NormalizeSchemas → EstimateModel → CrossValidate → DraftManuscript`.\n  Capability typing: `NormalizeSchemas` outputs a typed feature space that **entails** `EstimateModel`’s input; adapters specified for legacy datasets.\n  MIC outcome:\n\n  * **Promote:** `Submit()`, `ReleaseArtifacts()`.\n  * **Forward:** `CrossValidate.Folds(k)`.\n  * **Encapsulate:** ad‑hoc scrubbing utilities.\n\n* **Run‑time (Γ\\_method^run).**\n  The same order executes; **Γ\\_work** accounts for compute/storage spend.\n  Assurance hooks: cutset at `CrossValidate`; integration **CL** for schema mappings; post‑condition for `DraftManuscript` includes provenance SCR.\n\n",
        "b.1.5:6___method_interface_standard_(mic)_—_template_&_examples": "### B.1.5:6 - Method Interface Standard (MIC) — template & examples\n\n#### B.1.5:6.1 - MIC template (normative content)\n\n```\nMethod Interface Standard (MIC)\n  name:                human-readable identifier\n  version:             semantic label of this MIC\n  orderSpecHash:       hash(OrderSpec σ + step signatures)\n  externalInteractions:\n    - id:              external op name\n      mode:            {Promote | Forward | Encapsulate}\n      signature:       state/action types (typed interface)\n      preconditions:   predicates that must hold at call\n      postconditions:  predicates guaranteed on return\n      qosEnvelope:     optional envelope (throughput, latency, quality)\n  invariants:\n    - textual/logical invariants preserved by the method\n  notes:\n    - rationale for Promote/Forward/Encapsulate choices\n```\n\n#### B.1.5:6.2 - MIC excerpts (didactic)\n\n* **Manufacturing method MIC excerpt**\n\n  ```\n  externalInteractions:\n    - id: Start\n      mode: Promote\n      signature: Start(): Promise<BatchId>\n      preconditions: LineReady & MaterialsAvailable\n      postconditions: BatchId issued\n    - id: PrimerMixingPort\n      mode: Encapsulate\n  invariants:\n    - FunctionalTest.Pass implies TorqueTolerance ≤ δ\n  ```\n\n* **Evidence method MIC excerpt**\n\n  ```\n  externalInteractions:\n    - id: Submit\n      mode: Promote\n      signature: Submit(): Promise<SubmissionId>\n      preconditions: ManuscriptReady & SCRComplete\n      postconditions: DOI assigned on accept\n    - id: CrossValidate.Folds\n      mode: Forward\n      signature: Folds(k: Int): Report\n  invariants:\n    - Report.metrics computed on held-out data only\n  ```\n\n",
        "b.1.5:7___proof_obligations_(normative)": "### B.1.5:7 - Proof obligations (normative)\n\n**At planning time (Γ\\_method^plan):**\n\n1. **PO‑PLAN‑ORDER.** Provide `OrderSpec σ`; produce `orderSpecHash`.\n2. **PO‑PLAN‑TYPE.** For every edge, show **capability continuity**: `OutType(step_i) ⊢ InType(step_j)` or provide a typed **adapter StepSpec**.\n3. **PO‑PLAN‑MIC.** For each step interaction, decide **Promote/Forward/Encapsulate** and justify in MIC.\n4. **PO‑PLAN‑CL‑POINTS.** Identify integration edges whose **CL** will matter for B.3; record intended sources of mapping evidence.\n5. **PO‑PLAN‑NO‑WORK.** Confirm that costs/resources are **not** aggregated here; point to the planned **Γ\\_work** composition (by reference).\n\n**At run time (Γ\\_method^run):**\n\n1. **PO‑RUN‑PRE/POST.** Demonstrate that pre‑conditions hold before each step; check post‑conditions after.\n2. **PO‑RUN‑NC.** Show compliance with Γ\\_ctx **NC‑1..3** (determinism with σ, context hash, partial‑order soundness).\n3. **PO‑RUN‑MIC‑HONOUR.** Record that only MIC‑declared external interactions occurred.\n4. **PO‑RUN‑WORK.** Attach the **Γ\\_work** result (spent resources, yields, dissipation) aligned with the same order/join structure.\n5. **PO‑RUN‑ASSURANCE.** Provide the observed values for the cutset steps and the actual **CL** of integration mappings to feed B.3 assurance.\n\n",
        "conformance_checklist": "### B.1.5:8 - Conformance Checklist (normative)\n\n| ID            | Requirement                                                                                                                                                   | Purpose                             |\n| ------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------- |\n| **CC‑B1.5.1** | Γ\\_method **SHALL** be used in two flavours only: `Γ_method^plan` for specifications, `Γ_method^run` for enactments.                                          | Enforce design/run separation.      |\n| **CC‑B1.5.2** | Planning inputs **SHALL** use **SerialStepOf / ParallelFactorOf** edges with a declared **OrderSpec σ**.                                                      | Preserve order semantics.           |\n| **CC‑B1.5.3** | All joins **SHALL** be **type‑sound** (capability continuity) or include explicit typed adapters.                                                             | Prevent non‑executable composites.  |\n| **CC‑B1.5.4** | A **MIC** **SHALL** be produced for `Γ_method^plan` and **SHALL** be honoured by `Γ_method^run`.                                                              | Make external commitments explicit. |\n| **CC‑B1.5.5** | Resource spending/yields **SHALL** be computed via **Γ\\_work** and MUST NOT be inlined into Γ\\_method aggregation.                                            | Maintain separation of concerns.    |\n| **CC‑B1.5.6** | Γ\\_ctx **NC‑1..3** invariants **SHALL** hold for both flavours (determinism under σ, hash, partial‑order soundness).                                          | Guard non‑commutative correctness.  |\n| **CC‑B1.5.7** | If joining branches produces apparent super‑additivity beyond WLNK not explainable within Γ\\_method, an **MHT** **SHALL** be considered and recorded per B.2. | Prevent “synergy by arithmetic”.    |\n\n",
        "b.1.5:9___anti‑patterns_&_repairs": "### B.1.5:9 - Anti‑patterns & repairs\n\n| Anti‑pattern           | Symptom                                                       | Repair                                                                             |\n| ---------------------- | ------------------------------------------------------------- | ---------------------------------------------------------------------------------- |\n| **Design/Run Chimera** | Spec contains runtime measures; enactment adds planning edges | Split into `MethodDescription` vs `Method`; rerun Γ\\_method per flavour.                  |\n| **Orderless Set**      | Steps modelled as unordered; reordering breaks correctness    | Provide `OrderSpec σ` and recompose with Γ\\_method/Γ\\_ctx.                         |\n| **Silent Adapter**     | A join assumes implicit conversion                            | Add explicit typed **adapter StepSpec/Method** and re‑prove capability continuity. |\n| **Inline Costs**       | Method sums time/energy                                       | Move to **Γ\\_work**; link the work composition to the same order.                  |\n| **Boundary Fog**       | External calls occur ad‑hoc                                   | Define/Update **MIC**; Promote/Forward/Encapsulate explicitly.                     |\n| **Emergence by Join**  | Throughput leaps past WLNK with no story                      | Either (i) prove within Γ\\_method (cutset/CL/order) or (ii) declare **MHT** (B.2). |\n\n",
        "consequences": "### B.1.5:10 - Consequences\n\n**Benefits**\n\n* **Didactic clarity.** Readers see **what** is being composed (order & capability) vs **what** is spent (Γ\\_work) vs **what** is assured (B.3).\n* **Deterministic execution semantics.** Γ\\_ctx‑backed order with explicit joins yields reproducible composites.\n* **Robust interfaces.** MIC prevents accidental external dependencies and preserves modularity.\n* **Cross‑scale fit.** Same pattern works for physical, organizational, and epistemic methods.\n\n**Trade‑offs**\n\n* **More explicitness up‑front.** Capability typing and MIC authorship require care; in return, later integration is safer.\n* **Adapter discipline.** Modellers must create adapters rather than assuming conversions—this avoids hidden brittleness.\n\n",
        "rationale": "### B.1.5:11 - Rationale (informative)\n\n* **Order is semantic.** Many failures stem from pretending that order does not matter; Γ\\_method makes **non‑commutativity** explicit (via Γ\\_ctx) while keeping the operator set small.\n* **Strict Distinction.** The split between **Method/MethodDescription**, **Γ\\_method/Γ\\_work**, and **assurance** implements A.15, preventing category errors (behaviour vs spending vs claims).\n* **Mereology alignment.** Using **SerialStepOf / ParallelFactorOf** (A.14) keeps method composition orthogonal to structural composition (**ComponentOf**) and temporal phasing (**PhaseOf**).\n* **Assurance readiness.** Identifying cutsets and mapping CL points during planning makes B.3 application straightforward and auditable.\n\n",
        "relations": "### B.1.5:12 - Relations\n\n* **Builds on:** A.12 (Transformer Role), A.14 (Mereology Extension), A.15 (Strict Distinction); B.1.1 (Proof Kit), B.1.4 (Γ\\_ctx/Γ\\_time).\n* **Coordinates with:** B.1.6 (Γ\\_work) for resource accounting; B.3 (Assurance) for WLNK cutsets and CL penalties.\n* **Triggers/Complements:** B.2 (MHT) when new closure/supervision or context re‑base appears at method level.\n* **Used by:** Later domain architheories that define canonical methods in specific disciplines (without altering Γ\\_method).\n\n> **One‑sentence takeaway.**\n> **Γ\\_method** composes **ordered, typed steps** into a reliable method, keeps **interfaces explicit** (MIC), leaves **costs to Γ\\_work**, and provides clean hooks for **assurance** and **emergence**.\n",
        "b.1.5:end": "### B.1.5:End\n"
      },
      "content": "### B.1.5:End\n",
      "metadata": {},
      "part": "B",
      "cluster": null
    },
    {
      "id": "B.1.6",
      "title": "Γ\\_work — Work as Spent Resource",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## B.1.6 - Γ\\_work — Work as Spent Resource\n\n> **► decided‑by: A.14 Advanced Mereology**\n**A.14 compliance —** Only **Work** carries resource deltas; quantitative splits/consumption use **PortionOf** against pre‑consumption stocks; run histories use **PhaseOf** on Work; `MemberOf` MUST NOT be used for resource mereology; SCR/RSCR stay outside (use EPV‑DAG anchors).\n ",
        "problem": "### B.1.6:2 - Problem\n\nWithout a dedicated algebra for spent resources, models drift into four errors:\n\n1. **Process–Work conflation:** Time‑ordered steps and resource spending are mixed, producing ambiguous or double‑counted totals.\n2. **Conservation violations:** Totals appear that exceed inputs or create “free” resource, contradicting physical and informational conservation.\n3. **Boundary blindness:** Spending is reported without specifying the boundary across which it is measured, making numbers non‑comparable.\n4. **Category errors in mereology:** Collection membership (MemberOf) is misused as if it were parthood for resource stocks, polluting Γ proofs (B.1).\n\n",
        "forces": "### B.1.6:3 - Forces\n\n| Force                                               | Tension                                                                                                                        |\n| --------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------ |\n| **Conservation vs. Abstraction**                    | Totals must obey material/energy/information conservation ↔ models must stay simple and readable.                              |\n| **Run‑time measurability vs. Design‑time planning** | We need measurable deltas at run‑time ↔ we also need ex‑ante yields from MethodDescription to plan.                                   |\n| **Heterogeneous units vs. Unified sums**            | Resources come in different units (joules, kg, bits) ↔ we still need composite statements (vectors, typed sums).               |\n| **Safety vs. Synergy**                              | Weakest‑link bounds must cap availability ↔ redundancy or substitution can improve feasibility but belongs to emergence (B.2). |\n\n",
        "b.1.6:4___terminology_guard‑rails_(a.15_—_strict_distinction)": "### B.1.6:4 - Terminology guard‑rails (A.15 — Strict Distinction)\n\n> These rules are normative in this pattern; they exist to prevent the recurring confusion noted in prior drafts.\n\n* **MethodDescription** — design‑time description of a transformation (parameters, intended yield η).\n* **Method** — the run‑time execution of that MethodDescription by a **Transformer**; it exists only while it runs.\n* **Process** — a method seen as an ordered structure of steps; composed by **Γ\\_method**.\n* **Work** — **spent resource** (a measurable delta across a declared boundary) caused by executing a Method; composed by **Γ\\_work**.\n* **Transformer (T)** — a **U.System** playing a role that executes a Method (A.12).\n* **Mereology for resources (A.14):** use `PortionOf` for **quantitative splits** and `PhaseOf` for **time‑slices**; **do not** use `MemberOf` for resource stocks.\n\n",
        "solution": "### B.1.6:5 - Solution — The Γ\\_work Operator\n\n**Intent.** Provide a universal, conservative way to compose resource spending across parts and steps, without talking about control‑flow (that is Γ\\_method’s job).\n\n#### B.1.6:5.1 - Operator signature\n\n```\nΓ_work : (R : ResourceGraph, M_spec : U.MethodDescription?, T : U.TransformerRole) → W_tot : U.Work\n```\n\n* **R — ResourceGraph.** An acyclic graph whose nodes are **U.Resource** holons with typed, extensive quantities (e.g., energy, mass, information). Edges are **`consumes`**, **`produces`**, **`transfers`** and are tied to explicit **U.Boundary** declarations (A.14). Where a stock is subdivided, the split uses `PortionOf`; where a run is time‑sliced, the slices use `PhaseOf`.\n\n* **M\\_spec — optional.** If present, it provides *ex‑ante* yield/efficiency (η) for planning; if absent, Γ\\_work composes purely from measured deltas.\n\n* **T — TransformerRole.** The external system that executes or validates the resource accounting for the run; T is not a node of R (A.12).\n\n* **Result W\\_tot — U.Work.** A typed **Work vector** (possibly sparse) with the same basis as the resources in R. It is accompanied by a **Boundary Ledger** (see §3).\n\n> **Do not confuse:** Γ\\_work neither schedules nor orders steps; it composes **deltas**. If you need order, use Γ\\_method and then apply Γ\\_work per step and fold the resulting Work vectors (see Relations in Part 2).\n\n#### B.1.6:5.2 - What counts as “Work”\n\nWork is defined **with respect to a declared boundary** of the holon being transformed or assembled:\n\n* **Boundary‑relative delta (conservative form):**\n  For any resource type *q* measured on boundary *B* during a run,\n\n  ```\n  Work_B(q) = Inflow_B(q) − Outflow_B(q) − ΔStock_inside(q)\n  ```\n\n  where **ΔStock\\_inside(q)** is the change of internal stock over the run (positive when the stock grows).\n\n* **Embodiment split:**\n  Work can be split into **Dissipation** (lost to environment) and **Embodied** (retained in produced holons as state). Both are part of the same Work vector; the split is a reporting choice, not a second algebra.\n\n* **Heterogeneous vectors:**\n  Γ\\_work treats different resource types as a **typed vector space** (no implicit conversion). Equivalences (e.g., joules↔bits via a declared model) are allowed only if **declared in M\\_spec** or in a domain CAL; otherwise vectors remain multi‑dimensional.\n\n#### B.1.6:5.3 - Boundary Ledger (normative output metadata)\n\nEvery Γ\\_work result **MUST** include a **Boundary Ledger**:\n\n* **(i) Boundary scope:** which `U.Boundary` was used (source holon, ports).\n* **(ii) Time window:** start/stop or `PhaseOf` slice identifiers.\n* **(iii) Basis:** the ordered list of resource types and units.\n* **(iv) Method context:** reference to `M_spec` (if any) and run identifier of the Method.\n* **(v) Transformer:** identity of **T** (system playing the executing or auditing role).\n\nThis ledger is what makes cross‑model Work totals comparable and auditable (A.10).\n\n#### B.1.6:5.4 - The invariant quintet instantiated (overview)\n\nΓ\\_work preserves B.1 invariants; the detailed proofs and corner cases are in Part 2.\n\n* **IDEM (idempotence):** Work over a graph with a single resource node and no consumption edges is the zero vector.\n* **COMM / LOC (local commutativity / locality):** For **independent** subgraphs, composed Work is additive and independent of local fold order.\n* **WLNK (weakest‑link bound):** Effective Work is capped by the scarcest **critical** input on the boundary (no Work can exceed available supply).\n* **MONO (monotonicity):** Increasing an available resource cannot decrease Work (for the same boundary and time window); decreasing dissipation or improving η cannot reduce feasibility.\n\n#### B.1.6:5.5 - How Γ\\_work relates to Methods (and to Γ\\_method)\n\n* **Design‑time:** `M_spec` may declare an intended yield **η** and admissible equivalences between resource types (e.g., heat→mechanical), but these are **assumptions** until a Method runs.\n* **Run‑time:** A Method instance (executed by **T**) produces actual deltas. Γ\\_work composes those deltas; it does not speculate.\n* **Sequencing:** If multiple Methods are ordered, use **Γ\\_method** to compose the order, then apply Γ\\_work per step and sum the Work vectors (independent branches sum; synchronized branches take max on **time**, not on **Work**).\n\n> **Didactic tip:** Think of **Γ\\_method** as the **story of what happened**, and **Γ\\_work** as the **receipt of what it cost**, both anchored to the same boundary and time window.\n",
        "b.1.6:6___fold_rules_(how_γ\\_work_composes)": "### B.1.6:6 - Fold rules (how Γ\\_work composes)\n\n#### B.1.6:6.1 - Boundary partition (across parts of a whole)\nLet the system‑level boundary **B** be covered by a finite family of pairwise‑disjoint sub‑boundaries **{Bᵢ}** (ports, surfaces, interfaces) that together exhaust **B**. For any resource type *q* in the basis:\n\n* **Partition additivity (normative):**\n\n  ```\n  Work_B(q) = Σ_i Work_Bi(q)\n  ```\n\n  Preconditions: (i) `Bi` are disjoint except for measure‑zero interfaces, (ii) meters are aligned (same units, same time window), (iii) internal stock changes ΔStock\\_inside(q) are measured for the *same* closed region bounded by B.\n  *Why it matters:* this is the cross‑scale rule that lets part‑level Work totals roll up to the whole without double counting.\n\n#### B.1.6:6.2 - Time slicing (serial runs / phases)\nLet the run be split by a set of non‑overlapping intervals **{τⱼ}** that cover the window **τ** (use `PhaseOf` to tag the slices). Then:\n\n```\nWork_B(q, τ) = Σ_j Work_B(q, τ_j)\n```\n\nThis is the **temporal additivity** of Work. It is the Γ\\_work analogue of Γ\\_time’s coverage rule: we never “smear” or reorder; we sum non‑overlapping slices.\n\n#### B.1.6:6.3 - Concurrent branches (parallel activity)\nWhen two independent sub‑boundaries **B₁**, **B₂** are active over overlapping time, total Work still **adds**:\n\n```\nWork_B(q) = Work_B1(q) + Work_B2(q)\n```\n\nIndependence here means: no shared port, no shared stock variable, no hidden transfer between B₁ and B₂ that bypasses the declared meters. If a shared internal stock exists, it must be accounted in ΔStock\\_inside(q) for **B** to keep conservation exact.\n\n> **Didactic contrast:** Γ\\_method handles **duration** (Σ for serial, max for parallel). Γ\\_work handles **resource** (Σ in both serial and parallel), because resource spending composes additively across disjoint boundary parts and disjoint time slices.\n\n#### B.1.6:6.4 - Multi‑resource vectors and declared equivalences\nΓ\\_work never implicitly converts units. If a planning model needs an exchange (e.g., heat→mechanical, memory→compute), it must be **declared** in `M_spec` (or a domain CAL) as an **equivalence map** `E` applied **before** folding, yielding a new typed basis **E(basis)**. Absent such declaration, vectors remain multi‑dimensional and are added component‑wise.\n\n#### B.1.6:6.5 - Availability gates (weakest‑link discipline)\nMany runs require **critical** inputs (a subset **Q\\*** of the basis) to be present at or above a threshold. Let `Avail_B(q*)` be the measurable availability for `q* ∈ Q*` on boundary B during τ. Then feasibility is constrained by:\n\n```\nWork_B(q*) ≤ Avail_B(q*),  for all q* ∈ Q*\n```\n\nIf any inequality is violated, the fold **must fail** or the modeller must declare a **Meta‑Holon Transition (B.2)** that introduces redundancy/substitution as a new structural capability (changing Q\\* or the equivalence map). This is WLNK in resource form.\n",
        "b.1.6:7___embodiment_and_dissipation_(reporting_scheme)": "### B.1.6:7 - Embodiment and dissipation (reporting scheme)\n\nEvery Work vector **MAY** be split into two projections, both defined on the **same basis** and the **same boundary/time window**:\n\n* **Embodied\\_B(q)** — the part of Work retained **inside** B as *state change* of produced holons (e.g., latent heat stored, material incorporated, committed data).\n* **Dissipated\\_B(q)** — the part of Work irreversibly exported beyond B (e.g., heat loss, scrap, discarded packets).\n\nBy norm:\n\n```\nWork_B(q) = Embodied_B(q) + Dissipated_B(q)\n```\n\nThis split is **informative**, not a second algebra: Γ\\_work always folds the **total** Work; the split is attached in the **Boundary Ledger** for transparency.\n\n",
        "b.1.6:8___invariants_—_edge_cases_and_proof_sketches": "### B.1.6:8 - Invariants — edge cases and proof sketches\n\n#### B.1.6:8.1 - IDEM (idempotence)\nIf `R` has one resource node, no `consumes/produces/transfers` edges, and ΔStock\\_inside(q)=0, then\n\n```\nWork_B(q) = 0  (the zero vector)\n```\n\nTrivial by definition: no measured delta across B implies zero Work.\n\n#### B.1.6:8.2 - COMM/LOC (local commutativity / locality)\nLet `R` factor into independent subgraphs `{Rᵢ}` whose boundary partitions `{Bᵢ}` are disjoint and cover **B** (6.1). Since each `Work_Bi` is evaluated with its own meters and time slices (6.2), and vector addition is commutative/associative, any local fold order yields the same `Σ_i Work_Bi`. Hence Γ\\_work inherits commutativity/locality **under independence**.\n*Note:* If subgraphs share a stock variable, independence fails and the modeller must either (i) refactor boundaries to restore independence, or (ii) model the shared stock explicitly in ΔStock\\_inside(q) for the **parent** B.\n\n#### B.1.6:8.3 - WLNK (weakest‑link)\nLet **Q\\*** be the critical input set with availability caps `Avail_B(q*)`. Since the delta definition measures **net** consumption across B (inflow–outflow–Δstock), and no external creation is allowed, each `Work_B(q*)` cannot exceed `Avail_B(q*)`. If the plan suggests more, you have either (a) a measurement error, (b) a missing equivalence declaration in `M_spec`, or (c) a true emergent synergy that must be modelled as **MHT** (new redundancy/substitution capability).\n\n#### B.1.6:8.4 - MONO (monotonicity)\nMonotonicity is interpreted along three characteristics; in all cases “improvement” never makes the whole **worse** (i.e., never increases required Work nor decreases feasibility):\n\n* **Availability monotonicity:** Increasing `Avail_B(q)` for any non‑critical q leaves `Work_B(q)` unchanged (availability is not auto‑consumed); increasing it for a critical q cannot increase `Work_B(q)` and weakly increases feasibility.\n* **Yield monotonicity (η):** For a fixed output target, increasing declared or measured **η** weakly **decreases** the required `Work_B(q)` in the inputs, never increases it.\n* **Loss monotonicity:** Decreasing dissipation (better insulation, better compression) weakly **decreases** `Dissipated_B(q)`; total Work cannot go up as a result.\n\n#### B.1.6:8.5 - Compatibility with Γ\\_method\nLet a process be composed by Γ\\_method from steps `{S_k}`, each with its own boundary partition `{B_k}` and time slice `{τ_k}`. If independence holds between steps at the resource boundary level (no hidden cross‑leaks), the summed Work\n\n```\nΣ_k Work_Bk(q, τ_k)\n```\n\nis invariant to any topological sort consistent with Γ\\_method’s order (Γ\\_method may change *when* costs are incurred; Γ\\_work adds *how much* is spent).\n\n**Manager note.** When reviewing a plan, inspect **Γ\\_method** (is the order/capability sound?). When reviewing results, inspect **Γ\\_work** (do the boundary‑relative deltas and units make sense?). Use **PhaseOf** to align both views over time.\n",
        "archetypal_grounding": "### B.1.6:9 - Archetypal grounding (System / Episteme)\n\n| Facet                       | **U.System — Assembling a heat‑treated frame**                                                                      | **U.Episteme — Training and publishing a model**                                                                                     |\n| --------------------------- | ------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------ |\n| **Boundary**                | The enclosure boundary of the frame workstation; ports for electricity, gas, material in/out.                       | The boundary of the knowledge artefact: data ingress, model artefact egress, compute energy ingress.                                 |\n| **Work definition**         | Electricity and fuel inflows minus outflows minus Δstock of materials and thermal content retained in the frame.    | Energy spent (compute) + data‑read deltas; Embodied work includes the stored parameters (as committed bytes) and archived SCRs. |\n| **Embodied vs Dissipated**  | Embodied: material incorporated, latent heat retained; Dissipated: heat loss, scrap.                                | Embodied: parameter file written, proof artefacts; Dissipated: energy to heat, discarded intermediate data.                          |\n| **Additivity across parts** | Ports on furnace, press, conveyor are `Bᵢ`; total frame‑level Work is Σ over `Bᵢ`.                                  | Data‑read over dataset shards are `Bᵢ`; total training Work adds per‑shard deltas.                                                   |\n| **Time slicing**            | Heat → dwell → quench phases are `PhaseOf`; Work adds: Σ over phases.                                               | Epochs are `PhaseOf`; Work adds across epochs.                                                                                       |\n| **WLNK**                    | Gas supply cap limits feasible heat cycles (critical input); if redundancy is added (dual supply), model it as MHT. | Storage bandwidth caps data‑read; adding a cache hierarchy is MHT (new structural capability), not “free” efficiency.                |\n\n",
        "conformance_checklist": "### B.1.6:10 - Conformance Checklist (complete)\n\n| ID            | Requirement                                                                                                                                     | Purpose                                               |\n| ------------- | ----------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------- |\n| **CC‑B1.6.1** | Every Γ\\_work result SHALL include a **Boundary Ledger**: boundary, time window, basis, method context, transformer identity.                   | Make Work statements comparable and auditable (A.10). |\n| **CC‑B1.6.2** | Resource vectors SHALL be **typed**; no implicit unit conversions. Any equivalence MUST be declared in `M_spec` (or a domain architheory).      | Prevent silent inflation/deflation.                   |\n| **CC‑B1.6.3** | Resource stocks SHALL be structured with `PortionOf` and `PhaseOf`; `MemberOf` MUST NOT be used for resource mereology.                         | Align with A.14 and prevent category errors.          |\n| **CC‑B1.6.4** | For partitioned boundaries `{Bᵢ}` the fold MUST satisfy partition additivity and document the partition.                                        | Enable cross‑scale roll‑ups.                          |\n| **CC‑B1.6.5** | For time slicing `{τⱼ}` the fold MUST satisfy temporal additivity with non‑overlapping slices (Γ\\_time‑compatible).                             | Keep history coherent.                                |\n| **CC‑B1.6.6** | Critical inputs **Q\\*** and their availability caps MUST be explicit; any violation SHALL cause the fold to fail or require an MHT declaration. | Enforce WLNK conservatism.                            |\n| **CC‑B1.6.7** | If a shared internal stock exists between sub‑boundaries, it MUST be modelled in ΔStock\\_inside(q) at the **parent** boundary level.            | Preserve conservation and COMM/LOC preconditions.     |\n| **CC‑B1.6.8** | When `M_spec` declares a yield η, the report SHALL separate **planned** (ex‑ante) and **measured** (ex‑post) Work.                              | Keep planning distinct from accounting (A.15).        |\n| **CC‑B1.6.9** | Γ\\_work SHALL provide proofs of the invariant quintet under the independence assumptions used, or explicitly state where MHT is required.       | Maintain B.1 guarantees.                              |\n\n",
        "consequences": "### B.1.6:11 - Consequences\n\n**Benefits**\n\n* **Audit‑ready costing:** A single definition of Work makes multi‑scale totals consistent and comparable.\n* **Separation of concerns:** Control‑flow (Γ\\_method) never contaminates cost accounting (Γ\\_work).\n* **Cross‑scale reliability:** Partition/time additivity gives predictable roll‑ups from parts and phases.\n* **Safety by design:** WLNK gates reveal feasibility limits early; emergence is explicit via MHT.\n\n**Trade‑offs / mitigations**\n\n* **Boundary modelling effort:** Requires explicit ports and stock deltas. *Mitigation:* use A.14 templates for common boundary patterns.\n* **Vector heterogeneity:** Mixed units can be hard to read. *Mitigation:* keep vectors typed; add equivalence maps only when justified in `M_spec`.\n* **Independence discipline:** Shared stocks complicate additivity. *Mitigation:* elevate stock accounting to the parent boundary per CC‑B1.6.7.\n\n",
        "rationale": "### B.1.6:12 - Rationale (informative)\n\nΓ\\_work is a conservative algebra of **spent resources**. It respects physical conservation (mass/energy), supports information‑centric resources without conflation, and keeps the **design‑time** (MethodDescription) separate from **run‑time** (Method) facts (A.15). Additivity over disjoint boundaries and non‑overlapping phases is the minimal set of rules that yields stable cross‑scale accounting while remaining faithful to the universal invariants of B.1. Emergent efficiency (redundancy, substitution) is not “free”: it is made structural via **Meta‑Holon Transition** (B.2), after which the same algebra applies at the new level.\n\n",
        "relations": "### B.1.6:13 - Relations\n\n* **Builds on:** A.12 **Transformer Principle**; A.14 **Mereology Extension** (PortionOf, PhaseOf); A.15 **Strict Distinction** (MethodDescription / Method / Work).\n* **Coordinates with:** B.1.5 **Γ\\_method** (order and concurrency), B.1.4 **Γ\\_time** (temporal coverage), B.1.2 **Γ\\_sys** (system assembly).\n* **Triggers:** B.2 **Meta‑Holon Transition (MHT): Recognizing Emergence and Re‑identifying Wholes** when feasibility constraints (WLNK) are beaten by structural redundancy/substitution.\n* **Feeds:** B.3 **Trust & Assurance Calculus (F–G–R with Congruence)** (cost‑aware confidence overlays) — informative only, without altering Γ\\_work’s conservation semantics.\n\n> **Summary for practitioners.**\n> Use **Γ\\_method** to say **what happens and in which order**.\n> Use **Γ\\_work** to say **what it costs across a boundary**.\n> Keep boundaries, time windows, units, yields, and transformers explicit.\n> When apparent “free gains” appear, declare the structural change (MHT) and apply the same algebra one level up.\n",
        "b.1.6:end": "### B.1.6:End\n"
      },
      "content": "### B.1.6:End\n",
      "metadata": {},
      "part": "B",
      "cluster": null
    },
    {
      "id": "B.2",
      "title": "Meta‑Holon Transition (MHT): Recognizing Emergence and Re‑identifying Wholes",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## B.2 - Meta‑Holon Transition (MHT): Recognizing Emergence and Re‑identifying Wholes\n\n> **Plain‑English headline.**\n> When composition yields a **new, coherent whole**—with its **own boundary**, **objective**, and **capabilities** that cannot be faithfully treated as “just parts folded together”—declare a **Meta‑Holon Transition**. Record the **event** that created the new holon and let the Γ‑invariants apply **anew** at the higher level.\n",
        "problem": "### B.2:2 - Problem\n\nWithout an explicit MHT pattern, four pathologies recur:\n\n1. **Invariant evasion:** When redundancy or coordination lifts performance above the **weakest‑link** bound, authors “massage” arithmetic instead of acknowledging **new structure/closure**.\n2. **Identity drift:** A system changes boundary, objective, or supervisory structure, yet the model silently treats it as the “same holon,” corrupting histories (**Γ\\_time**) and claims (**B.3**).\n3. **Context leakage:** A composite crosses a **bounded context** (new vocabulary, units, policy), but the model keeps scoring in the old context, inflating **R\\_eff** by ignoring **congruence penalties**.\n4. **Order/time confusion:** Genuinely **order‑dependent synergies** (Γ\\_ctx/Γ\\_method) or **phase consolidations** (Γ\\_time) are misrepresented as simple structural sums (Γ\\_sys), losing causal and temporal meaning.\n\n",
        "forces": "### B.2:3 - Forces\n\n| Force                                       | Tension                                                                                                                                                     |\n| ------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **Parsimony vs. Expressivity**              | Keep the core algebra small (A.11) ↔ Admit real emergence when closure or supervision appears.                                                              |\n| **Continuity vs. Re‑identification**        | Preserve identity across phases where warranted ↔ Re‑identify when boundary/objective/capability qualitatively change.                                      |\n| **Local vs. Systemic**                      | Local improvements should stay inside MONO ↔ System‑level novelties must **restart** invariants at a new level.                                             |\n| **DDD familiarity vs. Ontological clarity** | Reuse intuitions from **bounded contexts** and **events** ↔ Keep them mapped to FPF’s holons, boundaries, and transformers without tool‑specific semantics. |\n\n",
        "solution": "### B.2:4 - Solution — **Part 1: What an MHT is, when to declare it, and how it relates to Γ**\n\n#### B.2:4.1 - Definition (normative)\n\nA **Meta‑Holon Transition (MHT)** is a **declared event** in which a configuration of holons—previously related by Γ‑composition in some flavour—**is promoted** to a **new holon** `H⁺` with a **new or revised**:\n\n* **Boundary** (external interface and enclosure, per A.14/B.1.2),\n* **Objective / Evaluation basis** (what `H⁺` tries to maintain/achieve), and/or\n* **Supervisory structure / Capability** (closed feedback, decision loop, policy enactment).\n\nAfter MHT, the Γ‑invariants apply **afresh** to `H⁺` and its parts. Prior assurance (B.3) remains valid for **pre‑MHT** claims; **post‑MHT** claims are assessed for `H⁺` under its own boundary, objective, and context.\n\n> **Didactic guard‑rail.**\n> If a perceived “synergy” is fully explainable **within the current Γ‑flavour**—e.g., by raising congruence **CL**, improving parts (MONO), or fixing order (Γ\\_ctx)—**do not** declare MHT. MHT is reserved for **new closure** or **new supervision** that changes what counts as “the whole”.\n\n\n#### B.2:4.2 - Triggers for declaring MHT (BOSC‑A‑T‑X)\n\nDeclare MHT when one or more of the following **observable triggers** occur (measurements are recorded in the promotion record):\n\n* **B — Boundary closure/opening.** A coherent external boundary emerges (e.g., internal interfaces encapsulated; single regulated port) or its **type** changes (open ↔ closed/permeable) such that the system’s external commitments are different.\n* **O — Objective emergence/reframe.** A new objective is instituted (e.g., regulation target introduced) or a prior objective becomes subordinate to a supervisory objective.\n* **S — Structural re‑organization for supervision.** New **coordination channels** or a feedback loop close a circuit that **did not exist** at the previous level, producing regulation or self‑maintenance.\n* **C — Capability super‑additivity (beyond WLNK).** Measured capability (or assurance) exceeds the **weakest‑link** bound **without** being explainable by improved parts or higher **CL** under the current Γ semantics.\n* **A — Agency threshold crossing (A.13).** The holon begins to **play AgentialRole** with an **agency grade** sufficient to maintain objectives autonomously; this lifts the system into a supervisory regime.\n* **T — Temporal consolidation.** Across **Γ\\_time** phases, properties consolidate into a qualitatively new regime (e.g., commissioning → operational service) that **re‑anchors identity** or boundary.\n* **X — Context rebase (bounded context).** The holon’s operative **vocabulary/units/policy** shift to a **new bounded context** (in DDD sense), requiring a new **Assurance context** and CL baselines.\n\n> **Rule of thumb.**\n> BOSC touches **what the holon is**; A/T/X touch **how and where it lives** (agency, time, context). Any **two** of these together almost always warrant MHT.\n\n\n#### B.2:4.3 - Identity stance: 4D vs. 3D+1 (FPF’s ecumenical Standard)\n\nFPF permits both readings **provided** you make **identity and event claims explicit**:\n\n* **4D Standard:**\n\n  * Pre‑MHT configuration is a set of world‑tube segments linked by Γ.\n  * The **MHT event** marks the start of a **new tube** `H⁺`; earlier segments remain as precursors.\n  * `PhaseOf` refers to **temporal parts**; **events** are boundaries between parts (and between tubes at MHT).\n\n* **3D+1 Standard:**\n\n  * Pre‑MHT configuration is an enduring holon with time‑indexed states.\n  * The **MHT event** is a creation event for **a new enduring holon** `H⁺`; a mapping relates `H⁺` to predecessors.\n  * `PhaseOf` refers to **states**; **events** are transitions; MHT is a re‑identification point.\n\n**Normative bridge:** Regardless of stance, you **must** (i) state whether identity **continues** (PhaseOf) or a **new identity** is created, and (ii) record the **Transformer** that performs the MHT.\n\n\n#### B.2:4.4 - Event taxonomy for MHT (small, reusable set)\n\nTo avoid ad‑hoc naming, choose one **event type** (or a pair) and fill its parameters:\n\n1. **Fusion** — several holons become `H⁺` with a new boundary/objective/supervision.\n2. **Fission** — one holon splits into several peers, each with a proper boundary/objective.\n3. **Phase Promotion** — a **Γ\\_time** phase boundary coincides with BOSC‑A‑T‑X conditions; identity is re‑anchored to `H⁺`.\n4. **Role‑Lift** — the holon starts **playing AgentialRole** at or above a declared grade threshold (A.13), enabling supervision.\n5. **Context Reframe** — the holon’s bounded context shifts (terminology/units/policy), establishing `H⁺` in the **new context**; mappings to the prior context are recorded.\n\nThese are **Transformer events** (A.12). They do **not** imply toolchains or storage; they are conceptual commitments with audit fields.\n\n\n#### B.2:4.5 - How MHT relates to Γ‑flavours and bounded contexts\n\n* **With Γ\\_sys / Γ\\_epist (structure):**\n\n  * If measured capability or assurance exceeds **WLNK** under current semantics, and the excess **cannot** be explained by **part improvements** or **CL** increases, **do not bend arithmetic**—declare MHT.\n  * After MHT, the new holon `H⁺` re‑establishes its own WLNK/CL baselines.\n\n* **With Γ\\_ctx / Γ\\_method (order):**\n\n  * If introducing order/joins **creates a closed supervisory loop** that maintains an objective (e.g., sense → decide → actuate), declare **Role‑Lift** or **Fusion** MHT.\n  * If order simply fixes a previously mis‑modelled sequence, that is **not** MHT; it is a normal correction under Γ\\_ctx.\n\n* **With Γ\\_time (phases):**\n\n  * Use **PhaseOf** for normal state progressions where identity continues.\n  * If a phase boundary coincides with BOSC‑A‑T‑X, **Phase Promotion** MHT creates `H⁺`; histories remain linked but assurances are **not silently merged**.\n\n* **With bounded contexts (DDD intuition):**\n\n  * A **bounded context** is a **modelling Standard** (vocabulary/units/policy). Crossing it without re‑baselining **CL** causes **trust inflation**.\n  * Use **Context Reframe** MHT to re‑anchor `H⁺` in the new context and declare the mappings; B.3’s congruence penalty `Φ(CL)` now refers to the **new** baseline.\n\n\n#### B.2:4.6 - What MHT is *not* (didactic contrasts)\n\n* **Not a shortcut around WLNK/Φ.** If synergy is explainable by raising `CL` or improving parts, stay within Γ and B.3.\n* **Not every KPI jump.** If the jump is within the declared envelope and context, **no** MHT is needed.\n* **Not a version bump.** Version changes (`PhaseOf`) with the **same identity** are **Γ\\_time**, not MHT.\n* **Not “agent = new type.”** Agency is **a role** (A.13); MHT only when role enactment **changes closure/supervision** at the system level.\n",
        "promotion_record_&_proof_obligations_(normative)": "### B.2:5 - Promotion Record & proof obligations (normative)\n\nTo declare an MHT you MUST create a **Promotion Record** that makes identity, boundary, objective, supervision, and context shifts explicit. This record extends the general proof kit in **B.1.1**.\n\n#### B.2:5.1 - Promotion Record — minimal fields\n\n```\nMHT.PromotionRecord\n  id:                unique identifier\n  eventType:         one of {Fusion | Fission | PhasePromotion | Role‑Lift | ContextReframe}\n  transformer:       U.TransformerRole (who/what enacted the transition)\n  identityStance:    one of {4D | 3D+1}\n  preConfig:\n    nodes:           list of holons (ids, kinds) involved before MHT\n    edges:           list of relations & their types (A.14), including CL on integration edges\n    Γflavour:        active Γ-flavour(s) prior to MHT\n    assurance:       Assurance tuples for relevant claims before MHT (B.3)\n    boundedContext:  name or description (vocabulary/units/policy) before MHT\n  triggers:\n    BOSC:            {B? O? S? C?} with measurements/artefacts\n    A?               Agency-CHR grade & context (A.13)\n    T?               Γ\\_time phase boundary details (coverage, carrier identity/continuation)\n    X?               context mapping summary (old↔new)\n  postHolon (H⁺):\n    boundary:        explicit BIC or equivalent boundary statement (B.1.2)\n    objective:       objective(s) and evaluation basis for H⁺\n    supervision:     supervisory/feedback structure present in H⁺ (if any)\n    Γflavour:        Γ-flavour(s) intended for H⁺\n    assurance:       initial Assurance(H⁺, C | K, S) with F/G/R & CL baselines\n    boundedContext:  new context; mapping to previous (with CL for mappings)\n  identityMapping:\n    4D:              continuity/cut specification (precursors→H⁺ tube start)\n    3D+1:            predecessor(s) and creation event; any PhaseOf segments preserved\n  notes:\n    alternativesConsidered:   why not modelled as non‑MHT Γ improvement\n    EvidenceGraphRef:          references to measurements, specs, interface Standards, tests\n    orderTimeRefs:            OrderSpec/TimeWindow if Γ\\_ctx/Γ\\_time material\n```\n\n#### B.2:5.2 - Proof obligations specific to MHT\n\n* **MHT‑BOSC‑EVD.** For each selected trigger (B/O/S/C/A/T/X), attach the artefacts that evidence it (e.g., boundary Standard for **B**, policy/regulation objective text for **O**, controller‑plant diagram for **S**, capability measurement vs WLNK bound for **C**, Agency‑CHR record for **A**, phase coverage & carrier identity for **T**, context mapping & unit schemes for **X**).\n\n* **MHT‑NO‑EVADE.** Show that the observed improvement cannot be explained by **within‑Γ** moves alone: improved parts (MONO), raised congruence CL, corrected order (Γ\\_ctx), or richer phase coverage (Γ\\_time). If any of those suffice, **MHT is not justified**.\n\n* **MHT‑ASS‑REBAS.** Provide **before/after** assurance tuples (B.3) for the same typed claim(s) or justify claim changes; do not fuse design/run scopes.\n\n* **MHT‑IDENT.** State identity stance (4D or 3D+1) and the identity mapping (continuation vs new identity). Mixing stances in the same record is forbidden.\n\n* **MHT‑CTX‑MAP.** For **ContextReframe**, list the concept/unit/terminology mappings and their CL levels; record the **new CL baseline** for future aggregations.\n\n",
        "archetypal_cases_(worked,_didactic)": "### B.2:6 - Archetypal cases (worked, didactic)\n\n#### B.2:6.1 - System — **Closed‑loop regulation emerges from components** (Fusion / Role‑Lift)\n\n* **Pre‑config:** Plant, sensor, actuator exist; analyses show performance capped by **WLNK** path through the slowest actuator; interfaces calibrated at CL2. No supervisory closure.\n\n* **Trigger:** **S** (supervisory structure closes a feedback loop) and **B** (boundary now exports a single regulated interface; internal ports encapsulated). Capability exceeds prior WLNK bound without any part upgrade.\n\n* **MHT:** Declare **Fusion** (or **Role‑Lift** if the controller plays AgentialRole). Create `H⁺ = RegulatedSystem` with BIC exposing the regulated port and supervisory objective (“maintain y≈r”).\n\n* **After:** Γ‑invariants re‑start for `H⁺`. **B.3** assurance uses a new cutset; congruence on controller–plant mapping is part of `CL_min`.\n\n* **Why not within‑Γ?** The performance jump is not due to improved parts or raised CL on existing edges; it stems from **new closure**.\n\n#### B.2:6.2 - Episteme — **From compendium to theory** (Fusion / ContextReframe)\n\n* **Pre‑config:** Several high‑quality results integrated as a catalogue; mappings among constructs are at CL1 (loose analogies).\n\n* **Trigger:** **O** (a unifying explanatory **objective**: predict & explain class Q), **C** (explanatory success beyond min of parts), **X** (terminology reframed around new primitives with verified mapping at CL2/CL3).\n\n* **MHT:** **Fusion** + **ContextReframe** to `H⁺ = Theory_T` with an explanatory objective; mappings to the prior compendium are documented.\n\n* **After:** Assurance for “explains Q within δ” starts at `H⁺` with its own `F_eff` (may rise if formalized), `G_eff` (supported domain), and `R_eff` penalized by the **new** mapping CL.\n\n#### B.2:6.3 - Temporal — **Commissioning → Operations** (PhasePromotion)\n\n* **Pre‑config:** `PhaseOf` slices (install, calibrate, trial). Identity of the same carrier is maintained.\n\n* **Trigger:** **T** (phase boundary) plus **B** (boundary type changes: open commissioning ports are encapsulated) and **O** (objective shifts from “achieve acceptance tests” to “deliver service SLA”).\n\n* **MHT:** **PhasePromotion** creates `H⁺ = System‑in‑Operation`. Past phases remain as documented temporal parts; design‑time assurance is not mixed with run‑time assurance.\n\n#### B.2:6.4 - Context — **Prototype → Certified product** (ContextReframe)\n\n* **Pre‑config:** Prototype in a lab context with ad‑hoc units and informal safety claims.\n\n* **Trigger:** **X** (bounded context shifts to regulated environment), **F rises** (formal safety case), **CL** for unit/requirement mappings vetted.\n\n* **MHT:** **ContextReframe** to `H⁺ = CertifiedProduct`; new **BIC** and regulatory vocabulary become the baseline; earlier lab claims are not silently “ported”.\n\n",
        "b.2:6.5___certification_interface_example_*(informative)*": "### B.2:6.5 - Certification Interface Example *(Informative)*\n\nConceptual signature (notation‑neutral):\n\n```\ncertify(role, context, window, snapshot, options) → StateAssertion\n```\n\n**Sketch.** `snapshot` contains coordinates over the Role’s RCS (A.19). `options` may reference named **NormalizationMethod(s)**/**NormalizationMethodInstance(s)** and overlays used in evaluation. The resulting **StateAssertion** states the target state (by name), the checklist applied (by name), the verdict, the window, and (if used) the **declared** **Bridge** or **NormalizationMethodInstance** employed for translation.  \n**Intent.** This example aids implementers; **normative constraints** on comparability, normalization, and evidence live in **A.19** and **C.16**, not here.\n",
        "conformance_checklist": "### B.2:7 - Conformance Checklist (normative)\n\n| ID          | Requirement                                                                                                                     | Purpose                                            |\n| ----------- | ------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------- |\n| **CC‑B2.1** | An MHT MUST have a **Promotion Record** with fields in §5.1 completed and **identityStance** chosen.                            | Avoid ambiguous identity shifts.                   |\n| **CC‑B2.2** | MHT MAY be declared only when at least **one BOSC‑A‑T‑X** trigger is evidenced and **MHT‑NO‑EVADE** holds.                      | Prevent “emergence by arithmetic”.                 |\n| **CC‑B2.3** | Post‑MHT holon `H⁺` MUST provide **BIC** (boundary), an **objective** statement, and (if present) a supervisory description.    | Re‑anchor what the whole **is**.                   |\n| **CC‑B2.4** | Pre‑ and post‑assurance MUST be reported as **separate** tuples (B.3).                                                          | No design/run or context chimeras.                 |\n| **CC‑B2.5** | **ContextReframe** MHT MUST include the mapping set and CL levels; **R\\_eff** thereafter uses the **new CL baseline**.          | Make context explicit; reset penalties coherently. |\n| **CC‑B2.6** | **PhasePromotion** MUST state whether identity continues (4D: new tube start; 3D+1: new enduring holon) and justify the choice. | Keep temporal semantics clear.                     |\n| **CC‑B2.7** | **Role‑Lift** MUST reference Agency‑CHR but MUST NOT use agency to bypass WLNK or CL penalties.                                 | Preserve safety invariants.                        |\n\n",
        "anti‑patterns_&_repairs": "### B.2:8 - Anti‑patterns & repairs\n\n| Anti‑pattern               | Symptom                                                 | Repair                                                                              |\n| -------------------------- | ------------------------------------------------------- | ----------------------------------------------------------------------------------- |\n| **Emergence by averaging** | Post‑composition KPI > WLNK, justified by means/weights | Declare MHT only if BOSC/S is met; otherwise raise CL or improve parts within Γ.    |\n| **Invisible context hop**  | New units/terms silently adopted                        | Use **ContextReframe**; record mappings and CL; re‑baseline assurance.              |\n| **Every phase = MHT**      | Each version treated as a new holon                     | Use **PhaseOf** for ordinary state progressions; reserve MHT for BOSC‑A‑T‑X.        |\n| **Agency as type**         | Introduce `U.Agent` and claim new identity              | Keep agency as role (A.13); MHT only if supervision/closure changes the whole.      |\n| **Boundary amnesia**       | Interfaces changed but not recorded                     | Update BIC; if external commitments change materially, declare MHT.                 |\n| **Order magic**            | Reordering steps treated as emergence                   | If order fixes correctness (Γ\\_ctx), no MHT; only closed loops/supervision qualify. |\n\n",
        "consequences": "### B.2:9 - Consequences\n\n**Benefits**\n\n* **Clarity & auditability.** Distinguishes **improvement within a level** from **creation of a new whole**.\n* **Invariant integrity.** WLNK and CL penalties are preserved; when a new whole appears, invariants restart cleanly.\n* **Method‑agnostic synergy.** Works with both **4D** and **3D+1** readings; dovetails with DDD’s **bounded contexts** and event‑centric modelling.\n* **Easier assurance management.** Pre/post claims are comparable without being conflated; teams can plan targeted moves (raise CL, formalize, reframe context).\n\n**Trade‑offs**\n\n* **Extra documentation at the right time.** Declaring MHT is deliberate; it requires a Promotion Record and evidence.\n* **Identity bookkeeping.** Teams must choose an identity stance and be consistent; this cost buys cross‑scale coherence.\n\n",
        "rationale": "### B.2:10 - Rationale (informative)\n\n* **Systems & control:** Closing feedback creates **new closed‑loop properties** not attributable to parts alone; treating this as an MHT avoids “synergy by arithmetic” and aligns with classical supervisory control and contemporary active‑inference views (A.13).\n* **Mereology & identity:** By remaining **ecumenical** (4D or 3D+1) but **Standardual** about identity declarations, FPF stays compatible with traditions akin to **BORO** (4D‑leaning) and **CCO** (endurantist uses), while keeping proofs unambiguous.\n* **DDD/Event‑centric modelling:** Popular practices (bounded contexts, event storming) pivot on **events** and **context boundaries**. MHT makes such events **first‑class** in FPF, turns context hops into explicit **ContextReframe** transitions, and ties them to assurance via **CL baselines**.\n* **Assurance discipline:** Re‑baselining **F/G/R** and **CL** at MHT points prevents cross‑context overconfidence and enables principled improvement plans.\n\n",
        "relations": "### B.2:11 - Relations\n\n* **Builds on:** A.12 (Transformer), A.13 (AgentialRole & Agency‑CHR), A.14 (Mereology Extension), A.15 (Strict Distinction); B.1.x (Γ flavours), B.3 (Assurance).\n* **Used by:** B.4 (Evolution Loops: MHT as macro‑steps on the loop), KD‑CAL action patterns (when re‑framing models/theories).\n* **Complements:** B.1.4 (Γ\\_ctx/Γ\\_time) by distinguishing **order/phase** corrections from **emergence**; B.1.2/B.1.3 by restarting compositional invariants at the new level.\n\n> **One‑sentence takeaway.**\n> **Declare MHT** when closure, supervision, or context re‑base creates a **new whole**; document the event, reset invariants, and keep pre/post assurance cleanly separated.\n",
        "b.2:end": "### B.2:End\n\n| B.2.1   | BOSC Triggers                            | Boundary • Objective • Supervisor • Complexity.                           |\n"
      },
      "content": "### B.2:End\n\n| B.2.1   | BOSC Triggers                            | Boundary • Objective • Supervisor • Complexity.                           |\n",
      "metadata": {},
      "part": "B",
      "cluster": null
    },
    {
      "id": "B.2.2",
      "title": "Meta-System Transition (MST)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## B.2.2 - Meta-System Transition (MST)\n",
        "problem": "### B.2.2:2 - **Problem**\n\nWhen a collection of systems begins to coordinate, managers and engineers face a critical decision point. If they continue to treat the aggregate as just a \"bag of parts,\" they fall victim to several pathologies:\n\n1.  **Reductive Blindness:** They miss emergent, system-level hazards (like cascade failures or swarm oscillations) because their analysis remains focused on individual component reliability.\n2.  **Accountability Vacuum:** There is no clear owner for the *collective's* behavior. When the swarm fails, who is responsible? The operator of drone A or drone B?\n3.  **Invalid Assurance Transfer:** A safety case or performance guarantee that was valid for an individual system may be silently invalidated by its interactions within the collective, but this goes unnoticed.\n",
        "forces": "### B.2.2:3 - **Forces**\n\n| Force | Tension |\n| :--- | :--- |\n| **Local Autonomy vs. Global Coherence** | How to allow individual systems to operate efficiently while ensuring their actions contribute to a stable and predictable collective goal. |\n| **Bottom-up Emergence vs. Top-down Design**| Is the new meta-system an unplanned, emergent phenomenon to be managed, or a deliberately designed system-of-systems to be constructed? |\n| **Performance vs. Predictability** | Tightly coupled coordination can unlock new capabilities, but it can also introduce complex, hard-to-predict failure modes. |\n",
        "solution": "### B.2.2:4 - **Solution**\n\nAn MST (Sys) is a formal promotion of an aggregate of `U.System`s to a new, single `U.System` holon. This promotion is not a subjective decision; it is a **mandatory modeling step** triggered when the aggregate demonstrably satisfies the **B-O-S-C** criteria, adapted for systems.\n\n#### B.2.2:4.1 - The B-O-S-C Triggers for Systems\n\nThe four triggers from the parent MHT pattern are interpreted in the context of physical and cyber-physical systems:\n\n| Trigger | System-Specific Interpretation | Manager's View: The \"Go/No-Go\" Question |\n| :--- | :--- | :--- |\n| **B - Boundary Closure**| The aggregate now exposes a single, unified **operational interface** (e.g., a single API gateway, a master control port). Internal system-to-system interactions are encapsulated and hidden from the outside world. | \"Can I now operate this entire collection through a single dashboard or Standard, without having to talk to each individual part?\" |\n| **O - Objective Emergence**| The collective pursues a new, measurable **operational objective** that did not exist for any individual system (e.g., maintaining a formation, maximizing fleet-wide energy efficiency, minimizing global latency). | \"Is this group now working towards a shared goal that is fundamentally different from what each member was doing alone?\" |\n| **S - Supervisor Emergence**| A new **control loop** appears. The collective state is measured, and this information is used to actively regulate the behavior of the individual systems to achieve the new objective. | \"Is there a mechanism—whether a central brain or a distributed consensus—that is actively steering the parts to work together?\" |\n| **C - Complexity Threshold** | The number and intensity of interactions between systems cross a point where reasoning about them as a whole is simpler and more predictive than tracking every pairwise interaction. | \"Have we reached the point where trying to manage every individual interaction is causing more problems than it solves?\" |\n\nWhen all four conditions are met, the collection **must be** re-identified as a new `U.System` via the `emergesAs` relation.\n\n> **Didactic Note for Managers: From \"A Bunch of Drones\" to \"The Swarm\"**\n>\n> An MST is the formal moment when you stop managing a collection of individual assets and start managing a new, single capability.\n>\n> *   **Before MST:** You have ten individual drones. You manage ten maintenance schedules, ten flight plans, ten risk assessments. Your primary concern is the reliability of each drone.\n> *   **After MST:** You have **one** search-and-rescue swarm. You manage **one** mission objective (e.g., \"cover this area\"), **one** collective health metric, and **one** set of swarm-level risks (e.g., \"risk of collective oscillation\").\n>\n> Declaring an MST is an act of architectural honesty. It forces you to update your management, assurance, and governance models to match the new reality that has emerged.\n",
        "archetypal_grounding": "### B.2.2:5 - **Archetypal Grounding**\n\n| Domain | Constituent `U.System`s | Emergent Meta-System (`U.System`) | Key Trigger Evidence (B-O-S-C) |\n| :--- | :--- | :--- | :--- |\n| **Cloud Computing** | A set of independent, containerized microservices. | An **autonomous cloud platform**. | **B:** A single API gateway and control plane now mediate all external traffic. **O:** A new system-wide SLO (Service Level Objective) for end-to-end latency is enforced. **S:** A Kubernetes-like orchestrator (the supervisor) actively schedules, scales, and heals the microservices based on global metrics. **C:** The number of services exceeds a threshold where manual pairwise management is no longer feasible. |\n| **Robotics** | A group of individual, autonomous drones with local navigation rules. | A **search-and-rescue swarm**. | **B:** The swarm communicates with the operator via a single command channel. **O:** A new objective emerges: \"collaboratively map and cover a designated area,\" which no single drone pursued. **S:** A distributed leader-election and formation-control algorithm acts as the supervisor. **C:** Swarm behavior becomes stable and predictable only above a certain number of drones (e.g., > 7). |\n| **Socio-Technical** | A group of engineers from Development, QA, and Operations working in separate silos. | A cohesive **DevOps team**. | **B:** The team now presents a single interface to the business: a unified backlog and a single \"definition of done.\" **O:** A new collective objective appears: \"reduce the cycle time from idea to deployment to less than 24 hours.\" **S:** The daily stand-up and CI/CD pipeline act as a supervisory feedback loop, regulating the work of all members. **C:** The complexity of coordinating the three functions separately became a bottleneck. |\n",
        "conformance_checklist": "### B.2.2:6 - **Conformance Checklist**\n\n*   **CC-B2.2.1 (Trigger Mandate):** An `emergesAs` relation for a set of `U.System`s **MUST** be justified by a **Promotion Record** (Pattern B.2) that provides evidence for all four B-O-S-C triggers.\n*   **CC-B2.2.2 (System-Holon Mandate):** Both the constituent parts and the resulting meta-system **MUST** be modeled as `U.System` holons, not as abstract `U.Episteme`s or `U.Method`s.\n*   **CC-B2.2.3 (Supervisor Mandate):** The emergent meta-system **MUST** contain an identifiable **supervisory component** or mechanism that implements the feedback loop. The architecture of this loop is further detailed in Pattern B.2.5.\n*   **CC-B2.2.4 (Boundary Inheritance):** The boundary of the new meta-system **MUST** be formally derived from the boundaries of its constituent systems, following a declared **Boundary-Inheritance Standard** (Pattern B.2.3, forthcoming).\n",
        "anti_patterns": "### B.2.2:7 - **Common Anti-Patterns and How to Avoid Them**\n\n| Anti-Pattern | Manager's View: What It Looks Like | How FPF Prevents It (Conceptually) |\n| :--- | :--- | :--- |\n| **The \"Big Bag of Parts\"** | A collection of systems is given a collective name (e.g., \"The Platform\"), but there is no unified interface, no shared objective, and no active coordination. | **CC-B2.2.1** requires evidence for all four B-O-S-C triggers. A simple collection without boundary closure or a supervisory loop does not qualify for MST. It remains an aggregate, not a meta-system. |\n| **The \"Emergence by Fiat\"** | A manager declares that a new, synergistic capability has emerged, but there is no underlying mechanism to sustain it. The \"improvement\" is a temporary artifact of heroic effort, not a stable property of the system. | **CC-B2.2.3** mandates the existence of an identifiable supervisor. If there is no feedback loop to maintain the new behavior, no MST has occurred. |\n| **The \"Hidden God-Controller\"** | A system appears to be a self-organizing swarm, but its behavior is actually dictated by a hidden, external, centralized controller that is not part of the model. | The FPF's **Transformer Principle (A.12)** and **Boundary rules (A.1)** require that all external influences are made explicit. The controller must either be modeled as part of the meta-system (and thus inside its new boundary) or as an external `Transformer`. |\n",
        "consequences": "### B.2.2:8 - **Consequences**\n\n| Benefits | Trade-offs / Mitigations |\n| :--- | :--- |\n| **Makes Emergence Manageable:** The pattern transforms emergence from a mysterious, unpredictable phenomenon into an explicit, auditable architectural event. This allows managers to assign ownership, budget, and assurance targets to the new meta-system. | **Modeling Overhead:** Formally documenting an MST and its new Standards requires deliberate modeling effort. *Mitigation:* This effort is an investment that pays off by preventing the much higher cost of managing the risks associated with un-recognized emergence. |\n| **Enables Scalable Assurance:** By re-applying the FPF's assurance calculus at the new meta-level, the framework can provide meaningful safety and reliability guarantees for complex systems-of-systems. | - |\n| **Provides a Language for Innovation:** The pattern gives architects and strategists a formal language for designing and reasoning about adaptive, self-organizing, and resilient systems. | - |\n",
        "rationale": "### B.2.2:9 - **Rationale**\n\nThis pattern provides the concrete instantiation of the universal MHT principle for the domain of systems. It is grounded in decades of research in cybernetics (Ashby's law of requisite variety), complexity science, and modern systems-of-systems engineering. By demanding evidence of **Boundary Closure**, a **Novel Objective**, and a **Supervisory Loop**, the pattern provides a robust, falsifiable filter that separates true emergence from mere aggregation.\n\nIt ensures that when we claim a system has \"emergent properties,\" we are not making a vague, philosophical statement, but a precise, testable, architectural one. This rigor is essential for building trustworthy and manageable complex systems.\n",
        "relations": "### B.2.2:10 - **Relations**\n\n*   **Is a specialization of:** `B.2 Meta-Holon Transition (MHT)`.\n*   **Is complemented by:** `B.2.3 MET (KD)` (for epistemic emergence).\n*   **Provides the context for:** `B.2.5 Supervisor–Subsystem Feedback Loop`, which details the architecture of the supervisory mechanism.\n",
        "b.2.2:end": "### B.2.2:End\n"
      },
      "content": "### B.2.2:End\n",
      "metadata": {},
      "part": "B",
      "cluster": null
    },
    {
      "id": "B.2.3",
      "title": "Meta-Epistemic Transition (MET)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## B.2.3 - Meta-Epistemic Transition (MET)\n\n> **Type:** Architectural (A)\n> **Status:** Stable\n> **Normativity:** Normative (unless explicitly marked informative)\n",
        "problem": "### B.2.3:2 - Problem\n\nWithout a formal concept of a Meta‑Epistemic Transition, knowledge programs tend to fall into predictable failure modes:\n\n1. **The “List of Facts” illusion.** A collection of well‑validated epistemes is mistaken for a coherent theory. The “whole” is treated as the sum of parts, and the opportunity for a unifying insight is missed.\n2. **Hidden incoherence.** Contradictions between epistemes are ignored, averaged away, or left unresolved. The result is a fragile collage, not a durable framework.\n3. **Flat explanatory power.** The portfolio can describe phenomena, but cannot explain them through shared principles. There is no “supervisor” that tells the parts how to compose.\n",
        "forces": "### B.2.3:3 - Forces\n\n| Force                         | Tension                                                                                                                           |\n| :---------------------------- | :-------------------------------------------------------------------------------------------------------------------------------- |\n| **Synthesis vs. aggregation** | A true synthesis creates new meaning ↔ a mere aggregation is an index, review, or catalog.                                        |\n| **Purity vs. integration**    | Preserve the integrity and local reliability of each episteme ↔ integrate across different assumptions, scopes, and vocabularies. |\n| **Creativity vs. rigor**      | A unifying theory is an abductive leap ↔ it must remain auditable and bound to evidence (no “narrative by fiat”).                 |\n",
        "solution": "### B.2.3:4 - Solution\n\nA Meta‑Epistemic Transition is modeled as a **Meta‑Holon Transition (B.2)** specialized to knowledge artifacts (typically starting from a `Γ_epist` portfolio and ending in a new `U.Episteme` holon).\n\n#### B.2.3:4.1 - Definition (normative)\n\nA **MET** is a declared MHT event in which a configuration of `U.Episteme`s (often managed as a `Γ_epist` portfolio) is **promoted** to a new, single `U.Episteme` holon via the `emergesAs` relation.\n\n* A MET is an act of **creation**, not passive drift. Therefore the `emergesAs` relation **MUST** be attributed to an explicit external `Transformer` (A.12) that performed the synthesis.\n* A MET declaration **MUST** be supported by a **Promotion Record** (B.2:5.1) containing explicit evidence for the B‑O‑S‑C triggers (B.2.1), interpreted for epistemes as below. The record still carries the parent schema fields (`eventType`, `identityStance`, and the explicit `preConfig/postHolon` deltas); do not “compress” MET into a narrative paragraph.\n* If the synthesis introduces new primitives/terms (i.e., it reframes the vocabulary rather than only summarising), the Promotion Record **SHOULD** treat the event as a `ContextReframe` (or, where the local taxonomy permits paired types, `Fusion + ContextReframe`) and **MUST** satisfy `MHT‑CTX‑MAP`: include the context mapping summary (`triggers.X?`) and record the new `boundedContext` plus its CL baseline in `postHolon.boundedContext` (B.2:5.1, B.2:5.2).\n* Post‑MET trust/assurance for the new meta‑episteme **MUST** be evaluated as a claim about a *new holon*, not silently inherited from the constituents: satisfy `MHT‑ASS‑REBAS` and apply congruence penalties when composing evidence across constituents (see B.2:5.2 and B.3).\n\n#### B.2.3:4.2 - The B-O-S-C triggers for epistemes\n\nThe four B‑O‑S‑C triggers are interpreted in the context of knowledge artifacts.\n\n**C note.** Across the MHT family, **C** appears in two adjacent readings: (i) **Complexity threshold** (manageability of a growing patchwork), and (ii) **capability/explanatory excess beyond a WLNK bound** (the core MHT narrative). This MET pattern uses the **Complexity threshold** reading by default; if you claim explanatory/predictive super‑additivity, record it explicitly as the `triggers.BOSC.C` evidence and tie it to the emergent objective (**O**) and supervisor (**S**) (do not treat it as a shortcut around assurance rebasing).\n\n| Trigger                      | Epistemic-specific interpretation                                                                                                                                                        | Manager’s view: the “Go/No-Go” question                                                                  |\n| :--------------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------- |\n| **B — Boundary closure**     | The collection is presented under a single conceptual boundary: a name, a unified vocabulary, stable definitions, and a shared symbolic representation. It becomes citable as one thing. | “Can we refer to this with a single name and reliably mean the same thing across the organisation?”      |\n| **O — Objective emergence**  | A unifying explanatory or predictive objective emerges that none of the individual epistemes could satisfy alone. The whole answers a bigger question.                                   | “Does this synthesis let us explain or predict something that the parts could not?”                      |\n| **S — Supervisor emergence** | A set of meta-principles, axioms, invariants, or core values is introduced that *governs* how constituent epistemes are interpreted and composed.                                        | “Is there now a ‘golden rule’ that tells us how the pieces fit together?”                                |\n| **C — Complexity threshold** | The web of parts, exceptions, and interrelations becomes more complex to manage than a unifying abstraction. The meta‑episteme is simpler than the patchwork.                            | “Are we drowning in edge cases and local fixes, such that a single framework is now the simpler option?” |\n\nWhen a `Transformer` can provide evidence for all four triggers, it can formally declare a MET, creating a new `U.Episteme` via `emergesAs`.\n\nIn practice, many METs also involve **X (context rebase)** when vocabulary or definitions change. When that happens, the Promotion Record **MUST** carry `triggers.X?` and satisfy `MHT‑CTX‑MAP` (B.2:5.2).\n\n#### B.2.3:4.3 - Didactic note for managers (informative)\n\n> **From a pile of bricks to a cathedral**\n> Before a MET, you have a pile of valuable bricks: reports, models, datasets. Each brick is useful, but they do not yet form a structure.\n> After a MET, a `Transformer` has built a cathedral: a coherent framework with a name (**Boundary**), a purpose (**Objective**), and guiding architectural principles (**Supervisor**).\n> A portfolio becomes capital only when it can be reused as one thing.\n\n#### B.2.3:4.4 - Common anti-patterns and how to avoid them (informative)\n\n| Anti-pattern                           | What it looks like                                                                                                        | How FPF prevents it                                                                                                                                                                                                             |\n| :------------------------------------- | :------------------------------------------------------------------------------------------------------------------------ | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n| **“Grand unifying narrative” fallacy** | A high-level write-up is called a “new theory”, but it adds no new explanatory principle and no new predictive objective. | The MET declaration requires evidence for **O** and **S**, not just summarisation. Without those triggers, the collection remains an aggregate.                                                                                 |\n| **“Forced marriage” of ideas**         | Conflicting epistemes are merged into an incoherent hybrid.                                                               | A MET is not a mechanical merge. The `Transformer` must supply a supervisory principle that reconciles or contextualises the constituents, and the trust model (B.3) penalises incoherent integration via congruence penalties. |\n| **“Ivory tower theory”**               | A beautiful synthesis is detached from evidence; it produces no testable constraints.                                     | The resulting `U.Episteme` is subject to the same assurance discipline as any other: explicit rebasing (`MHT‑ASS‑REBAS`) and congruence penalties apply; speculative synthesis remains low‑`R_eff` until supported.          |\n",
        "archetypal_grounding": "### B.2.3:5 - Archetypal Grounding\n\n#### B.2.3:5.1 - System vignette (Tell–Show–Show)\n\n**Tell.** A programme team has many operational dashboards, runbooks, and service metrics. Leaders call it “observability”, but each service still uses incompatible definitions and locally optimised alerts.\n\n**Show A (pre‑MET).** Each team maintains its own “SLO”, “incident”, and “error budget” episteme; cross-team comparisons are mostly rhetorical, and improvements do not transfer reliably.\n\n**Show B (post‑MET).** A `Transformer` (a standards group inside the organisation) publishes a single, named reliability doctrine with shared definitions, a unified objective (“predict and reduce user‑visible harm”), and a small set of invariants that govern interpretation (“measure what users experience”, “alerts must be actionable”). The doctrine is treated as one `U.Episteme` that supervises and constrains the constituent local practices.\n\n#### B.2.3:5.2 - Episteme vignette (cross-domain table)\n\n| Domain                           | Constituent `U.Episteme`s                                                                                              | Emergent meta-episteme (`U.Episteme`)                                                             | Key trigger evidence (B‑O‑S‑C)                                                                                                                                                                                                                                  |\n| :------------------------------- | :--------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------ | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **Physics**                      | Lorentz transformations; equivalence principle; Mercury perihelion anomalies; Maxwell’s equations.                     | **General Relativity**.                                                                           | **B:** A single name + coherent formalism. **O:** Gravity as spacetime geometry. **S:** Covariance + equivalence act as supervisory axioms. **C:** Patching classical mechanics became untenable.                                                               |\n| **Software development**         | Iterative development; user stories; daily coordination rituals; continuous integration; pair programming.             | **Agile** as a coherent body of practice.                                                         | **B:** Shared “Agile” boundary and vocabulary. **O:** A unifying objective around adaptability and feedback. **S:** Manifesto values/principles supervise local practices. **C:** Waterfall coordination costs exceeded a threshold.                            |\n| **Business strategy**            | Market analysis; competitor intelligence; capability assessments; technology forecasts.                                | A cohesive **multi‑year corporate strategy**.                                                     | **B:** Single authoritative strategy artefact. **O:** One overarching objective (e.g., leadership in a segment). **S:** Strategic pillars supervise execution plans. **C:** Disconnected departmental plans created unmanageable complexity.                    |\n| **Machine learning (post‑2015)** | Self‑supervised representation learning; attention mechanisms; large‑scale pretraining; prompt‑conditioning practices. | The **foundation‑model paradigm** (general‑purpose pretrained models with downstream adaptation). | **B:** A stable shared name and vocabulary. **O:** General-purpose representations enabling many tasks. **S:** Scaling laws and adaptation protocols supervise model development and use. **C:** Bespoke task-by-task pipelines became too complex to maintain. |\n",
        "bias_annotation": "### B.2.3:6 - Bias-Annotation\n\n**Lenses tested:** `Gov`, `Arch`, `Onto/Epist`, `Prag`, `Did`. **Scope:** Universal for MET declarations over `U.Episteme` holons (knowledge synthesis events), not for all MHT types.\n\n* **Gov.** Bias toward explicit responsibility: a named `Transformer` owns the synthesis claim. Mitigation: require a Promotion Record with evidence, so responsibility is auditable rather than merely social.\n* **Arch.** Bias toward structural comparability: MET is forced through the same BOSC trigger skeleton as other MHTs. Mitigation: the trigger interpretations are explicitly epistemic and do not pretend to be operational or physical.\n* **Onto/Epist.** Bias toward clarity about “what the new thing is”: the meta‑episteme is a first‑class `U.Episteme` holon with a supervisory core. Mitigation: avoid implying that synthesis increases truth; it only changes organisation and explanatory structure until evidence raises trust.\n* **Prag.** Bias toward actionability: the “Go/No‑Go” questions are framed for managers who need to allocate funding and ownership. Mitigation: conformance criteria still force evidence binding and do not reduce MET to a narrative decision.\n* **Did.** Bias toward teachability: the “bricks→cathedral” metaphor may over‑romanticise synthesis. Mitigation: anti‑patterns explicitly warn against rhetoric without BOSC evidence.\n",
        "conformance_checklist": "### B.2.3:7 - Conformance Checklist\n\n* **CC-B2.3.1 (Transformer mandate):** A Meta‑Epistemic Transition **MUST** attribute the `emergesAs` relation to an explicit external `Transformer` (e.g., a research team, a standards body, a synthesis agent). Constituent epistemes do not self‑organise into a promoted holon.\n* **CC-B2.3.2 (Trigger mandate):** The `Transformer` **MUST** provide a **Promotion Record** (B.2) containing evidence for all four epistemic B‑O‑S‑C triggers.\n* **CC-B2.3.3 (Episteme-holon mandate):** Both the constituents and the resulting meta‑episteme **MUST** be modeled as `U.Episteme` holons.\n* **CC-B2.3.4 (Supervisory principle mandate):** The emergent meta‑episteme **MUST** contain one or more identifiable supervisory principles (axioms, invariants, core values) that govern how its constituents are interpreted and composed.\n* **CC-B2.3.5 (Assurance re-baseline):** Any trust/assurance statement about the post‑MET meta‑episteme **MUST** be evaluated as a claim about a new holon and **MUST NOT** be asserted by silent inheritance from constituent `R` values.\n* **CC-B2.3.6 (Context reframe mapping):** If the MET introduces new primitives/terms or changes definitions, the Promotion Record **MUST** satisfy `MHT‑CTX‑MAP` (B.2:5.2): list concept/unit/terminology mappings with CL levels and record the new `boundedContext` and its CL baseline.\n",
        "consequences": "### B.2.3:8 - Consequences\n\n| Benefits                                                                                                                              | Trade-offs / mitigations                                                                                                                                               |\n| :------------------------------------------------------------------------------------------------------------------------------------ | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **Raises epistemic leverage.** A coherent meta‑episteme makes future reasoning and reuse cheaper and safer than managing a patchwork. | **High cognitive effort.** A MET is not routine. Mitigation: the trigger checklist is intentionally strict so the label is reserved for real synthesis.                |\n| **Creates stable foundations.** A well‑formed meta‑episteme can become a high‑`R_eff` platform for incremental work.                  | **Early fragility.** New syntheses are initially more speculative. Mitigation: conservative assurance and explicit congruence penalties keep trust inflation in check. |\n| **Improves governance.** Ownership, maintenance, and change control become assignable to a single artifact.                           | **Modeling overhead.** Promotion Records take time. Mitigation: the cost is paid once, and prevents repeated “reinvent the framework” cycles.                          |\n| **Guides innovation.** BOSC becomes a deliberate target for R&D teams (“what would count as a unifying supervisor?”).                 | **Risk of rhetoric.** Synthesis can be oversold. Mitigation: anti‑patterns and conformance criteria explicitly block narrative‑only declarations.                      |\n",
        "rationale": "### B.2.3:9 - Rationale\n\nThe most important leaps in human capability often come from re‑organising knowledge, not from adding more facts. MET is the architectural name for that re‑organisation.\n\nBy defining a Meta‑Epistemic Transition using observable triggers and an explicit `Transformer`, FPF gives a rigorous, non‑mystical account of paradigm‑level synthesis. It ensures that “unification” is not merely a rhetorical flourish, but a declared event with auditability and downstream governance consequences.\n",
        "sota_echoing": "### B.2.3:10 - SoTA-Echoing\n\nThis section aligns MET with post‑2015 state‑of‑the‑art practice in evidence synthesis, knowledge representation, and science‑of‑science.\n\n| Claim (MET need)                                                | SoTA practice                                                                             | Primary source (post‑2015)                                                                                 | Alignment with MET                                                                                                                                                                             | Adoption status                                                                                                    |\n| :-------------------------------------------------------------- | :---------------------------------------------------------------------------------------- | :--------------------------------------------------------------------------------------------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------------------- |\n| Synthesis must be auditable, not rhetorical.                    | Structured evidence-synthesis reporting and traceability norms.                           | PRISMA 2020 / PRISMA 2020 Statement (Page et al., 2021).                                                   | MET’s Promotion Record mirrors the idea that a synthesis claim needs explicit evidence and structure, but goes beyond reporting by requiring BOSC triggers and a supervising core.             | **Adopt/Adapt.** Adopt traceability discipline; adapt by adding BOSC and explicit `Transformer` attribution.       |\n| A synthesis should be continuously maintainable, not “one‑off”. | Living systematic reviews / living guidelines (continuous updating under evidence drift). | Living systematic review methodology (e.g., Elliott et al., 2017; and later living-review guidance).       | MET’s governance consequence (“assign ownership and maintenance”) matches the living-review premise: the synthesis is a managed asset, not a static report.                                    | **Adapt.** Same maintenance intent; MET is broader than health-science review protocols.                           |\n| Knowledge should be representable as composable claim networks. | Scholarly knowledge graphs capturing claims, evidence, and relations.                     | Open Research Knowledge Graph (ORKG) work (e.g., Jaradeh et al., 2019 and follow-on primary publications). | MET treats the resulting synthesis as a new `U.Episteme` holon that supervises constituents; claim‑graph representations are compatible as carriers, but MET adds explicit emergence criteria. | **Adopt/Adapt.** Adopt claim-network representation; adapt by requiring BOSC evidence for promotion.               |\n| Paradigm-level shifts have measurable structural signatures.    | Science‑of‑science models of how fields reorganise and consolidate.                       | “Science of science” synthesis (Fortunato et al., 2018).                                                   | MET’s **C** trigger (“complexity threshold”) and **B** trigger (“boundary closure”) correspond to consolidation signatures, while MET insists on explicit responsibility via `Transformer`.    | **Adapt.** Use the descriptive lens as grounding, but keep the MET declaration normative and responsibility‑bound. |\n",
        "relations": "### B.2.3:11 - Relations\n\n* **Is a specialization of:** `B.2 Meta-Holon Transition (MHT)`.\n* **Builds on:** `B.2.1 BOSC Triggers` and the `B.2` Promotion Record.\n* **Is complemented by:** `B.2.2 MST (Sys)` (system emergence) and `B.2.4 MFT` (capability emergence).\n* **Is performed by:** An external `Transformer` (A.12) executing an abductive synthesis (see B.5.2 for abductive moves).\n* **Produces:** A new `U.Episteme` whose trust/assurance is governed by `B.3 Trust & Assurance Calculus`.\n",
        "b.2.3:end": "### B.2.3:End\n\n"
      },
      "content": "### B.2.3:End\n\n",
      "metadata": {},
      "part": "B",
      "cluster": null
    },
    {
      "id": "B.2.4",
      "title": "Meta-Functional Transition (MFT)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## B.2.4 - Meta-Functional Transition (MFT)\n",
        "problem": "### B.2.5:2 - **Problem**\n\nWhile the concept of layered supervision is intuitive, its formal modeling is fraught with conceptual traps. Without a strict, principled distinction between different types of hierarchies, as mandated by **Strict Distinction (A.7)**, models become ambiguous. The primary challenge is to untangle three distinct hierarchies for any given holon:\n\n1.  **The Structural Hierarchy (Levels):** The mereological (part-whole) decomposition of the holon's **carrier**. For a `U.System`, this is its physical composition (e.g., an engine is `ComponentOf` a car). For a `U.Episteme`, this is the structure of its `Symbol` carrier (e.g., a chapter is `ComponentOf` a book).\n2.  **The Functional/Supervisory Hierarchy (Layers):** The decomposition of the management or reasoning task. This is a hierarchy of **`Transformer`s playing roles**. A `Transformer` in a higher layer (e.g., a scientific committee) `supervises` a `Transformer` in a lower layer (e.g., a research lab) by providing it with objectives or constraints.\n3.  **The Dataflow Network:** The network of information exchange (`U.Interaction`) between these `Transformer`s in their respective roles (e.g., `funding decisions` flowing down, `research findings` flowing up).\n\nConfusing these hierarchies leads to critical modeling errors. For example, treating a functional layer (a `U.Method` performed by a `Transformer`) as if it were a structural component (`ComponentOf` the holon it manages) is a category error that this pattern is designed to prevent.\n",
        "forces": "### B.2.4:3 - **Forces**\n\n| Force | Tension |\n| :--- | :--- |\n| **Component Skills vs. Integrated Capability** | How to represent the qualitative leap from a set of individual, executable functions to a single, coherent, and often adaptive composite `U.Method` that possesses properties not found in any of its parts. |\n| **Prescription vs. Performance** | The `MethodDescription` (the \"recipe\") describes how a method *should* be performed, but the MFT is about the emergence of the *actual, reliable capability* to perform it at run-time, often in ways that are more adaptive than the static recipe. |\n| **Decomposition vs. Synergy** | How to model a composite `U.Method` that is demonstrably more than the sum of its parts, possessing new regulatory and synergistic properties, without violating the conservative Weakest-Link principle where it still applies. |\n| **Explicit Design vs. Emergent Order** | Is the new meta-method a result of a deliberate, top-down design effort, or did it emerge bottom-up from the interactions of agents adapting to their environment? The framework must be able to model both pathways. |\n",
        "solution": "### B.2.4:4 - **Solution**\n\nAn MFT is a formal promotion of a set of `U.Method`s into a new, composite **`U.Method`**. This new `U.Method` is often referred to descriptively as a **\"meta-method\"** because of its supervisory role, but it remains a `U.Method` in type, preserving ontological parsimony. The transition is a change in the **operational reality** of a `Transformer` or a collective of `Transformers`. It is declared when the performance of the methods satisfies the B-O-S-C triggers, adapted for function and capability.\n\n#### B.2.4:4.1 - The B-O-S-C Triggers for Methods/Functions\n\nThe four triggers from the parent MHT pattern are interpreted in the operational context of methods and functions:\n\n| Trigger | Functional Interpretation | Manager's View: The \"Go/No-Go\" Question for Declaring a New Capability |\n| :--- | :--- | :--- |\n| **B - Boundary Closure**| The set of methods now exposes a single, unified **functional interface**. An external agent can invoke the entire workflow via a single, well-defined call (e.g., \"initiate deployment\"), without needing to know about or coordinate the individual internal steps. | \"Can I now ask the team to 'run the deployment process' as a single, black-box service, or do I still have to personally manage the hand-offs between coding, testing, and release?\" |\n| **O - Objective Emergence**| A new, **operational objective** for the entire workflow emerges, which is not merely the sum of the objectives of the individual steps. This is often a holistic, end-to-end performance goal (e.g., \"achieve a 99.9% success rate for the entire process\"). | \"Is the team now optimizing for the success of the *entire workflow*, even if it means one individual step has to run 'sub-optimally' (e.g., slower) for the good of the whole?\" |\n| **S - Supervisor Emergence**| A new **coordination and control logic** (the \"supervisor\") appears. This mechanism orchestrates the execution of the individual methods based on the state of the overall workflow. This \"meta\"-property is modeled via `controls` or `supervises` relations. | \"Is there a concrete mechanism—whether it's a CI/CD orchestrator, a formal team protocol, or a project manager's explicit control board—that is now actively managing the flow and making decisions between the steps?\" |\n| **C - Complexity Threshold** | The cognitive or coordination overhead of manually managing the individual methods becomes a significant bottleneck. The cost of *not* integrating outweighs the cost of creating and maintaining the new, integrated workflow. | \"Have we reached the point where the time we spend in meetings coordinating the hand-offs is taking more time and energy than the actual work itself?\" |\n\nWhen a `Transformer`'s performance demonstrates sustained evidence for all four triggers, an MFT has occurred. The `Transformer` now possesses a new, emergent composite `U.Method`.\n\n> **Didactic Note on \"Meta-\" vs. \"Supra-\":**\n> We use the prefix \"Meta-\" descriptively (as in a \"meta-method\") to signify the emergence of a new **layer of control and reflection**. A `U.Method` resulting from an MFT is not just a larger method; it is a method that *manages and orchestrates* other methods. This supervisory property is modeled through relations, not by creating a new `U.MetaMethod` type. This preserves ontological parsimony (Pillar C-5) by recognizing that the position in a control hierarchy is a relational property, not a change in fundamental type.\n\n> **Didactic Note on Terminology: \"Process,\" \"Workflow,\" \"Function\" vs. FPF's `Method` and `Work`**\n>\n> The terms \"process,\" \"workflow,\" \"function,\" and \"work process\" are notoriously overloaded. FPF resolves this ambiguity by mapping these common terms to its precise, distinct concepts, in alignment with Pattern A.15.\n>\n> | Your Domain's Term | How FPF Models It | The Core Distinction |\n> | :--- | :--- | :--- |\n> | **Workflow, Work Process, Function (as a sequence of steps)** | As a **`U.Method`** | This is the `run-time` **capability** or \"role-mask\" for work, enacted by a `Transformer`. It describes *how* an action is performed. |\n> | **The description of a workflow, a Standard Operating Procedure (SOP), an algorithm** | As a **`U.MethodDescription`** | This is the `design-time` **episteme** that documents the `Method`. It is the recipe, not the cooking. |\n> | **The actual execution of the workflow, an operation, a job** | As a **`U.Work`** | This is the `run-time` **occurrence**—the event of the `Method` being performed, which consumes resources. |\n>\n> The **Meta-Functional Transition (MFT)** described in this pattern is about the emergence of a new, composite **`U.Method`**. It is a transition in the *capability to act*, not just in the documentation or in a single execution.\n",
        "archetypal_grounding": "### B.2.5:3 - **Archetypal Grounding**\n\nThe universal architecture of the Supervisor-Subsystem loop is instantiated differently depending on the nature of the holon being managed. Below are two detailed archetypes that illustrate this distinction.\n\n#### B.2.5:3.1 - **Archetype 1: Loop for a `U.System` (Robotic Swarm)**\n\nHere, the loop governs the **physical behavior** of a collection of active `U.System`s.\n\n*   **Meta-System:** A swarm of autonomous delivery drones.\n*   **Sub-Holons:** The individual drones (`U.System`s).\n*   **`Transformer`s:** Each drone is its own `Transformer`, executing its local flight `Method`. The Supervisor is also a `Transformer` (either a designated leader drone or a distributed consensus algorithm running on all drones).\n\n**Instantiation of the Loop Roles and Principles:**\n\n| Role/Principle | Instantiation in the Robotic Swarm |\n| :--- | :--- |\n| **Supervisor** | The **consensus algorithm** (`U.Method`) running across the swarm. Its `GenerativeModel ℳ` is a shared map of the delivery area and the real-time state of all drones. Its `Objective Ξ` is to \"maximize fleet-wide delivery throughput.\" |\n| **Sub-Holons**| The individual drones. |\n| **Shared Medium**| A wireless mesh network (`U.Interaction` channel). |\n| **Loop in Action:** | 1. **Sense:** Each drone reports its position, battery, and status. The Supervisor aggregates this into a global state `X`. <br> 2. **Judge:** The Supervisor compares `X` to the optimal fleet configuration `Ξ` from its model. The `Error Δ` is the deviation (e.g., coverage gaps, overloaded drones). <br> 3. **Plan:** The Supervisor's influence policy `Λ` computes a new set of target waypoints and speed commands (`Influence Signal α`) for individual drones. <br> 4. **Act/Adapt:** Each drone receives its new command `α` and adapts its local flight `Method` (`πᵢ`) to move towards its new waypoint. |\n| **Stability Principles:** | **(P-C) Standardion:** The control law is designed so that the swarm exponentially converges to the target formation. <br> **(P-D) Dissipativity:** The system is dissipative; oscillations from a disturbance (like a sudden gust of wind) are actively dampened. <br> **(P-I) Information Constraint:** The loop is robust to a communication delay of `τ = 50ms`. |\n\n#### B.2.5:3.2 - **Archetype 2: Loop for a `U.Episteme` (A Scientific Theory)**\n\nHere, the loop governs the **conceptual integrity and evolution** of a passive knowledge artifact (`U.Episteme`). The \"actions\" are not physical movements but acts of reasoning and revision performed by human `Transformer`s.\n\n*   **Meta-System:** The entire body of knowledge known as \"The Theory of Evolution by Natural Selection.\"\n*   **Sub-Holons:** Individual epistemes that are `ConstituentOf` the theory, such as the Principle of Variation, the Principle of Inheritance, and the Principle of Selection.\n*   **`Transformer`s:** The global scientific community in the relevant field.\n\n**Instantiation of the Loop Roles and Principles:**\n\n| Role/Principle | Instantiation for the Scientific Theory |\n| :--- | :--- |\n| **Supervisor** | The **peer-review process and the scientific method itself** (`U.Method`), enacted by the community (`Transformer`). Its `GenerativeModel ℳ` is the core set of axioms and principles of the theory. Its `Objective Ξ` is \"to provide the most parsimonious and predictively powerful explanation for the diversity of life.\" |\n| **Sub-Holons**| The constituent principles and supporting evidence (individual papers, datasets). |\n| **Shared Medium**| Scientific journals, conferences, and preprint archives (`U.Interaction` channels). |\n| **Loop in Action:** | 1. **Sense:** A research lab (`Transformer`) performs an experiment and publishes a new finding (`U.Observation`, e.g., evidence for horizontal gene transfer). <br> 2. **Judge:** The community (`Supervisor`) compares this new finding `X` with the current predictions of the theory `Ξ`. The `Error Δ` is the anomaly—a result that the current theory cannot easily explain. <br> 3. **Plan:** Other researchers (`Supervisor`) propose revisions to the theory (`Influence Signal α`, e.g., a new paper suggesting a modification to the \"tree of life\" model). <br> 4. **Act/Adapt:** Over time, if the new proposal is corroborated by further evidence, the community (`Transformer`) updates the canonical understanding of the theory. The core `U.Episteme` is refined. |\n| **Stability Principles:** | **(P-C) Standardion:** A healthy scientific paradigm is Standardive; it progressively reduces the set of unexplained anomalies. <br> **(P-D) Dissipativity:** The process is dissipative; flawed or unfalsifiable hypotheses are eventually \"dampened\" and discarded by the community. <br> **(P-B) Bilevel Optimization:** The global objective (explanatory power) guides the local work of individual labs. |\n",
        "conformance_checklist": "### B.2.5:5 - **Conformance Checklist**\n\n*   **CC-B2.5.1 (Role Mandate):** Any model of a layered supervisory architecture **MUST** explicitly identify the holons (or `Transformer`s) playing the roles of `Supervisor` and `Sub-Holon`, as well as the `U.Interaction` channel that constitutes the `Shared Medium`.\n*   **CC-B2.5.2 (Loop Closure Mandate):** The model **MUST** demonstrate a closed feedback loop. A one-way, open-loop command structure is not a conformant Supervisor-Subsystem loop.\n*   **CC-B2.5.3 (Principle Evidence):** An assurance case for a supervisory loop **SHOULD** provide evidence, whether through formal proof, simulation, or empirical data, that it adheres to the four principles of stable control (Standardion, Dissipativity, Bilevel Optimization, Information Constraint).\n*   **CC-B2.5.4 (Levels vs. Layers Distinction):** The model **MUST** maintain the formal distinction between the structural hierarchy of `Levels` (`ComponentOf`) and the functional hierarchy of `Layers` (`controls`/`supervises`).\n",
        "anti_patterns": "### B.2.5:6 - **Common Anti-Patterns and How to Avoid Them**\n\n| Anti-Pattern | Manager's View: What It Looks Like | How FPF Prevents It (Conceptually) |\n| :--- | :--- | :--- |\n| **The \"Ghost in the Machine\"** | The model shows a collection of parts that somehow coordinate to achieve a global goal, but there is no identifiable mechanism or agent responsible for that coordination. | **CC-B2.5.1** forces the modeler to explicitly name the `Supervisor`. If no supervisor can be identified, then no supervisory loop exists, and the coordination is either an illusion or an un-modeled external factor. |\n| **The \"Functional Soup\"** | A diagram mixes physical components and functional layers in the same hierarchy. The \"Planning Layer\" is shown as a \"part of\" the physical system. | **CC-B2.5.4** and the strict mereology of FPF (A.14) forbid this. A functional layer is realized *by* physical components, but it is not *part of* them. This prevents category errors. |\n| **The \"Perfect Communication\" Fallacy** | The design of the control logic assumes that the supervisor has instant, infinite-bandwidth access to the state of all subsystems. The system fails in the real world due to network latency. | **Principle P-I (Information Constraint)** and its formal invariant **SSI-5** mandate that the stability analysis must account for the real-world constraints of the `Shared Medium`. |\n",
        "consequences": "### B.2.5:7 - **Consequences**\n\n| Benefits | Trade-offs / Mitigations |\n| :--- | :--- |\n| **Provable Stability and Robustness:** The pattern provides a path to creating complex, multi-agent systems that are not just functional but are provably stable and resilient to disturbances. | **Analytical Complexity:** Proving the formal invariants (SSI-1 to SSI-5) can be a non-trivial analytical or simulation task. *Mitigation:* For less critical systems, demonstrating adherence to the manager-facing criteria may be sufficient. The full formal proof is reserved for high-assurance applications. |\n| **Composable Control:** A well-formed LCA, proven to be Standardive and dissipative, can itself be treated as a stable \"sub-holon\" in an even higher-level supervisory loop. This enables the construction of deeply nested, yet manageable, control holarchies. | - |\n| **Clear Architectural Roles:** The pattern provides a clear language (Supervisor, Sub-Holon, Shared Medium) for describing the roles and responsibilities within a complex supervisory architecture, improving communication between teams. | - |\n| **Universal Applicability:** The pattern provides a single, unified conceptual tool for understanding control and regulation in systems as diverse as robotics, economics, and scientific communities. | - |\n",
        "rationale": "### B.2.5:8 - **Rationale**\n\nThis pattern distills the core insights of modern, post-2015 control theory and cybernetics into a universal, tool-agnostic architectural template. It recognizes that the classical, single-controller model is insufficient for the challenges of autonomy, collective intelligence, and large-scale socio-technical systems.\n\nBy formalizing the concepts of **Levels** vs. **Layers** and providing a set of universal stability principles (Standardion, Dissipativity, etc.), FPF creates a bridge between the abstract mathematics of control theory and the practical art of systems architecture. It provides a rigorous, first-principles answer to the fundamental question: \"How do you build a complex, multi-part holon that reliably works together to achieve a common goal, without falling into chaos?\" The pattern's true power lies in its universality: it reveals the congruent architectural logic that underpins effective supervision, whether that supervision is realized by a silicon chip, a nervous system, or a social Standard.\n",
        "relations": "### B.2.5:9 - **Relations**\n\n*   **Is an elaboration of:** The \"Supervisor Emergence\" (S) trigger in `B.2 Meta-Holon Transition (MHT)`. This pattern describes the architecture of the supervisor that emerges during an MHT.\n*   **Builds upon:** The `U.System`, `U.Method`, `U.Role`, and `U.Interaction` concepts from the FPF Kernel and Part A.\n*   **Constrains:** The design of any `U.Method` intended to serve a supervisory function.\n*   **Enables:** The creation of deep, multi-level holarchies where each level is itself a provably stable supervisory system.\n",
        "b.2.4:end": "### B.2.4:End\n\n## B.2.5 — Supervisor–Subholon Feedback Loop\n",
        "b.2.5:4___**key_distinction:**": "### B.2.5:4 - **Key Distinction:**\n\nIn the `U.System` example, the loop is a fast, often automated, **control system**. In the `U.Episteme` example, it is a slow, human-driven **process of collective reasoning**. However, the **architectural pattern is identical**: a supervisor monitors the state of sub-holons and issues corrective signals to maintain a global objective. This demonstrates the true universality of the LCA pattern.\n ",
        "b.2.5:end": "### B.2.5:End\n"
      },
      "content": "### B.2.5:End\n",
      "metadata": {},
      "part": "B",
      "cluster": null
    },
    {
      "id": "B.3",
      "title": "Trust & Assurance Calculus (F–G–R with Congruence)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## B.3 - Trust & Assurance Calculus (F–G–R with Congruence)\n\n> **Plain‑English headline.**\n> B.3 defines how **assurance** (trust) is **computed and propagated** for both physical systems and knowledge artifacts, using a small set of **characteristics** and **conservative aggregation rules** that respect the Γ‑invariants and A.15 **Strict Distinction**. It treats the **Working‑Model layer** as the **publication surface** for claims, with assurance **attached downward** (Mapping - Logical - Constructive - Empirical) per E.14.\n",
        "problem": "### B.3.3:2 - **Problem**\n\nHow do we create an objective, auditable, and balanced Standard for what constitutes \"trustworthiness\" at each stage of an artifact's development cycle? FPF requires a mechanism that moves beyond simple evidence counting to a qualitative assessment of assurance. This mechanism must prevent common failure modes, such as over-investing in run-time validation (LA) at the expense of design-time verification (VA), or neglecting the critical work of ensuring concepts are correctly mapped and typed (TA).\n",
        "forces": "### B.3:3 - Forces\n\n| Force                                    | Tension                                                                                                                             |\n| ---------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------- |\n| **Conservatism vs. Synthesis**           | Avoid overclaiming (WLNK) ↔ allow real gains from better integration (raise CL) or true emergence (B.2).                            |\n| **Universality vs. Domain nuance**       | One calculus for systems and epistemes ↔ physics and epistemology use different primitives; keep them comparable but not identical. |\n| **Simplicity vs. Fidelity**              | Keep the characteristic space small (A.11) ↔ capture enough structure to be informative and improvable by KD‑CAL actions.           |\n| **Static clarity vs. Dynamic evolution** | A score must be reproducible today ↔ tomorrow it should legitimately rise after formalization, replication, or reconciliation.      |\n\n",
        "solution": "### B.3.3:3 - **Solution**\n\nFPF establishes a formal Standard that links three distinct **Assurance Subtypes** to three computable **Assurance Levels**. An artifact's level is not assigned manually by an author; it is **derived automatically** by its anchored evidence. This creates a transparent and falsifiable system for tracking an artifact's journey from a speculative idea to a robust, reliable holon.\n\n#### B.3.3:3.1 - Assurance Subtypes: The Three Pillars of Trust\n\nThese three subtypes categorize the kind of question an assurance activity answers, ensuring a balanced approach to building confidence.\n\n| Subtype | Code | Core Question | Links to Epistemic Score | Manager's View: What It Prevents |\n| :--- | :--- | :--- | :--- | :--- |\n| **Typing Assurance** | TA | “Does the artifact faithfully represent its intended concept?” | **CL** (Congruence Level) | **Miscommunication & Integration Failures.** TA ensures that when a requirement says \"Sensor,\" the design model's \"Sensor\" component is the same conceptual thing. This activity directly improves the Congruence Level (CL) of the integration *edges* between artifacts. |\n| **Verification Assurance**| VA | “Is the holon logically correct under its stated assumptions?” | **FV** (Formal Verifiability)| **\"It Works on Paper\" Errors.** VA catches design flaws, logical inconsistencies, and specification errors before a single line of code is written or a physical part is machined. It ensures the blueprint is sound. |\n| **Validation Assurance**| LA | “Does the holon work correctly in the real world?” | **EV** (Empirical Validability)| **\"Works in the Lab, Fails in the Field\" Surprises.** LA confirms that the holon performs as expected under real or simulated operational conditions, accounting for noise, unexpected inputs, and environmental factors. |\n\n#### B.3.3:3.2 - Computed Assurance Levels: The Ladder of Maturity\n\nAn artifact’s level is computed based on the evidence it has accumulated. This creates a clear, step-by-step path for increasing trust.\n\n| Level | Name | How It Is Computed |\n| :--- | :--- | :--- |\n| **Level 0** | **Unsubstantiated** | No `verifiedBy` or `validatedBy` evidence is present. The artifact is a claim or an idea. |\n| **Level 1** | **Substantiated** | At least one `verifiedBy` or `validatedBy` link to an evidence artifact exists, and the artifact is supported by Typing Assurance (TA). |\n| **Level 2** | **Axiomatic** | The artifact is `verifiedBy` either a proof **or** a **Compose‑CAL (Γₘ) constructive narrative** that the author has linked from the Working‑Model via `tv:groundedBy` (CT2R‑LOG). Its FormalVerifiabilityScore (FV) meets or exceeds a pre‑defined threshold. Additionally, if the holon is designated as safety‑critical, it **MUST** also be supported by **Validation Assurance (LA)**. For non‑critical holons, LA is strongly recommended (`SHOULD`). |\n\n> **Didactic Note for Managers: What 'Level 1' Really Means**\n>\n> Think of moving from Level 0 to Level 1 as the first step toward professional seriousness.\n>\n> *   **Level 0** is an idea on a whiteboard. It has potential, but no receipts.\n> *   **Level 1** means you have **at least one receipt**. You have anchored the idea to something concrete: a passing test, a formal sketch, a simulation result. It's no longer just an opinion.\n>\n> Crucially, Level 1 also demands **Typing Assurance (TA)**. This sounds technical, but its business impact is simple: **it means you've named your terms correctly and consistently**. You've used the Role-Projection Bridge (Pattern B.5) to ensure that the \"Sensor\" in your requirements document is the same \"Sensor\" in your architectural diagram. This basic alignment work is what prevents costly integration failures and endless meetings where teams talk past each other. Good typing is the foundation of clear communication, and at Level 1, FPF makes it mandatory.\n",
        "b.3:4.8___prohibition_(normative)_—_f–g–r_is_not_a_characteristicspace": "### B.3:4.8 - Prohibition (normative) — F–G–R is not a CharacteristicSpace\nDo not treat `⟨F,G,R⟩` as a `U.CharacteristicSpace` and do not define geometric **trajectories** over it. Use **ESG** for episteme state and the **assurance‑trace** hooks for trends in assurance tuples.\n",
        "b.3:5_proof_obligations_(attach_these_when_producing_an_assurance_tuple)": "### B.3:5 Proof obligations (attach these when producing an Assurance tuple)\n\nThese obligations refine the generic Proof Kit from **B.1.1 §6** for **assurance** outputs. Each Γ‑flavour that emits an *Assurance(H, C | K, S)* tuple MUST attach the applicable obligations below.\n\n#### B.3:5.1 - Common obligations (all Γ‑flavours)\n\n* **ASS‑CLM (Typed claim & context).**\n  State the **claim** `C` (what is being assured), the **context** `K` (assumptions, environment), and the **scope** `S ∈ {design, run}`.\n\n* **ASS‑SCA (Scale discipline).**\n  Declare the **scale kind** used for each characteristic (F ordinal, G coverage, R ratio) and confirm that all operations are **admissible** for that kind (no averaging of ordinals; G via set/coverage ops).\n\n* **ASS‑WLNK (Weakest‑link evidence).**\n  Identify the **cutset** (node or edge set) that caps F/G/R for the claim (the proof spine for epistemes, the structural or assurance bottleneck for systems).\n\n* **ASS‑CL (Congruence path).**\n  Identify the **relevant integration path(s)** and record `CL_min` used in the penalty `Φ(CL_min)`.\n\n* **ASS‑MAN (SCR).**\n  Produce a **SCR** listing all contributing nodes and edges with `(F, G, R)` and `CL` values, their **DesignRunTag**, and Evidence Graph Ref (A.10). If order or time were material, include the **OrderSpec** or **TimeWindow** identifiers from **B.1.4**.\n\n* **ASS‑MONO (Declared monotone characteristics).**\n  List the characteristics along which local improvement cannot reduce the aggregate (this supports future evolution, B.4).\n\n#### B.3:5.2 - Γ\\_sys (systems) — additional obligations\n\n* **CORE‑BIC (Interface congruence).**\n  Reference the **Boundary‑Inheritance Standard** (BIC) from **B.1.2** and record any interface mismatches; these contribute to `CL_min`.\n\n* **CORE‑ENV (Operating envelope).**\n  Specify the domain used for **G** (e.g., load–temperature region) and how coverage is computed (set union constrained by support).\n\n#### B.3:5.3 - Γ\\_epist (epistemes) — additional obligations\n\n* **EPI‑SPN (Entailment spine).**\n  Identify the **premise/lemma spine** for the claim; `R_raw = min R_i` is taken along this spine, not over arbitrary satellites.\n\n* **EPI‑MAP (Semantic mapping congruence).**\n  Point to the **vocabulary/ontology mappings** used; their verification status sets the **CL** levels on the integration edges.\n\n#### B.3:5.4 - Γ\\_ctx / Γ\\_method (order‑sensitive) — additional obligations\n\n* **CTX‑ORD (OrderSpec).**\n  Attach the partial or total order `σ` and any **join‑soundness** conditions (types, pre/post‑conditions).\n  (See B.1.4 for NC‑1..3 invariants; B.1.5 adds duration/capability typing.)\n\n#### B.3:5.5 - Γ\\_time (temporal) — additional obligations\n\n* **TIME‑COV (Coverage & identity).**\n  Show that `PhaseOf` intervals cover the declared window without overlap for the **same carrier**; justify any gap/overlap explicitly.\n\n> **Note on Γ\\_work.**\n> Resource spending and efficiency live in **Γ\\_work**. Their *measurement integrity* can influence **R** for a claim (e.g., if a reliability figure depends on calibrated energy input), but **costs themselves are not assurance**; keep them in Γ\\_work and cite their **measurement assurance** as inputs here.\n\n",
        "archetypal_grounding": "### B.3:6 - Archetypal grounding (worked examples)\n\n#### B.3:6.1 - System archetype — **Battery pack safety claim**\n\n* **Claim `C`:** *Pack P meets discharge current L with thermal safety margin δ in environment K.*\n* **Context `K`:** Ambient ≤ 35 °C; airflow ≥ X; duty cycle Y. Scope `S = run`.\n* **Graph:** Cells `ComponentOf` modules `ComponentOf` pack; BIC exposes main power and thermal interface.\n* **Inputs:**\n\n  * `F` per node: module spec F2, cell test F1 → `F_eff = F1`.\n  * `G`: operating envelope regions; union constrained by supported test regimes.\n  * `R`: per‑module reliability from test data; cutset is **hot‑spot path** near weakest cell.\n  * `CL`: interface congruence (sensor calibration CL2; thermal contact CL1).\n* **Aggregation:**\n\n  * `R_raw = min R_i` along the thermal cutset.\n  * `R_eff = max(0, R_raw − Φ(CL_min=CL1))`.\n  * `G_eff`: union of supported (L,T) rectangles, dropping regions lacking validated thermal data.\n  * `F_eff = min(F_cell=F1, F_module=F2) = F1`.\n* **SCR:** Evidence for calibration, test campaigns, BIC.\n* **Improvement path:** raise `CL` (better thermal interface verification), raise `F` (formal thermal model), add supported envelope → **R\\_eff** and **G\\_eff** increase monotonically.\n\n#### B.3:6.2 - Episteme archetype — **Meta‑analysis claim**\n\n* **Claim `C`:** *Intervention X reduces outcome O by Δ on population P.*\n* **Context `K`:** Inclusion/exclusion criteria, measurement protocol; `S = design`.\n* **Graph:** Studies `MemberOf` evidence corpus; effect models `ConstituentOf` synthesis; mappings align different outcome scales.\n* **Inputs:**\n\n  * `F`: two RCTs at F3, one observational at F2 → `F_eff = F2`.\n  * `R`: per‑study replication/quality → weakest R on the entailment spine caps `R_raw`.\n  * `CL`: mapping of scales (CL1 vs CL3).\n  * `G`: populations union, but unsupported sub‑populations are dropped.\n* **Aggregation:**\n+* **Aggregation:**  \n* **\\[M‑1]** ordinal support ranking; note weakest‑link study.  \n* **\\[M‑2]** compute `R_eff` with Φ table; record `CL_min` for scale mappings.  \n* **\\[F‑constructive]** formalise the effect‑model equivalence and export proof‑term hash.  # [M/F]\n\n  * `R_eff = max(0, min(R_RCT1, R_RCT2, R_OBS) − Φ(CL_min=CL1))`.\n  * `G_eff`: union of supported sub‑populations; out‑of‑scope groups excluded.\n* **SCR:** Data provenance, scale mappings, bias assessment.\n* **Improvement path:** upgrade mapping verification to CL2/CL3; increase `F` via registered analysis plan; replicate lagging study.\n\n#### B.3:6.3 - Order/Process archetype — **Manufacturing route assurance**\n\n* **Claim `C`:** *Route R meets output defect rate ≤ ε.*\n* **Context `K`:** Materials, equipment class; `S = run`.\n* **Γ\\_ctx artifacts:** `σ` order; declared independent branches; join conditions at inspection.\n* **Assurance:**\n\n  * `R_raw = min R_step` along the **critical path** (includes inspection effectiveness).\n  * Penalty from poor join soundness `CL_min`.\n  * Improvement via faster but **verified** inspection (↑R\\_step) or tighter join spec (↑CL).\n\n#### B.3:6.4 - Temporal archetype — **Versioned model credibility**\n\n* **Claim `C`:** *Model M predicts within ±δ over τ.*\n* **Context `K`:** Data regime and drift tolerance; `S = run`.\n* **Γ\\_time artifacts:** `PhaseOf` slices v1, v2, v3 covering `τ`.\n* **Assurance:**\n\n  * `R_raw = min(R_v1, R_v2, R_v3)`;\n  * penalty if v2–v3 interface had low calibration congruence;\n  * improvement via re‑calibration (↑CL) or new validation campaign (↑R\\_v3).\n",
        "conformance_checklist": "### B.3.3:4 - **Conformance Checklist**\n\nTo ensure the integrity of the assurance calculus, the following rules are normative. A **Target of Assurance (ToA)** is any working-model element designated as a root claim (e.g., a top-level system requirement, safety goal, or core hypothesis).\n\n*   **CC-B3.3.1 (L1 Anchor Mandate):** A ToA **SHALL NOT** be considered to have reached `AssuranceLevel:L1` unless it is linked to at least one evidence artifact via `verifiedBy` or `validatedBy`.\n*   **CC-B3.3.2 (L1 Typing Mandate):** A ToA at `AssuranceLevel:L1` or higher **MUST** be supported by **Typing Assurance (TA)**. This includes, at a minimum, that its core concepts are mapped via the Role-Projection bridge (Pattern B.5) and it conforms to its declared schema.\n*   **CC-B3.3.3 (L2 V&V Mandate):** A ToA at `AssuranceLevel:L2` **MUST** satisfy all L1 criteria. In addition, it **MUST** be supported by **Verification Assurance (VA)** with `FV ≥ threshold_FV`. For holons designated as safety-critical (e.g., `criticality ≥ SIL-2`), the ToA **MUST** also be supported by **Validation Assurance (LA)** with `EV > 0`. For non-critical holons, LA **SHOULD** be present.\n    *   *Exemption Note:* Purely formal artifacts (e.g., mathematical axioms) may justify an exemption from the LA requirement, provided this is documented in their rationale.\n*   **CC-B3.3.4 (Concept-Bridge Completeness):** For any architheory used in a model at `AssuranceLevel:L1` or higher, all of its mandatory U.Types **MUST** be mapped to domain concepts via the Role-Projection bridge (Pattern B.5).\n*   **CC-B3.3.5 (Scope Separation):** Assurance claims **MUST** maintain a strict separation between `design-time` and `run-time` scopes (Pattern A.4). An assurance tuple for a `MethodDescription` (design-time) SHALL NOT be conflated with one for its corresponding `Work`/`Trace` (run-time). The Evidence Graph Ref (`verifiedBy`, `validatedBy`) must point to artifacts of the appropriate scope.\n* **CC-B3.3.6 (CT2R‑LOG Handshake):** If a ToA depends on **structural** claims, those claims **SHALL** be published as **Working‑Model** relations and, when used to justify `L2`, **SHALL** declare `validationMode=axiomatic` and provide **Constructive** grounding with `tv:groundedBy → Γₘ.(sum|set|slice)` (see B.3.5 and C.13).  \n* **CC-B3.3.7 (Downward‑Only Dependence):** Assurance artefacts (Mapping/Logical/Constructive/Evidence) **SHALL NOT** impose vocabulary or layout back onto the Working‑Model surface (E.14).\n ",
        "anti‑patterns_and_repairs": "### B.3:8 - Anti‑patterns and repairs\n\n| Anti‑pattern             | Symptom                                                    | Repair                                                                                                         |\n| ------------------------ | ---------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------- |\n| **Averaging assurance**  | Mean of `R_i` reported as system reliability               | Use `min R_i` on the cutset, then apply `Φ(CL_min)`.                                                           |\n| **Ordinal arithmetic**   | Averaging `F` or `CL` to produce “2.3”                     | Use `min`/`max` or thresholds; never average ordinals.                                                         |\n| **Coverage as centroid** | Replacing `G` union with a single “typical point”          | Keep `G` as set/coverage; if a numeric proxy is needed, derive it from the set.                                |\n| **Ignoring congruence**  | No penalty for weak mappings/interfaces                    | Assign `CL` to integration edges; apply `Φ(CL_min)`.                                                           |\n| **Design/run chimera**   | “One score” mixing blueprint and telemetry                 | Split into `S=design` and `S=run` tuples; compare explicitly.                                                  |\n| **Agency override**      | Claiming higher assurance because a controller is “clever” | Agency may justify *how* improvements are achieved; it cannot remove WLNK or `Φ`.                              |\n| **MemberOf as stock**    | Using `MemberOf` to sum reliabilities                      | Keep `MemberOf` for collections; reliability comes from the relevant **Γ** composition (e.g., Γ\\_sys cutset). |\n\n",
        "consequences": "### B.3.3:6 - **Consequences**\n\n| Benefits | Trade-offs / Mitigations |\n| :--- | :--- |\n| **Objective Gatekeeping:** The rules provide a clear, objective, and falsifiable basis for an artifact's assurance status, eliminating subjective judgment and \"assurance theater.\" | **Risk of Over-stringency:** The rules might feel too strict for rapid prototypes. *Mitigation:* The requirements for `L1` are deliberately lightweight, demanding only one piece of evidence and basic typing, making the first step onto the ladder accessible. |\n| **Balanced Assurance:** The Standard requires a mix of evidence types for higher levels, preventing teams from over-investing in one area (e.g., testing) while neglecting another (e.g., formal specification). | **Risk of Evidence Inflation:** Teams might add trivial evidence just to meet the criteria. *Mitigation:* The quality of evidence is assessed via the epistemic scores (FV, EV, CL); merely linking to low-quality evidence will not significantly raise the scores needed for L2. |\n| **Clear Progress Tracking:** The ladder provides a clear roadmap for maturing an artifact from an idea to a fully assured component, making planning and progress monitoring transparent. | **Overhead for Complex Holons:** A holon with many ToAs may require significant assurance work. *Mitigation:* The framework allows grouping, where a parent claim's evidence can satisfy the coverage requirements for its children if explicitly declared. |\n",
        "rationale": "### B.3.3:7 - **Rationale**\n\nThis pattern transforms the assurance framework from a descriptive taxonomy into a prescriptive, actionable Standard. By binding the computed `AssuranceLevel` to mandatory, well-defined evidence coverage, it makes the notion of \"trustworthiness\" in FPF an objective and auditable property. The rules ensure that as an artifact's formality and claimed reliability increase, the rigor and balance of its supporting evidence increase in lockstep, operationalizing the principle of \"no blind trust.\" The separation of `design-time` and `run-time` evidence, mandated by CC-B3.3.5, further ensures that claims made about a blueprint are not confused with claims made about a running system, preserving the integrity of the entire lifecycle.\n",
        "relations": "### B.3.3:8 - **Relations**\n\n*   **Builds on:** `B.3.1 Characteristic & Epistemic Spaces`, `A.10 Evidence Graph Referring`, `A.4 Temporal Duality`.\n*   **Constrains:** The computation and interpretation of `AssuranceLevel` for all holons.\n*   **Enables:** Objective quality gates in the Canonical Evolution Loop (B.4) and reliable inputs for the Trust-Aware Mediation Calculus (D.4).\n",
        "b.3:end": "### B.3:End\n\n## B.3.3 — Assurance Subtypes & Levels\n",
        "anti_patterns": "### B.3.3:5 - **Common Anti-Patterns and How to Avoid Them**\n\n| Anti-Pattern | Manager's View: What It Looks Like | How FPF Prevents It |\n| :--- | :--- | :--- |\n| **The \"Tested but Untyped\" Mess** | \"Our code has 100% test coverage, but we still have integration bugs and nobody understands what the architheories do.\" | **CC-B3.3.2** makes Typing Assurance (TA) mandatory for L1. You cannot claim your work is \"Substantiated\" without first ensuring your terms and concepts are clear and consistently mapped. |\n| **The \"Perfect Blueprint, Flawed Reality\"** | \"The design was formally proven to be perfect, but the physical product failed catastrophically in the field.\" | **CC-B3.3.3** mandates Validation Assurance (LA) for safety-critical systems at L2. A perfect blueprint (`FV=4`) is not enough; you must also provide empirical evidence (`EV>0`) that it works in the real world. |\n| **The \"Paper Compliance\" Shell Game** | \"We have thousands of documents and links, so we must be at a high assurance level.\" | The computed `AssuranceLevel` is not based on the *quantity* of evidence but on its *type* and *quality* (via FV/EV scores). You cannot reach L2 without strong formal verification (VA), no matter how much validation (LA) you do. |\n",
        "b.3.3:end": "### B.3.3:End\n"
      },
      "content": "### B.3.3:End\n",
      "metadata": {},
      "part": "B",
      "cluster": null
    },
    {
      "id": "B.3.4",
      "title": "Evidence Decay & Epistemic Debt",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## B.3.4 - Evidence Decay & Epistemic Debt\n",
        "problem": "### B.3.4:2 - **Problem**\n\nWithout a calculus for evidence aging, FPF models are vulnerable to three critical failure modes:\n\n1.  **Silent Risk Accumulation:** Trust silently decays. A component's high `AssuranceLevel` can become an illusion, resting on foundational evidence that is no longer valid in the current operational context. When aggregated, this stale trust propagates upwards, creating a seemingly robust system-of-systems that is, in fact, incredibly brittle.\n2.  **Audit Illusion:** An artifact can pass an audit with flying colors, showing a complete set of anchors to high-quality evidence, yet be fundamentally untrustworthy because that evidence is obsolete. This leads to a false sense of security and undermines the very purpose of the assurance case.\n3.  **Maintenance Paralysis:** Without a systematic way to flag stale evidence, re-validation efforts are often misdirected. Teams either engage in costly, unfocused re-testing of everything, or, more commonly, do nothing, allowing epistemic debt to accumulate until a failure forces a crisis.\n",
        "forces": "### B.3.4:3 - **Forces**\n\n| Force | Tension |\n| :--- | :--- |\n| **Timeless Truth vs. Contextual Reality** | Formal proofs and logical derivations feel permanent and universal, yet the assumptions they make about the world are context-dependent and perishable. |\n| **Rigor vs. Agility** | Continuously re-validating every piece of evidence is prohibitively expensive and would paralyze any agile workflow. |\n| **Transparency vs. Cognitive Load** | We need to make the \"staleness\" of evidence visible, but we must do so without overwhelming teams with a constant barrage of decay alerts. |\n| **Governance vs. Flexibility** | There must be a formal method for managing aging evidence, yet teams need the autonomy to make risk-informed decisions about when to accept, refresh, or deprecate it. |\n",
        "solution": "### B.3.4:4 - **Solution**\n\nFPF introduces a formal freshness model and a governance loop that make evidence aging a first-class, manageable property of the assurance calculus.\n\n#### B.3.4:4.1 - The Principle of Perishable Evidence\n\nThe core of the solution is a new normative principle: **Evidence is perishable**. The relevance of any piece of evidence is a function of time and context. An `AssuranceLevel` is therefore not a permanent achievement but a state that must be actively maintained.\n\n#### B.3.4:4.2 - Mechanism 1: The Freshness Standard (`valid_until`)**\n\nEvery evidence artifact anchored in the Assurance Layer **MUST** carry a `valid_until` attribute.\n\n*   **`valid_until: ISO-8601-date | null`**\n*   This attribute acts as a \"best before\" date, explicitly stating the time horizon over which its creators consider it to be fully relevant without review.\n*   A value of `null` signifies that the evidence is considered **perpetual**. This is reserved for artifacts like mathematical axioms or fundamental physical laws whose validity is not expected to decay on engineering timescales.\n\n#### B.3.4:4.3 - Mechanism 2: The Epistemic Debt Metric (ED)\n\nWhen the current time `t` surpasses an evidence artifact's `valid_until` date, that artifact begins to accrue **Epistemic Debt (ED)**.\n\n*   **Definition:** Epistemic Debt is a quantitative measure of an artifact's \"staleness.\" It is a function of its age past its expiry date.\n*   **Purpose:** ED is not a penalty but a **signal**. It makes the invisible risk of relying on old evidence visible and measurable.\n\n#### B.3.4:4.4 - Mechanism 3: The Governance Loop (`Refresh / Deprecate / Waive`)\n\nEpistemic Debt is managed through a project-level **epistemic_debt_budget**. When the total accrued debt exceeds this budget, an alert is triggered, and the team **MUST** take one of three actions:\n\n| Action | What It Means | Manager's View: The Practical Consequence |\n| :--- | :--- | :--- |\n| **Refresh** | Produce new, up-to-date evidence and set a new `valid_until` date. | **\"We invest the resources to re-validate.\"** This is the engineering fix: run the tests again, update the model, re-certify the component. |\n| **Deprecate**| Acknowledge that the evidence is no longer valid and formally downgrade the `AssuranceLevel` of the dependent artifact (typically to `L0` or `L1`). | **\"We accept the risk by lowering the component's official status.\"** The component is no longer considered fully assured and may be flagged for restricted use until it is refreshed. |\n| **Waive** | A designated authority (e.g., a senior systems engineer or a safety officer) formally accepts the risk of using the stale evidence for a limited time. | **\"I am signing off on this risk, for now.\"** This is a temporary, auditable override. It keeps the project moving but makes the risk acceptance explicit and assigns responsibility. |\n\n> **Didactic Note for Managers: Managing Your \"Trust Budget\"**\n>\n> Think of Epistemic Debt exactly like financial or technical debt. It’s not inherently evil, but it must be managed. The FPF dashboard now includes a \"Trust Health\" meter.\n>\n> *   **Green:** Your evidence is fresh. Your assurance case is solid.\n> *   **Amber:** Epistemic Debt is accumulating. It's time to plan for re-validation work in the next sprint.\n> *   **Red:** Your debt has exceeded its budget. Your CI/CD pipeline might be issuing warnings, and you are now carrying un-budgeted risk. You must immediately decide: **Pay it down (Refresh), write it off (Deprecate), or take out a short-term, high-visibility loan (Waive).**\n>\n> This loop transforms the vague problem of \"keeping things up to date\" into a concrete, resource-managed, and auditable engineering process.\n\n#### B.3.4:4.5 - Mechanism 4: The Epistemic Debt (ED) Calculation & Aggregation**\n\nTo make ED a useful leading indicator, it must be computed and aggregated consistently.\n\n*   **Calculation:** For a single evidence artifact `i`, its debt at time `t` is a function of its age past expiry:\n    `ED_t(i) = k * max(0, t - valid_until_i)`\n    *   The coefficient `k` is a configurable linear decay factor (default: `1.0 per day`), allowing projects to tune the \"interest rate\" on their debt.\n\n*   **Aggregation:** The total ED for an artifact `A` is the sum of the debt from all its direct and transitive Evidence Graph Ref:\n    `ED_t(A) = Σ_i ED_t(evidence_i)`\n    *   This rule ensures that debt propagates up the holarchy. If a foundational component's validation expires, the entire system that depends on it inherits that debt.\n\n*   **Impact on Assurance Level:** When an artifact's total `ED_t(A)` exceeds a defined threshold (typically `> 0` unless waived), its computed `AssuranceLevel` is **provisionally downgraded by one level**. For example, an `L2` artifact with expired evidence is treated as `L1` for governance and risk purposes until the debt is resolved. This makes the consequence of inaction immediate and visible on project dashboards.\n",
        "conformance_checklist": "### B.3.4:5 - **Conformance Checklist**\n\n*   **CC-ED.1 (Freshness Mandate):** Every evidence artifact anchored via `verifiedBy` or `validatedBy` **MUST** include a `valid_until` attribute. A value of `null` (perpetual) **MUST** be justified in the artifact's rationale.\n*   **CC-ED.2 (Debt Budget Mandate):** Every project or `U.System` at `AssuranceLevel:L1` or higher **MUST** declare an `epistemic_debt_budget` in its manifest.\n*   **CC-ED.3 (Aggregation Mandate):** The total Epistemic Debt of a composite holon **MUST** be the sum of the debt of its constituent parts, consistent with the aggregation rule `ED_t(S) = Σ_j ED_t(child_j)`.\n*   **CC-ED.4 (Downgrade Mandate):** An artifact with `ED_t > epistemic_debt_budget` **SHALL** have its effective `AssuranceLevel` provisionally downgraded until the debt is resolved via `Refresh`, `Deprecate`, or `Waive`.\n*   **CC-ED.5 (Waiver Auditability):** Any `Waive` action **MUST** be recorded as a formal, auditable event, citing the responsible authority, the rationale, and a new, short-term expiry date for the waiver itself.\n",
        "anti_patterns": "### B.3.4:6 - **Common Anti-Patterns and How to Avoid Them**\n\n| Anti-Pattern | Manager's View: What It Looks Like | How FPF Prevents It |\n| :--- | :--- | :--- |\n| **The \"Perpetual Evidence\" Fallacy** | \"We verified this component five years ago, so it's still L2. It's just a simple library, nothing has changed.\" | **CC-ED.1** forces a `valid_until` date. The context (compiler versions, new vulnerabilities, OS updates) has certainly changed. Setting `valid_until: null` requires explicit justification that the artifact is truly timeless, like a mathematical theorem. |\n| **The \"Invisible Debt\" Trap** | A critical, low-level component's test suite has been failing silently for months, but the high-level system dashboard is still green. | **CC-ED.3** ensures that the debt from the failing component's expired evidence propagates up to the system level, turning the dashboard amber or red and forcing attention. |\n| **The \"Risk Acceptance by Silence\"** | \"We know those tests are stale, but we're too busy to fix them. Let's just ignore the warnings for now.\" | **CC-ED.5** makes risk acceptance an explicit, auditable action. A manager must formally `Waive` the debt, putting their name on the decision. This transforms passive neglect into active, accountable risk management. |\n",
        "consequences": "### B.3.4:7 - **Consequences**\n\n| Benefits | Trade-offs / Mitigations |\n| :--- | :--- |\n| **Lifecycle Honesty:** The framework provides a transparent, quantitative way to track the erosion of trust over time, preventing \"assurance rot.\" | **Process Overhead:** Teams must now manage `valid_until` dates and respond to debt alerts. *Mitigation:* Tooling can automate much of this, suggesting default expiry dates based on artifact type and providing one-click actions for the governance loop. |\n| **Risk-Informed Maintenance:** Epistemic Debt becomes a leading indicator for maintenance and re-validation planning, allowing teams to allocate resources proactively, not reactively. | **Risk of False Positives:** Overly aggressive decay coefficients (`k`) could create excessive noise. *Mitigation:* The `k` value is configurable, and the `Waive` mechanism provides a safety valve for situations where a formal refresh is not yet warranted. |\n| **Enhanced Auditability:** The entire state progression of evidence—from creation to expiry and resolution—is now a traceable, auditable part of the FPF model. | - |\n",
        "rationale": "### B.3.4:8 - **Rationale**\n\nKnowledge frameworks that ignore time degrade silently. By embedding entropy accounting (epistemic debt) directly into the assurance calculus, FPF gains a self-regulating \"immune system.\" This pattern operationalizes the common-sense insight that evidence is perishable, transforming maintenance from an ad-hoc, often-neglected chore into a budgeted, auditable, and risk-informed engineering activity. It complements the human-centric loop of ADR-014 and the pragmatic utility guardrail of ADR-015 by ensuring that what we trust today remains trustworthy tomorrow.\n",
        "relations": "### B.3.4:9 - **Relations**\n\n*   **Builds on:** `B.3.3 Assurance Subtypes & Levels`, `A.10 Evidence Graph Referring`.\n*   **Constrains:** The temporal validity of `AssuranceLevel` for all holons.\n*   **Enables:** Proactive maintenance planning within the Canonical Evolution Loop (B.4) and provides a dynamic risk input for ethical and strategic decision-making (Part D).\n",
        "b.3.4:end": "### B.3.4:End\n"
      },
      "content": "### B.3.4:End\n",
      "metadata": {},
      "part": "B",
      "cluster": null
    },
    {
      "id": "B.3.5",
      "title": "Working-Model Relations & Grounding (CT2R-LOG)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## B.3.5 - Working-Model Relations & Grounding (CT2R-LOG)\n\n> **One‑line summary.**\n> CT2R‑LOG treats the everyday **Working‑Model relations**— **ut:ComponentOf**, **ut:MemberOf**, **ut:PortionOf**, **ut:AspectOf** —as the **publication surface** for structure, while binding each published edge to a **grounding trace** and a **declared `tv:validationMode`**. Authors keep using a short list of relations; reviewers get reconstructible provenance.\n",
        "b.3.5:1___intent": "### B.3.5:1 - Intent\n\n*Provide a single, human‑facing family of **Working‑Model** relations as the **publication surface**, with explicit hooks for (G) grounding and (R) reliability—without exposing constructor jargon or burdening day‑to‑day authors.*\n\n**What you get (manager/engineer view).**\n The same relations you already know (e.g., **ComponentOf**) remain the **public interface**.\n\n**What changes (auditor/ontologist view).**\n* Each published edge carries two additional commitments:\n\n  1. **`tv:groundedBy`** → points to a **reconstructible trace** (e.g., `Γ_m.sum`) whenever the edge is *structural*.\n  2. **`validationMode ∈ {axiomatic, inferential, postulate}`** → declares how the author justifies the assertion.\n\nThis is the **alias‑plus‑grounding** split: **Compose‑CAL** builds the trace; **CT2R‑LOG** declares the alias pattern and links it; **Lang‑CHR** supplies the labels.\n",
        "problem": "### B.3.5:3 - Problem\n\nDeclared sub‑relations of `ut:PartOf` (e.g., **ComponentOf**, **MemberOf**) are easy to use but **not self‑justifying**: nothing in their declaration shows *why* a given edge should be trusted, or how to **re‑derive** it if challenged. Conversely, exposing constructor traces everywhere makes the graph unreadable to non‑specialists.\n\n**We need**: a stable **publication surface** for relations *and* a mandatory, **reconstructible** **grounding channel**—plus a visible **validation intent** that downstream assurance can reason about.\n\n",
        "solution": "### B.3.5:4 - Solution (thumbnail)\n\nCT2R‑LOG introduces a **two‑link discipline** around each canonical edge:\n\n1. **Alias link (concept‑level).**\n   **Working‑Model relations** (e.g., `ut:ComponentOf`) are **alias patterns** over a general constructional principle. Denote by **`tv:AliasOf`**.\n\n2. **Grounding link (evidence‑level).**\n   Each **edge instance** carries **`tv:groundedBy`**:\n\n   * **MANDATORY** for **all structural edges** (sub-properties of `ut:StructPartOf`): the target is a valid **`Γ_m` trace** from **Compose-CAL** (one of `sum`, `set`, `slice`). **Set** `validationMode=axiomatic`; **`postulate` SHALL NOT be used for structural edges**.\n   * **Optional** for **epistemic edges** (e.g., `ConstituentOf`, `RepresentationOf`): if no `Γ_m` trace is appropriate, attach an **evidence object** whose admissibility is governed by the declared **`validationMode ∈ {inferential, postulate}`** (assurance rules).\n\n2. **Validation flag (author intent).**\n   Every declared edge or aggregation rule carries **`tv:validationMode`** with one of:\n   * **`postulate`** — pragmatic working claim backed by observations;\n   * **`inferential`** — reasoned consequence (proof outline);\n   * **`axiomatic`** — constructive grounding via a `Γ_m.*` composition.\n\n> **F–G–R alignment.**\n> **F** (the published *Fact*): `:PumpA ut:ComponentOf :Skid12`.\n> **G** (its *Grounding*): `:e123 tv:groundedBy :trace_Γm_sum_456`.\n> **R** (declared *Reliability mode*): `tv:validationMode=axiomatic` → inputs B.3.3’s **AssuranceLevel** assessment.\n",
        "b.3.5:5___vocabulary_&_notation_(normative)": "### B.3.5:5 - Vocabulary & notation (normative)\n\n* **Working-Model relations (front‑stage).**\n `ut:ComponentOf`, `ut:PortionOf`, `ut:AspectOf` are **publication-grade** sub-properties of `ut:StructPartOf` **(structural)**; `ut:MemberOf` is a sub-property of `ut:EpiPartOf` **(epistemic)**. \n\n* **Alias principle (lexical).**\n  `tv:AliasOf` links a **relation type** to its **generative rule schema** (e.g., “`ComponentOf` aliases the result of a `Γ_m.sum` with role=component”).\n\n* **Grounding (per‑edge).**\n `tv:groundedBy` on an *edge instance* **MUST** point to a **Γₘ trace** (`sum|set|slice`) for **structural** edges (**set** `validationMode=axiomatic`); for **epistemic** edges it **MAY** point to an **evidence object** or a logical proof per declared `validationMode ∈ {inferential, postulate}`. \n\n* **Trace family.**\n  `Γ_m.sum`, `Γ_m.set`, `Γ_m.slice` are the only normative constructors for structural grounding; no temporal or workflow constructor is added here (time slices live in Sys‑CAL; parallelism via `set`).\n\n* **Validation flag.**\n `tv:validationMode ∈ {postulate, inferential, axiomatic}` is **required** on every declared edge or aggregation rule; **for structural edges `postulate` is disallowed**.\n",
        "b.3.5:6___running_example_(didactic)": "### B.3.5:6 - Running example (didactic)\n\n> **Story.** A refinery team publishes `:PumpA ut:ComponentOf :Skid12`.\n\n* **Publication — Working-Model surface.**\n  They mint one edge with the **Working-Model** relation **ComponentOf** and **declare the surface’s `U.Formality`** (typically **F≈F3**, controlled narrative). Only the publication surface is visible to readers.\n\n* **Constructive grounding (Γₘ).**\n  In the background, the edge node records `tv:groundedBy :trace_Γₘ_sum_456`. That trace is a **Compose-CAL** “sum” that lists the parts aggregated into the skid. Any auditor can **replay** the trace to prove extensional identity. *(Grounding does not change the surface’s F; it sets `validationMode=axiomatic` and contributes to **R** in the **VA** lane.)*\n\n* **Assurance stance & R-lane.**\n Because the edge is construction-backed, authors set `tv:validationMode=axiomatic`. B.3.3 reads the flag and assigns an **AssuranceLevel** in the appropriate **R** lane (scale defined in B.3.3). **F**, **G**, and **R** remain **orthogonal**: this move raises assurance without changing claim scope (**G**) or the surface’s formality (**F**).\n\n* **Contrast (epistemic).**\nWhen the same team asserts `:MassFlowRepresentation RepresentationOf :FlowModel`, they declare `validationMode=postulate` and attach a calibration dataset (Empirical Validation) instead of a **Γₘ** trace. The edge remains publishable, but reviewers record a lower-confidence stance, and B.3.4’s **evidence ageing** policy will decay its trust over time.\n  \nResult: **one** visible relation for engineers, **two** hidden anchors for assurance.\n",
        "b.3.5:7___author_standard_(at_a_glance)": "### B.3.5:7 - Author Standard (at a glance)\n\nWhen you add or import a relation edge:\n\n1. **Pick a Working‑Model relation** (ComponentOf/MemberOf/…); avoid raw `ut:PartOf` unless you are drafting meta‑level axioms.\n   \n2. **Attach `tv:groundedBy`**:\n\n   * Structural? → **must** be a `Γ_m` trace ID.\n   * Epistemic? → `Γ_m` trace *or* evidence object.\n3. **Declare `tv:validationMode`** (**postulate** / **inferential** / **axiomatic**).\n\n> **What managers see:** nothing new in the graph picture.\n> **What auditors get:** a reliable trail from every published edge back to a principled constructor or an evidence pack.\n\n",
        "b.3.5:8___compatibility_&_cross‑references": "### B.3.5:8 - Compatibility & cross‑references\n\n* **B.3.2 (LOG‑use).** CT2R‑LOG supplies the **places to hang proofs/evidence** that B.3.2 formalizes.\n* **B.3.3 (Assurance levels).** `validationMode` + presence/quality of `tv:groundedBy` are the **inputs** to compute `AssuranceLevel (L0–L2)`.\n* **B.3.4 (Evidence ageing).** If an edge relies on **postulated evidence**, its confidence **decays** per that pattern until refreshed; **axiomatic** edges from `Γ_m` traces do not age, but their **inputs** (tokens) might.\n",
        "b.3.5:9___rule‑set_—_ct2r‑log_(conceptual,_human‑first)": "### B.3.5:9 - Rule‑set — CT2R‑LOG (conceptual, human‑first)\n\n**Intent (one line).** Make **Working‑Model** relations the canonical interface for authors, while providing a **clean, optional bridge** to formal assurance by way of *aliasing* and *grounding* semantics.\n\n#### B.3.5:9.1 - Vocabulary & Roles (what the words mean in this pattern)\n\n* **Working‑Model relation.** A human‑oriented statement an engineer would naturally write, using U.Type relations such as `ut:ComponentOf`, `ut:PortionOf`, `ut:AspectOf`, `ut:MemberOf`. This is the **canonical publication surface** for structure for readers and reviewers in Part B. (Didactic primacy governs this choice.)\n\n* **Assurance Layer.** Three complementary kinds of support an author MAY attach:\n\n  * **Constructive** grounding: a *generative* narrative that reconstructs the relation via the three mereological aggregators (`Γ_m.sum | Γ_m.set | Γ_m.slice`) from **Compose‑CAL**. (No formal notation is required in this pattern—only a reconstructible *story of construction*.)\n  * **Logical** grounding: a *reasoned* chain (think KD‑CAL style arguments) that shows why the relation follows from stated premises.\n  * **Mapping** grounding: a *type/lexical alignment* that shows the domain label truly denotes the intended U.Type relation (Kind-CAL / Lang‑CHR stance).\n    These three kinds of support are *complementary*, not exclusive.\n\n* **Empirical Validation.** How a published relation meets reality (observations, calibration scenarios). It lives beside, not inside, the relation. (See B.3 family.)\n\n* **Grounding vocabulary (`tv:`).**\n\n  * `tv:AliasOf` — declares that a Working‑Model relation is the **canonical projection** of a more general pattern (its “principle of use”).\n  * `tv:groundedBy` — points to the **author’s grounding narrative** (Constructive, Logical, or Mapping, as applicable).\n    The `tv:` namespace is part of the Core conceptual lexicon; it is **notation‑agnostic** and **tool‑agnostic**.\n\n* **`tv:validationMode ∈ {postulate, inferential, axiomatic}`.** A **declaration by the author** of the *confidence stance* for a relation instance:\n  *postulate* — a pragmatic working claim;\n  *inferential* — a reasoned consequence;\n  *axiomatic* — a constructively grounded identity (mereological extensionality is exhibited). (Modes align with the B.3 cluster’s trust model.) \n\n> **Authoring note.** This pattern defines *meanings*, not formats. The words above SHALL be used consistently and without reference to any specific notations or execution environments (Guard‑Rails: Notational Independence).\n\n\n#### B.3.5:9.2 - Normative rules (MUST/SHALL clauses for thinking‑and‑writing)\n\n**S‑1 (Working-Model first).**\nAuthors **SHALL** publish structural claims in the **Working‑Model** form (`ut:*Of` relations). This is the canonical interface for human readers and cross‑disciplinary teams. Formal reconstructions are **optional** and live in the Assurance Layer.\n\n**S‑2 (Alias declaration).**\nIf a Working‑Model relation follows a known general principle, the author **SHOULD** declare `tv:AliasOf <Principle>`, thereby making the intended *use‑pattern* explicit for reviewers and future readers. (This improves comparability without introducing extra formality.)\n\n**S‑3 (Grounding by mode).**\nFor every relation instance the author **MUST** set `validationMode` and follow the corresponding grounding stance:\n\n* **S‑3.a `postulate`.** The author **MAY** omit `Γ_m` grounding; the relation stands as a pragmatic working claim within a stated scope. The author **SHOULD** supply brief empirical cues (where the claim tends to hold) to ease later validation. (Empirical Validation is tracked in B.3.)\n\n* **S‑3.b `inferential`.** The author **SHALL** outline a *reasoned chain* (plain‑language steps) that makes the relation a consequence of previously admitted statements. No formal calculus is required in this pattern; the outline must be sufficient for a peer to follow. (Think KD‑CAL stance, conceptually.)\n\n* **S‑3.c `axiomatic`.** The author **SHALL** provide a *constructive grounding narrative* that reconstructs the relation as a `Γ_m.sum | Γ_m.set | Γ_m.slice` composition and **SHALL** link it with `tv:groundedBy`. The narrative **MUST** be reconstructible by a competent peer *without introducing new primitives* (parsimony). (Compose‑CAL’s three aggregators are the only constructive moves assumed here.)\n\n* **S-3.d Structural constraint.** For **structural** edges, `tv:groundedBy → Γ_m.*` is **REQUIRED regardless of `validationMode`**; the `postulate` mode **MUST NOT** be used for structural mereology. \n\n**S-4 (Relation-kind sense-making).**\n* For **structural** subtypes of `ut:StructPartOf` (Component/Portion/Aspect), constructive grounding (`tv:groundedBy → Γ_m.*`) is **REQUIRED** in all modes; **`postulate` MUST NOT be used** for structural mereology (see S-3.d).\n\n* For **epistemic/constitutive** links (e.g., representation, usage), constructive grounding is **OPTIONAL** in all stances; authors prefer *inferential* or *postulate* with empirical cues.\n\n**S‑5 (Order and time are not mereology).**\nAuthors **SHALL NOT** encode execution order, parallelism, or temporal slicing as part‑whole. Such concerns belong to `Γ_method` and `Γ_time` families and **SHOULD** appear as method/time statements adjacent to, not inside, Working‑Model structure. (This prevents conceptual leakage between planes.)\n\n**S‑6 (Unidirectional dependence).**\nCT2R‑LOG may *consume* Compose‑CAL and KD‑CAL conceptually; it **SHALL NOT** redefine them. Meaning flows **downward only** (Kernel → Architheory → Context → Instance).\n\n**S‑7 (Register discipline).**\nWhen naming principles in `tv:AliasOf`, authors **SHOULD** use Tech/Plain *twin labels* where available and obey minimal‑generality and rewrite rules (LEX‑BUNDLE), so that aliases are recognisable across context of meaning.\n\n**S‑8 (No tool talk).**\nCore prose **MUST NOT** introduce CI/CD terms, file formats, APIs, or machine‑oriented notations in place of concepts. If examples are needed, they **MAY** be plain‑language narratives or domain vignettes. (This pattern is conceptual by Standard.)\n\n\n#### B.3.5:9.3 - Scope & Non‑Goals (to keep the plane clean)\n\n* **In scope.**\n  Canonical publication of relations for humans; alias‑to‑principle clarity; conceptual grounding stories; author‑declared *validationMode*; separation of structure vs order/time.\n\n* **Out of scope.**\n  Any machinery that *executes* checks; any binding to specific notations; any process/workflow mechanics; any discussion of file formats. (Those belong to Tooling/Pedagogy artefacts and SHALL NOT be imported by the Conceptual Core.)\n  \n* **Edge placements.**\n  When a claim is chiefly about *naming fit* across Contexts, prefer **Mapping** grounding (Kind-CAL/Lang‑CHR stance). When it is chiefly about *why* it follows, prefer **Logical** grounding. When it is about *what the whole is, from its parts*, prefer **Constructive** grounding. (Authors MAY combine them.)\n\n\n#### B.3.5:9.4 - Author’s working moves (micro‑playbook, notation‑free)\n\n**M‑1.** State the relation in **Working‑Model** form (e.g., “Impeller `ComponentOf` Pump”).\n**M‑2.** Pick `validationMode`:\n\n* If you’re sketching and exploring → choose **postulate**; add one‑sentence scope.\n* If you’re justifying from known statements → choose **inferential**; list the 2–4 steps in plain language.\n* If you require extensional identity → choose **axiomatic**; narrate the `Γ_m.*` reconstruction in a short paragraph.\n\n**M‑3.** Add `tv:AliasOf` to the principle you intend readers to recognise (e.g., “Component = sum of parts”).\n**M‑4.** Keep *order/time* adjacent, not embedded: if you need “assembled in two parallel lines”, write that as a **method/time** statement next to the structure, not as a part‑of edge.\n**M‑5.** Stop when the *reader can follow without guessing*. This is the stopping rule for Quarter 2: clarity before formality. (Didactic primacy.)\n",
        "b.3.5:10___bias‑annotation_(auditable,_human‑first)": "### B.3.5:10 - Bias‑Annotation (auditable, human‑first)\n\nThe purpose of this section is to make **typical cognitive slips** visible and name the **counter‑moves** an author (or reviewer) should apply **in thought**—not with tools. These biases are generic; the remedies point to earlier FPF guard‑rails and neighbouring patterns.\n\n| Bias (name)                     | Symptom in the model                                                                                                          | Cognitive counter‑move (conceptual only)                                                                                                                                                                          | Where to check                                                       |\n| ------------------------------- | ----------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------- |\n| **Formalism capture**           | Treating a constructive trace as “the real thing” and the human relation (e.g., *ComponentOf*) as an optional label.          | Re‑assert **canonical‑first**: the Working‑Model relation is the canonical publication. A constructive trace is a **grounding** you may attach when assurance demands it. Choose a **validationMode** explicitly. | CC‑CT2R‑1, CC‑CT2R‑2; B.3 skeleton for assurance conservatism.       |\n| **Canonical inversion**         | Demanding a constructive grounding for **epistemic** claims by default. *(For **structural** claims, Constructive grounding is mandatory; epistemic remains progressive.)*                    | Keep **progressive assurance**: declare `validationMode ∈ {postulate, inferential, axiomatic}`; reserve *axiomatic* with **Constructive** grounding for structural; use **Logical/Mapping**/**Empirical** where appropriate. Express formality via **F** (C.2.3), not tiers. | CC-CT2R-2; B.3.3 relation-kind discipline & validation modes.         |\n| **Order/time leakage**          | Encoding sequence or phase as part‑whole edges.                                                                               | Apply **Strict Distinction**: order/time belong to Γ\\_method / Γ\\_time, not to mereology or CT2R relations.                                                                                                       | B.3 “keep order/time in their own lanes”; cross‑ref Γ\\_ctx/Γ\\_time.  |\n| **Notation lock‑in**            | Letting a diagram or syntax define the meaning (“it’s true because the diagram says so”).                                     | Enforce **Notational Independence**: meaning is defined in prose/maths; renderings are illustrative only.                                                                                                         | Part E guard‑rail on notational independence.                        |\n| **Congruence blindness**        | Composing strong parts through weak mappings without acknowledging the fit penalty.                                           | Make **edge‑fit first‑class**: reason about Congruence Level (CL) on connections; penalise low fit conceptually.                                                                                                  | B.3 universal aggregation skeleton (Φ(CL)); anti‑patterns list.      |\n| **Collection/composition swap** | Using **MemberOf** to stand in for **PartOf** (or vice versa), then carrying over reliability as if it were a structural sum. | Re‑separate **MemberOf** (collections) from **part‑whole** mereology; read A.14 notes in Γ\\_epist context.                                                                                                        | Γ\\_epist context / A.14 compliance.                                  |\n| **Design/run chimera**          | Mixing design‑time and run‑time evidence into one “assurance” line.                                                           | Split the **scope** of the claim: `S ∈ {design, run}`; compare side‑by‑side rather than merging.                                                                                                                  | B.3 typed claim tuple & anti‑pattern “design/run chimera”.           |\n\n> **Reviewer reminder.** Bias audit is a **reading aid**. It never licenses tooling talk in Core; use the guard‑rails in Part E to keep semantics primacy and unidirectional dependence of layers.\n\n",
        "conformance_checklist": "### B.3.5:11 - Conformance Checklist (normative, author‑facing)\n\nThe following obligations regulate **how to think and write** CT2R content. They are **notation‑agnostic** and purely conceptual.\n\n| ID                                              | Requirement                                                                                                                                                                                                                                   | Purpose                                                                   |\n| ----------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------- |\n| **CC‑CT2R‑1 (Canonical‑first).**                | A relation published for readers **SHALL** be stated in Working‑Model terms (`ut:*Of`) as the canonical form; any constructive or logical basis is recorded as **grounding** (not as the definition).                                         | Preserve human‑first canon and didactic primacy.                          |\n| **CC‑CT2R‑2 (Mode declaration).**               | For every declarative relation or rule, the author **SHALL** declare `tv:validationMode ∈ {postulate, inferential, axiomatic}` in prose (no silent defaults).                                                                                | Make assurance intent explicit and auditable by reading.                  |\n| **CC‑CT2R‑3 (Structural axiomatic grounding).** | If the relation is **structural** (a subtype of `ut:StructPartOf`) **and** the author chooses `axiomatic`, they **SHALL** provide a **grounding narrative** that can be reconstructed as one of the Γ\\_m aggregators (*sum*, *set*, *slice*). | Tie high‑assurance claims to constructive identity without tool mandates. |\n| **CC‑CT2R‑4 (No order/time in parts).**         | Authors **SHALL NOT** encode order (`Serial/Parallel`) or phase/time as part‑whole relations; handle them via `Γ_method` / `Γ_time` when relevant to the claim.                                                                               | Maintain the structure/order/time firewall.                               |\n| **CC‑CT2R‑5 (Collection vs part).**             | Authors **SHALL** keep **MemberOf** (collections) distinct from **PartOf** (structure) and refrain from carrying reliability as if membership implied structural composition.                                                                 | Prevent category errors flagged in B.3 anti‑patterns.                     |\n| **CC‑CT2R‑6 (Fit is explicit).**                | Where mappings or alignments matter, the author **SHALL** reason about **fit** explicitly (Congruence Level, conceptually) and acknowledge that weak fit reduces the effective reliability of any composed claim.                             | Keep integration quality first‑class.                                     |\n| **CC‑CT2R‑7 (Notational independence).**        | Core meaning **MUST NOT** hinge on any specific diagram or syntax; illustrative renderings, if present, are labelled *informative*.                                                                                                           | Ensure longevity and cross‑discipline portability.                        |\n| **CC‑CT2R‑8 (Layer direction).**                | Grounding flows **downwards** from Working‑Model to Assurance layers (Mapping/Logical/Constructive). Authors **SHALL** avoid back‑defining the canonical relation by its grounding artefact.                                                  | Preserve unidirectional dependence of layers.                             |\n| **CC‑CT2R‑9 (Scope split).**                    | When assurance is discussed, authors **SHALL** state the **typed claim** and **scope** `S ∈ {design, run}` and keep them distinct in reasoning.                                                                                               | Prevent design/run chimeras.                                              |\n\n",
        "consequences": "### B.3.5:12 - Consequences (benefits, trade‑offs, mitigations)\n\n**Benefits**\n\n* **Cognitive clarity for authors and readers.** By making Working‑Model relations canonical and keeping formal bases as optional groundings, CT2R reduces the barrier to disciplined reasoning while preserving a path to higher assurance when necessary.  This honours the B.3 family's “few characteristics, conservative aggregation” ethos and keeps order/time outside of structure.\n* **Progressive assurance without tooling commitments.** The *postulate → inferential → axiomatic* ladder lets teams raise assurance deliberately, matching their context and risk, in line with B.3.3’s maturity logic.\n* **Explicit fit management.** Treating edge‑fit (CL) as a first‑class concern prevents silent over‑confidence: weak mappings visibly cap reliability of composed claims.\n* **Cleaner separation of concerns.** Distinguishing collections from compositions and keeping sequence/time in Γ\\_method / Γ\\_time prevents recurrent category errors and preserves Γ‑algebra reviewability.\n\n**Trade‑offs & mitigations**\n\n* **Extra prose discipline.** Declaring `validationMode` and writing a short grounding narrative (when *axiomatic*) adds authoring effort. *Mitigation:* reuse local templates; keep narratives concise and Γ\\_m‑oriented by idea rather than notation.\n* **Temptation to stay “forever postulate.”** Teams may stop at Working‑Model relations. *Mitigation:* use B.3.3’s subtypes/levels as a **planning aid** to decide where *axiomatic* or *inferential* grounding is worth the cost.\n* **Perceived conservatism.** Acknowledging weak fit (CL) may lower effective reliability of otherwise strong parts. *Mitigation:* treat CL as a guide to improvement (reconcile terms, align units, verify interfaces) rather than a punishment.\n\n> **One‑line takeaway for managers.**\n> CT2R lets you **talk in natural, domain‑meaningful relations** while preserving a clear, optional path to formal grounding and empirical checking—so confidence can grow deliberately without dragging your model into tooling or syntax.\n\n",
        "rationale": "### B.3.5:13 - Rationale (informative)\n\n**13.1 Why canonical‑first?**\nCT2R‑LOG treats the **human‑readable, task‑appropriate relation** (e.g., `ut:ComponentOf`) as the **canonical publication form** because that is what engineers and managers actually use to reason, decide, and communicate. The formal layers exist to **support** that form—not to replace it. This is consistent with the authoring Standard in Part E (pattern template and style guide), which privileges **clarity, purpose and didactics** over premature formalism in the body text. Authors write *for people first*, then point to the kind of assurance they are invoking.\n\n**13.2 Why two `tv:` links—and why concept‑only?**\n`tv:AliasOf` and `tv:groundedBy` name **conceptual bridges** between a Working‑Model relation and its assurance. They are *not* mandates for any particular notational scheme; they are **mental handles** that keep authors honest about *what* grounds their claims (constructive, logical, mapping) and *when* that grounding is expected to be present. This honours the **Notational Independence** guard‑rail in Part E: we adopt **concepts and obligations**, not file formats or tool Standards, in the normative text.\n\n**13.3 Why a triad of `validationMode`?**\nThe triad **{postulate, inferential, axiomatic}** expresses a **scalable formality ladder** compatible with the FPF stance on staged assurance: start with what the team can responsibly claim now, and climb to stricter justification where risk or context demands it. That mirrors the “ladder” patterns in Part E and gives reviewers a shared vocabulary for **how strong** a claim is meant to be—without changing the canonical relation itself.\n\n**13.4 Why keep order/time out of mereology?**\nCT2R‑LOG aligns with A.14’s **firewall**: structure (parthood) is distinct from **order** and **temporal coverage**. The former is published as `ut:StructPartOf` sub‑relations; the latter live in `Γ_method` / `Γ_time` and must **not** be smuggled into part‑trees. This separation avoids classic modelling failures (temporal smearing, pseudo‑components for quantities) and keeps reasoning crisp across the Γ‑family.\n\n**13.5 Why point to `Γ_m.sum | set | slice` (Compose‑CAL) for constructive grounding?**\nThree constructive moves—**sum, set, slice**—are sufficient to narrative‑rebuild all structural trees while preserving **extensional identity**. When an author selects the *axiomatic* stance, a brief `grounding narrative` can always be told in those terms, without expanding the kernel or inventing bespoke constructors. This satisfies **parsimony (C‑5)** and keeps formal power **outside** the kernel, in a calculus.\n\n**13.6 Why mental obligations rather than process mandates?**\nPart E requires that patterns govern **thinking** and **authoring**; enforcement and automation, if any, are external concerns. CT2R‑LOG therefore states obligations as **self‑contained cognitive checks**: declare your mode; tell the constructive story only when you claim *axiomatic* strength; keep order/time in their places. This keeps the core specification **evergreen and tool‑agnostic**, as required.\n",
        "relations": "### B.3.5:14 - Relations\n\n**Builds on**\n• **A.14 Advanced Mereology** — structural catalogue and the firewall that excludes roles/recipes and distinguishes Portion/Phase/Component/Constituent; CT2R‑LOG preserves these distinctions at publication time.\n• **A.11 Ontological Parsimony (C‑5)** — constructive grounding lives in a calculus; the kernel remains minimal.\n• **B.1 Universal Γ** — shared invariants and the placement of order/time in their respective Γ‑flavours.\n• **Part E authoring rules** — canonical pattern template and notational independence, which CT2R‑LOG explicitly follows.\n\n**Coordinates with**\n• **Compose-CAL (Γ_m)** — provides the **constructive** shoulder of the Assurance layer for **structural** relations; CT2R-LOG’s `tv:groundedBy` points *conceptually* to traces narratable as **sum/set/slice**.\n• **KD‑CAL** — provides the **logical** shoulder (inferential justification) when authors pick `validationMode = inferential`.\n• **Kind-CAL / Lang‑CHR** — provide the **mapping** shoulder (type alignment and language hygiene) supporting alias policies without altering Working-Model relations.\n\n**Constrained by**\n• **Notational Independence (E.5.2)** — CT2R‑LOG refuses to prescribe formats, keeping all obligations conceptual.\n\n**Specialises / feeds**\n• **B.3.1–B.3.4** — supplies the publication discipline (Working-Model relations, declared **relation kind** and **validationMode**; **F** per C.2.3 where relevant) that B.3’s trust calculus expects; interacts with ageing and assurance-level assessments without changing the relations themselves.\n\n\n**Non‑relations**\n**No introduction of order/time** — CT2R‑LOG does **not** define `SerialStepOf` / `ParallelFactorOf` / temporal **phases**; those belong to **Method‑CAL** and **Sys‑CAL (TemporalPart)** respectively.  \n",
        "b.3.5:end": "### B.3.5:End\n"
      },
      "content": "### B.3.5:End\n",
      "metadata": {},
      "part": "B",
      "cluster": null
    },
    {
      "id": "B.4",
      "title": "Canonical Evolution Loop",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## B.4 - Canonical Evolution Loop\n",
        "problem": "### B.4:2 - **Problem**\n\nWithout a canonical, shared model for evolution, projects fall into predictable and costly failure modes:\n\n1.  **Design-Reality Divergence (The \"Drift\"):** The `run-time` artifact (the \"as-is\") slowly drifts away from its `design-time` specification (the \"as-intended\"). Over time, the formal models become elegant fictions, assurance cases become irrelevant, and the team loses the ability to reason reliably about their own creation.\n2.  **Learning Stagnation (The \"Ivory Tower\"):** Valuable insights are generated by observing a holon's performance in its context, but there is no formal method to feed this learning back into the design. \"Lessons learned\" are captured in static documents that are never acted upon.\n3.  **Chaotic Change (The \"Whack-a-Mole\"):** \"Improvements\" are made in an ad-hoc, reactive manner. Each change is a patch, not a principled refinement. This introduces hidden dependencies and unintended consequences, often making the holon more fragile over time.\n",
        "forces": "### B.4:3 - **Forces**\n\n| Force | Tension |\n| :--- | :--- |\n| **Stability vs. Change** | How to evolve a holon continuously while maintaining its core identity and assurance guarantees. |\n| **Learning vs. Operating** | How to balance the need for a holon to be stable in its operational context with the need to gather data and learn from its performance. |\n| **Top-Down Intent vs. Bottom-Up Reality** | How to reconcile strategic, top-down refinement goals with emergent, bottom-up feedback from operational reality. |\n",
        "solution": "### B.4:4 - **Solution**\n\nFPF defines the **Canonical Evolution Loop**, a four-phase cycle that serves as the universal engine for all principled, open-ended evolution. This loop is a direct implementation of the **Explore → Shape → Evidence → Operate** state machine (Pattern B.5.1) and is powered by the **Canonical Reasoning Cycle** (Pattern B.5).\n\nThe loop creates a closed, auditable circuit between the two temporal scopes. Crucially, transitions between phases are performed by an **external `Transformer`** (Pattern A.12). A holon does not evolve itself; it is evolved by an external agent acting upon it.\n\n*A diagram showing a cycle: Operate (Run-time) → Observe (Run-time to Design-time bridge, performed by a Transformer) → Refine (Design-time) → Deploy (Design-time to Run-time bridge, performed by a Transformer) → Operate.*\n\n**The Four Phases of the Loop:**\n\n| Phase | Core Activity | Role of the External `Transformer` | Key FPF Patterns Used |\n| :--- | :--- | :--- | :--- |\n| **1. Operate** | The holon exists in its `run-time` context, fulfilling its purpose. | **The `Transformer` observes the holon.** It does not act *on* it, but gathers data about its performance or state. For a `U.System`, this could be a sensor. For a `U.Episteme`, this could be a researcher applying the theory and noting its predictions. | `A.4 Temporal Duality` |\n| **2. Observe** | The `Transformer` compares the observed reality with an expected model, identifying an **anomaly** or an **opportunity**. This is the bridge from `run-time` back to `design-time`. | **The `Transformer` generates a new insight.** Based on the observation, the `Transformer` (e.g., the research team, an automated analysis system) formulates a new hypothesis about how to improve the holon. | `B.5.2 Abductive Loop`, `A.10 Evidence Graph Referring` |\n| **3. Refine** | The `design-time` model of the holon is updated by the `Transformer`. A new hypothesis is shaped (Deduction) and tested against evidence (Induction). | **The `Transformer` modifies the blueprint.** It alters the `design-time` episteme—the specification, the theory, the source code—to incorporate the new insight. | `B.5 Canonical Reasoning Cycle`, `B.3 Trust & Assurance Calculus` |\n| **4. Deploy** | The `Transformer` instantiates the refined `design-time` model as a new `run-time` version of the holon. This is the bridge that carries improvements from the blueprint back into the real world. | **The `Transformer` builds and releases the new version.** This could be a compiler building new software, a 3D printer creating a new physical part, or an editor publishing a revised version of a scientific paper. | `A.3 Transformer Constitution`, `A.4 Temporal Duality` |\n\n> **Didactic Note for Managers: The \"Learn and Adapt\" Engine**\n>\n> The Canonical Evolution Loop is your organization's formal method for **institutional learning**. It is a structured way to answer the four key questions of continuous improvement:\n> \n> 1.  **Operate:** \"Is the artifact (system, theory, process) performing its function in its environment?\"\n> 2.  **Observe:** \"What are our monitoring systems and our people (the `Transformers`) telling us? Are there any surprises or problems?\"\n> 3.  **Refine:** \"Based on what we've learned, how can our team (the `Transformer`) design a better version?\"\n> 4.  **Deploy:** \"How does our team (the `Transformer`) roll out the improved version safely and efficiently?\"\n>\n> This loop ensures that your projects don't just *deliver* once, but continuously *adapt* and *improve* based on real-world feedback. It makes the role of the acting agents (`Transformers`) in this evolution explicit and auditable.\n",
        "archetypal_grounding": "### B.4:5 - **Archetypal Grounding**\n\nThe Canonical Evolution Loop is universal. It applies identically to the evolution of physical systems, bodies of knowledge, and operational methods. The following sub-patterns detail its instantiation in each of these domains.\n\n*   **B.4-1 System Instantiation (Field Upgrade Loop):**\n    *   **Context:** A fleet of autonomous delivery drones (`U.System`) is in operation.\n    *   **Loop Example:**\n        1.  **Operate:** The drones perform deliveries.\n        2.  **Observe:** A monitoring service (`Transformer`) detects that battery performance degrades faster than expected in cold weather (an anomaly).\n        3.  **Refine:** The engineering team (`Transformer`) updates the drone's power management software (`design-time` model) with a new algorithm optimized for cold temperatures.\n        4.  **Deploy:** The team (`Transformer`) pushes the new firmware to the entire fleet. The cycle begins again.\n\n*   **B.4-2 Knowledge Instantiation (Theory Refinement Loop):**\n    *   **Context:** A scientific theory of protein folding (`U.Episteme`) is being used to predict structures.\n    *   **Loop Example:**\n        1.  **Operate:** The theory exists and is applied by researchers.\n        2.  **Observe:** A research lab (`Transformer`) discovers a new class of proteins whose structure the theory fails to predict (an anomaly). They publish this finding.\n        3.  **Refine:** Another research team (`Transformer`) revises the original theory, adding a new term to its equations (`design-time` model) that accounts for the new protein class.\n        4.  **Deploy:** The team (`Transformer`) publishes the revised theory in a journal. The scientific community begins to use the new version. **Note.** The *chart* and any CG‑frame readings derived from this episteme MUST cite the updated `MethodDescription` (per A.19.D1 CC‑A19.D1‑3) to keep comparability auditable.\n\n*   **B.4-3 Method Instantiation (Adaptive Workflow Loop):**\n    *   **Context:** A software development team uses a specific agile workflow (`U.Method`).\n    *   **Loop Example:**\n        1.  **Operate:** The team follows the defined workflow for its sprints.\n        2.  **Observe:** The scrum master (`Transformer`) notes that the time from code commit to production deployment is consistently exceeding the target SLA (an anomaly).\n        3.  **Refine:** The team (`Transformer`) redesigns its CI/CD pipeline (`design-time` model of the method), introducing a new automated testing stage to catch errors earlier.\n        4.  **Deploy:** The team (`Transformer`) implements the new pipeline configuration. The next sprint operates under the refined method. **Note.** Method evolution MUST be recorded as `Γ_method` composition over `U.Method` (design‑time) and separated from `U.Work` (run‑time), with DRR ids attached (per A.4/B.1.5).\n",
        "conformance_checklist": "### B.4:6 - **Conformance Checklist**\n\n*   **CC-B4.1 (Loop Integrity):** Any evolutionary change to a holon **MUST** be documented as a full traversal of the four-phase loop. Ad-hoc changes that bypass a phase (e.g., deploying a refinement without a documented observation and evidence phase) are a process violation.\n*   **CC-B4.2 (Temporal Scope Mandate):** The *Refine* phase **MUST** operate on `design-time` artifacts, while the *Operate* phase involves a `run-time` artifact. The *Observe* and *Deploy* phases are the only permissible bridges between these scopes.\n*   **CC-B4.3 (Transformer Mandate):** The *Observe*, *Refine*, and *Deploy* transitions **MUST** be performed by an explicitly identified external `Transformer` (Pattern A.12). A holon cannot observe, refine, or deploy itself.\n",
        "anti_patterns": "### B.4:7 - **Common Anti-Patterns and How to Avoid Them**\n\n| Anti-Pattern | Manager's View: What It Looks Like | How FPF Prevents It (Conceptually) |\n| :--- | :--- | :--- |\n| **The \"Immaculate Conception\"** | A new feature or design \"just appears\" in the specification, with no record of the problem it was meant to solve. | **CC-B4.1** and **CC-B4.3** mandate that every refinement must start with an *Observe* phase, performed by a named `Transformer`. There is no change without a documented observation and an agent who made it. |\n| **The \"Self-Healing Illusion\"** | The model claims \"the system automatically improves itself\" without specifying the mechanism. | **CC-B4.3** forbids self-evolution. The model must explicitly show an *external* `Transformer` (which could be an automated control loop, but is still modeled as external to the holon being changed) that performs the Observe-Refine-Deploy cycle. |\n| **The \"Run-time Edit\"** | An engineer makes a \"quick fix\" directly on a live system without updating the official design documents. | **CC-B4.2** enforces that all refinements happen in `design-time`. A \"hotfix\" is conceptually an emergency, accelerated run through the entire loop: the fix is observed, designed, and then deployed. |\n",
        "consequences": "### B.4:8 - **Consequences**\n\n| Benefits | Trade-offs / Mitigations |\n| :--- | :--- |\n| **Creates a \"Learning Architecture\":** The loop provides a formal, repeatable structure for continuous improvement and adaptation, making the organization's learning process explicit. | **Process Overhead:** Documenting each phase of the loop can feel bureaucratic for small, rapid changes. *Mitigation:* The conceptual requirement for a DRR (Design Rationale Record) can be lightweight. The key is to capture the *what* and *why* of the change, not to create extensive paperwork. |\n| **Ensures Design-Reality Sync:** The loop guarantees that `design-time` specifications and `run-time` realities are continuously reconciled, preventing divergence and maintaining a \"living\" assurance case. | - |\n| **Makes Evolution Auditable:** The entire lifecycle of a holon, including every refinement and the rationale behind it, becomes a traceable, auditable record performed by named `Transformers`. | - |\n",
        "rationale": "### B.4:9 - **Rationale**\n\nThis pattern operationalizes the **Open-Ended Evolution Principle (P-10)** by providing its core engine. It is the FPF's formalization of proven iterative cycles like the Deming Cycle (Plan-Do-Check-Act) and the OODA Loop (Observe-Orient-Decide-Act), but it enriches them with the strong semantic distinctions of the FPF, such as `design-time` vs. `run-time` and the formal role of the external `Transformer`.\n\nBy making the `Transformer`'s role explicit in every phase, the pattern avoids the common conceptual error of treating systems or theories as if they evolve on their own. Evolution is always an *action* performed by an agent on a holon. This rigorous, externalist stance is critical for clear causal reasoning and auditable accountability. By making this loop canonical, FPF ensures that all holons within its ecosystem are not just designed and built, but are designed *to be evolved* in a principled, traceable manner.\n",
        "relations": "### B.4:10 - **Relations**\n\n*   **Implements:** `P-10 Open-Ended Evolution`, `A.4 Temporal Duality`.\n*   **Orchestrates:** `B.5 Canonical Reasoning Cycle` (provides the cognitive engine for the *Observe* and *Refine* phases) and `B.3 Trust & Assurance Calculus` (provides the metrics for the *Evidence* sub-phase).\n*   **Is instantiated by:** The more detailed evolution loops for specific holon types, such as `B.4.1 System Instantiation`.\n",
        "b.4:end": "### B.4:End\n"
      },
      "content": "### B.4:End\n",
      "metadata": {},
      "part": "B",
      "cluster": null
    },
    {
      "id": "B.5",
      "title": "Canonical Reasoning Cycle",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## B.5 - Canonical Reasoning Cycle\n",
        "problem": "### B.5:2 - **Problem**\n\nWithout a formal, shared reasoning cycle, teams and individuals fall into predictable cognitive traps that stall progress and hide risks:\n\n1.  **Analysis Paralysis:** Teams get stuck endlessly debating existing assumptions, running deductions within a closed world of known facts without a mechanism to introduce genuinely new ideas.\n2.  **Blind Empiricism:** Teams engage in unstructured, expensive trial-and-error, running tests and gathering data (induction) without a clear, falsifiable hypothesis to guide their efforts.\n3.  **Innovation Gap:** In the face of a problem where existing knowledge is insufficient, there is no formal \"permission\" or process to generate a creative, plausible guess—the essential first step of any breakthrough.\n\nThese pathologies lead to wasted resources, circular debates, and a failure to solve the very problems that require first-principles thinking.\n",
        "forces": "### B.5:3 - **Forces**\n\n| Force | Tension |\n| :--- | :--- |\n| **Rigor vs. Innovation** | How can we encourage creative, \"out-of-the-box\" hypotheses while maintaining formal discipline and verifiability? |\n| **Certainty vs. Progress** | How can we act and learn systematically when faced with incomplete information and uncertainty? |\n| **Theory vs. Practice** | How do we ensure that abstract models and formal deductions are continuously anchored to real-world evidence and empirical validation? |\n| **Systematic Flow** | How do we transform problem-solving from a chaotic, ad-hoc art into a repeatable, auditable, and teachable science? |\n",
        "solution": "### B.5:4 - **Solution**\n\nFPF establishes the **Abductive–Deductive–Inductive Loop** as its canonical reasoning cycle. This cycle gives formal primacy to **abduction** (hypothesis generation) as the engine of innovation, while using deduction and induction as the rigorous mechanisms for testing and refining those hypotheses.\n\nThe loop consists of three distinct, sequential phases:\n\n#### B.5:4.1 - Abduction (Hypothesis Generation)\n\n*   **Core Question:** \"What is the most plausible new explanation or solution?\"\n*   **Description:** This is the creative, inventive leap. When faced with an anomaly, a design challenge, or an unanswered question, the first step is to propose a new `U.Episteme`—a new requirement, a new component, a new causal link—that *might* solve the problem. This act is not guaranteed to be correct; it is a conjecture. Within FPF, this new, untested artifact typically begins its life at **`AssuranceLevel:L0 (Unsubstantiated)`**. Abduction is the only phase that introduces genuinely novel ideas into the model. This formalizes the process described in the **Abductive Loop** (Pattern B.5.2).\n\n#### B.5:4.2 - Deduction (Consequence Derivation)\n\n*   **Core Question:** \"If this hypothesis is true, what logically follows?\"\n*   **Description:** This is the phase of rigorous analysis. Given the new hypothesis, we use the formal models and calculi of FPF to deduce its logical consequences. What are its testable predictions? Does it create internal contradictions with other parts of the model? How does it propagate through the system? This phase aligns with **Verification Assurance (VA)** and is concerned with raising the artifact's **FormalVerifiabilityScore (FV)**. Deduction turns a plausible idea into a set of precise, falsifiable claims.\n\n#### B.5:4.3 - Induction (Empirical Evaluation)\n\n*   **Core Question:** \"Do the predicted consequences match reality?\"\n*   **Description:** This is the phase of testing and learning from evidence. The predictions derived in the deductive phase are compared against real-world data from experiments, simulations, or observations. This phase aligns with **Validation Assurance (LA)** and is the primary mechanism for raising an artifact's **EmpiricalValidabilityScore (EV)** and, consequently, its **Reliability (R)**. A successful test corroborates the hypothesis (raising its `AssuranceLevel`), while a failed test (a refutation) provides critical new information that feeds back into the next abductive cycle.\n\n#### B.5:4.4 - **Didactic Note for Managers: The \"Propose → Analyze → Test\" Cycle**\n>\n> The Abductive-Deductive-Inductive loop is not an abstract philosophical concept; it is the formal name for the problem-solving cycle that all successful R&D and engineering teams instinctively use.\n>\n> | Phase | Simple Name | What Your Team Does | FPF's Contribution |\n> | :--- | :--- | :--- | :--- |\n> | **Abduction** | **Propose** | Brainstorms a new feature, architecture, or fix. | Gives formal permission for this creative step and a place to record the new idea (`L0` artifact). |\n| **Deduction** | **Analyze** | Thinks through the implications, runs simulations, checks for conflicts. | Provides the formal models (VA, FV) to make this analysis rigorous and repeatable. |\n| **Induction** | **Test** | Builds a prototype, runs A/B tests, gathers user feedback. | Provides the framework (LA, EV, R) to measure the results and build an auditable evidence base. |\n>\n> By making this cycle explicit, FPF transforms problem-solving from a chaotic art into a repeatable, auditable science. It gives teams a shared map for navigating from an unknown problem to a validated solution.\n",
        "conformance_checklist": "### B.5:5 - **Conformance Checklist**\n\nTo ensure the reasoning cycle is applied consistently and rigorously, the following criteria are normative:\n\n*   **CC-B5.1 (Abductive Primacy):** Any discipline that introduces a new, non-derivable claim or design element into a working model **MUST** document it as an abductive step. The resulting artifact **SHALL** initially be assigned `AssuranceLevel:L0`.\n*   **CC-B5.2 (Deductive Mandate):** An abductively generated hypothesis **SHALL NOT** be subjected to inductive testing (Validation Assurance) until its key logical consequences have been derived and documented through a deductive process.\n*   **CC-B5.3 (Inductive Grounding):** A claim **SHALL NOT** be promoted to `AssuranceLevel:L1` or higher on the basis of a successful inductive test unless that test is explicitly linked to a prediction derived in the deductive phase.\n*   **CC-B5.4 (Cycle Closure):** The outcome of an inductive test (whether corroboration or refutation) **MUST** be formally recorded as an evidence artifact (Pattern A.10), and this artifact **MUST** be used as an input for the next iteration of the reasoning cycle.\n*   **CC-B5.5 (State Machine Alignment):** The Abductive–Deductive–Inductive Loop is the cognitive engine that drives state transitions in the **Explore → Shape → Evidence → Operate** state machine (Pattern B.5.1). Abduction dominates the *Explore* phase; Deduction dominates the *Shape* phase; and Induction is the core of the *Evidence* phase.\n\n**Common Anti-Patterns and How to Avoid Them**\n\n| Anti-Pattern | Manager's View: What It Looks Like | How FPF Prevents It |\n| :--- | :--- | :--- |\n| **The \"Solution in Search of a Problem\"** | A team builds a technically impressive feature (deduction/induction) but cannot clearly state what user problem it solves. | **CC-B5.1** forces the process to start with an abductive hypothesis that is explicitly framed as a solution to a stated problem or anomaly. |\n| **The \"Ready, Fire, Aim\" Approach** | A team jumps directly from an idea to expensive prototyping and testing, without a clear model of what they expect to happen. | **CC-B5.2** mandates a deductive analysis phase *before* inductive testing. This ensures that every test is designed to confirm or refute a specific, well-defined prediction. |\n| **The \"Data Dredging\" Exercise** | A team gathers massive amounts of data and looks for correlations, hoping a solution will emerge. | The cycle requires a hypothesis *first*. Data is gathered to test that hypothesis, not in the hope of stumbling upon one. This makes the process more focused and cost-effective. |\n",
        "consequences": "### B.5:6 - **Consequences**\n\n| Benefits | Trade-offs / Mitigations |\n| :--- | :--- |\n| **Encourages Innovation:** By formally sanctioning abduction, the framework creates a safe and structured space for creative problem-solving and the introduction of novel ideas. | **Abduction is not algorithmic:** The framework cannot tell you *how* to generate a good hypothesis. *Mitigation:* It provides the structure to capture and test hypotheses, and can be used in conjunction with creative methodologies (e.g., TRIZ, design thinking) that specialize in hypothesis generation. |\n| **Improves Problem-Solving Efficiency:** The cycle provides a clear, repeatable workflow that prevents teams from getting stuck in analysis paralysis or wasting resources on unfocused testing. It ensures that effort is always directed toward falsifying or corroborating a clear claim. | **Requires Iterative Mindset:** The cycle is inherently iterative. Teams must be prepared for hypotheses to be refuted and for the need to restart the cycle. *Mitigation:* FPF's architecture (e.g., cheap state transitions) is designed to make this iteration low-cost. |\n| **Creates a Transparent Rationale:** The cycle produces a complete, auditable trail of how a solution was developed: which hypotheses were proposed, what their consequences were, and how they fared against empirical evidence. This \"intellectual provenance\" is invaluable for future maintenance, audits, and learning. | - |\n| **Aligns with Scientific and Engineering Best Practices:** The cycle is a formalization of the scientific method (conjecture and refutation) and modern engineering design cycles (e.g., Deming's PDCA loop). | - |\n",
        "rationale": "### B.5:7 - **Rationale**\n\nFPF is designed to be an \"operating system for thought,\" and this reasoning cycle is its central processing unit. By elevating abduction to a first-class citizen, FPF acknowledges a fundamental truth about complex problem-solving: progress does not come from simply rearranging known facts (deduction) or finding patterns in data (induction). It comes from the creative act of proposing a new way of seeing the world—a new hypothesis. Deduction and induction are the indispensable tools we use to discipline and validate this creativity.\n\nThis pattern provides the engine that drives an artifact up the ladder of `AssuranceLevels`. An abductive leap creates an `L0` artifact. Deduction begins the process of providing **Verification Assurance**, building its `FV` score. Induction provides the **Validation Assurance**, building its `EV` and `R` scores. Without this cycle, the assurance framework would be a static scoring system; with it, it becomes a dynamic model of knowledge growth.\n",
        "relations": "### B.5:8 - **Relations**\n\n*   **Integrates:** `B.5.1 Explore → Shape → Evidence → Operate`, `B.5.2 Abductive Loop`.\n*   **Drives:** The progression through `B.3.3 Assurance Subtypes & Levels`.\n*   **Enables:** The refinement phase of the `B.4 Canonical Evolution Loop`.\n*   **Operationalizes:** The core FPF mission of transforming ideas into reliable, evidence-backed holons.\n",
        "b.5:end": "### B.5:End\n"
      },
      "content": "### B.5:End\n",
      "metadata": {},
      "part": "B",
      "cluster": null
    },
    {
      "id": "B.5.1",
      "title": "Explore → Shape → Evidence → Operate",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## B.5.1 - Explore → Shape → Evidence → Operate\n",
        "problem": "### B.5.1:2 - **Problem**\n\nHow do we provide a simple, universal state machine that guides an artifact's journey from a raw concept to a reliable, operational holon? This pattern defines the four canonical states of this journey, providing a clear roadmap for teams and a stable framework for project management.\n",
        "solution": "### B.5.1:3 - **Solution**\n\nFPF defines a four-state development cycle model for any artifact (`U.Episteme` or `U.System`). An artifact transitions from one state to the next as it accumulates rigor and evidence. This state machine is driven by the **Canonical Reasoning Cycle** (Pattern B.5).\n\n**The Four States of an Artifact's Lifecycle:**\n\n| State | Core Activity | Manager's View: What It Means | Driven by Phase of Reasoning Cycle | Typical `AssuranceLevel` |\n| :--- | :--- | :--- | :--- | :--- |\n| **1. Exploration** | **Generating possibilities.** The focus is on brainstorming, questioning assumptions, and generating multiple, often competing, hypotheses. | \"We are in the 'what if' phase. All ideas are on the table. We are looking for a plausible path forward.\" | **Abduction** (Pattern B.5.2) | `L0` |\n| **2. Shaping** | **Defining a single, coherent form.** The most promising hypothesis from the exploration phase is selected and given a rigorous, internally consistent structure. | \"We've chosen our direction. Now we are building the blueprint, defining the architecture, and ensuring all the pieces fit together logically.\"| **Deduction** | `L0` → `L1` (if formalization counts as TA) |\n| **3. Evidence** | **Testing against reality.** The shaped artifact is subjected to rigorous empirical or formal tests to validate its claims and measure its performance. | \"The blueprint is done. Now we are at the proving ground. Does it actually work? We are running the tests and gathering the data.\" | **Induction** | `L1` → `L2` |\n| **4. Operation** | **Deploying and monitoring in a live environment.** The validated artifact is put into production, where it performs its intended function and is monitored for ongoing reliability. | \"It's live. The system is in service, delivering value, and we are monitoring its health and performance.\" | Continuous Induction (Monitoring) | `L2` (maintained) |\n\n> **Didactic Note for Managers: Aligning States with Your Project Plan**\n>\n> This state machine is not an abstract theory; it maps directly to the familiar phases of any well-run project.\n>\n> *   **Exploration** is your R&D or initial discovery sprint.\n> *   **Shaping** is your design and architecture phase.\n> *   **Evidence** is your QA, testing, and V&V phase.\n> *   **Operation** is the live deployment and maintenance phase.\n>\n> By using these four states, you can instantly communicate to your team and stakeholders exactly where an artifact is in its state transition, what the current focus is, and what needs to happen to move to the next stage.\n",
        "conformance_checklist": "### B.5.1:4 - **Conformance Checklist**\n\n*   **CC-B5.1.1 (State Explicitness):** Every artifact in a project **MUST** be tagged with its current state from the set {Exploration, Shaping, Evidence, Operation}.\n*   **CC-B5.1.2 (Sequential Progression):** An artifact **SHALL** progress through the states in sequence. Skipping a state (e.g., moving directly from Exploration to Evidence without Shaping) is a process violation and must be explicitly justified in the artifact's rationale.\n*   **CC-B5.1.3 (Reasoning Cycle Alignment):** The transition between states **MUST** be triggered by the completion of the corresponding phase of the Canonical Reasoning Cycle (Pattern B.5). For example, the transition from *Shaping* to *Evidence* requires the completion of the deductive analysis.\n",
        "consequences": "### B.5.1:5 - **Consequences**\n\n| Benefits | Trade-offs / Mitigations |\n| :--- | :--- |\n| **Clear Project Visibility:** The state machine provides a simple, shared language for tracking the maturity of every artifact in a project. | **Risk of Bureaucracy:** If applied too rigidly, the state machine could feel like a waterfall process. *Mitigation:* The cycle is meant to be rapid and iterative. A single artifact might cycle through all four states within a single sprint. The goal is clarity, not ceremony. |\n| **Improved Focus:** Each state has a clear primary activity, which helps teams focus their efforts and avoid common pitfalls like premature optimization or untested designs. | - |\n| **Reduces \"It's Done\" Ambiguity:** The states provide a precise definition of \"done\" for each phase. An artifact is not \"done\" with Shaping until its structure is coherent and its consequences are deduced. | - |\n",
        "rationale": "### B.5.1:6 - **Rationale**\n\nThis pattern operationalizes the **Principle of State Explicitness (P-9)**. By giving every artifact a clear, unambiguous state, FPF transforms the often-chaotic process of innovation into a structured, manageable, and auditable development cycle. This state machine provides the \"scaffolding\" upon which the more detailed cognitive work of the Canonical Reasoning Cycle is performed, ensuring that every idea is systematically guided from a speculative guess to a reliable operational reality.\n",
        "relations": "### B.5.1:7 - **Relations**\n\n*   **Is driven by:** `B.5 Canonical Reasoning Cycle`.\n*   **Organizes the progression of:** `B.3.3 Assurance Subtypes & Levels`.\n*   **Provides the states for:** `B.4 Canonical Evolution Loop`.\n",
        "b.5.1:end": "### B.5.1:End\n"
      },
      "content": "### B.5.1:End\n",
      "metadata": {},
      "part": "B",
      "cluster": null
    },
    {
      "id": "B.5.2",
      "title": "Abductive Loop",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## B.5.2 - Abductive Loop\n",
        "problem": "### B.5.2.1:2 - Intent & Problem\n\n**Intent.** Turn Step 2 (*generate*) and Step 3 (*filter*) of the Abductive Loop from ad‑hoc brainstorming into a **disciplined, instrumented exploration** that can (i) *produce many* distinct, plausible hypotheses and (ii) *surface the few worth pursuing*—*without* bloating the kernel or forcing a specific creative method.\n\n**Problem.** Unstructured ideation routinely fails on two fronts: it either produces *too little variety* (pet ideas win by seniority) or *too little plausibility* (grand theories with no testable predictions). **B.5.2** names these failure modes; this plug‑in adds a minimal, measurable counter‑mechanism aligned to FPF’s assurance lanes and state machine.\n",
        "forces": "### B.5.2:3 - **Forces**\n\n| Force | Tension |\n| :--- | :--- |\n| **Creativity vs. Discipline** | How can we encourage bold, imaginative leaps while ensuring they are grounded, plausible, and lead to testable outcomes? |\n| **Speed vs. Rigor** | How can we generate new ideas quickly without sacrificing the analytical rigor needed to vet them? |\n| **Openness vs. Focus** | How can we explore a wide range of possibilities without getting lost in endless, unproductive speculation? |\n",
        "solution": "### B.5.2.1:4 - Solution — **Binding to Γ_nqd.generate (C.18)**\n\n**Method name (Plain/Unified Tech).** *NQD‑Generate* — a **U.Method** that, given (i) a **HypothesisSpace** and (ii) a **CharacteristicSpace** with a **CoverageGrid**, returns a *finite*, **non‑dominated** set of candidate hypotheses that maximize **Quality** (per‑component) while maintaining **Diversity** and encouraging **Novelty**.\n\n**Minimal signature.**\n\n* **Inputs (declared in MethodDescription):**\n `HypothesisSpace`, `CharacteristicSpace`, `Seeds?`, `Budget (time/compute)`, `EmitterPolicy` (**E/E-LOG policy id**), `QualityMeasures (Q components)`, `NoveltyMetric`, `CoverageGrid/Granularity`, `CellCapacity K? (default=1)`, `EpsilonDominance ε? (default=0)`, `TieBreakPolicy? (S/I)`, `DedupThreshold?`, `Policy(TimeWindow)`, `DeterminismSeed?`\n \n* **Outputs:**\n  CandidateSet = {h_i: (desc_i, Q_i, N_i, D_i:=ΔDiversity_P(h_i | Pool), S_i, I_i, UseValue_i?), genealogy_i?, provenance_i (including **DHCMethodRef.edition** and **policyId** from E/E-LOG)} where `Q_i` is a vector and `provenance_i` captures generator settings and evaluation sources. If Use‑Value is present, include the objective id / acceptanceSpec, counterfactual method (if predicted), and model edition per C.17. Note: S and I are tie-breakers only unless promoted by explicit Context policy; Use-Value is informative for decision lenses and SHALL NOT enter the dominance set.\n\n**Strategy (notation‑neutral).**\n\n1. **Seeding.** Initialize with seeds (known solutions, random draws, or prior L0 artifacts).\n2. **Iterated illumination.** Propose variations, evaluate **Q** (per‑component); maintain up to **K** elites per cell (or descriptor bucket); compute **N/D/S/I** on the fly; deduplicate by `DedupThreshold` in **CharacteristicSpace**.\n3. **Budget‑bounded loop.** Iterate until budget or coverage‑convergence; return the **(ε‑)Pareto front** over `{Q₁…Q_k, D, N, ΔDiversity_P}` (do **not** collapse to a single scalar). Illumination is excluded from the dominance set by default; Surprise and Illumination act only as tie-breakers unless a Context policy explicitly promotes them. **Use-Value** may appear as a **side note** for decision discussions **but MUST NOT be mixed into NQD dominance set**.   \n4. **Traceability.** Emit a **Design Rationale Record (DRR)**: grids/metrics versions, seed(s), policy and `TimeWindow`, which cells were filled, why items were dominated (list **Characteristics**), and how the final set was produced (including `ε`, `K`, and dedup). (Lightweight DRR is permitted per B.4 guidance.)\n5. **Algorithmic freedom (informative).** Implementations MAY use MAP‑Elites/illumination, novelty search with local competition, Bayesian/surrogate‑assisted search, or deterministic enumerations; ε‑dominance or knee‑point thinning MAY be used *after* recording the full front in provenance.\n\n> **No kernel growth.** This is a *Method* (C.4 Method‑CAL) plus a CHR import; **no new Γ‑operator** is added (per **A.11**).\n",
        "conformance_checklist": "### B.5.2.1:6 - Conformance Checklist (normative)\n\n**CC‑B.5.2.1‑1 (CHR discipline).** If a Context uses this plug‑in, it **SHALL** declare the Creativity‑CHR **Characteristics** with **A.18**‑style templates (type, unit/range, polarity). No new kernel terms are introduced.\n**CC‑B.5.2.1‑2 (Instrumented generation).** Step 2 of **B.5.2** **SHALL** either (a) invoke *NQD‑Generate* or (b) justify a Context‑specific generator of equivalent effect (diversity + quality + novelty with measurable **Characteristics**).\n**CC‑B.5.2.1‑3 (Diversity coupling).** When this plug‑in is used, **D MUST be ΔDiversity_P** computed against the current candidate Pool using the **C.17** definition of **Diversity_P** under the same Context, CharacteristicSpace, kernel, and TimeWindow.\n**CC‑B.5.2.1‑Eligibility**: Eligibility requires **(i)** `ConstraintFit = pass` for the candidate (Norm‑CAL must‑set), **then (ii)** **USM** coverage for the TargetSlice and **(iii)** an enactable **RSG** state for the performer; only then may calls to `Γ_nqd.*` occur.\n**CC‑B.5.2.1‑4 (Non‑dominated shortlist).** The *CandidateSet* **MUST** include the **Pareto front** over `{Q₁…Q_k, N, D}`; any pruned candidate **MUST** carry a DRR note (“dominated by … on {Characteristics}”).\n**CC‑B5.2.1‑5 (Abductive primacy preserved).** The plug‑in **MUST NOT** bypass the ADI ordering mandated by **B.5**: induction may not start before deduction; abductive L0 creation remains the start.\n**CC‑B.5.2.1‑6 (Normalization for Pareto).** When **Q** has multiple components with different units/scales, Contexts **SHALL** normalize or use declared utility‑free monotone transforms before dominance tests.\n**CC‑B.5.2.1‑7 (Use‑Value separation). ** If Use‑Value (C.17 §5.2) is recorded, it SHALL remain outside Assurance scores; it MAY inform decision lenses (Decsn‑CAL). Do not alter **R/G** semantics based on Use‑Value. (see **C.17 §5.2** for `Use-Value / ValueGain` definition)\n**CC‑B.5.2.1‑8 (Provenance).** Each `h_i` in the *CandidateSet* **MUST** reference its `provenance_i` sufficient to reproduce scores given the same `Policy(TimeWindow)`, score/metric versions, and `DeterminismSeed?`.\n**CC‑B.5.2.1‑9 (Secondary metrics).** **I (illumination)** and **S (surprise)** SHALL be used only for tie‑breaking/reporting unless explicitly promoted by policy; the **primary dominance test is over {Q components}** by default.\n**CC‑B.5.2.1‑10 (Cell capacity & ε).** If `K>1` or `ε>0` are used, the values MUST be declared and recorded in provenance; any thinning AFTER recording the front SHALL be documented in the DRR.\n**CC‑B.5.2.1‑11 (Dominance set).** By default the dominance set **SHALL be {Q components}**; **N (Novelty@context)** and **ΔDiversity_P** act as **tie‑breakers** unless explicitly promoted by **policy** (record the policy‑id in provenance).\n",
        "consequences": "### B.5.2:6 - **Consequences**\n\n| Benefits | Trade-offs / Mitigations |\n| :--- | :--- |\n| **Structured Innovation:** The loop provides a repeatable, auditable method for generating high-quality hypotheses, making innovation a manageable engineering activity rather than a random event. | **Cognitive Effort:** Applying the plausibility filters requires deliberate, critical thinking. *Mitigation:* The method is designed to be lightweight and rapid. A team can cycle through the loop multiple times in a single workshop session. |\n| **Improved Decision Quality:** By forcing the consideration of multiple alternatives and the application of explicit filters, the process significantly increases the quality and robustness of the selected hypothesis. | - |\n| **Enhanced Traceability and Learning:** The process creates a clear record of the \"why\" behind a design choice—which problem was being solved, what alternatives were considered, and why the chosen path was selected. This is invaluable for future learning and onboarding. | - |\n| **Resource Optimization:** The loop acts as a \"quality gate\" for ideas. It ensures that only the most plausible and promising hypotheses proceed to the more resource-intensive deductive and inductive phases, saving significant time and money. | - |\n",
        "rationale": "### B.5.2:7 - **Rationale**\n\nThe Abductive Loop is the formal heart of the **Exploration** state (Pattern B.5.1). It operationalizes the principle that all rigorous inquiry begins with a well-formed question and a plausible, falsifiable answer. While FPF cannot automate creativity, it can and must provide a disciplined scaffold to guide it. This loop provides that scaffold.\n\nIt directly implements the **Primacy of Abduction** (from ADR-005) by placing hypothesis generation at the very start of the reasoning process. It is the engine that creates the initial `L0` artifacts that are the raw material for the rest of the FPF assurance lifecycle. By making this often-implicit process explicit, auditable, and repeatable, FPF provides a powerful tool for navigating the uncertainty and complexity inherent in any frontier-pushing project.\n",
        "relations": "### B.5.2:8 - **Relations**\n\n*   **Is the first step of:** `B.5 Canonical Reasoning Cycle`.\n*   **Takes place during:** `B.5.1 Exploration` state.\n*   **Produces:** `AssuranceLevel:L0` artifacts, which become the input for deductive analysis and subsequent progression through `B.3.3 Assurance Subtypes & Levels`.\n*   **Is informed by:** The **Role-Projection Bridge** (Pattern B.5.3), which can provide a rich vocabulary of domain-specific concepts to use in generating hypotheses.\n",
        "b.5.2:end": "### B.5.2:End\n\n## B.5.2.1 - Creative Abduction with NQD\n\n**Status.** Normative **binding** to **B.5.2 Abductive Loop** that delegates candidate generation to **Γ_nqd.generate** (**C.18 NQD-CAL**) and exploration/exploitation policy to **E/E-LOG (C.19)**; the kernel remains unchanged.\n\n**Non‑duplication & parsimony.** “Introduces **no new kernel primitives**; reuses the CHR kit (**A.17/A.18**) to define measurable **Characteristics**. This pattern does not introduce new eligibility conditions. Application is permitted only when USM coverage holds for the target slice and the performer’s RSG state is enactable (eligibility), without prescribing any team workflow. Per **A.11 Ontological Parsimony**, only a context‑local CHR import and a **Method** are added; **no changes to Γ/LOG**. All generation is performed via **Γ_nqd.* (C.18)** and all exploration/exploitation control via **E/E-LOG (C.19)**. \n**Terminology discipline.** Use **NQD** consistently (Novelty–Quality–Diversity). Treat **S**/**I** as *secondary* metrics unless explicitly promoted by policy (see §3, §5).\n",
        "b.5.2.1:3___the_**creativity‑chr**_(references_only;_no_re‑definitions_here)": "### B.5.2.1:3 - The **Creativity‑CHR** (references only; no re‑definitions here)\n\nThis binding **references** the context‑local **Creativity‑CHR** (see **C.17**) and **does not** restate measurement templates. The primary coordinates are:\n• **`Novelty@context`** (C.17 §5.1), • **`ΔDiversity_P`** (marginal; C.17 §5.5), and • **`Q` components** (per A.18).  \n**`Surprise`** and **`Illumination`** are **secondary**: Illumination is **report‑only telemetry** (published as **`IlluminationSummary`** over `Diversity_P`); both act as **tie‑breakers** unless explicitly promoted by policy (C.19).  \n**`Use‑Value`** (*alias:* `ValueGain`) is **informative for decision lenses** (Decsn‑CAL) and **MUST NOT** enter NQD dominance by default (see C.17 §5.2).\n\nAll listed **Characteristics** are **context‑local** with explicit units/ranges and **polarity↑**. They are *measurements*, not eligibility conditions; eligibility conditions are supplied by **USM/RSG**. (Complies with **A.18** measurement discipline; does not overload assurance semantics.)\n\n> **Lexical discipline.** The items above are **Characteristics** in the sense of **A.17/A.18**; avoid reserved names such as “validity” or “operation.”\n> **Normalization note.** If a **QualityVector** has heterogeneous units, Contexts SHALL normalize or nondimensionalize each component before Pareto analysis (see CC‑B.5.2.1‑7).\n> **D vs I (normative).** **D = ΔDiversity_P** (marginal gain) and is eligible for the primary dominance test. **I** is _portfolio illumination_ (report/visual); it **SHALL NOT** be part of the primary dominance test and is usable **only** as an explicit tie-break per policy.\n> **Measurement invariants.** Distances, grids, and transforms MUST be declared once per run, versioned, and referenced from provenance (§3, §5).\n",
        "b.5.2.1:5___implementation_&_binding_into_**b.5.2**_(two_injection_points)": "### B.5.2.1:5 - Implementation & Binding into **B.5.2** (two injection points)\n\n**Step 2 — Generate candidates.** \n**Precondition (USM+RSG).** Generation is permitted only when the **Claim/Work Scope** covers the TargetSlice (USM) **and** the performer’s **RoleAssignment** is in an **enactable RSG state** (Green-Gate law). \n\nWhen the plug‑in is imported, replace or *supplement* freeform brainstorming with **NQD‑Generate**; the output is a *pool* of L0 hypotheses annotated by `{N, D, Q, S, I, V?}` **plus provenance/DRR refs**. The abductive step remains *abduction* (a conjecture), now instrumented and diverse by construction.\n\n**Step 3 — Plausibility filters.** Apply B.5.2’s plausibility criteria, now with explicit hooks:\n\n* **Falsifiability** → filter out ideas with no testable predictions in the **Shaping/Evidence** states (B.5 alignment).\n* **Explanatory power** → prioritize candidates whose *Q‑improvements* (and attached rationales) align with the framed anomaly.\n\nThe *selected* “prime hypothesis” proceeds exactly as in B.5.2: formalize it as a new `U.Episteme` at **L0**, then move to Deduction/Induction.\n\nPrimary dominance test: compute the (ε-)Pareto front over {Q components}. By default, N (Novelty@context) and ΔDiversity_P act only as tie-breakers unless a policy explicitly promotes them into the dominance set; S (Surprise) and I (Illumination) are also tie-break/report-only by default; Use-Value remains non-dominant.\n\n**Defaults (if policy is unspecified)**  \n> **Dominance:** `{Q components}`, with `ConstraintFit=pass` as **eligibility gate**.  \n> **Tie‑breakers:** `Novelty@context`, `ΔDiversity_P`, and `Surprise`; `IlluminationSummary (telemetry summary over Diversity_P)` remains report‑only unless a CAL policy promotes it.  \n> **Archive:** `K=1`, `ε=0`, deduplication in `CharacteristicSpace`.  \n> **Policy:** UCB‑class with moderate temperature; `explore_share ≈ 0.3–0.5`.  \n> **Provenance (minimum):** record `DescriptorMapRef.edition`, `DistanceDefRef.edition`, `EmitterPolicyRef`, `TimeWindow`, `Seeds`.\n\n“**Scope‑of‑claim annotation (descriptive).** Record the **BoundedContext** and **TimeWindow** that delimit where each **N/Q/D** measurement is intended to hold; this is for reasoning traceability only (no operational gates).”\n\nNote — Status `Surprise` (scope and default role):\nBy default in B.5.2.1, `Surprise` functions solely as a secondary tie‑break among candidates that are otherwise Pareto‑equivalent on the Context’s primary characteristics. A Context policy MAY elevate `Surprise` into the dominance set, allowing it to enter the CreativitySpace dominance alongside the primary characteristics.  If no Context policy is specified, the default tie‑break role applies.\n",
        "b.5.2.1:7___cognitive_load_&_kernel_growth_budget": "### B.5.2.1:7 - Cognitive Load & Kernel Growth Budget\n\n**For engineers/managers (user cognitive load).**\n\n* *Added steps:* selecting descriptor **Characteristics** & granularity; reading a Pareto table (**non‑statisticians tip:** scan the “front” row; ignore dominated rows).\n* *Mitigations:* provide a one‑screen “NQD Cards” template analogous to RSG cards; default grids and metrics per Context. (Keep ≤ 7 visible **Characteristics**—mirrors RSG human‑scale guidance.)\n* *Reader quickstart (engineer‑manager):* (1) Pick 2–3 **Q** characteristics aligned to the anomaly + a simple **CharacteristicSpace** (2–4 dimensions). (2) Accept defaults for `NoveltyMetric`, grid granularity, and `K=1`. (3) Run **NQD‑Generate** to a fixed budget; read the *front row* first. (4) Apply Step 3 filters; log decisions in the DRR.\n\n**For the framework (kernel growth).**\n\n* *Zero* new primitives; only a CHR import and a **Method**. Passes **A.11** minimal‑sufficiency. \n",
        "b.5.2.1:8___placement_in_the_reasoning_cycle_(adi)": "### B.5.2.1:8 - Placement in the Reasoning Cycle (ADI)\n\nThis plug‑in **only structures hypothesis exploration** (Abduction) and does not define or imply any **operational** gates. It respects ADI ordering (Abduct → Deduct → Induct) and leaves deployment/readiness concerns to patterns outside this spec.\n",
        "b.5.2.1:9___context‑level_kpis_(optional,_informative)": "### B.5.2.1:9 - Context‑Level KPIs (optional, informative)\n\nContexts *may* monitor these—*not* as gates, but to improve practice:\n\n1. **Generativity (Gv).** Fraction of abductive cycles whose selected candidate reaches **L1/L2** within policy windows (time‑to‑L1; time‑to‑evidence). (Maps onto state transitions driven by **B.5**.)\n2. **Frontier‑Hit Rate (FHR).** % of cycles where the chosen candidate lies on the **Pareto front** of `{Q, N, D}` at selection time.\n3. Coverage Gain (ΔI, report). Change in the *illumination summary* (coverage map/%filled cells) per cycle (how much of the descriptor space is now “lit”).\n4. **Exploration Cost Ratio (ECR).** Compute/time spent in NQD‑Generate divided by downstream Shape/Evidence cost saved (tracks whether the plug‑in pays for itself).\n5. **Refutation Learning Yield (RLY).** Among *refuted* candidates, % that added new coverage or raised SurpriseScore—turning “failures” into map‑building.\n",
        "b.5.2.1:10___worked_micro‑example_(abbreviated)": "### B.5.2.1:10 - Worked micro‑example (abbreviated)\n\n**Framing = Step 1 in B.5.2**\n**Context:** A Context using FPF to evolve FPF itself (meta‑improvement). *Anomaly:* “Users perceive FPF as compliance‑heavy; we need first‑principles creativity surfaced.” \n\n**Step 2 (NQD‑Generate).**\n\n* **CharacteristicSpace:** {*creative‑characteristic count*, *explicit novelty metric present?*, *QD operator present?*, *didactic cards present?*}. *(Illustrative; Contexts SHALL define their own descriptors per §2.)*\n* **Q‑measures:** {*editor effort↓*, *time‑to‑L1↓*, *reader clarity↑*}.\n* **Output Pareto set (sketch):**\n\n  * `h₁ = “Add Creativity‑CHR + NQD plug‑in (this pattern)”` — high *D*, high *N*, medium *Q*.\n  * `h₂ = “Rename governance terms to arts vocabulary”` — low *N*, low *D*, medium *Q*.\n  * `h₃ = “Add live ideation sandbox (ops tooling)”` — medium *N*, medium *D*, high *Q*.\n\n**Step 3 (Filters).**\n\n* **Falsifiability:** `h₂` weak—no testable prediction → drop.\n* **Scope (USM):** `h₁` scoped to Part B; `TimeWindow = edition 2025‑Q4` → *covers TargetSlice*. `h₃` crosses Contexts (tooling) → requires Bridge; the overhead is accounted for in **R** (not **F/G**). *(This plug‑in does not create or alter Bridges.)*\n* **Select prime:** `h₁` → formalize as L0 episteme (this pattern), move to *Shaping* (define checklist), then *Evidence* (track KPIs).\n",
        "b.5.2.1:10___trade‑offs_&_mitigations": "### B.5.2.1:10 - Trade‑offs & mitigations\n\n* **Cognitive effort.** Interpreting Pareto sets and coverage maps adds thinking overhead. *Mitigation:* standard “NQD Card” + default grids; keep **Characteristics** small in number (≤ 7). *Manager shortcut:* pick 2–3 **Q** characteristics that reflect the anomaly, then run with defaults.\n* **Locality.** Novelty/diversity are **context‑local**; Cross‑context reuse requires **re‑measurement or an explicit mapping**. This pattern **does not define** Cross‑context operational controls.\n* **Not a magic idea machine.** Abduction remains human/agentic; the plug‑in *structures* search, it does not automate insight. B.5’s abductive primacy stands.\n* **Metric gaming & collinearity.** Avoid making **N** and **S** redundant by policy; when strong collinearity is detected, freeze one as informative only and record rationale in the DRR.\n",
        "b.5.2.1:11___related_patterns": "### B.5.2.1:11 - Related Patterns\n\n* **Extends:** **B.5.2 Abductive Loop** (Step 2/3 operationalization). \n* **Driven by / feeds:** **B.5 Canonical Reasoning Cycle** (Abduction→Deduction→Induction), **B.4 Evolution Loop** (Observe/Refine). \n* **Uses:** **A.17/A.18** for characteristic discipline and **B.5 ADI ordering**. **May** refer to Context‑specific MAP‑Elites/novelty‑search implementations in the MethodDescription. **No operational gating is in scope here.** C.17 (Use‑Value / ValueGain, normative definition).\n* **Respects:** **A.11** (no kernel growth beyond CHR template import + Method).\n  ",
        "b.5.2.1:end": "### B.5.2.1:End\n"
      },
      "content": "### B.5.2.1:End\n",
      "metadata": {},
      "part": "B",
      "cluster": null
    },
    {
      "id": "B.5.3",
      "title": "Role-Projection Bridge",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## B.5.3 - Role-Projection Bridge\n",
        "problem": "### B.5.3:2 - **Problem**\n\nHow can FPF bridge this gap between its universal core and the specific language of a domain without either polluting the kernel with domain-specific terms or forcing experts to abandon their familiar vocabulary? A simple alias mechanism (e.g., a dictionary mapping `U.System` to \"Thermodynamic System\") is insufficient because:\n\n1.  **It's brittle:** It assumes a one-to-one mapping, which often breaks down. A single domain concept can play multiple universal roles in different contexts.\n2.  **It's semantically poor:** It only captures naming, not the rich constraints and relationships that a domain-specific concept entails. We can't express that a \"Thermodynamic System\" is a *special kind* of `U.System` with specific properties related to temperature and pressure.\n3.  **It's not integrated:** The mappings live outside the formal model, making them difficult to govern, version, and use in automated reasoning.\n",
        "forces": "### B.5.3:3 - **Forces**\n\n| Force | Tension |\n| :--- | :--- |\n| **Universality vs. Specificity** | How to maintain a lean, universal kernel while accommodating the rich, specific terminologies of countless domains. |\n| **Flexibility vs. Rigor** | How to allow a single entity to be viewed through multiple lenses (e.g., as a physical system and an economic asset) without creating ambiguity. |\n| **Integration vs. Isolation** | How to incorporate domain knowledge into the formal model without hard-coding it into the FPF kernel, thereby preserving the Open-Ended Kernel principle (P-4). |\n",
        "solution": "### B.5.3:4 - **Solution**\n\nFPF solves this with the **Role-Projection Pattern**, a mechanism that creates a robust, semantically rich **Concept-Bridge** between the universal kernel and domain-specific vocabularies. This pattern is built on three core components:\n\n#### B.5.3:4.1 - The `Role` Concept\n\n*   **Description:** FPF introduces a new universal type, `U.Role`. A `Role` is not a concrete thing but an **abstract, context-dependent role** that an entity can play. It represents the domain-specific *interpretation* of a universal concept.\n*   **Example:** \"Thermodynamic System\" is not modeled as a new subtype of `U.System`. Instead, it is modeled as a `Role` that a `U.System` can *play* when it is being analyzed from a thermodynamic perspective.\n\n#### B.5.3:4.2 - The `refinesType` Relation**\n\n*   **Description:** Every `Role` **MUST** declare which universal `U.Type` it refines or specializes. This is done via the `refinesType` relation.\n*   **Example:** The `ThermodynamicSystemRole` would have the relation `refinesType: U.System`. This creates a formal, unbreakable link to the kernel. It guarantees that any entity playing this role still inherits all the fundamental properties and invariants of a `U.System`. This is a many-to-one relationship: many different roles (e.g., `EconomicSystemRole`, `BiologicalSystemRole`) can all refine the same `U.System` type.\n\n#### B.5.3:4.3 - The `plays_role_of` Relation**\n\n*   **Description:** This relation connects a **concrete entity** in a model to a `Role`. It is the assertion that \"this specific thing is currently playing that specific role.\"\n*   **Example:** In a model of a steam engine, we would assert that our specific engine instance `plays_role_of: ThermodynamicSystemRole`. This assertion signals to all tools and reviewers that this engine should be interpreted as a `U.System` and that the rules and constraints associated with the `ThermodynamicSystemRole` now apply to it.\n\n> **Didactic Note for Managers: From \"Alias\" to \"Job Description\"**\n>\n> The Role-Projection pattern is the difference between giving someone an alias and giving them a job description.\n>\n> *   **An Alias (the old way):** Simply says \"Bob is also known as The Manager.\" It's just a name swap.\n> *   **A Role (the FPF way):** Says \"Bob `plays_role_of` Manager.\" This is much richer. It implies that Bob has specific responsibilities, authorities, and performance expectations that come with the \"Manager\" role. He might also play other roles, like \"Mentor\" or \"Team Lead.\"\n>\n> Similarly, when we say a component `plays_role_of` \"Sensor,\" we are not just renaming it. We are activating a rich set of expectations and rules that come with being a sensor (e.g., it must have an output port, it must have a defined accuracy, etc.). This makes our models smarter, safer, and more precise.\n",
        "archetypal_grounding": "### B.5.3:5 - **Archetypal Grounding**\n\nTo illustrate the pattern in action, let's consider how we would bridge the domain of **classical thermodynamics** to the FPF kernel.\n\n1.  **Define the Roles:** A domain expert creates a set of `Role`s, each refining a core `U.Type`:\n    *   A `U.Role` named `ThermodynamicSystemRole` with `refinesType: U.System`. It might have a description: \"A region of the universe under study, separated by a boundary.\"\n    *   A `U.Role` named `MacrostateRole` with `refinesType: U.State`. Its description could specify that it is defined by variables (P, V, T, N).\n    *   A `U.Role` named `ControlVolumeRole` with `refinesType: U.Boundary`.\n    *   A `U.Role` named `FreeEnergyObjectiveRole` with `refinesType: U.Objective`.\n\n2.  **Apply the Roles in a Model:** An engineer modeling a heat engine would then use these roles:\n    *   They create an instance of `U.System` representing the engine and assert: `HeatEngine_Instance plays_role_of: ThermodynamicSystemRole`.\n    *   They model the engine's state and assert: `EngineState_Instance plays_role_of: MacrostateRole`.\n    *   They define the system's goal and assert: `EngineObjective_Instance plays_role_of: FreeEnergyObjectiveRole`.\n\n**What this achieves:**\n\n*   The model is now **semantically rich**. Tools can now understand that `HeatEngine_Instance` is not just any system, but one that should be analyzed using the laws of thermodynamics.\n*   The model is **verifiable**. A tool could now check if an entity playing the `MacrostateRole` actually has attributes for Pressure and Temperature, enforcing domain-specific consistency.\n*   The model remains **universally compatible**. Because `ThermodynamicSystemRole` refines `U.System`, the heat engine can still be reasoned about as a generic system in a wider context (e.g., in a model of the entire power plant).\n\n**Conformance Checklist**\n\n*   **CC-B5.3.1 (Role Grounding Mandate):** Every `U.Role` **MUST** be linked to exactly one universal `U.Type` via the `refinesType` relation. Orphaned roles are forbidden.\n*   **CC-B5.3.2 (Explicit Role Assertion):** A domain-specific concept **SHALL NOT** be treated as a subtype of a `U.Type` directly. Its relationship **MUST** be expressed using the `plays_role_of` relation to a `U.Role`.\n*   **CC-B5.3.3 (Multi-Role Flexibility):** A single entity **MAY** `play_role_of` multiple `Role`s simultaneously, even from different domains.\n*   **CC-B5.3.4 (Semantic Integrity):** A `Role` **MAY** introduce additional constraints or required attributes that are more specific than those of the `U.Type` it refines, but it **SHALL NOT** contradict them.\n\n**Common Anti-Patterns and How to Avoid Them**\n\n| Anti-Pattern | Manager's View: What It Looks Like | How FPF Prevents It |\n| :--- | :--- | :--- |\n| **The \"Subtype Explosion\"** | The list of system \"types\" in the project grows endlessly: `ThermodynamicSystem`, `EconomicSystem`, `SoftwareSystem`, etc. The ontology becomes bloated and unmanageable. | **CC-B5.3.2** forbids this. There is only one `U.System`. Different perspectives on it are modeled as `Role`s, which keeps the core ontology lean. |\n| **The \"Magic Synonym\"** | A developer simply renames `U.System` to \"Thermodynamic System\" in their diagrams, but there are no formal rules or constraints attached. The term is just an alias. | The FPF pattern requires a formal `Role` with a `refinesType` link. This is a rich, structural connection, not just a cosmetic name change. |\n| **The \"One-Hat Fallacy\"** | The model forces an entity to be only one thing. An asset can be a \"Physical Component\" or a \"Financial Asset,\" but not both, leading to duplicated models. | **CC-B5.3.3** explicitly allows an entity to play multiple roles. A single server in your data center can simultaneously `play_role_of` \"PhysicalComponent\" (for Sys-CAL) and \"DepreciableAsset\" (for a financial architheory). |\n",
        "consequences": "### B.5.3:6 - **Consequences**\n\n| Benefits | Trade-offs / Mitigations |\n| :--- | :--- |\n| **Semantic Richness and Precision:** The pattern allows domain-specific constraints and rules to be formally integrated into the model, enabling much more powerful automated checking and reasoning. | **Increased Modeling Granularity:** It introduces a layer of indirection (`Entity → Role → U.Type`) that modelers must learn. *Mitigation:* Tooling can automate much of this, suggesting relevant roles based on the context or domain. |\n| **Multi-Domain Integration:** The pattern provides a clean and robust mechanism for a single model to incorporate concepts from multiple, diverse domains without conflict. | - |\n| **Preserves a Lean Kernel:** The FPF kernel remains small and universal, with all domain-specific complexity handled in a modular, plug-in fashion via `Role` libraries. | - |\n| **Enhanced Traceability and Clarity:** The roles an entity plays are explicit assertions. This makes the model's intent clear and auditable. | - |\n",
        "rationale": "### B.5.3:7 - **Rationale**\n\nThe Role-Projection pattern is the cornerstone of FPF's approach to **universality with specificity**. It is a direct implementation of the **Open-Ended Kernel (P-4)** and **Plug-in Layering (P-5)** principles. By separating the timeless, universal concepts (`U.Types`) from their context-dependent, domain-specific interpretations (`Role`s), FPF achieves a powerful balance.\n\nThis approach is inspired by contemporary practices in both ontology engineering (e.g., the use of role concepts in foundational ontologies like UFO) and software architecture (e.g., aspect-oriented programming and role-based modeling), but it integrates them into a single, coherent pattern. It provides a formal, scalable, and semantically rich solution to the perennial problem of bridging the universal and the particular.\n",
        "relations": "### B.5.3:8 - **Relations**\n\n*   **Implements:** `ADR-003: Role-Projection Pattern and Concept-Bridge`.\n*   **Enables:** The practical application of all architheories by providing the \"glue\" that connects them to the FPF kernel.\n*   **Used By:** All other patterns in the reasoning cycle, as it provides the vocabulary for framing hypotheses and interpreting evidence in a domain-specific context.\n",
        "b.5.3:end": "### B.5.3:End\n\n# **Part C — Architheory Specifications**\n\n| §                                            | Architheory                        | Tag | Scope & Exports                                                      |\n| -------------------------------------------- | ---------------------------------- | --- | -------------------------------------------------------------------- |\n| **Cluster C.I – Core CALs / LOGs / CHRs**    |                                    |     |                                                                      |\n| C.1                                          | **Sys‑CAL**                        | CAL | Physical holon composition; conservation invariants; resource hooks. |\n"
      },
      "content": "### B.5.3:End\n\n# **Part C — Architheory Specifications**\n\n| §                                            | Architheory                        | Tag | Scope & Exports                                                      |\n| -------------------------------------------- | ---------------------------------- | --- | -------------------------------------------------------------------- |\n| **Cluster C.I – Core CALs / LOGs / CHRs**    |                                    |     |                                                                      |\n| C.1                                          | **Sys‑CAL**                        | CAL | Physical holon composition; conservation invariants; resource hooks. |\n",
      "metadata": {},
      "part": "B",
      "cluster": null
    },
    {
      "id": "C.2",
      "title": "Epistemic holon composition (KD-CAL)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## C.2 - Epistemic holon composition (KD-CAL)\n\n**Scope & exports.** A substrate‑neutral calculus for composing **epistemic holons** (`U.Episteme`) and reasoning about their motion and equivalence. Exports: (i) three **point‑characteristics**—**Formality F**, **ClaimScope G**, **Reliability R**—that locate a single episteme; (ii) a **pairwise ladder** of **Congruence Levels (CL 0…3)**; (iii) four **Δ‑moves** (*Formalise, Generalise/Specialise, Calibrate/Validate, Congrue*); (iv) **composition rules** (Γ_epist) for aggregates; (v) propagation laws for CL through mappings and notation bridges. KD‑CAL sits on the `U.Episteme` *semantic triangle* (Symbol–Concept–Object) and never confuses **notation** with **carrier**. All F–G–R computations are **context‑local**; Cross‑context traversals **require** an explicit **Bridge** with **CL** and apply the **B.3** congruence penalty **Φ(CL)** to **R**.  // Contexts ≡ U.BoundedContext; substitution is plane‑preserving only.\n\n**Formality F** is the rigor characteristic defined **normatively in C.2.3**. All KD‑CAL computations and guards **SHALL** use `U.Formality` (F0…F9) as specified there; **no parallel “mode” ladders** are allowed.\n",
        "problem": "### C.2:2 - Problem\n\nTeams routinely entangle **programs, specifications, proofs, and datasets**; a “proof” is treated as a tested routine, a “program” is cited as if it entailed a theorem. **Trust decays** because justification and evidence freshness are not explicit. Epistemes are anthropomorphised as actors (“the standard enforces…”), producing **category errors at execution**. Without a shared composition and equivalence calculus, aggregates hide weakest links and analogies harden into overclaims. KD‑CAL must stop these failure modes with a **single constitution and scale‑set**.\n\n",
        "forces": "### C.2:3 - Forces\n\n* **Universality vs domain idioms.** One calculus must host physics theories, legal codes, safety specs, algorithms, and formal proofs without flattening their differences.\n* **Meaning vs materiality.** Meaning must be independent of carrier, yet accountable to it historically.\n* **Deductive vs empirical.** Axiomatic certainty and empirical trust have different lifecycles; both must compose.\n* **Abstraction vs enactment.** Epistemes constrain action; **systems** act. The calculus must keep the roles distinct.\n\n",
        "solution": "### C.2:4 - Solution\n\n#### C.2:4.1 - Coordinates and the triangle\n\n**KD‑CAL characteristics (single‑episteme, point‑values).**\n\n* **Formality F.** From free prose to **machine‑checkable proof/specification**. Litmus: *would a machine reject it if wrong?*\n* **Claim scope (G), a set‑valued applicability over `U.ContextSlice`, with ∩/SpanUnion/translate algebra; CL penalties apply to R, not to F/G.** Litmus: *how wide is the declared scope, and under what minimal assumptions does the claim hold?*\n* **Reliability R.** From untested idea to **continuously validated claim**. Litmus: *where is the last successful severe test?* **R‑claims MUST bind to evidence and declare relevance windows; stale bindings degrade R or require waiver per ESG policy.**\n\n **Congruence Level (CL), pairwise ladder.**\n `CL‑0` **Opposed/Disjoint** (contrastive; no substitution); `CL‑1` **Comparable / Naming‑only** (label similarity; no substitution); `CL‑2` **Translatable / RoleAssignment‑eligible** (structure‑preserving mapping in a declared fragment with **stated loss**; theorems may transport); `CL‑3` **Near‑identity / Type‑structure‑safe** (invariants match; type‑structure substitution allowed). *CL is a characteristic of a relation between two epistemes; it is not a fourth charachteristic of epistemic characteristic space.* **Norm:** substitution is permitted only if plane‑preserving and **CL ≥ 2**; substituting **type‑structure** requires **CL = 3**.\n\n**Triangle link.** The characteristics live on the **Concept↔Object** side: *F* by the internal claim‑graph structure; *G* by the **ClaimScope** (scope & assumptions); *R* by evaluation templates and evidence bindings. The **Symbol** vertex hosts notation; **carriers are outside** the episteme and link via `isCarriedBy`. Multiple notations are allowed under a **single Symbol component**; authors SHOULD register `NotationBridge(n₁,n₂)` with an associated **CL** to make conversion loss explicit.\n\n#### C.2:4.2 - Four Δ‑moves (epistemic motion)\n\n* **ΔF — Formalise.** Rewrite for stricter calculi/grammars; raise proof obligations.\n* **ΔG — Generalise / Specialise.** Widen or narrow the **claim scope** (assumptions & scope). Changes to decomposition granularity are an **orthogonal view** and do not change **G** unless they alter the envelope.\n* **ΔR — Calibrate / Validate.** Strengthen severe tests or add live monitoring; update evidence bindings.\n* **ΔCL — Congrue.** Establish and record the sameness relation between **two** epistemes (ladder 0→3).\n  Moves compose into **paths**; CL along a path is the **minimum** of its links.\n\n#### C.2:4.3 - Composition (Γ\\_epist) and propagation\n\nLet **Γ\\_epist** combine epistemes `{Eᵢ}` into a composite episteme **Γ** that makes a joint claim (*AND‑style*) or exposes an interface (*series composition*). KD‑CAL imposes **safe defaults**:\n\n* **R (Reliability).** Along any justification **path** `P`, compute **`R_eff(P) = max(0, min_i R_i − Φ(CL_min(P)))`** (weakest‑link with congruence penalty). For **series** composition (claims needed conjunctively), the path‑wise weakest‑link applies; for **parallel** support (independent lines to the *same* claim), use **`R(Γ) = max_P R_eff(P)`** (annotate independence); never exceed the best attested line. Cross‑context steps and **NotationBridge** traversals contribute to `CL_min(P)`.\n\n* **F (Formality).** `F(Γ) = minᵢ F(Eᵢ)` (monotone non‑increasing along used paths). To raise **F**, apply **ΔF** to the weakest parts.\n* **G (ClaimScope).** On any dependency **path**, take the **intersection** of claim scopes (the **narrowest overlapping scope**). Across **independent support paths to the same claim**, set **`G(Γ) = SpanUnion({G_path})` constrained by support** (drop unsupported regions). Widening/narrowing the scope is an explicit **ΔG±** operation.\n* **CL (Congruence).** For a chain of mappings `E₀ ~ E₁ ~ … ~ Eₖ`, the **path congruence** is `min CL(Eⱼ,Eⱼ₊₁)`. Passing through a **NotationBridge** sets CL to the bridge’s declared level; the **Φ(CL)** penalty is applied in the **R** fold for any path that traverses it.\n\nThese rules keep Γ aligned with the **holonic kernel**: Γ is only defined on holons and respects identity/boundary discipline from the core. \n\n#### C.2:4.4 - What **must not** be conflated (normative guards)\n\n* **Symbol ≠ carrier.** Files, PDFs, or repositories are **carriers** outside the episteme; they never count as parts of `U.Episteme` (**see C.2.1 EP‑1; CC‑EPI‑2/3**).\n* **Epistemes do not act.** Only **systems** perform work; epistemes constrain/evaluate via **Object** and **Concept** (**per Core A.15 / CC‑EPI‑3**).\n* **CL is not a score.** It is a **qualitative ladder** of preservation strength; do not average it. \n\n",
        "archetypal_grounding": "### C.2:5 - ✱ Archetypal Grounding (Tell–Show–Show)\n\n**Universal rule (tell).** *Compose knowledge by Γ\\_epist with weakest‑link R, monotone F, and explicit CL on every bridge; keep Symbol–Concept–Object separate and never turn a carrier into a part.*\n\n**System (show, Sys‑CAL lens).** Consider a **battery‑pack thermal subsystem** integrating a physics model of heat flow and an operating envelope for fast‑charge. As a **system**, it composes pumps, sensors, and controllers by physical Γ with conservation constraints (Sys‑CAL). The assurance story depends on epistemes about the model and envelope; the system **acts**, epistemes constrain. (Archetypes and boundary discipline per core.)\n\n**Episteme (show, KD‑CAL lens).** Consider a **CMIP‑class climate projection episteme** (post‑2015 generation): its **Concept** is a claim‑graph over PDEs and parameterisations; its **Object** defines an claim scope (historical forcings, resolution); its **Symbol** may include two notations (domain equations vs. tabular schema) linked by a **NotationBridge** with an explicit CL. Compose sub‑epistemes for radiation, clouds, and ocean mixing: `R = min` across the critical path; an independent hindcast line can raise `R` only up to its own level; `F` is bounded by the least‑formal sub‑claim unless the composition adds formal invariants.\n\n",
        "bias‑annotation": "### C.2:6 - Bias‑Annotation\n\n* **Metric worship.** Treating `[F,G,R]` as ends rather than means; mitigation: require **evidence bindings** and narrative of limits in the Object envelope.\n* **Category slip.** Equating a notation or its carrier with the Concept; mitigation: Symbol–carrier separation and EP‑1 triangle cardinality.\n* **Analogy inflation.** Presenting CL‑0/1 as identity; mitigation: always name the **CL rung** for cross‑mappings.\n\n",
        "conformance_checklist": "### C.2:7 - Conformance Checklist\n\n1. **C2‑1 (Triangle).** Every `U.Episteme` **MUST** occupy exactly one slot per {Symbol, Concept, Object}; carriers link via `isCarriedBy` and are never parts.\n2. **C2‑2 (Coordinates).** Each episteme **SHALL** declare `[F,G,R]` with a brief rationale; **F** is `U.Formality ∈ {F0…F9}` per **C.2.3**, **exactly one episteme‑level F** computed as the **min over essential parts**. CL is declared for **pairs only**. Sub‑anchors: ** Contexts **MAY** mint named sub‑anchors (e.g., `F4[OCL]`, `F7[HOL]`), which **MUST** preserve the global order and **map to their parent anchor** from C.2.3.\n3. **C2‑3 (Composition).** Authors **SHALL** choose Γ_mode (**series** vs **parallel**). For any justification **path** use **`R_eff(P) = max(0, min_i R_i − Φ(CL_min(P)))`**; for **parallel** independent lines to the *same claim*, take **`R(Γ) = max_P R_eff(P)`** (never exceeding the strongest line). Compute `F(Γ) = min` along the used paths. For **G**, use **path‑wise intersections** and then **SpanUnion({G_path}) constrained by support**. Cross‑context traversals **MUST** use a Bridge with **CL** and apply **Φ(CL)** to `R`.\n4. **C2‑4 (NotationBridge).** Multi‑notation Symbol components **SHOULD** register `NotationBridge` edges with CL and loss note; any cross‑notation reasoning **MUST** cite the bridge’s CL.\n5. **C2‑5 (No action).** Epistemes **MUST NOT** be assigned actions; work is executed by systems in role.\n\n",
        "consequences": "### C.2:8 - Consequences\n\n**Benefits.** A single, compact **map** for all knowledge artefacts; fast detection of weakest‑link **R** in aggregates; disciplined reuse across domains with explicit **CL**; consistent separation of **meaning** from **material carriers**.\n**Trade‑offs.** Authors must learn to declare Γ‑mode and CL explicitly; multi‑notation work requires bridge bookkeeping; *mitigation:* the triangle and ladder keep the discipline brief and repeatable.\n\n",
        "rationale": "### C.2:9 - Rationale\n\nKD‑CAL externalises a long‑standing semiotic insight (Sign–Meaning–Referent) into a **holonic composition** where syntax/structure (**F,G**), pragmatics/evidence (**R**), and cross‑mapping strength (**CL**) are visible and composable. The explicit triangle (C.2.1) prevents carrier confusion; the characteristic provide a **manager‑readable** yet **formalisation‑ready** scale (with **G** grounded in **scope/envelope**, not part‑count); the CL ladder replaces overloaded “alignment” with a graded sameness notion.\n\n",
        "relations": "### C.2:10 - Relations\n\n* **Depends on:** `U.Episteme — Semantic Triangle via Components` (C.2.1): identity invariants EP‑1, Symbol–Concept–Object definitions, evidence bindings.\n* **Peers:** **Sys‑CAL** (C.1), which composes **systems**; KD‑CAL composes **epistemes** and feeds assurance lenses in Part B.\n* **Constrained by authoring:** Architectural patterns must include Tell–Show–Show with **Archetypal Grounding** (this section).\n",
        "worked_mini‑examples_(post‑2015_flavours)": "### C.2:11 - Worked mini‑examples (post‑2015 flavours)\n\n* **Formal lift (ΔF).** Recasting a 2019 **variational free‑energy** narrative into a typed calculus raises **F**, clarifies scope, and enables CL‑2 bridges between biological and ML formulations—*without* claiming empirical gain (**R** unchanged).\n* **Parallel evidence (R, max).** Two independent **hindcast** lines (circa CMIP6, 2019) supporting the same forecast allow `R(Γ)=max(R₁,R₂)`; if one line drifts, the composite is bounded by the stronger line until series constraints apply.\n* **Notation bridge (CL drop).** A 2021 **type‑theoretic specification** rendered in a semi‑formal DSL requires a `NotationBridge` with a CL<3 note; any theorem transported across must respect the bridge’s declared preservation.\n\n*(No tooling is implied; these are conceptual moves within the calculus.)*\n",
        "c.2:end": "### C.2:End\n"
      },
      "content": "### C.2:End\n",
      "metadata": {},
      "part": "C",
      "cluster": null
    },
    {
      "id": "C.2.1",
      "title": "U.Episteme — Epistemes and their slot graph",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## C.2.1 - U.Episteme — Epistemes and their slot graph\n\n> **One-line summary.** `U.Episteme` is the holon type for epistemes; its internal ontology is given by `U.EpistemeSlotGraph`, which replaces the legacy **semantic triangle** with a typed graph n-ary relation over `DescribedEntity`, `GroundingHolon`, `ClaimGraph`, `Viewpoint`, `View`, and `ReferenceScheme`, aligned with `U.RelationSlotDiscipline` and ready for both symbolic and distributed representations.\n",
        "c.2.1:1___context": "### C.2.1:1 - Context\n\nFPF’s kernel recognises two archetypal sub‑holons: **System** and **Episteme**. Systems are operational wholes; **epistemes** are **knowledge holons**—theories, models, specifications, standards, algorithms, proofs—whose reason for being is to **say something defeasible or deductive about something** and to be **held to account** by justification. \n\n**Readers.** Engineering managers and lead designers who need a uniform way to reason about **theories, specifications, algorithms, proofs**—from charter memos up to formal axiomatics—without collapsing into tooling or discipline‑specific notations.\n\nKD‑CAL (C.2) needs a precise notion of **what an episteme is** and **how it mediates** between:\n\n* the thing(s) it is about,\n* the contexts and systems that ground and test it, and\n* the representational machinery (notations, carriers, operations) we use to work with it.\n\nContemporary work on **formal languages as cognitive artifacts** (Dutilh Novaes), **operational iconicity** of notations (Krӓmer), **material engagement** (Malafouris), **distributed representations** and **latent‑space communication** in ML, and **tool‑augmented reasoning** (ReAct‑style agent loops) shows that:\n* the relation between an episteme and its **DescribedEntitySlot** is not a single “Object-vertex”: it involves explicit **slots and morphisms** (described-entity mapping, grounding, evaluation) typed by SlotKinds and contexts;\n* **representations** come in heterogeneous forms (symbolic, diagrammatic, latent, interactive), with very different **operational affordances**;\n* **inference** is often **mixed‑mode**: symbolic reasoning plus calls to tools, solvers, and learned models.\n\nFPF therefore needs a **more modular, graph‑shaped ontology** for epistemes which:\n* keeps **KD‑CAL** and I/D/S discipline intact,\n* is compatible with **A.6.0/A.6.5** signatures (`SlotKind`/`ValueKind`/`RefKind`),\n* can be used uniformly by A.6.2–A.6.4 (epistemic morphisms) and E.17.* (views & publication),\n* and demotes the old non-SoTA **semanit triangle** to a **didactic projection**, not the normative ontology.\n\nIn this pattern:+\n* `U.Episteme` is the **holon genus** for epistemes (C.2), with components and identity governed by A.1/A.6.A/A.7.\n* `U.EpistemeSlotGraph` names the **internal ontology graph** of `U.Episteme`: the small, typed n-ary relation over episteme positions (`DescribedEntitySlot`, `GroundingHolonSlot`, `ClaimGraphSlot`, `ViewpointSlot`, `ViewSlot`, `ReferenceSchemeSlot`) on which KD-CAL, A.6.2–A.6.4 and E.17.* rely.\n* Species such as `U.EpistemeCard`, `U.EpistemeView`, `U.EpistemePublication` are holonic realisations of `U.Episteme` whose component structure is constrained to be compatible with `U.EpistemeSlotGraph`.\n",
        "problem": "### C.2.1:2 - Problem\n\nWithout a shared **episteme constitution**, teams fall into recurring failure modes:\n\n1. **Object–Description–Carrier soup.** Diagrams and files are treated as *the theory itself*. Changes to a PDF are confused with theoretical change.\n2. **DescribedObject blur.** A spec seems to describe “everything in general”. The **GroundingHolon**—*what exactly this knowledge is about*—is implicit and drifts.\n3. **Proof vs program confusion.** Algorithms, specifications, and proofs are mixed: a “proof” is used as if it were a tested routine; a “program” is cited as if it entailed a theorem (Curry–Howard misunderstood).\n4. **Unanchored trust.** Claims accumulate with no explicit **justification graph** or **evidence freshness**, so assurance degrades invisibly.\n5. **Category errors at execution.** Epistemes appear as *actors* (“the standard enforces…”) instead of **systems** acting *with* or *on* epistemes such as data sets or algorithms.\n\nThe legacy non-SoTA “Semantic Triangle” treated an episteme as a holon with three components: **Concept** (ClaimGraph), **Object** (Reference Map), and **Symbol** (notation).\n\nThis worked well for:\n* separating **meaning** (Concept) from **carriers**, and\n* integrating KD‑CAL’s **F–G–R** characteristics (Formality, ClaimScope, Reliability).\n\nBut for current use‑cases it has structural blind spots:\n\n1. **No explicit DescribedEntity slot.**\n   The “Object vertex” bundles together *what the episteme is about* with *how we interpret and test it*. There is no explicit **slot** for the entity‑of‑interest (`U.Entity`) and no clear separation between:\n   * the **thing described**, and\n   * the **ReferenceScheme** used to read claims as statements about that thing.\n\n2. **Grounding collapses into Object.**\n   Material and organisational contexts (labs, infrastructures, organisations) that **ground** an episteme (in Malafouris’ sense) are hidden in the Object/Reference Map. KD‑CAL and Bridges need explicit **GroundingHolon** positions.\n\n3. **Viewpoints are not first‑class.**\n   ISO‑style **viewpoints** (families of stakeholders, concerns, conformance rules) and their induced **views** appear only indirectly, via KD‑CAL or MVPK. There is no explicit `U.Viewpoint` / `U.View` pair at the episteme core, which makes it hard to:\n\n   * connect to I/D/S **DescriptionContext**,\n   * organize multi‑view descriptions (E.17.0), or\n   * align publication viewpoints with engineering viewpoints.\n\n4. **Representations and operations are compressed into “Symbol”.**\n   Very different representational regimes are flattened into one Symbol vertex:\n\n   * purely denotational notations (no internal inference calculus),\n   * fully operational calculi (e.g., proof assistants),\n   * interactive visualisations,\n   * latent vectors and prompt‑programs for LLMs.\n     There is no place to say “this representation admits **syntactic inference** of such‑and‑such kind” vs “this is just a **passive label**”.\n\n5. **No explicit signature discipline.**\n   The triangle speaks of “Object/Concept/Symbol” but not of **slots** and **references** in the sense of A.6.5 `U.RelationSlotDiscipline`. In episteme this leads to:\n   * names where **slot, value and ref** are conflated (`DescribedEntityRef` used as if it were a slot),\n   * ambiguity between “epistemic object” (what is talked about) and “episteme” (the description),\n   * fragile interoperability with signatures for roles, methods, services.\n\nThus we have problems of:\n* **DescribedEntity drift.**\n Specifications and models accumulate without a stable notion of **which DescribedEntity they talk about**; fields like `SubjectRef` are overloaded and resist safe refactoring.\n* **Viewpoint confusion.**\n  Engineering, publication and governance views are mixed, making it hard to maintain consistency across surfaces or to reason about conformity of descriptions under different viewpoints.\n* **Representation mismatches.**\n  Trade‑offs between neural vs symbolic, diagrammatic vs textual, or interactive vs batch representations cannot be expressed at the episteme level; they leak into ad‑hoc tool descriptions.\n* **Broken modularity.**\n  As soon as we add KD‑CAL, LOG‑CAL, MVPK, and E.TGA, multiple **implicit triangles** appear, each with slightly different semantics, instead of a single shared `U.EpistemeSlotGraph`.\n\nWe need a replacement for the triangle that keeps its **didactic clarity** but matches the **graph‑ and morphism‑centric** reality of contemporary epistemic work.\n",
        "forces": "### C.2.1:3 - Forces\n\n| Force                                          | Tension we must resolve                                                                                                                |\n| ---------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------- |\n| **Geometry vs. operations**                    | Simple geometric pictures (triangles) are memorable; real epistemic work is **operational and graph‑shaped** (many nodes, many edges). |\n| **Universality vs. representation regimes**    | One ontology must accommodate symbolic calculi, diagrams, DSLs, interactive notebooks, and latent vectors.                             |\n| **Intension vs. description vs. spec (I/D/S)** | Intensional objects (I) are not epistemes; descriptions (D) and specifications (S) are. The core must honour Strict Distinction.       |\n| **Viewpoint locality vs. reuse**               | Viewpoints should be **local** to families of descriptions, yet we want reusable **viewpoint bundles** across domains (E.17.1/E.17.2). |\n| **Slot discipline vs. usability**              | A clean `SlotKind`/`ValueKind`/`RefKind` discipline is vital for reasoning, but must not render engineering episteme unreadable.             |\n| **Stability vs. SoTA evolution**               | The core must remain stable while integrating evolving practices: LLM tool‑use, ReAct‑style loops, structured cospans, optics, etc.    |\n",
        "solution": "### C.2.1:4 - Solution — from outdated semantic triangle to `U.EpistemeSlotGraph`\n\n#### C.2.1:4.0 - Overview\n\nFor `U.Episteme`, the legacy semantic triangle is replaced by `U.EpistemeSlotGraph` that is a **small, typed ontology graph** and an **n-ary relation view** over the core episteme positions:\n\n **Nodes / positions / slots.**\n  Minimal **kernel SlotKinds** (with their ValueKinds) that every episteme can refer to, following A.6.5:\n  * `DescribedEntitySlot`  (ValueKind `U.Entity` or a declared subkind) → *“what this episteme is about”*;\n  * `GroundingHolonSlot`   (ValueKind `U.Holon`) → *“where/how this is grounded”*;\n  * `ClaimGraphSlot`       (ValueKind `U.ClaimGraph`) → *“what is being said (intensional content)”*;\n  * `ReferenceSchemeSlot`  (ValueKind `U.ReferenceScheme`) → *“how we read claims as statements about entities”*;\n  * `ViewpointSlot`        (ValueKind `U.Viewpoint`) → *“under which viewpoint we read/validate this episteme”*;\n  * `ViewSlot`             (ValueKind `U.View`) → *“a view‑episteme produced under a viewpoint”*.\n\n* **Slots and signatures.**\n  These positions are realised as **SlotKinds** with associated **ValueKinds** and **RefKinds** under `U.RelationSlotDiscipline` (A.6.5). An **episteme kind** (`U.EpistemeKind`) is a **signature** over these slots.\n\n* **Episteme as n‑ary relation and as holon.**\n  Each concrete episteme instance can be seen both as:\n\n  * a **tuple** filling these slots (`U.EpistemeTuple`), and\n  * a **holon with components** (`U.EpistemeCard`, `U.EpistemeView`, `U.EpistemePublication`) whose fields correspond to those slots.\n\n`U.Episteme` is thus the holon type whose components are *disciplined* by the `U.EpistemeSlotGraph`; C.2.1 fixes that discipline.\n\n* **Morphisms.**\n  Simple **epistemic morphisms** (described-entity mapping, grounding, encoding, evaluation) are expressed as ordinary relations/functions between these positions. A.6.2–A.6.4 then specify general laws for effect-free morphisms over `U.Episteme`.\n\n* **Legacy triangle as didactic projection.**\n  The classic Symbol–Concept–Object triangle becomes a **didactic view** of this graph, not the normative ontology; it is simply the projection to:\n\n  * `Symbol` ≈ a subset of `U.RepresentationScheme`/`U.RepresentationToken`,\n  * `Concept` ≈ `U.ClaimGraph`,\n  * `Object` ≈ `{DescribedEntity, ReferenceScheme}`.\n\nThe rest of this pattern fixes the **minimal core** needed by KD‑CAL, A.6.2–A.6.4 and E.17.\\*. The representational nodes (`U.RepresentationScheme`, `U.RepresentationToken`, `U.PresentationCarrier`, `U.RepresentationOperation`) are introduced as an **extension C.2.1+**, preserving the interface defined here.\n\n#### C.2.1:4.1 - Minimal epistemic positions (nodes & slots)\n\nThis section defines the **minimal node set** for `U.EpistemeSlotGraph` and the associated **SlotKinds**. These are the positions that A.6.2–A.6.4 and E.17.* can rely on.\n\n##### C.2.1:4.1.1 - `DescribedEntitySlot` — “what this episteme is about”\n\n**Tech:** `DescribedEntitySlot` (SlotKind), `describedEntityRef : U.EntityRef` (Ref slot in tuples/cards).\n**Plain:** *described entity*, *entity‑of‑interest*, *object‑of‑talk*.\n\n**Intent.** Provide a **single, explicit slot** for the entity (or entities) that an episteme is about, avoiding the former conflation of Object/Reference/Context.\n\n**Normative definition.**\n\n1. `DescribedEntitySlot` is a **SlotKind** in the sense of A.6.5 `U.RelationSlotDiscipline`.\n\n   * Its **ValueKind** is `U.Entity`.\n   * Its **RefKind** is `U.EntityRef` (or a species thereof) and **MUST** be realised in data as a field named `describedEntityRef : U.EntityRef` (E.10 discipline).\n1. Species of `U.EpistemeKind` **MAY** constrain the ValueKind to a subtype `EoIClass ⊑ U.Entity` (for example, “EoI is always a `U.Holon` and, more specifically, a `U.System` or `U.Episteme`”). The subtype **MUST NOT** be named `U.DescribedEntity`; “described entity” remains a **role name**, not a kernel type.\n2. Wherever episteme previously used `U.EpistemicObject` as a separate type, it is re‑interpreted as **“`U.Entity` in the role of filling `DescribedEntitySlot`”** and is marked as **legacy alias** in LEX‑BUNDLE.\n\n**Didactic cue.**\n“Ask: *What, exactly, is this description about?* That is the DescribedEntity.”\n\n##### C.2.1:4.1.2 - `GroundingHolonSlot` — “where / in what holon this is grounded”\n\n**Tech:** `GroundingHolonSlot` (SlotKind), `groundingHolonRef : U.HolonRef?`.\n**Plain:** *grounding holon*, *holon‑of‑grounding*, *engagement context*.\n\n**Intent.** Capture the **material–social holon** (system, lab, infrastructure, organisation, runtime environment) with respect to which an episteme’s claims are **tested, calibrated or validated**.\n\n**Normative definition.**\n\n1. `GroundingHolonSlot` is a **SlotKind** with:\n\n   * **ValueKind** `U.Holon`,\n   * **RefKind** `U.HolonRef` (or a species thereof),\n   * and recommended field name `groundingHolonRef? : U.HolonRef` in episteme cards/views.\n2. `GroundingHolonSlot` is **optional** at the minimal core: an episteme may be **un‑grounded** at M‑mode (e.g., purely mathematical), but any episteme used for **empirical evaluation or assurance** under KD‑CAL **SHALL** either:\n\n   * populate `groundingHolonRef`, or\n   * declare explicitly that no such grounding is possible (e.g., counterfactuals, abstract logics), with consequences reflected in KD‑CAL `R`.\n3. The phrase *“grounding holon”* is **plain‑register**; there is no kernel type `U.GroundingHolon`. It always means “the holon currently filling `GroundingHolonSlot` for this episteme.”\n\n**Didactic cue.**\n“Ask: *In which lab/organisation/world‑slice do we test or observe this?* That is the GroundingHolon.”\n\n##### C.2.1:4.1.3 - `U.ClaimGraph` and `ClaimGraphSlot` — intensional content\n\n**Tech:** `U.ClaimGraph` (kernel type), `ClaimGraphSlot` (SlotKind).\n**Plain:** *claim graph*, *intensional content*.\n\n**Intent.** Reuse the existing KD‑CAL notion of **ClaimGraph** as the episteme’s **intensional body**, but make its role as a **slot value** explicit.\n\n**Normative definition.**\n\n1. `U.ClaimGraph` is the **ValueKind** for `ClaimGraphSlot`:\n\n   * nodes: typed claims (definitions, axioms, theorems, requirements, properties, assumptions);\n   * edges: logical/derivational/refinement relations, as already defined in C.2.\n2. `ClaimGraphSlot` is a **SlotKind** whose instances are always **stored by value** in core patterns:\n\n   * `content : U.ClaimGraph` is the normative field in `U.EpistemeCard` / `U.EpistemeView`;\n   * C.2.1 **MUST NOT** introduce `U.ClaimGraphRef` as a ValueKind. Any reference type for ClaimGraphs, if needed, is a **RefKind** defined by discipline packs on top of `U.ClaimGraph`.\n3. `ClaimGraphSlot` is **mandatory**: every `U.EpistemeKind` that uses C.2.1 **SHALL** have exactly one `ClaimGraphSlot`.\n\n**Didactic cue.**\n“Ask: *What is actually being claimed, defined, required, proved?* That is the ClaimGraph.”\n\n##### C.2.1:4.1.4 - `U.Viewpoint` and `ViewpointSlot` — perspective of concerns and validators\n\n**Tech:** `U.Viewpoint` (kernel type), `ViewpointSlot` (SlotKind), `viewpointRef : U.ViewpointRef?`.\n**Plain:** *viewpoint*, *perspective*, *stakeholder perspective*.\n\n**Intent.** Provide a **first‑class home** for ISO‑style viewpoints and their generalisations, as used by E.17.0 `U.MultiViewDescribing`, MVPK, and TEVB.\n\n**Normative definition.**\n\n1. `U.Viewpoint` is the type of **intensional viewpoint specifications**:\n\n   * families of **RoleEnactors/stakeholder groups** the viewpoint speaks for,\n   * their **concerns**,\n   * allowed **kinds of descriptions/specifications**,\n   * and **conformance rules** for views under this viewpoint.\n     (The internal structure of `U.Viewpoint` is fixed in E.17.0, not here.)\n2. `ViewpointSlot` is a **SlotKind** with:\n\n   * **ValueKind** `U.Viewpoint`,\n   * **RefKind** `U.ViewpointRef`,\n   * normative field name `viewpointRef? : U.ViewpointRef` on episteme cards/views.\n3. For **I/D/S descriptions/specs** (E.10.D2), `viewpointRef` is a **mandatory part of `DescriptionContext`**; C.2.1 treats that as a **species‑level constraint**, not as a universal requirement for all epistemes.\n4. `ViewpointSlot` may be unset in purely internal, pre‑viewpoint epistemes (e.g., raw formal developments), but any episteme that participates in **MultiViewDescribing** (E.17.0) **MUST** set it or be deterministically associated to it via a `ViewpointBundle`.\n\n**Didactic cue.**\n“Ask: *Who is this for, and what do they need to see to accept it?* That is the Viewpoint.”\n\n##### C.2.1:4.1.5 - `U.EpistemeView` / `U.View` and `ViewSlot` — episteme‑level views\n\n**Tech:** `U.EpistemeView` (kernel species of `U.Episteme`), alias `U.View`; `ViewSlot` (SlotKind); `viewRef : U.ViewRef`.\n**Plain:** *view*, *epistemic view*.\n\n**Intent.** Distinguish **view‑epistemes** (views **of** descriptions/specifications) from both:\n\n* the underlying descriptions/specifications themselves, and\n* the **PublicationSurface** carriers on which they are rendered (E.17, L‑SURF).\n\n**Normative definition.**\n\n1. `U.EpistemeView` is a **species of `U.Episteme`** whose episteme kind includes, at minimum:\n\n   * one `ClaimGraphSlot` (typically a **sliced or projected ClaimGraph**),\n   * one `DescribedEntitySlot`,\n   * one `ViewpointSlot`,\n   * and appropriate `ReferenceSchemeSlot`.\n2. `U.View` is an **alias** for `U.EpistemeView` in E‑cluster patterns (especially E.17.\\*), used where the word “view” is conventional.\n3. `ViewSlot` is a **SlotKind** whose:\n\n   * **ValueKind** is `U.View`,\n   * **RefKind** is `U.ViewRef` (or `U.EpistemeViewRef` species),\n   * intended usage is **in meta‑structures** such as `U.MultiViewDescribing` families and MVPK.\n4. `ViewSlot` **MUST NOT** be confused with carrier slots: Surfaces and faces are **not** values of `ViewSlot`; they are `U.Surface` artefacts in L‑SURF, related to views by MVPK.\n\n**Didactic cue.**\n“Ask: *Which particular slice of the description under this viewpoint are we talking about?* That is the View.”\n\n##### C.2.1:4.1.6 - `U.ReferenceScheme` and `ReferenceSchemeSlot` — reading ClaimGraph as claims about entities\n\n**Tech:** `U.ReferenceScheme` (kernel type), `ReferenceSchemeSlot` (SlotKind); `referenceScheme? : U.ReferenceScheme`.\n**Plain:** *reference scheme*, *interpretation scheme*, *description scheme*.\n\n**Intent.** Separate **what is being said** (ClaimGraph) from **how claims are read as statements about entities and contexts** (designation, measurement, evaluation envelopes), without reifying the referents themselves as a vertex.\n\n**Normative definition.**\n\n1. `U.ReferenceScheme` is a **component type of epistemes**, not an external object:\n\n   * it determines how nodes of `U.ClaimGraph` are mapped to **properties/relations** over values of `DescribedEntitySlot`,\n   * it specifies **measurement/evaluation templates** (how to test claims on `GroundingHolon`),\n   * it fixes **claim scope envelopes** over characteristic spaces.\n2. `ReferenceSchemeSlot` is a **SlotKind** with:\n\n   * **ValueKind** `U.ReferenceScheme`,\n   * **no RefKind in the minimal core** (ReferenceSchemes are stored by value as `referenceScheme? : U.ReferenceScheme` fields on episteme cards/views).\n     Discipline packs **may** introduce `U.ReferenceSchemeRef` as a **RefKind**, but **must not** repurpose it as a new ValueKind.\n3. `ReferenceScheme` is the place where the legacy “Object‑vertex” semantics now live:\n\n   * it does **not** “contain” the real‑world object,\n   * it hosts the **rules** that tie claims to entities and groundings.\n\n**Didactic cue.**\n“Ask: *Given this ClaimGraph, how exactly do we treat it as talking about these entities in these contexts, and how do we test it?* That is the ReferenceScheme.”\n\n##### C.2.1:4.1.7 - Minimal node set and extension C.2.1+\n\nThe **minimal `U.EpistemeSlotGraph` core** for C.2.1 consists of positions (the episteme core SlotKinds of A.6.5 CC‑A.6.5‑5):\n* `DescribedEntitySlot` (ValueKind `U.Entity`),\n* `GroundingHolonSlot` (ValueKind `U.Holon`),\n* `ClaimGraphSlot` (ValueKind `U.ClaimGraph`),\n* `ViewpointSlot` (ValueKind `U.Viewpoint`),\n* `ViewSlot` (ValueKind `U.View`),\n* `ReferenceSchemeSlot` (ValueKind `U.ReferenceScheme`).\n\nThis pattern **only fixes these positions**.\nThe **extension C.2.1+** (second step of the refactor) adds:\n* `U.RepresentationScheme` and `RepresentationSchemeSlot`,\n* `U.RepresentationToken` and `RepresentationTokenSlot`,\n* `U.PresentationCarrier` and `PresentationCarrierSlot`,\n* `U.RepresentationOperation` and `RepresentationOperationSlot` (with inference regime annotations),\n\nwithout changing:\n* the definition of `U.EpistemeKind`,\n* the minimal `U.EpistemeCard` interface,\n* or the assumptions A.6.2–A.6.4 / E.17.* make about episteme components.\n\nIn C.2.1+ carriers remain **structural publication artefacts**, not semantic parts of the episteme:\n`U.PresentationCarrier` values are linked to `U.Episteme` / `U.View` via MVPK / L‑SURF relations (e.g. `isCarriedBy` / faces) and **MUST NOT** be counted as components when reasoning about episteme identity, DescribedEntity/grounding, or KD‑CAL morphisms. Changing carriers or surfaces alone **never** changes the `U.Episteme` instance determined by C.2.1; it only produces new `U.Work` / publication events.\n\n##### C.2.1:4.1.8 - Attached epistemic structures (non-slot components)\n\n`U.EpistemeSlotGraph` deliberately does **not** reify every epistemic artefact as a node. Several key structures remain **attached, non-slot components** of `U.Episteme`:\n* **`JustificationGraph`** — the argument/evidence graph for nodes of `U.ClaimGraph` (A.10/B.3).\n* **`EvidenceBindings`** — per-claim `U.EvidenceRole` assignments that connect claims to external `U.Work` and carriers.\n* **`EditionSeries`** — the `PhaseOf` chain of episteme editions (A.14) with change-class annotations (symbol-only vs ClaimGraph vs ReferenceScheme changes).\n* **`ScopeCard` / `U.ClaimScope`** — USM scope objects (A.2.6) describing where the episteme’s claims hold.\n\nThese attached structures are **not extra positions** of `U.EpistemeSlotGraph`; they hang off the `U.ClaimGraph`/`U.ReferenceScheme` pair and are governed by KD-CAL (C.2), A.10 and B.3. C.2.1 only requires that an episteme which participates in KD-CAL exposes them in a way that keeps **ClaimGraph / ReferenceScheme / Evidence / EditionSeries / `ClaimScope`** clearly distinguishable.\n\n#### C.2.1:4.2 - Episteme as n‑ary relation and as holon\n\nTo prevent confusion between **objects‑of‑talk**, their **descriptions**, and the **places they occupy in an episteme**, C.2.1 explicitly treats epistemes both as:\n\n1. **n‑ary relations with a signature** (slots & values), and\n2. **holons with components** (fields & parts).\n\n##### C.2.1:4.2.1 - `U.EpistemeKind` — episteme as a typed n‑ary relation\n\n**Tech:** `U.EpistemeKind` (kernel type).\n\n**Intent.** Provide a **signature‑level** description of an episteme as an n‑ary relation whose arguments are governed by `SlotKind`/`ValueKind`/`RefKind` triples per A.6.5.\n\n**Normative definition.**\n\n1. Every episteme that participates in KD‑CAL **belongs to some `U.EpistemeKind`**.\n   The kind determines:\n\n   * which **SlotKinds** appear (`DescribedEntitySlot`, `GroundingHolonSlot`, `ClaimGraphSlot`, `ViewpointSlot`, `ViewSlot`, `ReferenceSchemeSlot`, …),\n   * the **ValueKind** for each slot (always a subtype of `U.Type`),\n   * the **RefKind** used to store it in episteme (when applicable).\n1. `U.EpistemeKind` is a **special case** of `U.Signature` (A.6.0), with its slots governed by `U.RelationSlotDiscipline` (A.6.5). C.2.1 **MUST NOT** define an alternative slot discipline.\n2. For the minimal core, every `U.EpistemeKind` **MUST** include:\n   * exactly one `ClaimGraphSlot`,\n   * at least one `DescribedEntitySlot`,\n   * and at least one `ReferenceSchemeSlot`.\n     Inclusion of `GroundingHolonSlot`, `ViewpointSlot`, `ViewSlot` **MAY** be species‑level constraints (mandatory for D/S‑epistemes, optional for others).\n\n**Didactic cue.**\n“An `EpistemeKind` is the *type* of episteme: which positions it has and what can go into them.”\n\n##### C.2.1:4.2.2 - `U.EpistemeTuple` — episteme as filled n‑ary relation\n\n**Tech:** `U.EpistemeTuple` (kernel species).\n\n**Intent.** Model **filled instances** of an episteme’s signature, separating the n‑ary relation from any particular holonic packaging or publication.\n\n**Normative definition.**\n\n1. `U.EpistemeTuple` is a species whose instances are **pure value tuples**:\n   * for each SlotKind in the associated `U.EpistemeKind`, a value of the slot’s **ValueKind** (or a reference value of **RefKind**, if the kind is configured as such).\n2. `U.EpistemeTuple` is **notation‑agnostic** and **carrier‑agnostic**: it does not know about files, formats, or surfaces.\n   It exists to give A.6.2–A.6.4 a minimal notion of “episteme as a point in Ep”.\n3. In episteme, `U.EpistemeTuple` rarely appears directly; it is typically **induced** by `U.EpistemeCard` and `U.EpistemeView` (which add component structure and meta‑information).\n\n**Didactic cue.**\n“An `EpistemeTuple` is the abstract record of *what fills which slots* — nothing more.”\n\n##### C.2.1:4.2.3 - `U.EpistemeCard`, `U.EpistemePublication`, `U.EpistemeView` — holonic realisations\n\n**Tech:** `U.EpistemeCard`, `U.EpistemePublication`, `U.EpistemeView` (species of `U.Episteme`).\n\n**Intent.** Provide **holon‑level structures** that engineers can work with (components, mereology, provenance), while keeping them aligned with `U.EpistemeKind` and `U.EpistemeTuple`.\n\n**Normative definition.**\n\n1. **`U.EpistemeCard`.**\n   A species of `U.Episteme` whose components correspond one‑to‑one to slots of some `U.EpistemeKind`:\n   * `content : U.ClaimGraph` (for `ClaimGraphSlot`),\n   * `describedEntityRef : U.EntityRef` (for `DescribedEntitySlot`),\n   * `groundingHolonRef? : U.HolonRef` (for `GroundingHolonSlot`),\n   * `viewpointRef? : U.ViewpointRef` (for `ViewpointSlot`),\n   * `referenceScheme? : U.ReferenceScheme` (for `ReferenceSchemeSlot`),\n   * optionally `representationSchemeRef? : U.RepresentationSchemeRef` (C.2.1+),\n   * `meta : Edition/Provenance/Status…`.\n     Minimal episteme identity is the pair `⟨content, describedEntityRef⟩` within a `U.BoundedContext`; all other fields are optional at the genus level but may be mandatory in species. Changes that alter `content` or the effective `referenceScheme` (or that intentionally re‑identify `describedEntityRef`) **SHALL** be realised as new phases in an `U.EditionSeries` (PhaseOf chain) under A.14/A.7. Changes confined to `U.PresentationCarrier` / surfaces or other publication artefacts **do not** create a new episteme; they are captured as `U.Work` / publication events over the same `U.Episteme`.\n2. **`U.EpistemePublication`.**\n   A species representing **epistemes that have been published** onto surfaces (MVPK). It:\n   * has at least the components of `U.EpistemeCard`,\n   * plus references to `U.Surface` / `U.Face` artefacts (E.17, L‑SURF),\n   * but **does not** re‑interpret these surfaces as parts of the episteme; carriers remain external.\n3. **`U.EpistemeView`.**\n   As defined in §4.1.5, a species of `U.Episteme` representing a **view** under a specific `U.Viewpoint`.\n   Its components are a specialisation of `U.EpistemeCard`:\n   * ClaimGraph often restricted/projection of a base description/specification,\n   * Viewpoint fixed,\n   * ReferenceScheme tailored to that viewpoint.\n\n**Alignment requirement.**\nFor any of these species, the pattern **MUST** state explicitly:\n* which `U.EpistemeKind` it realises, and\n* how each component maps to a SlotKind/RefKind under `U.RelationSlotDiscipline`.\n\nThis ensures that A.6.2–A.6.4 can treat any `U.Episteme*` uniformly as both:\n* an object in the category **Ep**, and\n* a structured holon with components.\n\n##### C.2.1:4.2.4 - SlotKind / ValueKind / RefKind discipline for DescribedEntity & GroundingHolon\n\nC.2.1 adopts **A.6.5 `U.RelationSlotDiscipline`** wholesale. For the two key positions:\n1. **DescribedEntitySlot.**\n   * `SlotKind = DescribedEntitySlot`;\n   * `ValueKind = U.Entity` (species may constrain to `EoIClass ⊑ U.Entity`);\n   * `RefKind = U.EntityRef` (or a species thereof);\n   * normative field name in episteme cards: `describedEntityRef : U.EntityRef`.\n     No kernel type named `U.DescribedEntity` is introduced; the phrase “described entity” always means “an instance of `U.Entity` in the role filling `DescribedEntitySlot`”.\n1. **GroundingHolonSlot.**\n   * `SlotKind = GroundingHolonSlot`;\n   * `ValueKind = U.Holon`;\n   * `RefKind = U.HolonRef`;\n   * normative field name: `groundingHolonRef? : U.HolonRef`.\n     There is no kernel type `U.GroundingHolon`; “grounding holon” is a **slot occupant name**.\nAny episteme that previously mixed slot/value/ref concepts (e.g., using `DescribedEntityRef` as if it were a type) **MUST** be migrated to this discipline over time; C.2.1 provides the normative anchor, and F.18 / discipline packs provide the migration guide.\n\n#### C.2.1:4.3 - Minimal epistemic morphisms (informal schema)\n\n> **Note.** The full mathematical treatment (categories Ep and Ref, describedEntity functor `α : Ep → Ref`, and effect‑free morphisms) lives in A.6.2–A.6.4. Here we fix only the **object‑level relations** that C.2.1 expects to exist between its positions.\n\nAt the level of `U.EpistemeCard` components and SlotKinds, we assume the following **primitive relations** (not all are functions):\n\n1. **`describedEntitySet : U.Episteme → P(U.Entity)`**\n   *derivable from `DescribedEntitySlot` and `ReferenceScheme`*\n   * For an episteme `E`, `describedEntitySet(E)` is (at least) the singleton containing the entity referenced by `describedEntityRef(E)`; in more complex cases, it may be a finite set or bundle of entities, determined by `ReferenceScheme`.\n   * The **functorial DescribedEntity mapping** `δ_E : Ep → Ref` used in A.6.2–A.6.4 is the categorical lift of this relation: it forgets episteme internals and keeps only the object in the ReferencePlane determined by the pair `<DescribedEntitySlot, GroundingHolonSlot>`.\n\n2. **`grounds : (U.Entity, U.Holon) ⇝ GroundingRelation`**\n   *relates described entities to grounding holons*\n   * Captures how values of `DescribedEntitySlot` are **situated** in holons that make evaluation possible (labs, infrastructures, organisations).\n   * Need not be total or functional; an entity may admit multiple grounding holons, or none.\n\n3. **`designates : (U.ReferenceScheme, U.ClaimGraph, U.Entity, U.Holon) ⇝ DesignationProfile`**\n   *how claims are read as statements about entities in contexts*\n   * Specifies, for each claim in `content` and each `<describedEntityRef, groundingHolonRef>`, what property/relation it purports to state, and under what conditions.\n\n4. **`satisfies / evaluatesTo : (U.ClaimGraph, U.ReferenceScheme, U.Holon) → TruthProfile/SuccessProfile`**\n   *evaluation of claims under a reference scheme and grounding*\n   * Forms the bridge to KD‑CAL’s `F, G, R` evaluation; details are given in C.2 and B.3.\n\n5. **View-related morphisms** (to be connected with A.6.3):\n   * `viewProject : (U.Episteme, U.Viewpoint) → U.View`\n     — effect-free, **DescribedEntity-preserving** projection that slices `ClaimGraph` and specialises `ReferenceScheme` under a given viewpoint.\n   * `viewEmbed : U.View → U.Episteme`\n     — embedding of a view back into the wider episteme, typically as a reference with correspondence proofs.\n\n5. **Reflexive describedEntity guard.**\n   When `DescribedEntitySlot` or `ReferenceScheme` picks out an episteme or claim that includes the referring claim itself (**ReferencePlane = episteme**), publishers **SHALL** ensure that the induced justification/evaluation structure is **acyclic per evaluation chain**: reflexive describedEntities may exist as literature handles, but they MUST NOT form a minimal support cycle for acceptance or KD‑CAL assurance. Self‑reference is allowed as a citation pattern, not as a way to close justification loops.\n\nThese are **not yet laws**; they are the **hooks** that A.6.2–A.6.4 will formalise into:\n* `U.EffectFreeEpistemicMorphing` (Ep→Ep morphisms over this structure),\n* `U.EpistemicViewing` (describedEntity‑preserving Ep→Ep),\n* `U.EpistemicRetargeting` (describedEntity‑retargeting Ep→Ep).\n",
        "c.2.1:5___legacy_semantic_triangle_as_didactic_view__*(informative)*": "### C.2.1:5 - Legacy semantic triangle as didactic view  *(informative)*\n\n**Position.** The classical semiotic or semantic triangle (“Symbol–Concept–Object”, Ogden–Richards/Frege–Carnap style) is **not** the normative ontology for epistemes in FPF. For `U.Episteme`, it is treated as a **didactic projection** of the richer hypergraph `U.EpistemeSlotGraph`:\n* **“Symbol” corner** ≈ {`U.RepresentationToken`, `U.RepresentationScheme`, `U.PresentationCarrier`} when C.2.1+ is in use; in the minimal core this is collapsed into whichever external artefact happens to carry `U.ClaimGraph`.\n* **“Concept” corner** ≈ `U.ClaimGraph` + `U.ReferenceScheme` under a chosen `U.Viewpoint`. This is the intensional content plus its interpretation recipe.\n* **“Object” corner** ≈ the occupant of `DescribedEntitySlot` (ValueKind `U.Entity`) plus the occupant of `GroundingHolonSlot` (ValueKind `U.Holon`) and the grounding relation between them.\n\nUnder this reading the triangle is a **three‑node quotient** of the `U.EpistemeSlotGraph`:\n```\n(Symbol)      = RepresentationToken + Scheme + Carrier\n(Concept)     = ClaimGraph + ReferenceScheme (+ Viewpoint)\n(Object)      = DescribedEntity + GroundingHolon\n```\n\nAll **viewpoints, operations, carriers and reference planes** are suppressed in the classical diagram. The cost of this suppression is precisely the confusion that motivates C.2.1:\n* describing becomes an single unlabeled arrow,\n* inference regimes disappear,\n* measurement and grounding are invisible.\n\n**Didactic use.** C.2.1 allows the triangle **only** in the following cases:\n1. As an **introductory picture** in guidance material (“this is the coarse triangle; the actual pattern is the episteme slot graph”).\n2. As a **quotient diagram**: an explicit note that “this figure ignores viewpoint, grounding, carrier, and operationality; see C.2.1 for the full structure”.\n3. As a **legacy alignment aid** when mapping to standards or literature that speak only in triangle terms.\n\n**Guard.** Any pattern or documentation page that uses a “semantic triangle” diagram **MUST** either:\n* explicitly state “this is a didactic projection of C.2.1 `U.EpistemeSlotGraph`”, or\n* treat it as a legacy reference when aligning with external standards.\n\nThe triangle **MUST NOT** be used as a kernel‑level ontology or as a basis for morphism laws. All normative reasoning about epistemes proceeds via the slots and components of `U.EpistemeSlotGraph`.\n",
        "c.2.1:6___interaction_with_i/d/s_and_descriptioncontext__*(normative)*": "### C.2.1:6 - Interaction with I/D/S and DescriptionContext  *(normative)*\n\nC.2.1 is the **episteme‑layer carrier** that I/D/S discipline (A.7, E.10.D2) relies on. The link is made via `DescriptionContext`.\n\n#### C.2.1:6.1 - DescriptionContext over C.2.1 components\n\nFor any episteme that is a **Description** or a **Specification** in the sense of E.10.D2, the field `subjectRef : U.SubjectRef` is interpreted as a **DescriptionContext triple**:\n```\nDescriptionContext = ⟨DescribedEntityRef, BoundedContextRef, ViewpointRef⟩\n```\n\nwhere:\n* `DescribedEntityRef : U.EntityRef` — occupies `DescribedEntitySlot` (ValueKind `U.Entity`, species often constrained via EoIClass ⊑ `U.Entity`).\n* `BoundedContextRef : U.BoundedContextRef` — points to the context that fixes vocabulary, units, and legal inferences for this description (E.10.D1).\n* `ViewpointRef : U.ViewpointRef` — occupies `ViewpointSlot` (ValueKind `U.Viewpoint`) and determines which concerns, role‑enactor families, and conformance rules apply.\n\n**Normative requirement (IDS‑13).**\nFor every `…Description` / `…Spec` episteme:\n1. `subjectRef` **SHALL** be decodable to a well‑formed DescriptionContext triple.\n2. `DescribedEntityRef` from that triple **SHALL** be identical to the field `describedEntityRef` that fills `DescribedEntitySlot` in the corresponding `U.EpistemeCard`/`U.EpistemeView`.\n3. `ViewpointRef` in DescriptionContext **SHALL** agree with `viewpointRef` in the episteme card or be uniquely derivable from a `U.ViewpointBundle` in E.17.1 (with the derivation rule documented).\n\nIntensions (I‑layer) such as `U.System`, `U.Method`, `U.Role` **do not** inhabit C.2.1 directly; they are the *targets* of I→D operations (`Describe_ID`) and appear as values of `DescribedEntitySlot` in resulting descriptions/specs.\n\n#### C.2.1:6.2 - I→D and D→S morphisms over C.2.1\n\n* **Describing (`Describe_ID : I → D`).**\n  Produces an episteme whose:\n  * `content : U.ClaimGraph` encodes the descriptive claims about the intension,\n  * `describedEntityRef` points to the intension’s entity,\n  * `groundingHolonRef` (if present) fixes where the description is evaluated or tested,\n  * `viewpointRef` selects the describing viewpoint.\n\n  `Describe_ID` is **conformant** to A.6.2 but not an Ep→Ep morphism (domain is Intension, codomain is Episteme). C.2.1 provides the **codomain schema** and ensures that the resulting Description has a valid DescriptionContext.\n\n* **Specifying/Formalising (`Specify_DS/Formalize_DS : D → S`).**\n  Takes a Description episteme and returns a Specification episteme with:\n  * the same `describedEntityRef`,\n  * the same `BoundedContextRef` and `ViewpointRef` (hence same DescriptionContext),\n  * a `content : U.ClaimGraph` that raises formality F (F≥4) and adds test harness hooks, but is conservative with respect to the underlying intension.\n\n  As an Ep→Ep morphism, `Specify_DS` is a **species of A.6.2** and must obey the invariants over the C.2.1 slots (DescribedEntityChangeMode = preserve; no change to DescribedEntity; ClaimGraph refinement only).\n\nC.2.1 does **not** define I/D/S; it only insists that any `…Description`/`…Spec` species that claims to respect I/D/S discipline must:\n* implement `U.EpistemeCard` or `U.EpistemeView` **with** `content`, `describedEntityRef`, `groundingHolonRef?`, `viewpointRef?`, and `referenceScheme?` fields, and\n* wire these fields into `subjectRef` as DescriptionContext.\n",
        "c.2.1:7___alignment_with_a.6.2–a.6.4_(episteme_morphisms)__*(normative)*": "### C.2.1:7 - Alignment with A.6.2–A.6.4 (episteme morphisms)  *(normative)*\n`U.EpistemeSlotGraph` is the **object‑level substrate** for the episteme morphism patterns:\n* A.6.2 `U.EffectFreeEpistemicMorphing`\n* A.6.3 `U.EpistemicViewing`\n* A.6.4 `U.EpistemicRetargeting`\n\n#### C.2.1:7.1 - Effect‑free episteme morphisms (A.6.2) over C.2.1\nFor any `f : X → Y` that is an instance of `U.EffectFreeEpistemicMorphing`:\n* **Typed objects.**\n  X and Y are `U.Episteme` instances realised as `U.EpistemeCard` / `U.EpistemeView` with at least the minimal core components:\n\n  ```\n  content            : U.ClaimGraph\n  describedEntityRef : U.EntityRef      // DescribedEntitySlot\n  groundingHolonRef? : U.HolonRef       // GroundingHolonSlot\n  viewpointRef?      : U.ViewpointRef   // ViewpointSlot\n  referenceScheme?   : U.ReferenceScheme// ReferenceSchemeSlot (ByValue)\n  ```\n\n  Any additional C.2.1+ components (RepresentationScheme, Tokens, Carriers, Operations) are visible to A.6.2 only through their declared SlotKinds (A.6.5).\n* **DescribedEntityChangeMode characteristic.**\n  `f` **MUST** declare a **`describedEntityChangeMode ∈ {preserve, retarget}`**:\n  * `preserve` — `describedEntityRef(Y) = describedEntityRef(X)` and any change to `groundingHolonRef`/`viewpointRef` must be justified by Bridges/CorrespondenceModel, without changing the DescribedEntitySlot value;\n  * `retarget` — permitted only for A.6.4 species; see below; in this case the characteristic records an intentional change in the pair `<describedEntityRef, groundingHolonRef>` under a declared `KindBridge` in the appropriate ReferencePlane.\n\n  This **DescribedEntityChangeMode** is a CHR-style *characteristic* (A.17) on episteme morphisms, which points directly to `DescribedEntitySlot`. Avoid introducing a separate “describedEntity” term alongside `DescribedEntity`. \n  \n* **Component discipline.**\n  P0–P5 from A.6.2 are read **directly** in terms of C.2.1 components:\n  * purity ⇒ only C.2.1 components of Y may change; no Work/Mechanism side‑effects;\n  * conservativity ⇒ claims in `content_Y` read via `referenceScheme_Y` about the new `<DescribedEntity, GroundingHolon>` do not go beyond what already follows from `content_X` via `referenceScheme_X` under the declared DescribedEntityChangeMode and Bridges;\n  * functoriality ⇒ composition of such transformations respects the slot structure and ReferenceSchemes.\n\nAny Ep→Ep pattern that operates on `U.Episteme` **MUST** state which C.2.1 slots it reads and which it may write, in terms of SlotKinds/ValueKinds/RefKinds (A.6.5), and then declare itself a species of A.6.2/3/4 as appropriate.\n\n#### C.2.1:7.2 - EpistemicViewing (A.6.3) as describedEntity‑preserving projections\n\n`U.EpistemicViewing` is the **DescribedEntity-preserving** species of A.6.2. Over C.2.1 this means:\n* `describedEntityRef(Y) = describedEntityRef(X)` — the same value in `DescribedEntitySlot`.\n* `groundingHolonRef` is preserved, or changed only within a fixed grounding context (e.g. normalising identifiers for the same lab or runtime).\n* `viewpointRef` is either:\n  * preserved (internal normalisation under the same viewpoint), or\n  * replaced by another `U.ViewpointRef` *within* a `U.MultiViewDescribing` family (E.17.0), with invariants enforced by a CorrespondenceModel.\n* `content` and `referenceScheme` are transformed **conservatively**: no new intensional claims about the same DescribedEntity are introduced.\n\nTypical examples:\n* filtering or aggregating `U.ClaimGraph` to a view relevant for a stakeholder group;\n* rendering a behavioural specification into a tabular or diagrammatic episteme under a publication viewpoint;\n* normalising a logic‑heavy episteme into a more operational one, while keeping the same described system and context.\n\nIn terms of SoTA, EpistemicViewing behaves like a **lens** or **optic** over C.2.1: a focus (SlotKinds for content/representation) is manipulated while the DescribedEntity is fixed.\n\n#### C.2.1:7.3 - EpistemicRetargeting (A.6.4) as DescribedEntity-bundle retargeting on episteme morphisms\n\n`U.EpistemicRetargeting` is the species of A.6.2 where **`describedEntityChangeMode = retarget`**.\nIt is always a **morphism between epistemes** (`f : X → Y` in `U.Episteme`), but the adjective “retargeting” refers **not** to the fact that an episteme is mapped to another episteme (this is true for all A.6.2 species), and **not** to a separate describedEntity, but specifically to the **change in the DescribedEntity-bundle** selected by C.2.1:\n* `describedEntityRef(Y) ≠ describedEntityRef(X)` — the value stored for `DescribedEntitySlot` changes;\n* a `KindBridge` must relate `Kind(describedEntityRef(X))` and `Kind(describedEntityRef(Y))`;\n* `groundingHolonRef` may remain the same (e.g. same plant, different subsystem) or be transformed along a Bridge in the same ReferencePlane.\n\nIn practice, many retargetings operate on the **target bundle** `<DescribedEntitySlot, GroundingHolonSlot>` (for example, when an episteme about a physical module is re-interpreted as an episteme about a function-holon realised in a different environment). The characteristic `describedEntityChangeMode` still classifies such morphisms by whether this bundle is preserved or intentionally re-identified under a `KindBridge` and reference-plane policy; the episteme on the codomain side is just the usual A.6.2 target object.\n\n\nOver C.2.1 this is used for:\n* **functional vs structural reinterpretation** (e.g. an episteme about a physical module retargeted to an episteme about the function it realises; StructuralReinterpretation in E.TGA becomes a species of A.6.4);\n* **signal vs spectrum** transitions (Fourier‑style moves where the object‑of‑talk changes from time‑domain signal to frequency‑domain representation but an invariant, such as energy, is preserved);\n* **data vs model** transitions (e.g. retargeting an episteme about raw observations to an episteme about a learnt model, with an invariant such as likelihood or sufficient statistics).\n\nC.2.1 ensures that these retargetings have a **clear source and target** at the DescribedEntitySlot and that any such move is expressed as a morphism over well‑typed slots, not as an unstructured rewrite of “subject” or “object” labels.\n",
        "c.2.1:8___alignment_with_e.17.*_(multi‑view_describing_&_publication)__*(normative)*": "### C.2.1:8 - Alignment with E.17.* (Multi‑View Describing & Publication)  *(normative)*\n\n`U.EpistemeSlotGraph` underpins the E.17 cluster:\n* E.17.0 `U.MultiViewDescribing`\n* E.17.1 `U.ViewpointBundleLibrary`\n* E.17.2 `TEVB — Typical Engineering Viewpoints Bundle`\n* E.17 `MVPK — Multi‑View Publication Kit`\n\n#### C.2.1:8.1 - Multi‑View Describing (E.17.0)\n\n`U.MultiViewDescribing` organises **families of descriptions/specifications** over a shared entity‑of‑interest:\n* The **EoIClass** parameter of E.17.0 is a species constraint on the ValueKind of `DescribedEntitySlot` (`EoIClass ⊑ U.Entity`).\n* Each member of a multi‑view family is a `…Description`/`…Spec` episteme with:\n  * `describedEntityRef` into that EoIClass,\n  * `viewpointRef` drawn from a `U.ViewpointBundle`,\n  * `subjectRef` decoding to DescriptionContext.\n\nWithin this pattern:\n* `U.Viewpoint` is **exactly** the ValueKind of `ViewpointSlot` in C.2.1.\n* `U.View` is `U.EpistemeView`, a species of `U.Episteme` whose `content` is already restricted to a particular `U.Viewpoint` and often also to a particular `U.RepresentationScheme`.\n\nC.2.1 thus supplies the **per‑episteme** structure that E.17.0 rearranges into multi‑view families.\n\n#### C.2.1:8.2 - Viewpoint bundles (E.17.1/E.17.2)\n\n`U.ViewpointBundleLibrary` and TEVB specialise the `U.Viewpoint` node:\n* A ViewpointBundle is a **set of `U.Viewpoint` instances** tailored to a class of DescribedEntities (e.g., holons in engineering contexts).\n* TEVB fixes `EoIClass = U.Holon` (typically `U.System` or `U.Episteme`) and provides canonical engineering viewpoints: functional, structural, role‑enactor, interface‑oriented, etc.\n\nFrom the C.2.1 perspective:\n\n* these bundles populate the ValueKind of `ViewpointSlot`;\n* engineering episteme species that want to be “TEVB‑aligned” must restrict `viewpointRef` to TEVB’s `EngineeringVPId` set, while keeping the same DescribedEntitySlot discipline.\n\n#### C.2.1:8.3 - MVPK (E.17) as publication over C.2.1 views\n\nMVPK treats `U.View` (i.e. `U.EpistemeView`) as its primary input:\n* it uses `U.EpistemicViewing` species (A.6.3) to generate publication‑oriented views from engineering or logical views;\n* it then packages these `U.View` epistemes into `U.Surface` artefacts via publication viewpoints and faces.\n\nC.2.1’s distinction between:\n\n* `U.Viewpoint` (intensional, epistemic perspective) and\n* `U.PresentationCarrier` (surface in C.2.1+ and L‑SURF)\n\nkeeps **epistemic perspective and physical medium separate**:\n* MVPK operates only on epistemes (Views) and then on carriers;\n* the same View can be realised on multiple carriers without changing its describedEntity or ClaimGraph.\n\nAny MVPK species that claims to be C.2.1‑conformant **MUST**:\n* treat `U.View` as a `U.EpistemeView` with a valid C.2.1 core,\n* document which C.2.1 slots it reads/writes (typically only representation/carrier‑related ones, leaving `DescribedEntitySlot` and `GroundingHolonSlot` untouched),\n* refrain from introducing new claims about the described entity beyond what is in the source `U.View`’s ClaimGraph.\n",
        "c.2.1:9___bias‑annotation__*(informative)*": "### C.2.1:9 - Bias‑annotation  *(informative)*\n\n**Episteme‑first and pragmatics‑first.**\nThe pattern assumes that *nothing is a meaningful episteme* unless it is **about something for someone under some perspective**. This follows the pragmatic turn in semantics: describedEntity and concerns are not afterthoughts but part of the core structure. The graph is therefore built around slots for DescribedEntity, GroundingHolon, Viewpoint and ClaimGraph, not around abstract “propositions in the void”.\n\n**Operational/representational bias.**\nC.2.1+ anticipates that certain RepresentationSchemes are **operational** in Novaes’ sense (supporting direct syntactic inference, like pen‑and‑paper arithmetic or proof states) while others are **purely notational**. The pattern remains neutral on which schemes are used but bakes in a place for operations and carriers so that:\n\n* symbol‑manipulating tools (SAT/SMT, proof assistants, classical programming languages),\n* distributed/latent representations (LLM embeddings, latent protocols like “DroidSpeak”, “Coconut”‑style communication),\n* hybrid ReAct‑style agent loops\n\ncan all be treated as different species operating over the same `U.EpistemeSlotGraph`. There is a bias towards making these operational differences **explicit** instead of hiding them behind “the model”.\n\n**Viewpoint and stakeholder bias.**\nThe pattern leans on the ISO‑style idea that viewpoints encode **stakeholder concerns and role‑families**, but it generalises this beyond architecture. `U.Viewpoint` is intentionally intensional and not bound to any single discipline; still, the examples are skewed toward engineering and epistemic use‑cases.\n\n**Didactic bias.**\nThe pattern is written to be teachable: semantic triangles are kept as didactic projections; examples like stools on lab rigs, services and SLAs, and model‑evaluation epistemes are deliberately simple. This may under‑represent more exotic epistemes (e.g. artistic, legal, or socio‑technical ones), but the intention is that these use the same slots with different species‑level constraints.\n",
        "conformance_checklist": "### C.2.1:10 - Conformance checklist  *(normative)*\n\n**CC‑C.2.1‑1 - Minimal core components for episteme species.**\nAny species of `U.Episteme` that participates in I/D/S discipline or in E.17 multi‑view/publishing **MUST** be representable as `U.EpistemeCard`/`U.EpistemeView` with at least:\n\n```\ncontent            : U.ClaimGraph\ndescribedEntityRef : U.EntityRef\ngroundingHolonRef? : U.HolonRef\nviewpointRef?      : U.ViewpointRef\nreferenceScheme?   : U.ReferenceScheme      // ByValue\nmeta               : …                      // edition, provenance, status (A.7/F.15)\n```\n\nand corresponding SlotSpecs consistent with A.6.5 (`DescribedEntitySlot`, `GroundingHolonSlot`, `ClaimGraphSlot`, `ViewpointSlot`, `ReferenceSchemeSlot`).\n\n**CC‑C.2.1‑2 - No kernel type for “DescribedEntity” or “GroundingHolon”.**\nPatterns **MUST NOT** introduce kernel types `U.DescribedEntity` or `U.GroundingHolon`:\n* DescribedEntitySlot has ValueKind `U.Entity` ( species‑constrained via EoIClass if needed),\n* GroundingHolonSlot has ValueKind `U.Holon`.\n\nPlain terms “described entity” and “grounding holon” are allowed only as **role descriptions** of slot occupants.\n\n**CC‑C.2.1‑3 - SlotKind/ValueKind/RefKind discipline.**\nAll episteme‑related slots, including `DescribedEntitySlot`, `GroundingHolonSlot`, `ClaimGraphSlot`, `ViewpointSlot`, `ViewSlot`, `ReferenceSchemeSlot` (and any extensions in C.2.1+), **MUST**:\n* follow the naming discipline of A.6.5 (`*Slot` for SlotKinds, `*Ref` only for RefKinds/fields),\n* declare a ValueKind and refMode (`ByValue` or a RefKind),\n* be used consistently across patterns that refer to the same conceptual position.\n\n**CC‑C.2.1‑4 - DescriptionContext wiring.**\nAny episteme species whose name or pattern claims to be a `…Description` or `…Spec` in the sense of E.10.D2 **MUST**:\n* expose `subjectRef : U.SubjectRef`,\n* provide a decoding to `DescriptionContext = ⟨DescribedEntityRef, BoundedContextRef, ViewpointRef⟩`,\n* ensure that `DescribedEntityRef` matches `describedEntityRef` (DescribedEntitySlot), and\n* ensure that `ViewpointRef` matches `viewpointRef` or is derivable from a `U.ViewpointBundle` under documented rules.\n\n**CC‑C.2.1‑5 - Morphism declarations over slots.**\nAny pattern in A.6.2–A.6.4, E.17, E.TGA, or discipline packs that defines morphisms between epistemes **SHALL**:\n* state whether it is a species of `U.EffectFreeEpistemicMorphing`, `U.EpistemicViewing`, or `U.EpistemicRetargeting`,\n* declare its `describedEntityChangeMode` (preserve/retarget),\n* name which SlotKinds it reads and writes,\n* state its behaviour on `describedEntityRef`, `groundingHolonRef`, `viewpointRef`, and `referenceScheme`.\n\n**CC‑C.2.1‑6 - Semantic‑triangle usage guard.**\nIf a semantic triangle or parallelogram diagram appears in a pattern or tutorial, there must be an explicit note that:\n* it is a didactic projection of `U.EpistemeSlotGraph`, and\n* normative laws are stated in terms of C.2.1 nodes and morphisms, not in terms of triangle corners.\n\n**CC‑C.2.1‑7 - KD‑CAL / ReferencePlane alignment.**\nAny pattern that evaluates or compares epistemes (KD‑CAL/LOG‑CAL, CHR, CG‑Spec, etc.) **MUST** point out:\n* how `U.ClaimGraph` is interpreted in a ReferencePlane,\n* how `GroundingHolonSlot` figures into measurement or validation,\n\n**CC‑C.2.1‑8 - Context locality and Bridges.**\nAny `U.Episteme` species that is consumed by KD‑CAL / LOG‑CAL / CHR‑based patterns **SHALL** declare a `U.BoundedContextRef`; all F–G–R computations and C.2.1 slot interpretations are **context‑local**.  Cross‑context use **MUST** proceed via an explicit Bridge with CL / Φ‑policy (F.9/B.3), with penalties routed to R‑lanes only; F and the slot structure from C.2.1 remain unchanged.\n\n**CC‑C.2.1‑9 - Carriers and Work outside episteme content.**\nC.2.1 **inherits** A.7/A.12’s separation obligations: `U.PresentationCarrier` / `U.Surface` artefacts and `U.Work` instances **MUST NOT** be treated as parts of `U.Episteme` or as values of any SlotKind in `U.EpistemeSlotGraph`. Episteme content stays in `U.ClaimGraph` and `U.ReferenceScheme`; evidence enters only via `U.EvidenceRole` bindings that point to external `U.Work` / carriers (A.10/B.3). Changing carriers or re‑publishing work alone does **not** change the episteme determined by ⟨content, describedEntityRef, referenceScheme⟩ in its `U.BoundedContext`.\n\n**CC‑C.2.1‑10 - Reflexive describedEntity guard.**\nWhen an episteme uses C.2.1 to speak **about** another episteme (ReferencePlane = episteme), or about itself (self‑describing or meta‑specification cases), patterns **SHALL** ensure that the resulting JustificationGraph / evaluation chains are **acyclic** along support paths. Reflexive `describe` / citation edges may exist as literature anchors, but they MUST NOT form minimal support cycles for acceptance or KD‑CAL assurance decisions; the trust calculus MUST always bottom out in external evidence (`U.Work` with `U.EvidenceRole`) rather than in purely self‑referential claims.\n",
        "consequences": "### C.2.1:11 - Consequences  *(informative)*\n\n**Benefits**\n* **Single, extensible episteme core.**\n  C.2.1 gives a small, stable set of positions (DescribedEntity, GroundingHolon, ClaimGraph, Viewpoint, View, ReferenceScheme) and components (`U.EpistemeCard`, `U.EpistemeView`, `U.EpistemePublication`) on which all higher‑level patterns depend. This avoids the proliferation of “epistemic objects” and “facets” with overlapping semantics.\n**Transparent DescribedEntity & grounding discipline.**\n  The pair (`DescribedEntitySlot`, `GroundingHolonSlot`) is no longer hidden inside ad-hoc “SubjectRef” fields or semantic triangles: both are explicit, typed slots. This makes retargeting, viewing and correspondence laws (A.6.2–A.6.4, E.17.0) easier to state and check.\n* **Better fit for contemporary representation practice.**\n  By distinguishing ClaimGraph, RepresentationScheme, Tokens, Carriers and Operations (in C.2.1+), the pattern matches contemporary SoTA views of notation and formalism:\n  * formal languages as cognitive artefacts and de‑semanticisation tools (Novaes),\n  * operational iconicity and medium‑sensitive reasoning (Krämer, Malafouris),\n  * hybrid symbolic–neural workflows (e.g. ReAct, tool‑augmented LLMs, latent protocols).\n  FPF can model both symbol‑heavy and latent‑heavy workflows without privileging either.\n* **Uniform substrate for multi‑view description and publication.**\n  MultiViewDescribing, viewpoint bundles (TEVB), and MVPK all land on the same episteme core. This avoids the current “views vs viewpoints vs faces” confusion and leaves “architecture” as a domain‑specific specialisation rather than a competing meta‑ontology.\n* **Tooling alignment.**\n  Slot discipline plus explicit episteme components map cleanly to implementation types (records, row‑typed schemas, effectful handlers). Tools can generate code, schemas or telemetry from episteme species without guessing what “subject”, “context” or “object” mean.\n\n**Trade‑offs / costs**\n* **More explicit structure.**\n  Authors must declare slots, ValueKinds and references explicitly, and keep DescriptionContext consistent. This is more upfront work than writing ad‑hoc “Subject/Object” fields, but it pays off in substitution safety and cross‑pattern reuse.\n* **Migration effort.**\n  Legacy uses of “EpistemicObject”, “Facet”, “Subject”/“Object”, and raw `…Ref` fields will need refactoring into C.2.1 slots + A.6.5 SlotSpecs. Migration notes and aliasing can ease the transition, but mechanical cleanup will still be required.\n* **Exposure of representation biases.**\n  Being explicit about RepresentationSchemes and Operations may surface disagreements about which representations are “primary” in a team or discipline. C.2.1 does not resolve these disagreements; it only makes them visible and therefore debatable.\n\n#### C.2.1:12 - Relations  *(overview)*\n\n**Builds on**\n* A.1 `U.Holon` — for treating episteme as a holon with components.\n* A.6.0 `U.Signature` — for interpreting episteme kinds as n‑ary relations over slots.\n* A.6.5 `U.RelationSlotDiscipline` — for SlotKind/ValueKind/RefKind discipline over episteme slots.\n* A.7, E.10.D2 — for I/D/S discipline and the Interpretation of `subjectRef` as DescriptionContext.\n* C.2 (KD‑CAL, LOG‑CAL) — for ClaimGraph semantics, ReferencePlanes, and Bridges.\n* E.8, E.10 — for pattern authoring discipline and lexical guards.\n\n* **Constrains**\n* A.6.2–A.6.4 — by fixing the minimal episteme component set those morphisms operate on and by requiring an explicit **DescribedEntityChangeMode characteristic** (`describedEntityChangeMode ∈ {preserve, retarget}`) over `DescribedEntitySlot`/`GroundingHolonSlot`.\n* E.17.0–E.17.2 — by specifying how `DescribedEntity`, `Viewpoint`, `View` and ReferenceSchemes are represented at episteme level.\n* E.17 (MVPK) — by separating `U.View` (episteme) from `U.PresentationCarrier` (surface), and by requiring that publication morphisms be `U.EpistemicViewing` species over C.2.1‑conformant views.\n* F.18 (LEX‑BUNDLE) — by providing the episteme‑specific name cards and guards for DescribedEntity/GroundingHolon/Viewpoint/View/ReferenceScheme and their SlotKinds.\n\n**Used by**\n* A.6.2 `U.EffectFreeEpistemicMorphing` — as the default episteme object structure for episteme‑to‑episteme transforms.\n* A.6.3 `U.EpistemicViewing` — as the substrate for describedEntity‑preserving projections (views).\n* A.6.4 `U.EpistemicRetargeting` — as the substrate for DescribedEntity-bundle retargeting transforms between epistemes (Ep→Ep with `describedEntityChangeMode = retarget`).\n* E.17.0 `U.MultiViewDescribing`, E.17.1, E.17.2 — to organise families of D/S‑epistemes under Viewpoints and EoI classes.\n* E.17 (MVPK) — to publish episteme views as surfaces.\n* E.TGA — to interpret StructuralReinterpretation and other engineering projections as episteme morphisms over a well‑typed `U.EpistemeSlotGraph`.\n\nTogether, these relations make `U.EpistemeSlotGraph` the **single normative core** for thinking about epistemes, their DescribedEntity mapping, their representations, and their transformations across FPF.\n",
        "c.2.1:end": "### C.2.1:End\n"
      },
      "content": "### C.2.1:End\n",
      "metadata": {},
      "part": "C",
      "cluster": null
    },
    {
      "id": "C.2.2",
      "title": "Reliability R in the F–G–R triad",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## C.2.2 - Reliability R in the F–G–R triad\n\n> Reliability (R) is a conservative, evidence-bound warrant signal for a typed claim under an explicit claim scope (G). Cross-context reuse is **Bridge-only**: scope may be re-expressed via `translate(Bridge,·)` (often narrowing), while congruence penalties route to **R only**.\n\n> **Type:** Architectural (A)\n> **Status:** Stable\n",
        "problem": "### C.2.2:2 - Problem\n\nFPF needs a reliability coordinate that is:\n\n1. **Auditable.** A reader can trace R to concrete evidence and see how reuse penalties were applied.\n2. **Composable.** R can be propagated through claim graphs conservatively, without illegal scale arithmetic.\n3. **Orthogonal.** R is not conflated with F (expression) or G (scope).\n4. **Bridge-safe.** Any loss from transport across contexts/kinds/planes is explicit and affects **R only**. \n5. **Minimal.** The solution does not introduce new core types or new face-kinds.\n",
        "forces": "### C.2.2:3 - Forces\n\n| Force                                         | Tension                                                                                                            |\n| --------------------------------------------- | ------------------------------------------------------------------------------------------------------------------ |\n| **Single number vs multi-tradition evidence** | People want one scalar ↔ evidence comes from heterogeneous practices (proofs, tests, telemetry, expert review).    |\n| **Rigor vs humility**                         | Claims need to be usable in decisions ↔ overconfident scores are dangerous and hard to unwind.                     |\n| **Formal vs empirical warrant**               | Proof can be decisive in a formal theory ↔ real-world deployment requires empirical adequacy and drift management. |\n| **Scope realism vs marketing scope**          | Narrow scopes raise R ↔ incentives push for broad statements with hidden preconditions.                            |\n| **Reuse vs semantic loss**                    | Reuse is valuable ↔ reuse across contexts/kinds/planes is inherently lossy.                                        |\n| **Toolability vs expressive freedom**         | A validator needs crisp rules ↔ authors want flexible narratives and domain nuance.                                |\n",
        "solution": "### C.2.2:4 - Solution\n\n#### C.2.2:4.1 - Canonical triad contract\n\n**Definition DEF‑C2.2‑1 (Epistemic location).**\nAn epistemic location for a claim `c` is the tuple:\n\n`Loc(c | K, S) = ⟨F(c), G(c), R_eff(c)⟩`\n\nwhere:\n\n* `F(c)` is Formality (C.2.3), treated as an **ordinal**.\n* `G(c)` is Claim scope (A.2.6), treated as a **set-like scope object**.\n* `R_eff(c)` is Effective reliability for `c`, treated as a **ratio-scale** scalar in `[0,1]` (or an **ordinal proxy** at **[M‑0/M‑1]**; see §4.5.A).\n  `R_eff` is computed **pathwise** (DEF‑C2.2‑3): when more than one admissible justification path exists, publish multiple path records (PathId rows) and cite which PathId(s) a guard/decision consumed (see §4.8.A / G.6). Any collapse to a single scalar is an explicitly declared Γ‑policy (no implicit averaging).\n\nA location is always understood *relative to* a bounded context and the assurance carriers used elsewhere in FPF:\n* `K` is the declared `U.BoundedContext`.\n* `S ∈ {design, run}` is the claim’s stance carrier (no design/run chimeras).\n* `ReferencePlane` is declared where applicable; plane crossings apply `CL^plane` and penalize **R only**.\n* When the claim is published on the Working‑Model surface, the author also declares `validationMode ∈ {postulate, inferential, axiomatic}` (E.14 / B.3).\n\n**Mode-to-lane hint (informative).** `validationMode` sets the *default expectation* for which assurance lane carries the initial burden (B.3.3 / B.3.5).\nIt does **not** add a new axis and does **not** change the meaning of `R`:\n* `axiomatic` → VA-dominant (constructive grounding / proof artifacts); if `ReferencePlane=world`, LA may still be required.\n* `inferential` → VA+TA-dominant (reasoned chain + typing/alignment assurance); LA is optional and scope-bound.\n* `postulate` → LA-dominant (empirical validation with freshness/decay); VA is optional.\nIn all modes, **R remains warrant**, not ontological truth; “proof ⇒ R=1 in the world” is a category error.\n\n**Profile note (informative; fold compatibility).** Some profiles treat empirical `R` as N/A for strictly **axiomatic** lines and use a tagged proxy `R_proxy := F` (`line=formal`) for folding, as an explicit proxy rather than an implicit “F⇒R” rule (B.1.3).\n\n`⟨F,G,R⟩` is an **assurance tuple**, not a `U.CharacteristicSpace`; do not draw “trajectories” in `⟨F,G,R⟩`.\n\n#### C.2.2:4.2 - What Reliability R means in KD‑CAL\n\n**Definition DEF‑C2.2‑2 (Reliability as warrant).**\n`R` is a conservative, evidence-bound indicator of how strongly the claim “holds as stated” under its declared scope and context. It is interpreted as a *warrant strength*, not as truth.\n\n**Prophylactic clarification.**\n\n* A higher `R` means “the evidence and its relevance supports relying on this claim under this scope.”\n* A higher `F` means “the claim’s form is amenable to stronger checking and reuse,” but does not itself imply the claim is warranted.\n* A larger `G` means “the claim applies to more cases,” but does not itself imply the claim is warranted in those cases.\n\n#### C.2.2:4.3 - Pathwise weakest-link propagation (series vs parallel)\n\nKD‑CAL’s default Γ‑fold is **weakest‑link** on the *entailment spine* (the premises/lemmas actually needed), computed per justification path. It is conservative, monotone, and auditable.\n\n**Definition DEF‑C2.2‑3 (Pathwise weakest-link fold).**\nLet `P` be a justification path for claim `c`. Let `SpineClaims(P)` be the required supports on the entailment spine, and let `SpineBridges(P)` be the bridges actually traversed on that spine (scope bridges, kind bridges, plane/notation transports where applicable).\n\nDefine the raw warrant of the path as:\n\n`R_raw(P) = min_{i ∈ SpineClaims(P)} R_eff(i)`\n\nand compute the effective warrant of the path by applying congruence penalties (see §4.5 for policy shape):\n\n`R_eff(P) = Π(R_raw(P); Φ(CL_min(P)), Ψ(CL^k_min(P)), Φ_plane(CL^plane_min(P)))`\n\n**Spine discipline.** The `min` is taken over the *entailment spine* only (no satellites, no “nice-to-have” citations).\n\nThis matches the KD‑CAL propagation rule (C.2:4.3) and the Trust & Assurance skeleton (B.3): weakest-link on the spine, penalize only by the worst (lowest) congruence encountered on the path (no averaging).\n\n**Parallel support (optional, declared).**\nIf the same claim `c` has multiple **independent** justification paths `{P_j}` (OR‑style support), the default is:\n\n`R_eff(c) = max_j R_eff(P_j)`\n\nIndependence is recorded as an explicit note (e.g., separate rigs/datasets/proof lines), per CC‑C.2.2‑10 and the KD‑CAL composition rule (C.2:4.3).\nIf the “multiple paths” actually cover **different** scope slices, do not use `max` to hide weaker slices; instead publish distinct `G_path` (SpanUnion‑style coverage) and keep per‑path `R_eff` traceable (A.2.6 / C.2:4.3).\n\n**Conflict detection (no averaging).**\nIf the evidence graph supports both `p` and `¬p` with overlapping scope, do **not** average. Separate by context/scope, or mark the claim **provisional** with explicit conflict edges until resolved.\n\n#### C.2.2:4.4 - Congruence penalties route to R only (no silent widening)\n\nCross-context reuse and cross-kind reuse are treated as **transport with loss**, and loss is expressed as a penalty that reduces `R`.\n\n**Invariant INV‑C2.2‑1 (R-only penalty routing).**\nFor any transport step that uses a bridge with a declared congruence level, the transported claim preserves its **F** value, re-expresses its scope via an explicit **scope translation** (`translate`) when needed, and only its **R** value is decreased by congruence penalties:\n\n`F_out = F_in`\n`G_out = translate(Bridge, G_in)`  *(identity only for within-context identity use; cross-context use is undefined without a Bridge)*\n`R_out ≤ R_in`\n\nClaim scope may be *re-expressed* by an explicit translation, but must not be silently widened:\n\n`G_out = translate(Bridge, G_in)`  (may narrow / drop unmappable slices; never widen without an explicit ΔG)\n\n**No implicit translation.** Translation between contexts never occurs implicitly: if the target context differs, an explicit Bridge (with declared CL and loss note) is mandatory; otherwise the reuse is non-conformant.\n**No implicit translation.** Cross‑Context reuse is conformant only via an explicit Bridge (declared CL + loss note) and an explicit `translate(Bridge,·)`; see **CC‑C.2.2‑4**.\n\nThis invariant is why KD‑CAL guard macros and crossing surfaces can be simple: transport never silently *widens* a claim; it either (i) translates/narrows scope explicitly, and/or (ii) reduces warrant.\n\n`translate` is the USM operator (A.2.6). It may drop unmappable slices and may include refit-like normalization; **this is not a penalty**. Any further narrowing is an explicit Δ‑move (ΔG−) under A.2.6. Congruence loss (CL/CL^k/CL^plane) still routes to **R only**.\n\n**Notation/plane transports.** NotationBridge and plane transports contribute to the relevant `CL*_min(P)` bottlenecks for the path; they do not “lower F” by penalty. If an author actually rewrites a claim into a different formality level, that is a new episteme (ΔF), not “transport”.\n\n#### C.2.2:4.4.A - Worked micro-example: `translate(G)` + penalty (A.2.6:12.2)\n\n**Source context:** `MaterialsLab@2026`. Claim:\n\n> `c:` “Adhesive X retains ≥85% tensile strength on Al6061 for 2 h at 120–150 °C.”\n\n* `G_src := {substrate=Al6061, temp∈[120,150]°C, dwell≤2h, Γ_time=window(1y), rig=Calib‑v3}`\n* `Loc_src(c) = ⟨F_src, G_src, R_raw⟩`\n\n**Target context:** `AssemblyFloor@EU‑PLANT‑B`. Reuse requires a declared Bridge `b`:\n\n* Bridge `Bridge#MatLab_to_PlantB` maps lab rig → plant rig and introduces a measurement correction; `CL(Bridge#MatLab_to_PlantB)=2` with loss note “±2 °C bias.”\n* **Scope translation:** `G_tgt := translate(b, G_src)` which (in this case) narrows the temperature span to `[122,148]°C` due to the correction.\n* **Penalty routing:** using policy `Φ=Φ_v1`, compute\n  `R_eff := max(0, R_src − Φ_v1(CL(Bridge#MatLab_to_PlantB)))`.\n\n**Key point:** `G` changed only because `translate(b,·)` explicitly re-expressed the *same entitlement* in the target Context’s slice vocabulary; the **congruence loss** still affects **R only**. If authors decide that only `[125,145]°C` is safe to claim on the floor, that is an explicit **ΔG−** decision (scope edit), not a congruence penalty.\n\n#### C.2.2:4.5 - Effective reliability under transport (policy-defined, monotone, bounded)\n\nWhen a claim is reused via bridges, `R_eff` is computed by applying penalties determined by congruence levels.\n\n**Definition DEF‑C2.2‑4 (Effective reliability under transport).**\nLet:\n\n* `CL` be the congruence level of a scope bridge (B.3).\n* `CL^k` be the congruence level of a kind bridge (C.3).\n* `CL^plane` be the congruence level of a plane transport bridge (B.3 / plane patterns).\n\nLet `Φ`, `Ψ`, and `Φ_plane` be **policy-defined**, **monotone**, **bounded**, **table-backed** penalty policies applied on the relevant edges:\n* `Φ(CL)` — scope/context Bridge penalty (CL).\n* `Ψ(CL^k)` — KindBridge penalty (CL^k) when kinds are mapped.\n* `Φ_plane(CL^plane)` — plane-crossing penalty when `ReferencePlane` differs.\n\n**Important (direction of monotonicity).** Congruence ladders are “polarity up” (higher CL = better fit). Per **CC‑G0‑Φ** and the Trust & Assurance skeleton, penalty tables are monotone **decreasing** in their CL ladders (if `CL1 < CL2` then `Φ(CL1) ≥ Φ(CL2)`, analogously for `Ψ` and `Φ_plane`) and bounded so that `R_eff` remains within `[0,1]` after clipping. Penalty magnitudes are not required to lie in `[0,1]` (tables may exceed 1 to force `R_eff → 0` under the subtractive default); what matters is monotonicity, boundedness, and published policy identifiers.\n\nDefine:\n\n`R_eff(P) = clip_0^1( Π(R_raw(P); Φ(CL_min(P)), Ψ(CL^k_min(P)), Φ_plane(CL^plane_min(P))) )`\n\nwhere each `*_min(P)` is the **lowest** congruence level encountered on the entailment spine of `P` for that dimension (a bottleneck; no averages), and `clip_0^1(x)` truncates to `[0,1]`.\n\n**Default (safe) instantiation (subtractive).**\nWhen policies are expressed as subtractive penalties, a safe default is:\n\n`R_eff(P) = max(0, R_raw(P) − Φ(CL_min(P)) − Ψ(CL^k_min(P)) − Φ_plane(CL^plane_min(P)) )`\n\nThis generalises the B.3 skeleton to multiple congruence ladders (scope vs kind vs plane) without introducing new axes. If a dimension is not present on the path, its penalty term is treated as neutral (`0` in the subtractive default).\n\n**Provisional marking.**\nDefault admissibility thresholds for reuse are set by Bridge calibration profiles (e.g., G.7). Typically, `CL=1` requires an explicit waiver to proceed and `CL=0` is inadmissible; this pattern only specifies that such thresholds gate transport before any numeric penalty is meaningful.\n\n#### C.2.2:4.5.A - Math-by-level gating (B.1.3:4.3)\n\n* **[M‑0/M‑1]** allow **ordinal** comparisons only (no arithmetic on `R_eff`); Φ/Ψ/Φ_plane may be qualitative (“low/med/high”). Publish evidence links + lane tags.\n* **[M‑2/L1]** numeric `R_eff` requires referencing numeric, table-backed policy identifiers for Φ/Ψ/Φ_plane (and Π if not default), plus reproducibility tags for empirical legs; otherwise treat the claim as [M‑1] semantics.\n\n#### C.2.2:4.6 - Evidence lanes are not new axes\n\nKD‑CAL does not add new global coordinates beyond F–G–R. Instead, it requires that reliability be *explainable* via **assurance lanes** (B.3.3):\n\n* **TA** (Typing assurance): semantic/type alignment sufficient for transport and composition.\n* **VA** (Verification assurance): logical/algorithmic checking, proof, model checking, static guarantees.\n* **LA** (Validation assurance): empirical adequacy under declared conditions, tests, benchmarks, telemetry.\n\nLane reporting is how KD‑CAL supports the common research distinction between logical soundness and empirical adequacy **without introducing new global axes**.\nLanes remain **separable** in SCR/Notes; they are not averaged into a “single tradition score”.\n\n#### C.2.2:4.7 - Scope operations are kind-safe (and use the ClaimScope algebra)\n\nReliability is meaningless if scope operations are applied to ill-typed entities.\n\n**Well-formedness constraint WFC‑C2.2‑1 (Type before scope).**\nLet `G1` and `G2` be claim scopes associated to described entities of kinds `K1` and `K2`. A scope operation that combines them (e.g., `G1 ∩ G2` for serial intersection, `SpanUnion({G_i})` for parallel coverage, or `translate(Bridge, G)` for cross‑context reuse) is defined only if:\n* `K1 = K2`, or\n* (same `U.BoundedContext`) `K1 ⊑ K2` or `K2 ⊑ K1` (an explicit kind relation/cast is named), or\n* (cross‑Context) there exists a declared **KindBridge** relating `K1` and `K2` with an explicit `CL^k` (C.3).\n\nThis constraint prevents “type-by-scope” anti-patterns where scope manipulation is used to hide type mismatch.\n\n#### C.2.2:4.8 - Minimal authoring recipe\n\nA minimal, conforming KD‑CAL authoring flow for reliability is:\n\n1. **Fix the typed claim.** State the claim as a typed proposition about a described entity (Kind‑CAL, C.3).\n2. **Declare claim scope.** Write `G` explicitly using A.2.6 operators; avoid scope-by-wording.\n3. **Declare stance carriers.** Declare `K=U.BoundedContext`, `S ∈ {design, run}`, and (where relevant on Working‑Model surfaces) `validationMode ∈ {postulate, inferential, axiomatic}`; declare `ReferencePlane` if crossings are in play.\n4. **Bind evidence.** Attach evidence stubs and lane tags (TA/VA/LA) and validity windows / decay policy where applicable (B.3.3, B.3.4).\n5. **Choose Γ-mode.** Declare whether the support is **series** (required) or **parallel** (independent lines to the same claim).\n6. **Compute R_raw.** Use the weakest-link fold on the entailment spine; for parallel support, use `max` only with an explicit independence note.\n7. **Declare bridges on reuse.** If you reuse across contexts/kinds/planes/notations, declare the bridge(s) (including NotationBridge where applicable) and their CLs.\n   Cross‑Context reuse is conformant only when an explicit Bridge is declared; CL admissibility rules apply (waiver or forbid) before any numeric penalty is meaningful (see **CC‑C.2.2‑4**).\n   **Reuse note (FPF discipline).** When this section refers to “reuse/portability across contexts/planes”, interpret it as Bridge-only reuse per §4.4: e.g., Bridge `Bridge#MatLab_to_PlantB` with `CL=2` and an explicit loss note, applying policy ids `Φ=Φ_v1` (and, where applicable, `Ψ=Ψ_v2`, `Φ_plane=Φ_plane_v1`) to reduce `R_eff` only.\n\n8. **Compute R_eff.** Apply the declared penalty policies into `R` (never into `F` or `G`), and publish `⟨F,G,R_eff⟩` with traceable references and policy identifiers.\n\nA reliable claim is not a loud claim; it is a claim that can be *carried*.\n\n#### C.2.2:4.8.A - Authoring template: Path summary row (copy/paste)\n\nWhen publishing `R_eff` for a claim, authors SHOULD include a compact, claim-local **path summary**. This is intentionally shaped so it can be turned into tooling later (EvidenceGraph/PathId in G.6) without introducing new Core types or face-kinds.\n\n| PathId | Entailment spine (required supports) | CL_min | CL^k_min | CL^plane_min | Policy-id(s) (Φ / Ψ / Φ_plane) | R_raw | R_eff | Lane tags (TA/VA/LA) | valid_until |\n| ------ | ----------------------------------- | ------ | -------- | ----------- | ------------------------------ | ----- | ----- | --------------------- | ---------- |\n| P‑1    | `c ← {c_a, c_b, c_c}`               | 2      | 3        | —           | `Φ=Φ_v1`, `Ψ=Ψ_v2`             | 0.82  | 0.67  | {TA, LA}              | 2026‑09‑30 |\n\nNotes:\n* `CL_*_min` values are **bottlenecks** on the relevant path/dimension (no averaging).\n* `valid_until` is the **earliest** expiry across empirical legs (or `—` / “fenced to TheoryVersion” for non-decaying proof legs).\n* If you publish multiple admissible paths, include multiple rows and cite which PathId(s) your decision/guard consumed.\n",
        "archetypal_grounding": "### C.2.2:5 - Archetypal Grounding\n\nInformative; non-binding.\n\n#### C.2.2:5.1 - System illustration\n\n**System.** A brake controller `S` has a claim:\n\n> `c1:` “For road friction μ ∈ [0.2, 0.9] and vehicle mass m ∈ [900, 2200] kg, wheel slip stays in [0.05, 0.25] under ABS control.”\n\n* `F(c1)=F5` because the controller and constraints are expressed as a machine-checkable model plus executable test harness (C.2.3).\n* `G(c1)` is the declared operating envelope (A.2.6) as a product set in `(μ, m, speed, tire)` space.\n* Evidence:\n\n  * VA: model-checking of a simplified plant/controller model (strong, but only for the simplified plant).\n  * LA: HIL simulation + track tests under sampled conditions with recorded telemetry windows (freshness required).\n  * TA: typed alignment between “μ” in simulations, “μ” in the estimation pipeline, and “μ” inferred from real-world sensors.\n\nIf telemetry is reused from the track context to the road context, a scope bridge is declared with `CL=2`. Using the default monotone penalty table (B.3), the LA contribution is reduced, and the derived `R_eff(c1)` drops accordingly. The claim’s envelope `G(c1)` does not change; only the warrant for transporting the evidence does.\n\n#### C.2.2:5.2 - Episteme illustration\n\n**Episteme.** A paper asserts two claims about an algorithm `A`:\n\n* `c2:` “A terminates for all inputs in domain D.” (axiomatic / proof-carrying)\n* `c3:` “A achieves ≥ 0.92 F1 on dataset family F under deployment preprocessing P.” (empirical)\n\n`c2` can achieve high VA with a proof artifact; its LA lane may be N/A, but its TA lane remains relevant because the intended meaning of “domain D” must align with the implementation’s input model.\n`c3` requires LA evidence and a freshness/shift policy because dataset and preprocessing drift change the scope and the warrant. If `c3` is reused from a lab dataset context to a production context, a bridge with explicit CL is required, and `R_eff` is reduced until new in-context evidence is attached.\n",
        "bias_annotation": "### C.2.2:6 - Bias-Annotation\n\nInformative; non-binding.\n\nLenses tested: **Gov**, **Arch**, **Onto/Epist**, **Prag**, **Did**. Scope: **Universal**.\n\n* **Onto/Epist bias:** High formality is often mistaken for high warrant (“proof therefore true in the world”). This pattern mitigates by forcing LA/TA visibility and by routing transport loss into R rather than mutating the claim.\n* **Prag bias:** Teams may Goodhart R by narrowing scope or selecting easy tests. This pattern mitigates by requiring explicit scope declaration and by making scope changes first-class (A.2.6).\n* **Gov bias:** Overconfident reuse across contexts is a recurring failure mode in governance settings. This pattern mitigates by forcing explicit bridges and penalties for reuse.\n* **Did bias:** A single scalar is seductive; it hides what kind of warrant exists. Lane reporting keeps the scalar honest.\n",
        "conformance_checklist": "### C.2.2:7 - Conformance Checklist\n\nNormative.\n\n| ID                                            | Requirement                                                                                                                                                                                                                 | Purpose                                                                       |\n| --------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------- |\n| **CC‑C.2.2‑1 (Triad publication).**           | Authors of a KD‑CAL location **SHALL** publish `⟨F,G,R_eff⟩` as a bundle for a specific claim, rather than publishing `R` alone.                                                                                            | Prevents decontextualised confidence scores.                                  |\n| **CC‑C.2.2‑2 (R-only penalty routing).**      | A conforming implementation of KD‑CAL transport **SHALL** satisfy **INV‑C2.2‑1**.                                                                                                                                           | Ensures bridges reduce warrant without silently mutating expression or scope. |\n| **CC‑C.2.2‑3 (Weakest-link fold).**           | A conforming implementation of KD‑CAL reliability propagation **SHALL** use **DEF‑C2.2‑3** as the default for required supports, unless an alternative Γ‑fold is explicitly declared and remains monotone and conservative. | Prevents confidence laundering through aggregation.                           |\n| **CC‑C.2.2‑4 (Bridge visibility for reuse).** | Authors **SHALL** declare explicit bridges with CL values for any cross-context, cross-kind, or cross-plane reuse that affects `R_eff`.                                                                                     | Makes transport loss auditable and machine-checkable.                         |\n| **CC‑C.2.2‑5 (Penalty policy visibility).**   | Authors or tooling **SHALL** reference the active policy identifiers used for `Φ`, `Ψ`, `Φ_plane` **and** the penalty aggregation rule `Π` (if not the default) when computing `R_eff`.                                   | Ensures repeatability and prevents hidden policy drift.                       |\n| **CC‑C.2.2‑6 (Type before scope).**           | Authors and validators **SHALL** enforce **WFC‑C2.2‑1** for scope composition operations.                                                                                                                                   | Prevents ill-typed scope algebra from creating incoherent reliability claims. |\n| **CC‑C.2.2‑7 (Evidence binding).**            | Authors **SHALL** bind any asserted `R_eff` to evidence references that enable TA/VA/LA inspection, consistent with the assurance lane discipline (B.3.3) and evidence decay discipline (B.3.4).                            | Keeps R grounded and updateable.                                              |\n| **CC‑C.2.2‑8 (No ordinal arithmetic).**       | Validators **SHALL** reject any computation that treats `F` or `CL` as if they were ratio-scale numbers (e.g., averaging, subtraction), except where explicitly permitted as a policy-defined penalty function on `R`. Validators **SHALL** also reject arithmetic over `R_eff` when it is published as an **ordinal proxy** ([M‑0/M‑1]). | Enforces CSLC legality and prevents silent scalarisation.                     |\n| **CC‑C.2.2‑9 (Stance carriers declared).**    | Authors **SHALL** declare `U.BoundedContext K`, `S ∈ {design, run}`, and (where applicable) `ReferencePlane` and `validationMode`, and **SHALL NOT** merge design- and run-time assurance into one score.                 | Prevents design/run chimera and makes interpretation auditable.              |\n| **CC‑C.2.2‑10 (Parallel requires independence).** | Authors **SHALL** treat `max`-composition of support paths as admissible **only** when an explicit independence justification is recorded; otherwise supports are treated as one entangled line and remain weakest-link. | Prevents confidence inflation by double-counting correlated evidence.         |\n",
        "anti_patterns": "### C.2.2:8 - Common Anti-Patterns and How to Avoid Them\n\nInformative; non-binding.\n\n| Anti-pattern               | Symptom                                                                                       | Why it fails                                                     | How to avoid / repair                                                                                    |\n| -------------------------- | --------------------------------------------------------------------------------------------- | ---------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------- |\n| **Averaging assurance**    | A mean/weighted sum of `R` values is reported as “confidence”.                               | It violates WLNK and is usually illegal scale arithmetic.        | Use weakest-link `min` on the entailment spine, then apply congruence penalties into `R` only.          |\n| **Truth-by-score**         | `R=0.9` is treated as “the claim is true.”                                                    | R is warrant strength, not ontological truth.                    | Require explicit evidence links and scope; treat R as decision warrant only.                             |\n| **Scope laundering**       | The claim’s applicability grows by wording changes while `G` is unchanged.                    | It silently widens scope, making comparisons meaningless.        | Use A.2.6 operators and treat scope changes as explicit revisions.                                       |\n| **Bridge laundering**      | A claim is reused in a new context without a bridge, and R is carried over unchanged.         | It hides semantic loss and encourages overconfident reuse.       | Declare bridges with CL and recompute `R_eff` using penalties.                                           |\n| **Design/run chimera**     | Design-time proofs and run-time telemetry are mixed as if they were the same evidence object. | Evidence belongs to different stances and decays differently.    | Separate lanes and validity windows; treat crossings explicitly.                                         |\n| **Ordinal arithmetic**     | CL or F levels are averaged to produce a pseudo-score.                                        | It violates scale legality and produces non-auditable numbers.   | Keep CL/F ordinal; convert only via declared penalty tables on R.                                        |\n| **Many-weak-makes-strong** | Numerous low-quality supports are combined to inflate confidence.                             | It violates the weakest-link intent of conservative propagation. | Default to `min` for required supports; allow `max` only with explicit independence arguments.          |\n",
        "consequences": "### C.2.2:9 - Consequences\n\nInformative; non-binding.\n\n| Benefits                                                                                                     | Trade-offs and mitigations                                                                                                                         |\n| ------------------------------------------------------------------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **Comparability.** Different claims can be compared in a disciplined way when F and G are explicit.          | **Conservatism.** Weakest-link propagation can feel pessimistic; mitigate by making support structure explicit and improving the weakest evidence. |\n| **Auditability.** Transport loss is visible and localised to R.                                              | **Overhead.** Declaring bridges and evidence links is work; mitigate with templates and reuse of standard lane schemas.                            |\n| **Upgradeable knowledge.** R can improve incrementally as evidence accumulates, without rewriting the claim. | **Scalar temptation.** People still want one number; mitigate by requiring lane breakdown visibility behind the number.                            |\n",
        "rationale": "### C.2.2:10 - Rationale\n\nA triad only works if each coordinate has a single job.\n\n* **G carries entitlement.** It states where the claim is asserted to apply. If G is implicit, teams argue about “what was meant” instead of updating scope.\n* **F carries checkability.** It states how much the claim’s form supports mechanised scrutiny and reuse. If F is conflated with R, formalisation becomes a rhetorical weapon.\n* **R carries warrant.** It states how much evidence supports relying on the claim under G. If R is not conservative, weak supports can be laundered into strong confidence.\n\nRouting congruence loss into **R only** prevents a subtle but pervasive failure mode: transport across contexts/kinds/planes does not silently rewrite the claim; it only reduces how confidently we should carry it.\n\nWeakest-link propagation is chosen because it is the simplest rule that is monotone, conservative, and auditable. When better combination rules exist, they can be introduced as explicit Γ‑policies, but the default must be safe.\n",
        "sota_echoing": "### C.2.2:11 - SoTA-Echoing\n\nNormative.\n\n**SoTA pack binding note.** If a SoTA Synthesis Pack exists for KD‑CAL reliability / cross‑context warrant transport in your Context (G.2), cite its ClaimSheet IDs / CorpusLedger entries / BridgeMatrix rows here. Otherwise, record `SoTA-Pack: TBD/none` and treat this section as the seed (do not fork it silently elsewhere).\n\n| Practice claim                                                                                                      | Post‑2015 source anchor                                                                   | Alignment to this pattern                                                                                                                                                           | Adoption status                                                                                                      |\n| ------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------- |\n| Verification and validation should be distinguished and tied to evidence quality, not to rhetoric.                  | ASME V&V 40‑2018 (model credibility assessment).                                          | This pattern separates VA and LA lanes and binds `R_eff` to evidence and declared scope rather than to narrative confidence.                                                        | **Adopt**, with KD‑CAL’s conservative fold as an explicit default.                                                   |\n| Trustworthiness is context- and risk-dependent and requires explicit documentation of limits.                       | NIST AI Risk Management Framework 1.0 (2023).                                             | This pattern makes limits first-class via `G` and makes reuse loss explicit via CL penalties rather than informal caveats.                                                          | **Adapt**, because FPF treats transport loss as an epistemic penalty, not as a purely organisational risk statement. |\n| Safety arguments should make claims, evidence, and assumptions explicit and reviewable.                             | UL 4600 (2020) and related assurance-case practice in autonomous systems.                 | This pattern treats `R` as an auditable warrant signal whose inputs are explicit evidence items and whose reuse requires explicit transport justification.                          | **Adopt**, while remaining notation-independent and avoiding tool mandates.                                          |\n| Empirical results should be accompanied by structured provenance and usage conditions to enable reuse and critique. | “Datasheets for Datasets” (Gebru et al., 2018) and “Model Cards” (Mitchell et al., 2019). | This pattern’s scope discipline and lane reporting make empirical warrant portable only when its conditions are explicit; cross‑Context reuse is Bridge-only (e.g., `Bridge#MatLab_to_PlantB`, `CL=2`, `Φ=Φ_v1`), and congruence loss routes to `R_eff` only. | **Adopt**, with congruence penalties as the reuse control mechanism.                                                 |\n| Reproducibility requires packaging evidence and making it re-checkable by others.                                   | ACM Artifact Review and Badging (updated practices post‑2015) and The Turing Way (2019).  | This pattern treats evidence as something that can be inspected across TA/VA/LA lanes and allows reliability to decay when evidence becomes stale or non-replayable.                | **Adapt**, because FPF treats decay and transport penalties as first-class calculus elements.                        |\n| Strong inference benefits from “severe tests” rather than from accumulation of weak confirmations.                  | Mayo (2018) on severity in statistical inference.                                         | Weakest-link propagation and explicit scope declarations discourage superficial confirmation piling and encourage explicit, discriminating evidence.                                | **Adapt**, because KD‑CAL is agnostic to frequentist vs Bayesian inference but requires auditability.                |\n",
        "relations": "### C.2.2:12 - Relations\n\n**Builds on:** C.2 (KD‑CAL overview), A.2.6 (Claim scope and operators), C.2.3 (Formality F), B.3 (Trust & Assurance calculus), B.1.3 (Γ‑fold patterns), B.3.3 (assurance lanes), B.3.4 (refresh/decay), C.3 (Kind‑CAL and kind bridges), F.9 (Bridges & CL), G.6 (EvidenceGraph PathId discipline), G.7 (Bridge calibration / admissibility thresholds).\n**Coordinates with:** C.16 (MM‑CHR evidence discipline), E.14 (working-model assertions), E.18/A.27 (crossing surfaces), C.25 (Q‑Bundle, for avoiding confusion between epistemic reliability and system reliability).\n**Used by:** C.3.3 (cross-kind reuse discipline), guard macro bundles in C.3.A and C.21, and any acceptance/gating logic that consumes `R_eff` while preserving `F` and `G`.\n**Clarifies:** The KD‑CAL meaning of reliability implicit in C.2:4.1 and the transport clauses referenced across B.3 and C.3.\n",
        "c.2.2:end": "### C.2.2:End\n\n"
      },
      "content": "### C.2.2:End\n\n",
      "metadata": {},
      "part": "C",
      "cluster": null
    },
    {
      "id": "C.2.3",
      "title": "Unified Formality Characteristic F",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## C.2.3 - Unified Formality Characteristic F\n\n> **One‑line summary.** Defines **Formality (F)** as a single, ordinal **Characteristic** (`U.Formality`) with **polarity “up”**, anchored by a **default ladder F0…F9** from **free prose** to **proof‑grade foundations**. This unifies how rigor is declared and compared across all epistemes and contexts, and supplies the **F‑coordinate** in the F–G–R assurance space.\n\n**Status.** Normative pattern in **KD‑CAL / Part C.2**. It **replaces** the legacy “modes/tiers” language and any parallel “formality ladders.” The letter **F** hereafter denotes the **Formality** characteristic in the **F–G–R** triple.\n\n**Scope.** Conceptual only. The pattern **does not** prescribe workflows, toolchains, or team procedures. It specifies *what Formality is and how to measure/declare it*, so that any team, discipline, or architheory can think and communicate rigor with the same yardstick.\n\n**Non‑goals.**\n– Not a publication process, not a governance gate.\n– Not a reliability metric (R) and not a scope/abstraction metric (G).\n– Not tied to any notation, repository layout, or CI/CD practice.\n\n",
        "c.2.3:1___context": "### C.2.3:1 - Context\n\nTransdisciplinary work (physics, software, systems, policy, data) needs a **shared notion of rigor** that travels across context of meaning. A controller invariant stated in a theorem prover, a research hypothesis framed in constrained English, and a managerial decision rule written as acceptance criteria must be **comparable**—not by their domain lore, but by **how strictly they are expressed**.\n\nHistorically, FPF texts carried **multiple signals of rigor** (narrative “modes,” editorial tiers, ad‑hoc “formal vs. informal” talk). These signals mixed with status labels (e.g., “Draft/Effective”), obscuring whether an “approved” artifact was **actually precise** or merely **organizationally accepted**. To reason soundly in KD‑CAL and to compose artifacts safely, we standardize a **single Formality characteristic F**:\n\n* **Portable:** works for math, code, models, requirements, policies.\n* **Ordinal & minimal:** few clear anchors from “sketch” to “foundations.”\n* **Composable:** participates in the F–G–R calculus and weak‑link invariants.\n* **Context‑extensible:** Contexts may introduce **intermediate anchors** without breaking comparability.\n\n",
        "problem": "### C.2.3:2 - Problem\n\nAbsent a unified **F**:\n\n1. **Rigor whiplash.** Either everything is forced into premature formalism (blocking exploration), or informal artifacts drift into high‑assurance use (creating silent risks).\n2. **Incomparability.** Each Context’s labels mean different things. Reviewers, integrators, and auditors cannot align expectations or compute trustworthy composites.\n3. **Lost continuity.** Moving from sketch to proof often becomes a **rewrite**, severing provenance; the same idea looks like different artifacts at each “mode,” inviting translation errors.\n4. **Confused roles.** Status (e.g., “accepted here”) gets conflated with rigor (“precise enough”), undermining governance and the KD‑CAL trust math.\n\n",
        "forces": "### C.2.3:3 - Forces\n\n| Force                                             | Tension to resolve                                                                                                                             |\n| ------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------- |\n| **Human ↔ Formal system**                         | Natural language is fast and legible; formal systems are unambiguous and checkable. We need a spectrum, not a cliff.                           |\n| **Local freedom ↔ Global comparability**          | Contexts must be free to set thresholds; cross‑context reasoning requires a shared scale and anchors.                                          |\n| **Readability ↔ Precision**                       | Rich narrative aids understanding; tight syntax prevents misinterpretation. The characteristic must not force one at the expense of the other. |\n| **Open‑world thinking ↔ Closed‑world guarantees** | Exploration benefits from openness; certification needs explicit closure. F must support gradual “closing” without renaming the artifact.      |\n\n",
        "solution": "### C.2.3:4 - Solution — The **Formality Characteristic F**\n\n#### C.2.3:4.1 - Identity and Type (MM‑CHR)\n\n* **Name:** `U.Formality` (nicknamed **F** in F–G–R).\n* **Type:** `U.Characteristic`.\n* **Scale:** **ordinal** (no arithmetic; comparisons and thresholds only).\n* **Polarity:** **up** (higher ⇒ more strictly and unambiguously expressed).\n* **Unit:** **formality step** (qualitative anchor).\n* **Value domain:** default anchors **F0…F9** (see §4.4).\n* **Carrier:** any `U.Episteme` (claim/theory/spec/model/policy/etc.).\n* **Notation‑agnostic:** the same F semantics apply regardless of symbol system; bridges between notations do **not** change F (they may affect R via CL, see C.2.2).\n\n**Normative reading.** “F = k” states *how strictly the content is expressed*, not whether it is true (R) nor how broadly it applies (G).\n\n\n#### C.2.3:4.2 - Relationship to KD‑CAL (F–G–R)\n\n* **F in the triple.** F is the **Formality coordinate** in the F–G–R assurance space. It influences trust **indirectly**: higher F reduces ambiguity, enabling stronger evidence and safer composition, but **does not** substitute for evidence (R) or scope (G).\n* **Composition invariant (weakest‑link).** For any composite episteme,\n  **F\\_composite = min(F\\_parts on support paths)**.\n  *Rationale:* the formal rigor of a whole cannot exceed its least‑formal essential part.\n* **Orthogonality.** Changing **G** (envelope/scope) or **R** (evidence) does not, by itself, change **F**; conversely, raising **F** does not imply broader G or higher R.\n\n\n#### C.2.3:4.3 - Extensibility and Local Anchors\n\nFPF provides **default anchors F0…F9** (next subsection). **Contexts MAY**:\n\n* introduce **intermediate anchors** (e.g., F6.5) or **named sub‑anchors** (e.g., “F4‑OCL” vs “F4‑TLA‑constraints”),\n* publish **domain exemplars** for anchors,\n* define **thresholds** (e.g., “claims of type X must be F≥7”).\n\n**Constraints (normative):**\n\n* **Monotonic order is preserved.** New anchors **MUST NOT** invert or blur the ordering.\n* **Anchor meaning is conserved.** Local elaborations **SHALL** map to the nearest global anchor without shifting global semantics (e.g., anything called “F8.x” remains **proof‑grade**).\n* **No proxy scales.** Do **not** invent alternative “formality modes/tiers” as surrogates; use **F** explicitly.\n\n\n#### C.2.3:4.4 - Default **F0…F9** Anchors (overview)\n\n> *Full anchor definitions with cross‑disciplinary examples appear in §5 (next part). Below is the overview for orientation.*\n\n* **F0 — Unstructured prose.** Free narrative; ambiguous; human interpretation only.\n* **F1 — Scoped notes.** Informal but term‑consistent scope; clearer than F0.\n* **F2 — Structured outline.** Template present; coherent sections; criteria mostly “TBD”.\n* **F3 — Controlled narrative.** Complete template; constraints sketched in constrained NL or pseudo‑formal phrasing.\n* **F4 — First‑order constraints.** Explicit invariants/properties expressible at ≈FOL level (checkable conditions exist).\n* **F5 — Executable math/algorithmics.** Precisely defined computational semantics; outcomes checkable by execution/simulation.\n* **F6 — Hybrid formalism.** Mixed discrete/continuous methods; model‑checking or equivalent obligations identified.\n* **F7 — Higher‑order verified.** Core claims encoded and checked in HOL‑style systems.\n* **F8 — Dependent/constructive proofs.** Proof‑carrying content (programs‑as‑proofs).\n* **F9 — Univalent/higher foundations.** Equality‑as‑structure; frontier‑grade formal foundations.\n\n**Intent of anchors.** They form a **gentle gradient** from “thinker‑friendly” (F0–F3) through “formalizable” (F4–F6) to **proof‑grade** (F7–F9), allowing the **same artifact** to climb without renaming or forking.\n\n\n#### C.2.3:4.5 - Usage Obligations (declaration, not governance)\n\n* **Declare F.** Every normative episteme **SHALL** declare its **F** (one value) in its context. There is **no default**.\n* **Use F in reasoning.** Any comparison, composition, or alignment that depends on rigor **SHOULD** reference **F** explicitly rather than implicit labels like “draft/final.”\n* **Do not conflate F with status.** Status systems (ESG/RSG) may **refer** to F in their guards, but **F ≠ status**. This pattern defines **what** rigor is, not **when** a Context should require it.\n\n",
        "c.2.3:5___canonical_anchors_**f0…f9**_(normative)": "### C.2.3:5 - Canonical Anchors **F0…F9** (normative)\n\n> **How to read this section.** Each anchor defines *what is minimally true* of an episteme to be rated at that level — across disciplines. The anchors are **ordinal**: F7 is strictly more formal than F6, etc. Levels are **about expression**, not truth; Reliability (R) and ClaimScope (G) are separate.\n\nFor every anchor we state **Definition**, **Inclusion criteria**, **Non‑examples** (to prevent over‑rating), and **Indicative artifacts** (cross‑disciplinary, post‑2015).\n\n\n#### C.2.3:5.1 - **F0 — Unstructured Prose**\n\n**Definition.** Free natural language; ambiguous; unstated assumptions; no required sections; meaning depends on reader context.\n**Inclusion criteria.** Narrative exists but lacks stable structure; terms may shift meaning; no explicit acceptance/denial conditions.\n**Non‑examples.** Any document with a consistent outline and stable vocabulary is at least F1.\n**Indicative artifacts.** Whiteboard photos; impromptu email threads; notes from a hallway discussion; an ad‑hoc wiki page with mixed jargon.\n\n\n#### C.2.3:5.2 - **F1 — Scoped Notes**\n\n**Definition.** Informal narrative with a **consistent scope** and **stable terms**; some headings; the central claim/problem is bounded.\n**Inclusion criteria.** Key terms are used consistently; scope is named (e.g., “for single‑node scheduling”); still no explicit criteria.\n**Non‑examples.** If each requirement already names a check or scenario, that is F2+.\n**Indicative artifacts.** A design note that consistently uses the same nouns/verbs and states “this applies to v2 of the service”; a lab memo defining a focus population.\n\n\n#### C.2.3:5.3 - **F2 — Structured Outline**\n\n**Definition.** A **complete template** (Context/Problem/Forces/Solution/…) is populated; content is coherent end‑to‑end; criteria are mostly placeholders.\n**Inclusion criteria.** All expected sections exist; cross‑references are consistent; open items are marked (e.g., “TBD acceptance”).\n**Non‑examples.** If acceptance criteria are explicit per claim, that is F3+.\n**Indicative artifacts.** A draft pattern/spec with fully populated sections but qualitative language; an experiment plan with all slots filled yet non‑operational metrics.\n\n\n#### C.2.3:5.4 - **F3 — Controlled Narrative**\n\n**Definition.** Narrative remains human‑readable but uses **constrained phrasing**; each claim has a **clear, singular interpretation**.\n**Inclusion criteria.** Use of controlled NL or disciplined templates (e.g., “shall/if/then”); per‑claim **acceptance statements** exist in prose.\n**Non‑examples.** If properties are encoded as logical constraints or typeable Standards, that is F4+.\n**Indicative artifacts.** Requirements written in Attempto‑style controlled English; decision rules with explicit pre‑/post‑conditions phrased in a fixed schema.\n\n\n#### C.2.3:5.5 - **F4 — First‑Order Constraints**\n\n**Definition.** Key claims are expressible at **≈ first‑order logic** (FOL) granularity; invariants/constraints are **explicit and checkable in principle**.\n**Inclusion criteria.** Each critical statement can be rendered as a predicate over well‑typed variables; conflict/consistency checks are conceivable.\n**Non‑examples.** Bare unit tests or executable code without stated invariants is not automatically F4.\n**Indicative artifacts.** TLA+ or OCL constraints on a model; an API spec where pre/postconditions and invariants are written as logic‑like rules; well‑typed schema constraints with quantification over entities.\n\n\n#### C.2.3:5.6 - **F5 — Executable Math / Algorithmics**\n\n**Definition.** Content has **precise execution semantics**; results can be checked by **running** (simulation or computation).\n**Inclusion criteria.** A model is encoded so that outcomes are deterministic (modulo declared randomness); simulations/tests demonstrate the claims’ executable shape.\n**Non‑examples.** “It runs” without a statement of what is guaranteed is not enough; opaque notebooks with side effects but no declared semantics stay F3–F4.\n**Indicative artifacts.** Differential‑equation models in code; a reference implementation with clear Standard comments linked to tests; an ML training recipe where the algorithmic pipeline and metrics are fully explicit (yet not proven).\n\n\n#### C.2.3:5.7 - **F6 — Hybrid Formalism**\n\n**Definition.** Combination of **discrete and continuous** reasoning or multiple formal layers; **model‑checking obligations** or equivalent are identified and traceable.\n**Inclusion criteria.** Hybrid claims (e.g., controller + plant) are spelled out with both sides’ formalisms and the glue; property checks are specified.\n**Non‑examples.** A prose description of cyber‑physical behavior without model obligations is ≤F5.\n**Indicative artifacts.** Safety envelopes for autonomous motion expressed as state‑space invariants plus controller logic; hybrid automata with stated safety properties; Standards linking simulation to discrete decisions.\n\n\n#### C.2.3:5.8 - **F7 — Higher‑Order Verified**\n\n**Definition.** Core claims are encoded in a **higher‑order logic (HOL)** or equivalent, and **machine‑checked**; proof scripts or structured proofs exist.\n**Inclusion criteria.** The kernel/tool verifies each inference step; failing changes break proofs.\n**Non‑examples.** A hand proof attached to F4 constraints without machine checking remains F4–F5.\n**Indicative artifacts.** A theorem in Isabelle/HOL or HOL‑Light proving a protocol invariant; a verified algebraic property of a cryptographic scheme.\n\n\n#### C.2.3:5.9 - **F8 — Dependent / Constructive Proofs**\n\n**Definition.** **Programs‑as‑proofs** (Curry–Howard) or **dependent type** artifacts; proof terms are part of the artifact; compilation/type‑check is verification.\n**Inclusion criteria.** Types capture the property; changing the property changes the type and breaks the build.\n**Non‑examples.** A typed program whose types do not encode the critical property is ≤F5.\n**Indicative artifacts.** A Coq/Lean implementation whose type encodes sortedness/safety; a certified compiler pass with proof objects maintained by the build.\n\n\n#### C.2.3:5.10 - **F9 — Univalent / Higher Foundations**\n\n**Definition.** Frontier‑grade **higher foundations** (e.g., homotopy type theory / univalence); equality is treated as **structure**; proofs live at that level.\n**Inclusion criteria.** Equivalences are recognized as identities by construction; properties rely on higher equalities.\n**Non‑examples.** Any proof that does not hinge on higher‑dimensional equality is ≤F8.\n**Indicative artifacts.** Formal developments where isomorphic structures are path‑equal by univalence; higher‑inductive types used to encode core invariants.\n\n\n#### C.2.3:5.11 - Cross‑anchor cautions (normative)\n\n* **Execution ≠ Proof.** Running code/examples (F5) is not a proof (F7+) unless proof obligations are explicitly encoded and checked.\n* **Schema ≠ Semantics.** Parseable schemas (F2) are not logical constraints (F4) without semantic predicates.\n* **Labels ≠ Levels.** “Approved,” “Final,” or “Published” are **status labels** and have no bearing on F unless they explicitly bind to these anchors.\n\n",
        "c.2.3:6___assigning_**f**_in_practice_(guidance)": "### C.2.3:6 - Assigning **F** in Practice (guidance)\n\nThis section is **informative**. It offers practical heuristics so engineers‑managers can triage artifacts quickly and consistently.\n\n#### C.2.3:6.1 - Three questions to place a first guess\n\n1. **Can a competent reader misread the claim?**\n   If yes, you are likely ≤F2. If no (unique reading by construction), you are ≥F3.\n2. **Are constraints stated as predicates over typed things?**\n   If yes, you are around **F4**; if they are only executable tests without predicates, you’re **F5**.\n3. **Would a tool *reject* an incorrect change?**\n   If “only by rerunning examples,” that’s **F5**; if “because the logic kernel/type checker refuses it,” that’s **F7–F8**.\n\n#### C.2.3:6.2 - Decision steps (quick rubric)\n\n* **Has complete template?** If not, **F0–F1**. If yes →\n* **Are per‑claim acceptances written (even informal)?** If not, **F2**. If yes →\n* **Are they predicate‑like (quantifiers, implies, forall/exists)?** If yes, **F4**; if no, **F3**.\n* **Is there an executable model with declared semantics?** If yes, **F5–F6** (hybrid if both discrete/continuous).\n* **Are core properties machine‑proved?** If yes, **F7**; if types carry the property, **F8**; if higher equivalence is essential, **F9**.\n\n#### C.2.3:6.3 - Litmus tests (do/don’t)\n\n* **Do** point to the **lowest** rigor segment that is essential to the artifact; **F is capped by the weakest required part**.\n* **Do** keep **F** independent from **R** and **G**: a well‑verified but informal hypothesis is **low F, high R**; a formal theorem without empirical content is **high F, R=N/A or VA‑lane only**.\n* **Don’t** “average” levels: a long F8 appendix does not make an F3 body F8; F sticks to the **claim** or the **episteme**, not to page counts.\n* **Don’t** upgrade F just because a tool was used; tooling matters only if the **content** reaches the anchor’s semantics.\n\n#### C.2.3:6.4 - Anti‑patterns\n\n* **Terminology inflation.** Calling acceptance criteria a “specification” without predicates → F3 at most.\n* **Notebook mirage.** Treating an executable notebook with hidden state as formal proof → remains F5 without explicit obligations.\n* **Schema worship.** Equating JSON Schema validity with logical safety → F2/F3, not F4.\n* **Proof‑by‑CI.** “The pipeline is green” is not a logic kernel; without proofs or dependent types, F≤F6.\n\n#### C.2.3:6.5 - Edge cases and how to rate them\n\n* **Generated docs from formal sources.** Rate **by the source**, not the rendered prose. If the source is F7 proofs, the generated PDF remains **F7** as long as it is a faithful view.\n* **Natural‑language with embedded formulas.** If formulas are illustrative only, keep **F3**; if they define obligations and are checkable, move **F4–F6** accordingly.\n* **Standards in code comments.** If they constrain behavior and are enforced (e.g., via runtime/type checks), consider **F4–F5**; otherwise **F3**.\n* **Hybrid ML systems.** The training procedure (executable) suggests **F5**; safety guards as formal constraints can raise parts to **F4/F6**; certified components may reach **F7/F8**.\n\n#### C.2.3:6.6 - Raising **F** (ΔF moves, informative)\n\nTypical **ΔF** steps (see KD‑CAL motion primitives):\n\n* **F2→F3:** Introduce controlled phrasing; per‑claim acceptances.\n* **F3→F4:** Recast acceptances as typed predicates/invariants.\n* **F4→F5:** Provide executable semantics with declared Standards.\n* **F5→F7:** Encode properties in a proof‑capable logic; prove core invariants.\n* **F7→F8/9:** Migrate property into types / adopt higher‑equality foundations.\n\n> **Note.** ΔF does not require changing **G** or **R**. Many projects raise F while holding scope and evidence constant, then tackle R (validation) separately.\n",
        "c.2.3:7___conformance_(normative)": "### C.2.3:7 - Conformance (normative)\n\nThis section defines what it means to **use F correctly** in KD‑CAL. All “**SHALL**/**MUST**/**SHOULD**/**MAY**” statements here are normative.\n\n#### C.2.3:7.1 - Declaration & Semantics\n\n* **CC‑F‑1 (Declaration).** Every normative `U.Episteme` **SHALL** declare exactly one value for `U.Formality` (**F ∈ {F0…F9}**, or a context‑defined sub‑anchor that maps to one of these).\n* **CC‑F‑2 (Ordinality).** F is an **ordinal Characteristic**: implementations **MUST NOT** perform arithmetic on F; only comparisons and thresholds are valid.\n* **CC‑F‑3 (Polarity).** The polarity of F is **up**: a larger F value denotes **strictly greater or equal** expressive rigor than a smaller one.\n* **CC‑F‑4 (No proxies).** Contexts **MUST NOT** introduce alternative “formality modes/tiers” as surrogates for F. If additional labels are desired, they **SHALL** be published as named **sub‑anchors** of F (see §4.3).\n\n#### C.2.3:7.2 - Locality, Extensibility, and Anchors\n\n* **CC‑F‑5 (Local extensibility).** A bounded context **MAY** introduce intermediate anchors (e.g., F6.5) and domain‑named anchors (e.g., “F4‑OCL”), **provided that** (a) the global F0…F9 order is preserved, and (b) each sub‑anchor is explicitly mapped to a parent anchor.\n* **CC‑F‑6 (Anchor conservation).** Sub‑anchors **SHALL NOT** redefine the global meaning of their parent anchor (e.g., anything under F8 remains **proof‑grade**).\n\n#### C.2.3:7.3 - Composition & Granularity\n\n* **CC‑F‑7 (Weakest‑link fold).** For any composite episteme (theory, spec, model), the effective Formality **F\\_composite** along any essential support path **SHALL** be computed as the **minimum** F of its essential parts on that path.\n* **CC‑F‑8 (Granularity rule).** If different parts of an episteme carry different F values, the **episteme‑level F** is the **minimum** over all **essential** parts (non‑essential/illustrative parts are excluded).\n* **CC‑F‑9 (No averaging).** Implementations **MUST NOT** average or otherwise combine F values numerically; the min rule suffices.\n\n#### C.2.3:7.4 - Orthogonality & Non‑Interference\n\n* **CC‑F‑10 (Orthogonality to G/R).** Changes in scope/envelope (G) or evidence (R) **SHALL NOT** alter F unless the **expression form** of the claims changes. Conversely, raising F **SHALL NOT** be interpreted as raising R or broadening G.\n* **CC‑F‑11 (Notation‑agnostic).** Changing notations or carriers (Symbol side) **does not** change F if the claim graph and its formal content are preserved. Any translation loss is accounted for by **CL** penalties in R, not by altering F.\n\n#### C.2.3:7.5 - Bridges & Cross‑Context Use\n\n* **CC‑F‑12 (Bridges keep F stable).** When a claim is used across bounded contexts via a Bridge, the original F value **SHALL** be preserved in attribution. If the receiving context requires a different expression form, it **MUST** produce a **new episteme** (with its own F).\n* **CC‑F‑13 (CL is for trust, not F).** Any mismatch across contexts **SHALL** be handled via Congruence Level (CL) and its effect on R; CL **MUST NOT** be used to down‑rate F.\n\n#### C.2.3:7.6 - Traceability & Change\n\n* **CC‑F‑14 (Observable basis).** An assigned F **SHALL** be justifiable by observable content (e.g., presence of predicates/invariants for F4; mechanized proofs for F7+).\n* **CC‑F‑15 (ΔF disclosure).** A **ΔF** move (raising or, if justified by discovered error, lowering F) **SHALL** be recorded as a content change to the episteme. Whether a context versions that change is outside this pattern’s scope.\n\n",
        "c.2.3:8___composition_&_interaction_(normative_+_informative_notes)": "### C.2.3:8 - Composition & Interaction (normative + informative notes)\n\n#### C.2.3:8.1 - Inside one episteme (normative)\n\n* **Essential paths.** Identify essential parts/claims that are required for the episteme’s truth. Apply **min‑F** along each support path; the **episteme‑level F** is the min over essential paths (CC‑F‑7, CC‑F‑8).\n* **Episteme‑about (ReferencePlane=episteme).** Descriptions about other claims/epistemes carry their **own** F and do **not** raise the target’s F; any cross‑plane penalty flows via **CL^plane → R**.\n\n> **Note (informative).** A long formal appendix (F8) attached to a largely narrative body (F3) does **not** make the whole F8; the episteme remains **F3** unless the core claims move into the formal appendix.\n\n#### C.2.3:8.2 - Relation to **G** (scope/envelope) (normative)\n\n* F concerns the **expression form** of the claim; G concerns its **claim scope**. Tightening the envelope without changing how the claim is expressed does not change F; re‑expressing the claim in a stricter form (e.g., predicates) can raise F without changing G.\n\n> **Caution (informative).** Raising F often **reveals** hidden assumptions, which may lead to a **ΔG** (narrower envelope). Treat this as a **separate** change: update G explicitly rather than smuggling scope changes under F.\n\n#### C.2.3:8.3 - Relation to **R** (evidence/assurance) (normative)\n\n* **F ≠ R.** Proof‑grade expression (F7+) still requires binding to appropriate assurance lanes (VA/LA/TA) in the trust calculus; empirical claims may have high R with low F if they remain informal.\n* **Decay independence.** F **does not decay** with time; R may decay (empirical freshness) or shift due to CL. Tool assurance (TA) is tracked independently of F.\n\n> **Note (informative).** Higher F typically **enables** stronger R (easier to test or prove), but no automatic relationship is assumed.\n\n#### C.2.3:8.4 - CL & Bridges (normative)\n\n* **CL effects.** Using content across context boundaries requires a Bridge with a CL rating. CL affects **R** (penalties) and **never** changes **F** (CC‑F‑12/13).\n* **Semantic change ⇒ new episteme.** If a cross‑context mapping **alters** the claim (e.g., coarsens predicates, drops obligations), treat it as a **new episteme** with its own F rather than “the same F with lower CL.”\n\n#### C.2.3:8.5 - Motion primitives (informative)\n\n* **ΔF** raises or (rarely) lowers the rigor of expression. Plan ΔF moves independently of **ΔG**/**ΔR**: projects often alternate “raise F” (make the claim checkable) with “raise R” (gather proof/validation) at a fixed G.\n* **Cost signals.** Typical costs: authoring overhead (F3→F4), model encoding (F4→F5/6), proof engineering (F6→F7/8). The benefit is reduced ambiguity and safer composition.\n\n#### C.2.3:8.6 - Gaps & thresholds (informative)\n\n* **F‑gap** = ordinal difference between two F anchors (no arithmetic). Large gaps signal translation risk: an F8‑level component will not accept informal inputs (F2) except via additional formalization (ΔF) or robust alignment (CL‑guarded).\n\n",
        "c.2.3:9___worked_examples_(informative)": "### C.2.3:9 - Worked Examples (informative)\n\n> Each mini‑case states the artifact, assigns **F**, and notes interactions with **G/R**. Examples are deliberately cross‑disciplinary to stress transdisciplinary comparability.\n\n#### C.2.3:9.1 - Research hypothesis (physics)\n\n**Artifact.** Short note proposing a new scaling law; clear vocabulary; scope “low‑Reynolds flows in microchannels.”\n**F.** **F3** (controlled narrative with per‑claim acceptance in prose).\n**G/R.** G is a narrow physical envelope; R is initially low (hypothesis).\n**Next ΔF.** Recast acceptance as predicates over variables → **F4**; encode a simple simulation harness → **F5**.\n\n#### C.2.3:9.2 - API specification (software)\n\n**Artifact.** REST API doc with request/response schemas and explicit pre/postconditions; invariants like “idempotent under retry.”\n**F.** **F4** (first‑order constraints).\n**G/R.** G = stated resource model; R improves via conformance tests (independent).\n**Next ΔF.** Reference implementation and executable test suite with declared Standards → **F5**; model‑check idempotence under failure injection → **F6**.\n\n#### C.2.3:9.3 - Safety controller (cyber‑physical)\n\n**Artifact.** Controller with plant model; safety distance invariant and braking envelope defined and verified in a hybrid model checker.\n**F.** **F6** (hybrid formalism with obligations checked).\n**G/R.** G = operating envelope (speed ranges, road conditions); R increases via track tests and simulation coverage.\n**Next ΔF.** Encode key invariants in HOL and prove monotonicity → **F7**; migrate safety property into dependent types in the control kernel → **F8**.\n\n#### C.2.3:9.4 - Decision policy (management)\n\n**Artifact.** Escalation policy: if risk score ≥ θ and budget slack ≤ β, escalate to committee; otherwise defer.\n**F.** **F3→F4** depending on phrasing. If the thresholds and variables are typed and the rule is predicate‑like, rate **F4**.\n**G/R.** G = organizational scope (which portfolios, time windows); R entails retrospective calibration (did escalations match outcomes?).\n\n#### C.2.3:9.5 - Verified algorithm (theory/software)\n\n**Artifact.** Sorting function implemented with a dependent type ensuring output is ordered and a permutation of input; proof included.\n**F.** **F8** (dependent/constructive proof).\n**G/R.** G = data types and preconditions; R (empirical) is irrelevant; VA lane suffices (proof stands).\n\n#### C.2.3:9.6 - ML classifier (data/ML)\n\n**Artifact.** Training pipeline fully specified; metrics defined; OOD detection configured; no formal invariants.\n**F.** **F5** (executable algorithmic semantics).\n**G/R.** G = data distributions and deployment envelope; R grows with validation/monitoring.\n**Next ΔF.** Add formal constraints for safety (e.g., monotonicity in features) → **F4/F6** for those aspects; certified post‑processing may achieve **F7** for a slice.\n\n#### C.2.3:9.7 - Meta‑specification (method description)\n\n**Artifact.** A guideline on how to review specs; it includes checklists and litmus tests.\n**F.** **F3–F4** depending on whether checks are predicates.\n**Interaction.** Its F does **not** lift the F of the reviewed artifacts; it only affects **R** via better CL (clearer alignments and fewer losses).\n",
        "c.2.3:10___authoring_&_review_guidance_(informative)": "### C.2.3:10 - Authoring & Review Guidance (informative)\n\nThis section helps engineering managers, architects, and researchers **assign F consistently**, plan **ΔF moves**, and **review** claims without slipping into status/process language.\n\n#### C.2.3:10.1 - For authors — placing and raising **F**\n\n* **Start honest.** If you’re drafting ideas in plain prose, declare **F0–F1**. You are not “behind”; you’re **appropriately early**.\n* **Stabilize vocabulary first.** Move to **F2–F3** by making terms stable and acceptance statements unambiguous (controlled phrasing).\n* **Name predicates next.** When acceptance can be written as **typed predicates** (“for all …, if … then …”), you have reached **F4**.\n* **Give semantics to execution.** When readers can **run** a model/algorithm with *declared* semantics and see outcomes aligned with the predicates, you are in **F5** (hybrid + obligations → **F6**).\n* **Prove what matters.** When the **logic kernel/type system** will **reject** incorrect changes to core claims, you are at **F7–F8**; if equality as structure is essential, **F9**.\n* **Keep identity.** Prefer **ΔF** on the *same* episteme (raising rigor stepwise) over creating new documents; this keeps provenance and reduces translation error.\n\n**Typical ΔF plan:** *Sketch (F1) → Controlled narrative (F3) → Predicates (F4) → Executable semantics (F5/6) → Machine‑checked core (F7/8).* Scope (G) and evidence (R) can remain fixed while F rises.\n\n#### C.2.3:10.2 - For reviewers — verifying the declared **F**\n\nUse **observable checks**:\n\n* **F2?** Template is complete; terms don’t drift; “TBD” acceptance is explicitly marked.\n* **F3?** Every claim has a **single reading** via constrained phrasing; hidden ambiguity is flagged.\n* **F4?** Each critical claim is **predicate‑like** (typed variables, quantifiers/implication allowed); conflicts are **checkable in principle**.\n* **F5?** Executable **semantics are declared**; runs/tests are not ad‑hoc but trace back to claims.\n* **F6?** Hybrid obligations are **identified and linked** (discrete + continuous, or layered formalisms).\n* **F7/8?** Incorrect edits to core claims are **rejected by the kernel/type system**; proof/scripts or proof‑objects exist and are traceable.\n* **F9?** Higher equalities are **first‑class** (e.g., univalence), and core results rely on them.\n\n**Failure modes to watch:** “green CI” as proof; schema validation treated as semantics; notebooks without declared semantics; long formal appendix while the main claim stays informal (rate by the **weakest essential part**).\n\n#### C.2.3:10.3 - For integrators & architects — using **F** in composition\n\n* **Plan around the minimum.** In any composition, **F\\_composite = min F\\_parts** along essential paths. Identify the **bottleneck F** first; your ΔF effort goes there.\n* **Mind the F‑gaps.** Large ordinal gaps (e.g., F7 vs F2) imply translation risks and alignment costs. Either **raise** the low‑F part or insert **bridges** with explicit scope and confidence impacts (handled in **R** via **CL**).\n* **Don’t upgrade by proximity.** An F8 component does not “elevate” an F3 neighbor. Keep F independent and visible.\n\n#### C.2.3:10.4 - For assurance leads — relating **F** to **G/R** without conflation\n\n* **F enables, R assures.** Raising **F** makes evidence easier to formulate and check; it does not **create** evidence. Rate R separately (calibration/validation/monitoring vs proof lanes).\n* **G is separate.** Tightening **G** (scope/envelope) may accompany ΔF (as assumptions become explicit) — treat this as a **ΔG** move, not a side effect.\n* **Use thresholds explicitly.** If a context expects “formalized before use,” write guard conditions as **`F ≥ k`**, not as status labels.\n\n#### C.2.3:10.5 - Common pitfalls & remedies\n\n| Pitfall                                   | Remedy                                                                                          |\n| ----------------------------------------- | ----------------------------------------------------------------------------------------------- |\n| Calling structured prose a “formal spec.” | If acceptance isn’t predicate‑like, rate **≤F3** and plan **ΔF: prose → predicates (F4)**.      |\n| Treating runnable code as proof.          | Declare **F5**; add **stated obligations** and property checks to progress **F6–F7**.           |\n| Averaging F across parts.                 | Use **min over essential parts**; if unsure which parts are essential, audit the support graph. |\n| Letting status leak into F.               | Keep **status** (e.g., “accepted here”) separate; **F** is about expression only.               |\n\n",
        "c.2.3:11___glossary_&_notation_(normative_where_noted)": "### C.2.3:11 - Glossary & Notation (normative where noted)\n\n**Formality (F).** `U.Formality` — an **ordinal Characteristic** with polarity **up**; default anchors **F0…F9** (§5). *(Normative)*\n\n**Anchor (F‑anchor).** A named qualitative milestone on the F scale (e.g., F4 “first‑order constraints”). Sub‑anchors are context‑local refinements that **preserve order**. *(Normative)*\n\n**ΔF.** A change to the expression form that alters F (usually **up**). Record as an episteme content change. *(Normative)*\n\n**Essential part/path.** A part or claim without which the episteme’s central assertion does not hold. Composition applies **min‑F** along essential support paths. *(Normative)*\n\n**Predicate / Invariant.** A typed, checkable statement about objects/states; at **F4** and above, critical claims are expressed as such.\n\n**Machine‑checked / Proof‑carrying.** Content for which a logic kernel/type system rejects incorrect changes (F7+) or where programs and proofs are the same artifact (F8).\n\n**Higher equality / Univalence.** Treatment of equivalence as identity in higher foundations relevant at **F9**.\n\n**Notation & examples.**\n\n* Declare as `F = Fk` (e.g., `F = F4`).\n* Sub‑anchor: `F = F4[OCL]` or `F = F7[HOL]`.\n* Thresholds in prose: “requires **F ≥ F6** for core claims.”\n* Mixed parts: list per part if useful (e.g., “Body F3; Appendix proofs F7 — **episteme F3**”).\n\n",
        "c.2.3:12___change_log_&_patch_notes_(normative_migration)": "### C.2.3:12 - Change Log & Patch Notes (normative migration)\n\n**12.1 Supersession.**\nThis pattern **supersedes** the legacy “modes/tiers” language. Any references to “M‑mode/F‑mode”, “publication tiers”, or parallel “formality ladders” are **deprecated**. From now on, **Formality** is expressed **only** as **F** with default anchors **F0…F9** (and optional sub‑anchors per §4.3).\n\n**12.2 Impacted cross‑references.**\n\n* **C.2.2 (F–G–R).** Replace any generic “F‑ladder” description with a normative reference to **C.2.3** and treat **F** in the triple as defined here (including **min‑F** composition).\n* **ESG/RSG text.** Where guards previously referenced “modes/tiers,” rewrite guards as **`F ≥ Fk`** conditions.\n* **Meta‑descriptions.** Ensure meta‑artifacts carry **their own F** and do not “lift” a target artifact’s F; use **CL→R** for cross‑context penalties, not F changes.\n\n**12.3 Transitional guidance.**\n\n* **Legacy artifacts without F.** Assign an initial F by applying the rubric in **§6**; record the assignment as a content attribution (not as a status change).\n* **Legacy labels in prose.** Replace them with explicit **F** declarations. If prose implies mixed rigor, rate by the **weakest essential** segment (see §7.3).\n* **No dual systems.** Do not keep “modes” alongside F; remove proxies and speak **F directly**.\n\n**12.4 Backward compatibility (non‑normative note).**\nDuring editorial refresh, it is acceptable to annotate historical records with both the **new F** and the legacy note for provenance. Forward‑looking reasoning and composition, however, **SHALL** use **F only**.\n\n**12.5 Versioning & edits.**\nRaising or (exceptionally) lowering **F** constitutes a **content change** (ΔF). Whether such a change triggers a new edition in a given Context is **outside this pattern**; respect the Context’s edition policy while keeping **F** accurate.\n",
        "c.2.3:end": "### C.2.3:End\n"
      },
      "content": "### C.2.3:End\n",
      "metadata": {},
      "part": "C",
      "cluster": null
    },
    {
      "id": "C.3",
      "title": "Kinds, Intent/Extent, and Typed Reasoning (Kind‑CAL)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## C.3 - Kinds, Intent/Extent, and Typed Reasoning (Kind‑CAL)\n\n> **One‑line summary.** Establishes **`U.Kind`** as the **minimal, context‑local intensional carrier** of “what a statement is about,” separates **intent** (KindSignature + its own **F**) from **extent** (*which* instances belong to the kind **in a given Context slice**), and situates **typed reasoning** alongside **USM Scope (G)** and **F–G–R** without conflation. Details of the core objects and operations live in **C.3.1–C.3.5**; guard shapes are standardized in **C.3.A**.\n\n**Status.** Normative architheory in **Part C**. Identifier **C.3**. This pattern lays the **architectural invariant** and manager‑level guidance. The **mechanics** are defined by its child patterns.\n\n**Readers.** Engineering managers, architects, and assurance leads who must reason about *typed claims* across Contexts without mixing up **describedEntity** (Kinds), **applicability** (**G**), and **assurance** (**R**).\n\n**Depends on.**\n— **A.2.6 USM** (Context slices & Scopes): **`U.ClaimScope` = G**, **`U.WorkScope`**, ∈/∩/**SpanUnion**/translate, **Γ\\_time** policy, Bridges + **CL** (scope).\n— **C.2.2 F–G–R**: weakest‑link composition; penalties to **R** for Cross‑context congruence (CL).\n— **C.2.3 Unified Formality F**: F0…F9 as an **ordinal Characteristic** (expression rigor).\n\n**Sub‑patterns (normative unless noted).**\n— **C.3.1** - `U.Kind` & `U.SubkindOf` (partial order).\n— **C.3.2** - `KindSignature` (**intent**, with **F**) & `Extension/MemberOf` (**extent** in a slice).\n— **C.3.3** - **KindBridge** & **`CL^k`** (type‑congruence; penalties route to **R**).\n— **C.3.4** - **RoleMask** (context‑local adaptation without cloning kinds).\n— **C.3.5** - **KindAT** (K0…K3, **informative facet**, not a Characteristic).\n— **C.3.A** - **Typed Guard Macros** (annex): admit/compose, masks, Cross‑context reuse; AT is **forbidden** in guards.\n\n**Deprecations.**\n— “**Generality ladder**” for **G**; **G is Scope** only (set‑valued over `U.ContextSlice`).\n— Any “**Kind scope**” characteristic (Kinds carry **intent/extent**, not Scope).\n— **Mark as legacy** any uses of **‘validity’ as a Characteristic** or **‘operation’ as a Scope‑like Characteristic**; **redirect** to **`U.ClaimScope`** / **`U.WorkScope`** (A.2.6) for applicability. Editors SHOULD add glossary redirects in Part E.\n\n**Editorial note (cut‑over).** Content formerly in C.3 that defined guard shapes, decision trees, and macro anti‑patterns now resides in **C.3.A**. Membership **evaluation obligations** live in **C.3.2** with `MemberOf`.\n\n",
        "rationale": "### C.3:15bis - Rationale (Part E form)\n\n**Problem.** (recap)\n— Authors conflate *describedEntity* with *applicability*, widening G by abstract wording.\n— Cross‑context reuse drifts semantically without declared mappings or risk accounting.\n— Planning misfires: over‑formalization for instance claims; under‑testing for class claims.\n— Unsafe compositions when describedEntity is implicit.\n\n**Forces.** (recap)\n— Local freedom vs global sense; minimality vs utility; intent vs extent; typed discipline vs F–G–R; abstraction vs applicability.\n\n**Decision (C.3‑D1…D7).**\n— D1: `U.Kind` is intensional and context‑local (`⊑` partial order).\n— D2: Separate intent (KindSignature + F) and extent (Extension/MemberOf@slice).\n— D3: No Scope on kinds (Scope lives with claims/capabilities via USM).\n— D4: Typed reuse is explicit: KindBridge + `CL^k`, penalties route to **R** only.\n— D5: Local adaptation via RoleMask; promote stable masks to subkinds.\n— D6: AT (K0…K3) as **facet**, not a Characteristic; never used in guards.\n— D7: Guard shapes: typed pre‑check → scope coverage → penalties/freshness.\n\n**Consequences.**\n(+) Predictable Cross‑context reuse: two‑bridge rule, separate penalties (Φ/Ψ) to **R**.  \n(+) Manager‑friendly planning: AT guides ΔF/ΔR; typed pre‑check blocks category mistakes.  \n(+) Clean F–G–R discipline: no “G‑ladder,” no hidden scope inside classifiers.  \n(−) Editorial discipline required: no “Kind scope”; masks must be cataloged; promote when stable.  \n(−) Initial bridge authoring cost; mitigated by loss‑notes and reuse.\n\n**Alternatives considered.**\n— *Global U.Type*: rejected as either too thin or too prescriptive across Contexts.  \n— *“Kind scope” in USM*: rejected; duplicates/obscures Scope vs Extension split.\n\n**Known uses.**\n— §11.1 (cyber‑physical braking); §11.2 (API with adapter); §11.3 (clinical dosage); §11.4 (ML fairness).  \n— ESG guard shapes in **C.3.A**; typed pre‑check in Compose‑CAL (§7.2.4).\n\n**Related patterns.**\nA.2.6 (USM), C.2.2 (F–G–R), C.2.3 (F), Part B (Bridges), Role‑CAL, Compose‑CAL, C.3.1–C.3.5, C.3.A.\n",
        "context": "### C.3:2 - Context\n\nCross‑disciplinary work mixes artifacts that *look like “types”* but behave differently: ontology classes, schema “shapes,” programming types, BORO super/sub categories, ad‑hoc labels. At the same time, **USM** made “scope” precise. What was missing was a *small, neutral* notion of **describedEntity** that (a) **does not** re‑invent a global “type system,” (b) composes with USM and F–G–R, and (c) lets Contexts keep their idioms—**with bridges** when crossing boundaries.\n\n",
        "problem": "### C.3:3 - Problem\n\n1. **Scope–type conflation.** Authors try to widen **G** by “abstracting the wording,” yielding claims that *sound* general but are only supported on a thin slice.\n2. **Silent drift across Contexts.** A “vehicle” here is not the same as a “transport unit” there; reuse proceeds without a declared mapping or risk accounting.\n3. **Wasteful planning.** Without a signal about the *kind‑level*, teams either over‑formalize single‑slice decisions or under‑test class‑level claims (no variant coverage along subkinds).\n4. **Unsafe composition.** Claims about incompatible “things” get composed because the describedEntity was implicit in prose.\n\n",
        "forces": "### C.3:4 - Forces\n\n| Force                             | Tension to resolve                                                                                 |\n| --------------------------------- | -------------------------------------------------------------------------------------------------- |\n| **Local freedom vs global sense** | Contexts need their own vocabularies; Cross‑context work needs a common skeleton for **describedEntity**.      |\n| **Minimality vs utility**         | The notion of kind must be tiny yet powerful enough to guide ΔF/ΔR/bridges/composition.            |\n| **Intent vs extent**              | Kinds come with a **definition** and a **population in place**; both are needed and must not mix.  |\n| **Typed discipline vs F–G–R**     | Typed safety must not distort **G** (Scope) nor introduce a parallel “assurance math.”             |\n| **Abstraction vs applicability**  | “Higher abstraction” is **not** “wider applicability”; the framework must make this split obvious. |\n\n",
        "solution": "### C.3:5 - Solution — Architectural Decisions (overview)\n\n**C.3‑D1 — `U.Kind` is intensional and context‑local.**\nKinds name *what a claim quantifies over*. They form a partial order **`⊑`** (**SubkindOf**). *(See C.3.1.)*\n\n**C.3‑D2 — Separate **intent** and **extent**.**\n— **KindSignature(k)**: the intensional content (predicates/invariants/Standards). It carries its **own F** (C.2.3).\n— **Extension(k, slice)**/**MemberOf**: which instances belong to `k` **in a given `U.ContextSlice`**. *(See C.3.2.)*\n\n**C.3‑D3 — Kinds do **not** carry Scope.**\n**Scope** lives with **claims/capabilities** (USM): a set of **Context slices** where the statement holds. Kinds carry **intent/extent** only. *(USM A.2.6 + C.3.2.)*\n\n**C.3‑D4 — Typed reuse across Contexts is explicit.**\nUse a **KindBridge** with **`CL^k`** (type‑congruence) and loss notes. Its effect is **only via R** penalties; **F/G remain unchanged**. *(See C.3.3.)*\n\n**C.3‑D5 — Local adaptation without cloning.**\nUse a **RoleMask** to bind a kind to Context‑specific constraints/aliases; promote to a **subkind** if the mask becomes stable and widely reused. *(See C.3.4.)*\n\n**C.3‑D6 — An **informative** “abstraction tier” exists for Kinds (AT: K0…K3).**\nA facet (not a Characteristic) that helps plan **ΔF/ΔR** and forecast bridge style; **AT never appears in guards**. *(See C.3.5.)*\n\n**C.3‑D7 — Guard shapes are standardized and fail‑closed.**\nTyped compatibility first (same‑Context **`⊑`** or **KindBridge**), then **Scope coverage** (USM), then **R** penalties and freshness. *(See C.3.A.)*\n\n> **Manager’s picture — Two characteristics (keep them separate).**\n> – **characteristic 1 (USM, G):** *Where* the claim holds → set of **Context slices**; composed by ∈ (membership) / ∩ (intersection) / **SpanUnion** (union across independent lines) / translate (scope mapping).\n> – **characteristic 2 (Kind extent):** *Which instances* in a **given slice** belong to the kind → `MemberOf(e, k, slice)`.\n> **Never “widen G” by abstract wording; widen only by ΔG with support.**\n\n",
        "core_concepts_(informative_summary;_authoritative_norms_live_in_c.3.1–c.3.5)": "### C.3:6 - Core Concepts (informative summary; authoritative norms live in C.3.1–C.3.5)\n\n\n> This section fixes the **Standard** of terms used in C.3 and points to the sub‑patterns for complete mechanics. All “**SHALL/MUST**” statements here are normative.\n\n**Editorial note.** This section is **informative**. It restates manager‑level takeaways and **points to** the canonical, normative rules in **C.3.1–C.3.5**. Where this section summarizes a rule, treat the cited sub‑pattern (and rule ID) as the **source of truth**.\n\n\n#### C.3:6.1 - `U.Kind` & `U.SubkindOf (⊑)`\n\n**Definition.** `U.Kind` is a **context‑local intensional object** naming a “kind of thing” that claims may quantify over.\n**Order.** `U.SubkindOf (⊑)` is a **partial order** (reflexive, transitive, antisymmetric). We write `k₁ ⊑ k₂`.\n\n**Summary of norms** *(authoritative text: **C.3.1 K‑01–K‑02**)*.\n— Contexts treat `⊑` as a partial order and document any computed meets/joins if they provide them.\n— Kinds do not carry Scope; Scope remains on claims/capabilities (USM).\n\n> *Full treatment:* **C.3.1** (definitions, invariants, examples).\n\n\n#### C.3:6.2 - **KindSignature** (intent) & **F**\n\n**Definition.** `KindSignature(k)` is the **intent**: predicates/invariants/Standards that define the kind in the Context. Its expression rigor has an explicit **`U.Formality`** (C.2.3).\n\n**Summary of norms** *(authoritative text: **C.3.2 K‑03–K‑04**)*.\n— `KindSignature(k)` declares its F (C.2.3). Claim‑level F does **not** auto‑inherit; weakest‑link applies on the claim’s own support paths.\n— If a signature change alters membership, treat it as a content change (Contexts may version kinds).\n\n> *Full treatment:* **C.3.2** (signature/intent with F; relation to claims).\n\n\n#### C.3:6.3 - **Extension** & **MemberOf** (extent in a slice)\n\n**Definition.** `Extension(k, slice) ⊆ EntitySet(slice)` = set of instances that belong to `k` **in the given `U.ContextSlice`**. `MemberOf(e, k, slice)` is the membership predicate: `e ∈ Extension(k, slice)`.\n\n**Summary of norms** *(authoritative text: **C.3.2 K‑05–K‑08**)*.\n— Membership is deterministic for a fixed `(k, slice)` (no hidden “latest”).\n— If `k₁ ⊑ k₂`, then `Extension(k₁,slice) ⊆ Extension(k₂,slice)` for all slices.\n— Definedness may be bounded; outside it, guards fail closed.\n— Keep **Scope (G)** and **MemberOf** as distinct guard predicates.\n\n> *Full treatment:* **C.3.2** (extent semantics, examples, authoring hints).\n\n\n#### C.3:6.4 - **KindBridge** & **`CL^k`** (type‑congruence)\n\n**Summary of norms** *(authoritative text: **C.3.3 KB‑01–KB‑12**)*.\n— A KindBridge states Contexts/versions, kind mapping/rules, preserved order links, **`CL^k`** anchors, loss notes, and definedness.\n— No inversions of preserved subkind links; collapses must be declared.\n— When classification depends on a KindBridge, apply a monotone penalty **Ψ(`CL^k`)** to **R** (scope‑bridge **Φ(CL)** applies separately). **F** and **G** remain unchanged.\n— Chaining uses weakest‑link on **`CL^k`**.\n\n> *Full treatment:* **C.3.3** (bridge shape, anchors, examples).\n\n\n#### C.3:6.5 - **RoleMask** (adaptation without cloning)\n\n**Definition.** `U.RoleMask(kind, Context)` is a **named binding** that carries constraints (optional **narrowing** of membership), vocabulary/notation aliases, and intended use for local procedures—**without** creating a new Kind.\n\n**Summary of norms** *(authoritative text: **C.3.4 RM‑01–RM‑08**)*.\n— Masks are registered/versioned; constraints are observable/deterministic at guard time.\n— Do not treat masks as kind synonyms; promote frequently reused constraint masks to explicit subkinds (`⊑`).\n\n\n> *Full treatment:* **C.3.4** (mask taxonomy, guard discipline, promotion rule).\n\n\n#### C.3:6.6 - **KindAT (K0…K3)** — *informative facet*\n\n**Status.** A **facet** attached to `U.Kind`, not a Characteristic: no algebra, **never** used in guards or composition.\n\n**Anchors (intentional view).**\n**K0** Instance; **K1** Behavioral pattern; **K2** Formal kind/class; **K3** Up‑to‑Iso.\n\n**Use.** Helps plan **ΔF/ΔR** and forecast bridge style (e.g., K3↔K3 suggests up‑to‑iso mapping). Do **not** conflate AT with **G** or **R**.\n\n> *Full treatment:* **C.3.5** (manager heuristics, anti‑misuse).\n\n\n#### C.3:6.7 - Quick examples (two‑characteristic awareness)\n\n**E‑Sketch 1 — Policy over `Vehicle`.**\nClaim: “For all `x ∈ Vehicle`: brakeDistance(x) ≤ 50 m (dry), ≤ 40 m (wet).”\n– **describedEntity:** `Vehicle` (Kind, typically K2) — *what* we quantify over.\n– **Scope (G):** `{surface∈{dry,wet}, speed≤50, rig=v3, Γ_time=rolling 180d}` — *where* the claim holds.\n– **Extent in slice:** which instances the lab currently classifies as `Vehicle` (via `MemberOf`).\nTyped checks happen **before** Scope intersection; **G** is not widened by “abstract wording.”\n\n**E‑Sketch 2 — API rule over `AuthenticatedRequest`.**\nProducer A emits `Request`; consumer B expects `AuthenticatedRequest`.\n– If `Request ⊑ AuthenticatedRequest` **does not** hold, add an **adapter** or adopt a **subkind**; do **not** force fit by widening **G**.\n– Scope remains independent (API version, Γ\\_time policy); evidence/freshness sits in **R**.\n",
        "how_to_use_typed_reasoning": "### C.3:7 - How to use typed reasoning\n",
        "c.3:7.1_how_typed_reasoning_plugs_into_**f–g–r_&_usm**": "### C.3:7.1 How typed reasoning plugs into **F–G–R & USM**\n\n#### C.3:7.1.1 - The basic shape of a typed claim (manager view)\n\nA typed claim has two independent parts:\n\n1. **describedEntity (Kind).** *Which things the statement talks about.*\n   “For every item of kind **k** in the **target context** (the selected **TargetSlice**) …”.\n   — The **definition** of kind **k** lives in **KindSignature(k)** (with its **F**, C.3.2).\n   — **Which items count as “k”** is evaluated in the **TargetSlice** (C.3.2) by a deterministic membership check.\n\n2. **Applicability (Scope, G).** *Where the statement holds.*\n   `U.ClaimScope(Claim)` is the **collection of contexts** where the claim is valid (USM A.2.6). Guards test: “Scope **covers** the TargetSlice”.\n\n**Discipline.** The guard first checks **typed compatibility** (in the same Context: “is‑a / subkind‑of”; across Contexts: a **KindBridge**, C.3.3), then **Scope coverage** (USM), then **R** freshness and any bridge congruence penalties. See **C.3.A Guard\\_TypedClaim**.\n\n\n#### C.3:7.1.2 - Composition of typed claims\n\n**Rule C‑T‑1 (typed pre‑check).** To compose a **producer claim** with a **consumer claim**, where the producer quantifies over kind **k (source)** and the consumer expects kind **k (expected)**:\n\n* **same Context:** require **“is‑a / subkind‑of”** to hold (the source kind is a subkind of the expected kind) (C.3.1).\n* **Cross‑context:** require a **KindBridge** that maps the source kind to a **local kind that is a subkind of the expected kind** in the target Context (C.3.3). If neither holds, the composition is **unsafe**; introduce a subkind, add an adapter (or a RoleMask), or decline.\n\n* **Role‑aware option (same Context):** if the consumer expects a **RoleMask** over the expected kind, you may satisfy the mask’s explicit constraints (C.3.4) instead of changing kinds, provided those constraints are observable at gate time.\n\n**Rule C‑T‑2 (scope after type).** After typed compatibility is satisfied, compute Scope as in USM:\n\n* **Serial path:** take the **intersection** of the contributors’ claim scopes.\n* **Parallel independent lines:** use **SpanUnion** of the serial scopes (only if independence is justified).\n\n**Rule C‑T‑3 (no type‑by‑scope).** A kind mismatch **MUST NOT** be “fixed” by widening **G**. Changes in describedEntity require **subkind introduction**, **signature edits**, or a **KindBridge**—not a scope change.\n\n**Manager hint.** First confirm the **port shape** matches (kinds line up), then check the **operating area** (scope), and finally look at **confidence** (evidence freshness plus any bridge congruence penalties).\n\n\n#### C.3:7.1.3 - F–G–R with typed claims (what changes, what doesn’t)\n\n* **F (Formality).**\n  – **Claim‑level F** follows C.2.3 (weakest‑link along the claim’s support paths).\n  – **KindSignature F** is declared **on the kind** (C.3.2) and influences claims **only** if the claim essentially depends on those predicates (weakest‑link again).\n  – **Raising F** can *reveal* hidden assumptions (which may trigger ΔG in the claim), but **does not change G** by itself.\n\n* **G (Scope).**\n  – Always **set‑valued over Context slices** (USM A.2.6).\n  – Typed reasoning does not alter G’s algebra (∈/∩/SpanUnion/translate).\n  – Never infer Scope from “how general the wording sounds.”\n\n* **R (Reliability).**\n  – Evidence freshness/decay (validation windows) remains separate from Scope coverage.\n  – **Cross‑context penalties** split cleanly: a **scope‑bridge penalty** (USM) and a **kind‑bridge penalty** (C.3.3). Both **reduce R only**; neither changes **F** or **G**.\n\n**Manager rule of thumb.**\nStart with the reliability from your support; then **apply the scope‑bridge penalty**; then **apply the kind‑bridge penalty**. Each step can only reduce reliability.  \nYou never add or average **F/G**: you **compose scope** per USM rules and apply **weakest‑link** for F/R along support paths.\n\n\n#### C.3:7.1.4 - ESG gating with typed claims\n\n* **Gate on F**, if your Context requires rigor before use (e.g., `U.Formality(Claim) ≥ F4`).\n* **Gate on Scope coverage** (USM) and an explicit **time selector** (Γ_time) policy.\n* **Gate on R freshness** and **minimum congruence** for bridges (e.g., `CL ≥ 2`, `CL^k ≥ 2`).\n* **Do not** gate on **AT** (C.3.5); it is an informative facet only.\n* Use **C.3.A guard macros** to keep guards short and auditable.\n\n#### C.3:7.2 - How typed reasoning plugs into the CAL chain (Lang‑CHR → Role‑CAL)\n\n> **Intent.** Show a clear, end‑to‑end path a manager can follow to take a typed claim from words to safe reuse across Contexts—without any tool or data‑governance assumptions. Each stage says **what it supplies**, **what it needs**, and **what it hands off** to the next stage.\n\n\n##### C.3:7.2.1 - **Lang‑CHR** — stable words first\n\n**What it supplies.** A disciplined vocabulary and controlled phrasing so that terms like *Vehicle*, *AuthenticatedRequest*, *AdultPatient* have **one meaning** in the Context.\n\n**What it requires.** Authors use controlled narrative (C.2.3 **F3**) at minimum: single‑meaning terms, explicit “shall / if / then”, and no drifting synonyms.\n\n**Hand‑off.** A small, curated lexicon entry for each candidate *Kind‑word*; these become **`U.Kind` names** in the next step.\n\n> *Manager hint.* If two teams cannot agree on the noun, you are not ready to type the claim. Resolve the noun in Lang‑CHR before introducing a Kind.\n\n\n##### C.3:7.2.2 - **Kind‑CAL** (this Part) — name the *describedEntity*\n\n**What it supplies.**\n• **`U.Kind`** objects for those nouns; a partial order **`⊑`** (subkind‑of).\n• **KindSignature(k)** (intent), with declared **F**.\n• **Extension(k, slice)** and **`MemberOf(e,k,slice)`** (extent).\n• (Optional) **AT (K0…K3)** as an **informative facet**.\n\n**What it requires.**\n• Deterministic membership (no “latest” defaults) and a clear rule for where membership is defined in each context.\n• No “Kind scope”: Scope remains with claims/capabilities (USM).\n\n> *Manager hint.* Use the kind’s **AT tag** only as a planning signal (where to invest rigor and tests). AT never gates decisions and never widens scope.\n\n**Hand‑off.** Typed quantifier sites for claims: “∀ x ∈ **Extension(k, slice)** …”, plus a visible **`⊑`** lattice for compatibility checks down the line. Typed claim sites written in Plain language: “for every item of kind **k** in the **target context** …”, plus a visible **subkind‑of** lattice for compatibility checks down the line.\n\n> *Manager hint.* Decide early whether your Kind is K0 (instance‑ish) or K2 (formal class). It sets your **ΔF/ΔR** budget expectations.\n\n\n##### C.3:7.2.3 - **Structure‑CAL** — give Kinds usable shape\n\n**What it supplies.** Structural building blocks **on Kinds**:\n• **combinations** (“and”),\n• **alternatives** (“either/or”),\n• **records** (named fields),\n• **functions** (inputs to outputs),\nplus relations like **has‑attribute** and **part‑kind**, and the minimal invariants those structures must respect.\n\n**What it requires.**\n• Do not hide Scope inside structure.\n• Put structural rules into the **KindSignature** as checkable statements (ideally **F4+**).\n\n**Hand‑off.** Typed *ports and shapes* of claims/specifications (“this policy expects `PassengerCar × ControllerConfig`”), making compatibility checks crisp before any Scope math.\n\n> *Manager hint.* If two claims expect different shapes (for example, one needs “Vehicle with ABS”, the other just “Vehicle”), plan a **subkind** or an **adapter**. Do not “solve” it by rewording the claim.\n\n**Note (informative).** If a Context declares structural constructors on kinds (e.g., product/sum/record/function), editors SHOULD document the corresponding **Extension** inclusion laws for those constructors. Keep Scope in USM; do not hide it in structure.\n\n\n##### C.3:7.2.4 - **Compose‑CAL** — compose with typed pre‑checks\n\n**What it supplies.** The **order of checks** you must follow for safe composition:\n\n1. **Typed compatibility**: in the same Context, the producer’s kind **is a subkind of** the consumer’s kind; across Contexts, a **KindBridge** maps the producer’s kind to a local kind that fits, with an acceptable **kind‑bridge congruence level** (C.3.3).\n2. **Scope checks** (USM): along dependency paths, take the **intersection** of scopes; use **SpanUnion** only when support lines are truly independent.\n3. **Assurance wiring**: apply the **scope‑bridge penalty** and the **kind‑bridge penalty** to **R**; check evidence freshness separately.\n\n**What it requires.** Independence justification for **SpanUnion**; no “type‑by‑scope” fixes.\n\n**Hand‑off.** A typed, scope‑checked composition that survives audit because each risk is accounted for in **R**.\n\n> *Manager hint.* Run the **typed pre‑check** first. It is the cheapest failure to catch and prevents “scope gymnastics” that mask a type mismatch.\n\n\n##### C.3:7.2.5 - **CT2R‑LOG** — speak the logic, keep the math honest\n\n**What it supplies.**\n• A clear logical reading of your typed claim: “for every item of kind **K**, condition **φ** holds” (or “there exists an item …”).\n• Rules for refinement and substitution that respect the **subkind‑of** relation.\n• When appropriate (K3), reasoning that treats structures as **equivalent up to isomorphism** (useful where exact identity is the wrong notion).\n\n**What it requires.**\n• Pick a logic that matches the **Formality** you declare (e.g., machine‑checked logic for higher **F**).\n• When the logic travels across Contexts, use a **KindBridge** to keep meaning aligned; any mismatch is reflected as a **kind‑bridge penalty** in **R**.\n\n**Hand‑off.** Proof obligations or reasoning templates that are consistent with your Kind/Structure setup and do not alter **G**.  **Shall‑note CT2R‑1.** Transferring typed formulas that depend on `MemberOf` across Contexts **uses a KindBridge**; any mismatch is accounted as **Ψ(`CL^k`)** in **R**. **F** and **G** remain unchanged. For **up‑to‑iso** situations, see **C.3.5 (AT)** for when K3 is appropriate.\n\n> *Manager hint.* If your proof keeps failing when you move between Contexts, add a **bridge at the Kind level**; do not try to “fix” it by changing scope.\n\n\n##### C.3:7.2.6 - **Role‑CAL** — adapt without cloning\n\n**What it supplies.** **RoleMask(kind, Context)**: a named, registered adaptation (extra constraints or local aliases, with optional narrowing) that reuses the **same** kind instead of creating a new one.\n\n**What it requires.**\n• Constraints must be testable at gate time and give deterministic answers.\n• If a constraint mask is reused often, **promote it to a subkind**.\n\n**Hand‑off.** Context‑specific views that keep identity intact and make typed guards practical (“use `PaymentAccount@PCI` mask in these steps”).\n\n> *Manager hint.* If the same mask appears in several guards, **promote** it to a subkind. This reduces future bridge and audit effort.\n\n\n##### C.3:7.2.7 - Mini end‑to‑end example (manager‑oriented)\n\n> **Scenario.** A risk gate for API requests must be reused by another program across Contexts.\n\n**Lang‑CHR.** Settle on *Request*, *AuthenticatedRequest*, *RiskScore*, *BudgetSlack*; write them in controlled phrases (F3).\n\n**Kind‑CAL.**\n• Define `Kind Request` (K2) and a **subkind** `AuthenticatedRequest ⊑ Request`;  publish a **KindBridge** for the PCI taxonomy with **kind‑bridge congruence level 2** (loss note: token class is collapsed).\n• Membership `MemberOf(e, AuthenticatedRequest, slice)` is deterministic under API v2.3 and Γ\\_time policy.\n\n**Structure‑CAL.**\n• `AuthenticatedRequest` is a **record kind** with fields (headers, tokenProof, body); invariants relate tokenProof to headers.\n\n**Compose‑CAL.**\n• Policy P says in Plain terms: “for every **AuthenticatedRequest** in the **target context**, deny the call when **riskScore** is at or above the set **risk threshold** and **budgetSlack** is at or below the set **budget limit**.”\n• Another service S expects `PCIRequest`. Typed pre‑check: does `AuthenticatedRequest ⊑ PCIRequest`? No.\n• Remedy: adapter A proves `AuthenticatedRequest → PCIRequest` in this Context; if reusing across Contexts, publish a **KindBridge** for the PCI taxonomy with **`CL^k=2`** (loss: token class collapsed).\n\n**CT2R‑LOG.**\n• State P in a state P in a proof‑checked logic (where appropriate for F7+), so that changes to token rules break proofs. Proofs rely on the **AuthenticatedRequest** definition, not on the consumer’s scope.\n\n**Role‑CAL.**\n• Register a **RoleMask** over `PCIRequest` for the consuming team; guards must be able to test the mask’s constraints at gate time.\n\n**Outcome.**\n• **Typed guard** approves only when: (i) the type pre‑check passes (same‑Context subkind‑of or a KindBridge with an acceptable congruence level), (ii) **Scope** covers the target context (API v2.3, explicit time selector), and (iii) **R** reflects the **scope‑bridge** and **kind‑bridge** penalties and evidence is fresh.\n• No one widened Scope to hide a type mismatch; the adapter + bridge made the semantics explicit and auditable.\n\n\n> **Takeaway.** If you keep these six hand‑offs in view—words → kinds → structure → composition → logic → roles—you get **predictable reviews**, **clean risk accounting**, and **reusable claims** that travel across Contexts without silent meaning drift.\n\n#### C.3:7.3 - Compliance & Regulatory Alignment — profile\n\nTreat regulatory categories as **Kinds**, carry their **intent** in `KindSignature` with declared **F**, move them across Contexts with a **KindBridge** (type‑congruence **`CL^k`** + loss notes), and express applicability as **Claim scope** over `U.ContextSlice` (with explicit **Γ_time**). Any Cross‑context uncertainty is routed to **R** via **Ψ(`CL^k`)** (kind) and **Φ(CL)** (scope); **F** and **G** remain unchanged.\n\n> **Authoritative obligations and guard macros** (C‑REG‑1…8, Guard_RegAdopt / Guard_RegChange / Guard_RegXContextUse) and worked scenarios live in **C.3.A, Annex A (Regulatory adoption profile)**.\n\n\n#### C.3:7.4 - How typed reasoning plugs into **Assurance Lanes (VA/LA/TA) & Evidence design**\n\n**Intent (manager’s view).** Typed reasoning turns “prove/test/qualify” into a **repeatable plan** by making *what the rule talks about* explicit (named **Kinds**, their **subkinds**, optional **RoleMasks**) and keeping **Scope (G)** over `U.ContextSlice` separate from **membership** inside the slice. Cross‑context uncertainty (Scope Bridge **CL**, KindBridge **`CL^k`**) always routes to **R** as penalties **Φ/Ψ**; it never changes **F** or **G**.\n\n**Evidence matrix (sketch).**\n\n| Row set                       | Column set                                                   | Cell content                                                                                                           |\n| ----------------------------- | ------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------- |\n| **Kinds** (subkinds or masks) | **Context slices** (Standard versions, env ranges, `Γ_time`) | **Evidence unit** (proof fragment, test batch, monitoring window), with **Scope** and **MemberOf** predicates attached |\n\n*Tip.* For formal kinds and “up‑to‑iso” kinds (AT K2/K3), expect **more rows** (variants). For instance‑like kinds (AT K0), expect **fewer rows** and **tighter columns** (narrow slices, stricter freshness).\n\n> **Authoritative evidence obligations and guard macros** (planning/attachment, VA/LA/TA duties, anti‑patterns) are in **C.3.A, Annex B**.\n\n#### C.3:7.5 - How typed reasoning plugs into **ESG and Method–Work gating**\n\n> Intent. Make state changes and work admissions deterministic, auditable, and safe by separating (1) **typed compatibility** (what the statement or capability is about) from (2) **scope coverage** (where it holds or can run). Any Cross‑context uncertainty is routed to **R** (reliability) only—never to **F** (form) or **G** (scope).\n\n\n##### C.3:7.5.1 - Scope & fit\n\nThis subsection defines **normative guard obligations** for:\n\n* **ESG** (Episteme State Graph) transitions whose assertions **quantify over kinds**, and\n* **Method–Work** admissions where a **capability** expects inputs/outputs of specified kinds.\n\nIt reuses:\n\n* **USM** (A.2.6): `U.ClaimScope` (G) and `U.WorkScope` coverage + `Γ_time`,\n* **Kind‑CAL core** (C.3.1–C.3.2): `U.Kind`, `MemberOf(e,k,slice)`, `⊑`,\n* **KindBridge** (C.3.3) with **`CL^k`** and loss notes,\n* **Scope Bridge** (Part B) with **CL** and loss notes,\n* **RoleMask** (C.3.4) when local adaptations of a kind are used,\n* **Formality F** (C.2.3) when transitions gate on rigor,\n* **Assurance R** (C.2.2) for evidence freshness and penalties Φ/Ψ.\n\n**Guard macros.** The **normative guard shapes** for ESG and Method–Work (**Guard_TypedClaim**, **Guard_TypedJoin**, **Guard_MaskedUse**, **Guard_XContext_Typed**) are specified in **Annex C.3.A**. Use those shapes; the present section is a manager‑level overview only.\n\n##### C.3:7.5.2 - Inputs & roles (at guard time)\n\n* **TargetSlice** — the specific context you are deciding for: Context, versioned Standards, environment parameters, and an explicit **time selector (Γ_time)**.\n* **Typed carriers**\n\n  * **ESG:** the **Claim** quantifies over one or more **Kinds** (e.g., “for all vehicles in the target context …”).\n  * **Method–Work:** the **Capability** declares expected input/output kinds (and possibly RoleMasks).\n* **Thresholds** (context‑local policy):\n\n  * Minimum **F** level for the Claim (if the Context gates on rigor),\n  * Minimum **congruence** for **scope bridges**,\n  * Minimum **type‑congruence** for **KindBridges**,\n  * Evidence **freshness windows** (R‑lane).\n* **Evidence bundle** (if the transition implies trust): references, dates, windows.\n\n\n##### C.3:7.5.3 - Manager’s 7‑step checklist (operational)\n\n1. **Name the slice.** Write the full `TargetSlice`/`JobSlice` tuple including **`Γ_time`**.\n2. **Check coverage.** Claim/Work scope **covers** the slice (USM).\n3. **Check typed definedness.** A deterministic membership check is available in this context for every kind you use (and any masks are registered).\n4. **Check typed compatibility.** same Context: `⊑` (or mask constraints met). Cross‑context: **KindBridge** with **`CL^k ≥ c`**.\n5. **Bridge scope if needed.** Scope Bridge with **CL ≥ c** for Cross‑context scope.\n6. **Apply penalties to R.** Apply the **scope‑bridge penalty** and the **kind‑bridge penalty**; then check evidence **freshness** windows.\n7. **(If gated) Check F.** Enforce `Formality ≥ F_k` for the transition.\n\n> **Remember:** **F** and **G** never change because of bridges; only **R** is penalized. AT (K0…K3) is informative and **not** used in guards.\n\n\n##### C.3:7.5.4 - Cross‑references\n\n* **USM / A.2.6:** Scope coverage, `Γ_time`, serial **∩**, **SpanUnion**, Bridge+CL.\n* **Kind‑CAL / C.3.1–C.3.4:** `U.Kind`, `⊑`, `MemberOf`, RoleMask, KindBridge + **`CL^k`**.\n* **Formality / C.2.3:** `U.Formality` thresholds (when ESG gates on rigor).\n* **Assurance / C.2.2:** Freshness windows; **Φ(CL)** and **Ψ(`CL^k`)** penalties to **R** (weakest‑link on paths).\n\nThis subsection is **normative** for guards in ESG and Method–Work that **use kinds**.\n",
        "cross‑context_typed_reuse_&_assurance_accounting": "### C.3:8 - Cross‑context typed reuse & assurance accounting\n\n#### C.3:8.1 - The **two‑bridge rule** (mandatory)\n\nWhen any part of the use crosses Contexts:\n\n1. **Scope Bridge** (USM/Part B) with **CL** → penalty **Φ(CL)** to **R**.\n2. **KindBridge** (C.3.3) with **`CL^k`** → penalty **Ψ(`CL^k`)** to **R**.\n\nBoth bridges carry **loss notes**; neither changes **F** or **G**. See **C.3.A Guard\\_XContext\\_Typed**.\n\n\n#### C.3:8.2 - Narrowing after mapping (best practice)\n\nIf a bridge’s loss notes indicate material mismatch (dropped invariants, collapsed subkinds):\n\n* **Narrow the mapped Scope** to areas where those losses are benign.\n* **Or** introduce an **adapter** (plus evidence) that restores the needed properties in the target Context.\n* Document the decision; the penalties still land in **R**.\n\n\n#### C.3:8.3 - Typical Cross‑context patterns (manager’s catalog)\n\n* **Name‑level overlap only (low `CL^k`).**\n  Expect significant Ψ penalty. Limit quantification, add local checks, or refuse reuse until the kind mapping is improved.\n\n* **Up‑to‑iso mapping (high `CL^k`).**\n  Often seen for K3 kinds. Ψ penalty is small; treat as “shape‑preserving” transfer. Still apply the appropriate **Φ(CL)** for Scope.\n\n* **Mask‑to‑subkind evolution.**\n  If receivers repeatedly use the same **RoleMask** to make a transfer safe, promote it to an explicit **subkind** and update the bridge to preserve that link.\n\n\n#### C.3:8.4 - Decision pattern (fast path)\n\n1. **Typed pre‑check:** `k_A ⊑ k_B` (same Context) **or** `KindBridge(k_A → k′_B)` with acceptable **`CL^k`**.\n2. **Scope coverage:** `translate(Scope_A)` covers `TargetSlice_B`.\n3. **Apply penalties:** **Φ(CL\\_scope)** and **Ψ(`CL^k`)** to **R**.\n4. **Freshness:** windows/decay for all bound evidence.\n5. **Publish:** a short “Bridge and Loss Notes” box; include any **narrowing** or **adapters** used.\n\n",
        "authoring_guidance_(engineers‑managers)": "### C.3:9 - Authoring guidance (engineers‑managers)\n\n#### C.3:9.1 - When to mint a `U.Kind`\n\nCreate a Kind when:\n\n* multiple claims refer to the **same “describedEntity”** using unstable labels;\n* you need **subkinds** (refinement) or repeated **RoleMasks**;\n* different Contexts must **map** this “describedEntity” via bridges;\n* you need to **quantify** over a population (and plan variant coverage) instead of over a single exemplar.\n\nAvoid creating a Kind for **one‑off** instance references—prefer a clear **K0** facet or just a literal exemplar in the claim.\n\n\n#### C.3:9.2 - Writing a **KindSignature** (and picking **F**)\n\n* Start with a concise **intent**: the invariants/constraints that make membership meaningful.\n* Aim for **F4** (predicate‑like) if the kind is intended for reuse; rise to **F7+** only where proof‑grade is justified.\n* Use **observable** terms (no “latest”); if a Standard matters, **name its version**.\n* If defining a Kind reveals systematic **narrowings** in use, introduce explicit **subkinds** (`⊑`) rather than accumulating opaque masks.\n\n> **Example (sketch).**\n> `Kind Vehicle` — intent: “has VIN; has brake system; has propulsion {ICE, EV, Hybrid}; …” (F4 predicates).\n> Subkind: `PassengerCar ⊑ Vehicle`.\n> RoleMask: `Vehicle@ABSRequired` for processes that demand ABS (deterministic constraints; candidates for promotion to subkind if widely reused).\n\n\n#### C.3:9.3 - Setting the **AT** facet (K0…K3)\n\nUse **AT** to **aim effort**, not to gate:\n\n* **K0**: instance/cohort — focus **R** on the TargetSlice; don’t over‑formalize.\n* **K1**: behavioral pattern — clarify Standards; plan ΔF (F3→F4).\n* **K2**: formal class — invest in F4–F7; plan **variant coverage** across subkinds in **R**.\n* **K3**: up‑to‑iso — expect high‑quality bridges; consider F7–F9 for critical invariants.\n\nNever treat **AT** as “wider/narrower” **G**.\n\n\n#### C.3:9.4 - Writing a typed claim (with USM blocks)\n\n**Skeleton.**\n\n* **Kinds used:** `Vehicle` (K2), subkinds `PassengerCar`.\n* **Claim scope (G):** `surface∈{dry,wet}; speed≤50; rig=v3; Γ_time=rolling 180d`.\n* **Statement:** `∀ x ∈ Extension(Vehicle, TargetSlice) …`\n* **Guards:** use **C.3.A Guard\\_TypedClaim**; if Cross‑context, add **Guard\\_XContext\\_Typed** (two‑bridge rule).\n\n**Tip.** Keep **Scope**, **MemberOf definedness**, **F thresholds**, and **freshness** as **separate** guard predicates—the auditor should be able to tick each box independently.\n\n\n#### C.3:9.5 - Minimal “Kind card” contents (Context catalog)\n\n* **Name** and **intent summary** (KindSignature snippet + **F**).\n* **`⊑` links** (parents/children).\n* **Examples of `MemberOf@slice`** (what membership looks like in practice).\n* **Known RoleMasks** (type, constraints, determinism).\n* **Known KindBridges** (source/target Contexts, **`CL^k`**, loss notes, definedness).\n* *(Optional)* **AT** facet with one‑line rationale.\n\n",
        "10___review_&_integration_guidance": "### 10 - Review & integration guidance\n\n#### C.3:10.1 - Reviewer’s 8‑point checklist\n\n1. **Named describedEntity.** Does the claim state **what** it quantifies over (`U.Kind`)?\n2. **Scope explicit.** Is **G** declared (no “domain” placeholders, no implicit “latest”)?\n3. **Typed compatibility.** For compositions, do we have `⊑` (same Context) or a **KindBridge**?\n4. **RoleMasks.** If used, are they **registered**, **deterministic**, and not masquerading as kinds?\n5. **Two‑bridge rule.** For Cross‑context use, do we have **both** Scope Bridge (**CL**) and **KindBridge** (**`CL^k`**)?\n6. **Penalties.** Are **Φ(CL)** and **Ψ(`CL^k`)** applied to **R**, not smuggled into F/G?\n7. **Freshness.** Are validation/monitoring windows separate from Scope coverage?\n8. **Evidence fit.** For class‑level claims, does the test plan cover **subkinds/variants**?\n\n\n#### C.3:10.2 - Integrator’s composition playbook (typed first, then scope)\n\n* **Step 1:** Check `k_A ⊑ k_B` (or KindBridge).\n* **Step 2:** Compute **Scope\\_serial** = `Scope(A) ∩ Scope(B)` (USM).\n* **Step 3:** If parallel supports exist, **SpanUnion** them (only where independent).\n* **Step 4:** Apply **Φ**/**Ψ** penalties to **R**; enforce freshness.\n* **Step 5:** If a **mask** is repeatedly required, consider promoting it to a **subkind**.\n\n\n#### C.3:10.3 - Assurance lead: wiring penalties and windows\n\n* Identify channels used: **Scope bridge? KindBridge?**\n* Apply **Φ(CL)** and **Ψ(`CL^k`)** to **R** (monotone; higher congruence ⇒ smaller penalty).\n* Verify **freshness windows** for all bound evidence (independent of bridges).\n* Publish a **one‑box summary**: bridges, levels, loss notes, any narrowing/adapters, net impact on **R**.\n\n\n#### C.3:10.4 - Red flags (stop‑the‑line)\n\n* “**We widened G because we reworded the type.**” → **Reject**; redo as subkind/bridge or revise Scope honestly.\n* “**Mask equals kind.**” → **Refactor**; register mask properly or promote to subkind.\n* “**Cross‑context without KindBridge.**” → **Block**; demand mapping and **`CL^k`**.\n* “**No Γ\\_time.**” → **Block**; add explicit time policy (point/window/rolling).\n\n",
        "worked_examples_(end‑to‑end)": "### C.3:11 - Worked examples (end‑to‑end)\n\n+> *Each example shows the typed pre‑check, Scope composition, penalties to **R**, and the managerial decision. Full guard clauses for these scenarios are in **Annex C.3.A**.*\n\n#### C.3:11.1 - Cyber‑physical braking policy across labs and plants\n\n**Claim (Lab Context).**\n“∀ `x ∈ Vehicle`: brakingDistance(x) ≤ 50 m (dry), ≤ 40 m (wet).”\n**Kinds.** `Vehicle` (K2, KindSignature F4); subkind `PassengerCar ⊑ Vehicle`.\n**Scope (Lab).** `{surface∈{dry,wet}, speed≤50, rig=v3, Γ_time=rolling 180d}`.\n\n**Reuse at Plant B.**\n– **KindBridge:** `Vehicle ↦ TransportUnit` with **`CL^k=2`** (loss: EV subkind collapsed).\n– **Scope Bridge:** `Lab → PlantB` with **CL=2** (rig bias ±2 %).\n– **Narrowing:** loss notes indicate wet‑surface bias; Plant B **narrows** mapped Scope to temp/adhesion ranges with acceptable bias.\n\n**Decision.**\nTyped pre‑check: **OK** via KindBridge. Scope coverage after translate/narrow: **OK**.\nPenalties: apply **Φ(2)** and **Ψ(2)** to **R**; freshness windows checked.\n**Outcome:** Adopt with reduced **R**; action item: qualify rig v4 to raise CL in the future.\n\n\n#### C.3:11.2 - API decision rule with adapter and subkind promotion\n\n**Consumer claim.**\n“∀ `x ∈ AuthenticatedRequest`: deny if riskScore(x) ≥ θ ∧ budgetSlack ≤ β.”\n\n**Producer reality.**\nService A emits `Request` (no auth guarantee).\n**Option A:** A proves it emits `AuthenticatedRequest` (introduce subkind or strengthen Standard).\n**Option B:** Insert **adapter** that filters/annotates `Request → AuthenticatedRequest`.\n\n**Typed check.**\nBefore: no `Request ⊑ AuthenticatedRequest`. After **Option B**: adapter supplies the guarantee; repeated use leads to promoting **mask** to **subkind**.\n\n**Scope.**\nAPI v2.3; Γ\\_time = rolling 30 d.\n**R.**\nNo Cross‑context reuse; no Φ/Ψ. Evidence: adapter correctness on the TargetSlice.\n\n**Outcome.**\nAdopt via Option B; open task: generalize producer to subkind and remove adapter later.\n\n\n#### C.3:11.3 - Clinical dosage rule across jurisdictions (bridge + mask)\n\n**Claim (Hospital X).**\n“∀ `x ∈ AdultPatient`: dosage ≤ D per kg for drug M.”\n**Kind.** `AdultPatient` (K2, F4).\n**Mask.** `AdultPatient@ClinicMask` narrows to the clinic’s cohort (deterministic DOB policy).\n\n**Reuse in Jurisdiction Y.**\n– **KindBridge:** `AdultPatient ↦ AdultPerson_Y`, **`CL^k=1`** (18 vs 21 years boundary).\n– **Scope Bridge:** coding systems differ (CL depends on mapping quality).\n– **Narrowing:** restrict Scope to datasets where DOB granularity supports boundary reconciliation.\n\n**Decision.**\nTyped pre‑check via KindBridge: **OK**. Scope coverage after translate/narrow: **OK**.\nPenalties: **Φ(CL\\_scope)** and **Ψ(1)** applied to **R**.\n**Outcome:** Adopt with strong **R** penalty; plan: negotiate a harmonized boundary to raise `CL^k`.\n\n\n#### C.3:11.4 - ML fairness constraint with typed quantification\n\n**Claim (Product Context).**\n“∀ `x ∈ EligiblePerson`: TPR difference ≤ δ across groups `G`.”\n\n**Kind.** `EligiblePerson` transitions from **K1→K2** as attributes and cohorts are formalized (KindSignature F4).\n**Scope.** `{pipeline=P, features=F, Γ_time=rolling 180 d}`.\n\n**Cross‑context use.**\nModel team Context has `Resident` with different feature basis.\n– **KindBridge:** `EligiblePerson ↦ Resident` with **`CL^k=1`** (feature loss).\n– **Scope Bridge:** `pipeline P → P′`, **CL=2**.\n\n**Decision.**\nTyped pre‑check **OK** via bridges; mapped Scope **covers** the subset where features align.\nApply **Φ(2)** and **Ψ(1)** to **R**; restrict groups to mapped subset; require monitoring freshness.\n**Outcome:** Adopt with reduced **R** and a mitigation note; action items: improve feature mapping and raise KindSignature F.\n",
        "anti‑patterns_&_how_to_fix_them": "### C.3:12 - Anti‑patterns & how to fix them\n\n> *Use this section as a “red flags” sheet in reviews. Each item links to a concrete remedy that preserves F–G–R & USM discipline (F/G/R separation, USM algebra, typed pre‑checks).*\n\n| Anti‑pattern (what goes wrong)                                   | Why it’s wrong (conceptual fault)                                                               | The fix (normative/informative pointers)                                                                                                              |\n| ---------------------------------------------------------------- | ----------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **“We widened G because we reworded the type.”**                 | Confuses **describedEntity** (kind) with **applicability** (scope). Abstract wording ≠ broader scope. | Keep typed pre‑check separate (C.3.1 `⊑` or C.3.3 KindBridge). Widen **G** only via **ΔG+** with support (USM A.2.6).                                 |\n| **“Kind scope” block attached to a Kind.**                       | Kinds don’t carry Scope; they carry **intent/extent**.                                          | Remove the block. Scope stays on claims/capabilities (USM). If you meant classifier definedness, state it via **K‑07** (C.3.2).                       |\n| **Inferring scope from extension size.**                         | **Scope ≠ Extension**; extension is “which instances in a slice,” not “where the claim holds.”  | Keep **G** set‑valued over `U.ContextSlice` (USM). Use `MemberOf` only inside the typed quantifier.                                                   |\n| **Mask used as a hidden kind (“just call it the masked kind”).** | Opaque drift; reviewers can’t see constraints.                                                  | Register a **RoleMask** (C.3.4). If reused across guards, **promote to subkind** with `⊑`.                                                            |\n| **Cross‑context reuse with only one bridge.**                       | Contexts differ on two characteristics: Scope **and** Kind.                                                   | Apply the **two‑bridge rule**: Scope Bridge (**CL** → Φ) **and** KindBridge (**`CL^k`** → Ψ). Both penalties land in **R**.                           |\n| **Using AT (K0…K3) as a gate/threshold.**                        | AT is an **informative facet**, not a Characteristic; gating on AT recreates a G‑ladder.        | Remove AT from guards. Use it only to **aim ΔF/ΔR** and to set **bridge expectations** (C.3.5).                                                       |\n| **“Automated execution success proves the type claim.”**                            | Execution success (F5/6) is not proof (F7+); also confuses **R** with **F**.                    | If you need proof‑grade properties, raise **F** for the claim/KindSignature (C.2.3) or restrict the claim. Keep **R** as evidence freshness/coverage. |\n| **Hidden “latest” in membership or scope checks.**               | Non‑deterministic evaluation; unverifiable audit trail.                                         | Declare **Γ\\_time** explicitly in Scope (USM). Membership must be **deterministic** (C.3.2 K‑05/K‑07).                                                |\n| **Fixing type mismatch by “unioning scopes.”**                   | G‑union cannot repair **describedEntity** mismatches.                                                 | Introduce a **subkind**, add an **adapter** (+evidence), or define a **KindBridge**.                                                                  |\n| **Collapsing subkinds silently in a bridge.**                    | Reviewers don’t see lost distinctions → false confidence.                                       | Record **loss notes** on the KindBridge (C.3.3 KB‑11); consider **narrowing** mapped Scope or adding an adapter.                                      |\n\n",
        "governance_&_conformance_pull‑ups": "### C.3:13 - Governance & conformance pull‑ups\n\n> *Contexts adopt Kind‑CAL by meeting the **Context‑level** obligations below. They summarize, not duplicate, the formal requirements in **C.3.1–C.3.5** and **C.3.A**. Use this as an adoption checklist.*\n\n#### C.3:13.1 - Context‑level obligations (must‑haves)\n\n1. **Kinds & order.** Maintain a Context catalog of `U.Kind` with an explicit **partial order** `⊑`.\n   – Conformance: **C.3.1** (K‑01/K‑02).\n\n2. **Kind signatures (intent).** For each Kind, publish a **KindSignature** with declared **F** (C.2.3).\n   – Conformance: **C.3.2** (K‑03/K‑04).\n\n3. **Deterministic membership.** Ensure `MemberOf(e,k,slice)` is **deterministic**; declare any definedness domain.\n   – Conformance: **C.3.2** (K‑05/K‑07).\n\n4. **Typed guards.** When a claim quantifies over kinds, guards SHALL use the **typed guard macros** (or equivalents) from **C.3.A**; **Scope coverage** and **typed checks** are separate predicates.\n\n5. **Role masks.** If a local projection is needed, register a **RoleMask** (type: constraint/vocabulary/composite); avoid cloning kinds.\n   – Conformance: **C.3.4** (RM‑01…RM‑06).\n\n6. **Two‑bridge rule for Cross‑context use.**\n   – **Scope Bridge** (Part B) with **CL** → Φ(CL) to **R**.\n   – **KindBridge** (C.3.3) with **`CL^k`** → Ψ(`CL^k`) to **R**.\n   – Conformance: **C.3.3** (KB‑01…KB‑10).\n\n7. **Decision records.** For each typed state change, record: **TargetSlice tuple**, typed compatibility outcome (`⊑` or KindBridge), **Scope coverage**, applied **Φ/Ψ** penalties to **R**, and **freshness** checks.\n\n#### C.3:13.2 - ESG / Method‑Work template inserts (normative snippets)\n\n* **Kinds used:** list `U.Kind` and any expected **subkinds** or **RoleMasks**.\n* **Claim scope (G):** explicit predicates over `U.ContextSlice` inc. **Γ\\_time**.\n* **Typed guard lines:**\n  – same Context: `k_A ⊑ k_B` *checked*.\n  – Cross Context: `KindBridge(k_A → k′_B)`, `CL^k ≥ c_k` *checked*.\n* **Scope bridge lines:** `Bridge(Context_A → Context_B)`, `CL ≥ c_s` *checked*.\n* **Assurance lines:** `Φ(CL)`, `Ψ(CL^k)` applied to **R**; **freshness windows** hold.\n\n#### C.3:13.3 - Audits & levels of adoption (informative)\n\n* **USM‑Typed‑Ready.** Catalog exists; `⊑` declared; guard macros installed.\n* **USM‑Typed‑Guarded.** All typed claims use **C.3.A** guard shapes; **Γ\\_time** explicit; two‑bridge rule enforced.\n* **USM‑Typed‑Auditable.** Decision records capture **TargetSlice**, typed checks, bridges, penalties, freshness.\n* **USM‑Typed‑Composed.** Compositions use typed pre‑check before Scope algebra; independence justified for **SpanUnion**.\n\n",
        "migration_&_editorial_impact": "### C.3:14 - Migration & editorial impact\n\n> *Apply these edits incrementally; you do not need to stop other work. The aim is to eliminate synonym drift, restore F/G/R separation, and make typed reasoning routine.*\n\n#### C.3:14.1 - Inventory & refactor (steps)\n\n1. **Inventory** claims that implicitly talk about “things” (vehicles, requests, accounts, cohorts…).\n2. **Name kinds** for recurring “describedEntity”; start at **K1**; promote to **K2** as invariants stabilize.\n3. **Extract KindSignature** (aim **F4**); declare **F**.\n4. **Refactor claims** to typed quantification: `∀ x ∈ Extension(k, slice) …` plus **Scope (G)** predicates.\n5. **Publish bridges** where reuse is Cross‑context: Scope Bridge (**CL**) and KindBridge (**`CL^k`**) with loss notes; wire penalties **Φ/Ψ** to **R**.\n6. **Normalize masks**: register RoleMasks; if reused, promote to subkinds (`⊑`).\n\n#### C.3:14.2 - Edits to other parts (normative redirects, no new math)\n\n* **A.2.6 (USM).**\n  – Add “no Scope on kinds” note.\n  – In typed examples, show `MemberOf` definedness + Scope coverage.\n  – Two‑bridge rule for Cross‑context typed reuse.\n\n* **C.2.2 (F–G–R).**\n  – Replace any “generality/abstraction” wording with **Claim scope (G)**.\n  – Before scope composition, require typed pre‑check (`⊑` or KindBridge).\n  – Distinguish penalties: **Φ(CL)** vs **Ψ(`CL^k`)** → both to **R**.\n\n* **C.2.3 (F).**\n  – Add note: **KindSignature** has its own **F**; claim‑level F remains by weakest‑link.\n\n* **Part B (Bridges).**\n – Introduce **KindBridge** with **`CL^k`**, monotone order preservation, loss notes; determinism.\n – Chaining uses **min** of levels (weakest‑link) **for both** **CL** (Scope bridges) **and** **`CL^k`** (KindBridges).\n\n\n* **Role‑CAL.**\n  – Add **RoleMask** for kinds; determinism; promotion rule to subkind when reused.\n\n* **Compose‑CAL.**\n  – Add typed pre‑check before Scope algebra; forbid “type‑by‑scope”.\n\n* **Part E (Lexicon).**\n  – Add: `U.Kind`, `U.SubkindOf (⊑)`, `KindSignature`(+F), `Extension`, `MemberOf`, `U.RoleMask`, **KindBridge**, `CL^k`, **AT (kinds, facet)**.\n  – Mark as **legacy aliases** (not characteristic names): *generality (as ladder), kind scope, validity (as characteristic), capability envelope*; redirect to **Claim/Work scope** or **Kind** entries.\n\n#### C.3:14.3 - Backwards compatibility\n\n* Historical prose may keep legacy words. **Guards, conformance text, and state assertions** MUST use the Kind‑CAL/USM vocabulary and guard shapes.\n* When annotating older records, add a small “typed note” box: **Kinds**, **Scope**, **Bridges (CL/`CL^k`)**, **loss notes**, **penalties to R**.\n\n",
        "quick_reference_for_managers": "### C.3:16 - Quick reference for managers\n\n#### C.3:16.1 - 10‑minute start\n\n1. Name the **Kind** your claim talks about.\n2. Write **Scope (G)** as slice predicates (with **Γ\\_time**).\n3. If composing, check **`⊑`** or **KindBridge** first.\n4. Use the **typed guard macro** (C.3.A).\n5. Route bridge levels to **R** (Φ/Ψ); check freshness.\n\n#### C.3:16.2 - 30‑day rollout plan\n\nWeek 1: Inventory & name Kinds (K1); adopt guard macros.\nWeek 2: Draft **KindSignature** for the top 5 Kinds (aim **F4**); register masks.\nWeek 3: Wire **two‑bridge rule** into ESG; add CL/`CL^k` lines to decision templates.\nWeek 4: Promote repeated masks to subkinds; publish first **KindBridge** records with loss notes.\n\n",
        "local_glossary_(reading_aid)": "### C.3:17 - Local glossary (reading aid)\n\n> *Canonical definitions live in sub‑patterns; this list is for quick recall while reading C.3.*\n\n* **`U.Kind`** — Minimal intensional “type/kind” object; carries **KindSignature** and **`⊑`** (C.3.1/C.3.2).\n* **`U.SubkindOf (⊑)`** — Partial order on kinds (C.3.1).\n* **KindSignature(k)** — Predicate‑like intent that defines the kind; has its own **F** (C.3.2).\n* **Extension(k, slice)** — Set of instances of `k` **inside** a `U.ContextSlice` (C.3.2).\n* **MemberOf(e, k, slice)** — Boolean membership predicate (C.3.2).\n* **RoleMask(k, Context)** — Registered adaptation (constraints/aliases; optional narrowing), no new kind (C.3.4).\n* **KindBridge** — Cross‑context mapping for kinds (intent/order) with **`CL^k`** and loss notes (C.3.3).\n* **`CL^k`** — Kind‑congruence level; penalty **Ψ(`CL^k`)** goes to **R** (C.3.3).\n* **AT (K0…K3)** — Informative facet of a Kind; aids planning/navigation; never used in guards (C.3.5).\n* **Guard macros** — Typed guard shapes for ESG/composition (C.3.A).\n\n> *End of C.3. See **C.3.1–C.3.5** and **C.3.A** for the referenced mechanics and guard macros.*\n",
        "c.3:end": "### C.3:End\n\n"
      },
      "content": "### C.3:End\n\n",
      "metadata": {},
      "part": "C",
      "cluster": null
    },
    {
      "id": "C.3.1",
      "title": "U.Kind & SubkindOf (Core)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## C.3.1 - U.Kind & SubkindOf (Core)\n\n> **One‑line summary.** Defines **`U.Kind`** as a **minimal, context‑local intensional carrier** for “what a claim is about,” and **`U.SubkindOf (⊑)`** as a **partial order** over kinds. **Kinds do not carry Scope.** Scope remains on **claims/capabilities** (USM). This core pattern supplies only identity, locality, and ordering; **intent & membership** (`KindSignature`, `Extension/MemberOf`) are specified in **C.3.2**, bridges & congruence in **C.3.3**, masks in **C.3.4**, and the AT facet in **C.3.5**.\n\n**Status.** Normative architheory in **Part C**. Identifier **C.3.1**.\n**Audience.** Engineering managers, architects, assurance leads.\n\n**Dependencies.**\n\n* **A.2.6 USM (Unified Scope Mechanism).** *Scope* is a set‑valued **USM property** over `U.ContextSlice` on **claims/capabilities**; algebra: `∈` (membership), `∩` (intersection), `SpanUnion` (union across independent lines), `translate` (scope mapping).\n* **C.2.2 F–G–R.** F = formality of expression; **G = Claim scope**; R = assurance/evidence; weakest‑link for F/R; CL penalties feed **R**, not **F/G**.\n* **C.2.3 U.Formality (F).** Ordinal F0…F9; no arithmetic; applies to all content, including Kind signatures (defined in **C.3.2**).\n* **Part B Bridges & CL.** Generic (scope) bridges and CL; **Kind bridges** are specialized in **C.3.3**.\n\n**Non‑goals.**\n\n* No data governance or repository/notation mandates.\n* No membership or signature semantics here (defined in **C.3.2**).\n* No Cross‑context mapping/congruence here (defined in **C.3.3**).\n* No role/mask mechanics here (defined in **C.3.4**).\n* No AT facet mechanics here (defined in **C.3.5**).\n",
        "c.3.1:1___purpose_&_audience": "### C.3.1:1 - Purpose & Audience\n\nThis pattern gives **one small, stable vocabulary** to say *what* a claim ranges over (its **describedEntity**) without entangling that with *where it applies* (Scope) or *how well it is supported* (R). For managers:\n\n* It prevents the costly mistake “more abstract wording ⇒ wider scope.”\n* It enables **typed composition** (you cannot combine claims about incompatible “things”).\n* It keeps **Scope** and **Assurance** math unchanged and predictable.\n\n",
        "c.3.1:2___context": "### C.3.1:2 - Context\n\nacross Contexts, “type” means OWL class, SHACL shape, code type, BORO category, etc. A **neutral, minimal** object is needed to name *the kind of entities* a claim quantifies over **without** importing a full type system or altering USM. **`U.Kind`** fills that role; **ordering** between kinds captures “is‑a/refines” relationships a Context relies on.\n\n",
        "problem": "### C.3.1:3 - Problem\n\n1. **Scope–Type conflation.** Teams broaden G by “abstracting” prose, not by adding supported slices.\n2. **Unsafe composition.** Claims are joined though they talk about different “things.”\n3. **Cross‑context drift.** Without an explicit core notion of kind, bridges blur describedEntity vs applicability.\n\n",
        "forces": "### C.3.1:4 - Forces\n\n| Force                          | Tension to resolve                                                        |\n| ------------------------------ | ------------------------------------------------------------------------- |\n| **Minimality vs utility**      | Keep the core tiny yet sufficient for composition and governance.         |\n| **Locality vs reuse**          | Kinds are context‑local, but projects reuse claims across Contexts via bridges. |\n| **describedEntity vs applicability** | Ordering should not leak into Scope; kinds must not carry G.              |\n| **Neutrality vs specificity**  | Avoid committing to any particular type/ontology stack or notation.       |\n\n",
        "solution": "### C.3.1:5 - Solution — Core Objects (overview)\n\n* **`U.Kind`** — a **context‑local intensional** object naming a “kind of thing” claims may quantify over.\n* **`U.SubkindOf (⊑)`** — a **partial order** on kinds (reflexive, transitive, antisymmetric). `k₁ ⊑ k₂` reads “`k₁` refines `k₂`.”\n\n> **No Scope on kinds.** Scope is for **claims/capabilities** (USM). Kinds supply **describedEntity only**; **membership** and **signature** live in **C.3.2**.\n\n",
        "c.3.1:6___norms_&_invariants_(normative)": "### C.3.1:6 - Norms & Invariants (normative)\n\n**C3.1‑K‑01 (Partial order).** `U.SubkindOf (⊑)` **SHALL** be a **partial order** on `U.Kind`: reflexive, transitive, antisymmetric. Editors **SHALL** document any Context‑specific meets/joins if they supply them (optional).\n\n**C3.1‑K‑02 (No Scope on kinds).** A `U.Kind` **MUST NOT** carry a Scope value. Scope lives with **claims** (`U.ClaimScope` = **G**) and **capabilities** (`U.WorkScope`) per **A.2.6**.\n*Rationale pointer:* see **C.3.2** for the **intent/extent vs Scope** split.\n\n**C3.1‑K‑03 (Identity & locality).** A `U.Kind` is **context‑local**. Cross‑context mapping of kinds is handled by **KindBridge** (see **C.3.3**); such mapping **MUST NOT** be conflated with Scope bridging.\n\n**C3.1‑K‑04 (Naming).** A Context **SHALL** assign stable identifiers to kinds and **SHOULD** catalog parent/child `⊑` links. Synonyms/aliases **SHALL** point to the canonical kind id.\n\n**C3.1‑K‑05 (Separation of concerns).** This core **does not** define kind intent or membership; those are specified in **C.3.2** (`KindSignature` with its own F; `Extension/MemberOf` and determinism).\n\n",
        "c.3.1:7___interactions_(informative)": "### C.3.1:7 - Interactions (informative)\n\n* **With USM (A.2.6).** Guards that quantify over a kind use **two** predicates: “Scope covers TargetSlice” (USM) **and** whatever **membership** predicate is defined for the kind (see **C.3.2**). Kinds themselves carry **no Scope**.\n* **With F–G–R (C.2.2).** This pattern does not alter the triple; typed checks happen **before** scope algebra, preventing invalid compositions.\n* **Order of checks reference.** See **Annex C.3.A §5 (E‑01)** for the normative evaluation order: typed compatibility first, then Scope coverage, then penalties to **R** and freshness.\n* **With Formality (C.2.3).** A **KindSignature** (C.3.2) declares its **F**; claims retain their own F via weakest‑link.\n* **With Bridges (Part B).** Use **KindBridge** (C.3.3) for describedEntity; use **Scope Bridge** (Part B) for applicability. Penalties land in **R** via different channels.\n\n",
        "c.3.1:8___authoring_&_review_(informative)": "### C.3.1:8 - Authoring & Review (informative)\n\n**When to mint a kind.**\nMint a `U.Kind` when claims repeatedly quantify over “the same sort of thing” and you need: (i) safe composition, (ii) clear Cross‑context mapping, (iii) a place to collect invariants (in **C.3.2**).\n\n**Don’t over‑mint.**\nIf a local constraint is temporary or purely procedural, prefer a **RoleMask** (C.3.4) over a new subkind.\n\n**Review prompts.**\n\n1. Does the draft introduce a new *describedEntity* concept? → consider a kind.\n2. Does prose hint at “is‑a” relationships? → capture as `⊑`, not as scope widening.\n3. Are authors trying to widen scope by abstracting wording? → stop; widen **G** only via **ΔG** (USM) with support.\n\n",
        "c.3.1:9___examples_(informative,_technology‑neutral)": "### C.3.1:9 - Examples (informative, technology‑neutral)\n\n1. **Vehicle/PassengerCar.**\n   Mint `Kind Vehicle`. Later add `PassengerCar ⊑ Vehicle`. Claims about **Vehicle** may be reused by narrowing to **PassengerCar** without touching **G**. Scope remains an independent predicate over `U.ContextSlice`.\n\n2. **Request/AuthenticatedRequest.**\n   If multiple policies speak about “authenticated requests,” declare `AuthenticatedRequest ⊑ Request`. Do **not** widen G to compensate for missing authentication; either change the producer’s kind or insert an adapter (C.3.2/C.3.4) while keeping G honest.\n\n",
        "conformance_checklist": "### C.3.1:10 - Conformance checklist (normative)\n\n| ID            | Requirement                                                                                             |\n| ------------- | ------------------------------------------------------------------------------------------------------- |\n| **C3.1‑K‑01** | `U.SubkindOf (⊑)` is a **partial order** (reflexive, transitive, antisymmetric).                        |\n| **C3.1‑K‑02** | `U.Kind` **does not carry Scope**. Scope remains on claims/capabilities per **A.2.6**.                  |\n| **C3.1‑K‑03** | Kinds are **context‑local**; Cross‑context mapping uses **KindBridge** (C.3.3), not Scope bridges.            |\n| **C3.1‑K‑04** | Kinds have **stable ids**; synonyms redirect; Contexts catalog `⊑` links.                                  |\n| **C3.1‑K‑05** | **No intent/membership** in this core; refer to **C.3.2** for `KindSignature` and `Extension/MemberOf`. |\n\n",
        "rationale": "### C.3.1:11 - Rationale (informative)\n\n**Why a tiny core?**\nContexts differ wildly in “type” practice. A large, prescriptive core would either (a) force one Tradition’s semantics on all, or (b) become an empty label. The **smallest powerful** core—identity + ordering—gives managers and integrators what they need (safe composition, predictable edits) and leaves intent/membership/bridges/masks to focused sub‑patterns.\n\n**Why “no Scope on kinds”?**\n**Scope** (USM) answers “**where** a claim/capability holds” over `U.ContextSlice`. Kinds answer “**what** the claim ranges over.” Blending them recreates the failure mode we are removing (“higher abstraction ⇒ wider scope”). The right split is:\n\n* **Kind**: intensional name + order (`⊑`) *(this pattern)*; intent & membership *(C.3.2)*.\n* **Scope**: set of context slices *(A.2.6)*.\n* **Assurance**: evidence & penalties *(C.2.2 / Part B)*.\n",
        "c.3.1:end": "### C.3.1:End\n"
      },
      "content": "### C.3.1:End\n",
      "metadata": {},
      "part": "C",
      "cluster": null
    },
    {
      "id": "C.3.2",
      "title": "KindSignature (+F) & Extension/MemberOf",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## C.3.2 - KindSignature (+F) & Extension/MemberOf\n\n> **One‑line summary.** Specifies the **intent and extent** of kinds: (**i**) a **`KindSignature(k)`** (the intensional definition of kind `k`) that **declares its own Formality F**; (**ii**) an **`Extension(k, slice) ⊆ U.EntitySet(slice)`** and the **membership predicate** `MemberOf(e, k, slice)` that are **deterministic per `U.ContextSlice`**; (**iii**) **monotonicity** of extension under `SubkindOf`; (**iv**) a **definedness policy** that fails **closed** outside its domain. **Kinds still carry no Scope** (that rule lives in C.3.1); Scope stays on **claims/capabilities** (USM). This pattern gives managers and reviewers the **observable basis** to check “what counts as a member here and now” without entangling applicability (G) or assurance (R).\n\n**Status.** Normative architheory in **Part C**. Identifier **C.3.2**.\n**Audience.** Engineering managers, architects, assurance leads, editors.\n\n**Depends on.**\n\n* **C.3.1** (*U.Kind & SubkindOf Core*): kinds are context‑local; `⊑` is a partial order; kinds carry **no Scope**.\n* **A.2.6 USM** (*Context slices & Scopes*): Claim scope (G) and Work scope live on claims/capabilities; algebra `∈` (membership), `∩` (intersection), `SpanUnion` (union across independent lines), `translate` (scope mapping).\n* **C.2.3 U.Formality (F)**: ordinal F0…F9; no arithmetic; weakest‑link composition applies to content that depends on the signature.\n* **C.2.2 F–G–R**: assurance calculus; CL penalties feed **R**, not **F/G**.\n* **Part B (Scope Bridges & CL).** CL (scope congruence) and scope translation live in Part B/USM; **kind‑congruence `CL^k`** and kind mapping live in **C.3.3** (KindBridge).\n\n**Non‑goals.**\n\n* No Scope semantics here (USM); no bridge semantics here (C.3.3).\n* No repository/notation mandates; this is concept‑level, not tooling.\n",
        "c.3.2:1___purpose_&_audience": "### C.3.2:1 - Purpose & Audience\n\nThis pattern makes **describedEntity testable** in a Context:\n\n* Authors get a place to write **what defines a kind** (`KindSignature`) and at **what rigor (F)**.\n* Reviewers can ask **deterministic** questions: *“Given this `TargetSlice`, which entities are in `k`?”*\n* Managers can plan **ΔF** (raise signature rigor) and **ΔR** (evidence over members) **without** changing **G** (applicability).\n\n**No tooling assumption.** The pattern is **conceptual** and notation‑neutral (no OWL/SHACL/type‑system requirement); it specifies reviewer‑checkable obligations that managers can read in plain language.\n",
        "c.3.2:2___context": "### C.3.2:2 - Context\n\nDifferent Contexts encode “type” intent differently (predicates, schemas, ontologies, Standards). Regardless of notation, a team must be able to answer, reproducibly: **who belongs to the kind at this slice?** If this is not stable, claims quantified over the kind are unverifiable, bridges are opaque, and composition becomes unsafe.\n\n",
        "problem": "### C.3.2:3 - Problem\n\n1. **Ambiguous membership.** Membership depends on tacit “latest” states or unwritten defaults.\n2. **Signature opacity.** A kind’s definition is scattered; no single place to declare rigor (**F**) or assumptions.\n3. **Order violations.** Subkind hierarchies do not guarantee subset behavior in practice.\n4. **Scope leakage.** Teams smuggle applicability (G) into kind definitions, recreating G‑ladders by another name.\n\n",
        "forces": "### C.3.2:4 - Forces\n\n| Force                              | Tension to resolve                                                                                   |\n| ---------------------------------- | ---------------------------------------------------------------------------------------------------- |\n| **Local freedom vs comparability** | Contexts need their own notations, but membership must be checkable in a common style.                  |\n| **Expressivity vs determinism**    | Rich intent is welcome, but membership must be deterministic given `slice`.                          |\n| **Intent vs applicability**        | Define “what counts” (intent/extent) without encoding “where valid” (G).                             |\n| **Rigor vs cost**                  | Raising signature F has cost; the framework must support low‑F drafts and high‑F safety cores alike. |\n\n",
        "solution": "### C.3.2:5 - Solution — Objects & Standards (overview)\n\n* **`KindSignature(k)`** — the **intensional** definition of kind `k` in the Context; it **declares `U.Formality`** per C.2.3.\n* **`U.EntitySet(slice)`** — the set (or well‑defined universe) of **entities addressable in a given `U.ContextSlice`**.\n* **`Extension(k, slice) ⊆ U.EntitySet(slice)`** — **which entities** belong to `k` **at** `slice`.\n* **`MemberOf(e, k, slice)`** — membership predicate: `e ∈ Extension(k, slice)`.\n\n**Design split.**\n\n* **Intent** lives in **`KindSignature`** (with F).\n* **Extent** is **computed per `slice`** via `MemberOf`.\n* **Applicability** (where a **claim** holds) remains a **Scope** on the claim (USM) and **MUST NOT** be encoded into `KindSignature`.\n\n",
        "c.3.2:6___norms_&_invariants_(normative)": "### C.3.2:6 - Norms & Invariants (normative)\n\n> IDs **C3.2‑K‑03…K‑08** correspond to the rules announced in C.3; additional local rules use **C3.2‑S‑\\***.\n\n#### C.3.2:6.1 - Signature & Formality\n\n**C3.2‑K‑03 (Signature F).** Every `KindSignature(k)` **SHALL declare `U.Formality`** per C.2.3 (F0…F9).\n— *Note:* Raising signature F **does not** automatically raise claim‑level F; claims follow weakest‑link along their **own** support paths.\n\n**C3.2‑K‑04 (Signature change = content change).** Any change to `KindSignature(k)` that **alters membership** (i.e., would change `Extension(k, slice)` for some `slice`) **SHALL** be recorded as a **content change** (Contexts may version kinds).\n\n#### C.3.2:6.2 - Extension & Membership\n\n**C3.2‑K‑05 (Deterministic membership).** For fixed `(k, slice)`, `MemberOf(e, k, slice)` **MUST** be deterministically evaluable **from observable content in `slice`**.\n— Implication: **“latest” is forbidden**; `Γ_time` must be explicit on `slice` (A.2.6).\n— If a classifier makes external assumptions, they **MUST** be named in `KindSignature`.\n\n**C3.2‑K‑06 (Monotone in `⊑`).** If `k₁ ⊑ k₂`, then for **every** `slice`:\n`Extension(k₁, slice) ⊆ Extension(k₂, slice)`.\n\n**C3.2‑K‑07 (Definedness & fail‑closed).** Each Context **MAY** restrict the **domain of definedness** for `MemberOf(–, k, –)` (e.g., only when a Standard or dataset is present at a given version). Outside that domain, `MemberOf` **MUST** be treated as **not defined** for guard purposes, and guards **MUST fail closed** (deny). Implementations MAY internally return `False`, but there **MUST** be no path where undefined membership yields implicit success.\n\n**C3.2‑K‑08 (Separation from G).** Guards **SHALL** keep **Scope coverage** (USM) and **membership** **as separate predicates**:\n“`U.ClaimScope(Claim) covers TargetSlice` **AND** `MemberOf(?, k, TargetSlice)` is defined/used”.\n\n#### C.3.2:6.3 - Entity set & time\n\n**C3.2‑S‑01 (`U.EntitySet`).** A Context **SHALL** document what counts as `U.EntitySet(slice)` (e.g., “rows in dataset D at version v,” “live objects in service S at build b,” “ontology individuals at vocabulary v”). This documentation **MUST** be stable and addressable via the `slice` tuple.\n**C3.2‑S‑02 (Time).** `slice` **SHALL** specify **`Γ_time`** (point/window/policy). Membership **MUST NOT** rely on implicit recency. \n\n`U.EntitySet(slice)` **MUST NOT** expand implicitly via external defaults or time; its extent is fixed by the `slice` tuple (see **C3.2‑S‑02**).\n",
        "c.3.2:7___interactions_&_placement_(informative)": "### C.3.2:7 - Interactions & Placement (informative)\n\n* **With C.3.1.** Kinds carry identity and `⊑`; **no Scope** on kinds. This pattern adds the **intent/extent** layer under those constraints.\n* **With A.2.6 (USM).** A typed claim’s guard normally evaluates, in the order specified by **Annex C.3.A §5 (E‑01)**: (1) typed compatibility, (2) **Scope coverage** at `TargetSlice`, (3) **`MemberOf(?, k, TargetSlice)`** definedness and any instantiation, followed by penalties to **R** and freshness checks. Use **Guard_TypedClaim** / **Guard_TypedJoin** rather than ad‑hoc shapes.\n* **With C.2.3 (F).** Signature F influences claims **only if** the claim **depends on** the signature content; weakest‑link min applies along the claim’s support path.\n* **With C.3.3 (KindBridge).** When `MemberOf` is computed via a **kind mapping across Contexts**, kind‑congruence `CL^k` contributes a **monotone penalty to **R** only (Ψ(`CL^k`)); **F/G MUST NOT** be adjusted. \n* **With Role‑CAL (C.3.4).** A **RoleMask** may **narrow** membership (context‑local adaptation). Frequent masks that encode stable narrowing **SHOULD** be promoted to subkinds (`⊑`).\n\n",
        "c.3.2:8___authoring_&_review_guidance_(informative)": "### C.3.2:8 - Authoring & Review Guidance (informative)\n\n#### C.3.2:8.1 - Authoring `KindSignature`\n\n* **Be explicit and observable.** Prefer predicate‑like clauses over prose (“has VIN format …”; “axles ≥ 2”).\n* **Bind to versions.** Name Standards/schemas by version; avoid “current.”\n* **Declare F honestly.** F3 for controlled narrative is fine in early phases; aim F4+ for durable kinds; consider F7+ for safety‑critical cores.\n* **Name assumptions.** If membership requires external conditions (e.g., calibrated rig), put them in the signature.\n\n#### C.3.2:8.2 - Authoring membership\n\n* **Define `U.EntitySet(slice)`.** Write it down once per Context, make it addressable via the `slice` tuple, and reuse.\n* **Determinism first.** No hidden IO, no implicit time; membership must be recomputable from the slice.\n* **Document definedness.** If `MemberOf` is undefined without a Standard, say so; guards will fail closed.\n* **Respect `⊑`.** If you declare `k₁ ⊑ k₂`, verify subset behavior (C3.2‑K‑06).\n\n#### C.3.2:8.3 - Review checklist (10 minutes)\n\n1. Is **signature F** declared? Is the signature sufficient to evaluate membership?\n2. Is **`U.EntitySet(slice)`** documented and addressable?\n3. Is **membership deterministic** with explicit `Γ_time` (no “latest”)?\n4. If `⊑` links exist, does **subset behavior** hold at sample slices?\n5. Are **Scope** and **membership** kept **separate** in guards?\n6. Any **Cross‑context** classification? If yes, is **KindBridge** referenced (C.3.3)?\n\n",
        "c.3.2:9___worked_examples_(informative)": "### C.3.2:9 - Worked Examples (informative)\n\n#### C.3.2:9.1 - Vehicle (signature F4) and membership\n\n**KindSignature(Vehicle)** *(F4)*:\n\n* `hasVIN(x)` is true and parseable;\n* `axles(x) ≥ 2`;\n* `hasBrakeSystem(x)`;\n* Standards: `registryAPI v1.4`; `Γ_time` policy: rolling 365 d for registry fields.\n\n**`U.EntitySet(slice)`**: “records in `registryAPI v1.4` for plant `A` at build `b`, as of `Γ_time`.”\n**`Extension(Vehicle, slice)`**: all records satisfying the predicates **in that `slice`**.\n**Monotonicity:** `PassengerCar ⊑ Vehicle` ⇒ `Extension(PassengerCar, s) ⊆ Extension(Vehicle, s)`.\n\n#### C.3.2:9.2 - AuthenticatedRequest (definedness & fail‑closed)\n\n**KindSignature(AuthenticatedRequest)** *(F4)*:\n\n* `Request` with `authHeader` present and `authSignature` valid according to `AuthStandard v2.3`;\n* `Γ_time`: point in time for key validity check.\n\n**Definedness:** `MemberOf(–, AuthenticatedRequest, slice)` is **undefined** if `AuthStandard v2.3` is **absent** in `slice` ⇒ guards **fail closed** (C3.2‑K‑07).\n\n#### C.3.2:9.3 - Clinical cohort (low‑F signature; deterministic membership)\n\n**KindSignature(AdultPatient)** *(F3→F4 as it hardens)*:\n\n* `ageYears(x, Γ_time) ≥ N` (jurisdictional N varies; recorded in the Context’s signature note).\n* `EntitySet(slice)`: EHR `ehr‑east v7.5` @ `Γ_time`;\n* Membership deterministic if DOB present; undefined otherwise (fail closed).\n\n",
        "c.3.2:10___anti‑patterns_&_remedies_(informative)": "### C.3.2:10 - Anti‑patterns & Remedies (informative)\n\n| Anti‑pattern                                         | Why it’s wrong                        | Remedy                                                              |\n| ---------------------------------------------------- | ------------------------------------- | ------------------------------------------------------------------- |\n| Using “latest” implicitly in membership              | Non‑deterministic; unreproducible     | Require explicit `Γ_time`; treat freshness separately in **R**      |\n| Encoding Scope (“only in EU plant”) in the signature | Confuses applicability with describedEntity | Move such conditions to **Claim scope (G)**; keep signature general |\n| Declaring `k₁ ⊑ k₂` but not ensuring subset behavior | Breaks typed reasoning                | Tighten `KindSignature` or drop the `⊑` link                        |\n| Treating RoleMask as a different kind                | Catalog sprawl; hidden semantics      | Keep mask as adaptation; promote to subkind if widely reused        |\n| Membership relying on external, unnamed assumptions  | Hidden dependencies; review fatigue   | Name assumptions in the signature; point to Standards/versions      |\n\n",
        "rationale": "### C.3.2:11 - Rationale (informative)\n\n#### C.3.2:11.1 - Why give **F** to `KindSignature`?\n\nBecause rigor in the **definition of a kind** materially affects how safely teams can quantify over it. A signature at **F4** (predicate‑like) makes membership checkable in principle; **F7+** (machine‑checked) can support proof‑carrying development. Keeping this **separate from claim‑level F** prevents “signature formalization” from inflating unrelated claims.\n\n#### C.3.2:11.2 - Why **Extension** is not **Scope**\n\n* **Extension** answers: *“Which entities count as `k` **in this slice**?”*\n* **Scope (G)** answers: *“In which slices does **this claim** hold?”*\n  Blending the two recreates the old failure mode where “more abstract wording” was treated as “wider applicability.” USM already gives the set‑algebra for G; Kind‑CAL supplies the **typed universe** the claim quantifies over.\n\n#### C.3.2:11.3 - Why **determinism** and **fail‑closed**?\n\nGuards must be **reproducible** and **auditable**: same `slice` ⇒ same membership result. If inputs are missing (undefinedness), the safest default is **deny** (fail closed), prompting either a richer slice or a scope/claim change.\n\n",
        "conformance_checklist": "### C.3.2:12 - Conformance checklist (normative)\n\n| ID            | Requirement                                                                                     |\n| ------------- | ----------------------------------------------------------------------------------------------- |\n| **C3.2‑K‑03** | Every `KindSignature(k)` **declares `U.Formality`** (F0…F9).                                    |\n| **C3.2‑K‑04** | Signature changes that alter membership are **content changes** (Contexts may version kinds).      |\n| **C3.2‑K‑05** | `MemberOf(e, k, slice)` is **deterministic** for fixed `(k, slice)` (no “latest”).              |\n| **C3.2‑K‑06** | **Monotonicity:** if `k₁ ⊑ k₂` then `Extension(k₁, s) ⊆ Extension(k₂, s)` for all `s`.          |\n| **C3.2‑K‑07** | **Definedness:** outside domain, membership **fails closed**; guards deny use.                  |\n| **C3.2‑K‑08** | **Separation:** guards keep **Scope coverage** (USM) and **membership** as distinct predicates. |\n| **C3.2‑S‑01** | The Context **documents `U.EntitySet(slice)`** (stable, addressable via `slice`).                |\n| **C3.2‑S‑02** | `slice` **specifies `Γ_time`**; membership **must not** rely on implicit recency.               |\n\n",
        "c.3.2:end": "### C.3.2:End\n"
      },
      "content": "### C.3.2:End\n",
      "metadata": {},
      "part": "C",
      "cluster": null
    },
    {
      "id": "C.3.3",
      "title": "KindBridge & CL^k — Cross‑context Mapping of Kinds",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## C.3.3 - KindBridge & CL^k — Cross‑context Mapping of Kinds\n\n> **One‑line summary.** Defines **`KindBridge`** as the normative mechanism for moving **kinds** (their **intent** and selected **subkind‑of** links) between bounded contexts (“Contexts”). A bridge declares **how a source kind maps to a target kind**, which parts of the **`⊑`** order are preserved or collapsed, and publishes a **type‑congruence level `CL^k`** with **loss notes** and a **definedness area**. **`CL^k` penalties apply only to Reliability (R)** when a claim depends on Cross‑context classification; **F** (formality) and **G** (Claim scope) remain unchanged. Scope translation continues to use the **USM Bridge + CL** channel; **KindBridge** is a **separate, parallel channel** for describedEntity.\n\n**Status.** Normative architheory in **Part C**. Identifier **C.3.3**.\n**Audience.** Engineering managers, architects, assurance leads, editors.\n\n**Depends on.**\n\n* **C.3.1 — U.Kind & SubkindOf (Core):** kinds are context‑local intensional objects; `⊑` is a partial order; kinds **do not carry Scope**.\n* **C.3.2 — KindSignature (+F) & Extension/MemberOf:** signature declares its own **F**; membership `MemberOf(e,k,slice)` is **deterministic** per `U.ContextSlice`.\n* **A.2.6 — USM (Context slices & Scopes):** Claim scope (**G**) and Work scope live on claims/capabilities; scope bridging and **CL** penalties are defined there.\n* **C.2.2 — F–G–R:** weakest‑link; penalties land in **R**, not **F/G**.\n* **C.2.3 — U.Formality (F):** signature rigor.\n\n**Non‑goals.**\n— No repository/notation mandates; conceptual only.\n— No Scope mapping here (that’s USM); **KindBridge** maps **kinds**, not scopes.\n— No new arithmetic on `CL^k`; it reuses the **ordinal anchor semantics** of CL (Part B) but applies to kinds.\n",
        "c.3.3:1___purpose_&_audience": "### C.3.3:1 - Purpose & Audience\n\nCross‑context reuse fails in two **orthogonal** ways:\n\n1. **Applicability** (G): *where* the claim holds (handled by USM Scope Bridge).\n2. **describedEntity** (Kind): *what* the claim quantifies over (handled by **KindBridge**).\n\n**C.3.3** gives managers an explicit, auditable channel for **(2)**, so a team can say, with evidence: *“`Vehicle` in Lab maps to `TransportUnit` in Plant with `CL^k=2`; the EV subkind collapses; here’s what we lost.”* Guards stay deterministic; assurance math stays clean (penalties in **R** only).\n\n",
        "c.3.3:2___context": "### C.3.3:2 - Context\n\nContexts use different **classifications**: ontology classes vs shape Standards, regulatory cohorts vs app types, etc. Informal “same‑name” reuse silently mutates describedEntity. USM already made scope moves explicit. **KindBridge** does the same for kinds: **declare the mapping**, rate its **congruence**, and capture known **losses**.\n\n",
        "problem": "### C.3.3:3 - Problem\n\n1. **Semantic drift.** Moving a claim into a target‑context with a different taxonomy changes “what counts” without anyone noticing.\n2. **Hidden order breaks.** Subkind relationships invert or vanish; downstream proofs/tests are misapplied.\n3. **Entangled channels.** Teams conflate “scope mapping” with “kind mapping,” making it impossible to assign penalties coherently.\n4. **Incomputable guards.** “We map it somehow” yields non‑deterministic classification at guard time.\n\n",
        "forces": "### C.3.3:4 - Forces\n\n| Force                                    | Tension to resolve                                                                              |\n| ---------------------------------------- | ----------------------------------------------------------------------------------------------- |\n| **Minimal disclosure vs precision**      | Bridges must be light to write yet precise enough to avoid semantic drift.                      |\n| **Local autonomy vs global reuse**       | Each target‑context keeps its vocabulary; reuse requires explicit, reviewable mappings.                   |\n| **Typed safety vs agility**              | We need typed compatibility checks without blocking exploratory reuse.                          |\n| **Separate channels vs operator burden** | Two channels (Scope & Kind) must be explicit, but guard writers shouldn’t drown in boilerplate. |\n\n",
        "solution": "### C.3.3:5 - Solution — The **KindBridge** object (overview)\n\nA **KindBridge** connects **source** Context **A** and **target** Context **B** for a set of kinds. It declares:\n\n1. **Mapping of kinds**: either to named target kinds or via **signature translation** rules.\n2. **Order preservation**: which `⊑` links are preserved (monotone), which are **collapsed**, and which are **unknown** (not claimed).\n3. **Type‑congruence `CL^k`**: reuses the **same anchors/labels** as **CL** (Part B) but applies to kind intent/order (not to Scope). *Gloss:* higher `CL^k` ⇒ closer preservation of kind intent and declared `⊑` links.\n4. **Loss notes**: human‑readable list of invariants and subkinds **not preserved**.\n5. **Definedness area**: the subset of `U.ContextSlice` characteristics where the mapping is **intended** to be used (e.g., certain Standards/versions).\n6. **Determinism**: fixed versions + mapping rules ⇒ deterministic result (no “latest”).\n\n**Effect on assurance.** When a **claim** in B depends on classification that goes through this bridge, **reduce R** by a monotone penalty **Ψ(`CL^k`)**. **Do not** change **F** or **G**.\n\n",
        "c.3.3:6___norms_&_invariants_(normative)": "### C.3.3:6 - Norms & Invariants (normative)\n\n> The following formalize the **KB‑01…KB‑12** rules announced in C.3.\n\n#### C.3.3:6.1 - Subject & Scope of a KindBridge\n\n**KB‑01 (Subject).** A KindBridge **maps**:\n\n* one or more **KindSignature**(s) from source to target; and\n* an **explicitly declared subset of `⊑` links** (which it claims to preserve or collapse).\n\n**KB‑02 (No Scope).** A KindBridge **MUST NOT** map Claim/Work scope (**G**). Scope translation uses the **USM Bridge + CL** channel (A.2.6, Part B).\n\n**No blended score.** Congruence for Scope (**CL**) and for Kind (**CL^k**) **MUST NOT** be aggregated into a single “interoperability” score in guards; each channel is assessed and penalized **separately**. See **Annex C.3.A §5 (E‑06)**.\n\n\n#### C.3.3:6.2 - Declaration & Shape\n\n**KB‑03 (Declaration).** A KindBridge record **SHALL** include:\n\n1. source/target Contexts and vocabulary/Standard **versions**;\n2. a **kind mapping** per source kind `k`: either a **named** target kind `k′` or a **signature translation rule** that constructs the **target‑context** `KindSignature(k′)` (the result is owned and versioned in the target Context);\n3. an **order preservation claim** for any `k₁ ⊑ k₂` it covers: *preserved* / *collapsed* / *unknown*;\n4. **`CL^k`** value (using the CL anchor ladder) labeled **“kind‑congruence”**;\n5. **loss notes** (non‑preserved invariants, collapsed subkinds, equality quirks);\n6. **definedness area** (constraints on `U.ContextSlice` dimensions where the bridge is meant to apply).\n\n**KB‑04 (Determinism & local evaluation).** Given fixed Context versions and mapping rules, **translateₖ** **MUST** be deterministic (no implicit “latest”). After mapping to `k′`, **membership SHALL be evaluated using the target Context’s own `KindSignature(k′)` and `MemberOf(–, k′, –)`**; source‑context membership results **MUST NOT** be reused as truth in guards (they may be cited as evidence in **R**).\n\n#### C.3.3:6.3 - Order & Monotonicity\n\n**KB‑05 (Monotone order).** If the bridge claims to **preserve** `k₁ ⊑ k₂`, then in the target Context **`translateₖ(k₁) ⊑′ translateₖ(k₂)`** **MUST** hold.\n**KB‑06 (No inversions).** The bridge **MUST NOT** assert preserved links that **invert** order. If real‑world constraints force reversal, the link **MUST** be marked **not preserved** with a **loss note**.\n**KB‑07 (Collapse semantics).** Marking a link as **collapsed** is allowed (two subkinds mapped to one target kind), but the record **SHALL** list the merged subkinds and any properties thereby lost.\n\n#### C.3.3:6.4 - Congruence & Assurance\n\n**KB‑08 (Anchor reuse & AT neutrality).** **`CL^k`** reuses the **ordinal anchor semantics** of CL (Part B) but applies **to kinds**. Editors **SHALL** label it explicitly as **kind‑congruence** to avoid confusion with Scope CL. **KindBridge records MUST NOT compute or alter KindAT (C.3.5 AT‑04); AT is editorial and independent of `CL^k`.**\n**KB‑09 (Effect on R only).** When a claim in the target Context depends on `MemberOf(–, translateₖ(k), TargetSlice)`, a **monotone penalty `Ψ(CL^k)`** **SHALL** reduce **R** (alongside any `Φ(CL)` penalty from the Scope Bridge). Implementations **MUST NOT** adjust **F or G** due to `CL^k`.\n**KB‑10 (Chaining).** For a chain of bridges, **effective `CL^k` = min** of the links (weakest‑link).\n\n#### C.3.3:6.5 - Loss Notes & Definedness\n\n**KB‑11 (Loss notes).** Bridges **SHALL** publish human‑readable **loss notes**: which invariants of `KindSignature` are **not preserved**, which subkinds are **collapsed**, and any **higher‑equality** caveats (e.g., up‑to‑iso only).\n**KB‑12 (Definedness & guard use).** The bridge’s **definedness area** **SHALL** be stated. Guards **MUST fail closed** outside it (i.e., if a classification relies on the bridge where it is not defined, the guard denies use).\n\n",
        "c.3.3:7___interactions_(informative)": "### C.3.3:7 - Interactions (informative)\n\n#### C.3.3:7.1 - With USM Scope bridges (two channels)\n\nWhen using a claim across Contexts, expect **two concurrent bridges**:\n\n* **Scope Bridge (USM)**: maps **G**; publishes **CL**; penalty **Φ(CL)** to **R**.\n* **KindBridge (this pattern)**: maps **kinds**; publishes **`CL^k`**; penalty **Ψ(`CL^k`)** to **R**.\n\n**Discipline:** compute both; **do not** collapse them into one “interoperability score.”\n\n See **Annex C.3.A §5 (E‑01)** for the normative evaluation order in guards.\n\n#### C.3.3:7.2 - With membership (C.3.2)\n\nAfter mapping `k` to `k′ = translateₖ(k)`, the **target Context** evaluates membership **as usual**: `MemberOf(e, k′, TargetSlice)`. If the bridge provides a **signature translation**, that definition becomes the **local** `KindSignature(k′)` (versioned per target Context policy).\n\n#### C.3.3:7.3 - With Role masks (C.3.4)\n\nIf a claim uses a **RoleMask(k)** across Contexts, you need:\n\n* a **KindBridge** for `k` (`CL^k` + loss notes), and\n* a documented **mask adapter** (how mask constraints translate).\n  Penalties still land in **R**. If the mask’s effect is stable and widely reused, consider promoting it to a **subkind** on the target side.\n\n#### C.3.3:7.4 - With guards (Annex C.3.A)\n\nUse the **`Guard_XContext_Typed`** macro (Annex C.3.A), which requires **both bridges** and applies **both penalties** to **R**:\n\n* find Scope bridge (CL≥threshold), translate **G**, check coverage;\n* find KindBridge (`CL^k≥threshold`), translate **kind**, check **membership definedness**;\n* apply **Φ(CL)** and **Ψ(`CL^k`)** to **R**; keep **F/G** untouched.\n\n",
        "c.3.3:8___authoring,_review_&_rating_guidance_(informative)": "### C.3.3:8 - Authoring, Review & Rating Guidance (informative)\n\n#### C.3.3:8.1 - Authoring a KindBridge\n\n* **Start narrow & honest.** Declare only the kinds and `⊑` links you **actually preserve**; mark the rest **unknown**.\n* **Prefer named targets.** If the target already has a suitable kind, map to it; use **signature translation** only when necessary, and list what’s preserved vs weakened vs dropped.\n* **Write loss notes in plain language.** Example: “EV vs ICE subkinds collapsed; battery‑health invariants dropped.”\n* **Fix the definedness area.** Bind to target Standards/versions and any environment selectors essential to classification.\n* **Assign `CL^k` from exemplars.** Calibrate on concrete counter‑examples and preserved properties; resist optimistic ratings.\n\n#### C.3.3:8.2 - Review playbook (10 minutes)\n\n1. **Two bridges present?** Scope Bridge **and** KindBridge?\n2. **Order claims honest?** Any `⊑` inversions? Collapses disclosed?\n3. **`CL^k` plausible?** Based on preserved properties, not name similarity?\n4. **Loss notes present?** Will they force narrowing of Scope or extra tests?\n5. **Definedness area clear?** Guard will **fail closed** outside it?\n6. **Penalties wired to R?** No hidden tweaks to **F/G**?\n\n#### C.3.3:8.3 - Rating `CL^k` (rules of thumb)\n\n* **High `CL^k`**: signature equivalence or **up‑to‑iso**; `⊑` fragment preserved; only cosmetic losses.\n* **Medium `CL^k`**: some invariants weakened; selected subkinds collapsed; order preserved on critical path.\n* **Low `CL^k`**: name‑only correspondences; properties diverge; order not preserved. Expect significant **R** penalty and/or adapters.\n\n",
        "c.3.3:9___worked_examples_(informative)": "### C.3.3:9 - Worked Examples (informative)\n\n#### C.3.3:9.1 - Vehicle → TransportUnit (manufacturing)\n\n**Source kind:** `Vehicle` (K2, signature F4).\n**target Context:** `PlantB`, kind `TransportUnit` exists.\n\n**KindBridge:**\n\n* `Vehicle ↦ TransportUnit`; **order**: preserves `PassengerCar ⊑ Vehicle`; **collapses** `EV ⊑ Vehicle` into `TransportUnit` (no EV subkind).\n* **`CL^k=2`** (mid); **loss notes:** “battery‑health invariants not carried”; **definedness:** only for `registryAPI v1.4`, `Γ_time` in last 365 d.\n\n**Use:** Claim quantified over `Vehicle` crosses to `PlantB`.\n**Guards:** scope bridge CL=2 (rig bias); kind bridge `CL^k=2`; both penalties reduce **R**. **F/G** unchanged.\n\n#### C.3.3:9.2 - AuthenticatedRequest across services (software)\n\n**Source kind:** `AuthenticatedRequest` defined by `AuthStandard v2.3`.\n**target Context:** `Frontend` with different auth header scheme.\n\n**KindBridge:** signature translation (`authHeader` → `x‑auth`), preserves “signature valid” property; **`CL^k=3`** (high).\n**Loss notes:** none; **definedness:** only where `AuthStandard v2.3` is in scope.\n\n**Effect:** Rules quantified over `AuthenticatedRequest` can be reused; **R** penalty small (Ψ(3) near 1). Scope remains independent (API v2.3).\n\n#### C.3.3:9.3 - AdultPatient across jurisdictions (clinical)\n\n**Source kind:** `AdultPatient` (≥ 18 at `Γ_time`).\n**target Context:** `JurisdictionY` uses ≥ 21.\n\n**KindBridge:** `AdultPatient ↦ AdultPerson_Y` with boundary mismatch; **`CL^k=1`**.\n**Loss notes:** “Boundary 18 vs 21; map narrows to ≥ 21”.\n**Guard:** Require **mask adapter** or **narrow Scope** to cohorts where DOB is known and ≥ 21. **R** penalty strong; **F/G** remain as declared.\n\n",
        "c.3.3:10___anti‑patterns_&_remedies_(informative)": "### C.3.3:10 - Anti‑patterns & Remedies (informative)\n\n| Anti‑pattern                                 | Why it’s wrong                         | Remedy                                                                              |\n| -------------------------------------------- | -------------------------------------- | ----------------------------------------------------------------------------------- |\n| One “interop score” for both kind & scope    | Blurs channels; corrupts penalties     | Use **two bridges**; apply **Φ(CL)** (Scope) and **Ψ(`CL^k`)** (Kind) **separately** |\n| Claiming preserved `⊑` while inverting order | Makes typed reasoning unsound          | Mark as **not preserved**; add **loss note**; consider adapter or subkind redesign  |\n| Hiding collapses                             | Overstates coverage                    | List collapsed subkinds explicitly; plan extra **R** for lost granularity           |\n| “Latest mapping”                             | Non‑deterministic; non‑auditable       | Version bridges; bind to Standards/versions; **fail closed** outside definedness    |\n| Using KindBridge to widen G                  | Conflates describedEntity with applicability | Keep Scope edits in **USM** (ΔG±); KindBridge never widens Scope                    |\n| Adjusting F/G for poor `CL^k`                 | Violates F–G–R & USM separation             | Route consequences to **R** only; consider narrowing Scope or adding adapters       |\n\n",
        "conformance_checklist": "### C.3.3:11 - Conformance Checklist (normative)\n\n| ID        | Requirement                                                                                                                                          |\n| --------- | ---------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **KB‑01** | A KindBridge **maps** `KindSignature`(s) and an explicitly declared subset of `⊑` links.                                                             |\n| **KB‑02** | A KindBridge **MUST NOT** map Scope; Scope uses USM Bridge (Part B).                                                                                 |\n| **KB‑03** | Bridge records **SHALL** include Contexts/versions, kind mapping/rules, order‑preservation claims, **`CL^k`**, **loss notes**, and **definedness area**. |\n| **KB‑04** | Mapping **MUST** be **deterministic** given fixed versions/rules (no “latest”).                                                                      |\n| **KB‑05** | Preserved order links **MUST** stay **monotone**: `k₁ ⊑ k₂` ⇒ `translateₖ(k₁) ⊑′ translateₖ(k₂)`.                                                    |\n| **KB‑06** | **No inversions**: preserved links cannot invert order; otherwise mark **not preserved** and add loss notes.                                         |\n| **KB‑07** | **Collapses** are allowed but **MUST** list merged subkinds and lost properties.                                                                     |\n| **KB‑08** | **`CL^k`** **SHALL** reuse CL anchors and be labeled **“kind‑congruence.”**                                                                           |\n| **KB‑09** | **Penalties:** when classification uses KindBridge, apply **Ψ(`CL^k`)** to **R**; **MUST NOT** adjust **F/G**.                                        |\n| **KB‑10** | **Chaining:** effective `CL^k` across a chain is **min** (weakest‑link).                                                                              |\n| **KB‑11** | **Loss notes** **SHALL** enumerate non‑preserved invariants and collapsed subkinds.                                                                  |\n| **KB‑12** | **Definedness:** bridge **SHALL** state its valid area; guards **fail closed** outside it.                                                           |\n\n**Integration requirements with Part B (bridges):**\n\n* **B‑P1.** Part B (Bridges) **SHALL** list **KindBridge** as a distinct bridge class alongside USM Scope bridges.\n* **B‑P2.** Part B **SHALL** state that **`CL^k` penalties route to R** via a monotone **Ψ**, never to **F/G**.\n* **B‑P3.** Part B **SHALL** define **chaining = min** for both **CL** and **`CL^k`** (weakest‑link).\n* **Templates.** ESG/Method templates should expose fields for **Scope Bridge (CL)** and **KindBridge (`CL^k`)** with loss notes & definedness.\n",
        "c.3.3:end": "### C.3.3:End\n"
      },
      "content": "### C.3.3:End\n",
      "metadata": {},
      "part": "C",
      "cluster": null
    },
    {
      "id": "C.3.4",
      "title": "RoleMask — Contextual Adaptation of Kinds (without cloning)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## C.3.4 - RoleMask — Contextual Adaptation of Kinds (without cloning)\n\n> **One‑line summary.** Defines **`U.RoleMask(kind, Context)`** as a **context‑local adaptation** of a `U.Kind` that (a) adds **constraints** and/or **vocabulary bindings**, and (b) may **narrow** membership **deterministically** within a `U.ContextSlice`, **without creating a new kind**. RoleMasks are catalogued, versioned, and guard‑addressable; frequent, stable constraint masks **SHOULD be promoted** to explicit **subkinds**. Cross‑context use of a RoleMask requires a **KindBridge** (for kinds) and, when needed, a **MaskAdapter** (for mask constraints). All penalties route to **R**; **F/G** remain unchanged.\n\n\n**Status.** Normative architheory in **Part C**. Identifier **C.3.4**.\n**Audience.** Engineering managers, architects, reviewers, editors.\n\n**Depends on.**\n\n* **C.3.1 — U.Kind & SubkindOf (Core):** kinds are intensional; `⊑` is a partial order; kinds **carry no Scope**.\n* **C.3.2 — KindSignature (+F) & Extension/MemberOf:** signature F; deterministic `MemberOf(e,k,slice)`; `EntitySet(slice)`.\n* **C.3.3 — KindBridge & CL^k:** Cross‑context kind mapping; `CL^k` penalties → **R** only.\n* **A.2.6 — USM (Context slices & Scopes):** Claim/Work scope (**G**) over `U.ContextSlice`; bridges and **CL** for scope.\n* **C.2.2 — F–G–R; C.2.3 — U.Formality (F).**\n\n**Non‑goals.**\n— No repository/notation mandates; conceptual only.\n— RoleMask is **not** a governance tier, data policy, or “mini‑type system.”\n— RoleMask does **not** redefine Scope; context conditions belong to **USM**.\n",
        "c.3.4:1___purpose_(manager’s_view)": "### C.3.4:1 - Purpose (manager’s view)\n\nTeams often need a **local projection** of a widely used kind:\n\n* **Constraint:** “For our procedure, take `Vehicle` **with ABS** only.”\n* **Vocabulary:** “Here, `AuthHeader` is called `X‑Auth`.”\n\nIf each team clones a fresh kind, catalogs fragment and bridges multiply. **RoleMask** is the disciplined alternative: **keep the kind identity**, apply **declared constraints and bindings**, and make the mask **first‑class** (registered, versioned, guard‑addressable). When a mask becomes stable “de‑facto subkind,” **promote** it to `⊑`.\n\n**Benefits:** fewer near‑duplicates, cleaner Cross‑context reuse, deterministic guards, and auditable narrowing instead of hand‑wavy “this is the version we mean.”\n\n",
        "c.3.4:2___context": "### C.3.4:2 - Context\n\nKinds (C.3.1/3.2) name **what** claims quantify over; USM (A.2.6) governs **where** claims hold. In practice, procedures need **local tailoring** of kinds for a role/process (compliance profile, product line, cohort). RoleMask gives that tailoring **without** mutating describedEntity (Kind) or applicability (Scope).\n\n",
        "problem": "### C.3.4:3 - Problem\n\n1. **Kind sprawl.** Teams mint near‑duplicate kinds (“Account\\_PCI”, “Account\\_Ledger”), and alignment decays.\n2. **Hidden constraints.** Informal “we only accept …” statements leak into prose; guards can’t check them deterministically.\n3. **Scope conflation.** Contextual requirements (jurisdiction, API version) get smuggled into “type” talk, blurring Scope vs Kind.\n4. **Cross‑context fragility.** Masks don’t travel unless their constraints are mapped; teams reuse names and hope.\n\n",
        "forces": "### C.3.4:4 - Forces\n\n| Force                                   | Tension to resolve                                                                                           |\n| --------------------------------------- | ------------------------------------------------------------------------------------------------------------ |\n| **Local specialization vs common core** | Need Context‑specific tailoring **without forking** kinds.                                                      |\n| **Expressivity vs determinism**         | Masks must express real constraints **and** be **deterministically checkable** at guard time.                |\n| **Context vs entity constraints**       | Conditions over **ContextSlice** (Scope) vs conditions over **entities** (membership) must be split cleanly. |\n| **Reuse vs proliferation**              | Encourage reuse and promotion to subkind when stable; avoid a mask zoo.                                      |\n\n",
        "solution": "### C.3.4:5 - Solution — **RoleMask** (overview)\n\nA **RoleMask** is a **named, versioned binding** `U.RoleMask(kind, Context)` that:\n\n1. **Adds constraints** (entity‑level predicates only),\n2. **Binds vocabulary/notation** (aliases, field maps) for the Context/process,\n3. **May declare context expectations** (selectors over `U.ContextSlice`, e.g., jurisdiction, API version). **These are enforced via USM Scope guards** (A.2.6) and **do not** change mask membership.\n4. **May narrow membership**: `Extension_mask(k, s) ⊆ Extension(k, s)` (entity‑level narrowing only),\n5. **Never creates a new kind**; identity stays with `k`.\n6. **Is guard‑addressable** and **deterministic** (no “latest”).\n\n**Mask types (declared):**\n\n* **Constraint mask** — adds constraints; may narrow membership;\n* **Vocabulary mask** — aliases only; no membership change;\n* **Composite mask** — both.\n\n**Separation discipline.**\n\n* **Entity‑level predicates** (e.g., “hasABS(x)”) → **mask membership** (narrowing).\n* **Context conditions** (e.g., “jurisdiction=EU”, “API=v2.3”) → **USM Scope** guards (intersection), **not** mask membership.\n  Masks **may carry both kinds** of information, but guards must route them into the **right channel**.\n\n",
        "c.3.4:6___norms_&_invariants_(normative)": "### C.3.4:6 - Norms & Invariants (normative)\n\n> The following formalize and expand **RM‑01…RM‑08** referenced in C.3.\n\n#### C.3.4:6.1 - Definition & Shape\n\n**RM‑01 (Definition).** `U.RoleMask(kind, Context)` **SHALL** be a named, versioned record with:\n(a) **intent** (what role/procedure the mask serves),\n(b) **constraints** (entity‑level predicates; optional context requirements),\n(c) **vocabulary/notation bindings**,\n(d) **membership narrowing** definition (if any),\n(e) **intended guard use**.\n\n**RM‑02 (Not a new kind).** A RoleMask **MUST NOT** introduce a new `U.Kind`. If the domain needs a stable refinement, Contexts **SHALL** publish an explicit `SubkindOf` node (C.3.1).\n\n**RM‑03 (Determinism).** Membership under a mask (if defined) **MUST** be **deterministic** given `slice` and published constraints; implicit “latest” is forbidden.\n\n**RM‑04 (Mask taxonomy).** A mask **SHALL** declare its type: **constraint / vocabulary / composite**.\n— **Vocabulary masks** MUST NOT change membership;\n— **Constraint/composite masks** MAY narrow membership **only via entity‑level predicates**.\n\n#### C.3.4:6.2 - Separation of channels\n\n**RM‑05 (Context vs entity).**\n\n* Predicates about **entities** (features, attributes) MAY narrow membership: `Extension_mask(k, s) ⊆ Extension(k, s)`.\n* Predicates about **ContextSlice** (jurisdiction, Standards, Γ\\_time) **SHALL** be enforced via **USM Scope** guards (A.2.6). Masks **MUST NOT** hide Scope requirements inside membership checks.\n\n**Guard routing.** Enforce ContextSlice predicates via **USM Scope** (A.2.6) and entity predicates via **membership**; see **Annex C.3.A §4.3 (Guard_MaskedUse)** and **§5 (E‑01)** for the normative order of checks.\n\n**RM‑06 (Guard use).** Guards **MAY** reference a RoleMask by name **only** if the mask is **registered, versioned, and its constraints are observable** at guard time. Mask names **MUST NOT** be treated as kind synonyms.\n\n#### C.3.4:6.3 - Promotion & Catalog\n\n**RM‑07 (Promotion rule).** A constraint mask reused broadly and stably **SHOULD** be promoted to an explicit **subkind** with a `⊑` link; retire the mask or keep it as a vocabulary wrapper. Editors **SHALL** track promotions in the catalog.\n\n**RM‑08 (Catalog).** Contexts **SHALL** catalog masks (name, version, type, intent, constraints, bindings, examples, related subkinds, known bridges/adapters). Redundant masks **SHOULD** be consolidated.\n\n#### C.3.4:6.4 - Cross‑context use\n\n**RM‑09 (Bridges & adapters).** If a claim uses `MemberOf(–, RoleMask(k), TargetSlice)` across Contexts, the receiving Context **SHALL** require:\n(a) a **KindBridge** for `k` (`CLᵏ`, loss notes), and\n(b) a **MaskAdapter** — a documented, deterministic mapping of the mask’s **entity‑level constraints** and **vocabulary bindings** into the target Context — whenever those constraints/bindings differ.\nPenalties **MUST** route to **R**: `Ψ(CLᵏ)` for kind, plus any **Φ(CL)** for scope bridge.\n\n**RM‑10 (Definedness & fail‑closed).** Mask evaluation **SHALL** state its definedness area; outside it, guards **fail closed**.\n\n",
        "c.3.4:7___invariants_&_non‑goals_(normative)": "### C.3.4:7 - Invariants & Non‑goals (normative)\n\n* **No Scope leakage.** RoleMasks **cannot** widen/narrow **Claim scope (G)**; any context conditions are enforced by USM guards.\n* **Identity preservation.** The carrier kind remains `k`; RoleMask does not change describedEntity.\n* **Weakest‑link unaffected.** RoleMasks do not alter weakest‑link rules on **F/R**; guards **route entity predicates to membership** and **context predicates to USM Scope**.\n",
        "c.3.4:8___interactions_(informative)": "### C.3.4:8 - Interactions (informative)\n\n#### C.3.4:8.1 - With Kinds & Subkinds (C.3.1)\n\nUse RoleMask for **procedural tailoring**. If the tailoring becomes **conceptual** and stable, **introduce a subkind** with `⊑` and update references.\n\n#### C.3.4:8.2 - With Membership & Signature (C.3.2)\n\n* **Entity‑level constraints** live in mask membership (deterministic).\n* **Signature F** belongs to the kind; raising F in the signature does not auto‑change masks.\n\n#### C.3.4:8.3 - With KindBridge (C.3.3)\n\nA RoleMask crossing Contexts needs **two artifacts**: the KindBridge (`CL^k`, loss notes) and a **MaskAdapter** (how constraints/aliases translate). **R** gets both penalties; **F/G** stay intact. If the adapter systematically narrows membership in the target Context, consider **target‑side subkind**.\n\n#### C.3.4:8.4 - With Guards (Annex C.3.A)\n\nUse **`Guard_MaskedUse`** (Annex **C.3.A §4.3**). It requires:\n— mask registration & determinism;\n— Scope coverage (A.2.6), **Γ\\_time** explicit;\n— where Cross‑context: KindBridge (`CL^k`) + MaskAdapter + penalties → **R**.\n— **Cross‑context combo.** When masks cross Contexts, use **`Guard_MaskedUse`** together with **`Guard_XContext_Typed`** (Annex **C.3.A §4.5**) so both bridges are checked and both penalties (**Φ(CL)** and **Ψ(CLᵏ)**) land in **R**.\n— **Order of checks.** Follow **Annex C.3.A §5 (E‑01)**: typed compatibility first, then Scope coverage, then penalties to **R** and freshness.\n",
        "c.3.4:9___anti‑patterns_&_remedies_(informative)": "### C.3.4:9 - Anti‑patterns & Remedies (informative)\n\n| Anti‑pattern                                      | Why it’s wrong                         | Remedy                                                                                |\n| ------------------------------------------------- | -------------------------------------- | ------------------------------------------------------------------------------------- |\n| Mask as “new type”                                | Duplicates kind; breaks alignment      | Keep the kind; if stable refinement → publish **subkind** (`⊑`).                      |\n| Hiding Scope in mask membership                   | Conflates channels; non‑portable       | Move context conditions to **USM** guards; keep only entity predicates in membership. |\n| Unregistered mask in guards                       | Non‑deterministic; un‑auditable        | Register & version the mask; fail closed otherwise.                                   |\n| Cross‑context use without KindBridge/MaskAdapter     | Silent semantic drift                  | Require **KindBridge** + **MaskAdapter**; apply `Ψ(CL^k)` and any `Φ(CL)` to **R**.    |\n| Mask proliferation (ten masks that mean the same) | Catalog entropy; inconsistent behavior | Consolidate; promote frequently used constraints to **subkinds**.                     |\n| Treating mask name as kind synonym                | Hides constraints; invites misuse      | In prose, say “`RoleMask(k, name)`”; in guards, reference mask fields explicitly.     |\n\n",
        "c.3.4:10___worked_examples_(informative)": "### C.3.4:10 - Worked Examples (informative)\n\n#### C.3.4:10.1 - `Vehicle@ABSOnly` (constraint mask)\n\n**Kind.** `Vehicle` (K2, signature F4).\n**Mask.** `Vehicle@ABSOnly` — entity‑level predicate `hasABS(x)=true`; type **constraint**.\n**Guards.** `MemberOf(–, Vehicle@ABSOnly, TargetSlice)` defined & deterministic; **Scope** (surface/speed/rig/Γ\\_time) checked separately.\n**Promotion?** If ABS‑only becomes a conceptual category, publish `VehicleWithABS ⊑ Vehicle` and retire the mask.\n\n#### C.3.4:10.2 - `AuthenticatedRequest@Frontend` (vocabulary mask)\n\n**Kind.** `AuthenticatedRequest` defined by `AuthStandard v2.3`.\n**Mask.** `@Frontend` binds `authHeader → X‑Auth` (aliases only); **no** narrowing; type **vocabulary**.\n**Cross‑context.** If reused in another Context, require **KindBridge** for the kind; **no** MaskAdapter needed (aliases are local).\n**R.** Only scope bridge penalties apply (if any).\n\n#### C.3.4:10.3 - `AdultPatient@Clinic` (composite mask) across jurisdictions\n\n**Kind.** `AdultPatient` (≥ 18 at `Γ_time`).\n**Mask.** `@Clinic`: entity constraint “DOB present”; context hint “EHR system = X” (this part routes to Scope). Type **composite**.\n**Cross‑context.** Jurisdiction Y uses ≥ 21 → **KindBridge** with `CL^k=1`; **MaskAdapter** maps DOB fields.\n**Guards.** Scope bridge (coding system) + KindBridge + MaskAdapter; penalties **Ψ(1)** (kind) + **Φ(CL)** (scope) to **R**.\n**Outcome.** Allowed with reduced R; consider target‑side subkind `AdultPerson_Y`.\n\n",
        "c.3.4:11___authoring_&_review_guidance_(informative)": "### C.3.4:11 - Authoring & Review Guidance (informative)\n\n#### C.3.4:11.1 - Authoring a RoleMask card\n\n**Fields (suggested).** `name`, `kind`, `type (constraint/vocabulary/composite)`, `intent`, `constraints (entity vs context split)`, `bindings`, `membership definition (if any)`, `definedness`, `examples`, `known bridges/adapters`, `promotion note`.\n**Rules of thumb.**\n\n* Keep entity predicates **small and testable**.\n* Put **context** in Scope, not in membership.\n* If ≥ 3 teams reuse the same constraint mask → **promotion** review.\n\n#### C.3.4:11.2 - Reviewer 7‑point checklist\n\n1. Mask **registered** and **versioned**?\n2. **Type** declared correctly (constraint/vocabulary/composite)?\n3. Entity vs context **split** respected?\n4. **Determinism** (no “latest”) satisfied?\n5. Guard **routes** context to **USM** and entity to **membership**?\n6. Any Cross‑context use has **KindBridge** + **MaskAdapter** with penalties **to R**?\n7. **Promotion** warranted (stable, reused) or consolidation needed?\n\n",
        "conformance_checklist": "### C.3.4:12 - Conformance Checklist (normative)\n\n| ID        | Requirement                                                                                                                                                |\n| --------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **RM‑01** | RoleMask **SHALL** be a named, versioned record with intent, constraints, bindings, membership definition (if any), and intended guard use.                |\n| **RM‑02** | RoleMask **MUST NOT** introduce a new `U.Kind`; stable refinements **SHALL** be modeled as subkinds (`⊑`).                                                 |\n| **RM‑03** | Mask membership (when defined) **MUST** be deterministic given `slice` and mask fields; implicit “latest” forbidden.                                       |\n| **RM‑04** | Mask **SHALL** declare its type: constraint / vocabulary / composite; vocabulary masks **MUST NOT** change membership.                                     |\n| **RM‑05** | Context conditions **SHALL** be enforced via **USM Scope** guards; membership narrowing **MAY** use entity predicates only.                                |\n| **RM‑06** | Guards **MAY** reference a mask only if it is **registered, versioned**, and its constraints are **observable**; mask names **MUST NOT** be kind synonyms. |\n| **RM‑07** | Frequently reused constraint masks **SHOULD** be **promoted** to subkinds; editors **SHALL** track promotions.                                             |\n| **RM‑08** | Contexts **SHALL** catalog masks; redundant masks **SHOULD** be consolidated.                                                                                 |\n| **RM‑09** | Cross‑context masked use **SHALL** declare a **KindBridge** (`CL^k`) and any **MaskAdapter**; penalties **MUST** reduce **R** only.                            |\n| **RM‑10** | Mask definedness **SHALL** be stated; guards **fail closed** outside the defined area.                                                                     |\n",
        "c.3.4:end": "### C.3.4:End\n"
      },
      "content": "### C.3.4:End\n",
      "metadata": {},
      "part": "C",
      "cluster": null
    },
    {
      "id": "C.3.5",
      "title": "KindAT — Intentional Abstraction Facet for Kinds (K0…K3)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## C.3.5 - KindAT — Intentional Abstraction Facet for Kinds (K0…K3)\n\n> **One‑line summary.** Defines **KindAT** as an **informative facet** attached to `U.Kind` that classifies the **intentional abstraction stance** of a kind—**K0 Instance**, **K1 Behavioral Pattern**, **K2 Formal Kind/Class**, **K3 Up‑to‑Iso**—to **guide ΔF/ΔR planning, bridge expectations, catalog/search, and refactoring**. **KindAT is not a Characteristic**: it has **no algebra**, **no thresholds**, and **MUST NOT** appear in guards or composition math. All assurance remains in **F–G–R**; typed semantics remain in **C.3.1–C.3.4**.\n\n**Status.** Mixed:\n— **Informative** for the anchors, heuristics, examples, and guidance.\n— **Normative** for the **usage rules** that forbid employing AT in guards/composition and constrain its placement.\n\n**Placement.** Part C (Kinds), identifier **C.3.5**. Audience: engineering managers, architects, editors, assurance leads.\n\n**Depends on.**\n— **C.3.1** (`U.Kind`, `U.SubkindOf (⊑)`), **C.3.2** (`KindSignature` + F, `Extension/MemberOf`), **C.3.3** (KindBridge + `CL^k`), **C.3.4** (RoleMask).\n— **A.2.6 USM** (Claim/Work scope over `U.ContextSlice`), **C.2.2 F–G–R**, **C.2.3 U.Formality (F)**.\n— **MM‑CHR** distinction **Facet vs Characteristic** (editors).\n\n**Non‑goals.**\n— No numerical scale, no gating, no composition operators, no “quality” scoring.\n— No effect on **F**, **G**, or **R** besides **planning hints**.\n",
        "c.3.5:1___purpose_(manager’s_view)": "### C.3.5:1 - Purpose (manager’s view)\n\nTeams constantly decide **how far to formalize** and **how broadly to validate**:\n\n* *Are we speaking about **this cohort** (instances), about **things that behave like X** (pattern), about a **formal class** with invariants, or about objects **up to isomorphism**?*\n* *Given that stance, should we invest in **F4 predicates**, **F7 proofs**, or **R** across variants?*\n* *What kind of **KindBridge** is realistic (coarse mapping vs up‑to‑iso), and what **`CL^k`** should we expect?*\n\n**KindAT** answers these with a **small, shared vocabulary (K0…K3)** that is **safe to use** (cannot distort F/G/R) yet **actionable** for planning and catalog/search.\n\n",
        "rationale": "### C.3.5:2 - Context & Rationale\n\n#### C.3.5:2.1 - The orthogonality we preserve\n\n* **G (Claim scope)** is **where** a claim holds (A.2.6).\n* **Kinds** give **what** a claim is about (C.3.1/3.2).\n* **R** is assurance (evidence, freshness, penalties).\n* **F** is expression rigor (C.2.3).\n\nTeams often **conflate abstraction with applicability** (“sounds general ⇒ applies broadly”) or **over‑engineer proofs** where **slice‑checks** suffice. AT separates these concerns.\n\n#### C.3.5:2.2 - Why a facet, not a Characteristic\n\nPer **MM‑CHR**, **Characteristics** (e.g., F, G) carry algebra and appear in guards/composition. **KindAT** is only a **tag** on `U.Kind`:\n\n* **No algebra, no thresholds**, not used in guards.\n* **Editorial placement** only: on kinds, not on claims.\n* **Planning signal**: what ΔF and ΔR typically pay off; what bridge style to expect.\n\nThis keeps AT **useful** without risking a “second G” or back‑door quality scores.\n\n#### C.3.5:2.3 - Design choice recap (moved from C.3 §15.2)\n\n* Making AT a Characteristic would **duplicate** G’s role and encourage gating.\n* As a **facet**, AT remains a **catalog/navigation and planning device**, not an assurance dimension.\n\n",
        "c.3.5:3___**anchors_k0…k3**_(informative)": "### C.3.5:3 - **Anchors K0…K3** (informative)\n\n> **How to read.** Each anchor states the **intentional stance** of the kind, **inclusion cues**, **non‑examples** (to prevent misuse), and **planning hints** (ΔF/ΔR/bridge expectations). Anchors are **context‑local editorial tags** on `U.Kind`.\n\n#### C.3.5:3.1 - **K0 — Instance‑level**\n\n**Intent.** The kind denotes **exemplars** or a **tightly curated set**; often a named cohort or a concrete template.\n**Cues.** Membership relies on listing or direct identity features; little to no general invariants.\n**Non‑examples.** Any kind with stable, general invariants belongs in **K2**.\n**Planning hints.** Focus **R on TargetSlice** (executable checks, F5/6); avoid premature proof engineering. Bridges are **instance‑maps**; expect **low `CL^k`** outside the Context.\n\n#### C.3.5:3.2 - **K1 — Behavioral Pattern**\n\n**Intent.** The kind is a **role/behavioral** pattern (“things that act like …”), typically stated via Standards or controlled NL, not a full type.\n**Cues.** “Duck‑typing” flavor; Standards reference behavior/state transitions.\n**Non‑examples.** If you can state global invariants as predicates, consider **K2**.\n**Planning hints.** Invest in **F3→F4** (predicate‑like acceptances); **R** must test **behavioral diversity**; bridges are **pattern maps** with moderate `CL^k`.\n\n#### C.3.5:3.3 - **K2 — Formal Kind/Class**\n\n**Intent.** A **formal class** with explicit **invariants/relations** (ontology class, type with Standards).\n**Cues.** Predicate‑like signature, subkind lattice, invariants reviewed.\n**Non‑examples.** Pure examples/cohorts (K0); informal roles (K1).\n**Planning hints.** Raise **KindSignature F** to **F4+**, consider **F7** for safety‑critical cores; **R** should cover **subkinds/variants**; bridges are **type‑maps**, `CL^k` often medium/high.\n\n#### C.3.5:3.4 - **K3 — Up‑to‑Iso**\n\n**Intent.** Defined **up to isomorphism/equivalence** (category‑theoretic flavor; “equal as structure,” not by identity); equality‑as‑structure matters.\n**Cues.** Statements invariant under isomorphism; reasoning by equivalence classes.\n**Non‑examples.** Classes where identity matters beyond structure.\n**Planning hints.** Expect **up‑to‑iso** bridges; `CL^k` can be high where equivalence is respected. **F7–F9** likely for key properties; **R** focuses on **witnesses of equivalence** at interfaces.\n",
        "c.3.5:4___manager_heuristics_(informative)": "### C.3.5:4 - Manager Heuristics (informative)\n\n| Decision area       | K0                               | K1                          | K2                                         | K3                                      |\n| ------------------- | -------------------------------- | --------------------------- | ------------------------------------------ | --------------------------------------- |\n| **ΔF investment**   | Prefer F5/6 executable semantics | F3→F4 acceptance predicates | F4→F7 (predicates/proofs)                  | F7→F9 (proof‑carrying, higher equality) |\n| **ΔR design**       | Slice‑focused checks             | Behavioral diversity        | Variant/subkind coverage                   | Equivalence witnesses at boundaries     |\n| **Bridge style**    | Instance map                     | Pattern map                 | Type map                                   | Up‑to‑iso / functorial                  |\n| **Expected `CL^k`** | Low outside Context                 | Medium                      | Med/High                                   | High where iso holds                    |\n| **Refactoring**     | Aggregate to K2 when stable      | Crystallize invariants → K2 | Maintain lattice; promote masks → subkinds | Keep iso constraints explicit           |\n\n",
        "c.3.5:5___misuse_&_antidotes_(informative)": "### C.3.5:5 - Misuse & Antidotes (informative)\n\n* **“Higher AT ⇒ wider G.”** *Wrong.* **G** changes only via **ΔG** (USM). AT does not alter scope.\n* **“Gate on AT.”** *Wrong.* Use **F** thresholds and scope/evidence guards; AT is never a gate.\n* **“Depth in `⊑` ⇒ AT.”** *Wrong.* AT is about **intentional stance**, not graph depth.\n* **“AT on claims.”** *Wrong.* AT tags **`U.Kind` only**.\n* **“AT as quality score.”** *Wrong.* Use **F** and **R** for rigor/reliability.\n\n",
        "c.3.5:6___**usage_rules_(normative)**": "### C.3.5:6 - **Usage Rules (normative)**\n\n> These are the **only** normative constraints in this pattern. Everything else is guidance.\n\n**AT‑01 (Facet, not Characteristic).** KindAT **SHALL** be treated as a **Facet** per MM‑CHR: it has **no algebra, no thresholds**, and **MUST NOT** appear in guards or composition math.\n\n**AT‑02 (Placement).** If recorded, KindAT **SHALL** be attached to **`U.Kind`** (or its catalog card). It **MUST NOT** be attached to claims/capabilities or used as a proxy for **G**/**F**/**R**.\n\n**AT‑03 (Editorial discipline).** Editors **SHALL NOT** write text implying “higher AT widens scope” or “higher AT increases rigor/reliability.” Any such text **MUST** be revised to reference **ΔG**/**F**/**R** explicitly.\n\n**AT‑04 (Bridge neutrality).** **KindBridge** records **MUST NOT** compute or adjust AT; they may include *informative* remarks about likely anchor alignment. `CL^k` is independent of AT and is assessed from signature/order preservation.\n\n**AT‑05 (Catalog).** Contexts that use AT **SHOULD** record it in **Kind catalog entries** alongside: signature snippet & **F**, subkinds, RoleMasks, KindBridges. Absence of AT implies **“not set”**, not K0.\n\n",
        "c.3.5:7___authoring_&_review_guidance_(informative)": "### C.3.5:7 - Authoring & Review Guidance (informative)\n\n#### C.3.5:7.1 - How to tag (fast rubric)\n\n* If the card lists **concrete items/cohorts**, tag **K0**.\n* If the card defines **behavioral obligations** in prose/templates but few global invariants, tag **K1**.\n* If the card states **predicates/invariants** and participates in a **subkind lattice**, tag **K2**.\n* If the card explicitly reasons **up to isomorphism**, tag **K3**.\n\n#### C.3.5:7.2 - Review checklist (5 minutes)\n\n1. Is the **carrier** a **`U.Kind`** (not a claim)?\n2. Does the **tag** match the **signature** (intent)?\n3. Are **ΔF**/**ΔR** implications noted for planning (not gating)?\n4. Any **RoleMasks** that should be promoted to subkinds (K2 hygiene)?\n5. Any **Cross‑context reuse** that suggests **bridge style** (pattern/type/iso)?\n\n",
        "c.3.5:8___integration_notes_(informative)": "### C.3.5:8 - Integration Notes (informative)\n\n* **With C.3.1/3.2 (Kinds, Signature, Extension).** AT guides *how* to evolve signature **F** and *what* R coverage is sensible; it **does not** change membership semantics.\n* **With C.3.3 (KindBridge).** AT hints at likely **bridge style** (instance‑map / pattern‑map / type‑map / up‑to‑iso), but **`CL^k`** is still computed from signature/order preservation; penalties route to **R**.\n* **With C.3.4 (RoleMask).** Persistent K1‑style masks often warrant **promotion to K2 subkinds**.\n* **With A.2.6 (USM).** All scope decisions remain under **G**. AT text should never be used to infer coverage.\n* **With C.2.3 (F).** AT does not raise/lower **F**; it **suggests** where raising F is cost‑effective.\n\n",
        "c.3.5:9___worked_mini‑examples_(informative)": "### C.3.5:9 - Worked Mini‑Examples (informative)\n\n* **K0 (Instance).** `Account_US_GAAP_2025_Q1_Cohort`. Plan **R** slice checks; avoid type‑maps across Contexts.\n* **K1 (Behavior).** `CacheableRequest` (“idempotent under retry; cache key well‑formed”). Raise **F3→F4**; design **R** for failure‑mode diversity; expect **pattern bridges**.\n* **K2 (Formal).** `Account` with invariants (balance = debits−credits; posting rules). Raise **F4+**; plan **R** over `Asset`/`Liability` subkinds; bridge via **type maps**.\n* **K3 (Up‑to‑Iso).** `UndirectedGraph` up to node relabeling. Expect **up‑to‑iso bridges**; proofs at **F7+**; **R** checks interface equivalence witnesses.\n\n",
        "conformance_checklist": "### C.3.5:10 - Conformance Checklist (normative)\n\n| ID        | Requirement                                                                                                   |\n| --------- | ------------------------------------------------------------------------------------------------------------- |\n| **AT‑01** | KindAT is treated as **Facet** (no algebra/thresholds); **MUST NOT** appear in guards/composition.            |\n| **AT‑02** | AT **MUST** be attached to **`U.Kind`** only (if used); not to claims/capabilities.                           |\n| **AT‑03** | Editorial text **MUST NOT** imply AT alters **F/G/R**; revise to name **ΔF/ΔG/ΔR** instead.                   |\n| **AT‑04** | KindBridge **MUST NOT** compute/alter AT; `CL^k` is assessed independently.                                   |\n| **AT‑05** | If a Context catalogs AT, it **SHOULD** include it in Kind cards with signature **F**, subkinds, masks, bridges. |\n",
        "c.3.5:end": "### C.3.5:End\n"
      },
      "content": "### C.3.5:End\n",
      "metadata": {},
      "part": "C",
      "cluster": null
    },
    {
      "id": "C.3.A",
      "title": "Typed Guard Macros for Kinds + USM (Annex)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## C.3.A - Typed Guard Macros for Kinds + USM (Annex)\n\n> **One‑line summary.** Provides **normative guard macros** that combine **USM Scope** (A.2.6) with **Kind‑CAL** (C.3.x) so authors can gate state changes and compositions that **quantify over kinds** without conflating **describedEntity** (Kinds) with **applicability** (Scope **G**) or **assurance** (**R**). Includes **decision trees, anti‑patterns, and examples** (informative). **AT (KindAT)** is **never** used in guards.\n\n**Status.** Mixed:\n— **Normative**: guard macro clauses, evaluation order, fail‑closed discipline, conformance checklist.\n— **Informative**: …  decision trees, anti‑patterns, worked examples, macro skeletons.\n\n**Placement.** Part C (Kinds), identifier **C.3.A** (Annex). Audience: engineering managers, editors, reviewers, assurance leads.\n\n**Depends on.**\n— **A.2.6 USM**: `U.ContextSlice`, `U.ClaimScope` (**G**), `U.WorkScope`, ∈/∩/**SpanUnion**/translate, **Γ\\_time** policy, Bridge + **CL** (scope).\n— **C.3.1**: `U.Kind`, `U.SubkindOf (⊑)`; **C.3.2**: `KindSignature` (with **F**) and `Extension/MemberOf`; **C.3.3**: **KindBridge** + `CL^k` (kind‑congruence) & loss notes; **C.3.4**: **RoleMask**.\n— **C.3.5**: **KindAT** (facet) — **explicitly forbidden** in guards.\n— **C.2.2 F–G–R**: weakest‑link, penalties to **R** only; **C.2.3 F**: F0…F9 (expression rigor).\n— **Part B Bridges & CL**: scope bridge semantics and CL ladder.\n",
        "c.3.a:1___purpose_&_audience": "### C.3.A:1 - Purpose & Audience\n\n**Purpose.** Give Contexts a **single set** of guard shapes to:\n(a) **admit** typed claims safely,\n(b) **compose** typed claims/specs,\n(c) **use** RoleMasks properly, and\n(d) **reuse across Contexts** via **both** scope and kind bridges—**without** inventing new scales or conflating **G**, **F**, and **R**.\n\n**Audience.** Engineering managers and reviewers who must read/author guards that are **legible, deterministic, and auditable** in context.\n\n",
        "problem": "### C.13:2 - Problem frame & Problem\n\nFPF presents a unified structural backbone used across disciplines. Historically, sub‑relations like *ComponentOf* or *MemberOf* were **declared** directly. This maximised usability but provided no generative guarantee that a new subtype was extensionally well‑behaved or reducible to common mereology.\n\nDeclared lists of part‑of sub‑relations **scale poorly** and **lack identity guarantees**. Engineers ask for a *single dial* (“is x part of y?”), while ontologists need a principled foundation that (a) avoids Kernel bloat and (b) proves that wholes are nothing over and above their parts. Adding yet another bespoke relation (e.g., *PortionOf*) should not entail schema surgery or ad‑hoc rules.\n",
        "solution": "### C.13:4 - Solution\n\n#### C.13:4.1 - Solution sketch\n\n**Compose‑CAL SHALL provide Γₘ with three and only three constructors:**\n1. **`Γₘ.sum(parts:Set[U.Entity])`** — returns a whole *W* such that each *p* in *parts* stands in **KernelPartOf(p, W)**.\n2. **`Γₘ.set(elems:Set[U.Entity])`** — returns a **collection** *C*; each *e* in *elems* stands in a calculus‑internal **mero:KernelPartOf(e, C)** under **member‑as‑part** semantics (publication alias: typically **`ut:MemberOf`**). **Counts/order** (e.g., parallel/serial factors) are **not carried here**; they live in method/time families adjacent to structure.  *Note:* although `mero:KernelPartOf` is transitive in the calculus, the **published** `MemberOf` alias remains **non‑transitive** by design (see A.14 guards). \n3. **`Γₘ.slice(entity:U.Entity, facet:U.Facet)`** — returns an **aspect** *S* such that **mero:KernelPartOf(S, entity)** and *S* carries the declared **facet**. Temporal facets are excluded here.\n   \n+**Note.** The calculus names an internal backbone **`mero:KernelPartOf`**; the Kernel’s public `ut:PartOf`/**A.14** catalogue remain unchanged. Publish only via Working‑Model aliases (CT2R‑LOG).\n\n+The calculus emits a **trace** for every construction; Structural aliases **MUST** be *grounded by* exactly one such trace.\n\n**Non‑goals (clarifications).**\n* No extra constructors for “parallelism” or “time slices”; parallelism is modelled via **set** (with order handled in `Γ_method`), and temporal parts live in the appropriate temporal/system calculus. This preserves parsimony.\n* Compose‑CAL does not define user‑visible relation names; those belong to the alias layer.\n\n#### C.13:4.2 - Normative Standard (high‑level)\n\n* **C13‑N1.** *Extensional identity.* Two Γₘ results are identical iff they have the same parts under the same constructor and facet conditions.\n* **C13-N2.** *Structural grounding stance.* Every **structural** edge **MUST** reference **exactly one** Γₘ trace as its grounding witness **and SHALL declare `validationMode = axiomatic`** (see B.3.5 / E.14). **Structural edges MUST NOT** be published in `postulate` or `inferential` stances.\n* **C13‑N3.** *Algebraic laws.* `Γₘ.sum` and `Γₘ.set` are **commutative** and **idempotent** over their inputs; `Γₘ.slice` composes only by facet‑compatible refinement.\n* **C13‑N4.** *Acyclicity & antisymmetry.* Structural part‑of induced by Γₘ is transitive, antisymmetric, and acyclic at the level of entities. *(Formal axioms appear later in this pattern.)*\n* **C13‑N5.** *Separation of concerns.* Γₘ provides constructions and traces; naming, aliasing and human‑level relation taxonomies are defined outside Compose‑CAL (see B.3.5 for the CT2R‑LOG handshake).\n* **C13‑N6.** *Member vs component.* `Γₘ.set` yields **collections** whose Working‑Model alias is **MemberOf**; authors **SHALL NOT** infer **ComponentOf** from **MemberOf** without a separate `Γₘ.sum` narrative.\n* **C13‑N7.** *Domain guard.* Do **not** apply Compose‑CAL to roles, methods, or works (see A.12/A.15): these are outside mereology.\n\n#### C.13:4.3 - Scope, applicability, terms & notation\n\n+Use Compose-CAL whenever a claim concerns **structural containment** of entities (assemblies, collections, aspects). Compose-CAL is *not* used for epistemic relations between knowledge artefacts; those are **epistemic** relations and may be justified by **Logical/Mapping** and/or **Empirical Validation** with an explicit `validationMode ∈ {inferential, postulate}`. Compose-CAL is neutral with respect to domain (mechanical, biological, software, etc.).\n\n* **Γₘ** — the mereological construction operator of this calculus.\n* **trace** — a minimal, inspectable witness that a constructor was applied to given inputs to yield a whole (or aspect).\n* **structural part‑of** — the structural relation induced by Γₘ; user‑facing aliases (e.g., *ComponentOf*, *MemberOf*) are separate patterns that **must** point back to traces.\n  \n **Alias readiness.** Typical CT2R mappings:  \n* **ComponentOf** ⇢ `sum` narrative;  \n* **MemberOf** ⇢ `set` narrative;  \n* **AspectOf** ⇢ `slice` narrative;  \n* **PortionOf** ⇢ `slice(entity, facet=\"material/spatial‑region\")` **plus** metrical semantics (A.14);  \n* **ConstituentOf** (logical/content) ⇢ `sum` narrative over conceptual parts. *(Material mixtures are **not** `ConstituentOf`; use `PortionOf` or `ComponentOf` per A.14.)*\n ",
        "c.3.a:4___normative_guard_macros": "### C.3.A:4 - Normative Guard Macros\n\n> **Notation.** “**SHALL**” clauses are normative obligations. “Notes” are informative reminders. Names like `Guard_TypedClaim` are editorial handles; Contexts may alias them, but **MUST** preserve semantics. Macro names (e.g., `Guard_TypedClaim`) are editorial handles; Contexts may alias them provided the logical obligations are preserved.\n\n\n#### C.3.A:4.1 - **Guard\\_TypedClaim** — admit a claim quantified over a kind\n\n**Intent.** Approve a state transition that asserts Claim **C** which quantifies over `U.Kind` **k** at **TargetSlice**.\n\n**Guard\\_TypedClaim(C, k, TargetSlice, thresholds?)** — **SHALL** include, in this order:\n\n1. **ScopeCoverage.** `U.ClaimScope(C) covers TargetSlice`. *(USM A.2.6)*\n2. **Γ\\_time declared.** TargetSlice **SHALL** specify **Γ\\_time** (point/window/policy). No “latest”. *(A.2.6)*\n3. **Kind definedness.** `MemberOf(?, k, TargetSlice)` is **defined and deterministic**. *(C.3.2 K‑05/K‑07)*\n4. **Typed compatibility.**\n   4.1 **same Context**: if C expects `k′`, require `k ⊑ k′`. *(C.3.1)*\n   4.2 **Cross Context**: if Contexts differ, require a declared **KindBridge** that maps `k → k′` and publishes **`CL^k ≥ c`** with loss notes. *(C.3.3)*\n5. **Assurance penalties (R only).** If step 4.2 used a KindBridge, the guard **SHALL** apply a monotone penalty **Ψ(`CL^k`)** to **R**. If a **Scope bridge** was used to move C’s Scope (USM), apply **Φ(CL)** to **R**. *(C.2.2 + C.3.3 + Part B)*\n6. **Evidence freshness (if trust is implied).** Freshness windows and expiry checks **SHALL** be separate predicates (not Scope). *(C.2.2)*\n7. **Formality threshold (if ESG mandates).** If the Context gates rigor, require `U.Formality(C) ≥ F_k`. *(C.2.3)*\n\n**Prohibitions.**\n— **AT forbidden.** KindAT **MUST NOT** appear in this guard. *(C.3.5 AT‑01/02)*\n— **No “domain” placeholders.** Guards **SHALL** name an addressable **TargetSlice**, not a fuzzy “domain”.\n\n\n#### C.3.A:4.2 - **Guard\\_TypedJoin** — compose two typed claims/specs (A → B)\n\n**Intent.** Permit composition where **A** produces facts over `k_A` and **B** consumes `k_B`.\n\n**Guard\\_TypedJoin(A, k\\_A; B, k\\_B; TargetSlice)** — **SHALL** include:\n\n1. **TypedCompat.**\n   1.1 **same Context**: require `k_A ⊑ k_B`.\n   1.2 **Cross Context**: require **KindBridge** mapping `k_A → k′_B` with **`CL^k ≥ c`** and `k′_B ⊑ k_B`.\n2. **ScopeSerial.** Compute `Scope_serial = ClaimScope(A) ∩ ClaimScope(B)`. Require `Scope_serial covers TargetSlice`. *(A.2.6)*\n3. **Penalties (R only).** Apply **Ψ(`CL^k`)** if a KindBridge was used; apply **Φ(CL)** if a Scope bridge was used. *(C.2.2 / Part B / C.3.3)*\n4. **Freshness.** Guard **SHALL** assert required freshness windows for evidence **along the serial path**.\n5. **No type‑by‑scope.** The guard **MUST NOT** widen Scope to “fix” a type mismatch; remedies are subkind introduction, adapter, or bridge.\n\n**Mask awareness.** If B expects a **RoleMask(k\\_B)**: either show A’s outputs already satisfy mask constraints, or add a documented **mask adapter** (see 4.3) and treat any **contextual** constraints as part of **ScopeSerial**.\n\n\n#### C.3.A:4.3 - **Guard\\_MaskedUse** — use a RoleMask with a kind\n\n**Intent.** Use `U.Kind` **k** under a **RoleMask** **m** in Context **R**.\n\n**Guard\\_MaskedUse(k, m, TargetSlice)** — **SHALL** include:\n\n1. **MaskRegistered.** `RoleMask(k, m, version)` is **registered and versioned**. *(C.3.4 RM‑06)*\n2. **MaskDeterminism.** All mask constraints are **observable** on TargetSlice; if the mask narrows membership, it **SHALL** be deterministic. *(RM‑03)*\n3. **MaskType clarity.** Mask **SHALL** declare its type: constraint / vocabulary / composite. *(RM‑04)*\n4. **Promotion cue.** If mask is reused widely as a de‑facto subkind, editors **SHOULD** promote it to an explicit `⊑` link. *(RM‑05)*\n5. **Cross‑context use.** If `TargetSlice.Context ≠ owner(k).Context`, require:\n   5.1 **KindBridge** with **`CL^k ≥ c`**;\n   5.2 **MaskAdapter** (if constraints need translation), deterministic;\n   5.3 Penalty **Ψ(`CL^k`)** to **R**. *(RM‑07 + C.3.3)*\n6. **ScopeCoverage.** `U.ClaimScope(artifact) covers TargetSlice`. *(A.2.6)*\n\n**Prohibitions.**\n— **Mask ≠ Kind.** Guards **MUST NOT** treat the mask name as a synonym for the Kind. *(RM‑06)*\n\n#### C.3.A:4.4 - **Guard\\_SpanUnion\\_Typed** — publish parallel coverage across independent support lines\n\n**Intent.** Publish **SpanUnion** of scopes for **the same typed claim** supported by **independent** lines `L₁…Lₙ`.\n\n**Guard\\_SpanUnion\\_Typed(C, k, {Lᵢ})** — **SHALL** include:\n\n1. **Per‑line discipline.** For each line `Lᵢ`, first satisfy **Guard\\_TypedClaim(C, k, Sliceᵢ)** (or its Cross‑context variant) at the relevant slices/supports.\n2. **Independence justification.** Publisher **SHALL** include a partition or certificate showing that essential components of `Lᵢ` are **disjoint** from `Lⱼ` (no shared weakest link). *(A.2.6 §7.3)*\n3. **Published scope.** `Scope_published = SpanUnion({Sᵢ})`, where each `Sᵢ` is the serial scope for line `Lᵢ`.\n4. **No overreach.** The union **MUST NOT** include slices not covered by any `Sᵢ`.\n5. **Typed consistency.** The **describedEntity** (kind **k**) is **the same** across lines; if not, normalize via subkinds or adapters before union.\n\n**Note.** Independence and union rules are USM‑native; this macro ties them to typed claims without adding new algebra.\n\n\n#### C.3.A:4.5 - **Guard\\_XContext\\_Typed** — Cross‑context typed reuse (both bridges)\n\n**Intent.** Reuse **C** quantified over **k** in another Context’s **TargetSlice**.\n\n**Guard\\_XContext\\_Typed(C, k, TargetSlice)** — **SHALL** include:\n\n1. **Scope bridge.** There **exists** a Scope Bridge **b\\_s** `(source = owner(C).Context, target = TargetSlice.Context)` with **CL ≥ c\\_s**. *(Part B)*\n2. **Kind bridge.** There **exists** a KindBridge **b\\_k** `(source = owner(k).Context, target = TargetSlice.Context)` with **`CL^k ≥ c_k`**. *(C.3.3)*\n3. **Mapped scope coverage.** `Scope′ = translate(b_s, ClaimScope(C))` and `Scope′ covers TargetSlice`.\n4. **Mapped kind definedness.** `k′ = translate(b_k, k)` and `MemberOf(?, k′, TargetSlice)` is **defined**.\n5. **Penalties (R only).** Apply **Φ(CL(b\\_s))** and **Ψ(`CL^k(b_k)`)** to **R**.\n6. **Loss notes.** Publisher **SHALL** attach loss notes from both bridges (rig bias, collapsed subkinds, etc.).\n\n**Prohibitions.**\n— **Do not** “merge” bridges; Scope and Kind are orthogonal channels.\n— **Do not** alter **F** or **G** due to `CL`/`CL^k`; penalties land in **R** only.\n\n",
        "c.3.a:5___evaluation_semantics_&_order_(normative)": "### C.3.A:5 - Evaluation Semantics & Order (normative)\n\n**E‑01 (Order of checks).** Guards **SHALL** check **typed compatibility first** (same‑Context `⊑` or KindBridge), **then** Scope coverage (USM), **then** apply penalties to **R** and verify freshness.\n\n**E‑02 (Determinism).** Given fixed inputs (slices, bridges, versions), evaluation **MUST** be deterministic. “Latest” time, unversioned Standards, or implicit mappings are disallowed.\n\n**E‑03 (Fail‑closed).** Undefined membership (`MemberOf`) or missing bridge **MUST** cause guard failure.\n\n**E‑04 (No AT in guards).** AT is an editorial facet and **MUST NOT** be referenced. *(C.3.5 AT‑01/02)*\n\n**E‑05 (Weakest link on congruence).** For chained bridges, effective **CL** / **`CL^k`** is the **minimum** of links.\n\n**E‑06 (Separation of predicates).** Scope coverage and evidence freshness **SHALL** be distinct predicates; do not fold freshness into Scope or kinds.\n\n**Evaluation order.** Apply checks in the order defined in **§5 (E‑01)**: typed compatibility → Scope coverage → penalties to **R** → freshness.\n\n",
        "conformance_checklist": "### C.13:7 - Conformance Checklist *(normative, calculus‑level)*\n\nThe following regulate **how to think and write** when invoking Compose‑CAL. They are notation‑agnostic and conceptual.\n\n| ID                                         | Requirement                                                                                                                                                                                    | Purpose                                                                 |\n| ------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------- |\n| **CC‑C13‑1 (Three moves only).**           | Authors **SHALL** construct structural narratives using exactly **`Γ_m.sum`**, **`Γ_m.set`**, and **`Γ_m.slice`**. No additional constructors are introduced in this calculus.                 | Preserve **parsimony** and cross‑domain comparability.                  |\n| **CC‑C13‑2 (Kernel invariants).**          | Constructive narratives **SHALL** respect **KernelPartOf** invariants (transitivity, antisymmetry, acyclicity) and yield extensional identity for wholes.                                      | Keep structural identity intelligible and replayable.                   |\n| **CC‑C13‑3 (Algebraic laws).**        | `sum`/`set` are commutative & idempotent; `slice` composes only with facet‑compatible refinement. | Make traces **peer‑reconstructible** and easy to replay in thought. |\n| **CC‑C13‑4 (No order/time in mereology).** | Authors **SHALL NOT** encode execution order, parallelism, or temporal coverage via constructors; such concerns belong to method/time planes and are stated adjacent to structure.             | Maintain the plane firewall.                                            |\n| **CC‑C13‑5 (Narratability).**              | Each constructive trace **SHALL** be narratable in plain language **without introducing new primitives**.                                                                                      | Enforce human‑first clarity; uphold C‑5.                                |\n| **CC‑C13‑6 (Alias alignment).**            | When Publishing Working‑Model relations for structural content, authors **SHOULD** align “sum→ComponentOf”, “set→MemberOf (or pattern‑specific)”, “slice→AspectOf” in their explanatory prose. | Keep alias semantics stable across Contexts.                               |\n| **CC-C13-7 (CT2R-LOG handshake).**     | For every **structural** edge on the Working-Model, authors **SHALL** set `validationMode=axiomatic` and point **`tv:groundedBy`** to exactly **one** Γₘ trace (`sum|set|slice`). *Legacy “Tier-1” wording deprecated; express formality via **F** per C.2.3.* | Clean bridge to the Working-Model alias layer; decouples relation kind from legacy “tiers”. |\n| **CC‑C13‑8 (Member ≠ Component).**         | A **set** output remains a *collection*; authors **SHALL NOT** infer **ComponentOf** from **MemberOf**. When an integrated assembly is intended, provide a separate **`Γ_m.sum`** narrative.   | Prevent membership→component conflation.                                 |\n| **CC‑C13‑9 (Facet explicitness).**         | **Slice** narratives **SHALL** name the **facet** used; temporal facets are excluded (handled elsewhere).                                                                                      | Keep aspects precise and non‑temporal.                                  |\n| **CC‑C13‑10 (No roles in mereology).** | Do not apply Γₘ to `U.Role`, `U.Method`, or `U.Work`; these are outside mereology (A.12/A.15). | Preserve the plane firewall. |\n| **CC‑C13‑11 (Member non‑transitive).** | When publishing `MemberOf`, do not rely on transitive closure across collection‑of‑collections; surface semantics remain non‑transitive per A.14. | Prevent Member→Component drift. |\n\n> **Author’s note.** Compose‑CAL is a calculus for **constructive** reasoning about structure. Publishing remains in the **Working‑Model** layer (see B.3.5); constructive narratives are attached when the team seeks stronger assurance, never as a substitute for clear human‑facing relations.\n",
        "c.3.a:7___decision_trees_(informative)": "### C.3.A:7 - Decision Trees (informative)\n\n**D1 - Admitting a typed claim**\n\n1. **same Context?** If **yes** → check `⊑` (`k ⊑ k′` if expected). If **no** → require **KindBridge**.\n2. **Scope coverage?** Compute `covers(TargetSlice)`.\n3. **Membership defined?** `MemberOf(?, k(′), TargetSlice)` defined? If **no** → deny.\n4. **Bridges used?** Apply penalties **Φ/Ψ** to **R**.\n5. **Freshness?** Check windows. **Optional**: `F ≥ F_k` if ESG mandates.\n\n**D2 - Composing A → B**\n\n1. Typed: `k_A ⊑ k_B` or **KindBridge** to `k′_B ⊑ k_B`.\n2. Scope: `Scope(A) ∩ Scope(B)` covers TargetSlice.\n3. Penalties: apply **Φ/Ψ** to **R**.\n4. Freshness: along serial path.\n5. If **mask** expected: either A implies it or add **mask adapter**.\n\n**D3 - Union across lines**\n\n1. Prove per‑line typed admission.\n2. Provide independence partition.\n3. Publish **SpanUnion**; no extrapolation.\n\n",
        "c.3.a:8___guard_anti‑patterns_&_remedies_(informative)": "### C.3.A:8 - Guard Anti‑patterns & Remedies (informative)\n\n| Anti‑pattern                                     | Why it’s wrong                         | Remedy                                                             |\n| ------------------------------------------------ | -------------------------------------- | ------------------------------------------------------------------ |\n| **Widening G** to “fit” a type mismatch          | Conflates describedEntity with applicability | Introduce subkind, adapter, or KindBridge; keep G honest           |\n| **Using mask name as kind**                      | Hides constraints; breaks determinism  | Register mask; reference constraints; promote to subkind if stable |\n| **Ignoring `CL^k`** in Cross‑context classification | Under‑counts risk; silent drift        | Require KindBridge; apply **Ψ(`CL^k`)** to **R**                   |\n| **Inferring Scope from Extension size**          | Scope ≠ Extension                      | Keep Scope (where) distinct from Extension (which instances)       |\n| **Implicit “latest”** time                       | Non‑deterministic; non‑auditable       | Declare **Γ\\_time** policy explicitly                              |\n| **Gating on AT**                                 | AT is a facet, not a Characteristic    | Replace with ΔF thresholds or Scope/Evidence predicates            |\n\n",
        "c.3.a:9___worked_examples_(informative,_brief)": "### C.3.A:9 - Worked Examples (informative, brief)\n\n> Detailed scenarios remain in **C.3 §11**. This Annex sketches how the macros apply; cross‑reference as needed.\n\n**E1 — Safety braking policy (same Context).**\nUse **Guard\\_TypedClaim**: `PassengerCar ⊑ Vehicle` passes; `ClaimScope` ∩ plant scopes covers TargetSlice; no bridges → no penalties; freshness checked.\n\n**E2 — Cross‑plant reuse (both bridges).**\nUse **Guard\\_XContext\\_Typed**: Scope bridge (CL=2) narrows temp; KindBridge (`CL^k=2`) collapses EV subkind. Apply **Φ(2)**×**Ψ(2)** to **R**; publish loss notes.\n\n**E3 — API rule with adapter.**\nUse **Guard\\_TypedJoin**: producer `Request` → consumer expects `AuthenticatedRequest`. Either prove `⊑` or add adapter; Scope remains separate (API v2.3 with Γ\\_time window).\n\n**E4 — Masked clinic cohort across jurisdiction.**\nUse **Guard\\_MaskedUse** + **Guard\\_XContext\\_Typed**: registered mask, deterministic DOB constraint; KindBridge `CL^k=1`; Scope bridge CL depends on coding; penalties to **R**; Scope narrowed to overlap.\n\n",
        "rationale": "### C.13:9 - Rationale (informative)\n\n**Why exactly three moves?**\n`sum`, `set`, and `slice` are jointly sufficient and minimally overlapping:\n\n* **`sum`** creates an **integrated whole** from parts and thereby establishes **component** structure (assembly identity).\n* **`set`** creates a **collection‑as‑whole**; members are **parts of the collection** under member‑as‑part semantics, but **no component integration** is implied.\n* **`slice`** returns an **aspect as part** of its bearer (facet‑constrained, e.g., spatial/material); temporal facets are excluded here.\n\nAll three moves create new entities; **sum** is the only move that establishes **component** identity. Neither `set` nor `slice` changes the identity of their inputs, and `set` never upgrades membership to component status. Temporal coverage and workflow order are handled in their own planes.\n\nThis separation mirrors long‑standing distinctions between composition, collection, and aspect, while enforcing **parsimony**: no additional constructors are introduced into the Kernel (C‑5). The calculus remains **notation‑agnostic**: its meanings are given in prose and mathematics; any diagrams are illustrative only, in line with the Notational‑Independence guard‑rail (E.5).\n\n**Why constructive grounding lives outside the publication surface.**\nFPF privileges **Working‑Model** relations as the canonical form for communication and design. Compose‑CAL supplies the **constructive shoulder** of the **Assurance Layer**: when authors choose `validationMode = axiomatic`, they narrate the whole as a `sum` of parts (with optional `set` and `slice` scaffolding) and point to that narrative via `tv:groundedBy`. This keeps the text readable while preserving a path to stronger assurance (B.3 family, Authoring Template).\n\n**Why order/time are out of scope.**\nCorrectness‑by‑sequence and temporal coverage are orthogonal to **parthood**. Encoding them as parts breeds contradictions (e.g., “phase‑as‑component”). Compose‑CAL deliberately refuses any “serial/parallel/temporal constructor,” delegating such concerns to `Γ_method` and `Γ_time` and aligning with B.1’s flavour separation.\n\n",
        "c.3.a:end": "### C.3.A:End\n\n## C.13 — Constructional Mereology (Compose‑CAL)\n*(architheory pattern; structural rung of the FPF ladder)*\n",
        "intent": "### C.13:1 - Intent\n\nProvide a single, generative calculus for part–whole structure so that **all** structural relations in FPF are *constructed* (not merely declared) from three primitives and thereby inherit extensional identity by design. The calculus is hidden from day‑to‑day users behind relation aliases; its artefacts are traces that witness how a whole arises from its parts.\n\nAlso known as *“Γₘ mereology”*, *“constructor‑based composition”*.\n\n**Layer.** *calculus.*\n**Depends on.** Kernel only (no upward imports).\n**Consumed by.** CT2R‑LOG (B.3.5) Working‑Model alias logic and any architheory that needs part–whole semantics. Compose‑CAL does **not** import alias definitions; it merely emits traces that others may reference.\n\nCompose‑CAL introduces a **single construction operator Γₘ** with exactly three constructors—**sum**, **set**, **slice**—sufficient to build structural wholes, collections‑as‑wholes, and aspects **without** extending the Kernel’s type set. No “parallel” or “temporal slice” constructor is added. Every construction yields a **trace** that serves as the witness for structure. Human‑facing relations such as *ComponentOf*, *MemberOf*, *AspectOf* are defined elsewhere as **Working‑Model aliases** and are *grounded* in these traces; Compose‑CAL itself remains purely generative and extensional.\n\n",
        "forces": "### C.13:3 - Forces\n\n* **Parsimony (C‑5).** Add no core types if composition suffices; keep the constructor set minimal.\n* **Minimal Kernel (P‑1).** Generativity must live in a plug‑in calculus, not in Kernel axioms.\n* **Cognitive asymmetry.** Everyday users want “one part‑of query”; specialists accept complexity backstage.\n* **Trans‑disciplinary unification.** Every architheory that needs mereology should reuse one *generative* basis.\n* **Green‑field strictness.** With no legacy to break, we can require grounding for new structural edges.\n",
        "archetypal_grounding": "### C.13:5 - Archetypal Grounding *(System / Episteme duo)*\n\n> **Tell–Show–Show.** Compose‑CAL is a thinking‑level calculus for building structural wholes from parts. We *show* it twice—first on a **System** (structural) and then on an **Episteme** case (where constructive grounding is *not* the primary mode).\n\n#### C.13:5.1 - **System** (structural; constructive grounding)\n\n**Story.** A **Skid** is assembled from its **Pump**, **Motor**, **Baseframe**, and **Manifold**.\n\n**Constructive grounding (Γ\\_m).**\nNarrate a *sum* of parts: “Skid = sum{Pump, Motor, Baseframe, Manifold}.” This uses **`Γ_m.sum`** to obtain a whole whose parts stand in **KernelPartOf**; the resulting Working‑Model relation engineers publish is **`ut:ComponentOf`** on each edge from part to whole. The mapping “*sum → ComponentOf*” reflects the intended aliasing between constructive traces and human‑facing mereology.\n\n**Facets and collections.** \nNeed the **inspection surface**? Narrate **`Γₘ.slice(Skid, \"spatial\")`** and publish **`ut:AspectOf`**. Need a group of **Transfer interactions**? Narrate **`Γₘ.set{…}`** and publish **`ut:MemberOf`**—this is a **collection-as-whole**, not a sub‑assembly; no component identity is implied without a separate **`Γₘ.sum`** narrative.\n\n**Plane separation.**\nAssembly **order** and **time** are *not* encoded here: parallel lines and schedules live in method/time families and are described adjacent to, not inside, the part‑tree.\n\n#### C.13:5.2 - **Episteme** (knowledge‑bearing; non‑constructive first)\n\n**Story.** A **Mass‑Flow Representation** is used to stand for a measured flow in a plant dataset.\n\n**Grounding choice.** \nHere the Working‑Model relation (e.g., **RepresentationOf**) is **epistemic**. Authors typically justify it by *inferential* or *postulate* stances (argument or calibration cues), not by a mereological construction; constructive traces remain optional. This preserves the firewall between structure and knowledge claims while keeping a clear path to stronger assurance if the team later reframes part of the representation structurally (e.g., sets of interactions as a **`Γ_m.set`** for a flow bundle).\n\n#### C.13:5.3 - Scope justification\n\n* **Universality.** The trio **sum / set / slice** appears across mechanical assemblies, biological complexes, and organizational artifacts; aliasing to **ComponentOf / MemberOf / AspectOf** provides a stable Working‑Model surface for those domains.\n* **Parsimony.** No “parallel” or “temporal slice” constructor is added; time slices belong in the temporal calculus, and parallelism is modelled as a **set** plus method metadata.\n",
        "bias‑annotation_*(cognitive_anti‑patterns_and_counter‑moves)*": "### C.13:6 - Bias‑Annotation *(cognitive anti‑patterns and counter‑moves)*\n\n| Bias (name)                       | Symptom                                                                                                         | Counter‑move (conceptual)                                                                                                    | Where to look                               |\n| --------------------------------- | --------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------- |\n| **Constructor‑centrism**          | Treating the trace as “the real thing” and the Working‑Model edge (e.g., **ComponentOf**) as merely decorative. | Re‑affirm **Working‑Model first** (publish in `ut:*Of`), then attach constructive narratives only when assurance demands it. | B.3.5 (Working‑Model relations & grounding) |\n| **Collection ↔ Composition swap** | Using **MemberOf** to stand in for **PartOf**, then inferring structural identity.                              | Keep **set** outputs as *collections*; use **sum** for wholes with extensional identity.                                     | A.14 (Advanced Mereology)                   |\n| **Temporal leakage**              | Smuggling sequence/phase into part‑trees.                                                                       | Route order/time to their planes; **no** “temporal slice” constructor in Compose‑CAL.                                        | B.1.\\* (Γ\\_method / Γ\\_time)                |\n| **Over‑slicing**                  | Multiplying aspects until identity becomes opaque.                                                              | Declare the **facet** explicitly; stop when aspects no longer aid recognition of the same whole.                             | A.14 (Aspect/Phase distinction)             |\n| **Feature creep**                 | Proposing a new constructor for a special case.                                                                 | Reduce to **sum / set / slice**; if reduction fails across ≥ 3 domains, reconsider the modelling plane before adding power.  | C‑5 (Parsimony)                             |\n| **Axiomatic inflation**           | Demanding constructive traces for epistemic links by default.                                                   | Use *inferential* / *postulate* where appropriate; reserve *axiomatic* for structural identity.                              | B.3.5 (validation modes)                    |\n\n",
        "consequences": "### C.13:8 - Consequences\n\n**Benefits**\n\n * **Extensional clarity.** Every structural claim is reconstructed from `Γ_m.sum | Γ_m.set | Γ_m.slice`: **sum** establishes component‑assembly identity; **set** establishes collection identity; **slice** yields aspects as parts—without expanding the Kernel.\n* **Human–first publication, formal–on‑demand.** Teams keep publishing **Working‑Model** relations (e.g., `ut:ComponentOf`), while **assurance** is attached as needed via a constructive grounding narrative and `tv:groundedBy` (see B.3.5).\n* **Separation of planes preserved.** Order/parallelism and temporal coverage remain in `Γ_method` / `Γ_time`; structure is never overloaded to carry them, avoiding recurrent category errors.\n* **Uniformity across domains.** The same triad models mechanical assemblies, socio‑technical memberships, and informational wholes without domain‑specific constructors or ad‑hoc exceptions.\n* **Didactic economy.** Authors learn one compact calculus; reviewers gain a predictable place to look for constructive justification when `validationMode = axiomatic` (B.3.5 alignment).\n* **Compositional reuse.** Traces are reusable fragments of reasoning; complex wholes are narratable as sums of sub‑traces, with sets for concurrency and slices for aspect selection.\n\n**Trade‑offs / Mitigations**\n\n* **Discipline cost at higher assurance.** Writing a concise grounding narrative for axiomatic claims takes effort. *Mitigation:* reuse the micro‑templates in this pattern’s Grounding section and keep narratives notation‑free.\n* **Over‑use risk.** Temptation to treat collections as integrated assemblies. *Mitigation:* keep **MemberOf** distinct from **ComponentOf**; both `set` and `sum` yield wholes, but only **`sum`** establishes **component** structure and assembly identity.\n* **Temporal leakage risk.** Authors may try to smuggle time into structure via “temporal slices.” *Mitigation:* use `Γ_time` for temporal statements and `slice` only for intensional aspects, not for time windows.\n\n> **One‑line takeaway.** Compose‑CAL gives a minimal, universal *how‑it‑was‑built* story for any structural edge, without disturbing the human‑first publication surface defined in B.3.5.\n\n",
        "relations": "### C.13:10 - Relations\n\n**Builds on**\n\n* **A.14 Advanced Mereology.** Uses its structural catalogue (Component/Portion/Aspect vs Member) as the *target* of constructive narratives; never collapses Member into Part.\n* **E.5 Guard‑Rails (Notational Independence).** Meanings are given in prose; diagrams are illustrative only.  \n* **E.5 Guard‑Rails (Unidirectional Dependency).** Compose‑CAL depends **downward** only; it never imports alias layers or higher planes.\n* **E.8 Authoring Conventions.** Conforms to the canonical pattern template (Grounding section for architectural patterns; CC placement).\n\n**Coordinates with**\n* **B.3.5 CT2R‑LOG.** `tv:groundedBy` refers (conceptually) to Compose‑CAL traces when `validationMode = axiomatic`; **Working‑Model** relations remain the publication interface.\n* **B.1 flavours.** Keeps order (`Γ_method`) and time (`Γ_time`) outside structure; may co‑appear in narratives when relevant but never as constructors.\n* **Kind-CAL / Lang‑CHR.** Provide the Mapping shoulder of assurance (labels, type alignment) that complements constructive narratives in this pattern.\n* **KD‑CAL.** Provides the Logical shoulder when authors justify relations inferentially instead of constructively.\n* **C.16 (Measurement substrate).** Supplies quantitative hooks when a constructive narrative benefits from explicit counts/ratios (e.g., cardinalities, coverage), while keeping metrics distinct from mereology.\n\n**Constrains**\n* Any architheory that **creates** or **reasons about** structural wholes SHOULD narrate them using only `sum | set | slice`.\n* Structural publication MUST NOT encode order/time; such claims belong to their dedicated flavours.\n* Introducing new structural constructors requires a separate parsimony argument and is discouraged unless the triad cannot narrate the case without ambiguity.\n\n**Provides**\n* A minimal generative basis (`Γ_m.sum | Γ_m.set | Γ_m.slice`) and the corresponding reading discipline for constructive narratives.\n* A stable interface with CT2R‑LOG for `tv:groundedBy` links under `validationMode = axiomatic`.\n",
        "c.13:end": "### C.13:End\n"
      },
      "content": "### C.13:End\n",
      "metadata": {},
      "part": "C",
      "cluster": null
    },
    {
      "id": "C.16",
      "title": "Measurement & Metrics Characterization (MM‑CHR)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## C.16 - Measurement & Metrics Characterization (MM‑CHR)\n",
        "intent_(normative)": "### C.16:1 - Intent (Normative)\n\n**Name.** *Measurement & Metrics Characterization (MM‑CHR).* This is user-oriented name: in user‑facing narrative we say ‘metrics’; in Tech register we speak `U.DHCMethodRef`/`U.Measure`.\n**Intent.** Provide a **transdisciplinary substrate for measurement** that any architheory can rely on: a small, stable set of intensional constructs and relations—**`U.DHCMethodRef`**, **`U.Measure`**, **`U.Unit`**, **`U.EvidenceStub`**—disciplined by **CSLC** (*Characteristic / Scale / Level / Coordinate*) so that every recorded value is **interpretable** and **comparable** across CG‑frames (physics lab time‑of‑flight, figure‑skating judging, architectural modularity, etc.). **C.16** does **not** re‑define **Characteristic** (A.17) nor the CSLC kernel Standard (A.18); instead, it **exports** the measurement substrate that *binds* an architheory’s metric notions to **one Characteristic and one Scale** and frames a **conceptual link to evidence**. This characterization is **notation‑neutral**, **tool‑agnostic**, and **open‑ended** (no “lifecycle” narrative; evolution proceeds via **RSG** moves with checklists). \n\n**Outcomes.**\n(1) A uniform way for architheories to *declare* what is measured and *read* what has been measured; (2) explicit **Characteristic anchoring** and **Scale typing** per CSLC; (3) principled **comparability** and **polarity** (declared at the template level); (4) **traceability** via conceptual evidence stubs; (5) seamless alignment with cross‑domain quantity notions (ISO 80000, ISO/IEC 25024, QUDT, SOSA/SSN, Verspoor) through Unification rows (Part F). \n",
        "scope_&_status_(normative)": "### C.16:2 - Scope & Status (Normative)\n\n**Scope.** **C.16** specifies the **measurement substrate** for FPF architheories: the roles of `U.DHCMethodRef`, `U.Measure`, `U.Unit`, `U.EvidenceStub`; their **CSLC discipline**; the notions of **Scale type**, **polarity**, **comparability**, and **evidence sufficiency** at the level of *conceptual conditions*. It **exports** these constructs for all architheories (KD‑CAL, Arch‑CAL, etc.) without prescribing domain formulae or procedures. \n\n**Status.** **Normative architheory.** C.16 **depends on** A.17 (canonical **Characteristic**) and A.18 (minimal **CSLC** in Kernel). Where C.16 cites external CG‑frames, the stance is through **Part F** rows and **Bridges** (with CL and loss notes), not by vocabulary import. \n\n**Out of scope.** No computational recipes, no workflow prescriptions, no governance/process guidance. C.16 concerns **objects of thought** (intensions) and their **validity conditions**, not records or tooling. (Implementation guidance, if any, belongs outside Part C.)\n\n",
        "problem": "### C.16:3 - Problem & Context (Informative)\n\n#### C.16:3.1 - The problem C.16 solves\n\nAcross architheories, people say “score”, “metric”, “rating”, “property”. Without a shared substrate, numbers drift: *42 of what? on which scale? comparable to whom?* C.16 eliminates drift by requiring every metric notion to **bind** to **one** Characteristic and **one** Scale, and by **separating** intensional anchors from descriptions and ScoringMethods. The result is **portable meaning**: a measure is always readable as a **Coordinate on a declared Scale of a named Characteristic**, with a principled path to evidence. \n\n#### C.16:3.2 - Context and prior art\n\n* **Kernel canon.** A.17 makes **Characteristic** the sole canonical anchor for measurability; A.18 fixes **CSLC** as the minimal sufficiency for interpretability. C.16 relies on both.\n* **Cross‑domain alignment.** The MM‑CHR family already maps FPF U.Types to **ISO 80000‑1 (Quantity)**, **ISO/IEC 25024 (Data‑quality Characteristic)**, **QUDT (QuantityKind/QuantityValue)**, **W3C SOSA/SSN (Observable/Observed/Result)**, and domain “feature/metric” usage (Verspoor, TF Metrics). C.16 uses these rows **as Bridges** (Part F), preserving local senses and documenting losses.  \n* **Open‑ended evolution.** FPF replaces “lifecycle” with **Reachable‑States Graph (RSG)**: movement is along **certified states** with checklists; measurement work adopts the same open‑endedness (re‑entry allowed when distinctions change). C.16 uses RSG to frame **readiness** and **revision** of metric notions conceptually (no processes implied).\n\n",
        "forces": "### C.16:4 - Forces (Informative)\n\n**F1 — Interpretability first.** A value detached from its Characteristic/Scale is meaningless; CSLC supplies minimum context.\n**F2 — Transdisciplinarity.** Physics, architecture, curation, sport judging—*one* substrate must cover all while respecting scale types and polarity.\n**F3 — Intension vs description.** Confusing the **Characteristic** (intensional object) with its rubric or exemplar text (descriptions) corrupts claims; C.16 keeps them distinct.\n**F4 — Comparability without coercion.** Ordinal ≠ interval; ratio admits unit change, ordinal does not; polarity matters for “better/worse”. C.16 encodes these **as conceptual constraints**, not formulas.\n**F5 — Evidence sufficiency.** A measure should be *checkable in principle*; evidence is a **conceptual link** (not storage advice).\n**F6 — Lexical discipline.** One canon in normative register; narrative labels are didactic only (Part E). C.16 reuses E.10’s **register mapping**.\n\n",
        "solution": "### C.16:5 - Solution Outline (Normative)\n\n**S1 — Exported objects.** C.16 **exports** four intensional constructs to be used by any architheory:\n\n1. **`U.DHCMethodRef`** — the *binding* of **one `U.Characteristic`** to **one Scale form**, with declared **polarity** and a conceptual **compatibility claim** (what counts as “same‑scale” for comparison). It is an *intensional specification*, not a record layout.\n2. **`U.Measure`** — an *assertion* that a **subject** occupies a **Coordinate** (or **Level**, if discrete) on that Scale; the measure **references** its template and carries a **conceptual pointer to evidence** (`U.EvidenceStub`).\n3. **`U.Unit`** — the *unit kind* associated with the Scale where applicable (physical quantities, normalized “points”, “stars”, “%”); unit coherence is part of comparability conditions.\n4. **`U.EvidenceStub`** — a *conceptual locator* of grounds for the asserted value (type, identifier, brief summary, optional integrity notion); sufficiency criteria are **conceptual** (see §9, later).\n\n**S2 — Comparability stance.** C.16 states **conceptual comparability** conditions: *same Characteristic*, *compatible Scale type and parameters*, *unit coherence* for interval/ratio; **no** forced coercions for nominal/ordinal; any score‑producing ScoringMethod **must be monotone** w\\.r.t. template polarity. (Details: §7–§8 in later parts.)\n\n**S3 — Evidence stance.** A measure that, by its template, **requires** evidence, is **inadmissible** without a meaningful `U.EvidenceStub`. C.16 defines **what it means conceptually** for evidence to “connect” the subject, the Characteristic, and its symbolic description; mechanisms are out of scope. (Details: §9 in later parts.)\n\n**S4 — RSG framing (open‑endedness).** Readiness, calibration, and revision of metric notions are expressed as **RSG node moves with checklists** (e.g., “characteristic anchored”, “Scale typed”, “Unit coherent”, “ScoringMethod declared”), allowing **re‑entry** when distinctions change; there is no terminal “lifecycle”. (Details: §10, later.)\n\n\n#### C.16:5.1 - Lexical Discipline & Registers (Normative)\n\n**L1 — Canon.** Use **Characteristic / Scale / Level / Coordinate / Score / Unit / ScoringMethod** in **Tech** register; their `U.*` counterparts in **Formal**; narrative labels (e.g., *axis*, *points*, *stars*) are **didactic only** at first‑mention mapped to canon (E.10). \n**L1‑bis — “metric”.** The noun *metric* is **not** a Tech‑register canonical token for measurables; use **Characteristic / Scale / Coordinate / Score / ScoringMethod**. It **may** appear in the architheory title and in the Formal names `U.DHCMethodRef` / `U.Measure`. Do not use *metric* as a synonym for **Characteristic** or **Score** in normative prose.\n**L2 — Intension vs Description.** Keep **intensional objects** (`U.DHCMethodRef`, `U.Characteristic`) distinct from **descriptions** (rubrics, exemplars) and from **claims** (`U.Measure`). No collapsing of names across these layers.\n**L3 — No synonym sprawl.** In normative clauses do **not** substitute *dimension/axis/property/feature* for **Characteristic**; A.17 governs canonicalization. (C.16 inherits A.17’s rename policy.)\n**L4 — Bridge‑only unification.** Cross‑vocabulary sameness appears only via **F.9 Bridges** with **CL** and **loss notes**; C.16’s lexicon is the *source* side for measurement rows.\n**L5 — “Metric” in registers.** In **Tech/Formal** avoid the noun *metric* as a primitive; use `U.DHCMethodRef` / `U.Measure` / **Score**. In **Plain** register *metric* MAY denote “a Template+Measure family” on first mention, with an explicit pointer to canonical terms.\n\n#### C.16:5.2 - Relations (pointers; details later)\n\n**To A.17 / A.18.** C.16 *uses* A.17’s canonical **Characteristic** and A.18’s **CSLC sufficiency**; it neither re‑states nor weakens them.\n**To Part F.** C.16 is the **exporting architheory** behind measurement rows in UTS/Bridges (e.g., **result‑value** ↔ SOSA `Result`, ISO `QuantityValue`).\n**To Arch‑CAL.** Architectural qualities (*Coupling, Cohesion, Evolvability*) become **Characteristics** measured via C.16 templates; architectural dynamics read as trajectories in **CharacteristicSpace** (A.17 context).\n\n#### C.16:5.3 - Normative Core Model (types & Standards)\n\n> **Position.** MM‑CHR does **not** redefine kernel terms; it **binds** them to an architheory‑level Standard that every metric must satisfy. Canonical vocabulary and CSLC duties are inherited from **A.17**/**A.18** and referenced here without duplication.\n> \n> **Source of Truth** A.17/A.18 are the sole sources of truth for Canon and CSLC; C.16 **adopts by reference** and **forbids restatements** of their definitions. C.16 only **exports** `U.*` constructs, comparability stance, evidence semantics, and RSG touch‑points.\n\n##### C.16:5.3.1 - `U.DHCMethod` — the metric definition (normative)\n\n**Role.** An intensional **Standard** that fixes *what is measured* and *how values must be read*—without producing any values itself. It is a *Definition*, not a Measure. **References to this template in data use `U.DHCMethodRef`.**\n\n**R‑MT‑1 (CSLC anchor).** A DHCMethod **SHALL** bind to **exactly one** `U.Characteristic` and **exactly one** **Scale‑form** admissible for that Characteristic (cf. A.18). Level is **optional** (used when the scale is enumerated); otherwise values are given directly as Coordinates.\n\n**R‑MT‑2 (Unit).** If the scale carries units (interval/ratio), the template **SHALL** designate a **Unit** of presentation. For ordinal/nominal scales, unit may be absent or a nominal label (e.g., “stars”). (Old MM‑CHR Annex A already listed these structural elements; here we fix the conceptual obligation. )\n\n**R‑MT‑3 (Polarity).** For any ordered scale, the template **SHALL** declare polarity (*higher‑is‑better / lower‑is‑better / target‑is‑best*), used by downstream ScoringMethods and comparisons (see §6). A **targeted** Scale **SHALL** declare at the Template: (a) the **target value**, (b) the **tolerance semantics** (e.g., symmetric band ±δ, or asymmetric bands), and (c) the **monotone fall‑off** convention outside the band. Any 𝒢 derived from a targeted Scale **MUST** be piecewise‑monotone toward the target and respect the declared tolerance semantics.\n\n**R‑MT‑4 (Applicability).** A template **SHALL** state the **applicability frame** (what kinds of subjects it meaningfully applies to) in conceptual terms; this is a property of the definition, not of any measure.\n\n**R‑MT‑5 (Intension vs description).** The template is an **intensional object**. Any rubric, checklist, or prose that explains it is a **Description**; they are related but not identical (E.10 discipline).\n\n**R‑MT‑6 (Cardinality hint).** A Template **MAY** declare its intended **cardinality semantics** for a subject within a **time stance** (e.g., *latest‑only*, *at‑most‑one‑per‑day*, *time series*).\nWhere declared, claims outside that semantics are **inadmissible conceptually** (they must be reframed or versioned). *Purpose:* prevent silent duplicates and mixed regimes without imposing storage logic.\n\n **R‑MT‑7 (MAY):** “`UncertaintyPolicy` — optional conceptual guidance on how uncertainty is expressed/read (e.g., band/CI/quantile), without prescribing methods/tools.\n    \n\n##### C.16:5.3.2 - `U.Measure` — the recorded reading (normative)\n\n**Role.** A **claim** that a subject occupies a **Coordinate** (or named **Level**) on the template’s scale, backed by a minimal pointer to its grounds.\n\n**R‑ME‑1 (Template binding).** Every Measure **SHALL** reference exactly one DHCMethodRef; its **Value/Coordinate** must be **valid** for that template’s scale (type, range, category).\n\n**R‑ME‑2 (Subject).** A Measure **SHALL** identify its **subject‑of‑measurement** (the bearer) unambiguously in the same Context of meaning as the template’s applicability frame.\n\n**R‑ME‑3 (Evidence stub).** Where the template requires it, a Measure **SHALL** include an **EvidenceStub**—a conceptual pointer sufficient to support independent reasoning about the claim’s origin. (The old spec framed this as “traceability/provenance”; we keep only the **conceptual** role here. )\n\n**R‑ME‑4 (Time stance).** A Measure **SHALL** carry a **time stance** (e.g., “as‑observed at T”, or “as‑aggregated over W”), expressed conceptually; it disambiguates the reading’s intended window without prescribing formats.\n\n**R‑ME‑5 (Entity vs relation).** If the Characteristic is **relational**, the subject is a **tuple** (pair, k‑tuple); the wording of the claim reflects that arity and the template’s relation topology (cf. A.17).\n\nR‑ME‑6 (MAY):** “`UncertaintyStub` — optional conceptual pointer to the adopted uncertainty estimation for this Measure, **if** required by the template.\n\n> *Informative anchor.* The old Annex B example “Article Completeness” illustrates the split template/measure/evidence; **C.16** keeps the split but forbids storage‑level talk.\n\n##### C.16:5.3.3 - `U.Unit` — semantics of quantities (normative)\n\n**Role.** A conceptual marker of **quantity kind** and admissible **conversions** within that kind; not every scale requires it.\n\n**R‑UN‑1 (Quantity kind).** Where units apply, the template **SHALL** indicate the **quantity kind** (e.g., Time, Length, Dimensionless‑Score). Units are meaningful only **within** one kind.\n\n**R‑UN‑2 (Convertibility).** Comparisons across different units are permitted **iff** they are **convertible** by kind‑preserving transformation (ratio/interval scales); for ordinal/nominal scales, no numeric conversions exist. (Old Annex A listed conversion hints; here we assert the conceptual boundary. )\n\n**R‑UN‑3 (Canonical labels).** `%` denotes “fraction×100”; “points” denotes dimensionless magnitudes used for scores; “stars” denotes discrete ordinal marks. These are **labels** of representation, not new characteristics.\n\n**R‑UN‑4 (Quantity‑kind bridge).** A Template on an interval/ratio Scale **SHOULD** name the underlying **quantity kind** (e.g., ISO 80000/QUDT category) to enable safe external bridges. This does **not** import external vocabularies; it declares an alignment point.\n\n##### C.16:5.3.4 - `U.EvidenceStub` — pointer to grounds (normative)\n\n**Role.** A compact **tie** from a Measure to the grounds sufficient for **reasoned audit** (not a repository prescription).\n\n**R‑EV‑1 (Minimal sufficiency).** An EvidenceStub **SHALL** carry, at minimum, a **type‑of‑ground** and an **identifier** sufficient to retrieve or reconstruct the grounds in the appropriate Context of meaning.\n\n**R‑EV‑2 (Compositionality).** Multiple grounds may be **composed** as a finite set; composition is **commutative/associative/idempotent** at the level of stubs, enabling conceptual merge of corroborations.\n\n**R‑EV‑3 (Soundness axiom).** A Measure **is admissible** only if at least one **auditable chain of grounds** can be stated from the bearer to the Characteristic via an appropriate Description (Object–Concept–Symbol triangle in the episteme). (The old text motivates “transparency/trust”; **C.16** states the conceptual admission rule. )\n\n#### C.16:5.4 - Polarity, Comparability, and ScoringMethods (normative)\n\n> **Notation.** To avoid clashes with the kernel’s global aggregation symbol, this architheory denotes a **ScoringMethod** (score‑level mapping) by **𝒢** (calligraphic 𝒢).\n\n**R‑POL‑1 (Declared polarity).** Every ordered scale **SHALL** declare polarity at the **template**. Any **ScoringMethod** **𝒢** must be **monotone** with that polarity.\n\n**R‑CMP‑1 (Comparability conditions).** Two readings are **directly comparable** when they share **Characteristic**, **scale type**, and **unit** (or unit is convertible within one quantity kind). Otherwise, comparability requires an explicitly declared **𝒢** on a common representation.\n\n**R‑G𝒢‑1 (ScoringMethod disclosure).** If a metric issues a **Score**, its **ScoringMethod** **𝒢 : Coordinate → Score** **SHALL** be named with a **bounded codomain** and stated monotonicity. (The old text discussed “score ranges” and mapping; **C.16** keeps only the conceptual duty. )\n\n**R‑G𝒢‑2 (Ordinal respect).** For ordinal inputs, **𝒢** must be **order‑preserving**; interval assumptions **MUST NOT** be smuggled in.\n\n\n#### C.16:5.5 - Entity vs Relation bindings (normative clarifications)\n\n**R‑ER‑1 (Arity preservation).** If the Characteristic is `U.EntityCharacteristic`, the subject is **one** bearer; if `U.RelationCharacteristic`, the subject is a **k‑tuple** (k ≥ 2). The Measure’s claim text **SHALL** reflect this arity.\n\n**R‑ER‑2 (Relation scale).** Relation‑valued scales **SHALL** fix their symmetry/antisymmetry and directionality (e.g., distance symmetric; influence directional), at the **template** level.\n\n**R‑ER‑3 (Bridge to CG‑frames).** In architectural CG‑frames, **Coupling/Cohesion** are Characteristics over **modules** (structure) or **roles** (function). Their measures are relational (**Coupling**) or unary (**Cohesion** within an element), but both live in the same MM‑CHR substrate. (Alignment hinted in the old mapping rows across contexts. )\n\n\n#### C.16:5.6 - Acceptance (conceptual, RSG‑aware)\n\n> Acceptance here is **thought‑level**. It uses the **Reachable‑States Graph (A.2.5)** pattern to organise mental checks—no “lifecycle” narratives.\n\n**SCR‑C16‑A (Template sufficiency).** You can traverse **N1→N3** (Characteristic fixed → Scale typed → Unit coherent) for the template **without** invoking any implementation artifacts (cf. A.18 RSG alignment).\n\n**SCR‑C16‑B (Reading sufficiency).** For a given subject, you can traverse **N4→N6** (ScoringMethod named where needed → exemplar‑anchored sense → reading established) with polarity and arity explicit.\n\n**SCR‑C16‑C (Comparability).** When two readings are placed side‑by‑side, you can state in one breath whether they are **comparable as‑is** or only **after 𝒢**, and **why**.\n\n**SCR‑C16‑D (Evidence adequacy).** For any required EvidenceStub, you can sketch at least one **auditable chain of grounds** from the subject to the Characteristic via a Description in the right Context.\n\n\n#### C.16:5.7 Cross‑references & anchors\n\n* **A.17 (CHR‑NORM).** Canonical **Characteristic** and Entity/Relation split; lexical rules and alias sunset.\n* **A.18 (CSLC‑KERNEL).** One Characteristic + one Scale per template; Level optional; operation guard by scale type.\n* **Annex C (old MM‑CHR).** Cross‑domain alignment hints for Characteristics/Observations/Quantities across ISO 80000, ISO/IEC 25024, QUDT, SOSA/SSN (used here only as conceptual witnesses).\n",
        "permitted_operations_by_scale_type_(with_anti‑examples)": "### C.16:6 - Permitted operations by scale type (with anti‑examples)\n\n| Scale type   | Comparisons    | Location          | Differences        | Ratios                   | Admissible summaries                                  | Typical anti‑patterns (forbidden)                                   |\n| ------------ | -------------- | ----------------- | ------------------ | ------------------------ | ----------------------------------------------------- | ------------------------------------------------------------------- |\n| **Nominal**  | =, ≠           | mode, frequencies | —                  | —                        | counts, proportions                                   | averaging labels; ordering categories without a declared order      |\n| **Ordinal**  | <, =, > (rank) | median, quantiles | **not meaningful** | —                        | order‑respecting summaries (median rank, percentiles) | arithmetic mean of ranks; variance on ranks; linear blends of ranks |\n| **Interval** | <, =, >        | mean location     | Δ meaningful       | ratio **not** meaningful | mean, sd of **differences**, correlation              | ratio claims (“twice as hot” in °C); geometric mean                 |\n| **Ratio**    | <, =, >        | mean location     | Δ meaningful       | ratios meaningful        | arithmetic/geometric means, cv, growth rates          | adding heterogeneous units; log on nonpositive values               |\n\n**Guards.**\nG‑1 (Order). On ordinal, any transform used inside 𝒢 **MUST** be **monotone**.\nG‑2 (Differences). On interval/ratio, **Δ** is legitimate; on ordinal/nominal, it is **undefined**.\nG‑3 (Ratios). Only ratio Scales admit **x/y** semantics; interval/ordinal/nominal do not.\nG‑4 (Unit coherence). Interval/ratio arithmetic presumes compatible units (or declared conversion).\nG‑5 (Target polarity). If polarity is “targeted”, comparison is via distance‑from‑target, not simple ↑/↓.\n\n*(These rules line up with the MM‑CHR exposition of CSLC and term discipline; A.17 fixes the lexical side.)* \n",
        "evidence_semantics_(normative)": "### C.16:7 - Evidence Semantics (Normative)\n\n#### C.16:7.1 - What an Evidence Stub is (and is not)\n\n**Definition.** `U.EvidenceStub` is a **conceptual pointer** that ties a **measure** to the **grounds** sufficient for independent checking (observations, arguments, lawful transformations). It is not the run log, not the carrier, and not the intensional characteristic itself. This keeps **intension–description–specification** distinct per E.10.D2 and the Clarity Lattice.\n\n**Rule Σ‑1.** Whether evidence is **required** is a **property of the metric template**; if required, each `U.Measure` **SHALL** include an `U.EvidenceStub`.\n**Rule Σ‑2.** Evidence composition is **commutative, associative, idempotent** at the concept level (sets/multisets of grounds); combining grounds can never *reduce* what is knowable about the measure’s warrant.\n**Rule Σ‑3.** *Soundness minimum:* there exists a conceptual chain linking **bearer → Characteristic → Scale/Unit → admissible method/episteme**. (No “free‑floating numbers”.)\n**Rule Σ‑4.** Declared *agreement* constructs (e.g., dual readings, panels) **MUST** be appropriate to the scale type (rank concordance for ordinal; tolerances for interval/ratio).\n*Anchors:* MM‑CHR units/evidence notion; Strict Distinction and the separation of objects from their descriptions/specs.\n\n",
        "integration_with_rsg_&_dynamics_(normative/clarifying)": "### C.16:8 - Integration with RSG & Dynamics (Normative/Clarifying)\n\n#### C.16:8.1 - RSG (Role‑State Graph) touch‑points\n\nMM‑CHR **supplies recognisers** used in **State Checklists**. A checklist criterion **may** refer to a measure (e.g., “Cohesion ≥ T on ordinal ladder”), but the **state itself remains intensional**; the checklist is its **description**, and a **StateAssertion** is an evidence‑backed verdict over a Window. No lifecycle language is implied; RSGs are open‑ended graphs with re‑entry edges.\n\n**Rule RSG‑M1.** When a checklist cites a measure, it **SHALL** do so by **Characteristic + Scale semantics** (and unit if applicable), not by colloquial aliases; Tech/Formal registers apply. **Rule RSG‑M2.** Thresholds in checklists **MUST** respect the scale type (no ratio talk on interval scales; no arithmetic on ordinal ladders).\n\n#### C.16:8.2 - Dynamics & CharacteristicSpace\n\n`U.Dynamics.stateSpace` is a **CharacteristicSpace**—a named set of Characteristics with units/topology. MM‑CHR provides the **measurement side** of that space; architheories specify the **transition law**. Architectural or epistemic **dynamics** are then *trajectories in the declared CharacteristicSpace*. **No** procedural or storage commitments are implied.\n",
        "conformance_checklist": "### C.16:9 - Conformance Checklist (Normative)\n\n> *Thought‑level acceptance conditions for authors and reviewers; they constrain meaning, not tooling.*\n\n**CC‑MCHR‑1 - CSLC anchoring.** Each `U.DHCMethodRef` binds **exactly one** `U.Characteristic` and **exactly one** scale; each `U.Measure` carries a value valid for that scale (cf. A.18).\n**CC‑MCHR‑2 - Polarity declared.** Every **ordered** scale in a template declares **polarity**; any **Score** via 𝒢 is monotone w\\.r.t. that polarity.\n**CC‑MCHR‑3 - Unit coherence.** Claims that compare or combine values are **grounded in unit coherence** (or declared conversions for interval/ratio).\n**CC‑MCHR‑4 - Comparability honesty.** Ordered comparisons are asserted **only** when §7.2 holds; otherwise authors use qualitative/set‑level language.\n**CC‑MCHR‑5 - Evidence sufficiency.** Where evidence is required by the template, the measure’s grounds are **conceptually sufficient** to retrace the claim; composition respects Σ‑laws (§8).\n**CC‑MCHR‑6 - RSG alignment.** If a measure gates a **state** in an RSG, the checklist criteria **respect scale semantics** and the **intensional vs description** split. No lifecycle phrasing; use RSG open‑ended moves.\n**CC‑MCHR‑7 - Dynamics awareness.** Where discussions involve change, the **CharacteristicSpace** is **named** (characteristics, units, topology) and separated from the **transition law** (architheory side).\n**CC‑MCHR‑8 - Lexical guard‑rails.** Tech identifiers and headings use **Characteristic/Scale/Level/Value/Score/Unit/ScoringMethod**; aliases (axis/dimension/points/stars) appear **only** in explanatory Plain register with a first‑mention mapping to the Tech canon.\n",
        "invariants_&_anti‑patterns_*(normative_unless_marked_“informative”)*": "### C.16:10 - Invariants & Anti‑Patterns *(Normative unless marked “Informative”)*\n\n#### C.16:10.1 - Invariants (N‑rules)\n\n**N‑1 — One Characteristic + one Scale per template.**\nEvery `U.DHCMethodRef` binds *exactly one* **Characteristic** and *exactly one* **Scale** (its type + admissible range or level‑set). This is the CSLC sufficiency condition for interpretability.\n\n**N‑2 — Value validity.**\nA `U.Measure` holds a **Value** that is *admissible* for the template’s Scale (numeric range, categorical level); when a **Level** is used, it is among the named rungs declared for that Scale.\n\n**N‑3 — Polarity is declared at the template.**\nFor ordered Scales, the template states the comparison direction (↑ better / ↓ better / target‑is‑best). Any **ScoringMethod mapping** to **Score** preserves that monotonic ordering. *(Note: we use “ScoringMethod mapping” instead of the Greek letter used elsewhere in FPF to avoid symbol conflicts.)*\n\n**N‑4 — Unit coherence.**\nWithin one template there is one *primary* **Unit** of expression (or an explicit level‑set for non‑numeric Scales). Conversions are conceptually allowed only where the Scale supports meaningful arithmetic (interval/ratio); nominal/ordinal Scales are not subject to numeric conversions.\n\n**N‑5 — Comparability guard.**\nTwo Measures are comparable *iff* they share the same template (hence, the same Characteristic + Scale + Unit) **or** stand in an explicit equivalence declared via the Unification suite (F‑cluster Bridges). Otherwise, comparability is not presumed.\n\n**N‑6 — Evidence as conceptual anchoring.**\nIf a template requires it, each Measure includes an **EvidenceStub** that conceptually links the Value to its grounds; absence where required makes the Measure inadmissible for use. *(This is a conceptual obligation; no process mechanics are implied.)*\n\n**N‑7 — Arity clarity.**\nIf the Characteristic is relational (applies to a pair/tuple), the subject of measurement is the relation itself; the reading must not be re‑described as a unary property of either participant.\n\n**N‑8 — Open‑ended evolution; graph, not lifecycle.**\nWhen MM‑CHR is used in change reasoning, movement happens in a **CharacteristicSpace** and along a reachable‑states graph (RSG). There is no lifecycle terminal; revisions may re‑enter earlier framing nodes as per A.17. *(Conceptual control structure only.)*\n\n\n#### C.16:10.2 - Anti‑Patterns (A‑rules) — with cures\n\n**A‑1 — Scale drift under the same template.**\n*Smell:* the Scale meaning (bounds, categories) shifts while the template ID remains.\n*Cure:* version the template; declare the relation in the Unification suite.\n\n**A‑2 — Arithmetic on ordinal.**\n*Smell:* averaging “stars” or ranking labels as if they were intervals.\n*Cure:* either keep order‑respecting operations only, or introduce a **ScoringMethod** that defines a proper Score range.\n\n**A‑3 — Unit soup.**\n*Smell:* mixing milliseconds and seconds for the same template, or “%” and “points” for one Scale.\n*Cure:* one primary Unit per template; conversions (when meaningful) are declared conceptually, not ad‑hoc.\n\n**A‑4 — Alias leakage.**\n*Smell:* “axis/dimension/point/ladder” in normative identifiers or headings.\n*Cure:* use only canonical tokens in normative prose; narrative labels are allowed *solely* in Plain register with first‑mention mapping (A.17).\n\n**A‑5 — Multi‑Characteristic stuffing.**\n*Smell:* one template tries to carry a vector of Values for several Characteristics.\n*Cure:* separate templates (one Characteristic each) and compose coordinates explicitly when needed.\n\n**A‑6 — Evidence afterthought.**\n*Smell:* Measures required to have grounds are introduced without an intelligible EvidenceStub.\n*Cure:* treat the EvidenceStub as part of the measurement claim itself, not an accessory.\n\n**A‑7 — Template mutation after Measures exist.**\n*Smell:* retro‑editing Characteristic/Scale/Unit of an active template.\n*Cure:* immutability of that triad post‑use; publish a successor template if the concept changes.\n\n**A‑8 — Score‑of‑everything.**\n*Smell:* collapsing heterogeneous Values into a single “points” Score without declared ScoringMethod and SCP.\n*Cure:* retain the Value on its Scale; add an explicit ScoringMethod and SCP only when there is a justified need for a Score.\n",
        "cross‑domain_vignettes_*(informative,_transdisciplinary)*": "### C.16:11 - Cross‑Domain Vignettes *(Informative, transdisciplinary)*\n\n> *Each vignette shows an CSLC‑conformant template → measure, without duplicating the A.17/A.18 glossaries.*\n\n**V‑A (Architecture — relational property).**\nCharacteristic: **Coupling** (relational) between modules; Scale: ordinal {Low, Med, High}; Unit: level‑labels; Polarity: ↓ better.\nReading: subsystem pair ⟨M₁, M₂⟩ gets **Med**; **ScoringMethod** (optional) maps levels monotonically to a bounded Score for comparative dashboards.\n\n**V‑B (Physics — interval/ratio).**\nCharacteristic: **ResponseTime**; Scale: ratio with non‑negative reals; Unit: seconds; Polarity: ↓ better.\nReading: subject S has **0.237 s**; comparability holds with any template that declares the same Characteristic+Scale+Unit (or an explicit equivalence).\n\n**V‑C (Performing arts — ordinal).**\nCharacteristic: **EdgeControlQuality**; Scale: ordinal levels 1…5; Unit: level‑labels; Polarity: ↑ better.\nReading: performance P gets **4**; any aggregation uses a declared ScaleComplianceProfile (SCP) that respects order.\n\n**V‑D (AI ethics — ratio).**\nCharacteristic: **ParityGap** (difference of positive rates); Scale: interval with symmetric bounds; Unit: percentage points; Polarity: ↓ better (0 is target).\nReading: model M on cohort C shows **3.2 pp**; evidence points conceptually to the derivation rationale (inputs, reference cohorts).\n",
        "relations": "### C.16:12 - Relations & Placement *(Informative)*\n\n**Kernel.** MM‑CHR *imports* the canonical Characteristic vocabulary and the CSLC discipline fixed by A.17 and A.18; it does not redefine them. CharacteristicSpace reasoning (for change) lives in the architheories that consume MM‑CHR readings.\n\n**Using architheories.** KD‑CAL, Arch‑CAL and others *instantiate* templates and produce measures; MM‑CHR remains a neutral measurement substrate. Trade‑off analyses and architectural trajectories operate over coordinates that MM‑CHR makes available, not inside MM‑CHR.\n\n**Unification (F‑cluster).** External standards (e.g., ISO 80000 quantity types; W3C SOSA/SSN observable properties; QUDT units/quantity kinds) are related via Concept‑Set rows and Bridges; MM‑CHR treats those alignments as context supplied by F‑patterns, not as local re‑definitions.\n",
        "c.16:end": "### C.16:End\n"
      },
      "content": "### C.16:End\n",
      "metadata": {},
      "part": "C",
      "cluster": null
    },
    {
      "id": "C.17",
      "title": "Characterising Generative Novelty & Value (Creativity‑CHR)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## C.17 - Characterising Generative Novelty & Value (Creativity‑CHR)\n\n**Status.** Architheory specification (**CHR**) — normative where stated.\n**Depends on.** A‑kernel (A.1–A.15), **CHR‑CAL** (C.7), **MM‑CHR** measurement infrastructure (C.16), **KD‑CAL** and **Sys‑CAL** for carriers and holons, **Decsn‑CAL** (utility), **Norm‑CAL** (constraints/ethics).\n**Coordinates with.** **B.5.2.1 NQD** (abductive generator) for search instrumentation, **Agency-CHR** (C.9) for agential capacity, B-cluster trust/assurance (B.3), Canonical Evolution Loop (B.4), Role Assignment & Enactment Cycle (Six-Step) (F.6) and Naming Discipline for U.Types & Role Names (F.5).\n**Guard‑rails.** Obeys E‑cluster authoring rules (Notational Independence; DevOps Lexical Firewall; Unidirectional Dependency).\n\n**What this architheory provides (exports):**\n\nThis architheory exports **Characteristics** and measurement templates **only**. It **does not** export any Γ\\_\\* operators, portfolio composition rules, or selection/scalarization policies; those live in **C.18 NQD-CAL** and **C.19 E/E-LOG** (or **Decsn-CAL** for decision lenses). A Context _publishes_ the measurement space and admissible policies; a decision is taken by an _agent in role_ using a _named lens_ within that space.\n\n* **`U.CreativitySpace`** — a **CharacteristicSpace** (CHR) with named **Characteristics** and scale metadata for evaluating creative work/outcomes **inside a `U.BoundedContext`**.\n* **`U.CreativityProfile`** — a vector of coordinates in `U.CreativitySpace` attached by a **`U.Evaluation`** to a specific **Outcome** (usually an `U.Episteme` produced by `U.Work`).\n* **Core Characteristics (kernel nucleus; Context‑extensible):**\n1. **`Novelty@context`** — distance from a **`ReferenceBase`** in the current Context/time window; ∈ \\[0, 1].\n2. **`Use‑Value`** *(alias: `ValueGain`)* — measured or predicted improvement against a **declared objective**; interval/ratio scale per Context.\n3. **`Surprise`** — negative log‑likelihood under a **GenerativePrior**; bits or nats.\n4. **`ConstraintFit`** — degree of **must‑constraint** satisfaction (Norm‑CAL / Service acceptance); ∈ \\[0, 1].\n5. **Diversity_P (portfolio-level)** — coverage/dispersion (set-level). **Illumination** is a **report-metric over Diversity_P** (coverage/QD-score summaries). It is **report-only** and **never** part of the primary dominance test.\n6. **`AttributionIntegrity`** — provenance/licensing discipline for lawful, transparent recombination; ∈ \\[0, 1].\n7. **`FamilyCoverage`** — (count, polarity ↑, scope=portfolio, unit=families, provenance: F1‑Card)\n8. **`MinInterFamilyDistance`** — (ratio [0,1] or metric units, polarity ↑, scope=portfolio, DistanceDef@F1‑Card)\n9. **`AliasRisk`** —  (ratio [0,1], polarity ↓, diagnostic; drop if dSig ≥3/5 characteristics collide)\n10. **`U.DomainDiversitySignature (dSig)`** — 5‑tuple over discrete characteristics **[Sector, Function, Archetype, Regime, MetricFamily]**  attached to each `U.BoundedContext`. Used for **Near‑Duplicate** diagnostics and `AliasRisk`. Policy: flag as Near‑Duplicate when ≥3 characteristics match; see F.1 invariants and SCR‑F1‑S08..S09. \n11. **Note (AliasRisk binding).** `AliasRisk` MAY be computed using `dSig` collision diagnostics; a Context MUST declare the collision rule and policy id in DescriptorMap provenance when AliasRisk is reported.\n\n* **Supporting types (linking points):**\n\n  * **`U.ReferenceBase`** — the domain‑local corpus (by Context & time window) used to compute `Novelty@context`.\n  * **`U.SimilarityKernel`** — a declared similarity metric class for the Context (text/image/design/code/etc.), with invariance notes.\n  * **`U.GenerativePrior`** — a predictive model over the Context’s artifacts/behaviours used to compute `Surprise`.\n  * **`U.CreativeEvaluation`** — a specialisation of `U.Evaluation` that yields a `U.CreativityProfile` and the Evidence Graph Ref.\n  * **`EffortCost`** *(advisory)* — resource outlay to achieve the outcome; from WorkLedger (Resrc‑CAL). *(For normalization and planning; not itself “creativity.”)*\n\n* **Operators (first tranche):** `composeProfiles` (set → portfolio), `dominates` (partial order in space), `frontier` (Pareto set), `normaliseByEffort`. *(Formal laws introduced in Quarter 2.)*\n* **Relations (informative; not exported):** dominance relation (partial order in the space), frontier predicate (Pareto set), portfolio composition view. *C.17 exports no operators; these are mathematical relations only.*\n* \n> **Scope note.** This architheory **does not** define who is “a creative person.” It characterises **creative outcomes and episodes** as **observed in Work** and **expressed as Epistemes**. Agency (capacity to originate) is measured in **Agency‑CHR (C.9)**; here we measure **what came out** and **how it scores** against stated goals and references.  A **Context publishes** the measurement space and admissible policies; a **decision is made by an agentic system in role**, using a named lens within that space. CHR exports **no Γ‑operators** and **no team workflow rules**.\n",
        "motivation_&_intent_(manager’s_read‑first)": "### C.17:1 - Motivation & Intent (manager’s read‑first)\n\n**Problem we solve.** Teams talk past each other about “creativity”: some prize **novelty**, others **business value**, others **originality** or **risk‑managed invention**. Without a shared, context‑local measurement space, reviews derail, portfolios drift, and safety constraints are waived ad‑hoc.\n\n**Intent.** Provide a **small, universal measurement kit** that turns “this is creative” into **checkable, context‑local statements** — grounded in **evidence**, aligned to **objectives**, and **composable** from individuals to portfolios.\n\n**Manager’s one‑screen summary (what you can do with it):**\n\n1. **Score** a design/code/theory change on **Novelty–Value–Surprise–ConstraintFit** with declared references and models.\n2. **Compare** options in a **Pareto sense** (no single magic score forced).\n3. **Consider** constraints as a **coordinate** in the space; compare options on **frontiers** while keeping Context for high‑novelty options\n4. **Track** a portfolio’s **Diversity** to avoid local maxima and groupthink.\n5. **Defend** decisions with an auditable **CreativeEvaluation** that cites **what was new relative to which base**, **how value was measured**, and **why this counts here**.\n\n",
        "forces": "### C.17:2 - Forces\n\n| Force                                | Tension we must resolve                                                                                                                 |\n| ------------------------------------ | --------------------------------------------------------------------------------------------------------------------------------------- |\n| **Universality vs. domain detail**   | One kit must serve hardware design, software, policy, and science, yet let each Context pick similarity kernels, priors, and value models. |\n| **Invention vs. constraint**         | Creative leaps are valuable; safety, ethics, and acceptance are non‑negotiable.                                                         |\n| **Local truth vs. Cross‑context reuse** | Meaning is context‑local (A.1.1); yet we need Bridges to compare across organisations/disciplines.                                         |\n| **Single score vs. frontier**        | Management wants a number; reality is multi‑objective.                                                                                  |\n| **Randomness vs. intention**         | Random noise looks “novel” yet useless; planned recombination can be highly creative.                                                   |\n\n**Design answer.** A **context‑local CreativitySpace** with a **small set of characteristics**, each with **clear measurement templates** and **Evidence Graph Ref**; composition uses **frontiers and partial orders**, not forced scalarisation.\n\n",
        "solution": "### C.17:3 - Solution Overview — The context‑local CreativitySpace\n\n**Idea.** Creativity is **not a type**; it is a **profile** measured on an **outcome** (episteme) or **episode** (set of works) **inside a bounded context**. The context supplies the **ReferenceBase**, **SimilarityKernel**, **GenerativePrior**, **objective function(s)**, and **acceptance constraints**.\n\n**Objects in play (A‑kernel alignment):**\n\n* A **system** (person, team, service) performs **`U.Work`** under a role (A.2).\n* That work yields a **carrier** (doc/model/design/code), i.e., an **`U.Episteme`**.\n* We apply a **`U.CreativeEvaluation`** to that episteme (and linked work) to produce a **`U.CreativityProfile`** with evidence.\n\n**Cre­ativitySpace (first‑class CHR):**\n`U.CreativitySpace(Context) := 〈Novelty@context, ValueGain, Surprise, ConstraintFit, Diversity_P, AttributionIntegrity, EffortCost?〉`\nwith **scale**/**unit** metadata from **MM‑CHR** (C.16), and Context‑specific **measurement methods** bound by **MethodDescription**.\n\n**Design/run split (A.4):**\n\n* **Design‑time**: score **concepts** or **specs** against **surrogate value models** and **priors**; record **assumptions** (USM scopes; A.2.6).\n* **Run‑time**: recompute **ValueGain** and **ConstraintFit** from Work evidence (service acceptance, KPIs) and refresh **Surprise** if priors update.\n\n",
        "vocabulary_(chr_terms_&_d‑stubs)": "### C.17:4 - Vocabulary (CHR terms & D‑stubs)\n\n> Names are **context‑local**; below are kernel terms. Roles like “Designer/Reviewer” are contextual (A.2). **Documents don’t act** (A.7/A.12); they are **evaluated**.\n\n1. **`U.ReferenceBase`** *(D).* A curated, versioned **set of artifacts** (epistemes) and/or behaviours that define “what exists already” **in this Context and time window**.\n   **Conformance (RB‑1):** must declare **inclusion criteria**, **time span (`TimeWindow`)**, and **coverage notes**.\n\n2. **`U.SimilarityKernel`** *(D).* A declared **metric family** with invariances (e.g., text: cosine over embeddings, image: LPIPS, code: AST graph edit).\n   **Conformance (SK‑1):** must cite **MethodDescription** and **test corpus**; state **limits**.\n\n3. **`U.GenerativePrior`** *(D).* A model that yields **likelihood** of artifacts given the Context’s history (n‑gram/LM, design grammar, trend model).\n   **Conformance (GP‑1):** must publish **training slice**, **fit method**, **perplexity/fit metrics**, and **refresh policy**.\n\n4. **`U.CreativeOutcome`** *(D).* Any **`U.Episteme`** put forward for creative evaluation (e.g., new design, algorithm, spec, policy draft).\n   **Note.** If the outcome is a **system change** without a single carrier, attach the evaluation to a **bundle** (set) of carriers referenced from Work.\n\n5. **`U.CreativeEvaluation`** *(D).* A **`U.Evaluation`** that outputs a **`U.CreativityProfile`** and anchors to **ReferenceBase**, **Kernel/Prior**, **objective(s)**, **acceptance tests**, and **Work evidence**.\n\n6. **`U.CreativityProfile`** *(D).* The **coordinate tuple** in `U.CreativitySpace` with provenance to the above inputs and **USM scopes**.\n   **Conformance (CP‑1):** profile **must** include **scales/units**, **scopes**, **confidence bands** (B.3), and the **edition** of space definitions.\n\n",
        "the_core_characteristics_(kernel_nucleus)": "### C.17:5 - The Core Characteristics (kernel nucleus)\n\nEach characteristic is specified per **MM‑CHR (C.16)** with: **name**, **intent**, **carrier**, **polarity**, **scale type**, **measurement template**, **evidence**, **scope (USM)**, and **didactic cues**. *Context profiles MAY add characteristics; kernel characteristics MAY NOT be removed without a Bridge.*\n\n#### C.17:5.1 - `Novelty@context` — “How unlike the known set is this?”\n\n* **Intent.** Quantify **distinctness** of the outcome relative to **`U.ReferenceBase`** (global or targeted slice).\n* **Carrier.** `U.Episteme` (the outcome).\n* **Polarity.** Higher is “more novel.”\n* **Scale.** **\\[0, 1]**; ratio (0 = duplicate under kernel; 1 = maximally distant).\n* **Measurement template (normative pattern):**\n\n  1. Declare **ReferenceBase** `B` and **TimeWindow** window.\n  2. Declare **SimilarityKernel** `σ` and its invariances.\n  3. Compute **`Novelty@context := 1 − max_{b∈B} sim_σ(outcome, b)`**, or a robust variant (top‑k mean).\n  4. Publish **sensitivity note** (how results shift with kernel/`B`).\n* **Evidence.** Kernel/version id; top‑k neighbours with distances; ablation on invariances.\n* **Scope hooks (USM).** `B` **must** be a declared **slice**; Cross‑context use needs a **Bridge** with **CL** and **loss notes**.\n* **Didactic cues.**\n\n  * **Not** “randomness.” Noise has high novelty, low value.\n  * **Local, not global.** Novelty is **to this Context now**, not timeless originality.\n\n#### C.17:5.2 - `Use‑Value` *(alias: `ValueGain`)* — “What good did this add under our objective?”\n\n* **Intent.** Quantify **benefit** vs a baseline objective (Decsn‑CAL utility, Service acceptance, KPI).\n* **Carrier.** Outcome (episteme) with **Work** evidence.\n* **Polarity.** Higher is better.\n* **Scale.** Interval/ratio, unit **declared by the Context** (e.g., ΔSNR, % defects, profit/period).\n* **Measurement templates (pick one):**\n\n  * **Measured:** `ValueGain := metric_after − metric_before` (declare counterfactual method).\n  * **Predicted:** `E[ValueGain | model]` with error bars; update post‑run.\n  * **Evidence.**  Declared **objective/criterion**; measurements or credible predictions; counterfactual method (A/B, back‑test, causal inference).\n  * **Scope.** State the **context window** used for the objective; claims outside that window are **informative only**.\n  * **Didactic cues.**\n\n  * Value is **relative to stated objective**; if the objective is wrong, the value reflects it.\n  * Keep **counterfactual discipline**; otherwise “gain” is storytelling.\n\n#### C.17:5.3 - `Surprise` — “How improbable under our learned world?”\n\n* **Intent.** Capture **unexpectedness** given **`U.GenerativePrior`**.\n* **Carrier.** Outcome.\n* **Polarity.** Higher surprise = more unexpected.\n* **Scale.** **bits** or **nats**: `Surprise := −log p_prior(outcome)`.\n* **Measurement template:**\n\n  1. Declare **GenerativePrior** (training slice, model class).\n  2. Encode outcome for the prior; compute likelihood proxy.\n  3. Publish calibration curve (reliability diagram / PIT histogram).\n* **Evidence.** Model cards; fit metrics; OOD diagnostics; refresh policy.\n* **Scope.** Training slice declared as **ContextSlice**; Bridges penalise **R** (trust), not the value itself (A.2.6).\n* **Didactic cues.**\n\n  * **Novelty vs Surprise:** high novelty under one kernel may be low surprise under a broad prior; publish both.\n\n#### C.17:5.4 - `ConstraintFit` — “Did it honour the non‑negotiables?”\n\n* **Intent.** Ensure **mandatory constraints** (safety, ethics, standards, SLOs) are satisfied.\n* **Carrier.** Outcome + Work evidence.\n* **Polarity.** Higher is **better** (1 = all mandatory satisfied).\n* **Scale.** **\\[0, 1]**, ratio or pass/fail.\n* **Measurement template:** declare **set `C_must`** (Norm‑CAL / Service acceptance), compute **`ConstraintFit := |{c∈C_must : pass(c)}| / |C_must|`**; optionally weight per criticality.\n* **Evidence.** Checklists, tests, audits; Who/Role performed the **SpeechActs** (approvals/waivers).\n* **Scope.** Constraints are **context‑local**; Cross‑context requires **Bridge**; waivers are **SpeechAct Work** with RSG gates (A.2.5).\n* **Interpretation note.** Low `ConstraintFit` signals tension with declared **must‑constraints** and warrants reframing or redesign; **this pattern does not prescribe go/no‑go rules**.\n\n#### C.17:5.5 - `Diversity_P` *(portfolio‑level)* — “Are we exploring the space?”\n\n* **Intent.** At the **set** level, avoid myopic exploitation; promote **coverage**.\n* **Carrier.** A **set** of outcomes.\n* **Polarity.** Higher means **broader coverage** (not “better” per se).\n* **Scale.** Set‑functional; Context defines metric (e.g., **average pairwise distance**, **k‑cover** over features).\n* **Template.** Declare **kernel** and **covering policy**; compute score and **coverage map (illumination)**; relate to **USM ClaimScopes**.\n* **Alignment note.** The **illumination/coverage** view corresponds to *IlluminationScore* used by **B.5.2.1 NQD‑Generate**; no separate characteristic is introduced here—measure it as part of `Diversity_P`.\n* **Evidence.** Distance matrix/cover plots; sensitivity to kernel.\n* **Didactic cue.** Use **Diversity\\_P** to **shape portfolios**, not to pick single winners.\n* **Marginal gain (for generators)** — normative. For a candidate h and current set S, ΔDiversity_P(h | S) := Diversity_P(S ∪ {h}) − Diversity_P(S). Contexts using NQD SHALL compute D as this marginal and publish the Diversity_P definition alongside the CharacteristicSpace/kernel and TimeWindow.\n\n**Heterogeneity Characterisation**\n* FamilyCoverage  (polarity ↑) — count of distinct domain‑families covered by a portfolio/triad; unit: families; window: declared.\n* MinInterFamilyDistance (polarity ↑) — min distance between selected families in DescriptorMap; unit: per DistanceDef; window: declared.\n* AliasRisk (polarity ↓) — collinearity/near‑duplicate risk indicator for contextual signatures; unit: score (0–1) with policy id.\n\n\n**Lexical special case (F.18 naming).**  \nFor **lexical CandidateSets** used by Name Cards (F.18), **Diversity_P SHALL be computed over head-term families, not over raw strings**. Variants that share the same lexical head (e.g., “Reference plane”, “Plane of reference”, “Planar reference”) **MUST** be treated as one family for coverage and distance; only candidates with distinct heads contribute to lexical Diversity_P. This aligns lexical use of Diversity_P with `FamilyCoverage` / `AliasRisk` and prevents inflating diversity by near-synonyms of a single head.\n\n\n#### C.17:5.6 - `AttributionIntegrity` — “Did we credit sources and licences correctly?”\n\n* **Intent.** Discourage “novelty theft”; ensure **recombination** is **lawful and transparent**.\n* **Carrier.** Outcome + provenance graph.\n* **Polarity.** Higher is better.\n* **Scale.** **\\[0, 1]**; fraction of **required attributions/licence duties** satisfied.\n* **Template.** Trace graph coverage against Context policy; licence constraints as **Norm‑CAL** rules.\n* **Evidence.** PROV‑style links; licence scans; acknowledgements.\n* **Didactic cue.** High `AttributionIntegrity` signals lawful and transparent recombination; low values indicate unacceptable practice in most Contexts.  \n* **Default role.** `AttributionIntegrity` is **measurable but non‑dominant**. It MAY serve as a **policy filter/tie‑break** (C.19). If certain attribution duties are **must‑constraints**, they belong to **ConstraintFit** (Norm‑CAL) and act as **eligibility gates**. It is **not** part of the default dominance set.\n* **Dominance & gating note (normative).** `AttributionIntegrity` is a measurable **Characteristic**; it is **not** in the default dominance set. Contexts MAY use it as a **filter** or **tie‑break** via policy (C.19). Legal/ethical **must‑fit** checks live in **ConstraintFit** (Norm‑CAL); failing those blocks eligibility **before** dominance.\n\n#### C.17:5.7 - `EffortCost` *(advisory)* — “What did it take?”\n\n* **Intent.** Normalise comparisons by cost; not part of “creativity” per se.\n* **Carrier.** WorkLedger.\n* **Polarity.** Lower is better when used as denominator.\n* **Scale.** Resource units (hours, energy, \\$).\n* **Template.** Sum cost categories over Work that produced the outcome.\n* **Evidence.** Time/resource logs; BOM deltas.\n* **Didactic cue.** Use **`CreativityPerCost := f(Novelty@context, ValueGain, Surprise)/EffortCost`** for operations planning, not for excellence awards.\n\n",
        "conformance_checklist": "### C.17:20 - Conformance Checklist (pattern‑level, normative)\n\n> *Pass these and your CS modelling remains a thinking architecture, not a team‑management manual.*\n\n**CC‑C17‑1 (context‑local CS).**\nEvery **CreativitySpace** (the characteristic set where ideation and selection are measured) **MUST** be defined *inside one* `U.BoundedContext`; all characteristics and their scales are local to that Context. (Bridges with CL penalties are required across Contexts; see §C.17.16.)\n\n**CC‑C17‑2 (Characteristics, not “characteristics”).**\nEach CS dimension **SHALL** be a named **Characteristic** per **MM‑CHR**, with kind (`qualitative`, `ordinal`, `interval`, `ratio`, or `set‑valued`), unit/scale, polarity, and admissible operations. No free‑floating coordinates. (A.CHR‑NORM / A.CSLC‑Kernel.)\n\n**CC‑C17‑3 (Profile ≠ plan).**\nA **Profile** is a *state description over characteristics* (what the option *is* in CS); a **Plan** or **Method** is *how you will act*. Never encode choices or schedules into the profile.\n\n**CC‑C17‑4 (Portfolio = set + rule).**\nA **Portfolio** is a set of candidate profiles **plus** a selection rule (objective + constraints) declared *in the same Context*. Presenting only a scatterplot is non‑conformant.\n\n**CC‑C17‑5 (Dominance operator well‑typed).**\nA dominance claim **MUST** name the **characteristic subset and polarity** under which it is evaluated. Dominance on incomparable scales (or mixed polarities without explicit transformation) is invalid.\n\n**CC‑C17‑6 (Frontier from rule, not from taste).**\nA **Frontier** (Pareto or constraint‑bound) **SHALL** be computed from the declared selection rule; drawing a “nice hull” by eye fails conformance.\n\n**CC‑C17‑7 (Search–Exploit as **dynamics**, not policy dogma).**\nExploration/exploitation **MUST** be expressed as a **dynamics on the portfolio measure(s)** (e.g., exploration share as a function of marginal value of information), *not* as a prescriptive budget recipe. (Design‑time statements belong to Decsn‑CAL; see §C.17.16.)\n\n**CC‑C17‑8 (Evidence Graph Referring for scores).**\nAny numeric score in a profile **MUST** cite its **MeasurementTemplate** (MM‑CHR) and the **observation/evaluation** that yielded it. No anonymous numbers.\n\n**CC‑C17‑9 (Separable uncertainty lanes).**\nKeep **aleatory** vs **epistemic** uncertainty separate on characteristics; their combination rule **MUST** be stated (e.g., interval arithmetic, conservative bound).\n\n**CC‑C17‑10 (Time is explicit).**\nComparisons across iterations **MUST** state `TimeWindow` (snapshot window) and whether *drift* or *refit* occurred (§C.17.14). “Latest” is not a time selector.\n\n**CC‑C17‑11 (No proxy collapse).**\nIf a composite “creativity index” is used, its **aggregation algebra** (weights, monotone transforms) **MUST** be declared; the primitive characteristics remain queryable.\n\n**CC‑C17‑12 (Work stays on Work).**\nResource/time actuals and run logs live on `U.Work`; CS never carries actuals. We reason **about** profiles/portfolios; we do not audit operations here.\n\n",
        "manager’s_quick‑start_(apply_in_5_steps)": "### C.17:7 - Manager’s Quick‑Start (apply in 5 steps)\n\n1. **Name the Context** *(context + edition)*.\n2. **Pick measurement defaults** *(kernel, prior, objective, constraints)* from the Context’s handbook.\n3. **Score outcome** → `Novelty@context`, `Use‑Value`, `Surprise`, `ConstraintFit`.\n4. **Decide by frontier**: shortlist **non‑dominated** options; use **ConstraintFit** as a gate; apply **policy** if a scalar is approved.\n5. **Record a CreativeEvaluation** with evidence; if crossing Contexts, attach the **Bridge id**.\n\n> **Mental check.** *New to our base? Helpful to our objective? Unexpected under our model? Safe & licenced?*\n> If any answer is “unknown,” you are **not done measuring**.\n\n",
        "archetypal_grounding": "### C.17:8 - Archetypal Grounding (three domains)\n\n**(a) Manufacturing design change)**\n*Outcome.* New impeller geometry for Pump‑37.\n*Context.* `PlantHydraulics_2026`.\n*Novelty@context* 0.42 (shape‑descriptor kernel vs last 5 years).\n*ValueGain.* +6.8% flow @ same power (bench Work).\n*Surprise.* 1.3 bits (within evolutionary trend prior).\n*ConstraintFit.* 1.0 (materials, safety, noise).\n*Decision.* **Frontier winner**: modest novelty, clear value, safe. Portfolio keeps **Diversity\\_P** by also funding one high‑surprise concept for exploration.\n\n**(b) Software architecture refactor)**\n*Outcome.* New concurrency model for ETL.\n*Context.* `DataPlatform_2026`.\n*Novelty\\_G.* 0.27 (AST/edit kernel vs internal corpus).\n*ValueGain.* −20% latency, −35% p95 stalls (A/B Work).\n*Surprise.* 0.5 bits (trend prior expected co‑routines).\n*ConstraintFit.* 0.83 (fails SoD—same author as reviewer).\n*Decision.* Return for **SoD fix**; then likely adopt. Creativity is **not** a waiver over governance.\n\n**(c) Scientific hypothesis)**\n*Outcome.* A new scaling law claim.\n*Context.* `GraphDynamics_2026`.\n*Novelty\\_G.* 0.66 (formula kernel vs literature base).\n*ValueGain.* Predicted: explains 12 prior anomalies (model check).\n*Surprise.* 3.7 bits (strongly unexpected under prior).\n*ConstraintFit.* 1.0 (ethics N/A; evidence roles bound with decay windows).\n*Decision.* Fund **replication Work**; track **R** decay per policy.\n\n",
        "anti‑patterns_(fast_fixes)": "### C.17:9 - Anti‑Patterns (fast fixes)\n\n| Anti‑pattern                   | Why it fails                                                                  | Fix with this architheory                                                        |\n| ------------------------------ | ----------------------------------------------------------------------------- | -------------------------------------------------------------------------------- |\n| **“Creativity = randomness.”** | Noise yields high `Novelty@context`, low `ValueGain` and often low `ConstraintFit`. | Evaluate **all four** characteristics; require ConstraintFit=1 for musts.                   |\n| **Global originality claims.** | Ignores context‑local meaning and current corpus.                                | Declare **Context & ReferenceBase**; cross Contexts only via **Bridge**.               |\n| **One magic score.**           | Hides trade‑offs; fragile under drift.                                        | Decide on **Pareto frontier**; publish scalar only with explicit weights/policy. |\n| **Hand‑wavy value.**           | No objective → no audit.                                                      | Tie to **Service/KPI** or **utility**; state **counterfactual**.                 |\n| **Silent borrowing.**          | Legal/ethical risk; reputational damage.                                      | Track **AttributionIntegrity**; licence scans in evidence.                       |\n\n",
        "relations": "### C.17:18 - Relations\n\n* **Builds on**: B.1 Γ‑algebra (WLNK/COMM/IDEM/MONO), B.3 Trust & Assurance (F–G–R, CL), A.2.6 USM (Claim/Work scopes), A.10 Evidence Graph Referring.\n* **Coordinates with**: A.2 Role suite (Observer/Evidence roles for probes), A.15 (Work & plans for probes), C.16 MM‑CHR (scale polarity & units). **C.18 NQD-CAL** (generation/illumination operators Γ_nqd.\\*) and **C.19 E/E-LOG** (policies, selection, and portfolio rules). This CHR remains measurement-only.\n* **Defers to**: F.9 Bridges for Cross‑context transfers; D‑cluster for ethical/speech‑act gates.\n",
        "authoring_aids_(didactic_cards)": "### C.17:11 - Authoring Aids (didactic cards)\n\n* **Write the Context.** Context + edition on every profile.\n* **Name the base & kernel.** Without them, `Novelty@context` is undefined.\n* **State the objective.** Value without a KPI is a story.\n* **Publish priors.** Surprise needs a trained model with cards.\n* **Gate by musts.** `ConstraintFit` < 1 blocks enactment unless waived.\n* **Prefer frontiers.** Shortlist non‑dominated options; let governance decide trade‑offs.\n* **Bridge explicitly.** Cross‑context talk needs CL and loss notes.\n",
        "cslc_recap_and_the_creativity_characteristicspace": "### C.17:12 - CSLC recap and the Creativity CharacteristicSpace\n\n**Purpose.** Ground “creativity” as a **measurable family of characteristics** (CHR) rather than a role, capability, or virtue. Each characteristic is scoped to a **`U.BoundedContext`**, evaluated on **`U.Work`** (episodes), **artifacts** (epistemes, e.g., design sketches, models), or **holders** (systems/teams) via **MM‑CHR** exports (`U.DHCMethodRef`, `U.Measure`, `U.Unit`, `U.EvidenceStub`), using the **CSLC** discipline (*Characteristic / Scale / Level / Coordinate*).\n\n> **Strict Distinction (A.7) reminders.**\n> *Creativity is not a Role* (no one “plays CreativityRole”). It’s a **characterisation** of outcomes/process.\n> *Creativity is not Work* (no resource deltas). Work **produces** artifacts we later characterise.\n> *Creativity is not a Service* (no external promise). Services are judged from Work; creativity may correlate with value.\n\n#### C.17:12.1 - The Creativity CharacteristicSpace (CHR‑SPACE)\n\nThe core **characteristics** below are **kernel‑portable** names; Contexts **specialise** them (rename if needed, but keep semantics). Each characteristic declares: **what we measure**, **on what carrier**, **typical scale**, and **where it lives** in FPF.\n\n| Characteristics (kernel name)       | What it captures (intuitive)                                 | Measured on           | Typical scale (CSLC)                               | Lives with / checked by              |\n| ------------------------ | ------------------------------------------------------------ | --------------------- | -------------------------------------------------- | ------------------------------------ |\n| **Novelty\\@context**        | Distance from known ideas **in this Context**                   | Artifact / Work set   | Ratio or bounded \\[0..1] via *similarity→distance* | `KD‑CAL` corpus + `U.BoundedContext` |\n| **Use‑Value**            | Benefit vs a **declared objective**                          | Artifact / Evaluation | Ordinal (Fail/Partial/Pass) or scalar KPI          | `B.3` Evidence & `U.Evaluation`      |\n| **Surprise**             | Unexpectedness under the Context’s **GenerativePrior**          | Artifact              | bits or nats (−log‑likelihood)                     | Prior cards & calibration            |\n| **ConstraintFit**        | Degree of **must‑constraints** satisfied while exploring     | Work / Artifact       | % satisfied (0–100)                                | `Norm‑CAL` + step guards             |\n| **Diversity_P**          | Portfolio **coverage/dispersion** (incl. coverage map view)  | Set of artifacts      | Set‑functional; coverage index                     | `Γ_ctx` fold + USM ClaimScopes       |\n| **AttributionIntegrity** | Lawful & transparent **provenance/licensing**                | Artifact + provenance | \\[0,1]                                              | PROV + Norm‑CAL                      |\n\n> **Locality.** **Every characteristic is context‑local** (e.g., **Novelty\\@context**). Cross‑context claims **must** use a **Bridge** and record **CL** penalties (B.3). No global novelty.\n\n#### C.17:12.2 - Context extensions & policy‑level characteristics (non‑kernel)\n\nThe following **context‑local** characteristics remain available but are **not** part of the kernel nucleus; use them as **derived** or **policy** measures:\n\n* **ReframeDelta** — change in the **problem frame** that improves solvability (episteme‑pair; ordinal).\n* **Compositionality** — degree of **re‑use and new relations** among parts (artifact; boolean + structure score).\n* **Transferability\\@X** — portability to **Context X** via a Bridge (artifact; ordinal + CL penalty).\n* **DiversityOfSearch** — breadth of **approach classes tried** (work set; count/rate).\n* **Time‑to‑First‑Viable** — elapsed time to first **Use‑Value = Pass** (work; duration).\n* **Risk‑BudgetedExperimentation** — planned vs realized exploration share (workplan vs work; ratio; policy gate).\n\n> **Compatibility note.** This split removes duplicate “core lists” and aligns C.17 with **B.5.2.1 NQD** and **C.16/A.17–A.18**: the **kernel nucleus** captures creativity *qualities*; the items above instrument **process/policy** or **portfolio shaping**.\n\n#### C.17:12.3 - Scale choices (CSLC discipline)\n\nFor each characteristic, **declare the scale** explicitly (nominal / ordinal / interval / ratio). **Do not** average ordinal scores; fold with medians or distributional summaries. Choose **units** (when applicable) and **coordinate** semantics (e.g., what “distance” means).\n\n* *Novelty\\@context.*\n  Coordinate = `1 − max_similarity(candidate, corpus)` with a declared encoder (text, graph, CAD). Unitless in \\[0..1]. Document encoder & corpus freeze (`A.10` Evidence Graph Ref).\n* *Use‑Value.*\n  `Pass` iff **acceptanceSpec** (from `U.ServiceClause` or Decision KPI) is met from **Work** evidence; else `Partial`/`Fail`. For scalar KPIs, publish mean ± CI and the acceptance threshold; predicted values carry error bars and are updated post‑run.\n* *ConstraintFit.*\n  Ratio = satisfied / declared **must** constraints. Constraints are `Norm‑CAL` rules; **count only declared** ones (no unspoken “norms”).\n\n\n#### C.17:12.4 - Metric templates (normative kernels + manager‑ready variants)\n\n **Template syntax (MM‑CHR):**\n`U.DHCMethod { name, context, carrierKind, definition, unit?, scale, EvidencePin, acceptanceHook? }`\n*Note:* Data instances carry `DHCMethodRef` pointing to this template.\n\n##### C.17:12.4.1 - Templates (kernel definitions)\n\n1. **`MT.Novelty@context`**\n\n* **carrierKind:** Artifact|WorkOutput.\n* **definition:** `1 − max_sim(encode(x), encode(y))` over y in **ReferenceSet**@Context.\n* **scale:** ratio \\[0..1].\n* **EvidencePin:** `{ReferenceSetId, EncoderId, Version}`; frozen by `A.10`.\n* **notes:** Publish encoder & corpus drift in RSCR.\n\n2. **`MT.Use‑Value`**\n\n* **carrierKind:** Work (fulfillment) → artifact (decision memo).\n* **definition:** Evaluation of an outcome against a declared **objective/criterion** for the current context (or predicted value with explicit model & error).\n* **scale:** ordinal {Fail, Partial, Pass} or scalar KPI.\n* **EvidencePin:** links to `U.Work` that **fulfilServiceClause\\`**; cite acceptanceSpec edition.\n\n3. **`MT.ConstraintFit`**\n\n* **carrierKind:** Work / Artifact.\n* **definition:** `|{c∈C_must : pass(c)}| / |C_must|` within the **MethodDescription** scope; optional weighting by criticality allowed if declared.\n* **scale:** ratio \\[0..1].\n* **EvidencePin:** constraint list from **Norm‑CAL**; checks from Work telemetry.\n\n4. **`MT.ReframeDelta`**\n\n* **carrierKind:** Episteme pair (ProblemStatement v0→v1).\n* **definition:** Categorise frame change as {None, Local, BoundaryShift, Systemic}; **justify** with a Scope diff (`A.2.6 U.ContextSlice` delta) and causal map simplification.\n* **scale:** ordinal 0–3.\n* **EvidencePin:** diff artifact + Bridge notes if Cross‑context.\n\n5. **`MT.DiversityOfSearch`**\n\n* **carrierKind:** Work set (episode).\n* **definition:** Count of **distinct approach classes** tried (domain‑local typology) / time.\n* **scale:** count; derived rate.\n* **EvidencePin:** tagged Work items; typology lives in the Context glossary.\n\n6. **`MT.Compositionality`**\n\n* **carrierKind:** Artifact.\n* **definition:** set aggregator (Compose‑CAL) of reused components ≥ K and presence of novel relation among ≥ 2 parts.\n* **scale:** boolean + secondary “structure score” (e.g., depth or edge novelty).\n* **EvidencePin:** component graph + provenance of parts.\n\n7. **`MT.Transferability@X`**\n\n* **carrierKind:** Artifact.\n* **definition:** Applicability in target **Context X** via a **Bridge**; report **CL** and residual scope slice.\n* **scale:** ordinal {not portable, portable with loss, near‑iso}; record CL (0–3).\n* **EvidencePin:** Bridge id + pilot Work in X.\n\n8. **`MT.Time‑to‑First‑Viable`**\n\n* **carrierKind:** Work episode.\n* **definition:** elapsed wall‑clock to first `UsefulnessEvidence = Pass`.\n* **scale:** duration.\n* **EvidencePin:** first passing `U.Work` id.\n\n9. **`MT.Risk‑BudgetedExperimentation`**\n\n* **carrierKind:** WorkPlan vs Work.\n* **definition:** `(Planned exploratory spend) / (Allowed risk budget)` and realised counterpart; flag **overrun**.\n* **scale:** ratio + policy gate (pass/fail).\n* **EvidencePin:** WorkPlan ledger vs `WorkLedger`.\n\n##### C.17:12.4.2 - Manager’s quick checks (plain‑language adapters)\n\n* **Novelty** without a **frozen corpus** is **storytelling**—freeze corpus, fix encoder, then score.\n* **Use‑Value** without a **consumer‑facing acceptance** is a **proxy**—bind to a **Service** or explicit Objective.\n* **Diversity** counts **approach classes**, not color‑swap variants—publish your typology.\n",
        "novelty_&_transfer_are_**context‑local**_(bridges_mandatory)": "### C.17:13 - Novelty & transfer are **context‑local** (Bridges mandatory)\n\n**Rule N‑1 (Locality).** `Novelty@context` is defined **only** within its `U.BoundedContext`. **Never** compare scores across Contexts without an **Alignment Bridge** (F.9).\n\n**Rule N‑2 (Directional mapping).** A Bridge may assert a **directional** substitution (e.g., *Novelty\\@DesignLab → Novelty\\@Manufacturing* with CL = 2, **loss:** aesthetics encoder absent). Reverse mapping is **not** implied.\n\n**Rule N‑3 (Penalty to R, not to G).** Cross‑context novelty **does not** change scope **G**; it **reduces R** (reliability) by the **CL penalty** (B.3), unless validated by pilot Work in the target Context.\n\n**Practical pattern.** Publish novelty **with its Context tag** and—when reused—attach the **Bridge id** and target‑context **pilot** outcomes.\n\n",
        "anti‑goodhart_guard_(use_creativity_metrics_safely)": "### C.17:14 - Anti‑Goodhart guard (use creativity metrics safely)\n\n> **Goodhart’s Law:** “When a measure becomes a target, it ceases to be a good measure.” — We bake in **guards** so creativity scoring **improves** outcomes instead of gaming them.\n\n#### C.17:14.1 - Guard‑rails (normative)\n\n* **G‑1 Paired appraisal.** **Never** assess **Novelty** in isolation; pair it with **Use‑Value** or **ConstraintFit** to avoid proxy myopia\n* **G‑2 Frozen references.** Novelty requires **frozen corpus + encoder**; changes create a **new edition** and **RSCR** rerun. Portfolio/selection heuristics are **policy-level** (see **C.19**); do not “reward” Illumination beyond its role as a report-metric.\n* **G‑3 Time‑lag sanity.** Include a **post‑fact check** (e.g., 30–90‑day retention or cost‑to‑serve delta) before celebrating “creative wins.”\n* **G‑4 Exploration budget.** Tie **DiversityOfSearch** to **Risk‑BudgetedExperimentation**; flag overspend.\n* **G‑5 No ordinal averaging.** Do not average **ordinal** scales; use distributions/medians or convert only under declared models.\n\n#### C.17:14.2 - Conformance Checklist — **CC‑C17‑M (metrics & guards)**\n\n| ID             | Requirement                                                                                                                            | Practical test                                                              |\n| -------------- | -------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------- |\n| **CC‑C17‑M.1** | Each metric instance **MUST** cite its **Context**, **edition**, and **evidence hooks** (corpus/encoder, acceptanceSpec, constraint set). | Scorecard lists `ContextId`, `Edition`, and hook ids resolvable via `A.10`. |\n| **CC‑C17‑M.2** | **Novelty** scores **MUST NOT** be used to approve Work without a **paired gate** (**Use‑Value** **or** **ConstraintFit**).               | Find decisions referencing novelty; check co‑gate present.                  |\n| **CC‑C17‑M.3** | Cross‑context reuse **MUST** cite a **Bridge** and record **CL**; **R** is penalised accordingly.                                         | Scorecards with foreign Context tag lacking Bridge → **fail**.                 |\n| **CC‑C17‑M.4** | Ordinal metrics **MUST** be summarised with medians/distributions, not means, unless a declared model justifies numeric treatment.     | Reports using a mean on ordinal without model → **fail**.                   |\n| **CC‑C17‑M.5** | Metric templates **MUST** be versioned; changing encoder, reference set, or acceptanceSpec **creates a new edition**.                  | Diff shows changed hooks without edition bump → **fail**.                   |\n\n",
        "worked_mini‑cases_(engineer‑manager_focus)": "### C.17:15 - Worked mini‑cases (engineer‑manager focus)\n\n> **All names are context‑local; bridges and editions are explicit.**\n> We show **(a)** what is measured, **(b)** who acts, **(c)** what is accepted, and **(d)** how evidence flows.\n\n#### C.17:15.1 - Case A — Hardware ideation sprint (manufacturing design)\n\n* **Context.** `DesignLab_2026`.\n* **Objective.** Reduce fastener count by ≥ 30 % without tooling changes.\n* **MethodDescription.** “Morphological matrix ideation v2.”\n* **Work.** 1‑day sprint, 6 sessions.\n* **Metrics.** `Novelty@context` (encoder: CAD‑graph v1; ReferenceSet: in‑house assemblies), `ConstraintFit` (no‑tooling‑change), `Use‑Value` (acceptance: Pass if sim shows ≤ +5 % assembly time).\n* **Roles.** Performers = design cell (#TransformerRole); Observer = methods coach (#ObserverRole ⊥).\n* **Outcome.** 22 candidates; 4 **Pass** usefulness; best `Novelty`=0.41 with **100 %** constraints respected; `Time‑to‑First‑Viable` = 3 h 40 m.\n* **Evidence.** Scorecard episteme holds metrics; links to Work ids; acceptance tied to internal **Service** “Design‑for‑Assembly Simulation”.\n\n**Manager’s read.** “We didn’t just produce ‘novel’ shapes; 4 passed the sim and respected constraints, within the day.”\n\n\n#### C.17:15.2 - Case B — Data‑science hypothesis generation (health analytics)\n\n* **Context.** `Cardio_2026`.\n* **Objective.** Find a new risk factor candidate for readmission (< 30 days).\n* **MethodDescription.** “Causal discovery v3 + clinician review.”\n* **Metrics.** `DiversityOfSearch` (approach classes: feature ablation, IVs, DAG‑learners), `Novelty@context` (text encoder over prior hypotheses), `Use‑Value` (AUROC uplift ≥ 0.03 on hold‑out), `Transferability@Hospital_B` (Bridge CL=2).\n* **Roles.** SRE pipeline (#ObserverRole) computes metrics; clinicians (#ReviewerRole) set acceptance; data squad (#TransformerRole) performs experiments.\n* **Outcome.** Two candidates; one meets AUROC uplift; **Transferability** requires follow‑up (CL penalty).\n* **Evidence.** Episteme bundle: model cards, hold‑out plots, Bridge note.\n\n**Manager’s read.** “One candidate works **here**; plan a pilot at Hospital B (we recorded CL=2).”\n\n\n#### C.17:15.3 - Case C — Product squad reframing (software UX)\n\n* **Context.** `SaaS_Onboarding_2026`.\n* **Objective.** Reduce time‑to‑value (TTV) by 20 %.\n* **MethodDescription.** “JTBD interviews + onboarding flow experiments.”\n* **Metrics.** `ReframeDelta` (BoundaryShift: split onboarding into ‘job setup’ and ‘first result’), `Use‑Value` (TTV ‑22 % on A/B), `Risk‑BudgetedExperimentation` (within cap), `Compositionality` (reuse of existing workflow widgets).\n* **Roles.** UX researcher (#ObserverRole), squad (#TransformerRole), product ops (#ReviewerRole).\n* **Outcome.** Frame changed; TTV target passed; experiments within budget.\n* **Evidence.** Reframing episteme with Scope diff + A/B report.\n\n**Manager’s read.** “We changed the problem frame and proved the value drop—within risk limits.”\n\n\n#### C.17:15.4 What these cases illustrate (tie‑backs)\n\n* **Locality.** All novelty/usefulness claims are **Context‑tagged**; Cross‑context steps use **Bridges** with **CL**.\n* **Dual‑gate.** Novelty never acts alone; usefulness/constraints co‑gate decisions.\n* **SoD & Evidence.** Observers are **separate** from performers; metrics live on **epistemes** with **frozen hooks**; Work proves fulfillment.\n\n",
        "working_examples": "### C.17:16 - Working examples\n\n#### C.17:16.1 - Software (algorithmic/architectural ideation)\n\n**Kernel characteristics (↑/↓/gate).**\nNovelty↑ (algorithmic / compositional), Use‑Value↑ (targeted user/job metric), ConstraintFit=gate (resource/latency envelope), Cost‑to‑Probe↓ (hours to runnable spike), Evidence‑Level↑ (tests/benchmarks confidence), Option‑Value↑ (paths unlocked), RegretRisk↓ (blast radius if wrong).\n\n**Priors.**\n\n* Novelty prior **skeptical** beyond nearest known family (discount by conceptual distance).\n* Evidence prior at **L0** (B.3) until benchmarks exist; regression tests act as **ObserverRole** evidence.\n\n**Context card (one screen).**\n\n* Γ\\_bundle: Cost = sum; ConstraintFit = AND; Novelty = subadditive; Evidence = min (chain) / SpanUnion (indep).\n\n#### C.17:16.2 - Hardware (mechanical/electro‑mechanical concepting)**\n\n**Kernel characteristics.**\nNovelty↑ (principle/material), Use‑Value↑ (performance delta), ConstraintFit=gate (manufacturability window), Time‑to‑Probe↓ (bench jig), Cost‑to‑Probe↓, SafetyRisk↓ (hazard), Evidence‑Level↑ (bench data), Option‑Value↑ (platform reuse).\n\n**Priors.**\n\n* SafetyRisk has **WLNK** priority (R must cover hazard chain).\n* ConstraintFit must pass **manufacturing gate** before frontier inclusion.\n\n**Context card.**\n* Γ\\_bundle: Hazard = max; ConstraintFit = AND; Cost = sum+coupling; Evidence = min on chain; Scope via **WorkScope** (A.2.6).\n\n#### C.17:16.3 - Policy design (rules/standards/programs)\n\n**Kernel characteristics.**\nNovelty↑ (institutional), Use‑Value↑ (measurable social/operational effect), ConstraintFit=gate (legal/operational), Cost‑to‑Probe↓ (pilot), Evidence‑Level↑ (triangulated), EthicalRisk↓ (D‑cluster), Option‑Value↑ (coalitions/pathways), Scope (ClaimScope G) explicit.\n\n**Priors.**\n* EthicalRisk uses **status‑only** eligibility conditions; Evidence aging (decay) is **fast**; cross‑context Bridges carry **CL** penalties.\n\n**Context card.**\n* Γ\\_bundle: EthicalRisk = max; ConstraintFit = AND (legal & operational); Cost = sum; Evidence = min/SpanUnion; Scope = ClaimScope (A.2.6).\n",
        "consequences": "### C.17:25 - Consequences (informative)\n\n| Benefit                    | Why it matters                                                                                                                    |\n| -------------------------- | --------------------------------------------------------------------------------------------------------------------------------- |\n| **context‑local rigour**      | Creative comparison is made decidable *where meaning lives*; Cross‑context reuse is explicit and penalised only in trust, not scale. |\n| **Frontier honesty**       | Decisions rest on declared characteristics and polarities; frontiers follow rules, not taste.                                     |\n| **Temporal comparability** | RSCR prevents silent drift; “better/worse” claims retain meaning over iterations.                                                 |\n| **Method independence**    | Any tooling can implement the cards; C.17 remains a conceptual API for thought.                                                   |\n\n**Trade‑offs:** upfront ceremony (declare characteristics, polarity, TimeWindow) and disciplined bridges. The payoff is comparability and explainability.\n",
        "quick_reference_cards_(tear‑out)": "### C.17:19 - Quick reference cards (tear‑out)\n\n* **Dominance test**: apply **signs** + **eligibility conditions** + **trust**; then partial order.\n* **Frontier use**: **show frontier** + **name the lens** that picked your choice.\n* **Portfolio policy**: keep `ExploreShare` and `WildBetQuota`; set `BackstopConfidence`; rebalance on cadence.\n",
        "worked‑context_handbooks_(concept_cards,_not_runbooks)": "### C.17:21 - Worked‑Context Handbooks (concept cards, not runbooks)\n\n> *Each Context publishes one page per card. These are **thinking kernels**: priors, objectives, admissible characteristics, and example transforms. No staffing, no process charts.*\n\n**(a) Kernel Card — “What is a creative win here?”**\n\n* **Context:** `<Context/Edition>`\n* **Purpose Characteristic(s):** what “win” means (e.g., *Novelty*, *Usefulness*, *Adoptability*), with polarity and admissible ops.\n* **Constraint Characteristics:** *Risk*, *Cost of change*, *Time to learn*, etc.\n* **Objective** *(Decsn‑CAL pointer)*: Maximise `<purpose>` subject to declared constraints.\n* **Frontier Rule:** Pareto over `{purpose ↑, risk ↓, cost ↓, time ↓}`.\n* **Evidence Hooks:** which observations/evaluations populate each characteristic.\n\n**(b) Priors Card — “What we believe before seeing data.”**\n\n* **Default priors** on uncertainty for each characteristic (e.g., Beta for adoption probability).\n* **Bridge policy:** minimal CL acceptable for imported profiles.\n* **Exploration prior:** initial exploration share as a function of prior entropy.\n\n**(c) Objective Variants Card — “Admissible objective shapes.”**\n\n* Catalog the *few* objective forms this Context allows (lexicographic tie‑break, ε‑constraint, max‑min fairness), with **didactic pictures** of their frontiers.\n* State when to switch objective (e.g., during bootstrapping vs exploitation).\n\n**(d) Ready‑to‑use transforms** *(MM‑CHR aligned)*\n\n* Monotone maps (e.g., log utility), normalizations, ordinal→interval “do & don’t” (only with evidence of order‑to‑interval validity).\n* **Forbidden transforms** list (e.g., averaging ordinal ranks).\n\nThese cards are *conceptual fixtures*; **Tooling** may implement them, **Pedagogy** may teach them, but **C.17** only standardises their content as **thinking affordances**.\n",
        "placement_sanity‑check_across_the_pattern_language_*(avoid_scope_creep)*": "### C.17:22 - Placement sanity‑check across the pattern language *(avoid scope creep)*\n\n* **MM‑CHR (C.16):** defines **Characteristic/Scale/Unit/Measure** and the *characterisation discipline*. **All** CS dimensions live there; C.17 **uses** them, never re‑defines scales.\n* **A.CHR‑SPACE (A.19):** exports **CharacteristicSpace & Dynamics hooks**; C.17 is a **Contexted specialisation** for creative reasoning (profiles/portfolios/selection).\n* **Decsn‑CAL (C.11):** hosts **objective functions, constraints, preference orders, utility proofs**, and the **search–exploit dynamics** as decision policies. C.17 only **names** the hooks (objective, rule), keeps policy math out.\n* **KD‑CAL (C.2) & B.3 (Trust):** carry **evidence provenance**, **assurance** and **congruence penalties (CL)** for Cross‑context reuse. C.17 requires anchors; it does not invent confidence calculus.\n* **Compose‑CAL (C.13):** governs **set/union/slice** aggregation; the portfolio set is a **Γ\\_m.set** over profiles; frontier is derived **without** ad‑hoc geometry.\n* **B.4 Canonical Evolution Loop:** where *Run→Observe→Refine→Deploy* sits. C.17 supplies the **view** in which refinement is judged.\n\n**Out of scope here:** team staffing, budgeting workflows, data‑governance procedures, ticket states, any “how to manage people”. This pattern organises **thought**, not **teams**.\n",
        "anti‑patterns_&_canonical_rewrites_(conceptual_hygiene)": "### C.17:23 - Anti‑patterns & canonical rewrites (conceptual hygiene)\n\n1. **characteristic‑speak.** “Along the novelty characteristic…” → **Rewrite:** “Along the **Novelty characteristic** (ordinal; higher is better)…”.\n2. **Pretty hulls.** Drawing a convex hull and calling it a frontier → **Rewrite:** compute Pareto under declared characteristic polarities.\n3. **Ordinal arithmetic.** Averaging ranks or Likert values → **Rewrite:** either treat as **ordinal** and use **order‑safe** operators, or justify an interval mapping via MM‑CHR evidence.\n4. **Proxy tyranny.** Single composite index driving choice unseen → **Rewrite:** publish **primitive characteristics**, index formula, and sensitivity.\n5. **Policy‑as‑math.** “10% wild bets” as a rule → **Rewrite:** declare an **exploration dynamics** tied to value‑of‑information; if keeping a heuristic, label it as such.\n6. **Global meaning.** Porting a profile from another Context by name → **Rewrite:** attach a **Bridge** with CL and loss notes; adjust trust, not scales.\n7. **Plan‑profile blur.** Putting milestones into profiles → **Rewrite:** move schedules to `U.WorkPlan`; keep CS for *how options compare*, not *how to execute*.\n",
        "minimal_didactic_cards_(one_screen_each)": "### C.17:24 - Minimal didactic cards (one screen each)\n\n**(1) Profile Card**\n\n* **Option id & Context**\n* **Characteristics table** (value, unit/scale, uncertainty split)\n* **Evidence Graph Ref** (Observation/Evaluation ids)\n* **Notes** (bridges used, CL penalties)\n\n**(2) Portfolio‑with‑Rule Card**\n\n* **Set of candidate profiles (refs)**\n* **Objective & constraints** (Decsn‑CAL pointer)\n* **Dominance subset** & **Frontier snapshot** (with TimeWindow)\n* **Delta vs previous** (entered/exited/moved)\n\n**(3) Search–Exploit Card** *(conceptual)*\n\n* **Exploration share** as function of **marginal VOI** (symbolic)\n* **Update cadence** (TimeWindow policy)\n* **Stop conditions** (e.g., VOI below threshold; risk bound reached)\n\n**(4) RSCR Summary Card**\n\n* **What changed?** (refit/Δ±)\n* **Sentinels status**\n* **Frontier churn**\n* **Bridge CL drift**\n\nThese cards are **thinking scaffolds**; they do not prescribe org process.\n",
        "open_questions_(non‑normative,_research_hooks)**": "### C.17:26- Open questions (non‑normative, research hooks)**\n\n* **Information geometry of CS:** can certain Contexts justify canonical distance metrics across characteristics without violating MM‑CHR parsimony?\n* **Multi‑agent exploration:** how to couple individual CS frontiers into a *co‑exploration* equilibrium without importing team governance?\n* **Learning‑to‑rank vs measurement:** what minimal evidence suffices to treat an ordinal characteristic as interval for the purpose of frontier estimation?\n",
        "c.17:end": "### C.17:End\n"
      },
      "content": "### C.17:End\n",
      "metadata": {},
      "part": "C",
      "cluster": null
    },
    {
      "id": "C.18",
      "title": "Open‑Ended Search Calculus (NQD‑CAL)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## C.18 - Open‑Ended Search Calculus (NQD‑CAL)\n\n**Status.** Architheory specification (**CAL**). Exports `Γ_nqd.*` operators for open‑ended, illumination‑style generation. **ΔKernel = 0** (no kernel primitives added). *Minting note:* this CAL **does not mint** new U‑types; it defines **CAL‑records** that MAY alias to registered U‑types where present via **E.10/UTS**.\n\n**Depends on.** A‑kernel (A.1–A.15), **MM‑CHR** (C.16) for measurements, **KD‑CAL** for similarity/corpora, **Sys‑CAL** for carriers, **Decsn‑CAL** (objectives; advisory), **Compose‑CAL** (set aggregation; advisory).\n\n**Coordinates with.** **B.5.2.1** (binding), **C.17 Creativity‑CHR** (characteristics & scales), **C.19 E/E‑LOG** (policies: emitter selection, explore/exploit).\n\n**Exports (CAL; no U‑type minting here).**\n - Records: `NQD.DescriptorMap` (alias of `U.DescriptorMap` if minted), `NQD.NQDArchive` (alias of `U.NQDArchive`), `NQD.Niche`, `NQD.ArchiveCell`, `NQD.EmissionSeed?`, `U.EmitterPolicyRef`, `U.InsertionPolicyRef`, `U.IlluminationSummary`, and `NQD.CandidateSet` (alias of `Set<U.Hypothesis>`).\n",
        "problem": "### C.18:2 - Problem\nWithout a disciplined NQD calculus, contexts (a) conflate illumination telemetry with dominance, (b) lose reproducibility due to undeclared DescriptorMap/DistanceDefRef.editions, and (c) perform illegal aggregations across scales.\n",
        "forces": "### C.18:3 - Forces\n• Posets vs. scalarisation — selectors must return sets (Pareto/archive) rather than illegal weighted sums across mixed scales.\n• Exploration vs. exploitation — emitters must adapt while preserving provenance and editioning.\n• Telemetry metric vs. objective — Illumination (coverage/QD‑score) informs health but is not a dominance characteristic by default.\n• Reproducibility vs. adaptivity — budgets, ε, K, and InsertionPolicy must be edition‑tracked.\n",
        "solution": "### C.18:4 - Solution\nProvide Γ_nqd.* operators and U.Types for DescriptorMap, Archive/Niche, policies, and illumination telemetry summaries; bind measurement legality to MM‑CHR and policy control to E/E‑LOG. (Exports/Type notes/Operator specs below are normative parts of this Solution.)\n\n- Operators (Γ):\n  - `Γ_nqd.generate(seed?, EmitterPolicyRef, Budget, DescriptorMapRef, QualityMeasuresRef, NoveltyMetricRef, CoverageGrid, CellCapacity K=1, EpsilonDominance ε=0, DedupThreshold?, InsertionPolicyRef?) → CandidateSet<U.Hypothesis>`\n  - `Γ_nqd.updateArchive(Archive, CandidateSet, InsertionPolicyRef?) → Archive'`\n  - `Γ_nqd.illuminate(Archive) → IlluminationSummary{coverage, QD-score, occupancyEntropy, filledCells}` (report‑only telemetry summary; not a dominance characteristic unless a policy explicitly promotes it).\n  - `Γ_nqd.selectFront(Archive|CandidateSet, characteristics={Q components, Novelty@context, ΔDiversity_P, …}) → ParetoFront`\n\n**Type notes.**\n- `U.DescriptorMap (Tech; twin‑labelled Plain) : Hypothesis → ℝ^d` (declares encoder, invariances, version, **CharacteristicSpaceRef**). Publish Tech/Plain per **E.10**; declare `DescriptorMapRef.edition` and `DistanceDefRef.edition`. **Dimensionality rule.** **Require `d≥2` only when QD/illumination surfaces are active**; for non‑QD contexts `d≥1` is lawful.\n- `NQD.CandidateSet` ≡ `Set<U.Hypothesis>` with attached per‑item vectors `{Q_i, N_i, D_i:=ΔDiversity_P, S_i?, provenance_i}`.\n- `U.NQDArchive` holds per‑cell elites and genealogy refs; context‑local.\n- `U.Niche` is a region in CharacteristicSpace (grid bucket / CVT centroid / cluster).\n- `U.EmitterPolicyRef` points to a named policy in **C.19 E/E‑LOG**.\n- `U.InsertionPolicyRef` — named archive‑update policy (e.g., `replace_if_better | replace_worst | bounded_age | bounded_regret`); versioned.\n- `U.IlluminationSummary` is a **telemetry summary** over `Diversity_P` (see C.17), not a dominance characteristic.\n\n**Operator specs (normative).**\n- `Γ_nqd.generate(… )` SHALL:\n  (a) respect **Budget**,  \n  (b) compute `{Q_i}` (vector), `N_i` (Novelty@context), `D_i := ΔDiversity_P(h_i | Pool)` under the same CharacteristicSpace & TimeWindow as the Pool, and optional `S_i` (Surprise),\n  (c) deduplicate by `DedupThreshold` in CharacteristicSpace,  \n  (d) record `DescriptorMapRef.edition`, `DistanceDefRef.edition`, `EmitterPolicyRef`, `ε`, `K`, `Seeds`, and genealogy references (parent/seed ids) to enable replay and selection auditing.\n- `Γ_nqd.updateArchive` SHALL apply local competition per cell (keep up to K elites), preserve genealogy, and **enact the declared `InsertionPolicyRef`**; default is `replace_if_better` with deterministic tie‑breakers.\n- `Γ_nqd.illuminate` SHALL return coverage and QD‑score computed against the declared grid and archive edition.\n- `Γ_nqd.selectFront` SHALL compute the (ε‑)Pareto front over the declared characteristics; **Illumination** is excluded by default (report‑only).  \n\n**Pipeline:** apply **Eligibility (ConstraintFit=pass)** → **Dominance (default set from C.19; by default `{Q components}` only)** → **Tie‑breakers (`Novelty@context`, `ΔDiversity_P`, `Surprise`; `Illumination` telemetry metric)**.\n**Pure academic QD-mode:** Contexts MAY elect a _pure‑QD_ mode (dominance on `Q` only; `N/ΔD` used via archive occupancy and tie‑breakers). Any deviation SHALL be declared by policy id and recorded in provenance.\n\n**Reproducibility & editions.** Each call SHALL emit provenance sufficient for replay: `{DHCMethodRef.edition, DescriptorMapRef.edition, EmitterPolicyRef (params), **InsertionPolicyRef**, DedupThreshold?, ε, K, Seeds, TimeWindow}`.\nTelemetry hook: whenever IlluminationSummary increases (Δcoverage>0 or ΔQD‑score>0), the Context SHALL emit a Telemetry(PathSlice) record that cites {EmitterPolicyRef, DescriptorMapRef.edition, DistanceDefRef.edition, InsertionPolicyRef?, TimeWindow}. (Aligns with G.6/G.7/G.11 portfolio/edition constraints.)\n\n**Measurement alignment.** `Novelty@context`, `Use‑Value (ValueGain)`, `Surprise`, `Diversity_P` SHALL be measured per **C.17** (MM‑CHR templates). **IlluminationSummary** is a telemetry summary over `Diversity_P` (coverage/QD‑score); when CharacteristicSpace includes domain‑family cells, publish grid id and FamilyCoverage, plus **DescriptorMapRef.edition/DistanceDefRef.edition**.\n.\n",
        "conformance_checklist": "### C.18:5 - Conformance Checklist\n- **C18‑1** Declare `DescriptorMap` (encoder, invariances, corpus edition) before generation.\n- **C18‑1b** When used in F/G triads, DescriptorMap SHALL declare a domain‑family coordinate (grid/cells) and reference an F1‑Card::DistanceDefRef & δ_family.\n- **C18‑1c**  When a domain‑family coordinate is declared, the Context SHALL compute and publish **AliasRisk** for each front/portfolio emission, together with the dSig collision rule and the policy id. AliasRisk is computed against `U.DomainDiversitySignature (dSig)`; **the DescriptorMap SHALL publish**: (i) `collisionRuleId` (near‑duplicate threshold, e.g. “≥3 characteristics equal”),  (ii) `dSigSource` pointers used for coding the five characteristics. The collision rule and formula **MUST** be part of `DescriptorMap` provenance (see **Creativity‑CHR**, Heterogeneity Characterisation).\n- **C18‑2** Record `EmitterPolicyRef` (policy id from C.19) and parameter set.\n- **C18‑3** Compute `D = ΔDiversity_P(h | Pool)` under the same DescriptorMap & TimeWindow as the Pool (see C.17).\n- **C18‑4** Exclude Illumination from dominance unless policy explicitly promotes it.\n- **C18‑5** Keep `Use‑Value` separate from assurance scores; do not alter `F/G/R` semantics (see B.3, C.17 §Use‑Value).\n- **C18‑6** Emit full provenance; thinning after front computation MUST be recorded.\n- **C18‑7** Before computing any front, apply **ConstraintFit = pass** as a hard eligibility filter.\n\n**Defaults.** Normative defaults **live in C.19 (EmitterPolicy)** and are **not restated** here. Minimum provenance remains: `DescriptorMapRef.edition` and `DistanceDefRef.edition`, `DHCMethodRef.edition`, `EmitterPolicyRef`, `InsertionPolicyRef`, `TimeWindow`, `Seeds`, `DedupThreshold?`; also record `FamilyCoverage/MinInterFamilyDistance`.\n\n**Didactic quickstart (Context).**\n1) Pick 2–4 Quality coordinates and a simple DescriptorMap (2–4 dims).  \n2) Set defaults: `K=1`, `ε=0`, a conservative `EmitterPolicy`.  \n3) Run `Γ_nqd.generate` to fixed Budget; inspect the front; log coverage (IlluminationSummary).  \n4) Apply abductive plausibility filters; promote prime hypothesis to L0.\n",
        "archetypal_grounding": "### C.18:6 - Archetypal Grounding\n**System.** Legged‑robot gait exploration: Q = forward speed & energy efficiency (ratio), D = morphology/coordination descriptors (ℝ^d); Archive = CVT grid; Illumination reports coverage without entering dominance.\n\"**Episteme.** SoTA palette synthesis: Q = Use‑Value proxies per C.17 (ratio/interval as legal), D = method‑family niches; publish DescriptorMapRef.edition and DistanceDefRef.edition for reproducible fronts.\n",
        "bias‑annotation": "### C.18:7 - Bias‑Annotation\nLexical firewall and notation independence apply; no vendor/tool tokens; ordinal characteristics never averaged; illumination treated as report‑only telemetry unless a policy promotes it. (E.5.1, E.5.2, C.16)\n",
        "consequences": "### C.18:8 - Consequences\n• Portfolio honesty (no forced scalarisation). • Reproducibility (editioned maps/policies). • Healthy diversity signals via telemetry metrics.\n",
        "rationale": "### C.18:9 - Rationale\nPost‑2015 Quality‑Diversity (MAP‑Elites & successors) demonstrates illumination efficacy; NQD‑CAL captures these ideas while preserving MM‑CHR legality and LOG governance.\n",
        "relations": "### C.18:10 - Relations\nBuilds on: C.16, C.2. Coordinates with: B.5.2.1 (binding), C.17, C.19, G.5, G.6, G.11.\n",
        "c.18:end": "### C.18:End\n"
      },
      "content": "### C.18:End\n",
      "metadata": {},
      "part": "C",
      "cluster": null
    },
    {
      "id": "C.18.1",
      "title": "Scaling‑Law Lens Binding (SLL)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## C.18.1 - Scaling‑Law Lens Binding (SLL)\n\n**One‑screen purpose (manager‑first).**\nMake **generation/selection** scale‑savvy: at the level of **conceptual descriptors**, declare (a) **which monotone knobs** we would scale, (b) the **ScaleWindow** over which we claim behaviour, and (c) the **elasticity class** we observed—**without** imposing numeric fits or vendor tools at Core level. This surfaces knees early and keeps comparisons lawful and fair across families. (Parity is handled by **G.9**; illumination remains a **report-only telemetry** unless a CAL policy promotes it.)  \n\n**Builds on.** C.16 (MM‑CHR), C.17 (Creativity‑CHR), C.18 (NQD‑CAL); advisory: C.5 (Resrc‑CAL).\n**Coordinates with.** C.19 (E/E‑LOG), G.5 (Selector & Registry), G.9 (Parity Harness), G.10 (Shipping), G.11 (Refresh‑Telemetry), C.24 (Agent‑Tools‑CAL).\n**Keywords.** scaling law; **Scale Variables (S)**; ScaleWindow; knee; diminishing returns; **iso‑scale parity**; **UNM/NormalizationMethod‑based mapping**; **scale‑probe**; **DoE** (design‑of‑experiments); segmented regression; knee detection.\n",
        "problem": "### C.18.1:2 - Problem\n\nOmitting **Scale Variables** and the comparison window causes: (i) **unfair parity** (compute/data/FoA mismatched), (ii) **illumination/coverage report-metric  creep** into dominance by default, (iii) late detection of knees and budget waste. **G.9** already forbids scalarising mixed scales and mandates equal **FreshnessWindows**/**pinned editions**; SLL complements this with **ScaleWindow** & elasticity. \n",
        "forces": "### C.18.1:3 - Forces\n\nNotation independence vs useful scaling heuristics; local context vs cross‑context generality; **telemetry vs objectives** (illumination stays report‑only telemetry unless policy promotes it); early exploration vs reproducible policy.\n",
        "solution": "### C.18.1:4 - Solution — *binding lens for generator/selector profiles* (normative)\n\n#### C.18.1:4.1 - Types (aliases; ΔKernel = 0).\n`SLL.Profile` is an **annotation** on a `MethodFamily/Generator` or a `Selector` profile; **no new U.Types** are minted (LEX discipline). \n\n#### C.18.1:4.2 - Fields (conceptual descriptors).\n\n* **S — Scale Variables.** Minimal set of **monotone knobs** for the Context: `compute` (steps/tokens/FLOPs/time/energy), `data` (size/quality), `model capacity` (params/branches), `iteration budget`, **`freedom‑of‑action (FoA)`**/**environment richness**, etc. Declare **units** via **Resrc‑CAL** and bind to a **ScaleWindow**. Where training/inference trade, **name the phase** the claim concerns.\n* **ScaleWindow.** Declared range of `S` values for which behaviour claims hold (editioned). This is **distinct from** **FreshnessWindow** used by parity. \n* **Scale‑Probe.** At least **two** (preferably **≥ 3**) **parity‑respecting** points in `S` within the ScaleWindow, recorded with **replicates/seeds** and **CI/error bars** to support elasticity classification. Pick points via a **small factorial or Latin‑hypercube** when multiple knobs vary.\n* **ElasticityClass** `χ ∈ {rising, knee, flat, declining}` — a **qualitative** class; numeric exponents/fits live in domain annexes, not Core.\n* **ParityNotes.** `iso‑scale parity?` flag (and **loss notes** if not achieved), plus **Bridge/Φ/Ψ** IDs when crossing contexts (penalties **route to R only**). \n\n#### C.18.1:4.3 - Norms (SLL).\n\n* **SLL‑1 (Declaration).** Any profile **claiming scale behaviour SHALL** declare `S` and a **ScaleWindow** for the Context.\n* **SLL‑2 (Probe).** Early investigation **SHALL** include a **scale‑probe** (≥ 2 points in `S`, with replicates/CI) and record **χ**. Multi‑knob probes **SHALL** hold unspecified knobs fixed or pinned, and disclose invariants.\n* **SLL‑3 (Parity).** Where `S` is declared, comparisons **SHALL** ensure **iso‑scale parity** and lawful **UNM/NormalizationMethod‑based mapping** across heterogeneous knobs (e.g., FLOPs↔tokens) **before** comparing outcomes; **FreshnessWindows/editions** must be equal/pinned per **G.9**. Record **seeds/replicates**, ComparatorSet, and policy‑ids in telemetry/SCR. \n* **SLL‑4 (Selection lens).** Within the **same Context and ScaleWindow**, if other heads (N/U/C) are tied, selectors **MAY** use illumination as a tie‑breaker, but it **SHALL NOT** change default dominance; illumination remains **report‑only telemetry** unless a CAL policy promotes it.\n* **SLL‑5 (Knee test).** A **knee** is **claimed** only where a monotone rise is followed by a **statistically significant** slope drop across adjacent probe points within the ScaleWindow; thresholds (e.g., Δslope & CI level) are **policy‑defined** (E/E‑LOG) and must be cited. Absent such evidence, classify as **rising**.\n* **SLL‑6 (Telemetry invariants).** Probes **SHALL** export seeds/replicates, edition pins, policy‑ids, and Resrc‑CAL units to **G.11**.\n\n#### C.18.1:4.4 - Method — minimal SoTA probe recipe (notation‑agnostic; informative).\n1) **Choose knobs** `S` that are plausibly monotone in the Context (compute/data/capacity/FoA).  \n2) **Pick 3–5 probe points** per active knob (edge/mid/edge) under iso‑scale parity; use a **fractional factorial** if >2 knobs.  \n3) **Run replicates** (≥ 3 preferred) and **bootstrap** 95% CI on the primary objective(s); log seeds.  \n4) **Estimate local slopes** on a log‑log grid; apply **piecewise/segmented regression** or a **knee detector** (e.g., L‑curve/Kneedle) to support `χ`.  \n5) **Record invariants** (pinned knobs, safety envelope) and publish **SLL.Card@Context**.  \n6) **If χ changes** across the window, split the ScaleWindow and re‑classify per segment.\n",
        "c.18.1:5___interfaces_—_minimal_i/o_(conceptual)": "### C.18.1:5 - Interfaces — minimal I/O (conceptual)\n\n**G.9 Plan/Run Parity** consumes `S`/ScaleWindow to align budgets, **pin editions**, and perform **UNM/NormalizationMethod‑based mapping**; **G.11** carries **policy‑id**, **PathSliceId**, seeds/replicates, CI level, and edition pins per parity CC. \n",
        "conformance_checklist": "### C.18.1:6 - Conformance Checklist (CC‑SLL)\n\n1. `S` declared **or** `S = N/A` with rationale.\n2. **Scale‑probe** performed; **χ** recorded with **replicates/CI**; invariants disclosed.\n3. **iso‑scale parity** or **loss notes** + penalties **→ R only**; editions/seeds pinned; ComparatorSet cited.\n4. If used as tie‑breaker, the selector cites **χ** and **lens id** in **E/E‑LOG** provenance.\n5. Knee claims cite the **policy threshold** and CI level used.\n",
        "c.18.1:7___anti‑patterns_&_remedies": "### C.18.1:7 - Anti‑patterns & remedies\n\nHidden budget mismatches; averaging ordinals across families; **illumination in dominance by default**; unpinned editions; slope claims without **replicates/CI**; training/inference phase mixing → **cure** with **G.9** parity (equal windows/editions; normalize‑then‑compare; return sets), phase‑label the claim, and record slope uncertainty per Scale‑Audit discipline.  \n",
        "archetypal_grounding": "### C.18.1:8 - Archetypal grounding (post‑2015; informative)\n\n* **LLM scaling.** Kaplan‑style & **Chinchilla‑optimal** regimes; **Mixture‑of‑Experts** and **retrieval‑augmented** families shift effective capacity with different inference budgets; prompt‑policies often transfer better than narrow pipelines.\n* **RL/Planning.** Model‑based optimization & general agents vs hand‑tuned controllers; slopes reported wrt budget/FoA under safety envelopes.\n* **QD/OEE.** MAP‑Elites, **CMA‑ME**, **DQD**, **QDax**; **POET/Enhanced‑POET** families: coverage/illumination as telemetry metrics; parity uses fixed grids/spaces and edition pins.  \n",
        "c.18.1:9___payload_—_exports": "### C.18.1:9 - Payload — exports\n\n`SLL.Card@Context` (UTS row; editioned):\n`⟨S{knobs, units, phase}, ScaleWindow, Scale‑Probe{points≥2, design=one‑liner, seeds, CI}, ElasticityClass χ, ParityNotes{iso‑scale?|loss, invariants}, BridgeIds?/Φ/Ψ, PolicyIds? (E/E‑LOG), PathSliceId?⟩`.\n\n**UTS row template (conceptual; pencil‑ready).**\n`SLL.Card@Context := S=(COMPUTE|DATA|CAPACITY|FOA; units=…; phase=TRAIN|INFER), ScaleWindow=[LOW…HIGH], Probe=(points=…, design=factorial|LHD, seeds=…, CI=…), χ=rising|knee|flat|declining, ParityNotes=(iso=true|false; invariants=…), Bridge/Φ/Ψ=(…), PolicyIds=(…), PathSliceId=(…)`.\n",
        "relations": "### C.18.1:10 - Relations\n\n**Builds on:** C.16/17/18. **Coordinates with:** C.19 (lenses/policies), **G.5** (set‑returning selector), **G.9** (parity; **ParetoOnly** default; UNM/NormalizationMethod‑based mapping), **G.10** (shipping). \n\n> *Pedagogical cue.* **Say what you would scale, probe it twice, and use the slope‑class to steer.**\n",
        "c.18.1:end": "### C.18.1:End\n"
      },
      "content": "### C.18.1:End\n",
      "metadata": {},
      "part": "C",
      "cluster": null
    },
    {
      "id": "C.19",
      "title": "Explore–Exploit Governor (E/E‑LOG)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## C.19 - Explore–Exploit Governor (E/E‑LOG)\n\n**Status.** Architheory specification (**LOG**). Defines exploration/exploitation policies and selection lenses. **No Γ operators** are exported; policies parameterize calls in **C.18 NQD‑CAL**.\n",
        "problem": "### C.19:2 - Problem\nAd‑hoc exploration mixes ordinal and interval folds, silently scalarises posets, and loses lens/policy provenance—undermining legality and reproducibility.\n",
        "forces": "### C.19:3 - Forces\n• Trust gates vs. discovery — graduation requires backstop confidence while maintaining explore_share.\n• Heterogeneity vs. focus — fairness quotas by family vs. depth on proven lines.\n• Lens expressiveness vs. audit — scalarised choices must not be called 'the frontier' and MUST record lens ids.\n",
        "solution": "### C.19:4 - Solution\nDefine EmitterPolicy (class, params, ε, K, insertion/dedup) and selection lenses with a fixed pipeline (Eligibility → Dominance → Tie‑breakers); bind provenance (policy id, lens id) and guard promotions of Surprise/Illumination to dominance to explicit policy declarations.\n\n**Agency note.** Decisions are taken by a **system in role**. **Contexts publish** measurement spaces and admissible policies as **semantic frames**; LOG profiles lenses and policies but does **not** enact choices.\n**Depends on.** **C.18 NQD‑CAL** (generators), **C.17 Creativity‑CHR** (measurements), **Decsn‑CAL** (objectives/constraints, scalarization lenses), **B.3** (trust adjustments), **Compose‑CAL** (set aggregation; advisory).\n\n**EmitterPolicy (named profile).** A context‑local, versioned policy with fields:\n`{ name, class ∈ {UCB, Thompson, BO‑EI, GP‑UCB, PES, …}, params, explore_share∈[0,1], temperature τ≥0, rebalance_period, wild_bet_quota≥0, backstop_confidence (assurance level), epsilon_dominance ε, cell_capacity K, **insertion_policy**, **dedup_threshold** }`.\nPolicies are referenced as `U.EmitterPolicyRef` by NQD generator call (C.18) and are conceptual lenses, not staffing/budget instructions.\n\n**Defaults (if policy is unspecified):**  \n• **Dominance:** `{Q components}` with `ConstraintFit=pass` as **eligibility gate**.  \n• **Tie‑breakers:** `Novelty@context`, `ΔDiversity_P`, `Surprise`; `Illumination` (telemetry over Diversity_P: coverage/QD‑score) MAY be used as a tie‑breaker but is **not** in the dominance set.  \n• **Archive:** `K=1`, `ε=0`, deduplication in `CharacteristicSpace`.  \n• **Policy:** UCB‑class with moderate temperature; `explore_share ≈ 0.3–0.5`.  \n• **Provenance (minimum):** record `DescriptorMapRef.edition`, `DistanceDefRef.edition`, `DHCMethodRef.edition`, `EmitterPolicyRef`, `InsertionPolicyRef`, `dedup_threshold?`, `TimeWindow`, `Seeds`.\n\n**Scalarization lenses (policy‑level).** A lens `J_ℓ` declares: (a) hard eligibility conditions (e.g., ConstraintFit=pass), (b) soft aggregation (weights/curves), (c) trust policy (how assurance/CL discounts enter).  \n**Conformance.** A Context MUST name the lens used to pick from a frontier; scalarized rankings MUST NOT be presented as “the frontier”; the **`lens id MUST be recorded in provenance of each selection`**.\n\n**Promotion rules (policy).**  \n- **Tie‑breaks.**  `Surprise` and `Illumination` MAY act as tie‑breakers; **promotion into the dominance set MUST be declared by lens or policy id** and captured in provenance.\n- **Graduation.** Profiles graduate from Explore→Exploit when **backstop_confidence** (B.3 level) and eligibility conditions are met.  \n- **Sunset/Pivot.** Profiles failing VOI/backstop thresholds are sunset or pivoted at `rebalance_period`.\n\n**Explore/Exploit loop (per rebalance_period).**\n1) Recompute frontier with trust discounts.  \n2) Enforce `explore_share` (minimum attention on high‑Novelty, not‑yet‑proven profiles).  \n3) Update generator `temperature τ` / emitter mix.  \n4) Apply `backstop_confidence` to graduate; sunset stale probes.  \n5) Satisfy `wild_bet_quota` by seeding fresh high‑Novelty candidates.\n6) HET‑FIRST — apply group‑fairness quotas by domain‑family and/or DPP/Max‑min repulsion before exploit lenses; log quotas and sampler policy id.\n\n**Named lenses (heuristics; policy‑level, not norms)**\nThe following **lens profiles** are **illustrative heuristics**. Contexts MAY reuse/modify them; they are **not** normative.\n• **Frontier‑sweeper** — maintain attention on the full front; promote only when `backstop_confidence` holds.  \n• **Barbell** — enforce `explore_share ≥ θ` with a `wild_bet_quota`; otherwise exploit top‑trust region.  \n• **Spike‑first** — pick highest **Use‑Value** subject to `ConstraintFit=pass` and a small **Cost‑to‑Probe** cap.  \n• **Safety‑first** — minimize **SafetyRisk** subject to `Use‑Value ≥ θ` and `ConstraintFit=pass`.  \n• **Platform‑option** — maximize **Option‑Value** under probe cost bounds.  \n• **Pilot‑then‑scale** — optimize **Use‑Value** on pilot scope with `BackstopConfidence ≥ L1`; widen `G` once **R** holds.  \n• **Heterogeneity‑first (policy id).** Eligibility → Dominance → Tie‑breakers; Hard gate: FamilyCoverage ≥ k, MinInterFamilyDistance ≥ δ_family; Fairness quotas: ≤1 candidate per sub‑family at pre‑front sampling; DPP/Max‑min sampler allowed.\n**Conformance (lens recording).** A decision that uses any lens **MUST** record its **lens id** alongside `EmitterPolicyRef`. (This restates and localizes C19‑3.)\n",
        "conformance_checklist": "### C.19:5 - Conformance Checklist\n- **C19‑1** Each NQD generator call (C.18) **SHALL** cite `U.EmitterPolicyRef` (policy id + params) **and the active `InsertionPolicyRef`/`dedup_threshold` when not inherited**.\n- **C19‑2** The characteristic set & signs used for dominance **MUST** be declared; eligibility conditions applied first. *(References to C.18 generator operators are descriptive only; LOG exports no Γ.)*\n- **C19‑3** If a lens is used, its id MUST be recorded; do not label scalarized top‑1 as “frontier”.  \n- **C19‑4** Promotion of Surprise/Illumination into dominance MUST be explicit in policy.  \n- **C19‑5** USM/RSG gate applies: policy actions SHALL operate within the Context’s scope and enactable RSG states.\n- **C19‑6** Each selection lens **MUST** implement and document the pipeline` Eligibility (ConstraintFit=pass) → Dominance (declared set) → Tie‑breakers (declared)`. Any **promotion** of Surprise/Illumination into the dominance set **MUST** be named by lens/policy id and recorded in provenance.\n- **C19‑7 (LEX‑AUTH trigger).** Any change to `EmitterPolicy` defaults that affects domain‑family quotas/samplers (HET‑FIRST), or any change to `DescriptorMap` family coordinates, `DistanceDef`, or the `δ_family` threshold MUST be authored via **E.15 LEX‑AUTH** with a published **LAT**; the DRR SHALL carry the LAT pointer (see **CC‑DRR.6**). Record policy/card ids in SCR.\n- **C19‑8**  When the Heterogeneity‑first lens is used, provenance MUST include: (i) the family‑quota vector (including the default triad quota k), (ii) the subFamilyDef id (from F1‑Card) if sub‑family quotas apply, (iii) the sampler class, seed, and policy id.\n\n**Illumination & Diversity_P.** Illumination is **report‑only telemetry over `Diversity_P`** (coverage/QD‑score; published as `IlluminationSummary`). It informs exploration health and tie‑breaks; it is **not** a dominance characteristic by default.\n\nWhen **Name Cards** (F.18) use NQD-CAL for lexical search, the underlying `DescriptorMap` and `Diversity_P` **MUST** follow the **head-term family** discipline:  \n– group label candidates into families by lexical head (base noun/verb, ignoring minor prepositions and inflection);  \n– compute `Diversity_P` and any illumination/coverage telemetry over these families (cf. `FamilyCoverage`, `AliasRisk`), not over individual string variants.  \nThis requirement prevents treating small morphological tweaks of one head as a “diverse” frontier and keeps lexical NQD-fronts honest.\n\n**Baseline profile (informative, context‑local template).**\n`EmitterPolicy#NQD-Default-2025`:\n    class=`UCB`, explore_share=`0.3–0.5`, temperature `τ=moderate`,\n    rebalance_period=`Context default`, wild_bet_quota=`≥0`,\n    backstop_confidence=`policy L1`, epsilon_dominance=`ε=0`,\n    cell_capacity=`K=1`.\nContexts MAY clone/adjust; if used, record its id in provenance.\n\n**Didactic quickstart (Context).**\n- Start with policy class = `UCB` or `Thompson`; set `explore_share≈0.3–0.5`, `τ` moderate.  \n- Name the dominance set: `{Q components, Novelty@context, ΔDiversity_P}` with `ConstraintFit=pass` as gate.  \n  *(Use‑Value / Cost‑to‑Probe may appear in **lenses** or **constraints**; they are **not** in the default dominance set.)*\n- Pick a lens for the final choice (or stick to frontier if undecided); record the lens id in the decision memo.\n",
        "archetypal_grounding": "### C.19:6 - Archetypal Grounding\n**System.** Policy‑driven A/B of architectural variants: Eligibility = constraint‑fit; Dominance = {Q components, Novelty@context, ΔDiversity_P}; lens = 'Frontier‑sweeper' vs 'Barbell'.\n**Episteme.** Method‑family portfolio in SoTA pack: fairness quotas across traditions; lens id recorded; Illumination used as tie‑breaker only unless promoted.\n",
        "bias‑annotation": "### C.19:7 - Bias‑Annotation\nNo global scalarisation of partial orders; ordinal scales excluded from arithmetic; all selections record lens id and policy id; notation/tool neutrality.\n",
        "consequences": "### C.19:8 - Consequences\n• Transparent exploration budgets. • Repeatable lens‑based selections. • Heterogeneity preserved without illegal aggregates.\n",
        "rationale": "### C.19:9 - Rationale\nPost‑2015 exploration practice (bandits/BO/RL with QD) shows policies must be explicit, auditable, and editioned; LOG provides that governance.\n",
        "relations": "### C.19:10 - Relations\nBuilds on: Decsn‑CAL, B.3. Coordinates with: C.18, C.17, G.5, G.9.\n",
        "c.19:end": "### C.19:End\n"
      },
      "content": "### C.19:End\n",
      "metadata": {},
      "part": "C",
      "cluster": null
    },
    {
      "id": "C.19.1",
      "title": "Bitter‑Lesson Preference (BLP)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## C.19.1 - Bitter‑Lesson Preference (BLP)\n\n**One‑screen purpose (manager‑first).**\nEstablish, at **governing policy** level, the empirical **Bitter Lesson**: **prefer general, scale‑amenable methods**—those that improve with **more data/compute/capacity and greater freedom‑of‑action**—over narrow hand‑crafted heuristics **when safety and legality are equal**. Exceptions require a transparent **Scale‑Audit** under the parity harness. \n\n**Builds on.** C.19 (E/E‑LOG), C.24 (Agent‑Tools‑CAL; **ATC‑2**), B.3 (Assurance), E.3 (Precedence), E.5 (Guard‑Rails).\n**Coordinates with.** G.5 (Selector), G.8 (SoS‑LOG Bundles), G.9 (Parity), G.11 (Refresh‑Telemetry), A.0 (On‑Ramp).\n**Keywords.** general‑method preference; scale‑amenability; **BLP‑waiver**; iso‑scale parity; **Scale‑Audit**; slope vector; **α/δ tolerances**.\n",
        "problem": "### C.19.1:1 - Problem frame\n\nBespoke heuristics can win locally but **do not scale**; general methods (search/learning/planning) **improve with scale** and transfer across bridges/planes. Without a standing policy, selectors drift toward hand‑craft and single‑winner leaderboards, violating parity and lawful orders. \n",
        "c.19.1:2___policy_clauses_(normative;_synchronized_with_core)": "### C.19.1:2 - Policy clauses (normative; synchronized with Core)\n\n**BLP‑1 — Scale‑Audit requirement.**\nAny DRR that selects a **narrower/hand‑engineered** method over a **general/scalable** alternative **MUST** include a **Scale‑Audit**:\n(a) **Parity harness**: equal **FreshnessWindows**, a common **ComparatorSet**, **replicates/seeds**, **portfolio‑first** evaluation; **Dominance = ParetoOnly** unless a CAL policy says otherwise (policy‑id cited).  \n(b) **Budget sweeps**: vary **compute**, **data**, and **FoA** within a fixed safety envelope; **pin** any unsweepable knob and record the invariant. \n(c) **Slopes & uncertainty**: report ∂quality/∂compute, ∂quality/∂data, and (where applicable) ∂coverage/∂FoA, with **CI/error bars** and **edition/policy pins** in telemetry. Use **bootstrapped CIs** or repeated‑seed estimates; disclose heteroscedasticity handling.\n(d) **Resources**: publish **Resrc‑CAL** accounts (time/energy/FLOPs) and assurance deltas (B.3). \n(e) **Objective vector**: list **Q/Risk/Cost** and—**only if policy promotes them**—illumination/coverage telemetry metrics. \n(f) **DoE recipe**: for ≥2 active knobs, apply a **fractional factorial** or **Latin‑hypercube** with ≥ 3 levels per knob to avoid aliasing; justify any lower design.  \n(g) **Knee & regret tests**: if claiming a heuristic wins, show either (i) a **knee** inside the audited window for the general method (per SLL‑5 policy thresholds) or (ii) **budget‑constrained regret** over the sweep where the heuristic dominates within CI.\n\n**BLP‑2 — Preference rule (with α/δ tolerances).**\nAmong admissible options with comparable assurance (within **δ**) and budget (within **α**), prefer the method whose **slope vector** **Pareto‑dominates** over the audited range; if no dominance within error bounds, prefer the **more general** method; else resolve by the **E/E‑LOG** tie‑breakers declared in policy. (Agentic contexts implement this as **ATC‑2**; **BLP_delta_α/δ** live in **ATC.Policy**.)  \n\n> **BLP‑2.1 — Valid waiver grounds (override transparency).**\n> Overrides of BLP‑2 are allowed **only** when:\n> • **Deontic override:** regulation/ethics make the general method inapplicable (E.5/E.3).\n> • **Scale‑probe overturn:** under **iso‑scale parity** in the declared **ScaleWindow**, the heuristic **sustainedly outperforms** with uncertainty accounted for.\n> • **Complementary bias:** the heuristic is an **inductive bias** that **improves** the general method **without blocking scale** (graceful degradation as `S` grows).\n> All overrides record a **BLP‑waiver** with rationale, owner, and expiry/review in the DRR. \n\n**BLP‑3 — Minimal‑prescription default.**\nAuthor **rules‑as‑prohibitions** (negative constraints) instead of stepwise scripts; encode limits in **Φ policy tables** (and **Φ_plane**) and allow agents to **sequence autonomously** within those constraints. Scripts are permissible only when mandated by safety/regulation or with compelling DRR evidence reviewed under E.3/E.5. \n\n**BLP‑4 — Heuristic‑Debt register (mandatory).**\nAny admitted heuristic is recorded as **Heuristic Debt** with scope, owner, expiry/review window, and a de‑hardening plan; track in **CalibrationLedger/BCT** and cite in SCR. \n\n**BLP‑5 — Continuous‑learning posture.**\nWhere product policy allows, enable **feedback‑driven adaptation** (preference learning, critique loops) within Guard‑Rails and privacy controls; disabling adaptation requires DRR justification and review date. \n\n**BLP‑6 — Precedence & safeguards.**\nBLP is constitutional (instantiates **P‑10/P‑11/P‑7/P‑1**), but **does not supersede Guard‑Rails (E.5) or precedence rulings (E.3)**. Where **NQD/E/E‑LOG** promotes illumination into dominance, **BLP adopts that lens** for the audited window.  \n\n**BLP‑7 — Publication discipline.**\nScale‑Audit artefacts **SHALL** be exported to **G.11** with edition pins, CI level, α/δ, ComparatorSet, and **BLP.Policy@Context** reference so downstream selectors can reuse evidence without re‑running audits.\n",
        "conformance_checklist": "### C.19.1:3 - Conformance Checklist (CC‑BLP)\n\n1. **α/δ tolerances** declared in DRR or via policy profile (and CI level stated).\n2. DRR includes a **Scale‑Audit** (BLP‑1a–g) with slopes, **CI**, edition/policy pins, and Resrc‑CAL.\n3. Selection cites **BLP‑2** and precedence checks.\n4. Any heuristic is logged as **Heuristic‑Debt** with expiry and de‑hardening plan.\n5. Authoring defaults to **rules‑as‑prohibitions**; deviations are DRR‑justified and safety‑anchored.\n6. **Resrc‑CAL** accounts and assurance deltas reported.\n7. **Replicate counts/seeds** and **confidence intervals** recorded for slope estimates; heteroscedasticity handling disclosed.\n8. Audit artefacts exported to **G.11** with **BLP.Policy@Context** id.\n",
        "c.19.1:4___anti‑patterns_&_remedies": "### C.19.1:4 - Anti‑patterns & remedies\n\nSingle‑winner leaderboards; hidden budget mixing; promoting illumination into dominance **without policy**; missing edition pins; heuristics without expiry; slope estimates without CI or with aliased designs → **remedy** with G.9 parity + edition pins, explicit **policy‑ids**, DRR publication, **Heuristic‑Debt** entries, and BLP‑1f DoE discipline. \n",
        "archetypal_grounding": "### C.19.1:5 - Archetypal grounding (post‑2015; informative)\n\n* **LLMs:** prompt‑programs, **retrieval‑augmented** and **MoE** policies vs narrow task‑specific pipelines; portfolio‑first selection across editions/budgets.\n* **RL & planning:** model‑based optimization/general agents vs hand‑coded controllers (subject to α/δ and safety).\n* **Preference learning:** **RLHF ↔ DPO** families.\n* **QD/OEE:** MAP‑Elites/**CMA‑ME**/**DQD**/**QDax**; **POET/Enhanced‑POET**; illumination remains **report‑only telemetry** unless policy promotes it. \n",
        "c.19.1:6___payload_—_exports": "### C.19.1:6 - Payload — exports\n\n`BLP.Policy@Context` (UTS row; editioned):\n`⟨PreferenceDefault, α/δ tolerances + CI, Scale‑Audit recipe (G.9 link; DoE), WaiverRegister{reason, owner, expiry}, E/E‑LOG lens policy‑ids, ATC.PolicyRef? (agentic), G.11.TelemetryPins⟩`.\n\n**UTS row template (conceptual; pencil‑ready).**\n`BLP.Policy@Context := PreferenceDefault=(prefer‑general|neutral), α/δ=(α=…, δ=…, CI=…), Scale‑Audit=(parity=G.9; sweep=S={…}; DoE=factorial|LHD; kneeTest=policy‑τ), WaiverRegister=[{reason=…, owner=…, expiry=…}], E/E‑LOG=(policyIds=…), ATC.PolicyRef=(…), TelemetryPins=(edition=…, seeds=…, comparatorSet=…)`.\n",
        "relations": "### C.19.1:7 - Relations\n\n**Depends on:** **G.5/G.9** (selector/parity), **G.11** (refresh telemetry), **C.5** (Resrc‑CAL), **C.18** (NQD‑CAL), **C.19** (E/E‑LOG), **F.7/F.9** (Bridges, CL/Φ/Ψ). **Constrained by:** **E.5** Guard‑Rails and **E.3** precedence. \n\n> *Memory hook.* **Prefer what scales; explain when you don’t.**\n",
        "c.19.1:end": "### C.19.1:End\n"
      },
      "content": "### C.19.1:End\n",
      "metadata": {},
      "part": "C",
      "cluster": null
    },
    {
      "id": "C.20",
      "title": "Composition of `U.Discipline` (Discipline‑CAL)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## C.20 - Composition of `U.Discipline` (Discipline‑CAL)\n\n**Builds on.** **C.2 KD‑CAL** (F–G–R & CL routing), **A.19/G.0 CG‑Spec** (comparability), **F.9 Bridges** (cross‑Context alignment), **E.10 LEX** (registers & twin labels). **Coordinates with.** **C.21** (Discipline‑CHR, field health), **C.23** (Method‑SoS‑LOG), **F.17–F.18** (UTS). \n",
        "problem": "### C.20:2 - Problem\nWithout a **composition calculus** for disciplines:\n* fields degenerate into labels; editions and rival **Traditions/Lineages** blur;  \n* cross‑Context reuse silently drops meaning (no Bridge/CL), or performs illegal aggregations (means on ordinals; unit mixing);  \n* selectors (Part G) cannot lawfully gate methods because maturity/evidence are not tied to a field’s canon and carriers.\n",
        "forces": "### C.20:3 - Forces\n| Force | Tension |\n|---|---|\n| **Pluralism vs Cohesion** | Rival traditions must co‑exist ↔ a discipline holon must present a coherent public surface. |\n| **Locality vs Federation** | Meaning is context‑local (rooms) ↔ reuse needs Bridges with CL and recorded loss notes. |\n| **Rigor vs Agility** | CG‑Spec legality, KD‑CAL lanes ↔ practical authoring and edition flow (UTS/DRR). |\n| **Didactic surface vs Assurance depth** | Human‑readable Discipline Card ↔ auditable F–G–R & provenance. |\n",
        "solution": "### C.20:4 - Solution — the **Discipline holon** and Γ_disc\n\n#### C.20:4.1 - U.Types (minting & registers)\n* **`U.Discipline`** — a **Holon** that composes an **EpistemeCanon**, **Standards/Practices**, and **Organisational Carriers** into a durable **unit of talk** (R‑core name; twin labels).  \n* **`U.AppliedDiscipline`**, **`U.Transdiscipline`** — subtypes of `U.Discipline`.  (**Kernel U‑types; LEX‑governed**).\n* **`U.Tradition`**, **`U.Lineage`** — auxiliary holons that organise variants/editions within a `U.Discipline`.  \n\n**Placement/LEX.** `U.Discipline` and its subtypes are **Kernel U‑types** introduced under the **Open‑Ended Kernel** & **Ontological Parsimony** guards (**A.5**, **A.11**) and registered per **E.10/F.17**. This CAL **uses** them, it does not redefine them. If not yet present in A‑cluster, mark as **“provisionally minted”** and open a DRR to finalize placement (E.10 V‑ladder). \n\nAll are **UTS‑published** with **twin labels**; minting follows **E.10** registers/prefix policy and **A.11** parsimony.\n\n#### C.20:4.2 - What a `U.Discipline` is / is not\n* A `U.Discipline` is **not** a `U.BoundedContext` and **not** a **Domain**. **Domain** remains a *catalog label* (stitched to D.CTX + UTS): **Discipline ≠ Domain** is enforceable via **E.10 LexicalCheck**; any cross‑Domain/Context reuse **MUST** cite a **Bridge (F.9) + CL + loss notes**; penalties to **R** only; **F/G invariant** (USM/KD‑CAL). \n* **Comparability** of a discipline flows **only through** the discipline’s **CG‑Spec** entries (no ad‑hoc formulas).  \n* Cross‑Context/Tradition reuse **MUST** use **Bridge(s)** with **CL** and loss notes; **CL penalties route to R** (KD‑CAL/B.3); **F/G remain invariant**.  \n* Public naming surfaces obey **LEX** (I/D/S; twin labels; banned heads); “discipline column” is **didactic only** and **carries no semantics** (enforced by LexicalCheck).\n\n#### C.20:4.3 - Constructor **Γ_disc** (CAL export)\n*Signature.*  \n`Γ_disc : ⟨EpistemeCanon, StandardsSet, OrgCarriers, {Bridges}, Policy⟩ → U.Discipline`  \n*Intent.* Fold the three constituents into a `U.Discipline`, **preserving provenance**, publishing UTS cards, and enabling lawful comparability via referenced **CG‑Spec** rows.  \n*Obligations.*  \n1) **Provenance & lanes.** Each imported episteme/standard declares **A.10 anchors** and lane tags **{TA, VA, LA}**; freshness windows are recorded.  \n2) **Assurance fold.** Use KD‑CAL weakest‑link on R with **Φ(CL)** (and, where applicable, **Φ_plane** for ReferencePlane crossings) **table‑backed and monotone**; publish policy ids. For any justification **path P**, compute **`R_eff(P) = max(0, min_i R_i − Φ(CL_min(P)))`**; for parallel independent lines to the *same* claim take **`R(Γ) = max_P R_eff(P)`**; **`F(Γ)=min`** along used paths. No thresholds inside CHR/CAL (Acceptance‑only). Unknowns propagate as {pass|degrade|abstain} to Acceptance. \n3) **CG‑Spec guard.** Any numeric comparison/aggregation in Discipline reports **MUST** cite the discipline’s **CG‑Spec** with lawful **ScaleComplianceProfile (SCP)**, **Γ‑fold**, and **MinimalEvidence**; units/scale/polarity legality via **MM‑CHR/CSLC** precedes aggregation.  \n4) **Scale/Unit/Polarity legality.** Before any comparison/aggregation, **prove legality via MM‑CHR/CSLC** and cite **CG‑Spec characteristic ids** used in the fold (A.17–A.19).\n5) **ReferencePlane guard.** When crossings touch `world|concept|episteme`, apply **CL_meta** and route penalties to **R** only; record **plane** on the UTS row.\n6) **Edition discipline.** Changes to canons/standards that alter computed ⟨F,G,R⟩ **create a new edition**; DRR captures the rationale; UTS lifecycle records transitions.  \n7) **No stealth globalisation.** Cross‑Context mappings are **by Bridge only**; “by‑name reuse” is forbidden** even with similar labels.\n\n#### C.20:4.4 - Discipline ESG (state graph, informative surface)\n\nExport a **Discipline.ESG** with named states and guarded transitions (e.g., *Emerging → Consolidating → Codified → Fragmenting*), where **guards reference C.21 metrics** (CHR‑typed; **Scale/Unit/Polarity + freshness windows**) and cite **CG‑Spec ids**; **all thresholds live only in AcceptanceClauses** (G.4). ESG is **descriptive**; all gating remains in CHR/CAL/LOG packs.\n",
        "archetypal_grounding": "### C.20:5 - Archetypal Grounding *(Tell–Show–Show)*\n\n| Slot | **System** (safety code in a factory) | **Episteme** (discipline canon across editions) |\n|---|---|---|\n| **Object** | Production line with hazardous operations | “Safety engineering” as *describedEntity target* (accident models, tolerable risk) |\n| **Concept** | Acceptance clauses & evaluation templates bound to rigs/windows | Canon texts: causality models, design rules, proofs/benchmarks (e.g., **formal knowledge bases**, **proof artefacts**, **concept schemas**) |\n| **Symbol** | Local SOP/notation sets for checklists | Notation packages (CLIF, RDF/TriG, proof scripts) |\n| **Γ_disc assembly** | Fold {line‑specific standard, plant procedures, certifying unit} into **`Discipline: Safety‑Plant‑A`** | Fold {canon papers, formal models, journals/committee} into **`Discipline: Safety‑Engineering`** with **Traditions** (e.g., system safety vs resilience engineering) |\n| **Evidence lanes** | LA test campaigns (freshness windows), VA design proofs, TA tool quals | VA proofs over kinds, LA replications/meta‑analyses; TA for checkers |\n",
        "bias‑annotation": "### C.20:6 - Bias‑Annotation\n**Lenses:** Governance (naming/UTS), Architecture (CAL+CHR split), Onto/Epist (discipline ≠ domain; triangle fidelity), Pragmatic (authoring/editions), Didactic (twin labels; System/Episteme scenes). **Scope:** context‑local; no “global discipline”.\n",
        "conformance_checklist": "### C.20:7 - Conformance Checklist (normative)\n| ID | Requirement | Purpose |\n|---|---|---|\n| **CC‑C20‑1 (CG‑Spec linkage).** | A `U.Discipline` **SHALL** declare the **CG‑Spec** ids and **CHR characteristic ids** behind any comparison/aggregation; thresholds live only in **Acceptance** clauses referenced by those CG‑Specs. | Auditable comparability; no illegal ops. |\n| **CC‑C20‑2 (Bridge‑only reuse).** | Any cross‑Context/Tradition use **SHALL** cite **Bridge id + CL + loss notes**; penalties **route to R only**; **F/G invariant**. | Prevent silent globalisation; align with KD‑CAL. |\n| **CC‑C20‑3 (ReferencePlane).** For any crossing touching `world|concept|episteme`, **publish plane** and apply **Φ(CL)** (and **Φ_plane**, where applicable) — both **MUST** be **monotone, bounded, table‑backed**; **unknowns** propagate as **{pass|degrade|abstain}** into **Acceptance** with **SCR note**; **no silent `unknown→0`**. |\n| **CC‑C20‑4 (Γ_disc integrity).** | `Γ_disc` **MUST** record lane tags and freshness windows for all imported evidence; **Φ(CL)** **MUST** be monotone and table‑backed per policy. | Deterministic assurance; hygiene of penalties. |\n| **CC‑C20‑5 (Edition & DRR).** | Discipline editions **SHALL** be recorded via **UTS lifecycle** with DRR links; no silent rewrites or renames. | Traceable evolution. |\n| **CC‑C20‑6 (LEX/I‑D‑S).** | `U.Discipline` names **SHALL** follow **LEX** (twin labels; registers; banned heads). **Domain** mentions are catalog‑only. | Register hygiene; avoid “Domain = Discipline”. |\n| **CC‑C20‑7 (Crossing visibility hooks).** | Any **cross‑stance / cross‑Context / cross‑plane** reference in Discipline materials **SHALL** publish a **CrossingSurface** for the crossing (**E.18**; Bridge+UTS **A.27**; BridgeCard **F.9**) and expose it via `Expose_CrossingHooks` (**G.10‑3**). Published crossings **MUST** be checkable for **LanePurity** (CL→R only; F/G invariant; Φ tables present) and **Lexical SD** (**E.10**) under the active GateProfile / GateChecks (**A.21**). | Prevents implied crossings; makes provenance auditable & replayable. |\n| **CC‑C20‑8 (Discipline column is didactic).** | Any use of a “discipline column” in tables is **didactic only**; semantics are carried by **UTS rows + Bridges**; **Domain** remains a catalog stitch (**E.10/F.17**). |  |\n| **CC‑C20‑9 (Lexical firewall).** | Normative sections remain **notation/tool‑neutral**; vendor/tool tokens are avoided (see **E.5.1**). |  |\n\n#### C.20:7.1 - Canonical rewrites (anti‑ambiguity)\n* “TDD discipline” → **`Tradition: Test‑Driven`** *(Plain twin keeps “Tradition”)*.  \n* “Safety Discipline Owner” → **`Holder#DisciplineStewardRole:Safety‑Context`**.  \n* “ClinicalSafetyDomain Governance” → **`DisciplineSpec: Clinical‑Safety`** with comparability in **CG‑Spec**; the **Domain** mention remains a **D.CTX + UTS** catalog stitch.\n",
        "consequences": "### C.20:8 - Consequences\n**Benefits.** Auditable field composition; lawful federation across traditions; selector‑ready maturity/evidence linkage; didactic surface for stewardship.  \n+**Trade‑offs.** Discipline authoring requires CG‑Spec literacy and Bridge hygiene; paid back by safe reuse and clearer governance.\n",
        "rationale": "### C.20:9 - Rationale\nThe calculus keeps **describedEntity local**, **comparability lawful**, and **assurance explicit**. It aligns with KD‑CAL’s weak‑link folds and CL routing, with CG‑Spec’s **ScaleComplianceProfile (SCP)** and **Γ‑fold** rules, and with LEX twin‑label governance. It avoids “phlogiston disciplines” by tying fields to measurable CHRs (C.21) and evidence lanes.\n",
        "relations": "### C.20:10 - Relations\n**Builds on.** KD‑CAL (C.2); CG‑Spec (A.19/G.0); Bridges (F.9); LEX (E.10).  \n**Coordinates with.** C.21 (field‑health CHRs), C.22 (Problem‑CHR), C.23 (Method‑SoS‑LOG).  \n**Constrains.** G.2 **MUST** publish **TraditionCards**/**BridgeMatrix** sufficient for `Γ_disc` to assemble **≥2 Traditions** and **≥3 `U.BoundedContext`** per SoTA synthesis to avoid monoculture. G.5 selector **SHALL** cite Discipline **CG‑Spec ids** and **EvidenceGraph** rows when admitting families.\n",
        "c.20:end": "### C.20:End\n"
      },
      "content": "### C.20:End\n",
      "metadata": {},
      "part": "C",
      "cluster": null
    },
    {
      "id": "C.21",
      "title": "Field Health & Structure (Discipline-CHR)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## C.21 - Field Health & Structure (Discipline-CHR)\n\n> *Purpose.* Give FPF a **typed, auditable** way to speak about the *health, maturity, and structure* of a scientific/engineering **discipline**, without collapsing into taste, anecdotes, or single-number scores. The pattern defines a **portable set of Characteristics** and guards (legality, freshness, scope) that any Context can specialize.\n\n*This pattern supplies the CHR “vocabulary of health” for disciplines. C.20 composes the discipline; C.21 measures its health; Part G (G.2, G.12) harvests SoTA and operationalizes dashboards; Bridges keep meaning honest; penalties touch **R** only.*\n\n **Status & placement.** Part C (Architheory Specifications) → Cluster C.I (Core CHRs/CALs). \n  **Depends on:** **MM-CHR** (C.16), **KD-CAL** (C.2), **USM/Scope** (A.2.6), **Trust & Assurance** (B.3), **E.10 (LEX‑BUNDLE)**. \n  **Coordinates with:** **C.20 Discipline‑CAL** (what a `U.Discipline` is), **G.2** (SoTA palette), **G.12** (dashboard), **G.0** (CG‑Spec registry).\n",
        "problem": "### C.21:2 - Problem\n\nNarrative health claims cause three recurrent failure modes:\n\n1. **Illegality.** Averaging ordinals, mixing units, or comparing incommensurate Contexts ⇒ nonsense roll-ups.\n2. **Staleness.** Health “scores” rarely declare **freshness windows** or evidence lanes (TA/VA/LA).\n3. **Scope slippage.** “The field” is left implicit; cross-Context reuse lacks **Bridges & CL**, leading to silent semantic loss. Any numeric comparison/aggregation MUST cite a **CG‑Spec** row (characteristics, lawful **ScaleComplianceProfile (SCP)**, **Γ‑fold**, MinimalEvidence) before computation.\n",
        "forces": "### C.21:3 - Forces\n\n| Force                            | Tension                                                                                                                    |\n| -------------------------------- | -------------------------------------------------------------------------------------------------------------------------- |\n| **Comparability vs nuance**      | Need global pictures without erasing local meaning (Context, traditions, cohorts).                                         |\n| **Ordinal vs interval/ratio**    | Powerful stats tempt illegal ops on ranks and categories.                                                                  |\n| **Local evidence vs federation** | Health must be computed *in room* (Context slice) yet projectable across rooms via Bridges & CL (penalties to **R** only). |\n| **Recency vs stability**         | Health evolves; dashboards must reflect **freshness**, not just cumulative history.                                        |\n",
        "solution": "### C.21:4 - Solution — **Discipline Health Characterisation (DHC)**\n\n#### C.21:4.0 - Ontology quick sheet (normative, clarifying)\n**What “DHC” is.** DHC is a **CHR vocabulary pack** (intensional) that defines **Characteristics** + **Scales/Units/Polarity** for discipline health; it is not a document or a run.\n**Artifacts.**\n• **`U.DHCPack`** (I‑layer name; published as an episteme): the **slot set** (Characteristic/Scale declarations) for a Context.  \n• **`U.DHCMethodSpec`** (S‑layer): the **computational specification(s)** for deriving each DHC slot (e.g., replication‑window definition, CD‑index class), table‑backed; multiple per slot allowed, editioned separately.  \n• **`U.DHCSeries`** (episteme w/ `EditionSeries`): a **time‑indexed publication** of computed DHC readings for a Discipline×Context, each value bound to `…Ref.edition` for every referenced method/metric/distance.\n**Edition subjects.**  \n(i) **DHCPack.edition** — when the **slot semantics** (Characteristic/Scale) change.  \n(ii) **DHCMethodSpecRef.edition** — when a **computation method** (formula/class/policy) changes.  \n(iii) **DHCSeries.edition** — when the **published series** changes its content (not carriers).  \n**Publication.** Releases are **Work** on Carriers; **no** edition change unless content changes per `U.EditionSeries`.  \n**Ref discipline.** All bindings to packs/methods/distances **SHALL** use `…Ref.edition` (dot on the Ref).\n\nDefine a **portable minimal set** of CHR **slots**. Each slot is **CHR-typed** (Characteristic, Scale/Unit/Polarity per **A.17–A.18**), **Context-local**, and guarded by **USM** (Claim scope **G**), **freshness windows**, and **evidence lanes** (TA/VA/LA).  Contexts MAY extend the set; MUST NOT alter scale types illegally. \n\n**“Health” is a vector** of CHR‑typed coordinates; **no single scalar** is implied. Lawful scalarization lives in **Acceptance** (G.4) under an explicit **CG‑Spec ScaleComplianceProfile (SCP)** and **Γ‑fold** rules, and is never embedded in CHR.\n\n#### C.21:4.1 - Core Characteristics (kernel-portable names)\n\n1. **ReproducibilityRate** *(ratio ∈ [0,1]; polarity ↑; ReferencePlane=episteme; CG‑Spec‑bound)*\n   Fraction of tested claims/benchmarks that independent teams **replicate** under a declared **ContextSlice** and **Γ\\_time** window. **Lane tags:** LA (validation) with TA (typing) for protocols.\n\n2. **StandardisationLevel** *(ordinal; polarity ↑; ReferencePlane=episteme)*\n   {none, *emerging*, *de facto*, *de jure*}. **No mean.** Use medoid/mode; legal comparisons are ≤/=/> only. Tracks convergence on vocabularies, interfaces, or procedures.\n\n3. **AlignmentDensity** *(ratio; polarity ↑; ReferencePlane=episteme; CG‑Spec‑bound)*  \n   Density of **Substitution Bridges** (same **senseFamily**, CL≥2) between major `U.Tradition`s **per 100 DHC‑SenseCells** (G.2 F‑hooks) in the SoTA palette.  Substitution rule:  free substitution permitted at **CL=3**; at **CL=2** substitute only with extra‑guard (count in reporting, but this is not «free substitution») Units: `bridges_per_100_cells`. Cross‑Context use requires Bridge+CL; penalties → **R_eff** only.\n\n 4. **DisruptionBalance** *(interval; polarity = target band; ReferencePlane=episteme; CG‑Spec‑bound)*  \n  Relative share of **disruptive vs consolidating** works within **Γ_time** using a **registered CD‑index class** (editioned; cite **method id** in UTS). **Default plane:** *episteme*. Publish the **target band** via **Acceptance (G.4)**; not in CHR.\n   \n  5. **EvidenceGranularity** *(Context-declared: ordinal|ratio; polarity ↑; ReferencePlane=episteme)*  \n   If ratio: units = `claims_per_artifact` or `anchors_per_claim` (declare). If ordinal: publish level names and **ORD_COMPARE_ONLY**.\n   Fineness of evidential units and declared envelopes (experiment cards, benchmark tasks, audit granules). Encourages *smaller, well-scoped* claims over monoliths.\n\n  6. **MetaDiversity** *(portfolio dispersion; polarity ↑ to band; ReferencePlane=episteme; CG‑Spec‑bound)*  \n  Use entropy/HHI **over MethodFamily/Tradition shares** (method edition id in UTS); publish **guard‑band** as **Acceptance** binding; cross‑ordinal scalarisation is forbidden.\n  Entropy/Herfindahl-type dispersion across `U.Tradition`s, method families, or data regimes, bounded by a **Context-declared guard-band** (too low ⇒ monoculture; too high ⇒ incoherence).\n\n> **Typing & legality.** Each slot **MUST** declare **Scale/Unit/Polarity**; illegal ops (e.g., mean on ordinals; unit mixing) are **fail-fast** per **A.18/MM-CHR**.\n\n#### C.21:4.2 - Guard Macros (normative)\n\n* **ORD\\_COMPARE\\_ONLY(x)** — for **StandardisationLevel** (ordinal).\n* **UNIT\\_CHECK(x)** — forbid cross-unit aggregation (AlignmentDensity, ReproducibilityRate).\n* **POLARITY_CHECK(x)** — enforce declared polarity (↑/↓/target-band) per MM‑CHR.\n* **FRESHNESS(x; window)** — ensure values come from evidence within declared **Γ_time**; record **valid_until**; stale ⇒ {degrade|abstain} at Acceptance.\n* **PLANE_NOTE(x)** — record **ReferencePlane**; compute **CL^plane** on crossings; penalties → **R_eff** only.\n* **LANE\\_TAGS(x; {TA|VA|LA})** — annotate contribution lanes.\n* **SCOPE\\_COVERS(x; TargetSlice)** — enforce **USM** coverage of the computation.\n* **BRIDGE_CL(x; id, CL≥k)** — on cross‑Context roll‑ups, require **Bridge** with **CL**; penalties route to **R** only. If planes differ, apply **CL^plane** and cite **Φ_plane** policy id. **Hint:** for **AlignmentDensity** reporting, set **k=2** (CL≥2); **CL=3** counts as *free substitution*.\n\n#### C.21:4.3 - Legality Matrix (extract)\n\n| Operation     | ReproducibilityRate (ratio) | StandardisationLevel (ordinal) | AlignmentDensity (ratio) | DisruptionBalance (interval) |\n| ------------- | --------------------------: | -----------------------------: | -----------------------: | ---------------------------: |\n| mean          |                      **OK** |                     **FORBID** |                   **OK** |                       **OK** |\n| median        |                          OK |                         **OK** |                       OK |                           OK |\n| compare (<,>) |                          OK |                         **OK** |                       OK |                           OK |\n| unit mix      |                  **FORBID** |                            n/a |               **FORBID** |                          n/a |\n\n*Note:* For **MetaDiversity/EvidenceGranularity (ordinal)** use **median/mode**; forbid affine ops; unit mix always fails.\n",
        "interfaces_&_data_paths": "### C.21:5 - Interfaces & Data Paths\n\n* **Inputs.** `U.Discipline` from **C.20** (composition), SoTA **Palette**/**BridgeMatrix** from **G.2** (**DHC‑SenseCells** included), EvidenceProfiles from **G.4/G.6**.\n* **Outputs.** Per‑Context **DHC rows** (these six slots), **UTS** Name Cards with twin labels (E.5/F.17–F.18), **Registry/RSCR hooks** on method edition changes; feeds **G.12** (time‑series).\n* **Cross-Context reuse.** Only via **F.9 Bridges** with **CL** and **loss notes**; **Φ(CL)** penalties applied to **R** (never F/G).\n",
        "archetypal_grounding": "### C.21:6 - Archetypal Grounding (three fields)\n\n#### C.21:6.1 - Computer Vision (Benchmarks 2015→)\n* **ReproducibilityRate.** Ratio of independently reproduced results on ImageNet-style tasks within **rolling 24 mo** (LA lane).\n* **StandardisationLevel.** *de facto* for dataset specs and metrics in *Vision\\_2024*; *emerging* for robustness protocols.\n* **DisruptionBalance.** Use an editioned CD‑index class (e.g., Wu‑style disruption family) with method id; publish target band via Acceptance; annotate ReferencePlane=episteme.\n* **AlignmentDensity.** Bridges with **CL≥2** across sub-traditions (supervised vs self-supervised).\n* **MetaDiversity.** Entropy across method families (CNN/ViT/Hybrid) kept within guard-band to avoid monoculture.\n\n#### C.21:6.2 - Biomedicine (Gene–Disease Associations)\n* **ReproducibilityRate.** Fraction of associations replicated in independent cohorts within **Γ\\_time(36 mo)**; LA lane with TA (typing of protocols).\n* **StandardisationLevel.** *de jure* for certain reporting guidelines; *emerging* for pre-registration norms.\n* **EvidenceGranularity.** Move from “paper-level” to *claim-level* units (Context raises the score).\n* **DisruptionBalance.** Target band discourages sustained “novelty spikes” unbacked by replication.\n\n#### C.21:6.3 - Software Performance Engineering (SPE)\n* **StandardisationLevel.** *emerging* → *de facto* for SLO taxonomies and trace schemas across vendors.\n* **AlignmentDensity.** CL-rated Bridges between tracing ecosystems.\n* **ReproducibilityRate.** Share of publicly replicable perf claims in rolling windows.\n* **MetaDiversity.** Balance across load models, failure modes, and toolchains.\n\n#### C.21:6.4 - Decision‑Making (2015→)\n• ReproducibilityRate — share of causal effect estimates replicated across independent datasets within Γ_time; LA lane.\n• StandardisationLevel — *emerging* for identification checklists; *de facto* for SCM notation in leading stacks (ordinal; no means).\n• AlignmentDensity — CL‑rated Bridges between SCM/DoWhy‑style and RL/BO traditions per 100 DHC‑SenseCells.\n• MetaDiversity — dispersion across method families (SCM/RL/BO/DT) within guard‑band; entropy/HHI (units declared in CG‑Spec).\n\n#### C.21:6.5 - Evolutionary Architecture (software)\n• ReproducibilityRate — fraction of architecture fitness results reproduced on independent workloads (rolling 18–24 mo; LA lane).\n• StandardisationLevel — *de facto* for ADR/ATAM patterns; *emerging* for continuous fitness protocols.\n• AlignmentDensity — Bridges across ATAM/SAAM/ADR style guides (CL≥2) normalised per 100 DHC‑SenseCells.\n• MetaDiversity — portfolio dispersion across patterns (microservices, event‑driven, layered) with guard‑bands; no ordinal arithmetic.\n",
        "measurement_&_publication_procedure_(authoring_harness)": "### C.21:7 - Measurement & Publication Procedure (authoring harness)\n\n1. **Declare Context & TargetSlice.** (USM) Name editions, Standards, env params, `Γ_time`.\n2. **Collect evidence.** Bind sources via **G.6 EvidenceGraph**; tag lanes and freshness.\n3. **Compute DHC slots.** Enforce **Legality Matrix** and Guard Macros.\n4. **Bridge (if needed).** Map via **F.9**; attach **CL** and **loss notes**; apply **R** penalties.\n5. **Publish to UTS.** Name Cards (Tech/Plain), twin labels; **bind `DHCMethodSpecRef.edition`**, `DistanceDefRef.edition`, and, where templates are used, `DHCMethodRef.edition`; register RSCR triggers (method change, ScoringMethod/NormalizationMethod edits).\n6. **Dashboard.** Feed G.12 with time-series and guard-bands (disruption, diversity).\n",
        "bias_annotation": "### C.21:8 - Bias-Annotation (E-cluster lenses)\n\n* **Didactic.** Plain names + twin labels; one-screen tables for managers.\n* **Architectural.** No ordinals averaged; all cross-Context movement goes through Bridges+CL; penalties never touch F/G.\n* **Pragmatic.** Freshness-aware; unknowns tri-state; values are decision-support, not trophies.\n* **Epistemic.** Evidence lanes explicit; reproducibility is LA, typing is TA; validation distinct from verification in dashboards.\n",
        "conformance_checklist": "### C.21:9 - Conformance Checklist (normative)\n\n**CC-C.21-1 (CHR typing).** Every DHC slot **MUST** declare **Characteristic + Scale/Unit/Polarity**, with CSLC legality proved before any aggregation.\n**CC-C.21-2 (Freshness).** Published values MUST carry Γ_time selector and freshness window; stale rows escalate to {degrade|abstain} in **G.4 Acceptance**.\n**CC-C.21-3 (Plane).** ReferencePlane declared; cross‑plane re‑use publishes **CL^plane** (policy id) alongside CL; both penalties route to **R_eff**.\n**CC‑C.21‑4 (DesignRunTag).** Every DHC row SHALL declare **DesignRunTag ∈ {design, run}**; design‑ and run‑characteristics **not mixing** in one value/aggregate.\n**CC-C.21-5 (Lane tags).** Each value **MUST** tag **TA/VA/LA** lanes of contributing evidence.\n**CC-C.21-6 (Ordinal discipline).** **StandardisationLevel** is ordinal; **no means**, **no z-scores**.\n**CC-C.21-7 (Scope).** All computations declare **TargetSlice**; **USM** membership is decidable and deterministic.\n**CC-C.21-8 (Bridges).** Cross-Context comparisons/publishers **MUST** cite **Bridge id + CL**; penalties route to **R\\_eff**, never to F/G.\n**CC-C.21-9 (UTS).** Publish DHC rows as **UTS Name Cards** with **twin labels** (Tech/Plain).\n**CC‑C.21‑10 (Registry).** DHC methods are table-backed; silent method changes are forbidden (**bump `DHCMethodSpecRef.edition` + RSCR trigger**). \n**CC-C.21-11 (Unknowns).** Unknown inputs propagate tri-state {pass|degrade|abstain} to Acceptance; **no `unknown→0` coercion**.\n**CC-C.21-12 (No tool/vendor tokens).** Core narrative follows **E.5.1** (Lexical Firewall).\n**CC-C.21-13 (CG‑Spec citation).** Any numeric operation (comparison/aggregation) in DHC **MUST** refer to **CG‑Spec** (characteristics, **ScaleComplianceProfile (SCP)**, **Γ‑fold**, MinimalEvidence).\n**CC-C.21-14 (Φ‑policies).** **Φ(CL)** and **Φ_plane** — **monotone** and **table‑backed**; published by policy id.\n**CC‑C.21‑15 (Ref discipline).** Any edition pinning **SHALL** appear as `…Ref.edition` on the relevant reference field (DHCPack/MethodSpec/DistanceDef/DHCMethodRef); bare `…Edition` fields are non‑conformant.\n**CC‑C.21‑16 (Role kit, informative).** Use standard roles from F.4: `DisciplineStewardRole` (governs DHCPack), `DHCMethodAuthorRole`, `DHCSeriesPublisherRole`. Roles are **design‑time**; values are **run‑ or design‑stance** per slot and must declare **ReferencePlane**.\n",
        "consequences": "### C.21:10 - Consequences\n\n**Benefits.** Lawful comparisons; freshness-aware governance; explicit cross-tradition alignment; dashboards that don’t lie by averaging ranks.\n**Costs.** Some ceremony (scales, windows, lanes, bridges), offset by template macros and UTS automation.\n**Risks avoided.** “Phlogiston disciplines” (charisma-driven fields) fail DHC audits; **No-Free-Lunch** preserved by G.5 (selector returns sets, not universal scalars).\n",
        "rationale": "### C.21:11 - Rationale (post-2015 signals & practice)\n\n* **Replication & credibility (2015→).** Field-level health in SciSci emphasizes **replicability**, *fresh* evidence windows, and claim-level units—captured by **ReproducibilityRate** and **EvidenceGranularity**.\n* **Disruption vs consolidation (2019→).** Empirical “disruption indices” distinguish papers that open new lines from those that refine—hence **DisruptionBalance** with *target bands*, not monotone “more is better.”\n* **Standardization waves (2016→).** Package/ecosystem norms show ordinal trajectories (none→emerging→de facto→de jure); **ordinal typing** prevents illegal arithmetic.\n* **Plural traditions (ongoing).** Mature fields maintain **bridges** with explicit **loss notes**; **AlignmentDensity** rewards CL-rated bridges without semantic collapse.\n\n*(Names are illustrative of contemporary practice; the CHR is notation-agnostic and tool-neutral.)*\n",
        "relations": "### C.21:12 - Relations\n\n* **Builds on:** **A.17–A.18** (Characteristic/CSLC), **A.2.6** (USM scopes), **B.3** (assurance lanes), **C.16** (MM-CHR templates).\n* **Coordinates with:** **C.20** (what a `U.Discipline` *is*), **G.2** (SoTA palette and BridgeMatrix), **G.12** (Dashboard operationalization), **G.9** (parity harness for fair comparisons).\n* **Constrains:** **G.10** (pack ships DHC rows + method ids), **G.11** (refresh windows/decay), **G.5** (selector may reference DHC only via admissible predicates; no cross‑ordinal scalarisation). **Coordinates:** **F.9** (Bridges for cross‑Tradition comparisons).\n",
        "annex_—_author’s_quick_template_(copy_paste)": "### C.21:13 - Annex — Author’s quick template (copy-paste)\n\n```\nC.21.DHC(Context: <name/edition>; TargetSlice: <tuple>; Γ_time: <policy>)\n  ReproducibilityRate:\n    value: <0..1>   lane: LA   window: <…>   scope: <…>\n  StandardisationLevel:\n    value: {none|emerging|de_facto|de_jure}   compare_only: true\n  AlignmentDensity:\n    value: <ratio>   units: bridges_per_100_DHC_SenseCells   CL_min: 2   scope: <…>\n  DisruptionBalance:\n    value: <−1..1>   method: <CD-index class / edition>   target_band: [l,u]\n  EvidenceGranularity:\n    value: <ordinal|ratio per Context>   notes: <…>\n  MetaDiversity:\n    value: <entropy/HHI>   target_band: [l,u]\nGuards: ORD_COMPARE_ONLY(StandardisationLevel), UNIT_CHECK(*), FRESHNESS(*), LANE_TAGS, SCOPE_COVERS, BRIDGE_CL(if x-Context)\nPublish: UTS twin labels; RSCR triggers on method edition change.\n```\n",
        "c.21:end": "### C.21:End\n"
      },
      "content": "### C.21:End\n",
      "metadata": {},
      "part": "C",
      "cluster": null
    },
    {
      "id": "C.22",
      "title": "Problem Typing & TaskSignature Assignment (Problem-CHR)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## C.22 - Problem Typing & TaskSignature Assignment (Problem-CHR)\n\n**Purpose.** Give FPF a **lawful, minimal, and portable** way to speak about “the problem we face” so that the **selector** (G.5) can legally admit/abstain without prose or guesswork. We do this by (i) **typing problems** with CHR‑grounded traits and (ii) **binding** them to a **TaskSignature (S2)** that downstream architheories can consume. The Standard is **Context‑local**, evidence‑anchored, tri‑state‑aware, and bridge‑savvy. TaskSignature is *minimal* but sufficient for **eligibility**, **acceptance**, and **policy‑governed** choice. \n\n**Status & placement.** Part C (Architheory Specifications) → Cluster C.I (Core CHRs/CALs).\n**Depends on:** **C.16 MM‑CHR** (measurement legality), **G.5** (selector S2/S3), **G.0** (CG‑Spec invariants).\n**Coordinates with:** **G.4** (Acceptance/Evidence profiles), **C.23** (MethodFamily admissibility & maturity), **C.18 NQD‑CAL** (QD/illumination), **C.19 E/E‑LOG** (emitters/policies), **E.10** (LEX).\n",
        "intent": "### C.22:1 - Intent\n\nOperationalise No‑Free‑Lunch discipline in selection by ensuring every run‑time decision sees a **typed TaskSignature (S2)**, not a paragraph, and that **“problem”** (method unknown) is cleanly separated from **“task”** (method known; signature bound). The signature is the **smallest CHR‑typed set** sufficient to drive **Eligibility → Acceptance → policy‑governed selection** without illegal arithmetic or silent coercions; crossings are auditable (Bridge+CL → **R_eff only**).",
        "problem": "### C.22:5 - Solution — **Problem‑CHR** (fields) + **TaskSignature (S2) binding** *(normative)*\n\n#### C.22:5.1 - Minimal CHR fields (tri‑state aware).\nEach field is **CHR‑typed** (Characteristic/Scale/Unit/Polarity; MM‑CHR discipline). Every predicate admits `unknown` (tri‑state). Unknowns must propagate to {degrade|abstain|sandbox} per Acceptance/EvidenceProfile policy (recorded in SCR). (G.4/G.6 alignment)\n\n* **`DataShape`** — data regime & admissible transforms (e.g., tabular, sequence, graph; density; stationarity claims).\n* **`NoiseModel`** — uncertainty class / robustness envelope (e.g., iid Gaussian; heavy‑tailed; adversarial budget).\n* **`ObjectiveProfile`** — objective heads (**Scale/Unit/Polarity** and **ReferencePlane** declared), polarity, and **lawful orders** (lexicographic, Pareto, medoid/median where legal). **Weighted sums across mixed scale types are forbidden**; ordinal heads use order‑only guards. For QD tasks, explicitly enumerate **Q (quality)**, **D (diversity)**, and **QD‑score** heads; see **DominanceRegime** below.\n* `RegularityTraits` — method‑relevant structure (**convexity/differentiability/separability/monotonicity**) as CHR‑typed predicates with guard‑macros (e.g., `ORD_COMPARE_ONLY`, `UNIT_CHECK`, `POLARITY_CHECK`). Include `ConditionClass` (e.g., stiffness/κ‑proxies) where applicable.\n* **`Constraints`** — explicit hard/soft constraint classes (feasibility predicates; **ResourceEnvelope**/**RiskEnvelope**). **Thresholds live in Acceptance (G.4) only; never inside CHR or code paths.**\n* **`ShiftClass/Stationarity`** — CHR‑typed claims about regime stability (iid | covariate‑shift | concept‑drift | adversarial). Default=`unknown`. Acceptance/Flows MUST honor this in gating or abstain.\n* `EvidenceGraphRef (A.10)` — carriers & **lane tags (TA/VA/LA)** with **freshness windows**; **no self‑evidence**; default Γ‑fold = **weakest‑link** unless CAL proves an alternative.\n* `ScopeSlice(G)` — **USM** slice of **describedEntity/scope** to bound claims (discipline governance in **CG‑Spec**; Domain is a catalog mark only).\n* `Size/Scale` — size/condition proxies (**n, m, κ, sparsity**) with **declared units**; unit mismatch ⇒ {sandbox|refuse}.\n* **`Freshness`** — validity window for descriptors.\n* `Missingness` — **MCAR/MAR/MNAR** (or mapped equivalents) per **CHR.Missingness**; MUST be honoured by Acceptance/Flows.\n* `KindSet` — **`U.Kind[]`** of objects‑of‑talk addressed by the TaskKind; separates **describedEntity (Kind)** from **Scope (USM)**.\n\n**QD / Illumination extensions (normative; ties to C.18/C.19).**\n* **`CharacteristicSpaceRef`** — reference to **`U.CharacteristicSpace`**, with declared **d≥2**; **characteristics are CHR‑typed**; **ReferencePlane** per characteristic; pin edition via **`CharacteristicSpaceRef.edition`**.\n* **`ArchiveConfig`** — archive **topology** (grid/CVT/graph), **resolution** (bins/centroids), **K‑capacity**, **`InsertionPolicyRef`** (elite replacement/dedup/novelty), and **`DistanceDefRef.edition`** (declare **metric/pseudometric** status and invariances; any normalisation **MUST** cite lawful scale transforms in **CG‑Spec**); legality follows CG‑Spec.\n* **`EmitterPolicyRef`** — pointer to emitter/governor policy (C.19) applicable to this TaskSignature; **edition id** recorded.\n* **`DominanceRegime`** — `{ParetoOnly | ParetoPlusIllumination}`. **Default = `ParetoOnly`** (illumination remains report‑only telemetry unless CAL explicitly authorises `ParetoPlusIllumination`, policy‑id cited).\n* **`IlluminationSummary`** — a **telemetry summary over `Diversity_P`**; **published** by default; excluded from dominance unless a CAL enables `ParetoPlusIllumination` (policy‑id cited).\n* **`IlluminationMap`** *(parity‑run)* — required **publication artefact** (grid/CVT/graph per `ArchiveConfig`) recording coverage per niche/cell with `DescriptorMapRef`/`DistanceDefRef.edition`. **Leaderboards as single‑score lists are forbidden**; comparisons **MUST** be under CG‑frames.\n* **`PortfolioMode`** — `{Pareto | Archive}`. **Default = `Archive`**: selectors **publish portfolios** (QD archives) rather than a single “best” set; ε‑fronts remain admissible for local decisions under CG‑Spec.\n* **`Budgeting`** — evaluation/time/batch **budgets**, including **E/E‑LOG exploration budget** id; units declared (CG‑Spec).\n* **`TelemetryHooks`** — **PathSliceId**, **decay/refresh policy ids**, and **edition counters** to record **U.DescriptorMap** and **policy‑id** updates upon illumination gains.\n* **`GeneratorIntent`** (OEE) — optional intent to invoke a **`GeneratorFamily`** (G.5) with pointers to **`EnvironmentValidityRegion`**, **`TransferRulesRef`**, and **coverage/regret** reporting expectations.\n\n**Legality.** Before any numeric comparison/aggregation, **prove CSLC legality** (Scale/Unit/Polarity) and **cite CG‑Spec.Characteristics**; publish **ReferencePlane**. **Unknowns** propagate as {degrade|abstain|sandbox}; **no `unknown→0/false` coercions**.\n\n#### C.22:5.2 - TaskSignature (S2) — binding definition (design‑time + run‑time).\nA TaskSignature is a minimal typed record the selector consumes:\n`⟨Context, TaskKind, KindSet:U.Kind[], DataShape, NoiseModel, ObjectiveProfile, Constraints{incl. Resource/Risk Envelopes}, ScopeSlice(G), EvidenceGraphRef, Size/Scale, Freshness, Missingness, ShiftClass?, BehaviorSpaceRef?, ArchiveConfig?, EmitterPolicyRef?, DominanceRegime?, PortfolioMode?, Budgeting?, TelemetryHooks?, GeneratorIntent?⟩`\n\n\n**Minimality rule.** S2 carries only fields required for **Eligibility→Acceptance→lawful selection**; any additional traits derived at design‑time are published as provenance (UTS) but **do not expand S2**. \n\nValues are **CHR‑typed** with **provenance**; traits may be **inferred** from CHR/CAL bindings (e.g., *convexity known? differentiable? ordinal vs interval scales?*) and from **USM** scope metadata. Unknowns are tri‑state; **Missingness semantics MUST align with CHR.Missingness** and be honored by Acceptance/Flows. \n\n**Design/Run hygiene.** Do not mix DesignRunTag in one signature; **publish GateCrossings** as **CrossingSurface** bundles (**E.18**; Bridge+UTS **A.27**; BridgeCard **F.9**) when importing design‑time traits into run‑time.\n\n#### C.22:5.3 - Provenance & planes.\nRecord **Context**, **ReferencePlane** for each value; on any cross‑Context/plane reuse, attach BridgeDescription + UTS row, apply **CL** (and, if planes differ, **CL^plane**) penalties to **R_eff only**; both **Φ(CL)** and (if used) **Φ_plane** MUST be **monotone, bounded, and table‑backed**; **no “distance” language; penalties never mutate F/G.** Publish policy‑ids in SCR and cite Bridge ids on crossings.\n\n#### C.22:5.4 - Binding & use.\n\n* **Eligibility** gates read TaskSignature against each **MethodFamily.Eligibility** (C.23) and **CG‑Spec.MinimalEvidence** for referenced characteristics.\n* **Acceptance** clauses (G.4) use these fields for **threshold predicates** (thresholds live in Acceptance only).\n* **Selection kernel** (G.5.S3) applies a **lawful order** (often partial); **weighted sums across mixed scale types are forbidden**. If only a partial order remains, **return a Pareto (non‑dominated) set** with tie notes. If `PortfolioMode=Archive`, the selector **may** return a **QD archive** (per `ArchiveConfig`) **in addition to** or **instead of** a Pareto set. **Illumination** enters dominance **only** if `DominanceRegime=ParetoPlusIllumination` is **enabled by CAL** (policy id cited); otherwise, QD metrics are **reported** but **excluded** from dominance.\n* When `GeneratorIntent` is present, G.5 may dispatch to a registered **`GeneratorFamily`** (POET‑class); the selection surface becomes **pairs** `{environment, method}`, with Environment guarded by **`EnvironmentValidityRegion`** and **`TransferRulesRef`** (C.23 wiring). Report **`IlluminationSummary`** as a **telemetry summary over `Diversity_P`** (report‑only by default) in telemetry; dominance remains unaffected unless policy changes as above.\n\n#### C.22:5.5 - Unknowns.\nEvery field supports `unknown`; downstream **degrade/abstain/sandbox** behavior is explicit per Acceptance/EvidenceProfile; no implicit coercions. \n\n#### C.22:5.6 - Publication.\nEmit a **ProblemProfile** (…Description) that carries the bound TaskSignature, **UTS** Name Cards for any minted values (twin labels), and SCR‑visible provenance (A.10 anchors, lane tags, freshness, **ReferencePlane**). **Mark any vendor/tool examples as Plain‑register only (LEX V‑4); they are non‑normative.**\n\n#### C.22:5.7 - Open‑Ended tasks (GeneratorFamily) *(normative)*.\nIf the problem requires **open‑ended generation** of tasks/environments, S2 **SHALL** include `GeneratorIntent` with pointers to **`EnvironmentValidityRegion`** (lawful support of generated environments), **`TransferRulesRef`** (cross‑environment transfer constraints), and **coverage/regret** telemetry expectations. Selector outputs are then portfolios over **{environment, method}**; **coverage/regret** are **telemetry metrics** (reported) and **IlluminationSummary** is a **telemetry summary** (reported), excluded from dominance unless a **CAL** policy promotes them (policy‑id recorded in SCR; see `DominanceRegime`). Edition increments of **CharacteristicSpaceRef.edition**/**DescriptorMapRef.edition**/**DistanceDefRef.edition** and (OEE) **`TransferRulesRef.edition`**, and the **policy‑id** that caused illumination increases **SHALL** be recorded in SCR.\n\n",
        "forces": "### C.22:4 - Forces\n\n| Force                        | Tension                                                                                                                           |\n| ---------------------------- | --------------------------------------------------------------------------------------------------------------------------------- |\n| **Parsimony vs sufficiency** | Fewer fields to avoid ceremony **vs** enough to drive lawful gating.                                                              |\n| **Unknowns**                 | Many traits are **unknown** at intake → tri‑state semantics must propagate to Acceptance without silent coercions.                |\n| **CHR legality**             | **No mean on ordinals; no unit mixing**; polarity & scale type must be declared *before* aggregation.                             |\n| **Locality vs portability**  | Problem is **in‑room**; still must cross **via Bridges**, with **CL** and (if planes differ) **CL^plane** penalties → **R** only. |\n\n",
        "archetypal_grounding": "### C.22:6 - Archetypal Grounding (Tell–Show–Show)\n\n*Tell–Show–Show hook (per E.8):* label examples as **Show‑1 (continuous ODE)** and **Show‑2 (MIP)** and cite CHR guard‑macros in‑line so engineers can see **which field drove which gate**.  **Explicitly annotate which S2 fields triggered each Eligibility/Acceptance decision** (e.g., `service_level@ordinal → ORD_COMPARE_ONLY`, `budget@ratio → unit alignment check`).\n\n**A. Differential equations (continuous systems, solver choice).**\n*ProblemProfile.* `DataShape=ODE, stiff?=unknown, Size/Scale={n≈10^3}, ObjectiveProfile={↓error@ratio, ↑throughput@ratio}, Constraints={budget≤X, safety_gate@ordinal}, RegularityTraits={Lipschitz known?=unknown, Jacobian sparsity=high}, Missingness=MAR`.\n*Binding.* Selector reads TaskSignature; **eligibility** filters MethodFamilies that require known stiffness or differentiability (unknown ⇒ **degrade/abstain** per family); **Acceptance** enforces `safety_gate` as **ordinal predicate**, not averaged (ORD\\_COMPARE\\_ONLY), and budgets with **unit‑aligned sums** (ratio). The selector returns a **Pareto set**; no cross‑ordinal weighting.\n\n**B. Mixed‑integer optimisation (planning/scheduling).**\n*ProblemProfile.* `DataShape=MIP, NoiseModel=deterministic, ObjectiveProfile={↓cost@ratio, ↑service_level@ordinal}, Constraints={SLA hard, workforce soft}, RegularityTraits={convex_relaxation=available}, Size/Scale={vars~10^5}, Missingness=MCAR`.\n*Binding.* **CG‑Spec** forbids means over **service\\_level** (ordinal); **Acceptance** holds thresholds; **Eligibility** checks convex‑relaxation availability; **Selection** applies **lexicographic** guard (assumption‑fit ≻ evidence‑fit ≻ resource), compute **R\\_eff** with Γ‑fold, route **CL** to **R** only; if partial order remains, return a **Pareto set**.\n\n> *Contemporary anchors (informative):* modern **Julia** ecosystems illustrate the “**general call outside, specialised implementations inside**” ethos (e.g., DifferentialEquations.jl, JuMP), aligning with C.22→G.5 multi‑method dispatch under NFL.\n\n**C. Quality‑Diversity portfolio (illumination).**\n*ProblemProfile.* `DataShape=policy‑search; ObjectiveProfile={↑reward@ratio, ↑coverage@ratio (report‑only)}, DominanceRegime=ParetoOnly, PortfolioMode=Archive, CharacteristicSpaceRef(d=3, characteristics=CHR‑typed), ArchiveConfig(grid, res=32×32×16, K=1, InsertionPolicyRef=elite‑replace, DistanceDefRef.edition=v1), EmitterPolicyRef=v2, Budgeting{eval=1e6}, TelemetryHooks{PathSliceId=…}`.\n*Binding.* Selector may return an **archive**; **coverage/illumination** are **reported** but **excluded** from dominance (default). Any change of `DistanceDefRef.edition`/Emitter policy is **editioned** and logged in SCR.\n\n**D. Open‑ended environment generation (POET‑class).**\n*ProblemProfile.* `GeneratorIntent{GeneratorFamilyRef=…, EnvironmentValidityRegion=… (CHR‑typed), TransferRulesRef=…, CoverageMetric=…}`, `PortfolioMode=Archive`.\n*Binding.* Selector outputs **{environment, method}** pairs that pass Eligibility; **TransferRules** govern cross‑environment policy reuse; telemetry reports **coverage/regret** and **IlluminationSummary** with **edition/policy‑id** when improved.\n",
        "bias‑annotation_(lex/discipline_guards)": "### C.22:7 - Bias‑Annotation (LEX/discipline guards)\n\n* **No minted “Strategy” head.** “Strategy/policy” are *roles/lenses* inside G.5; do **not** introduce a new `U.Type` “Strategy”.\n* **No minted `U.Type` “Strategy”.** Strategy/policy are roles/lenses inside G.5 Compose under E/E‑LOG; keep “strategy” as Plain where pedagogically needed.\n* **Transdiscipline vs domain.** Comparability flows through **`U.Discipline` CG‑Spec**; “Domain” is a catalog mark stitched to D.CTX + UTS; do **not** attach norms to Domain labels.\n* **Plain twins & head‑anchoring.** Use Description/Spec morphology correctly (I/D/S; E.10.D2). \n",
        "anti‑patterns_(normative)": "### C.22:8 - Anti‑patterns (normative):\n* **AP‑1** Pre‑binding a Method into S2 (“problem as if task”); **Remedy:** keep S2 method‑agnostic; bind only lawful traits.\n* **AP‑2** Silent `unknown→false/0` in Eligibility/Acceptance.  \n* **AP‑3** Cross‑ordinal averaging / ordinal–interval scalar mixes.  \n* **AP‑4** **Design/run chimera** signatures (mixing stances).  \n* **AP‑5** **Domain** treated as governance (attach governance to **U.Discipline/CG‑Spec**, not Domain).  \n* **AP‑6** Implicit handling of data‑shift (assume iid); **Remedy:** declare `ShiftClass` (or `unknown`) and gate via Acceptance.\n* **AP‑7** Tool/vendor tokens in normative text; **Remedy:** move to Plain‑register note; keep Tech anchors on CHR/CAL ids (LEX V‑4).\n**Remedies:** tri-state predicates; lawful orders (lexi/Pareto/median/medoid); **GateCrossing visibility** via Bridge+UTS+CL/CL^plane (penalties → R only); Domain stitched to **D.CTX + UTS** only.\n**Remedies:** tri‑state predicates; lawful orders (lexi/Pareto/median/medoid); explicit **GateCrossing** publication via **CrossingSurface** (BridgeCard + UTS row + `CL/Φ` policy‑ids; **E.18/A.27/F.9**); Domain stitched to **D.CTX + UTS** only.\n",
        "conformance_checklist": "### C.22:9 - Conformance Checklist (normative)\n\n0. **Minimal S2.** S2 contains only fields necessary for Eligibility/Acceptance/selection; any extra derived traits remain provenance.\n1. **TaskSignature present (S2).** All TaskKinds **publish** a TaskSignature with all fields declared and **CHR‑typed**; `unknown` supported for each.\n2. **CHR legality proven.** Any numeric comparison/aggregation **cites CG‑Spec** by **Characteristic id** and proves **CSLC legality**; **no mean on ordinals; no unit mixing**.\n3. **Unknowns propagate.** Unknowns **must** map to {pass|degrade|abstain} in **Acceptance**/**Eligibility**; no implicit coercions; behavior recorded in **SCR**.\n4. **Evidence lanes.** **A.10 anchors** + **Assurance lanes (TA/VA/LA)** + **freshness windows** recorded; **Γ‑fold** default=weakest‑link unless proved otherwise.\n5. **ReferencePlane guarded.**  ReferencePlane noted **per value and per ObjectiveProfile head**; on crossings apply **CL** (and **CL^plane** if planes differ); **Φ(CL)/Φ_plane** are **monotone, bounded, table‑backed and documented in the `CG‑Spec`**; penalties → **R_eff only** (F/G invariant).\n6. **Acceptance thresholds live in CAL.** No thresholds in CHR or code paths; only in **G.4 AcceptanceClauses**. \n7. **Selector legality.** Selection uses **admissible (possibly partial) orders**; **weighted sums across mixed scale types are forbidden**; return a **Pareto set** when appropriate. \n8. **Crossings published (visibility).** Any cross-stance/cross-Context reuse emits **BridgeCard/BridgeDescription + UTS row** with CL notes and (if planes differ) CL^plane + Φ_plane.\n9. **UTS twin labels.** All exported cards publish **Name Cards** with twin labels; Bridges carry loss notes. \n10. **GateCrossing checks.** Published TaskSignature and any referenced crossings satisfy: (i) stance tagging (if used; informative only), (ii) **CrossingSurface** presence/consistency (**E.18**; **A.27**; **F.9**), (iii) **LanePurity** (CL→R only; F/G invariant; Φ tables present), and (iv) **Lexical SD** (**E.10**). Failures are **blocking** under the active GateProfile / GateChecks (**A.21**).\n11. **QD fields (when QD is in scope).** If `PortfolioMode=Archive` or QD heads are present, **CharacteristicSpaceRef** (d>=2), **ArchiveConfig** (topology, resolution, K, `InsertionPolicyRef`, `DistanceDefRef.edition`), and **EmitterPolicyRef** **SHALL** be present and CHR-typed; characteristics declare **ReferencePlane**.\n12. **DominanceRegime default.** `DominanceRegime` **defaults to `ParetoOnly`**; inclusion of illumination in dominance **MUST** be enabled by a **CAL.Acceptance policy**; the policy id **SHALL** be published in SCR.\n13. **Telemetry.** **PathSliceId**, **refresh/decay policies**, and **edition counters** for **CharacteristicSpaceRef**/**DistanceDefRef**/**EmitterPolicyRef** **SHALL** be recorded; any illumination increase **SHALL** log the **policy-id** that triggered it.\n14. **GeneratorIntent (when OEE is in scope).** `GeneratorIntent` **SHALL** cite **`EnvironmentValidityRegion`** and **`TransferRulesRef`** (ids resolvable in G.5/C.23); absence => `Abstain` for OEE dispatch.\n15. **Budgets.** `Budgeting` (eval/time/batch) **SHALL** declare units and E/E-LOG exploration budget id when used.\n16. **Archive legality.** `DistanceDefRef.edition` and any novelty measures **SHALL** be CSLC-lawful and **editioned**; illegal ops => **Abstain**.\n17. **Planes.** **ReferencePlane** **SHALL** be declared for all QD heads/axes; plane crossings apply **Phi\\_plane** (penalty to **R** only).\n18. **Unknowns.** Unknown QD fields **map** to `{degrade|abstain|sandbox}`; no coercions.\n",
        "interfaces_&_data_paths": "### C.22:10 - Interfaces & Data Paths\n\n*Inputs.* `ProblemProfile` (…Description), CG-Spec ids, Evidence Graph Ref (A.10), D.CTX; (if QD) CharacteristicSpaceRef/ArchiveConfig/EmitterPolicyRef configs; (if OEE) GeneratorIntent.\n *Produces.* `TaskSignature@Context` (S2) with provenance; **SCR-visible** fields; UTS Name Cards for any minted traits; (if QD/OEE) archive/portfolio semantics and telemetry hooks declared.\n *Consumed by.* **G.5** (Eligibility/Selection kernel), **G.4** (Acceptance/Evidence), **C.23** (admit/degrade/abstain rules; maturity ladder).\n",
        "consequences": "### C.22:11 - Consequences (informative)\n\n* **Lawful selection.** Dispatch is **explainable** and **audit-ready**; every reason in/out cites TaskSignature fields, CG-Spec rows, and Gamma-fold contributors. \n* **Local first, portable later.** Context-local semantics are primary; Bridges make portability **deliberate and costed** (penalties to **R** only). \n* **Frictionless downstream.** G.1-G.5 consume a **single, typed** Standard; thresholds are cleanly separated into **Acceptance**; unknowns are not guessed.\n* **QD/OEE-ready.** Typed QD and GeneratorIntent fields make **portfolio** and **open-ended** workflows **first-class**, with lawful dominance, editioned distances, and policy-aware illumination.\n",
        "relations": "### C.22:12 - Relations\n**Builds on:** **C.16 MM-CHR**, **G.0 CG-Spec**. **Coordinates with:** **G.4 Acceptance**, **G.5 Selector**, **C.18 NQD-CAL**, **C.19 E/E-LOG**, **C.23 Method-SoS-LOG**. **Constrained by:** **E.10 (LEX/I/D/S)**, **E.18 (GateCrossing visibility / publication gating)**.\n",
        "author's_quick_checklist": "### C.22:13 - Author's quick checklist\n\n1. **Write the ProblemProfile.** Context, TaskKind, ObjectKinds, USM **ScopeSlice(G)**, describedEntity (GroundingHolon, ReferencePlane). \n2. **Fill TaskSignature (S2).** Populate all fields; mark `unknown` explicitly; align **Missingness** with CHR semantics. \n3. **Bind CG-Spec ids.** For any numeric comparison/aggregation you expect downstream, cite **CG-Spec.Characteristics** and prove **CSLC** legality. \n4. **Attach Evidence Graph Ref.** Lanes (TA/VA/LA), carriers, freshness windows; set **Gamma-fold** default; no self-evidence. \n+5. **Publish crossings.** If importing across a **GateCrossing** boundary, mint **BridgeDescription + UTS row**; record **CL/CL^plane**; penalties **→ R only**. \n6. **Keep thresholds in Acceptance.** Move any thresholds (gate numbers) into **G.4**;  wire **RSCR** refusal tests (illegal ops; unit/scale checks; **tri-state unknowns**; CL->R routing; **Phi tables present**).\n7. **Run GateCrossing checks** on the signature and crossings: stance tagging (if used; informative only), **CrossingSurface** presence/consistency (**E.18/A.27/F.9**), **LanePurity**, and **Lexical SD** (**E.10**); attach **UTS Name Cards** with twin labels.\n8. **Bias audit.** Check E.5.4 and C.21 hooks if the problem lives *inside* a discipline dashboard or SoTA pack.\n\n",
        "goldilocks_hook_(design‑time)": "### C.22:14 - Goldilocks hook (design‑time)\n\nWhen generating candidate solutions for a **TaskKind**, target **“goldilocks”** slots (feasible‑but‑hard) so that the TaskSignature is informative (neither trivial nor impossible); this aligns with **G.1** (target goldilocks, abductive provenance) and ensures the **TaskSignature is informative** (neither trivial nor impossible) for **G.5** selection.\n",
        "c.22:end": "### C.22:End\n"
      },
      "content": "### C.22:End\n",
      "metadata": {},
      "part": "C",
      "cluster": null
    },
    {
      "id": "C.23",
      "title": "MethodFamily Evidence & Maturity (Method‑SoS‑LOG)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## C.23 - MethodFamily Evidence & Maturity (Method‑SoS‑LOG)\n\n*Architheory: LOG (deductive shells for admissibility)*\n*First use expansion:* **SoS‑LOG = Science‑of‑Science LOG** (LEX short‑form discipline applied).\n\n**HomeContext.** For this pattern, *HomeContext* means the `U.BoundedContext` where a `MethodFamily` is registered (LEX D.CTX).\n\n**Builds on.** **G.5** (MethodFamily registry/selector), **G.4** (Acceptance & EvidenceProfiles), **C.22** (TaskSignature S2), **C.18 NQD‑CAL** (QD/illumination), **C.19 E/E‑LOG** (emitters/policies), **B.3** (Assurance lanes & `R_eff`), **A.10** (Evidence Graph Ref), **E.10** (LEX), **E.18** (GateCrossing / CrossingSurface visibility). **Coordinates with.** **G.6** (EvidenceGraph), **G.8** (LOG bundling), **G.9** (Parity), **G.11** (Refresh).     \n",
        "problem": "### C.23:2 - Problem\n\nUnstructured “readiness” stories and undisciplined evidence lead to:\n\n* (i) **Illicit scalarisation** across mixed scale types,\n* (ii) **Prose‑only** gating that a dispatcher cannot execute,\n* (iii) Cross‑Context reuse without Bridges/CL, and\n* (iv) Immature families leaking into production.\n  We need a **notation‑independent LOG layer** that turns **TaskSignature (S2)** + **EvidenceProfiles** into **executable rules** for *admit / degrade / abstain*, **routing any CL penalties to `R_eff` only** (never mutating **F/G**). \n",
        "forces": "### C.23:3 - Forces\n\n* **Pluralism vs. dispatchability.** Competing Traditions expose different invariants; selection must compare **without semantic flattening**.\n* **Maturity vs. opportunity.** Open‑ended exploration (E/E‑LOG) must coexist with **run‑safe** exploitation; *immature ≠ forbidden* → provide safe **degrade** paths.\n* **Unknowns (tri‑state).** Missing or `unknown` S2 fields must propagate **explicitly** to *degrade/abstain/sandbox*; no silent coercions.\n* **Lexical discipline.** Head‑anchoring, I/D/S separation, Bridge hygiene; **no tool names in Core**.\n\n",
        "solution": "### C.23:4 - Solution — **Method‑SoS‑LOG**: deductive shells over Eligibility & Evidence\n\n#### C.23:4.1 - Objects & heads (LEX/I‑D‑S)\n\n*Tech heads; Plain twins are published via UTS.*\n**`MethodFamily`** (registered in G.5) carries **Eligibility** and artefact identity; **`MaturityCard`** (this pattern) carries evidence‑aware maturity; **`SoS‑LOG.Rule`** (this pattern) is an executable rule schema that returns one of `{Admit | Degrade(mode) | Abstain}` for a `(TaskSignature, MethodFamily)` pair. Descriptions live as `…Description`; when harnessed they become `…Spec`. \n\n#### C.23:4.2 - Rule schema (normative)\n\nFor each `MethodFamily` **f**, author an **executable** rule set:\n\n```\nLOG.Deduce_f(TaskSignature S2) → {Admit | Degrade(mode) | Abstain}\n```\n\nwith the following **branch obligations**:\n\n**R0 — CG‑Spec gate (precondition, HomeContext).** Before R1–R3, verify **CG‑Spec.MinimalEvidence** for every CHR characteristic referenced by *f*’s Acceptance/Flows **in the home Context**; failure ⇒ `Abstain` with reasons (no silent sandbox). Publish the **CG‑Spec ids** consulted. \n*Rationale:* selector legality requires the CG‑Spec gate to be explicit, not implicit in prose. Publish associated **ReferencePlane** notes alongside the consulted ids.\n\n**R0.QD — QD/OEE pre‑gates (if applicable).** If S2 declares **BehaviorSpaceRef/ArchiveConfig/EmitterPolicyRef** or `PortfolioMode=Archive`, verify:\n(i) **CharacteristicSpaceRef** characteristics are CHR‑typed, d≥2, **ReferencePlane** per characteristic declared;\n(ii) **ArchiveConfig** is lawful (topology, resolution, **K**>0, `InsertionPolicyRef`, `DistanceDef` with **edition id** and declared metric/pseudometric status);\n(iii) **EmitterPolicyRef** present (with **edition id**);\n (iv) **DominanceRegime** present; if absent, **default= ParetoOnly**.\n Failure of any ⇒ `Abstain` with reasons.\n\n**R1 — Admit.** `Admit` **IFF**\n(a) S2 satisfies **Eligibility** predicates of *f* (tri‑state aware),\n(b) **EvidenceProfile minima** referenced by Acceptance/Flows for *f* are met (lanes/anchors/freshness) **in the home Context** (post R0),\n(c) all relevant **CAL.AcceptanceClauses** (G.4) evaluate to true under lawful CHR comparisons,\n(d) any **maturity gating** (e.g., a floor on Maturity rungs) is expressed as an **AcceptanceClause** and referenced here by id (no thresholds inside LOG).\n*LOG never sets thresholds; it only executes and cites Acceptance verdicts.*\n\n**R2 — Degrade.** If (a) holds but (b) or (c) is **partially** satisfied or **unknown**, return `Degrade(mode)` where `mode ∈ {scope‑narrow | sandbox | probe‑only}` and **emit scope notes** (USM Scope(G), Γ_time). Record which S2 unknowns or Evidence minima caused the degrade. **LOG‑Degrade** never changes **CHR scales or planes**; it **narrows Scope (G)** or **execution mode**. \n**Note (CAL vs LOG).** CAL‑level **`degrade.order`** (fall‑back to order‑only comparisons) is governed by **G.4**/**CG‑Spec** and is **not** a LOG mode. **SoS‑LOG never overrides CAL outcomes**; a LOG branch **only narrows** `Scope(G)` or **execution mode** (e.g., `sandbox`, `probe‑only`), it **does not** alter CHR scales or admissible orders.\n`probe‑only` MUST cite an **E/E‑LOG policy id** (exploration budget) and Acceptance‑bound guards.\n\n**R3 — Abstain.** If S2 violates **Eligibility** *or* **R0** fails, return `Abstain` (with reasons). **Abstain** is mandatory on **illegal CHR operations** (e.g., ordinal means) and when **Bridge/CL** requirements are unmet. \n\n**R4 — CL routing.** Any cross‑Context/plane reuse must cite **Bridge ids** (with loss notes). Apply **Φ(CL)** and (if planes differ) **Φ_plane** that are **monotone, bounded, table‑backed**; **publish policy‑ids** in the SCR; **penalties reduce `R_eff` only**; **F/G must remain invariant**.\n\n**R5 — Proof hooks.** Every branch **MUST** cite **Evidence Graph Ref** (A.10), lane tags (TA/VA/LA), freshness windows, and (if bridged) **Bridge ids + loss notes**; the decision is **SCR‑visible**. When **G.6 EvidenceGraph** is present, also **publish EvidenceGraph path id(s)** for the branch (admit/degrade/abstain). **No self‑evidence**.\n\n**R6 — QD portfolio semantics (if applicable).** If `PortfolioMode=Archive`, `Admit` may return a **QD archive** (per `ArchiveConfig`) instead of only a Pareto set. Unless **CAL** authorises `DominanceRegime=ParetoPlusIllumination` (**policy‑id recorded in SCR**), **IlluminationSummary** is a **report‑only telemetry summary** and any **coverage/regret** are **telemetry metrics** (reported) that **do not** affect dominance.\n\n**R7 — GeneratorFamily branches (open‑ended).** If S2 includes `GeneratorIntent`, SoS‑LOG **MUST**:\n (i) verify **`EnvironmentValidityRegion`** is declared and lawful;\n (ii) verify **`TransferRulesRef`** exists; if `unknown` ⇒ `Degrade(scope‑narrow)` or `Abstain` per family policy;\n (iii) treat the selection surface as **pairs `{environment, method}`**; publish **coverage/regret** and **IlluminationSummary** as **report‑only telemetry** (IlluminationSummary = telemetry summary; coverage/regret = telemetry metrics); dominance participation per **R6**.\n\n**R8 — Telemetry & Refresh hooks.** On any illumination increase or archive change, publish **edition increments** for **CharacteristicSpaceRef**/**DistanceDefRef** and the **policy‑id** (Emitter/Acceptance) that caused the change; expose **PathSliceId** for refresh/decay in SCR.\n\n> *Aphorism.* **“Admit on lawfulness and sufficiency; degrade on uncertainty; abstain on illegality.”**\n\n#### C.23:4.3 - Maturity ladder (poset, not a scalar; Description, not Spec)\n\nPublish a **`MethodFamily.MaturityCardDescription@Context`** (UTS enum ids; **Scale kind = ordinal**; **ReferencePlane declared**). Do **not** embed thresholds here; any **maturity floors** used for admission are authored as **G.4 AcceptanceClause** and referenced by id from R1.\n\n* **L0 — Anecdotal.** Claims exist; lanes sparse; examples ad‑hoc.\n* **L1 — Worked‑Examples.** Multiple **worked examples** with lane tags and **Scope slices** declared; *no replication yet*.\n* **L2 — Replicated.** Independent replication(s) in distinct Context slices (publish D.CTX + UTS rows), lane separation observed, decay windows explicit.\n* **L3 — Benchmark‑Severe.** Repeated wins or parity on **community baselines** or **severe tests**; cross‑Tradition bridges declared with **loss notes**.\n\n*Optional rung (for QD/OEE‑heavy families; ordinal, closed enum):*\n* **L4 — QD‑Hardened.** Archive stability under declared **InsertionPolicy/DistanceDef** editions; reproducible **IlluminationSummary** improvements under controlled budgets; OEE generators pass **EnvironmentValidityRegion** severe tests.\n\n**Norms.**\n**M1.** The ladder is **lane‑aware** (TA/VA/LA) and **freshness‑aware**; it is **not** a global numeric score. Declare **Scale kind=ordinal** and the **closed enumeration** of rungs; register the enum at **UTS** (twin labels; editioned).\n**M2.** Transitions **MUST** be justified by **EvidenceGraph** paths (once G.6 is available) and UTS publication; missing anchors ⇒ no advance.\n**M3.** Any **maturity floor** used for admission (e.g., “run‑critical Context requires ≥L2”) **MUST** be authored as a **CAL.AcceptanceClause** and referenced by id from R1; SoS‑LOG does **not** embed thresholds.\n**M4.** Declare **ReferencePlane** for the MaturityCard; on ReferencePlane crossings apply published **Φ_plane** policy (penalty to **R_eff only**), with Bridge id and loss notes.\n\n> *Rationale note.* Treating maturity as a **poset** aligns with B.3’s lane calculus and avoids **scalarisation across ordinal/ratio** scales; assurance penalties remain on **R**, never **F/G**.\n\n#### C.23:4.4 - Unknowns & Shift classes (tri‑state discipline)\n\n**U1. (LEX).** Enumerations for `Degrade(mode)` and Maturity rungs **MUST** be declared as **closed value sets** and **registered at UTS** (twin labels). **Lexical SD** (**E.10**) applies.\n**U2.** Every S2 field is tri‑state; `unknown` **MUST** map to a branch (`Degrade` or `Abstain`) declared on the **family** (no coercions). Each branch publishes a **branch‑id** and (where used) a `mode` from a **closed enum** registered at **UTS** (LEX enum clarity).\n**U3.** `ShiftClass` semantics follow **C.22**. If `ShiftClass ∈ {covariate‑shift, concept‑drift, adversarial}` or `unknown`, default outcome is `Degrade(scope‑narrow)` unless a CAL.AcceptanceClause explicitly guards the regime.\n\n#### C.23:4.5 - Publication & wiring\n\n**W1.** Each family publishes a **`MaturityCardDescription@Context`** (UTS twin labels; ReferencePlane declared) and **registers SoS‑LOG rule ids**; editions are versioned and **RSCR‑tested for branch‑coverage** (Admit/Degrade/Abstain, unknown paths). **Φ(CL)/Φ_plane policy‑ids** must be present in SCR where applicable.\n**W2. Admissibility Ledger.** Publish an **`AdmissibilityLedger@Context`**: rows = `(MethodFamilyId, RuleId, MaturityRung, BranchIds, BridgeIds, ΦPolicyIds, EvidenceGraphPathIds?, DominanceRegime, PortfolioMode, Edition)`, UTS‑registered; this ledger is the **selector‑facing** export.\n**W3. Strategy token.** Do **not** mint a `U.Type` “Strategy”; strategy remains a **composition** inside G.5 (`Compose`) under **E/E‑LOG**.\n**W4.** Selector (G.5) **consumes** these rules; results appear in the **Dispatcher Report** with reasons in/out and cited anchors/bridges.\n",
        "archetypal_grounding": "### C.23:5 - Archetypal Grounding (Tell–Show–Show)\n\n*(Plain register for pedagogy; Core remains notation‑independent per E.10/E.8.)*\n\n**Show‑1 - Continuous dynamics (ODE task).**\n*S2 excerpt.* `DataShape=ODE; stiff?=unknown; Size≈10^3; Objective={↓error@ratio, ↑throughput@ratio}; Constraints={safety_gate@ordinal}; Jacobian_sparsity=high; Missingness=MAR`.\n*Families.* `Implicit‑BDF` vs `Explicit‑RK` vs `Symplectic`.\n*Rules.*\n— `Implicit‑BDF`: **Eligibility** tolerates `stiff?=unknown` if `Jacobian_sparsity=high` (guarded precondition); **MaturityCard**=`L3` (replicated & benchmarked). Outcome: `Admit`.\n— `Explicit‑RK`: requires `stiff?=false`; with `unknown` ⇒ `Degrade(sandbox)` (probe).\n— `Symplectic`: eligible only when `Hamiltonian=true`; here ⇒ `Abstain`.\n*Didactic anchor.* This mirrors C.22’s typed‑signature discipline and CHR legality (no ordinal means; unit alignment for **ratio**).\n\n> Contemporary ecosystem examples of these families (post‑2015) are organised in **DifferentialEquations.jl**, which exposes multiple solver **families** under one call surface—precisely the pattern G.5 expects. ([Journal of Open Research Software][17])\n\n**Show‑2 - Planning/scheduling (MIP task).**\n*S2 excerpt.* `DataShape=MIP; NoiseModel=deterministic; Objective={↓cost@ratio, ↑service_level@ordinal}; Size≈10^5 vars; convex_relaxation=available`.\n*Families.* `MILP (branch‑and‑bound)`, `Constraint‑Programming`, `Heuristic meta‑search`.\n*Rules.*\n— `MILP`: **Eligibility** requires `convex_relaxation=available`; **MaturityCard**=`L3` in the home Context ⇒ `Admit`.\n— `Constraint‑Programming`: **MaturityCard**=`L2`; Acceptance demands `service_level≥B` (ordinal predicate). With `B` met but baseline parity unknown ⇒ `Degrade(scope‑narrow)`.\n— `Heuristic meta‑search`: **MaturityCard**=`L1` ⇒ `Degrade(sandbox)` or `Abstain` depending on RSCR parity policy.\n*Didactic anchor.* Selector returns a **Pareto set** (no cross‑ordinal weighting), as required by G.5.\n\n> Contemporary “single call / many solvers” packaging that motivates MethodFamily rows is exemplified by **JuMP** (2017–2022), which cleanly separates **model description** from solver choice. ([Miles Lubin][18])\n\n— *DifferentialEquations.jl* illustrates **family‑based** solver packaging (multi‑method under one interface), 2017–2024 ecosystem. ([Journal of Open Research Software][17])\n— *JuMP* illustrates **model/solver separation** and registry‑like selection (2021–2022 papers, site). ([Miles Lubin][18])\n— *Science of Science* review (2018) supports the emphasis on replication/benchmarks in maturity assessment. ([Science][19])\n\n**Show‑3 - QD archive (policy search).**\n*S2 excerpt.* `PortfolioMode=Archive; CharacteristicSpaceRef(d=2); ArchiveConfig(CVT, res=1k cells, K=1, DistanceDefRef.edition=v2, InsertionPolicyRef=dyn‑elite); EmitterPolicyRef=v3; DominanceRegime=ParetoOnly`.\n*Rules.* `Admit` returns an **archive**; illumination **reported**; changes to `DistanceDef`/Emitter **editioned** in SCR; dominance remains **ParetoOnly**.\n\n**Show‑4 - Open‑ended GeneratorFamily (POET‑class).**\n*S2 excerpt.* `GeneratorIntent{GeneratorFamilyRef=GF‑01, EnvironmentValidityRegion=EVR‑A, TransferRulesRef=TR‑A, CoverageMetric=…}; PortfolioMode=Archive`.\n*Rules.* `Admit` yields portfolios over `{environment, method}`; `Degrade(scope‑narrow)` if `TransferRules`=`unknown`; telemetry publishes **coverage/regret** and **IlluminationSummary** with **edition/policy‑id** on improvements.\n\n[17]: https://openresearchsoftware.metajnl.com/articles/10.5334/jors.151 \"DifferentialEquations.jl – A Performant and Feature-Rich … \"\n[18]: https://mlubin.github.io/pdf/jump-sirev.pdf \"JuMP: A Modeling Language for Mathematical Optimization\"\n[19]: https://www.science.org/doi/10.1126/science.aao0185 \"Science of science\"\n",
        "bias‑annotation": "### C.23:6 - Bias‑Annotation\n\n**Principle‑taxonomy lenses.** *Universality* (trans‑discipline), *Didactic primacy* (Tell–Show–Show), *Open‑ended evolution* (refresh‑ready), *Lexical firewall* (no tool names in Core), *Notation independence*. Limits: Worked examples reference widely‑used ecosystems **in Plain register** only. \n",
        "conformance_checklist": "### C.23:7 - Conformance Checklist (normative)\n\n| ID           | Requirement                                                                                                                                                                                | Purpose                                       |                                                                    |                        |\n| ------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | --------------------------------------------- | ------------------------------------------------------------------ | ---------------------- |\n| **CC‑C23.1** | Each `MethodFamily` **SHALL** publish a `MaturityCard` with rung justification via **A.10** anchors (lanes, freshness windows) and (if bridged) **Bridge ids** with **CL** and loss notes. | Makes maturity **auditable** and lane‑typed.  |                                                                    |                        |\n| **CC‑C23.2** | `SoS‑LOG` rules **MUST** be **executable** (no prose‑only) and cite: Eligibility test result; CG‑Spec gate verdict; EvidenceProfile minima; Acceptance verdict; Γ‑fold contributors; **EvidenceGraph PathId/PathSliceId**; CL/Φ policy‑ids. |\n| **CC‑C23.3** | Enumerations used by the rules (**Degrade(mode)**; Maturity rungs) **SHALL** be **closed** and **UTS‑registered** (twin labels). |\n| **CC‑C23.4** | **Unknowns** in S2 **SHALL** map to `{degrade | abstain | sandbox}` with explicit **branch‑ids**; no `unknown→0/false` coercions.                                                          | Tri‑state discipline.                          |                                                                    |                        |\n| **CC‑C23.5** | Cross‑Context/plane use **MUST** cite a **Bridge**; **Φ(CL)**/**Φ\\_plane** **MUST** be monotone, bounded, table‑backed; penalties **→ `R_eff` only**.                                      | Keeps F/G invariant; legal CL routing.        |                                                                    |                        |\n| **CC‑C23.6** | **No thresholds** in CHR or Maturity; thresholds **live only** in **AcceptanceClauses** (G.4).                                                                                             | Separation of concerns.                       |                                                                    |                        |\n| **CC‑C23.7** | `MaturityCard` **SHALL NOT** be turned into a global scalar; treat as **poset**; any ordering **MUST** be lawful over CHR types.                                                           | Forbids cross‑scale scalarisation.            |                                                                    |                        |\n| **CC‑C23.8** | Publish to **UTS** with twin labels; run **GateCrossing visibility checks** on cited crossings: **CrossingSurface** attestation (**E.18/A.27/F.9**), **LanePurity**, and **Lexical SD** (**E.10**) under GateChecks/GateProfile (**A.21**). | Publication & crossing visibility hygiene. |                                                                    |                        |\n| **CC‑C23.9** | All enumerations (e.g., `Degrade(mode)`, Maturity rungs) **SHALL** declare a **closed value set** and **Scale kind**, and be registered at UTS (LEX enum clarity).                          | Avoids lexical drift; lawful typing.          |                                                                    |                        |\n| **CC‑C23.10** | **RSCR tests** cover negative/refusal paths (illegal CHR ops; CG‑Spec gate fail; Bridge missing; **Φ table/policy‑id missing**; **Lexical SD violations (E.10)**); ensure **branch coverage** (Admit/Degrade/Abstain, unknown). |\n| **CC‑C23.11** | If QD fields are in scope, **R0.QD** **MUST** pass: lawful **CharacteristicSpaceRef** (d≥2, characteristics typed, planes declared per characteristic), **ArchiveConfig** (topology/resolution/K, `InsertionPolicyRef`, **editioned** `DistanceDef`), **EmitterPolicyRef** present. | QD legality gate. | |\n| **CC‑C23.12** | **DominanceRegime** **SHALL** default to `ParetoOnly`; switching to `ParetoPlusIllumination` **MUST** be authorised by **CAL** and cited by id in SCR.                                    | Prevents implicit scalarisation.              |                                                                    |                        |\n| **CC‑C23.13** | If `PortfolioMode=Archive`, LOG **MUST** allow archive outputs (R6) and publish **IlluminationSummary** as a report-only telemetry metric unless CAL opts‑in to dominance participation.                         | Lawful archive semantics.                     |                                                                    |                        |\n| **CC‑C23.14** | If `GeneratorIntent` present, **R7** **MUST** verify **EnvironmentValidityRegion** and **TransferRulesRef**; outputs are **{environment, method}** portfolios; coverage/regret telemetry published. | OEE legality & telemetry. | |\n| **CC‑C23.15** | On illumination increases/archive changes, **edition increments** (BehaviorSpace/DistanceDef/EmitterPolicy) and the **policy‑id** responsible **SHALL** be logged (R8).                   | Reproducibility & refresh.                    |                                                                    |                        |\n",
        "consequences": "### C.23:8 - Consequences\n\n* **Explainable admission.** Every *Admit/Degrade/Abstain* is backed by **anchored** evidence and explicit unknown handling (selector reports are SCR‑linked).\n* **Run‑safe pluralism.** Multiple families can co‑exist with **policy‑governed** exploration (E/E‑LOG) and maturity‑aware gating.\n* **Portable governance.** Bridge hygiene and CL routing make cross‑Tradition reuse **deliberate and costed** (penalties to **R** only).\n",
        "rationale": "### C.23:9 - Rationale\n\nThe ladder and LOG shells align with FPF’s **Assurance calculus**: **F** (form) is governed by artefact kind, **G** (scope) by USM slices, and **R** (reliability) accumulates via WLNK then **Φ(CL)** penalties. Treating maturity as **evidence‑typed rungs**—rather than a “score”—avoids illegal arithmetic and lets **design/run** remain separate via `DesignRunTag` discipline (A.4) and explicit GateCrossings. This mirrors contemporary **science‑of‑science** insights: replication, benchmarking, and field health indicators are the **currency** of maturity, not anecdote.  ([Science][19])\n",
        "relations": "### C.23:10 - Relations\n\n**Builds on:** **G.5** (selector consumes these rules), **G.4** (Acceptance & EvidenceProfiles), **C.22** (S2 typing), **C.18 NQD‑CAL**, **C.19 E/E‑LOG**, **B.3** (Assurance tuple & WLNK).   \n**Publishes to:** **UTS** (MaturityCards, rule ids), **SCR/RSCR** (branch coverage; parity hooks).\n**Constrains:** **G.8** (LOG Bundling must cite MaturityCards), **G.9** (parity harness draws baselines per rung), **G.11** (refresh windows per rung & decay), **G.5** (Open‑Ended Family mode for GeneratorFamily).\n**Outcome.** The pattern introduces **new content** (LOG shells + maturity poset + degrade modes + publication Standard) and **does not duplicate** CG‑Spec legality rules, CHR guard‑macros, or CAL acceptance mechanics; it *integrates* them into **admissibility logic** for MethodFamilies.\n",
        "c.23:end": "### C.23:End\n"
      },
      "content": "### C.23:End\n",
      "metadata": {},
      "part": "C",
      "cluster": null
    },
    {
      "id": "C.24",
      "title": "Agentic Tool‑Use & Call‑Planning (C.Agent‑Tools‑CAL)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## C.24 - Agentic Tool‑Use & Call‑Planning (C.Agent‑Tools‑CAL)\n\n**Status.** Architheory specification (**CAL**). Defines the conceptual calculus for **agentic selection and sequencing of tool calls** under budgets, trust gates, and policy. **ΔKernel = 0** (no kernel primitives added). *Minting note:* this CAL **does not mint** new U‑types; it **aliases** canonical U‑types where appropriate via **E.10/UTS**.\n\n**Instantiates / Refines Pillars.** E.2 P‑3 Scalable Formality, P‑7 Pragmatic Utility, P‑10 Open‑Ended Evolution, P‑11 SoTA Alignment, and the **Bitter‑Lesson Preference** (prefer scalable, general methods that benefit from more data/compute over fragile hand‑tuned heuristics when assurance/cost are comparable).\n\n**Depends on.** A‑kernel (A.1–A.15) for holonic basics and **Role–Method–Work** separation; **B.3** Trust & Assurance (F–G–R with CL penalties); **E.3/E.5** (precedence & Guard‑Rails); **C.5** Resrc‑CAL; **C.18** NQD‑CAL (candidate generation/portfolio); **C.19** E/E‑LOG (explore–exploit policies); **optional** Compose‑CAL and KD‑CAL (knowledge dynamics) where available.\n\n**Coordinates with.**\nU.WorkPlan and U.ServiceClause bindings (acceptance gates), Working‑Model publication discipline (**per B.3**), Evidence/Provenance (G.6).\n",
        "problem": "### C.24:2 - Problem\nWe need a **tool‑agnostic** way to (i) identify **admissible tools**, (ii) **score** candidate call sequences, (iii) allocate an **explore/exploit** share, (iv) enforce **budget & harm** gates, and (v) **replan** on signals—**without** baking domain‑specific heuristics into the core and **without** violating B.3 assurance discipline. \n",
        "forces": "### C.24:3 - Forces\n\n| Force                              | Tension                                                                                                        |\n| ---------------------------------- | -------------------------------------------------------------------------------------------------------------- |\n| **General methods vs. hand‑craft** | Scalable, model‑centric search ↔ short‑term wins of bespoke scripts (guarded by **Bitter‑Lesson Preference**). |\n| **Assurance vs. Autonomy**         | F‑G‑R gates & CL penalties ↔ agent freedom to sequence calls and learn online.                                 |\n| **Exploration vs. Delivery**       | Exploration share for illumination ↔ delivery SLAs and cost ceilings (E/E‑LOG policy).                         |\n| **Separation of concerns**         | Planning (MethodDescription) ↔ execution (Work) ↔ service promises (U.ServiceClause).                                |\n",
        "solution": "### C.24:4 - Solution — Signature & Realization\n\n**Types (aliases).**\n*`ATC.CallSpec`* ≡ `U.MethodDescription` with `accessSpec` for a tool service;\n*`ATC.CallPlan`* ≡ `U.WorkPlan` specialised for tool invocations;\n*`ATC.CallGraph`* ≡ Evidence/Provenance graph over a `U.Work` ledger;\n*`ATC.Policy`* references `U.EmitterPolicyRef` (E/E‑LOG) and local call gates **including BLP tolerances (α, δ)**.\n\n**Roles.**\nA **System in AgentialRole** composes a **Plan** (MethodDescription); upon enactment, a **Performer** executes **Work** (calls), and **Observers** record **Observations** with acceptance checks. (A.15 strict distinction.) \n\n**Operators (Γ_agent; CAL, conceptual):**\n\n1. `Γ_agent.eligible(tool, TaskSignature, K_ctx) → {true|false, notes}`\n   *Eligibility gate* based on capability fit, policy allow‑list/deny‑list, and context K (incl. safety constraints).\n\n2. `Γ_agent.enumerate(TaskSignature, K_ctx) → CandidateSet<ATC.CallSpec>`\n   Returns admissible calls. **MAY** delegate to **NQD‑CAL** for portfolio enumeration when families are heterogeneous and **MUST** apply the current **E/E‑LOG lens** (objectives & telemetry) to tag candidates.\n\n3. `Γ_agent.plan(Objective, CandidateSet, Budget, ATC.Policy) → ATC.CallPlan`\n   Produces a **call plan** with steps `{pre, call, post}`, *explicit budgets* (compute, cost, time, risk), and **E/E policy** (explore_share, tie‑breakers, stop‑conditions). The plan is a MethodDescription, not Work.  \n\n4. `Γ_agent.execute(ATC.CallPlan) → {ATC.CallGraph, Observations}`\n   Executes with **hard gates** (budget, risk, constraint‑fit) and logs provenance suitable for B.3 assurance reporting (design/run separated). \n\n5. `Γ_agent.replan(Signals, ATC.CallPlan, Budget′) → ATC.CallPlan′`\n   Triggered by sentinel breaches, assurance drops, or policy events; preserves **editioned** policy and context. (Design/run separation; Working‑Model handshake.) \n\n6. `Γ_agent.score(Plan or Step) → ⟨ValueProxies, Cost, Risk, FGR_floor⟩`\n   Computes selection signals **without** illegal scalarisation across mixed scales; **uses Pareto comparison under the C.19 E/E‑LOG lens** and defers final dominance to declared policies. \n\n**Normative Laws (ATC‑Laws).**\n\n* **ATC‑1 (Model‑the‑Call, not the App).** A tool call is a **Work** instance that enacts a referenced **MethodDescription** promised by a **Service**; plans schedule calls but are **not the calls**. (A.15.)\n* **ATC‑2 (Bitter‑Lesson Preference).** When two admissible choices are within **δ (assurance)** and **α (budget)**, **prefer the more general, scale‑benefiting method** whose **slope vector Pareto‑dominates** under the declared E/E‑LOG objectives; any override **MUST** record a **BLP‑waiver** with expiry. (E.2; precedence governed by E.3.)\n* **ATC‑3 (Budget & Harm Gates).** Plans **SHALL** declare ceilings on compute, cost, wall‑time, and risk; execution **MUST** abort or replan on breach. (Assurance ties to B.3; design/run kept separate.)\n* **ATC‑4 (Explore‑Share Discipline).** Plans **MUST** declare `explore_share`; defaults **inherit from E/E‑LOG profiles**. **Informative defaults**: `0` for safety‑critical or deterministic tasks; `≈0.2–0.4` for ambiguous tasks with heterogeneous tool families. Promotion of illumination telemetry into dominance **requires explicit policy**.\n* **ATC‑5 (Provenance & Replay).** Every call **MUST** emit a **CallGraph** with: Service id, MethodDescription edition, inputs/outputs (redacted per privacy), **EmitterPolicyRef**, and budget deltas. (NQD/E/E provenance fields apply when used.)\n* **ATC‑6 (Assurance‑First Decisions).** Selection **MUST** respect B.3: WLNK minima on F/R (weakest‑link floors), CL penalties on integration, and **no** chimera scores across design/run. Publish **⟨F,G,R⟩** for the *typed claim* “this plan is admissible under K,S”.\n* **ATC‑7 (Notation/Vendor Independence).** Core pattern text **MUST NOT** encode vendor‑specific tokens; bindings occur in Context via Bridges/Profiles. (Lexical guard‑rails.)\n\n",
        "policy_block_(normative,_profile‑able)": "### C.24:5 - Policy Block (normative, profile‑able)\n\n**ATC‑Policy fields (conceptual):**\n`{ backstop_confidence, explore_share, risk_bound, cost_ceiling, time_ceiling, tie_breakers, novelty_quota?, wild_bet_quota?, stop_conditions, BLP_delta_α, BLP_delta_δ }` — realized by referencing an **E/E‑LOG EmitterPolicy** and adding **BLP** clauses. Defaults inherit from E/E‑LOG; any deviation is editioned.\n\n**BLP Precedence.** In conflicts with tactics that hard‑code narrow scripts, **BLP** applies **subject to E.3/E.5 precedence**. Where scripts encode **safety‑critical gating or regulatory compliance**, scripts **prevail** unless a DRR records: (i) **override rationale**, (ii) **expiry**, (iii) **measured hazard** avoided, and (iv) planned **re‑evaluation** window (P‑10 evolution duty).\n",
        "archetypal_grounding": "### C.24:6 - Archetypal Grounding (informative; non‑binding)\n\n1. **LLM Research Agent (knowledge work).**\n   Task: answer a novel technical question. Candidate tools: retrieval, structured web search, code runner, table/plot generator.\n   **Plan:** `enumerate → plan(explore_share≈0.4) → call(search→retrieve→synthesise→code‑check) → replan on sentinel (low R)`; **BLP** favours **general retrieval + prompting policies** over hand‑coded, per‑site scrapers unless assurance demands otherwise. (Echoes SoTA: *ReAct* (2022), *Self‑Ask* (2022), *Reflexion* (2023), *Tree‑of‑Thoughts* (2023), *Toolformer* (2023).)\n\n2. **Program Repair Agent (systems/software).**\n   Task: propose a patch against a failing test suite. Candidate tools: repo introspection, static analyzer, unit runner.\n   **Plan:** prefer **search‑and‑learn loops** with test‑guided feedback over fixed “if error X then patch Y” tables; exploration quota enforces trials across patch families before exploitation. (Aligns with post‑2019 automated program repair lines and *SWE‑bench*‑style agent loops.)\n\n3. **Lab Automation Agent (physical).**\n   Task: adjust a wet‑lab protocol under drift. Candidate tools: planner, pipetting controller, spectrometer, Bayesian optimizer.\n   **Plan:** **BLP** drives toward **model‑based optimization** under budgeted sample counts; heuristics remain as **policy‑documented** fallbacks with expiry. (Resonates with quality‑diversity and BO practice since 2015, mirrored by NQD/E/E policies.) \n",
        "conformance_checklist": "### C.24:7 - Conformance Checklist (CC‑AT)\n\n1. **CC‑ATC‑1 — Declared separation.** Plan is a `MethodDescription`; execution is `Work`; acceptance is via `U.ServiceClause`. No schedule inside specs; schedules live in `U.WorkPlan`.\n2. **CC‑ATC‑2 — Budgets on record.** `time/compute/cost/risk` ceilings exist **ex ante**; stop conditions listed.\n3. **CC‑ATC‑3 — E/E policy.** `EmitterPolicyRef` (or equivalent) and `explore_share` are editioned and logged.\n4. **CC‑ATC‑4 — Assurance tuple.** Publish the **typed claim** “Plan admissible under K,S” with **⟨F,G,R⟩** and CL penalties traceable in the **CallGraph** SCR. Design/run never merged.\n5. **CC‑ATC‑5 — BLP waiver discipline.** Any heuristic override against a general method includes **expiry** and **re‑evaluation** date.\n6. **CC‑ATC‑6 — Provenance minimum.** Record `{ServiceClouseRef, MethodDesc.edition, EmitterPolicyRef, DescriptorMapRef? (if NQD), DistanceDefRef? (if NQD), TimeWindow, Seeds?, Dedup?}`.\n7. **CC‑ATC‑7 — Notation independence.** No vendor tokens in conceptual text; bindings via Bridges/Profiles only.\n8. **CC‑ATC‑8 — BLP tolerances declared.** **α/δ** tolerances are present in `ATC.Policy` or referenced via the active E/E‑LOG profile.\n",
        "consequences": "### C.24:8 - Consequences\n\n*Positive.* Portable agent patterns; **auditable autonomy**; lawful exploration; faster hypothesis cycles via BLP; replayable call graphs; decision‑grade Working‑Model surfaces.\n*Trade‑offs.* Requires explicit budgets/policies; BLP may defer quick wins from bespoke scripts; stronger logging discipline.\n",
        "rationale": "### C.24:9 - Rationale (post‑2015 SoTA alignment, informative)\n\n* **Scaling‑first methods** (language‑model and representation‑learning scaling laws; subsequent data/compute‑balanced scaling) empirically support **BLP**: general, learnable mechanisms tend to dominate as budgets rise—hence **ATC‑2**.\n* **Tool‑use agents** in the literature (*ReAct*, *Self‑Ask*, *Reflexion*, *Toolformer*, *Tree‑of‑Thoughts*, open‑ended *Voyager*‑style skill acquisition) all benefit from **explicit planning + feedback**, exactly what CC‑AT‑2/3/6 encode.\n* **Quality‑Diversity & BO** practice motivates the **explore_share** default and the distinction between **dominance vs. illumination telemetry** (kept separate unless policy promotes).  \n",
        "relations": "### C.24:10 - Relations\n\n* **Builds on:** A.15 Role–Method–Work alignment (planning vs execution vs service), B.3 Trust & Assurance (F–G–R/CL), C.5 Resrc‑CAL, C.18 NQD‑CAL (candidate/portfolio), C.19 E/E‑LOG (policies).    \n* **Constrains:** Any `U.ServiceClause` used as a “tool” MUST expose acceptance conditions and observation hooks sufficient for B.3 reporting. \n* **Enables:** Human‑centric Working‑Model surfaces with policy/assurance disclosures (design/run separated). \n",
        "bias‑annotation": "### C.24:11 - Bias‑Annotation\n\n*Lexical firewall* and *notation independence* apply; no vendor tokens; mixed‑scale characteristics are never averaged; illumination remains a **report only telemetry** unless a policy promotes it into dominance.  \n\n#### C.24:12 - Didactic Quick Card (1‑screen crib)\n\n**Agentic Call Plan (public):**\n*Objective - Context(K) - Budget{time/compute/cost/risk} - PolicyRef (E/E‑LOG) - Explore‑share - Steps[ pre/ call /post ] - Stop‑conditions - **BLP tolerances (α,δ)** - BLP‑note (if any) - Assurance⟨F,G,R|K,S⟩ - Provenance ids.*\n",
        "c.24:end": "### C.24:End\n"
      },
      "content": "### C.24:End\n",
      "metadata": {},
      "part": "C",
      "cluster": null
    },
    {
      "id": "C.25",
      "title": "Q‑Bundle: Authoring “‑ilities” as Structured Quality Bundles",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## C.25 - Q‑Bundle: Authoring “‑ilities” as Structured Quality Bundles\n\n**Status & placement.** Part C (measurement/comparability); **Definitional pattern reusing Core patterns (**A.2.6 USM**; **A.6.1 Mechanism**; **C.16 MM‑CHR / A.18 CSLC**). Intended as a **lightweight authoring aid** for Contexts; it adds no new kernel types.  (A.6.1; A.2.6 § 6.2; C.16/A.18). \n",
        "problem": "### C.25:2 - Problem (recurring)\n*‑ilities* are often treated as if they were **single metrics**, while in practice many are **composites** whose evaluation depends on (i) **declared context‑of‑use** (Scope), (ii) **one or more CHR measures** (SLIs/SLOs), and (iii) **supporting mechanisms/statuses**. Collapsing these into “one number” invites illegal arithmetic and breaks USM locality.  (A.2.6; C.16).\n",
        "forces": "### C.25:3 - Forces\n**Locality vs comparability.** Scope must remain **context‑local** (USM) while measures remain **legally comparable** (CSLC). \n**Mechanism vs measure.** Presence of a mechanism (A.6.1) is not itself a measurement, yet may gate admissibility and influence **R**.  (A.6.1; C.16/A.18).\n",
        "solution": "### C.25:4 - Solution — Q‑Bundle normal form (Tell → Show → Show; E.8 order)\n**Definition.**  \n`Q‑Bundle := ⟨ Name, Carrier, ClaimScope?, WorkScope?, Measures[CHR], QualificationWindow?, Mechanisms?, Status?, Evidence? ⟩`\n\n**Fields (conceptual; reuse existing types).**\n* **Name.** The quality family label (e.g., *Availability*, *Resilience*).  \n* **Carrier.** `U.System | U.ServiceClause | U.Episteme` (what bears the quality).  \n* **ClaimScope / WorkScope.** **USM** set(s) over `U.ContextSlice` (where the claim holds / where the capability can deliver). **Set‑valued; not CHR.**  (A.2.6 § 6.2).  \n* **Measures[CHR].** One or more **CHR Characteristics bound to one Scale each** (e.g., `AvailabilityRatio[%]`, `RTO[min]`). **These are the measurable slots.** (C.16/A.18).  \n* **QualificationWindow.** Time policy used by guards (point/window/rolling).  \n* **Mechanisms / Status.** References to **A.6.1 U.Mechanism** realizations (e.g., redundancy policy, audit/trace) or certification/status flags. **Not measurements.** (A.6.1).  \n* **Evidence (optional).** Anchors/stubs per A.10 or C.16 to justify measures/mechanisms.\n\n**Conformance (minimal).**\n1) If a publisher intends to use an “‑ility” as a **single measurement axis**, they **MUST** bind it to a **named `U.Characteristic` + CSLC Scale** and cite that axis in guards/UTS; otherwise publish a **Q‑Bundle**. (C.16/A.18).  \n2) **Scope** remains **USM set‑valued**; guards use **membership/coverage** (“Scope covers TargetSlice”), never ordinal/averaging on G. (A.2.6 § 6.2).  \n3) **Mechanisms/Status** MAY gate admissibility but **MUST NOT** be conflated with **Measures**; penalties from Bridges/planes route to **R** only. (A.6.1; Part B).\n",
        "micro‑catalogue_(worked_mini‑sketches)": "### C.25:5 - Micro‑catalogue (worked mini‑sketches)\n**Availability (often Q‑CHR).**  \n*Scope:* observation window + region/tier (USM). *Measure:* `AvailabilityRatio[%]` (CHR). *Mechanisms:* redundancy/failover (A.6.1). **Guard:** Scope covers TargetSlice ∧ SLI/SLO satisfied.  \n\n**Resilience (Q‑CMP).**  \n*Scope:* disruption scenarios (USM). *Measures:* `MTTR`, `RTO`, `RPO` (CHR set). *Mechanisms:* drills/restore runbooks. **Guard:** scenario‑specific gates; **R** absorbs penalties from crossings.  \n\n**Security (Q‑MECH/Q‑CMP).**  \n*Scope:* trust zones/attack classes (USM). *Measures:* time‑to‑patch, coverage proportions (CHR). *Mechanisms/Status:* control sets, certs. **Guard:** policy/mechanism present ∧ measures thresholds ∧ Scope match.\n",
        "relations": "### C.25:6 - Relations\n**Builds on.** **A.2.6** (USM scope algebra, set‑valued; no CSLC), **A.6.1** (mechanism intensions and guards), **C.16/A.18** (measurement legality: one Characteristic ↔ one Scale).  \n**Coordinates with.** **B.3** (R/CL penalties only), **A.15** (Method–Work gates use Scope + Measures + Windows).\n",
        "consequences": "### C.25:7 - Consequences (brief)\n* **No category errors.** Authors cannot “average scope” or treat mechanisms as measurements.  \n* **Portable comparisons.** Numbers compare on CHR Scales; scope composes by set algebra.  \n* **Cleaner gates.** Admission checks become `Scope covers TargetSlice ∧ Measures met ∧ Window valid`.\n",
        "quick_authoring_checklist_(lintable)": "### C.25:8 - Quick authoring checklist (lintable)\n* If the term is an **‑ility**, choose: **CHR axis** (bind to Characteristic+Scale) **or** **Q‑Bundle**.  \n* Ensure any scope is **USM** (set over `U.ContextSlice`); no “G‑levels.”  \n* Cite mechanisms/status separately; route crossings’ penalties to **R** only.\n",
        "c.23:end": "### C.23:End\n\n\n# **Part D – Multi-scale Ethics & Conflict‑Optimisation**\n\n| §       | ID & Title                           |  Concise reminder — “what belongs here”                                         |\n| ------- | ------------------------------------ |  ------------------------------------------------------------------------------ |\n| **D.1** | **Axiological Neutrality Principle** |  No built‑in value hierarchy; ethics expressed as explicit preference lattices. |\n| **D.2** | **Multi‑Scale Ethics Framework**     |  Four nested arenas: *Self → Team → Ecosystem → Planet*; scoping rules.         |\n| D.2.1   | Local‑Agent Ethics                   |  Duties & permissions for a single `U.System` or `U.Agent`.                     |\n| D.2.2   | Group‑Ethics Standards               |  Collective norms, veto mechanisms, subsidiarity rule.                          |\n| D.2.3   | Ecosystem Stewardship                |  Inter‑architheory externalities; tragedy‑of‑commons mitigations.               |\n| D.2.4   | Planetary‑Scale Precaution           |  Catastrophic‑risk anchors; long‑termism discount curves.                       |\n| **D.3** | **Holonic Conflict Topology**        |  Typology of clashes: resource, goal, epistemic, temporal.                      |\n| D.3.1   | Conflict Detection Logic (LOG‑use)   |  Formal predicates (`conflictsWith`, `mitigatedBy`) and satisfiability checks.  |\n| D.3.2   | Conflict Routing Protocol            |  From local negotiation → external mediation → DRR appeal.                      |\n| **D.4** | **Trust‑Aware Mediation Calculus**   |  Resolution algorithm blends value‑weights with B.3 trust scores.               |\n| D.4.1   | Fair‑Share Negotiation Operator      |  Nash‑like but bias‑corrected; imports `Resrc‑CAL` cost functions.              |\n| D.4.2   | Assurance‑Driven Override            |  When safety evidence overrides utility maximisation.                           |\n"
      },
      "content": "### C.23:End\n\n\n# **Part D – Multi-scale Ethics & Conflict‑Optimisation**\n\n| §       | ID & Title                           |  Concise reminder — “what belongs here”                                         |\n| ------- | ------------------------------------ |  ------------------------------------------------------------------------------ |\n| **D.1** | **Axiological Neutrality Principle** |  No built‑in value hierarchy; ethics expressed as explicit preference lattices. |\n| **D.2** | **Multi‑Scale Ethics Framework**     |  Four nested arenas: *Self → Team → Ecosystem → Planet*; scoping rules.         |\n| D.2.1   | Local‑Agent Ethics                   |  Duties & permissions for a single `U.System` or `U.Agent`.                     |\n| D.2.2   | Group‑Ethics Standards               |  Collective norms, veto mechanisms, subsidiarity rule.                          |\n| D.2.3   | Ecosystem Stewardship                |  Inter‑architheory externalities; tragedy‑of‑commons mitigations.               |\n| D.2.4   | Planetary‑Scale Precaution           |  Catastrophic‑risk anchors; long‑termism discount curves.                       |\n| **D.3** | **Holonic Conflict Topology**        |  Typology of clashes: resource, goal, epistemic, temporal.                      |\n| D.3.1   | Conflict Detection Logic (LOG‑use)   |  Formal predicates (`conflictsWith`, `mitigatedBy`) and satisfiability checks.  |\n| D.3.2   | Conflict Routing Protocol            |  From local negotiation → external mediation → DRR appeal.                      |\n| **D.4** | **Trust‑Aware Mediation Calculus**   |  Resolution algorithm blends value‑weights with B.3 trust scores.               |\n| D.4.1   | Fair‑Share Negotiation Operator      |  Nash‑like but bias‑corrected; imports `Resrc‑CAL` cost functions.              |\n| D.4.2   | Assurance‑Driven Override            |  When safety evidence overrides utility maximisation.                           |\n",
      "metadata": {},
      "part": "C",
      "cluster": null
    },
    {
      "id": "D.5",
      "title": "Bias-Audit & Ethical Assurance",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## D.5 - Bias-Audit & Ethical Assurance\n",
        "problem": "### D.5:2 - **Problem**\n\nWithout a formal, repeatable method for surfacing and mitigating these biases, FPF models risk becoming \"flawed by design.\" This leads to three critical failure modes:\n\n1.  **Systemic Harm:** The deployed holon, despite meeting all its technical specifications, causes unintended negative consequences for certain groups or in certain contexts.\n2.  **Eroded Trust:** Stakeholders or the public lose trust in the system (and its creators) when its inherent biases are exposed after deployment.\n3.  **Hidden Risk:** The assurance case appears strong on paper, but it is built on a foundation of unexamined and potentially dangerous assumptions, creating a significant hidden risk.\n",
        "forces": "### D.5:3 - **Forces**\n\n| Force | Tension |\n| :--- | :--- |\n| **Objectivity vs. Inevitable Subjectivity** | How to strive for objective, neutral models while acknowledging that all creation is influenced by the subjective perspectives of the creators. |\n| **Speed of Delivery vs. Depth of Reflection** | How to integrate a thoughtful ethical review process without paralyzing the agile, iterative cycles of development. |\n| **Expertise vs. Inclusivity** | How to leverage specialized ethical expertise without disenfranchising the core engineering team from moral responsibility. |\n| **Process vs. Culture** | Is ethical assurance a bureaucratic checklist to be completed, or a cultural practice of continuous self-critique? |\n",
        "solution": "### D.5:4 - **Solution**\n\nFPF introduces the **Bias-Audit Cycle (BA-Cycle)**, a lightweight, iterative ceremony designed to integrate ethical reflection directly into the engineering development cycle. It is not a one-time gate but a continuous loop of inquiry.\n\n#### D.5:4.1 - The Bias-Audit Cycle: Four Phases\n\nThe cycle consists of four distinct phases, aligned with the project's natural rhythm.\n\n| Phase | Trigger | Core Activity | Output |\n| :--- | :--- | :--- | :--- |\n| **BA-0: Kick-off** | Project start or major new feature. | **Framing the ethical scope.** The team identifies potential areas of bias and creates an initial, living document called the **Bias Register**. | A skeleton Bias Register with initial questions. |\n| **BA-1: Rapid Scan**| End of each sprint or design session. | **Continuous lightweight check.** A rotating member of the core team (the *Engineer-Scrutineer*) quickly scans recent changes against a checklist, flagging potential issues in the Bias Register. | Updated Bias Register with new items flagged for discussion. |\n| **BA-2: Panel Review**| Before a major integration or release decision (e.g., before moving to the `Evidence` state). | **Deep, multi-perspective critique.** A small panel, including individuals in roles like **Ethicist**, **Domain Sociologist**, and **UX Design Critic**, reviews the flagged items and proposes concrete mitigations. | A structured, auditable artifact called the **Bias-Audit Report**, documenting findings and required actions. |\n| **BA-3: Closure** | At the release freeze. | **Ensuring accountability.** The facilitator confirms that all \"blocking\" issues from the Bias-Audit Report have either been resolved or have a documented, accepted risk. | The final Bias-Audit Report is marked as *resolved* or *risk-accepted* for that release. |\n\n#### D.5:4.2 - The Bias Taxonomy: A Shared Language for Critique\n\nTo structure the audit, FPF provides a minimal, extensible taxonomy of common bias categories.\n\n| Code | Bias Category | Manager's View: The Simple Question to Ask |\n| :--- | :--- | :--- |\n| **REP** | **Representation Bias** | \"Whose voice, data, or perspective is missing from this model?\" |\n| **ALG** | **Algorithmic Bias** | \"Could our automated rule or formula unintentionally amplify unfairness for minority or edge cases?\" |\n| **VIS** | **Visual Framing Bias** | \"Does this diagram, color choice, or dashboard visualization steer the user towards a preferred conclusion?\" |\n| **MET** | **Metric Proxy Bias** | \"Are we chasing a metric that is easy to measure, at the expense of the real, harder-to-measure objective?\" (Connects to ADR-015) |\n| **LNG** | **Lexical Bias** | \"Do our naming choices (e.g., 'master/slave', 'blacklist/whitelist') encode unintended value judgments or historical baggage?\" |\n\n> **Didactic Note for Managers: This is Risk Management, Not a Philosophy Seminar**\n>\n> The Bias-Audit Cycle is FPF's \"immune system.\" It's designed to find and neutralize hidden assumptions before they become costly product failures or public relations disasters. Think of it like a security audit, but for the ethical and social integrity of your system.\n>\n> *   **It's not about being \"perfect\"; it's about being \"aware.\"** The goal is not to eliminate all bias (an impossible task) but to make your team's biases explicit, documented, and consciously managed.\n> *   **It's cost-effective.** The lightweight \"Rapid Scan\" catches most issues early, during a sprint. The more intensive \"Panel Review\" is reserved for key moments, ensuring that expert time is used efficiently.\n> *   **It creates a defensible record.** The Bias-Audit Reports provide a clear, auditable trail showing that your team has taken a systematic and responsible approach to identifying and mitigating potential harms. In an era of increasing scrutiny on AI and autonomous systems, this record is not just good practice—it's a critical business asset.\n\n#### D.5:4.3 - Normative Artifacts\n\nThe Bias-Audit Cycle produces two key conceptual artifacts that serve as the auditable record of ethical deliberation.\n\n*   **The Bias Register:**\n    *   **Nature:** A living, evolving **episteme** that serves as a repository of questions, concerns, and potential biases identified throughout a holon's evolution.\n    *   **Content:** It is a structured collection of inquiries, organized by the Bias Taxonomy (REP, ALG, etc.). It is continuously updated during the Rapid Scans (BA-1) and represents the \"running log\" of ethical and bias-related considerations for the project.\n\n*   **The Bias-Audit Report:**\n    *   **Nature:** A formal, versioned **episteme** that documents the findings of the Panel Review (BA-2).\n    *   **Content:** It contains a structured record of findings. Each finding is a `U.Episteme` with attributes for:\n        *   `biasCode`: The category from the Bias Taxonomy.\n        *   `severity`: An ordinal level (`high`, `medium`, `low`).\n        *   `description`: A narrative explaining the issue.\n        *   `mitigation`: A proposed `U.Method` or `U.ConstraintRule` to address the issue.\n        *   `status`: A state (`blocking`, `resolved`, `risk-accepted`).\n    *   **Conceptual Example:**\n        *   `finding-01`: An episteme with `biasCode: REP`, `severity: high`, and a `description` stating that the training data for a recognition holon lacks representation from certain demographics. The `mitigation` would be a `U.Method` for acquiring a balanced dataset, and the `status` would be `blocking` until this method is executed and its outcome validated.\n",
        "conformance_checklist": "### D.5:5 - **Conformance Checklist**\n\n*   **CC-D5.1 (Cycle Mandate):** Any project developing a holon that interacts with or makes decisions about humans **MUST** conduct the Bias-Audit Cycle.\n*   **CC-D5.2 (Artifact Mandate):** The project **MUST** maintain a **Bias Register** and produce a **Bias-Audit Report** before any major release.\n*   **CC-D5.3 (Blocking Issue Mandate):** A release **SHALL NOT** be considered conformant if its latest Bias-Audit Report contains any unresolved findings with `status: blocking`. The issue must either be moved to `resolved` (mitigated) or `risk-accepted` (formally signed off by a designated authority).\n*   **CC-D5.4 (Role Mandate):** The Panel Review (BA-2) **MUST** involve at least three individuals representing distinct perspectives, ideally aligning with the roles of *Ethicist*, *Domain Sociologist*, and *UX Design Critic* from the Intellect Stack.\n",
        "anti_patterns": "### D.5:6 - **Common Anti-Patterns and How to Avoid Them**\n\n| Anti-Pattern | Manager's View: What It Looks Like | How FPF Prevents It (Conceptually) |\n| :--- | :--- | :--- |\n| **The \"Ethics Ghetto\"** | One person is the \"ethics officer,\" and the rest of the engineering team sees bias as \"not my job.\" | The **Rapid Scan (BA-1)** is a conceptual activity performed by a rotating member of the core team. This distributes the responsibility for ethical reflection across all roles. |\n| **The \"Checklist Charade\"** | The team mechanically answers \"yes/no\" to bias questions just before a release, without any real reflection, simply to satisfy a process requirement. | The **Panel Review (BA-2)** is a moment of deep, multi-perspective critique that a perfunctory checklist cannot survive. The requirement for a structured **Bias-Audit Report** also forces concrete findings and mitigation methods, not just checkmarks. |\n| **The \"Bias Whack-a-Mole\"** | The team fixes one bias issue, only for another to pop up, because they are only addressing symptoms. | The **Bias Taxonomy** encourages a more systematic approach. By considering categories like Representation (REP) and Metric Proxy (MET), the team is prompted to look for root causes (e.g., flawed data collection methods or poorly chosen objectives) rather than just patching individual algorithmic flaws. |\n",
        "consequences": "### D.5:7 - **Consequences**\n\n| Benefits | Trade-offs / Mitigations |\n| :--- | :--- |\n| **Proactive Risk Mitigation:** The cycle surfaces and addresses potential ethical and social harms *before* they are deployed, preventing costly failures and reputational damage. | **Additional Ceremony:** The cycle introduces new conceptual steps and artifacts into the workflow. *Mitigation:* The process is designed to be lightweight and to align with existing agile cadences (e.g., the Rapid Scan is a brief conceptual check at the end of a sprint). |\n| **Creates an Auditable Ethical Record:** The Bias-Audit Reports provide a transparent, defensible trail demonstrating that the organization has a systematic process for managing ethical risks. | **Finding the Right Expertise:** It may be challenging to find individuals to fill the required roles. *Mitigation:* These roles represent perspectives, not necessarily formal job titles. The key is the diversity of viewpoints. |\n| **Builds a Culture of Responsibility:** By making ethical reflection a routine part of the engineering process, the cycle fosters a culture where every team member is empowered and expected to think critically about the broader impact of their work. | - |\n| **Improves Holon Quality:** Designing for a wider range of users and edge cases, as prompted by the audit, often leads to more robust, user-friendly, and innovative holons. | - |\n",
        "rationale": "### D.5:8 - **Rationale**\n\nFormal correctness is not a substitute for moral responsibility. This pattern recognizes that bias is not an occasional flaw but a systemic feature of any human-led design process. The Bias-Audit Cycle is FPF's formal mechanism for managing this reality. It is a direct implementation of the **Cross-Disciplinary Bias Audit Guard-Rail (E.5.4)**.\n\nBy integrating this cycle into the core reasoning workflow, FPF moves ethical assurance from a peripheral, often-ignored \"nice-to-have\" into a central, non-negotiable component of engineering excellence. It ensures that the powerful tools of formal reasoning and validation provided by FPF are always directed towards creating holons that are not only correct, but also conscionable.\n",
        "relations": "### D.5:9 - **Relations**\n\n*   **Implements:** The `Cross-Disciplinary Bias Audit` Guard-Rail (E.5.4).\n*   **Complements:** `D.4 Trust-Aware Mediation Calculus` by providing inputs on fairness and value alignment; `B.3.4 Evidence Decay & Epistemic Debt` by questioning the longevity of assumptions about social context.\n*   **Operationalizes:** The conceptual roles of `Ethicist`, `Domain Sociologist`, and `UX Design Critic` from the Intellect Stack.\n",
        "d.5:end": "### D.5:End\n\n\n| D.5.1   | Taxonomy‑Guided Audit Templates      |  Onto / Arch / Prag / Did dimensions; sampling guidance.                        |\n| D.5.2   | Assurance Metrics Roll‑up            | Composite “Ethical Risk Index”, traceable to Evidence Graph Ref.                 |\n\n\n# **Part E - FPF Constitution and Authoring Cluster**\n\n# Section E‑I - The FPF Constitution\n"
      },
      "content": "### D.5:End\n\n\n| D.5.1   | Taxonomy‑Guided Audit Templates      |  Onto / Arch / Prag / Did dimensions; sampling guidance.                        |\n| D.5.2   | Assurance Metrics Roll‑up            | Composite “Ethical Risk Index”, traceable to Evidence Graph Ref.                 |\n\n\n# **Part E - FPF Constitution and Authoring Cluster**\n\n# Section E‑I - The FPF Constitution\n",
      "metadata": {},
      "part": "D",
      "cluster": null
    },
    {
      "id": "E.1",
      "title": "Vision & Mission: “Operating System for Thought”",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## E.1 - Vision & Mission: “Operating System for Thought”\n",
        "problem": "### E.1:2 - Problem\nAbsent such a scaffold, every discipline re‑invents epistemology and systems thinking, spawning silos, steep learning curves, and brittle life‑cycle models. Previous attempts either froze agility in rigid hierarchies or dissolved rigour in tool‑centric jargon.\n",
        "forces": "### E.1:3 - Forces\n\n| Force                           | Tension                                                                 |\n| ------------------------------- | ----------------------------------------------------------------------- |\n| **Conceptual Unity**            | Freedom to evolve ↔ invariant principles that prevent vocabulary drift. |\n| **Rigor vs Agility**            | Formal verifiability ↔ rapid, iterative exploration.                    |\n| **Universality vs Specificity** | Domain‑agnostic kernel ↔ problem‑specific leverage.                     |\n| **Didactic Clarity**            | Human comprehension ↔ abstract purity and density.                      |\n| **Physical Grounding**          | Abstract constructs ↔ a *material Transformer* that proves feasibility.     |\n\n**Mission Statement**\n\n> *Enable any motivated system/actor/agent/transformer — human or AI — to transform a raw idea into a reproducible, auditable change in the physical world through incremental, falsifiable cycles.*\n\n**Vision Statement**\n\n> *Reliable reasoning should be as accessible as version control: clone the conceptual kernel, extend it with domain plugins, and commit decisions that remain traceable across time, scale, and discipline.*\n",
        "solution": "### E.1:4 - Solution — *FPF as an Operating System for Thought*\nFPF delivers a **generative scaffold** realised as:\n\n1. a **micro‑kernel** of non‑derivable, cross‑domain **first principles**;\n2. pluggable **architheories**—Systemic Calculus, Knowledge Dynamics, etc.—that instantiate those principles;\n3. a **pattern language** (*Architectural* ► why/ how; *Definitional* ► what) with embedded **Conformance Checklist (CC)**;\n4. **Design Rationale Records (DRRs)** that govern safe, auditable evolution;\n5. three **core invariants** that every artefact must honour\n\n   * **Evolvability** — change is expected and governed;\n   * **Cross‑Scale Coherence** — the same algebra binds parts to wholes at any level;\n   * **Didactic Transparency** — each element exposes its own reasoning path.\n",
        "conformance_checklist": "### E.1:5 - ** Conformance Checklist**\n\n| ID              | Requirement                                                                                                                                          | Rationale                                       |\n| --------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------- |\n| **CC‑Vision.1** | Every composite artefact **MUST** cite a *material Transformer* that can, in principle, perform the aggregation (`Γ(D,C)`) that produced it.             | Ensures physical feasibility and auditability.  |\n| **CC‑Vision.2** | Every normative rule **MUST** demonstrably support at least one core invariant (*Evolvability, Cross‑Scale Coherence, Didactic Transparency*).       | Keeps the Canon lean and purpose‑driven.        |\n| **CC‑Vision.3** | Conceptual text **MUST NOT** contain tokens black‑listed by the **DevOps Lexical Firewall** (`yaml`, `docker`, …).                                   | Preserves layer purity and tool‑agnostic core.  |\n| **CC‑Vision.4** | A conformant artefact **MUST** state a measurable benefit for at least one of the three roles (*Engineer, Researcher, Learner*) or justify omission. | Aligns success with stakeholder trajectories.   |\n",
        "consequences": "### E.1:6 - Consequences\n\n*Positive* — Unified language accelerates cross‑disciplinary discovery; regulators can audit claim lineages; learners acquire concepts through the spec itself.\n*Trade‑offs* — Authors face an initial learning curve and must trace every rule to an invariant; disciplined traceability is required to prevent variant sprawl.\n",
        "relations": "### E.1:7 - Relations & Precedence\nPattern E.1 governs **E.2 Eleven Pillars** and the Guard‑Rail set **A.5–A.8**; any later pattern that conflicts with E.1 **MUST** be revised via a DRR before entering the Canon.\n\n*“Purpose without a scaffold is wishful thinking; a scaffold without purpose is cargo‑cult—FPF welds the two into disciplined imagination.”*\n",
        "e.1:end": "### E.1:End\n"
      },
      "content": "### E.1:End\n",
      "metadata": {},
      "part": "E",
      "cluster": null
    },
    {
      "id": "E.2",
      "title": "The Eleven Pillars",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## E.2 - The Eleven Pillars\n",
        "problem": "### E.2:2 - Problem\nFrameworks without binding first principles wobble between two extremes: rigid dogmas that kill adaptation and amorphous guidelines that invite cognitive chaos. In either case, reasoning fragments, auditability collapses, and physical impact suffers.\n",
        "forces": "### E.2:3 - Forces\n| Force                          | Tension                                                |\n| ------------------------------ | ------------------------------------------------------ |\n| **Foundational Stability**     | Immutable core ↔ perpetual adaptation to new knowledge |\n| **Cognitive Load**             | Minimal elegance ↔ comprehensive coverage              |\n| **Rigor vs Accessibility**     | Formal soundness ↔ intuitive entry for non‑specialists |\n| **Universality vs Modularity** | Domain‑agnostic scope ↔ plug‑in extensibility          |\n| **Pragmatic Grounding**        | Abstract invariants ↔ measurable, falsifiable outcomes |\n",
        "solution": "### E.2:4 - Solution\nFPF rests on **eleven non‑negotiable pillars**. Each pillar is a binding constraint that every artefact, pattern, and design‑rationale record (DRR) **must** honour. Together they form the load‑bearing structure that guarantees evolvability, cross‑scale coherence, and didactic clarity.\n\n| ID       | Pillar                         | Essence                                                                                                                   |\n| -------- | ------------------------------ | ------------------------------------------------------------------------------------------------------------------------- |\n| **P‑1**  | **Cognitive Elegance**         | Highlight decisive structure, eliminate ornamental formalism; separate data governance from thinking.                     |\n| **P‑2**  | **Didactic Primacy**           | Human comprehension outranks theoretical or tooling purity.                                                               |\n| **P‑3**  | **Scalable Formality**         | A single artefact can mature step‑by‑step from informal guess to formally assured state without forks or rewrites.        |\n| **P‑4**  | **Open‑Ended Kernel**          | The micro‑kernel contains only meta‑concepts; all domain knowledge lives in external architheories.                       |\n| **P‑5**  | **Plug‑in Layering**           | Architheories are modular, declarative extensions that can be added, replaced, or removed without destabilising the core. |\n| **P‑6**  | **Lexical Stratification**     | Every core concept is expressible in four registers: plain name, technical term, formal U.Type, and mathematical symbol.  |\n| **P‑7**  | **Pragmatic Utility**          | Proofs, metrics, and models exist to achieve real‑world objectives; falsification is rewarded over confirmation.          |\n| **P‑8**  | **Cross‑Scale Consistency**    | Composition algebras (aggregation, boundary, emergence) are invariant across material systems, knowledge, and methods.    |\n| **P‑9**  | **State Explicitness**         | Every artefact declares its state (`design‑time`, `run‑time`, etc.); transitions are cheap, traceable, auditable.         |\n| **P‑10** | **Open‑Ended Evolution**       | Every entity is expected to evolve indefinitely; cycles must remain cheap, safe, and cognitively rewarding.               |\n| **P‑11** | **State‑of‑the‑Art Alignment** | The kernel and architheories track reliable contemporary knowledge and update when the SoTA advances.                     |\n\n> Any DRR that contradicts a pillar must first amend this constitutional pattern.\n",
        "conformance_checklist": "### E.2:7 - Conformance Checklist — BLP\n\n| ID            | Requirement                                                                                                     | Purpose                                       |\n| ------------- | --------------------------------------------------------------------------------------------------------------- | --------------------------------------------- |\n| **CC‑BLP.1**  | Tolerances **α (budget)** and **δ (assurance)** are declared in the DRR or referenced via policy profile.      | Makes BLP decisions reproducible.             |\n| **CC‑BLP.2**  | DRR includes a **Scale‑Audit** (BLP‑1a–e) with published slopes and pinned editions/policy‑IDs.               | Makes scale behavior auditable.               |\n| **CC‑BLP.3**  | Selection decision cites **BLP‑2** and lists the governing pillars and precedence checks.                      | Ties choice to constitution.                  |\n| **CC‑BLP.4**  | Any admitted heuristic is logged as **Heuristic Debt** with expiry/review and de‑hardening plan.               | Prevents silent drift toward brittle rules.   |\n| **CC‑BLP.5**  | Default authoring uses **rules‑as‑prohibitions**; deviations are DRR‑justified and safety‑anchored.            | Preserves agent autonomy under constraints.   |\n| **CC‑BLP.6**  | Resource accounts (time/energy/FLOPs) and assurance deltas are reported via **Resrc‑CAL** and B.3.             | Avoids “free heuristic” illusions.            |\n| **CC‑BLP.7**  | **Replicate counts/seeds** and **confidence intervals** for slope estimates are recorded.                      | Prevents spurious slope inferences.           |\n",
        "policy_—_bitter‑lesson_preference_(blp)": "### E.2:6 - Policy — Bitter‑Lesson Preference (BLP)\n\n**Intent.** Favor **general, computation‑leveraged**, and **freedom‑of‑action** methods over hand‑tuned, brittle heuristics *when safety and legality are held constant*. This codifies the empirical trend that methods which scale with **data, compute, and search breadth** outpace bespoke rule‑engineering. **Applicability:** beyond ML, this policy covers **search/optimization**, **control**, **simulation‑based inference**, and other computational sciences where capability improves with scale and exploration. When **NQD/E/E‑LOG** promotes **novelty/coverage (illumination)** telemetry into dominance (via an explicit **CAL** policy; **policy‑id recorded in SCR**), these telemetry metrics are included in BLP comparisons for the audited window.\n\n**BLP‑1 — Scale‑Audit Requirement.** Any DRR that selects a more specialized/hand‑engineered method over a general/scalable alternative **MUST** include a **Scale‑Audit**:\n* (a) **Parity harness**: same **ComparatorSet**, **freshness window**, and **evaluation seeds/replicates**; portfolio‑first evaluation (see **G.5/G.9**). Dominance criterion: **Pareto‑only** by default across the declared objective vector; any alternative requires a documented waiver by **Gov‑CAL** under **E.3** precedence.\n* (b) **Budgets**: sweep **compute** (**steps/tokens/params/time/energy**, as applicable), **data** (size/quality), and **freedom‑of‑action** (from script‑like instructions → minimal prohibitions) **under a fixed risk/safety envelope**. If any parameter cannot be swept, **pin** it and record the invariant.\n* (c) **Slopes & uncertainty**: report ∂quality/∂compute, ∂quality/∂data, and (where applicable) ∂coverage/∂**freedom‑of‑action** and **∂novelty/∂budget**; include **error bars/CI** from multi‑seed trials; publish edition pins and policy‑IDs in SCR/telemetry (**G.11**).\n* (d) **Resources**: publish **Resrc‑CAL** accounts (time/energy/FLOPs) and assurance deltas (B.3).  \n* (e) **Objective declaration**: list the **objective vector** (quality, risk, cost, **and any illumination telemetry explicitly promoted into dominance via CAL** with **policy‑id recorded in SCR**) used for Pareto comparison.\n\n**BLP‑2 — Preference Rule.** Given lawfulness and comparable assurance (within δ) and budget (within α), prefer the method whose **slope vector** is **Pareto‑dominant** over the audited range (per **BLP‑1c/1e**). If no dominance holds within error bounds, prefer the **more general** method (fewer domain‑specific heuristics, greater transfer via Bridges Φ/Ψ); otherwise resolve via **E/E‑LOG** tie‑breakers declared in policy.\n\n**BLP‑3 — Minimal‑Prescription Default.** Author **rules‑as‑prohibitions** (negative constraints) over step‑by‑step scripts. Encode limits in **Φ policy tables** (and **Φ_plane** where applicable) instead of procedural checklists; allow the agent/system to sequence functions autonomously under those constraints (SoS‑LOG). **Pre/post‑conditions and test harnesses remain permitted**; **scripts** are permissible only when mandated by safety/regulation, or with compelling evidence recorded in the DRR **and reviewed under E.3 precedence / E.5 Guard‑Rails**.\n\n**BLP‑4 — Heuristic‑Debt Register.** Any hand‑tuned rule admitted for pragmatic reasons **MUST** be registered as **Heuristic Debt** with: scope, owner, expiry/review window, measurable replacement target under BLP‑2, and a de‑hardening/sunset plan. Track in **CalibrationLedger/BCT (Baseline Change Tracker)** and cite in SCR.\n\n**BLP‑5 — Continuous‑Learning Posture.** Where product policy allows, enable **feedback‑driven adaptation** (e.g., preference learning, critique loops) within Guard‑Rails (**E.5**) and privacy/regulatory controls, with appropriate opt‑outs where required. Disabling adaptation requires DRR justification and a review date.\n\n**BLP‑6 — Precedence & Safeguards.** BLP is a **Gov/Arch** policy instantiated by Pillars **P‑10 (Open‑Ended Evolution)**, **P‑11 (SoTA Alignment)**, **P‑7 (Pragmatic Utility)**, and **P‑1 (Cognitive Elegance)**. It does **not** override safety/ethics (**E.5**) **nor** E.3 precedence rulings; where BLP conflicts with Guard‑Rails, **Guard‑Rails prevail**. When **NQD/E/E‑LOG** elevates illumination to dominance for exploration mandates, BLP **adopts that lens** rather than overriding it.\n\n*Informative SoTA contexts (post‑2015):* portfolio‑first selection across **LLM prompt‑programming vs fine‑tuned task models**; **preference‑learning families (RLHF ↔ DPO)**; **QD archives (MAP‑Elites/CMA‑ME/DQD/QDax)**; **open‑ended environment–method co‑evolution (POET‑class)**; **offline RL vs Decision Transformer parity**; and beyond ML, **optimization/control** (model‑based planning vs hand‑tuned controllers) and **simulation‑based inference** in the sciences. These are **illustrative only**; use the parity harness instead of single‑winner leaderboards.\n",
        "relations": "### E.2:12 - Relations\n* **Depends on:** `pat:constitutional/vision` – pillars operationalise the mission.\n* **Refined by:** All subsequent patterns in the Core Specification.\n* **Governs:** Every DRR, tool, and pedagogical artefact linked to FPF.\n\n*These pillars are not a cage but the load‑bearing columns of a workshop where ideas can be safely built, dismantled, and evolved.*\n",
        "definitions": "### E.2:9 - Definitions\n**α (budget tolerance)** may be relative or absolute; declare units (e.g., % cost, wall‑time, energy). **δ (assurance tolerance)** is the permissible delta in assurance under **B.3**; declare measure and floor(s).\n",
        "consequences": "### E.2:10 - Consequences\n\n*Positive*\n\n* Provides an explicit “north star” for every contributor.\n* Delivers a falsifiable checklist for evaluating proposals.\n* Builds trust in high‑assurance domains through transparency.\n\n*Trade‑offs*\n\n* Constitutional review adds friction to rapid, informal changes.\n* Amending the pillar set itself demands high‑bar governance.\n",
        "rationale": "### E.2:11 - Rationale\n\nThe pillars are distilled from systems engineering, philosophy of science, software architecture, and ontology design. They interlock: *Cognitive Elegance* (P‑1) enables *Didactic Primacy* (P‑2); *Open‑Ended Kernel* (P‑4) and *Plug‑in Layering* (P‑5) make *Open‑Ended Evolution* (P‑10) and *SoTA alignment* (P‑11) feasible; *Cross‑Scale Consistency* (P‑8) provides the algebraic backbone for *Scalable Formality* (P‑3). This minimal yet sufficient set balances stability with change, rigor with accessibility, and abstraction with measurable impact.\n",
        "e.2:end": "### E.2:End\n\n"
      },
      "content": "### E.2:End\n\n",
      "metadata": {},
      "part": "E",
      "cluster": null
    },
    {
      "id": "E.3",
      "title": "Principle Taxonomy & Precedence Model",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## E.3 - Principle Taxonomy & Precedence Model\n",
        "problem": "### E.3:2 - Problem\n\nWhen two pillars or derived principles pull in opposite directions, architectural decisions stall—or worse, drift toward the loudest voice. Without an explicit **taxonomy and precedence cascade**, FPF risks devolving into subjective debate, breaking its claim to be a rigorously *auditable* “operating system for thought.”\n",
        "forces": "### E.3:3 - Forces\n| Force                                 | Tension                                                            |\n| ------------------------------------- | ------------------------------------------------------------------ |\n| **Categorical Clarity**               | Coherent grouping ↔ preservation of individual nuance              |\n| **Deterministic Conflict Resolution** | Predictable hierarchy ↔ flexibility for context‑specific overrides |\n| **Evolutionary Stability**            | Durable core ↔ adaptability to new knowledge                       |\n",
        "solution": "### E.3:6 - Illustrative Conflict Resolution\n\n1. **The Conflict**  \n   * **P‑1 Cognitive Elegance** (`Arch`) demands an unambiguous term for “part–whole” entities, pushing us toward **Holon**.  \n   * **P‑2 Didactic Primacy** (`Did`) values immediate practitioner familiarity, pushing us to retain **System**.\n\n2. **Risk of Stalemate**  \n   Without a precedence cascade, the discussion would collapse into subjective argument: *“purity beats clarity!”* vs *“clarity beats purity!”*.\n\n3. **Applying the Precedence Model**  \n   * Default order: **Gov ≫ Arch ≫ Epist ≫ Prag ≫ Did**.  \n   * `Arch` outranks `Did`; therefore **P‑1** takes formal precedence over **P‑2**.\n\n4. **Principled Decision**  \n   We adopted **Holon** to satisfy the higher‑priority principle and mitigated the didactic cost by:  \n   * declaring `System ≡ U.System ⊑ U.Holon`,  \n   * providing aliases and an “On‑Ramp” tutorial.\n\n> *The precedence rule did not merely name a winner; it compelled a solution that honoured both principles in proportion to their rank.*\n\n**Precedence (high → low).** Law & Regulation → **E.5 Guard‑Rails** → **B.3 Trust & Assurance** → **E.3 governance decisions** → **E/E‑LOG policies** (editioned) → **BLP (E.2)** → Product Policies → Implementation Tactics.\n\n**Notes.**\n* BLP is a constitutional policy (see E.2 / “BLP”), but **does not supersede** E.5 Guard‑Rails nor B.3 assurance floors; it **does govern** ties among lawful, comparable‑assurance options.\n* Wherever **NQD/E/E‑LOG** promotes illumination telemetry to dominance (via an explicit **CAL** policy; **policy‑id recorded in SCR**), **BLP adopts that lens** rather than overriding it (see E.2 BLP‑6).\n* Any exception to policy **MUST** include a DRR with rationale and expiry.\n* **BLP Override (Waiver).** When a narrower hand‑engineered method is selected over a general/scalable alternative **within declared tolerances** (α = budget, δ = assurance), the DRR **MUST** include:\n  - a **BLP Scale‑Audit** (see E.2 **BLP‑1**) covering compute/data/**freedom‑of‑action** sweeps and slope/uncertainty reporting,\n  - the **tolerances** α/δ and objective vector used (E.2 **BLP‑1e**),\n  - a **Heuristic‑Debt** entry (owner, scope, expiry/review, de‑hardening plan) per E.2 **BLP‑4**,\n  - an **AutonomyProfileId** (see **E.3‑ABL**) and the GateDecision authority (see **Gate‑decision authority map** below).\n**Portfolio‑first parity.** All precedence decisions that compare methods **MUST** use the G.5/G.9 parity harness and **Pareto** dominance; scalarisation across mixed scales/units is **prohibited** (B.3).\n\n**BLP — Bitter‑Lesson Hooks into Precedence**\n1) **Tie‑breaking.** If two lawful options are **within δ** assurance and **within α** budget, prefer the option whose **slope vector Pareto‑dominates** over the audited window; if no dominance, prefer the **more general** method. (E.2 **BLP‑2**.)\n2) **Script‑vs‑Search conflicts.** For conflicts between **procedural scripts** and **general search/learning**, scripts prevail **only** when mandated by E.5 or regulation, or when a DRR records a **BLP‑waiver** with expiry and hazard rationale (E.2 **BLP‑3/6**).\n3) **Publication.** Precedence rulings that reference BLP **MUST** publish editioned policy‑IDs, edition pins, and **Resrc‑CAL** accounts to the SCR (E.2 **BLP‑1d**; G.11).\n\n**ABL — Autonomy‑Budget & Oversight Profiles (GateProfile)**\nThis section defines an **extensible family of autonomy oversight profiles** for agentic tool use: each profile specifies (i) a budget envelope, (ii) a Freedom‑of‑Action (FoA) descriptor, and (iii) the required **gate‑decision publication** to authorize execution under that envelope. The familiar labels **L0…L4** are treated here as **profile identifiers** (not a fixed managerial ladder): projects MAY introduce additional profiles or sub‑profiles by minting new profile ids, provided they publish the same fields (budgets, FoA, decision roles, telemetry contracts) and keep profile changes explicit and auditable.\n\n| ProfileId | Name                         | Freedom‑of‑Action (FoA)                  | Explore‑Share (default) | Typical Use                                     | GateDecision authority |\n|---------:|------------------------------|------------------------------------------|-------------------------|-------------------------------------------------|------------------------|\n| **L0** | Scripted Execution           | **Whitelist only**; fixed scripts        | 0                       | Compliance‑critical, deterministic procedures   | Engineer‑of‑Record (EoR) |\n| **L1** | Constrained Sequencing       | Negative constraints; **single‑tool**    | ≤ 0.10                  | Low‑risk automation with bounded novelty        | EoR + Peer Review |\n| **L2** | Supervised Autonomy          | Multi‑tool plans; bounded replanning     | 0.20 (±0.10)            | Ambiguous tasks; moderate budget                | Team Lead + Safety |\n| **L3** | Auditable Autonomy           | Multi‑step, self‑replanning; adaptive    | 0.30 (±0.10)            | Production agents with learning under guard‑rails | Product + Safety + Legal |\n| **L4** | Open‑Ended / Research Mode   | Broad FoA within sandbox & rails         | 0.40–0.50               | Illumination‑first exploration, sandboxes only  | Governance Board (Gov‑CAL) |\n\n**Normative requirements by profile.**\n* **Budgets.** Each profile **MUST** declare ceilings for **time / compute / cost / risk** and a FoA descriptor; units must be explicit (Resrc‑CAL). Budgets are **hard gates** at run‑time (C.Agent‑Tools‑CAL **ATC‑3**).\n* **Profile binding & change visibility.** Every CallPlan **MUST** declare the active profile id. Any profile change is a **GateCrossing** (E.18) and **MUST** be published (DecisionLog entry + pinned policy‑ids), so an auditor can reconstruct which profile governed which Window.\n* **Assurance floors.** **B.3** WLNK minima on **F** and **R** apply at all profiles. Any profile‑specific tightening (e.g., higher required **R_eff** or stricter CL/Φ policies for broader FoA) **MUST** be declared on the profile and pinned by policy‑id. Pre‑deployment **assurance deltas** MUST be recorded for L2+.\n* **Exploration discipline.** `explore_share` MUST be explicit in the **CallPlan** (C.Agent‑Tools‑CAL **ATC‑4**). Deviations from defaults require DRR justification.\n* **Provenance.** L1+ MUST emit a **CallGraph** with Service/Method editions, EmitterPolicyRef, budget deltas, and observation hooks (C.Agent‑Tools‑CAL **ATC‑5/6**).\n* **BLP conformance.** For L2+, selection MUST apply **BLP** (E.2 **BLP‑2**) with **α/δ** tolerances declared in the plan policy. Any admitted heuristic requires a **Heuristic‑Debt** entry (E.2 **BLP‑4**).\n* **Learning/Adaptation.** L3–L4 MAY enable **feedback‑driven adaptation** within E.5 Guard‑Rails and privacy controls; L0–L2 default **off** unless a DRR documents mitigation (E.2 **BLP‑5**).\n* **Human‑in‑the‑Loop (HITL).** HITL obligations are expressed as **gate decisions and pause/resume hooks**, not an implicit “approval ladder”:\n  * **L0–L1:** execution MAY start only after an explicit **GateDecision** authorizing the CallPlan is present in the declared window.\n  * **L2:** sentinels MUST be able to pause execution; resumption requires a new **GateDecision** recorded in the DecisionLog.\n  * **L3:** the profile MUST declare periodic review windows; continued execution across a review boundary requires an explicit **GateDecision**.\n  * **L4:** continuous telemetry review; the default locus is **sandboxed**; leaving the sandbox requires an explicit **GateCrossing** with a published CrossingSurface (E.18 + F.9/A.27).\n\n**Gate‑decision authority map (default signers; who may author GateDecisions).**\n* **L0:** EoR or appointed maintainer.\n* **L1:** EoR **and** peer reviewer (two‑person rule).\n* **L2:** Team Lead **and** Safety representative.\n* **L3:** Product Owner **and** Safety **and** Legal/Privacy.\n* **L4:** **Gov‑CAL Board** (multi‑disciplinary) with documented scope, time‑boxed **trial budget**, and rollback criteria.\n\n**Profile promotion / demotion triggers.**\n* **Promote** a profile when repeated **BLP‑consistent** results show stable assurance within δ and budget adherence within α for ≥ **N_policy** runs (declare **N_policy** in the active profile). Promotion is not implicit: a **GateDecision** **MUST** authorize the profile change and cite the slope evidence (E.2 **BLP‑1c**).\n* **Demote** a profile when: (i) a sentinel breaches risk or budget, (ii) assurance drops below floors, (iii) policy changes, or (iv) a significant **heuristic‑debt** item expires without replacement. Demotion **MUST** be published as a GateCrossing with updated budgets/policies pinned.\n",
        "conformance_checklist": "### E.3:7 - **Conformance Checklist — E.3 ↔ BLP Interop**\n\n| ID          | Requirement                                                                                                          | Purpose                          |\n| ----------- | -------------------------------------------------------------------------------------------------------------------- | -------------------------------- |\n| **CC‑E3.10** | Precedence list includes **BLP** explicitly **below** E/E‑LOG and **above** product tactics; conflicts handled via **BLP‑waiver** discipline. | Makes BLP’s standing auditable. |\n| **CC‑E3.11** | Every DRR that overrides BLP **MUST** include a **Scale‑Audit** (E.2 **BLP‑1**) and a **Heuristic‑Debt** entry (E.2 **BLP‑4**). | Prevents silent heuristic drift. |\n| **CC‑E3.12** | Each agentic plan declares an **AutonomyProfileId** (e.g., L0–L4) with explicit budgets, `explore_share`, and **E/E‑LOG EmitterPolicyRef**. | Aligns autonomy with assurance. |\n| **CC‑E3.13** | L1+ executions emit **CallGraphs** with editioned policy/method ids and budget deltas; L3+ include adaptation status. | Ensures replayability & audit. |\n| **CC‑E3.14** | Profile changes follow **promotion/demotion** triggers and are published as GateCrossings with edition pins in the SCR. | Keeps autonomy under control. |\n",
        "consequences": "### E.3:8 - Consequences\n*Positive* — Turns subjective debate into objective, traceable decisions; high‑impact conflicts surface early.\n",
        "rationale": "### E.3:9 - Rationale\nThe chosen taxonomy mirrors FPF’s layered dependency: **Governance** rules how change occurs; **Architecture** shapes what can exist; **Epistemology** secures meaning and trust; **Pragmatics** and **Didactics** ensure usefulness and learnability. Explicit override edges supply the flexibility experts need, while the default hierarchy keeps day‑to‑day design deterministic—a “living constitution” that remains both human‑intelligible and machine‑enforceable.\n",
        "relations": "### E.3:10 - Relations\n* **Depends on:** `pat:constitutional/vision`, `pat:constitutional/pillars`\n* **Governs:** All subsequent patterns and DRRs; Guard‑Rail patterns reference CC‑PT.\\\n\n> *“A taxonomy sorts principles; precedence gives them order—together they convert debate into design.”*\n",
        "e.3:end": "### E.3:End\n"
      },
      "content": "### E.3:End\n",
      "metadata": {},
      "part": "E",
      "cluster": null
    },
    {
      "id": "E.4",
      "title": "FPF Artefact Architecture",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## E.4 - FPF Artefact Architecture\n",
        "problem": "### E.4:2 - Problem\n\nHow can we structure the FPF ecosystem to ensure a clean separation of concerns between normative concepts, didactic materials, and executable tooling? A formal architecture is required to maintain conceptual purity, enable independent evolution of components, and provide a clear map for all stakeholders.\n",
        "forces": "### E.4:3 - Forces\n\n| Force | Tension |\n| :--- | :--- |\n| **Stability vs. Agility** | The conceptual core must evolve slowly and deliberately ↔ tools and tutorials must iterate quickly to keep pace with technology and user needs. |\n| **Authority vs. Accessibility** | Users need to know which rules are normative and binding ↔ they also need accessible, non-normative guides to help them learn. |\n| **Modularity vs. Cohesion** | The different artifact families must be able to evolve independently ↔ they must remain part of a single, coherent FPF ecosystem. |\n",
        "solution": "### E.4:4 - Solution\n\nThe FPF ecosystem is formally stratified into three canonical **artefact families**. Each family has a distinct purpose and is governed by different rules, ensuring a clear separation of concerns. The interaction between these families is governed by the **Unidirectional Dependency Principle** (see Guard-Rail E.5.3).\n\n1.  **The Conceptual Core (The Canon):** This family contains the **normative** pattern language of FPF. It is the single source of truth for all universal concepts, rules, and invariants. It is defined to be tool-agnostic and notation-independent. This family represents the timeless \"law\" of FPF.\n\n2.  **The Tooling Reference:** This family contains **executable artifacts** that implement or verify the normative rules of the Core. This includes reference linters, simulators, and data schemas. This family is the \"instrument\" that makes the law of the Core operational.\n\n3.  **The Pedagogical Companion:** This family contains **non-normative, didactic materials** designed to help humans learn and apply FPF. This includes tutorials, worked examples, and playbooks. This family is the \"textbook\" that explains both the law and the instruments.\n",
        "archetypal_grounding": "### E.4:5 - Archetypal Grounding (System / Episteme)\n\n*   **For a `U.System`:**\n    *   **Conceptual Core:** Defines the universal pattern `U.System`.\n    *   **Tooling Reference:** Provides a modeling language profile or a serialization schema for modeling systems.\n    *   **Pedagogical Companion:** Provides a tutorial on how to model a water pump using that profile.\n\n*   **For an `U.Episteme`:**\n    *   **Conceptual Core:** Defines `U.Episteme` and the F-G-R characteristics.\n    *   **Tooling Reference:** Provides the reference linting tool to automatically score epistemes.\n    *   **Pedagogical Companion:** Provides a case study on how a scientific theory's R-score evolves over time.\n",
        "conformance_checklist": "### E.4:6 - Conformance Checklist\n\n| ID | Requirement |\n| :--- | :--- |\n| **CC-E.4.1** | Every artifact in the FPF ecosystem **MUST** declare which of the three families (Core, Tooling, Pedagogy) it belongs to. |\n| **CC-E.4.2** | The content of each artifact **MUST** be consistent with the defined purpose of its family (e.g., no normative rules in the Pedagogical Companion). |\n| **CC‑E.4.3** | Artefacts in the Tooling or Pedagogy families SHALL NOT be imported by artefacts in the Conceptual Core. |\n",
        "consequences": "### E.4:7 - Consequences\n\n| Benefits | Trade-offs / Mitigations |\n| :--- | :--- |\n| **Clear Separation of Concerns:** Users and contributors can immediately identify the nature and authority of any given artifact. | **Requires Discipline:** Authors must be careful to place new content in the correct artifact family. |\n| **Decoupled Release Cycles:** The Core can maintain a stable, slow release cadence, while the Tooling and Pedagogy artifact family can evolve rapidly. | - |\n| **Architectural Clarity:** Provides a simple, powerful mental model for navigating the entire FPF ecosystem. | - |\n",
        "rationale": "### E.4:8 - Rationale\n\nThis pattern establishes the macro-architecture of the entire FPF ecosystem. By separating the timeless \"why\" and \"what\" (the Conceptual Core) from the practical \"how\" (Tooling) and the educational \"how-to-learn\" (Pedagogy), it creates a system that is simultaneously stable, agile, and accessible. This layered architecture is a proven pattern in large-scale systems, from the OSI model in networking to the structure of modern operating systems, and it is essential for FPF's long-term health and scalability.\n",
        "relations": "### E.4:9 - Relations\n\n*   **Instantiates:** **P-5 (Plugin Layering)** at a macro-level.\n*   **Is Constrained by:** **E.5.3 (Unidirectional Dependency)**.\n*   **Is Foundation For:** The entire authoring and governance model, as it defines the \"territories\" where different rules apply.\n\n> *“A canon without a rationale is scripture; a rationale without a canon is gossip. FPF keeps both, fused in patterns.”*\n",
        "e.4:end": "### E.4:End\n"
      },
      "content": "### E.4:End\n",
      "metadata": {},
      "part": "E",
      "cluster": null
    },
    {
      "id": "E.5",
      "title": "Four Guard‑Rails of FPF",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## E.5 - Four Guard‑Rails of FPF\n",
        "problem": "### E.5:2 - Problem\nWithout explicit, non‑negotiable protectors the Conceptual Core would\nslowly:\n\n* entangle with transient technology terms,  \n* hard‑freeze into a single dialect,  \n* devolve into a tightly coupled “big ball of mud”,  \n* betray its trans‑disciplinary promise.\n",
        "forces": "### E.5:3 - Forces\n\n| Force | Tension |\n|-------|---------|\n| **Purity vs Pragmatism** | Preserve pristine concepts ↔ need real examples. |\n| **Universality vs Convention** | Rules valid across domains ↔ convenience of one familiar notation. |\n| **Modularity vs Integration** | Independent layers ↔ temptation to cross‑link for speed. |\n| **Objectivity vs Perspective** | Neutral framework ↔ Transformers’ unavoidable cultural lens. |\n",
        "solution": "### E.5:4 - Solution — the Four Guard‑Rails\nFPF establishes **four architecturally enforced guard‑rails** that every Core, Tooling, and Pedagogy artefact must obey.  They function as an “immune system” resisting each entropic pull.\n**Scope note (conceptual, not lint).** These guard‑rails regulate the **architecture of thought**—concepts, claims, and their relations. They **do not** mandate tools, file formats, notations, or workflows; any linting or automation lives outside the Core and is optional, provided it preserves these conceptual constraints.\n\n\n| # | Guard‑Rail | Protects against |\n|---|------------|------------------|\n| **GR‑1** | **DevOps Lexical Firewall** | Implementation, governance, automatisation and DevOps concerns gravity |\n| **GR‑2** | **Notational Independence** | Notation lock‑in |\n| **GR‑3** | **Unidirectional Dependency** | Convenience cycles |\n| **GR‑4** | **Cross‑Disciplinary Bias Audit** | Disciplinary monoculture |\n\nConcrete rules for each rail live in patterns **E.5.1 – E.5.4**.\n",
        "archetypal_grounding": "### E.5:5 - Archetypal Grounding (System / Episteme)\n\n| Guard‑Rail | `U.System` example | `U.Episteme` example |\n|------------|-------------------|----------------------|\n| GR‑1 | Definition of `U.System` never cites file formats or build scripts. | Definition of `U.Episteme` avoids naming specific proof engines. |\n| GR‑2 | Pump boundary invariant is true in plain text or any diagram. | F‑G‑R semantics hold in algebraic or graph notation alike. |\n| GR‑3 | A sizing helper imports Core invariants; Core never imports helper tutorials. | Learning guide cites R‑score; Core never cites guide. |\n| GR‑4 | Bias audit removes thermo‑mechanical jargon from a “universal” pattern. | Audit replaces physics‑centric metaphors in a trust pattern. |\n",
        "conformance_checklist": "### E.5:6 - Conformance Checklist\n\n| ID | Requirement | Purpose |\n|----|-------------|---------|\n| **CC‑GR.1** | Every new Core pattern **SHALL** cite, in its *Relations* section, the guard‑rail(s) it relies on or may affect. | Ensures traceability and deliberate rule interaction. |\n| **CC‑GR.2** | Artefacts classified as Tooling or Pedagogy **MUST NOT** violate any rule in GR‑1 through GR‑4. | Keeps entropic forces outside the Conceptual Core. |\n| **CC‑GR.3** | A revision to any guard‑rail pattern **REQUIRES** a Design‑Rationale Record that (a) states the reason, and (b) includes a Pillar‑impact analysis per E.3 precedence model. | Aligns evolution with higher‑level principles. |\n| **CC‑GR.4** | The aggregate of guard‑rail rules **MUST** remain internally consistent and acyclic; no guard‑rail may override another without explicit precedence edges. | Preserves deterministic governance. |\n| **CC‑GR.5** | Every Core pattern **MUST** anchor its primary subject with a declared **ReferencePlane** (`world | concept | episteme`) at first mention. | Keeps Core about “life” objects (extensional/intensional) rather than their paperwork, and aligns with CHR:ReferencePlane. |\n*All CC‑GR duties are **conceptual**. Any automated checks are **informative only** and live in Tooling/Pedagogy.*\n",
        "consequences": "### E.5:7 - Consequences\n\n| Benefits | Trade‑offs / Mitigations |\n|----------|-------------------------|\n| **Long‑term integrity** – stops slow drift of the Core toward jargon, notation lock‑in, and hidden cycles. | Authors must run a guard‑rail checklist before submission. *Mitigation:* template auto‑inserts the checklist. |\n| **Stable yet evolvable ecosystem** – Core stays timeless while Tooling & Pedagogy can iterate rapidly. | Early stage contributions may feel constrained; examples in the Pedagogical Companion show compliant paths. |\n| **Trust & auditability** – stakeholders can verify the framework’s purity independently. | Adds overhead to governance; justified by safety and longevity. |\n",
        "rationale": "### E.5:8 - Rationale\nA constitution without enforcement degrades into *dead‑letter rules*.  \nThe four guard‑rails translate abstract Pillars into **concrete, testable\nconstraints**.  Grouping them under one umbrella pattern:\n\n* gives newcomers a single “safety index” to consult,  \n* makes compliance binary (*pass / amend*),  \n* provides a stable anchor for future automated conformance tools—without\n  mentioning any specific engine, thus honouring GR‑1 itself.\n\nThey collectively instantiate Pillars **P‑1**, **P‑2**, **P‑4**, **P‑5**\nand reinforce the precedence order defined in **E.3**.\n",
        "relations": "### E.5:9 - Relations\n\n* **Comprises:**  \n  * `pat:guard/devops‑firewall` (E.5.1) – GR‑1  \n  * `pat:guard/notational‑independence` (E.5.2) – GR‑2  \n  * `pat:guard/unidirectional‑dependency` (E.5.3) – GR‑3  \n  * `pat:guard/bias‑audit` (E.5.4) – GR‑4\n* **Depends on:**  \n  * `pat:constitution/pillars` (E.2)  \n  * `pat:constitution/principle‑taxonomy` (E.3)\n* **Constrains:** every Core, Tooling, and Pedagogy artefact; all DRRs.\n",
        "e.5:end": "### E.5:End\n"
      },
      "content": "### E.5:End\n",
      "metadata": {},
      "part": "E",
      "cluster": null
    },
    {
      "id": "E.5.1",
      "title": "DevOps Lexical Firewall",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## E.5.1 - DevOps Lexical Firewall\n",
        "problem": "### E.5.1:2 - Problem\n*Conceptual erosion*: a rule that cites a transient technology becomes\nobsolete when that technology fades, forcing unnecessary Core revisions\nand fragmenting historical audits.\n",
        "forces": "### E.5.1:3 - Forces\n\n| Force | Tension |\n|-------|---------|\n| **Timelessness** | Concepts must survive tool turnover. |\n| **Pedagogic clarity** | Examples need concreteness ↔ too much concreteness hard‑codes technology. |\n| **Cross‑domain reach** | Physical‑system engineers and knowledge‑theorists use different stacks. |\n",
        "solution": "### E.5.1:4 - Solution\nEstablish a **Lexical Firewall** around the **Conceptual Core** *(conceptual constraint; not a build‑time linter)*:\n\n1. **Forbidden lexicon**  \n   Normative patterns **SHALL NOT** contain tool‑or file‑specific words\n   (e.g. protocol keywords, file extensions, IDE commands).  \n   Permissible wording: “a reference parser”, “a serialisation schema”.\n\n2. **Indirection rule**  \n   When a Core concept needs an executable illustration, the pattern\n   cites the **Tooling Reference family** artefact by *conceptual name*,\n   never by concrete path or syntax.\n\n3. **Glossary pointer**  \n   If an unavoidable technical term appears, it is defined in a *Tooling Glossary* outside the Core and referenced by conceptual alias—not embedded.\n*Non‑normative automation.* Machine checks **MAY** exist in Tooling; they are advisory and **MUST NOT** be imported into the Core.\n",
        "archetypal_grounding": "### E.5.1:5 - Archetypal Grounding (System / Episteme)\n\n| Scenario | `U.System` example | `U.Episteme` example |\n|----------|-------------------|----------------------|\n| **Normative text** | “A system boundary must expose at least one conserved‑quantity flow.” (No mention of modelling language.) | “An episteme records its F–G–R coordinates.” (No mention of proof syntax.) |\n| **Illustrative link** | A modelling profile resides in the Tooling family; Core cites it as “the reference system‑profile”. | A linting routine lives in Tooling; Core cites it as “the reference episteme‑checker”. |\n",
        "conformance_checklist": "### E.5.1:6 - Conformance Checklist\n\n| ID | Requirement |\n|----|-------------|\n| **CC‑LFW.1** | A Core pattern **SHALL** fail review if it contains implementation‑specific tokens. |\n| **CC‑LFW.2** | References to executable artefacts **MUST** use conceptual names, not file paths or command strings. |\n| **CC‑LFW.3** | Pedagogical examples inside Core **MAY** describe behaviour, but **MUST NOT** embed code snippets. |\n",
        "consequences": "### E.5.1:7 - Consequences\n\n| Benefits | Trade‑offs / Mitigations |\n|----------|-------------------------|\n| Core stays evergreen and cross‑domain. | Authors must relocate concrete examples to Tooling or Pedagogy. |\n| Reviewers can machine‑scan for banned tokens. | Requires a small vocabulary allow‑list; maintained in Tooling Guide. |\n",
        "rationale": "### E.5.1:8 - Rationale\nLanguage shapes thought.  By firewalling transient jargon, we uphold\n**P‑1 Cognitive Elegance** (clarity), **P‑2 Didactic Primacy** (domain‑neutral\nexposition) and **P‑5 Plug‑in Layering** (clean separation between Core\nand Tooling).  The rule is content‑agnostic and thus itself immune to the\nvery decay it prevents.\n",
        "relations": "### E.5.1:9 - Relations\n* **Parent umbrella:** `pat:constitution/guard‑rails` (E.5)  \n* **Constrains:** every pattern in Conceptual Core  \n* **Instantiates pillars:** P‑1, P‑2, P‑5\n",
        "e.5.1:end": "### E.5.1:End\n"
      },
      "content": "### E.5.1:End\n",
      "metadata": {},
      "part": "E",
      "cluster": null
    },
    {
      "id": "E.5.2",
      "title": "Notational Independence",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## E.5.2 - Notational Independence\n",
        "problem": "### E.5.2:2 - Problem\n*Semantic lock‑in*: when a definition relies on a particular glyph set or\ndiagram grammar, alternative communities either translate it—risking\ndrift—or ignore FPF altogether.\n",
        "forces": "### E.5.2:3 - Forces\n\n| Force | Tension |\n|-------|---------|\n| **Expressiveness** | Diagrams and formal grammars aid precision ↔ they should never become the definition itself. |\n| **Longevity** | A 20‑year horizon ↔ notation life‑cycles of 3‑5 years. |\n| **Cross‑discipline adoption** | Mathematicians prefer algebraic syntax; engineers prefer schematics. |\n",
        "solution": "### E.5.2:4 - Solution — Notational Independence Guard‑Rail *(conceptual; semantics over syntax; not a notation mandate)*\n\n1. **Semantics primacy**  \n   Normative content **SHALL** define concepts in linguistic form first\n   (plain English + mathematics if needed). Visual or syntax examples\n   are secondary illustrations.\n\n2. **Equivalence clause**  \n   When an official alternate notation exists, the pattern must state:\n   *“Representation A and Representation B are semantically equivalent\n   under mapping M.”*\n\n3. **Reference indirection**  \n   If the Core cites a diagram, it does so by *conceptual role*\n   (“reference boundary schematic”) rather than by file or syntax name.\n\n4. **Conceptual prefix neutrality**  \n   FPF **conceptual prefixes** (e.g., `U.`, `Γ_`, `ut:`, `tv:`, `ev:`, `mero:`) are  **cognitive namespaces**, not syntax tokens. Core patterns **MUST NOT**  tie their meaning to any concrete serialisation or URI scheme for these prefixes; any expansions are **illustrative only** and live in Tooling or Pedagogy.\n\n5. **Cards and other \"forms\"**\nCards, tables and other \"forms\" exist in FPF core only as conceptual model, not as data model, thus no need to data-related notation or notation for lint. Comformance checklist and quards is also conceptual, argumentation like \"this will ease machine check\" is forbidden, no machine checking is intended in core; machine checks and linters live only in Tooling.\n",
        "archetypal_grounding": "### E.5.2:5 - Archetypal Grounding (System / Episteme)\n\n| Scenario | `U.System` example | `U.Episteme` example |\n|----------|-------------------|----------------------|\n| Definition | Boundary of a pump is expressed in prose plus set notation; a diagram is illustrative. | F‑G‑R characteristics defined textually; a triple‑store serialisation is illustrative. |\n| Alternate rendering | Same pump semantics rendered in a lattice diagram or a tabular sheet remain valid. | R‑scores plotted in a heatmap or listed in CSV remain equivalent. |\n",
        "conformance_checklist": "### E.5.2:6 - Conformance Checklist\n\n| ID | Requirement |\n|----|-------------|\n| **CC‑NI.1** | A Core pattern **MUST NOT** embed semantics that hinge on one specific notation. |\n| **CC‑NI.2** | Illustrative renderings **SHALL** be marked “informative”. |\n| **CC‑NI.3** | When multiple official renderings exist, the pattern **MUST** declare the semantic mapping between them. |\n| **CC‑NI.4** | If a **conceptual prefix** appears in Core, its expansion (if shown) **SHALL** be marked *informative* and **MUST NOT** be required to interpret the semantics. |\n",
        "consequences": "### E.5.2:7 - Consequences\n\n| Benefits | Trade‑offs / Mitigations |\n|----------|-------------------------|\n| Ensures FPF survives notation turnover. | Authors invest time describing mappings; mitigated by reusable mapping templates. |\n| Lowers entry barrier for domains using different diagram traditions. | Excessive illustrations can bloat pages; guidance in Pedagogical Companion limits scope. |\n",
        "rationale": "### E.5.2:8 - Rationale\nLanguage and diagrams are tools, not truths. By elevating semantics over\nsyntax, FPF maintains **P‑1 Cognitive Elegance** and **P‑2 Didactic\nPrimacy** while safeguarding **P‑5 Plug‑in Layering**: tooling layers can\nadd new renderers without Core edits.\n",
        "relations": "### E.5.2:9 - Relations\n* **Parent umbrella:** `pat:constitution/guard‑rails` (E.5)  \n* **Constrains:** every normative Core pattern and official alternate rendering  \n* **Instantiates pillars:** P‑1, P‑2, P‑5\n",
        "e.5.2:end": "### E.5.2:End\n"
      },
      "content": "### E.5.2:End\n",
      "metadata": {},
      "part": "E",
      "cluster": null
    },
    {
      "id": "E.5.3",
      "title": "Unidirectional Dependency",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## E.5.3 - Unidirectional Dependency\n",
        "problem": "### E.5.3:2 - Problem\n*Architectural gravity*: a tutorial or helper script adds a new feature,\nCore patterns import it “temporarily,” and within months the supposedly\ntimeless layer depends on transient assets—breaking Pillar **P‑5\nPlug‑in Layering**.\n",
        "forces": "### E.5.3:3 - Forces\n\n| Force | Tension |\n|-------|---------|\n| **Agility vs Stability** | Tooling must iterate quickly ↔ Core must remain slow and deliberate. |\n| **Reuse vs Isolation** | Authors want to reuse helper concepts ↔ Core cannot depend on volatile code. |\n| **Simplicity** | Rule must be testable and unambiguous ↔ must allow legitimate upward imports. |\n",
        "solution": "### E.5.3:4 - Solution — One‑Way, Acyclic Imports\nDefine a strict **partial order** over artefact families **and guard meaning flow** (see **E.10 V‑1**): imports point only **upward** in stability, and **no Core semantics** may derive from Tooling/Pedagogy. No linters or machine checking in Conceptual Core.\n\nPedagogical Companion  ⟶  Tooling Reference  ⟶  Conceptual Core\n\n1. **Allowed edges**  \n   Dependencies **MAY** point **only upward** (toward greater semantic\n   stability). No cycle is ever permitted.\n\n2. **No downward import**  \n   Core artefacts **SHALL NOT** import Tooling or Pedagogy artefacts.\n   Tooling artefacts **SHALL NOT** import Pedagogy artefacts.\n\n3. **Future layers**  \n   Any new family is inserted below an existing one or becomes part of\n   the Tooling or Pedagogy strata; the ordering extends accordingly.\n",
        "archetypal_grounding": "### E.5.3:5 - Archetypal Grounding (System / Episteme)\n\n| Layer | `U.System` illustration | `U.Episteme` illustration |\n|-------|------------------------|---------------------------|\n| Core | Definition of `U.System` and boundary invariant. | Definition of F‑G‑R characteristics. |\n| Tooling | “Reference system‑profile” that checks boundary flow; *imports* Core invariants. | “Episteme‑scoring routine” that calculates R‑score; *imports* Core characteristics. |\n| Pedagogy | Tutorial using the system‑profile to model a pump; *imports* profile and Core term. | Case study explaining R‑score evolution; *imports* scoring routine and Core term. |\n| **Forbidden** | Core pattern importing measurement script. | Core pattern importing R‑score web dashboard. |\n",
        "conformance_checklist": "### E.5.3:6 - Conformance Checklist\n\n| ID | Requirement |\n|----|-------------|\n| **CC‑UD.1** | Dependency graph among all artefacts **MUST** be acyclic. |\n| **CC‑UD.2** | An artefact **SHALL** import only from its own family or any family above it in the order. |\n| **CC‑UD.3** | A DRR that introduces a downward edge **SHALL** be automatically rejected. |\n",
        "consequences": "### E.5.3:7 - Consequences\n\n| Benefits | Trade‑offs / Mitigations |\n|----------|-------------------------|\n| Core stays free of tool churn and tutorial bias. | Authors must create abstraction layers in Tooling instead of inserting hooks into Core. |\n| Release cadence decoupled: Core (slow), Tooling (medium), Pedagogy (fast). | Slight duplication when multiple tools target same concept; mitigated by shared Core definitions. |\n",
        "rationale": "### E.5.3:8 - Rationale\nOne‑way import graphs are a proven safeguard in operating systems\n(kernel vs user land) and layered protocols. Here the rule operationalises\nPillars **P‑4 Open‑Ended Kernel** and **P‑5 Plug‑in Layering**, ensuring\nthat innovation happens “below” without contaminating the timeless Core.\n",
        "relations": "### E.5.3:9 - Relations\n* **Parent umbrella:** `pat:constitution/guard‑rails` (E.5)  \n* **References layer definition:** `pat:constitution/artefact‑architecture` (E.4)  \n* **Instantiates pillars:** P‑4, P‑5  \n* **Constrains:** All artefact imports recorded in DRRs or SCRs\n",
        "e.5.3:end": "### E.5.3:End\n"
      },
      "content": "### E.5.3:End\n",
      "metadata": {},
      "part": "E",
      "cluster": null
    },
    {
      "id": "E.5.4",
      "title": "Cross‑Disciplinary Bias Audit",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## E.5.4 - Cross‑Disciplinary Bias Audit\n",
        "problem": "### E.5.4:2 - Problem\nUnrecognised bias hides in wording, examples, unit choices or principle\nweighting. Once embedded in normative language, such bias is hard to\nremove and contradicts Pillars **P‑2 Didactic Primacy** and **P‑8\nCross‑Scale Consistency**.\n",
        "forces": "### E.5.4:3 - Forces\n\n| Force | Tension |\n|-------|---------|\n| **Neutrality** | One voice for all disciplines ↔ need for relatable examples. |\n| **Conciseness** | Audit guidance must be brief ↔ must cover multiple bias types. |\n| **Longevity** | Guidance must survive emergence of new domains. |\n",
        "solution": "### E.5.4:4 - Solution — Principle‑Taxonomy‑Guided Bias Audit\n\n1. **Bias‑Lens set**  \n   Every normative pattern is assessed through **five lenses** that match the\n   Principle classes from **E.3**:  \n   `Gov`, `Arch`, `Onto/Epist`, `Prag`, `Did`.\n\n2. **Equilibrium question**  \n   For each lens ask:  \n   *“Does the pattern over‑privilege this class or silence it?”*  \n   *Examples:*  \n   *   Over‑reliance on `Onto/Epist` precision may ignore `Prag` cost.  \n   *   Dominant `Arch` metaphors may alienate `Did` audiences.\n\n3. **Scope‑or‑Balance rule**  \n   * If imbalance is found and universality is intended, re‑phrase to\n     restore balance.  \n   * If imbalance is intentional (domain‑specific pattern), mark the\n     scope explicitly: *“Applies primarily to thermodynamic systems.”*\n\n4. **Audit trace**  \n   The pattern carries a short **Bias‑Annotation** paragraph recording\n   which lenses were tested and any scoping statement. No workflow checklists or\n   reviewer metadata or other data and data format and data governance tips is stored in the Core.\n",
        "archetypal_grounding": "### E.5.4:5 - Archetypal Grounding (System / Episteme)\n\n| Bias lens | Example imbalance | Conceptual correction |\n|-----------|------------------|-----------------------|\n| `Arch` vs `Did` | Pump pattern uses abstract category theory terms. | Add plain‑language boundary narrative or move abstraction to appendix. |\n| `Onto/Epist` vs `Prag` | Episteme trust score defined with complex logic but no guidance on empirical cost. | Add pragmatic note on evidence collection burden or scope the pattern. |\n",
        "conformance_checklist": "### E.5.4:6 - Conformance Checklist\n\n| ID | Requirement | Purpose |\n|----|-------------|---------|\n| **CC‑BA.1** | Each Core pattern **SHALL** include a *Bias‑Annotation* listing the five lenses and any declared scope limitation. | Ensures explicit reflection on bias. |\n| **CC‑BA.2** | A pattern labelled “universal” **MUST NOT** privilege a single lens without justification or scoping note. | Preserves trans‑disciplinary integrity. |\n| **CC‑BA.3** | If scope is declared, the pattern **SHALL** reference the mapping or rationale that enables cross‑domain translation. | Keeps pathways open for other calculi. |\n| **CC‑BA.4 (QD‑triad evidence for “universal”).** | Any pattern that labels itself **“universal”** SHALL cite **A.8 CC‑UC 1 + CC‑UC 2** and attach the **QD evidence** (Diversity_P + IlluminationSummary, with edition and binning) or else **scope** the claim to its home Context. | preserves domain quality diversity |\n",
        "consequences": "### E.5.4:7 - Consequences\n\n| Benefits | Trade‑offs / Mitigations |\n|----------|-------------------------|\n| Neutral, inclusive language attracts wider adoption. | Authors spend a few extra lines on Bias‑Annotation; mitigated by template snippet. |\n| Bias is surfaced at writing time, not after publication. | — |\n",
        "rationale": "### E.5.4:8 - Rationale\nCoupling the audit directly to the Principle Taxonomy keeps the guard‑rail\n**concept‑driven**, not workflow‑driven. No mention of review boards,\nCI‑jobs, or checklists appears in the Core; such mechanics belong in the\nTooling Guide. This guard‑rail therefore satisfies **GR‑1** (Firewall)\nwhile securing Pillars **P‑2, P‑7 Pragmatic Utility, P‑8**.\n",
        "relations": "### E.5.4:9 - Relations\n* **Parent umbrella:** `pat:constitution/guard‑rails` (E.5)  \n* **Depends on:** `pat:constitution/principle‑taxonomy` (E.3)  \n* **Constrains:** All normative patterns claiming universality\n",
        "e.5.4:end": "### E.5.4:End\n\n"
      },
      "content": "### E.5.4:End\n\n",
      "metadata": {},
      "part": "E",
      "cluster": null
    },
    {
      "id": "E.6",
      "title": "Didactic Architecture of the Specification",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## E.6 - Didactic Architecture of the Specification\n",
        "problem": "### E.6:2 - Problem\nIf core ideas are buried under formalism or scattered across parts,\nreaders either give up or misuse the framework. We need a **fixed\nnarrative scaffold** that guides cognitive load from low to high while\nkeeping normative sections discoverable.\n",
        "forces": "### E.6:3 - Forces\n\n| Force | Tension |\n|-------|---------|\n| **Cognitive Load** | Early clarity ↔ eventual formal depth. |\n| **Conceptual Integrity** | Foregoing examples risks abstraction ↔ too many examples delay axioms. |\n| **Uniform Flow** | Single, predictable roadmap ↔ flexibility for future parts. |\n",
        "solution": "### E.6:4 - Solution — “On‑Ramp to Archetypes first, Authoring last” sequence\n\nThe \"On-Ramp First\" Macro-Structure: The specification is ordered to create a smooth cognitive ramp:\n* It begins with an informal, non-normative Preface (The On-Ramp), which uses storytelling and concrete examples (System and Episteme) to build intuition.\n* It then proceeds through the normative Parts (A-D), moving from the foundational kernel to the rich patterns of trans-disciplinary reasoning.\n* It concludes with the authoring rules (Part E) and appendices, ensuring that this \"meta\" content does not obstruct the primary learning path.\n\n1. **Preface (On‑Ramp)**  \n   Informal tour; introduces `U.System` and `U.Episteme` via concrete\n   stories before any normative language appears.\n\n2. **Part A Kernel**  \n   Minimal holonic ontology and the Transformer principle give readers\n   the essential vocabulary.\n\n3. **Part B Trans‑disciplinary Reasoning**  \n   Tell‑Show‑Show pedagogy: universal rule → Sys‑CAL example →\n   KD‑CAL example.\n\n4. **Part C Architheories**  \n   Domain‑specific calculi expand on the examples already seen.\n\n5. **Part D Ethics & Conflict Optimisation**  \n   Shows reflective patterns only after readers grasp holonic reasoning.\n\n6. **Part E Authoring**  \n   Constitution, guard‑rails, and contributor rules come last; novices\n   can postpone reading.\n\n7. **Appendices (Annexes)**  \n   Tutorials, tooling guides, and migration scripts live here.\n",
        "archetypal_grounding": "### E.6:5 - Archetypal Grounding (System / Episteme)\n\n| Narrative layer | First sight of `U.System` | First sight of `U.Episteme` |\n|-----------------|---------------------------|-----------------------------|\n| Preface | Coffee‑machine story (pump as system). | Meta‑analysis story (study bundle as episteme). |\n| Part A | Formal definition inherits boundary invariant. | Formal definition inherits F‑G‑R coordinates. |\n| Part B Tell‑Show‑Show | Γ\\_sys example: assemble pump. | Γ_epist example: merge study bundle. |\n",
        "conformance_checklist": "### E.6:6 - Conformance Checklist\n\n| ID | Requirement |\n|----|-------------|\n| **CC‑DA.1** | Each Part **SHALL** open with a one‑paragraph situational “hook” before formal text. |\n| **CC‑DA.2** | Every architectural pattern **MUST** implement Tell‑Show‑Show: universal rule plus System & Episteme illustrations. |\n| **CC‑DA.3** | Governance patterns (**Part E**) **SHALL NOT** appear before the Kernel in the main document flow. |\n",
        "consequences": "### E.6:7 - Consequences\n\n| Benefits | Trade‑offs / Mitigations |\n|----------|-------------------------|\n| Smooth learning curve; readers can stop at their needed depth. | Template discipline required; mitigated by authoring guide (E.8). |\n| Reduces forward‑reference clutter; each concept is primed before formal use. | Preface evolves when new archetypes added; handled via On‑Ramp revision DRR. |\n",
        "rationale": "### E.6:8 - Rationale\nEducational research shows retention improves when abstract rules are\nimmediately paired with contrasting illustrations. By fixing the reading\norder and mandating Tell‑Show‑Show inside every architectural pattern, FPF\nembeds pedagogy into its architecture, realising Pillars **P‑2 Didactic\nPrimacy** and **P‑1 Cognitive Elegance** without weakening rigour.\n",
        "relations": "### E.6:9 - Relations\n* **Depends on:** `pat:constitution/guard‑rails` (GR‑1 ensures example jargon stays outside Core).  \n* **Constrains:** Placement of all Parts, patterns, and appendices.  \n* **Instantiates pillars:** P‑1, P‑2\n  ",
        "e.6:end": "### E.6:End\n"
      },
      "content": "### E.6:End\n",
      "metadata": {},
      "part": "E",
      "cluster": null
    },
    {
      "id": "E.7",
      "title": "Archetypal Grounding Principle",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## E.7 - Archetypal Grounding Principle\n",
        "problem": "### E.7:2 - Problem\nA purely abstract statement risks two failures:\n\n1. **Didactic failure** – readers dismiss the pattern as “too meta,”\n   violating Pillar **P‑2 Didactic Primacy**.  \n2. **Unproven universality** – without cross‑domain instantiation the rule\n   remains an untested claim.\n",
        "forces": "### E.7:3 - Forces\n\n| Force | Tension |\n|-------|---------|\n| **Universality vs Concreteness** | Abstract law ↔ concrete example. |\n| **Brevity vs Clarity** | Spec should stay concise ↔ dual examples add length. |\n| **Rigour vs Accessibility** | Formal semantics ↔ intuitive narrative. |\n",
        "solution": "### E.7:4 - Solution — mandatory *Archetypal Grounding* subsection\n\nEvery architectural pattern **SHALL** include a dedicated\nsection, titled exactly **“Archetypal Grounding,”** that *shows* how the\nabstract law SCRs in FPF’s two canonical holon flavours:\n\n1. **`U.System`** – the archetype of a **physical, operational holon**.  \n2. **`U.Episteme`** – the archetype of an **abstract, epistemic holon**.\n\nThis enforces a repeatable **Tell‑Show‑Show** rhythm:\n\n| Stage | Content |\n|-------|---------|\n| **Tell** | `Solution` section states the universal rule. |\n| **Show #1** | `Archetypal Grounding` – concrete `U.System` example. |\n| **Show #2** | Same section – parallel `U.Episteme` example. |\n",
        "archetypal_grounding": "### E.7:5 - Archetypal Grounding (of this pattern itself)\n\n| Universal rule | `U.System` instantiation | `U.Episteme` instantiation |\n|----------------|--------------------------|----------------------------|\n| “Every architectural pattern requires grounding.” | Pattern *D.1 Algebra of Aggregation* illustrates Γ\\_sys on assembling a water pump. | The same pattern illustrates Γ_epist on merging a meta‑analysis. |\n",
        "conformance_checklist": "### E.7:6 - Conformance Checklist\n\n| ID | Requirement | Purpose |\n|----|-------------|---------|\n| **CC‑AG.1** | Every architectural pattern in Parts A, B, C, D, E **SHALL** contain a subsection headed exactly *“Archetypal Grounding”*. | Guarantees consistent Tell‑Show‑Show rhythm. |\n| **CC‑AG.2** | The Archetypal Grounding subsection **MUST** illustrate the rule with both `U.System` *and* `U.Episteme`. | Demonstrates trans‑disciplinary reach. |\n| **CC‑AG.3** | If a rule intentionally applies to only one substrate, the subsection **SHALL** state the scope limitation and justify it against the five Principle‑Taxonomy lenses (`Gov`, `Arch`, `Onto/Epist`, `Prag`, `Did`). | Prevents silent bias; links to Bias‑Audit guard‑rail. |\n| **CC‑AG.4** | Patterns lacking a compliant Archetypal Grounding subsection **MAY NOT** progress to “Accepted” status. | Enforces discipline without referring to workflow mechanics. |\n",
        "consequences": "### E.7:7 - Consequences\n\n| Benefits | Trade‑offs / Mitigations |\n|----------|-------------------------|\n| **Immediate clarity** – readers see abstract laws in action. | Patterns grow by one short table; mitigated by consistent template snippet. |\n| **Proof of universality** – every rule is self‑documenting across substrates. | Authors must think cross‑domain; fosters richer patterns. |\n| **Narrative cohesion** – recurring System/Episteme protagonists create a memorable storyline. | — |\n|Built-in Proof of Universality: The specification consistently demonstrates its trans-disciplinary claims, building trust and credibility. | — |\n",
        "rationale": "### E.7:8 - Rationale\nTell‑Show‑Show is a proven pedagogical sequence. By making it normative,\nFPF hard‑codes **P‑2 Didactic Primacy** into the fabric of every architectural\npattern while still honouring **P‑1 Cognitive Elegance**—the grounding\nsection replaces brittle ad‑hoc anecdotes with a disciplined dual\nexample. Linking scope‑justification to the five Principle lenses ties the\npattern to the **Taxonomy‑Guided Bias Audit** and keeps governance\nlanguage out of the Core.\n",
        "relations": "### E.7:9 - Relations\n\n* **Implements macro flow:** `pat:authoring/didactic‑architecture` (E.6)  \n* **References base types:** `pat:kernel/holon` (A.1) (`U.System`, `U.Episteme`)  \n* **Interacts with bias guard‑rail:** `pat:guard/bias‑audit` (E.5.4) via CC‑AG.3  \n* **Constrains:** Authoring template in `pat:authoring/pattern‑template` (E.8)\n",
        "e.7:end": "### E.7:End\n"
      },
      "content": "### E.7:End\n",
      "metadata": {},
      "part": "E",
      "cluster": null
    },
    {
      "id": "E.8",
      "title": "FPF Authoring Conventions & Style Guide",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## E.8 - FPF Authoring Conventions & Style Guide\n\n> **Type:** Architectural (A)  \n> **Status:** Stable  \n> **Normativity:** Normative (unless explicitly marked informative)\n",
        "problem": "### E.8:2 - Problem\n*Structural drift* and *stylistic fragmentation* threaten three qualities:\n\n1. **Comparability** – readers cannot align patterns lacking common\n   headings.  \n2. **Narrative cohesion** – prose swings from dry jargon to informal\n   blog style.  \n3. **Auditability** – missing sections hide safety checks\n   (Archetypal Grounding, Bias‑Annotation).\n",
        "forces": "### E.8:3 - Forces\n\n| Force | Tension |\n|-------|---------|\n| **Uniformity vs Expressiveness** | Consistent template ↔ freedom for diverse domains. |\n| **Rigor vs Readability** | Formal precision ↔ engaging prose. |\n| **Brevity vs Completeness** | Concise patterns ↔ mandated safety subsections. |\n",
        "solution": "### E.8:4 - Solution — One template, enriched by style principles\n\n#### E.8:4.1 - Canonical Pattern Template\nWithin each pattern, the **canonical** section headings **SHALL** appear in the order below.\nFor each **canonical content section heading (1–12)**, the `<Title>` component (after the heading separator, e.g. ` - `) **MUST** start with the canonical section title (case-insensitive match; canonical capitalisation preferred); an optional clarifier after an em dash is allowed (e.g., `Solution — …`).\nThe **Footer marker** (section **13**, if present) is a sentinel and is governed by **H‑9** rather than the standard `<FullId> - <Title>` shape.\n\n**Extensibility.**\nAuthors **MAY** add additional sections. Prefer expressing them as subsections under the nearest canonical section (e.g., `4.1`, `4.1.1` under *Solution*). If an additional top-level section is necessary, it **MUST NOT** delete or reorder the canonical sections and its title **MUST NOT** shadow a canonical title.\n\n**Mandatory vs optional.**\n* Canonical sections **1–13** are mandatory in every pattern.\n* The escape hatch `Not applicable` is permitted **only** where explicitly stated below; when used, it **MUST** include a short justification (1 paragraph).\n\n**Template:**\n- **Title line:** Hashes + FullId + ` - ` + Pattern Title; optional `(informative)` note.\n- **Header block:** Type, Status; optional Normativity override.\n1. **Problem frame**\n2. **Problem**\n3. **Forces**\n4. **Solution**\n5. **Archetypal Grounding** (Tell–Show–Show; System / Episteme; `Not applicable` allowed only with justification)\n6. **Bias‑Annotation**\n7. **Conformance Checklist**\n8. **Common Anti‑Patterns and How to Avoid Them** (`Not applicable` allowed only with justification)\n9. **Consequences**\n10. **Rationale**\n11. **SoTA‑Echoing** (post‑2015 practice alignment; terminology drift & deltas; `Not applicable` allowed only with justification)\n12. **Relations**\n13. **Footer marker** \n\n**Footer marker.** End each pattern with a single visible sentinel heading line on its own: `### <PatternId>:End`. This makes truncation detectable even when HTML comments are stripped or surfaced by editors. The footer marker is intentionally content‑free: **do not** place prose under it.\n\n*Note.* Pattern boundaries are still parseable by scanning for the next pattern heading (`## …`), but an explicit `:End` marker helps retrieval pipelines (and LLM prompts) distinguish “this chunk is the whole pattern” from “this chunk was cut mid‑pattern”.\n\n##### E.8:4.1.1 - Heading & ID discipline (human tooling + retrieval)\nFPF is often consumed through full‑text search and retrieval (RAG). A reader or an LLM may see a subsection without its parent headings, so headings must be **self‑identifying**.\n\n**H‑1 (Heading shape).** Every pattern heading and every subsection heading inside a pattern **SHALL** follow:\n`<hashes> <FullId> - <Title> (optional note of non‑normativity)`\n\n*Exception.* The **Footer marker** is a sentinel heading and is governed by **H‑9**, not by the standard `<FullId> - <Title>` shape.\n\n**H‑2 (Heading separator).** The canonical separator between `<FullId>` and `<Title>` is ` - ` (ASCII, space-hyphen-space).\nLegacy text may use ` - `; tooling **SHOULD** treat the two as equivalent, and authors **SHOULD** migrate to ` - ` when touching a heading.\n\n**H‑3 (FullId).** `FullId` is the full hierarchical address.\nFor a **pattern heading** it is the pattern ID (e.g., `A.2`, `E.10.D1`).\nFor **headings inside a pattern**, append dot‑separated ordinal section numbers after the colon (`:`) (e.g., `A.2:4.4`, `E.10.D2:3`).\n*Exception:* the Footer marker uses the reserved sentinel token `:End` as defined in **H‑9**.\nThe colon (`:`) is **reserved** for section paths and **MUST NOT** appear in pattern IDs.\n\n**H‑4 (Ordinals).** Ordinals in section paths **SHOULD** track the canonical template numbering (**1 = Problem frame**, …, **13 = Footer marker**) to maximise cross‑pattern comparability. During refactors or in legacy patterns, ordinals **MAY** be local. In that case, the **canonical section title at the start of `<Title>`** is the semantic key; readers and tools **MUST NOT** infer section semantics from the ordinal alone.\n*Note:* the Footer marker itself is exempt from ordinal encoding; it uses the reserved token `:End` (see **H‑9**).\n\n**H‑5 (Where kind and normativity live).** Pattern **kind** (e.g., Architectural / Definitional) **MUST** be declared in the **Header block**, not encoded into the heading text. Normativity (**normative** / **informative**) **MUST** also live in the Header block when it deviates from the default. If a reminder is needed for readers, authors **MAY** add a short parenthetical note at the end of the heading (e.g., `(informative)` / `(non‑normative)`), but headings **MUST NOT** use square‑bracket tags.\n\n**H‑6 (Heading levels).** Heading levels **MUST** preserve a fixed offset between structural layers (Part or Cluster (flat) → Pattern → Pattern sections):\n* Part and Cluster headings **MUST** use `#` (level 1) across the file.\n* A Pattern heading **MUST** use `##` (level 2).\n* Inside a pattern, each nested section **MUST** add exactly one `#` per level (e.g., `## A.2 - …`, `### A.2:2 - …`, `#### A.2:2.1 - …`).\n\n**H‑7 (Ellipsis discipline).** Authors **MUST NOT** use **three consecutive full stops/dots** (`...`) as punctuation in headings or narrative prose. Authors **MUST** use the Unicode ellipsis `…` (U+2026) instead. For editorial elisions in quotations, authors **SHOULD** prefer `[…]` to make the omission explicit and distinguish it from retrieval truncation.\n*Exception:* literal three‑dot sequences that are part of an external language’s syntax **MAY** appear **only inside code spans or fenced code blocks**.\n\n**H‑8 (Normative keywords).** The key words **MUST**, **MUST NOT**, **REQUIRED**, **SHALL**, **SHALL NOT**, **SHOULD**, **SHOULD NOT**, **RECOMMENDED**, **MAY**, and **OPTIONAL** are to be interpreted as described in RFC 2119, as clarified by RFC 8174 (only when capitalised). Authors **SHOULD** avoid informal deontic phrasing (“need to”, “is required to”) in normative clauses.\n\n**Deontics vs admissibility.** Use RFC keywords only for **deontic obligations** (requirements on authors, reviewers, implementers/tooling, or published artefacts) — i.e., things an agent can choose to do or omit. Do **not** use RFC keywords to state **definitions**, **structural invariants**, **typing rules**, or other **admissibility conditions** of the modeled world.\n\nWhen you need an enforceable constraint that is *mathematical* rather than *deontic*, express it as a non‑deontic predicate using one of: `Definition:`, `Invariant:`, or `Well‑formedness constraint:` (optionally with formal quantifiers). Prefer mathematical terms like `cardinality 1..1 (total)` / `0..1 (partial)` / `0..n` over deontic adjectives like “mandatory/optional” when the intent is cardinality, not duty.\n\n**Admissibility predicate discipline (recommended shape).**\nWhen expressing admissibility/validity constraints as predicates (`Definition:` / `Invariant:` / `Well‑formedness constraint:`):\n* Authors **MUST NOT** use RFC keywords inside the predicate block.\n* Authors **SHOULD** give each predicate a stable identifier and short name (e.g., `RA‑1 (Locality)`, `RE‑3 (Method gate)`), so that Conformance Checklist items can reference it without re‑authoring the rule.\n* Authors **SHOULD** write the constraint as a declarative predicate (optionally quantified), e.g., `role ∈ Roles(context)`, rather than as “X MUST …”.\n* If the constraint needs to be enforceable as part of a pattern’s contract, authors **SHOULD** reference the predicate identifier from the Conformance Checklist (and/or call out validator behaviour), rather than duplicating the predicate with RFC keywords.\n\n**H‑9 (Footer marker sentinel).** Footer marker **SHALL** be a single heading line whose `FullId` is the pattern ID followed by the reserved sentinel token `:End` (no ordinals, no title, no square‑bracket tags): \n`### <PatternId>:End`\nIt is the only allowed heading *inside* a pattern whose section token is non‑numeric. It **MUST** be the final line of the pattern and **MUST NOT** carry any prose. Tooling and readers **MUST** treat it as a boundary sentinel, not as a semantic section.\n\n*Unification note:* historic A‑ and D‑templates differed only by the presence/absence of **Bias‑Annotation** and **Relations**; the unified template keeps the headings everywhere while allowing explicit `Not applicable` statements when justified.\nThe Alexandrian pattern canon historically calls *Problem frame* “Context”. FPF avoids that label because **Context** is already overloaded in FPF (e.g., `U.BoundedContext` and its Plain‑register label).\n\n#### E.8:4.2 - Stylistic Principles (S‑0 … S‑13)\n\n| # | Principle | Guideline |\n|---|-----------|-----------|\n| S‑0 | Narrative Flow Seven‑Step Heuristic | Authors are encouraged to structure major paragraphs or subsections using the seven‑step mnemonic. |\n| S‑1 | Density without Jargon | Short declarative sentences; tool names belong in Pedagogy/Tooling. |\n| S‑2 | Internal Cohesion | Inline references to Pillars and related patterns. |\n| S‑3 | Embedded Mini‑Definitions | Gloss a new term in parentheses on first appearance. |\n| S‑4 | Contextualisation | Brief historical or disciplinary lineage anchors. |\n| S‑5 | Prophylactic Clarification | Pre‑empt common misreadings inside the prose. |\n| S‑6 | Quotable Closers | Finish Solution or Consequences with a memorable aphorism. |\n| S‑7 | Generative over Prescriptive | Present rules as enabling constraints, not bureaucracy. |\n| S‑8 | Trans‑disciplinary Tie‑ins | Illustrate using at least two distinct fields. |\n| S‑9 | Physical Grounding Reference | Link abstractions to a `Transformer` or physical process. |\n| S‑10 | Punchy Blocks | ≤ 5 sentences per paragraph; lists for clarity. |\n| S‑11 | Narrative Flow | Ensure sections read as a continuous story, not bullet soup. |\n| S‑12 | Full sentences over tags | Avoid “keyword soup”. Each list item SHOULD contain a subject and a verb; prefer 2–4 sentence micro‑paragraphs to bare tag lists. |\n| S‑13 | SoTA‑Echo craft | In the SoTA‑Echoing section, present: **claim → practice → source → alignment → adoption status (adopt/adapt/reject)**; cite Bridges & CL when crossing Contexts/planes. |\n\nAuthors use the principles as a *scaffold*, not a straitjacket: the goal\nis coherent, engaging insight.\n\n**S‑0 (Narrative Flow Seven‑Step Heuristic) — explanation**\nNarrative flow is recommended to follow these steps: **Hook → Frame → Weave → Anchor → Bridge → Flow → Close**.\n\nBrief explanations: \n| Step       | Purpose in a paragraph/section                             |\n| ---------- | ---------------------------------------------------------- |\n| **Hook**   | Grab attention with a vivid image or paradox.              |\n| **Frame**  | State the specific question or problem space.              |\n| **Weave**  | Connect to earlier patterns or Pillars.                    |\n| **Anchor** | Tie to a concrete System/Episteme or physical process.     |\n| **Bridge** | Show the implication for the upcoming claim or rule.       |\n| **Flow**   | Deliver the formal content or argument.                    |\n| **Close**  | End with a quotable line or payoff that reinforces memory. |\n\nNarrative Flow Heuristic also operationalises S‑1 (Density w/o Jargon), S‑2 (Internal Cohesion), S‑4 (Contextualisation), and S‑6 (Quotable Closers).\n\n#### E.8:4.3 - Autonomy authoring stub (mandatory when autonomy is claimed)\nIf a pattern or example claims **autonomy** for any Role/Method/Service:\n1) Add a subsection **“Autonomy (RoC‑E.16)”** that lists:\n   * `AutonomyBudgetDeclRef` (id, version, Scope (G), Γ_time),\n   * `Aut-Guard policy-id (PolicyIdRef)`,\n   * `OverrideProtocolRef` (SpeechAct names, SoD),\n   * pointer to where **Green‑Gate** applies in the Method steps,\n   * where **AutonomyLedgerEntry** is recorded on `U.Work`.\n2) Include one **Tell‑Show‑Show** vignette that demonstrates **depletion** and **override** handling.\n3) Use **LEX‑BUNDLE** terms (Scope (G), Γ_time, Role/Method/Work). Avoid “validity”, “process”, “actor”, “system”, “mechanism” unless mapped to kernel types.\n",
        "archetypal_grounding": "### E.8:5 - Archetypal Grounding (System / Episteme)\n\n| Template element | `U.System` illustration | `U.Episteme` illustration |\n|------------------|------------------------|---------------------------|\n| Section order | Pump‑assembly pattern follows sections **1–12** (and, optionally, **13**). | Meta‑analysis pattern follows the same sections. |\n| S‑1 Density w/o Jargon | “The pump boundary is the sealing plane.” | “This episteme raises **F (Formality)** by making falsifiers testable.” |\n| Hook‑Weave‑Anchor | Opens with field anecdote → weaves in Γ‑core → anchors to motor torque. | Opens with historical paradox → weaves in **A.10** anchors → anchors to peer‑review data. |\n\n*Note:* Prefer examples that reuse FPF’s own characteristics vocabulary (e.g., **F (Formality)** rather than “F‑score”) unless you explicitly mean an external metric and name it as such.\n",
        "bias‑annotation": "### E.8:6 - Bias‑Annotation\nLenses tested: **Gov**, **Arch**, **Onto/Epist**, **Prag**, **Did**. Scope: **Universal** for the authoring conventions in this pattern.\nThis guidance biases toward **Did** (readability, narrative flow) and **Arch** (template regularity) by design; the mitigation is explicit optionality (`Not applicable`) and the requirement to justify omissions in‑text.\n",
        "conformance_checklist": "### E.8:7 - Conformance Checklist\n\n**CC style (canonical).**\nConformance Checklist items are obligations/conditions in the **authoring plane**: they constrain artefacts that claim conformance (and the reviewers/validators that accept them). A CC clause of the form “X SHALL …” is to be read as “In a conforming artefact, X SHALL …”, not as a deontic statement about the modeled world.\n\n**Preferred wording for new or edited CC items:** start with an explicit conformance subject (e.g., “Authors …”, “Reviewers …”, “A conforming implementation …”, “A validator …”). If a CC item is enforcing an admissibility predicate, it **SHOULD** cite the predicate’s identifier (from a `Definition:` / `Invariant:` / `Well‑formedness constraint:` block) rather than restating the predicate as “X MUST …”. For boundary/interface/protocol/contract patterns, prefer A.6.B‑routed claim IDs (L/A/D/E) or cite an existing Claim Register (A.6.B:7) instead of restating mixed prose.\n\n| ID | Requirement | Purpose |\n|----|-------------|---------|\n| **CC‑SG.0 (Heading discipline).** | Pattern and subsection headings **SHALL** follow **H‑1 … H‑9** (FullId prefix, reserved punctuation, heading levels, ellipsis discipline). The Footer marker **SHALL** follow **H‑9**. | Makes chunks self‑contained; reduces ambiguity between author elision and retrieval truncation. |\n| **CC‑SG.1** | Every new pattern **SHALL** follow the section order defined in the Canonical Template (Title block → … → Footer marker). | Guarantees structural comparability. |\n| **CC‑SG.2 (Grounding required).** | Every pattern **MUST** include an *Archetypal Grounding* section. If **System** or **Episteme** grounding is inapplicable, authors **MUST** state `Not applicable` and give a one‑paragraph justification. | Keeps patterns teachable and reduces “definition‑only” ambiguity. |\n| **CC‑SG.3** | The *Bias‑Annotation* section **SHALL** cite the five Principle‑Taxonomy lenses and declare either “Universal” or an explicit scope limitation. | Keeps cross‑disciplinary neutrality explicit (ties to Guard‑Rail 4). |\n| **CC‑SG.4** | Deontic normative sentences **MUST** use only RFC‑style keywords (see **H‑8**); RFC keywords **MUST NOT** appear inside `Definition:`/`Invariant:`/`Well‑formedness constraint:` blocks. When enforceable, admissibility/validity predicates **SHOULD** be referenced by id from the Conformance Checklist (rather than duplicated as “X MUST …”). Informal deontic verbs are prohibited in normative clauses. | Prevents ambiguity between obligation language and model validity; improves auditability. |\n| **CC‑SG.5** | Pattern prose **SHOULD** demonstrate adherence to Style Principles **S‑0 … S‑13**; reviewers are empowered to request revision when clarity or didactic quality suffers. | Embeds common narrative voice without rigid policing. |\n| **CC‑SG.6 (SoTA‑Echo required).** | Every pattern **SHALL** include a **SoTA‑Echoing** section and clearly state divergence of its Solution from SoTA with explanation of why. Architectural patterns **SHALL** satisfy the full obligations below; Definitional patterns **MAY** satisfy the reduced obligations (terminology drift + ≥ 1 post‑2015 primary source) when a full SoTA comparison is not meaningful. | Ensures explicit lineage and guards against vocabulary drift. |\n| **CC‑SG.7 (Post‑2015, multi‑Tradition).** | For Architectural patterns, SoTA‑Echoing **SHALL** cite ≥ 3 post‑2015 sources across ≥ 2 Traditions; each item **MUST** carry adoption status (adopt/adapt/reject) with reason. | Guards against monoculture; makes intent explicit. |\n| **CC‑SG.8 (Bridge & CL on reuse).** | Any cross‑Context or plane reuse mentioned in SoTA‑Echoing **MUST** cite **Bridge id + CL** and (if planes differ) **Φ(CL)**/**Φ_plane** policy‑ids; penalties **→ R_eff** only. | Safe, auditable reuse. |\n| **CC‑SG.9 (Lexical hygiene).** | The term **mapping** **SHALL NOT** appear in SoTA‑Echoing except in the precise E.10 sense; use **alignment/Bridge/relation** instead. | Avoids overloading reserved vocabulary. |\n| **CC‑SG.10 (No keyword soup).** | SoTA‑Echoing items **MUST** be written as sentences (not bare noun phrases); bullet lists are acceptable only with complete clauses. | Improves didactic quality and comparability. |\n| **CC‑SG.11 (Anti‑patterns).** | Every pattern **SHALL** include a **Common Anti‑Patterns and How to Avoid Them** section. It **MAY** be `Not applicable` only with a one‑paragraph justification. | Makes misuse paths explicit and reduces review churn. |\n| **CC‑SG.12 (Boundary routing).** | If a pattern’s subject is a boundary/interface/protocol/contract (API boundary, protocol, connector, “contract” description, or a published boundary surface), it **MUST** either (a) provide an **A.6.B**‑routed atomic claim set (`L-*`/`A-*`/`D-*`/`E-*`, with stable IDs), or (b) explicitly cite an existing **A.6.B Claim Register** / routed claim set that it reuses. | Pulls A.6.B into the authoring contour; prevents “contract soup” and makes review lintable. |\n",
        "common_anti‑patterns_and_how_to_avoid_them": "### E.8:8 - Common Anti‑Patterns and How to Avoid Them\n\nThese failure modes recur in drafts and in downstream application. They are predictable ways the Forces in this pattern get violated.\n\n| Anti‑pattern | Symptom | Why it fails (force violated) | How to avoid / repair |\n|-------------|---------|------------------------------|-----------------------|\n| **Template cargo‑culting** | Headings exist, but each section is a thin bullet list with no narrative. | Satisfies Uniformity but loses Readability and Didactic Primacy. | Use S‑0 narrative flow per section; write 2–4 sentence micro‑paragraphs before any list/table. |\n| **Un‑grounded abstractions** | Problem/Solution stay abstract; no concrete System/Episteme Tell–Show–Show. | Breaks teachability and makes misuse likely. | Fill Archetypal Grounding first; then back‑propagate concrete nouns into Problem/Forces/Solution. |\n| **SoTA name‑dropping** | SoTA‑Echoing is a list of nouns/buzzwords with no adopt/adapt/reject rationale. | Violates CC‑SG.7 and CC‑SG.10; readers cannot audit alignment. | For each source, state what is adopted/adapted/rejected and why (complete clauses, 2–4 sentences). |\n| **Tool‑bound normativity** | A vendor tool, file format, or schema is described as required to apply the pattern. Data governance implied. | Violates Guard‑Rails (lexical firewall; notation independence, data governance absence); reduces portability and conceptual clarity. | Keep normative content conceptual; move tooling and data governance into Context‑local Profiles. |\n| **Hidden trade‑offs** | Solution sounds universally good; Consequences lists only benefits. | Removes decision‑support value; applicability cannot be judged. | In Consequences, include at least one trade‑off and a mitigation; if none exists, explain why. |\n",
        "consequences": "### E.8:9 - Consequences\n\n| Benefits | Trade‑offs / Mitigations |\n|----------|-------------------------|\n| **Predictable skeleton** – readers instantly know where to find context, forces, and criteria. | Limits author freedom in macro layout; mitigated by flexibility inside the Solution subsection. |\n| **Cohesive voice** – S‑principles give FPF a recognisable style, aiding memorability. | Reviewers must read for style, not only semantics; checklists ease load. |\n| **Embedded pedagogy** – Tell‑Show‑Show and Hook → Close heuristics turn the spec into a self‑teaching text. | Slightly longer patterns; justified by better comprehension and fewer clarifying DRRs. |\n",
        "rationale": "### E.8:10 - Rationale\nStructure and style function as FPF’s *grammar*. By unifying what were\nonce separate “template” and “style guide” patterns, authors face a\nsingle reference point that satisfies:\n\n* **P‑1 Cognitive Elegance** – uniform, minimal surprises.  \n* **P‑2 Didactic Primacy** – narrative flow, dual archetype examples.  \n* Guard‑Rails 1 & 2 – no tool jargon, no notation lock‑in inside prose.\n\nA unified template also improves retrieval: a chunk containing `A.2:<n> - Bias‑Annotation` remains self‑identifying even when parent headings are missing, and the recommended footer marker makes truncation detectable.\n\nInternational and industry standards often speak in terms of *conformance criteria*. FPF uses the label **Conformance Checklist** to make adoption easier for engineers and managers.\n",
        "sota‑echoing__*(normative;_lineage_&_deltas_to_contemporary_state‑of‑the‑art)*": "### E.8:11 - SoTA‑Echoing  *(normative; lineage & deltas to contemporary State‑of‑the‑Art)*\n\n**Purpose.** Make each pattern’s relationship to contemporary practice explicit and comparable without importing tooling or data governance. This section is prose‑first and notation‑independent.\n\n**Minimum contents (obligations).**\n1) **Evidence binding (no duplicate SoTA).** If a **SoTA Synthesis Pack** exists (G.2), this section **SHALL cite** its **ClaimSheet IDs** / **CorpusLedger entries** / **BridgeMatrix rows** as the source‑of‑truth for claims and report `adopt/adapt/reject` **consistent with those IDs**. Avoid forking an untracked SoTA narrative.\n2) **Sources (post‑2015).** For **Architectural patterns**, cite ≥ 3 primary SoTA sources (standards/papers/books), with at least **two independent Traditions**. For **Definitional patterns**, cite ≥ 1 post‑2015 primary source and, where relevant, a short note on terminology drift/deprecations.\n3) **Practice alignment.** For each cited item, state **what is adopted/adapted/rejected** and **why** (2–4 sentences).\n4) **Scale legality.** If numeric operations are implied, bind to ComparatorSet/CG‑Spec and declare partial‑order stance (no hidden scalarisation).\n5) **Cross‑Context reuse.** Any reuse across `U.BoundedContext` must surface Bridge+CL/Φ_plane policy‑ids (penalties affect only `R_eff`).\n6) **Lexical hygiene.** Avoid “mapping” unless you mean an explicit Bridge/translation relation with loss notes.\n\n**Writing guidance (readability).**\n*Write short paragraphs, not tag lists.* For each Tradition, provide (a) a one‑sentence capsule of the practice, (b) a one‑sentence comparison to the pattern’s Solution, (c) a one‑sentence adoption status with reason. Where helpful, add one **System** and one **Episteme** micro‑example (Tell–Show–Show).\n\n**Format: human‑first.** A small table is allowed, but each row **MUST** be accompanied by 1–2 sentences as above. Vendor/tool tokens, file formats, or data schemas are out of scope.\n\n#### E.8:11.1 - SoTA alignment for this pattern (E.8 self‑echo)\n\n| Claim (E.8 need) | SoTA practice (post‑2015) | Primary source (post‑2015) | Alignment with E.8 | Adoption status |\n|---|---|---|---|---|\n| Pattern texts must be teachable, not just “correct”. | Use a stable skeleton (context/problem/forces/solution/actions/consequences) plus illustration and checklists to keep patterns readable and actionable. | Iba (2021), “How to Write Patterns …” (PLoP 2021 PLoPourri). | Canonical Template mirrors the skeleton and adds Archetypal Grounding + Conformance Checklist as first‑class sections. | **Adopt/Adapt.** Adopt the skeleton; adapt by making bias and conformance explicit sections. |\n| Pattern quality needs explicit validation beyond folklore. | Critique of ad‑hoc validation (incl. “rule of three”) and push toward more rigorous discovery/validation methods. | Riehle et al. (2020), “Pattern Discovery and Validation Using Scientific Research Methods”. | E.8 encodes validation as Conformance Checklist + SoTA‑Echoing with adoption status and evidence binding. | **Adopt.** Adopt auditability goals; keep the mechanism lightweight (checklists + evidence binding). |\n| Governance should constrain structure, not mandate tools. | Specify conformance and structure; do not prescribe processes, notations, tools, or recording media. | ISO/IEC/IEEE 42010:2022 (architecture description). | E.8 is template‑ and conformance‑centric, with guard‑rails against tool/notation lock‑in in core narrative. | **Adopt.** Direct alignment. |\n| Pattern languages are networks; visuals often mislead. | Systematic surveys report low consensus on what to visualise and ambiguous/inexpressive visuals; relations need clear definition in text. | Quirino, Barcellos, Falbo (2018), survey of visual notations for software pattern languages (SBES 2018). | E.8 requires a Relations section and keeps diagrams optional, placing primacy on textual structure and explicit links. | **Adapt.** Use the finding as rationale for text‑first, relation‑explicit authoring. |\n",
        "relations": "### E.8:12 - Relations\n\n* **Builds on:** E.6, E.7  \n* **Constrained by:** Guard‑Rails E.5.1–E.5.4 (lexical firewall, notation independence, etc.)  \n* **Constrains:** All patterns; the DRR template references the same section order.  \n",
        "e.8:end": "### E.8:End\n"
      },
      "content": "### E.8:End\n",
      "metadata": {},
      "part": "E",
      "cluster": null
    },
    {
      "id": "E.9",
      "title": "Design‑Rationale Record (DRR) Method",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## E.9 - Design‑Rationale Record (DRR) Method\n",
        "problem": "### E.9:2 - Problem\nDirect edits to the Core, absent a structured rationale, trigger three\nsystemic hazards:\n\n1. **Lost provenance** – future authors cannot infer the reasoning behind\n   a rule; intent decays.  \n2. **Implicit assumptions** – discarded alternatives vanish from memory,\n   so debates resurface and churn repeats.  \n3. **Conceptual drift** – incremental tweaks slip past the Eleven Pillars\n   and Principle Taxonomy lenses, blurring the framework’s foundations.\n",
        "forces": "### E.9:3 - Forces\n\n| Force | Tension |\n|-------|---------|\n| **Agility vs Rigour** | Evolve swiftly ↔ demonstrate deliberate, Pillar‑aligned decisions. |\n| **Transparency vs Efficiency** | Provide a public argument trail ↔ avoid bureaucratic drag on minor edits. |\n| **Clarity vs Conciseness** | Capture full reasoning ↔ prevent meta‑text from bloating the Core itself. |\n",
        "solution": "### E.9:4 - Solution — the DRR as a structured argument\nAny proposal to add, modify or deprecate a `NORM`, `A`, `D`, or `GOV`\nrule **MUST** be accompanied by a **Design‑Rationale Record**. By default,\nit contains exactly four conceptual components (below); a lightweight\neditorial variant is permitted by CC‑DRR.5.\n\n| Component | Guiding question | Typical content |\n|-----------|------------------|-----------------|\n| **Problem frame** | *Why are we talking about this?* | Problem statement, triggering insight, or external change. |\n| **Decision** | *What will we do?* | Precise normative text to enter the specification. |\n| **Rationale** | *Why is this the right thing?* | Comparison of alternatives, Pillar check, taxonomy‑lens balance. |\n| **Consequences** | *What happens next?* | Expected benefits, trade‑offs, impacted patterns, risk notes. |\n\nThe DRR lives **outside** the normative Core. Upon acceptance, its\n*Decision* **SHALL** be applied to the relevant pattern(s) as explicit\nnormative text (the change is \"in the Core\"; the DRR is not).\n\nTo preserve **P‑2 Didactic Primacy** without duplicating meta‑text,\nstable and reusable parts of the DRR’s *Rationale* and *Consequences*\n**SHOULD** be **distilled** into the **informative** sections of the\naffected pattern(s) (Rationale, Consequences, SoTA‑Echoing, Archetypal\nGrounding; per the Pattern Template, E 8). The full DRR remains\nexternal as provenance.\n",
        "archetypal_grounding": "### E.9:5 - Archetypal Grounding (System / Episteme)\n\n| Holon flavour | DRR analogue | Four components illustrated |\n|---------------|--------------|-----------------------------|\n| **`U.System`** (physical) | Engineering Change Order for pump motor upgrade. | Context: inefficiency; Decision: switch to brushless DC; Rationale: energy gain vs cost; Consequences: new control schema + supplier change. |\n| **`U.Episteme`** (knowledge) | Foundational theory revision paper. | Context: conflicting data; Decision: introduce new axiom; Rationale: explains legacy & new data, Pillar alignment; Consequences: fresh predictions, update to curricula. |\n",
        "conformance_checklist": "### E.9:6 - Conformance Checklist\n\n| ID | Requirement | Purpose |\n|----|-------------|---------|\n| **CC‑DRR.1** | Any **semantic** change (Δ‑2/Δ‑3) to a `NORM`, `A`, `D`, or `GOV` pattern **SHALL** be preceded by an accepted DRR containing Problem‑frame (Context), Decision, Rationale, Consequences. | Prevents undocumented semantic edits. |\n| **CC‑DRR.1a** | When the proposed change is expressed as a (new or revised) pattern written in the standard template (E 8), the DRR **MAY** satisfy its four components by **pointing to** the corresponding pattern sections, rather than duplicating prose. | Avoids “double writing” while keeping the argument recoverable. |\n| **CC‑DRR.2** | The *Rationale* element **MUST** assess the proposal against **all Eleven Pillars** and the five Principle‑Taxonomy lenses (`Gov`, `Arch`, `Onto/Epist`, `Prag`, `Did`). | Keeps evolution aligned and cross‑disciplinary. |\n| **CC‑DRR.3** | The DRR **SHALL** list every pattern it supersedes, amends, or risks impacting. | Maintains explicit impact graph. |\n| **CC‑DRR.4** | Once approved, the *Decision* text **SHALL** be inserted into the Core as the normative change. Other DRR sections **MAY** be distilled into **informative** pattern sections (Rationale/Consequences/SoTA‑Echoing/Grounding) but **SHALL NOT** introduce new normative constraints except via explicit `NORM`/`A`/`D`/`GOV` text. | Preserves brevity while keeping the Core teachable. |\n| **CC‑DRR.5** | Minor, non‑substantive edits (Δ‑0/Δ‑1; e.g., typos, wording clarity, didactic rearrangements) **MAY** follow a lightweight DRR variant containing Problem‑frame (Context) + Decision only (“no semantic change”), provided they do not alter semantics. | Avoids bureaucratic drag on editorial work. |\n| **CC‑DRR.6 (LAT pointer)** | For Δ‑2/Δ‑3 changes to part F or part G patterns, the DRR **SHALL** include a non‑normative pointer (id/URI) to a published LEX‑AUTH Trace (LAT) archived as `U.Work`; the LAT is evidence, not normative prose. | Binds high‑impact changes to re‑runnable authoring evidence without importing tooling. |\n",
        "consequences": "### E.9:7 - Consequences\n\n| Benefits | Trade‑offs / Mitigations |\n|----------|-------------------------|\n| **Complete audit trail** – every semantic normative change carries a structured “why”. | Adds deliberate friction; mitigated by CC‑DRR.5 (Δ‑0/Δ‑1 lightweight) and CC‑DRR.1a (pointer‑based DRRs). |\n| **Higher decision quality** – Pillar & lens check surfaces hidden conflicts early. | Authors must learn taxonomy; template checklist shortens ramp‑up. |\n| **Institutional memory** – prevents re‑litigation of rejected alternatives. | DRR archive grows; index stored in a non‑normative annex. |\n",
        "rationale": "### E.9:8 - Rationale\nFPF evolves by **explicit, reviewable deltas** rather than silent edits.\nThe DRR is the *minimal structured argument* that keeps **P‑10\nOpen‑Ended Evolution** compatible with **P‑1 Cognitive Elegance** and\n**P‑2 Didactic Primacy**: the Core stays succinct and teachable, while\nthe “why” is recoverable. Pointer‑based DRRs (CC‑DRR.1a) prevent\nduplicated prose, and distillation into informative pattern sections\n(CC‑DRR.4) keeps the spec itself learnable.\n",
        "relations": "### E.9:9 - Relations\n\n* **Instantiates:** P‑10 Open‑Ended Evolution, P‑2 Didactic Primacy  \n* **Template governed by:** `pat:authoring/pattern‑template` (E 8)  \n* **Interacts with:** `pat:guard/bias‑audit` (E 5.4) via lens check  \n* **Complemented by:** `pat:authoring/code‑of‑conduct` (E 12) – etiquette for DRR debate  \n",
        "e.9:end": "### E.9:End\n"
      },
      "content": "### E.9:End\n",
      "metadata": {},
      "part": "E",
      "cluster": null
    },
    {
      "id": "E.10",
      "title": "Unified Lexical Rules for FPF (LEX‑BUNDLE)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## E.10 - Unified Lexical Rules for FPF (LEX‑BUNDLE)\n*Definitional pattern; normative for all Core/Architheory text and for any Context that claims FPF conformance.*\n\n**Status & placement.** Part E.10 (“Lexical Discipline & Stratification”); complements **E.10.D1 (D.CTX)**, **E.10.D2 (I/D/S)**, and the **DesignRunTag / CtxState boundary discipline** (**A.15**; **E.18**), and is referenced by F‑cluster naming practices (F.4–F.8). This bundle consolidates all lexical constraints in one place so authors can cite **“LEX‑BUNDLE”** instead of listing rules scattered across documents.\n\n**Builds on:** A.7 **Strict Distinction (Clarity Lattice)**; E.5 Guard‑Rails (DevOps Lexical Firewall; Notational Independence; Unidirectional Dependency); F.5 **Naming Discipline for U.Types & Roles**.\n**Coordinates with.** A.2/A.15 (Role–Method–Work alignment), A.10 (Evidence Graph Referring), B.1/B.3 (Γ‑algebras & assurance), F‑cluster (context of meaning; Bridges).\n\n",
        "problem": "### E.10.2 - Problem\n\n1. **Polysemy drift.** *Process, function, service, agent, activity* slide between structure, recipe, execution, and promise.\n2. **Cross‑context collision.** A label (e.g., *Owner*) is assumed “global” though meanings differ per `U.BoundedContext`.\n3. **Name bloat vs. parochialism.** Either hyper‑specific domain names leak into core types, or vague umbrella names obscure invariants.\n4. **I/D/S collapse.** Authors mix **intension** (the thing), **description** (how we describe it), and **specification** (testable criteria).\n5. **Register soup.** Tech terms bleed into Plain pedagogy and vice‑versa, inviting category errors.\n\n",
        "forces": "### E.10:3 - Forces\n\n| Force                          | Tension to resolve                                                                         |\n| ------------------------------ | ------------------------------------------------------------------------------------------ |\n| **Universality vs. local fit** | Kernel must stay universal while allowing domain nuance in a Context of meaning.              |\n| **Brevity vs. clarity**        | Short names help, but only if morphology signals the right kernel slot.                    |\n| **Stability vs. evolution**    | Names should survive refactors; yet we must accommodate new roles/types without explosion. |\n| **Pedagogy vs. precision**     | Plain words aid learners; Tech labels anchor formal checks.                                |\n\n",
        "solution": "### E.10:4 - Solution — the **LEX‑BUNDLE** rule‑set (overview)\n\n**LEX‑BUNDLE** aka **ULR (Unified Lexical Rules)** is a compact set of **register, naming, and rewrite** rules with conformance checks.\n\n1. **Vertical Stratification Ladder** (E.10 → four strata);\n2. **Twin‑Register Discipline** (Tech/Plain pairs);\n3. **Minimal Generality (MG)** principle + tests;\n4. **Morphology & Style** (suffixes, casing, reserved prefixes);\n5. **Canonical Rewrites** for overloaded words (L‑rules);\n6. **Conformance Checklist (CC‑LEX)** and **Regression Stubs (RSCR‑LEX)**.\n\nBelow are the **normative clauses** \n",
        "vertical_stratification_ladder_(four_strata;_no_cross‑bleed)": "### E.10:5 - Vertical Stratification Ladder (four strata; no cross‑bleed)\n\n> **Rule V‑0 (Strata).** Every lexical item in a conformant text belongs to exactly one **stratum**:\n\n1. **Kernel** — `U.*` types, kernel relations, invariants (e.g., `U.Holon`, `U.Role`, `U.Method`, `U.Work`, `U.ServiceClause`).\n2. **Architheory** — CAL/LOG/CHR exports (e.g., **Sys‑CAL**, **KD‑CAL**, **Agency‑CHR**) that **extend** but do not override Kernel.\n3. **Context** — a **`U.BoundedContext`** with its **Glossary, Invariants, Roles**, and **Bridges** (local Context of meaning).\n4. **Instance** — concrete identifiers (holders, role assignments, works, carriers).\n\n**V‑1 (Unidirectional meaning).** Meaning **flows downward** only: Kernel → Architheory → Context → Instance. No stratum may redefine a higher stratum’s term; it may only **specialise** or **bridge** it.\n\n**V‑2 (Strata vs authoring stances).** The four lexical strata above constrain **tokens**. They are independent of an artefact’s **stance** (its `CtxState` pins such as `DesignRunTag`, `ReferencePlane`, and `Locus`). Strata answer “what words mean here”; stance answers “where this claim lives in the flow” and which evidence‑lane expectations apply.\n\n**V‑3 (Citation style).** When a Context term is used, its **Context** must be visible at first mention (e.g., `OwnerRole:ITIL_2020`). If an author needs Cross‑context reuse, they **MUST** cite a **Bridge** with a stated **Congruence Level (CL)** (see F.9).\n\n**V‑4 (Firewall).** Tooling/Pedagogy idioms shall not leak into Kernel prose (DevOps Lexical Firewall). CI/CD jargon, file formats, or API names **MUST NOT** appear in Core definitions. (Pedagogy may use them **as examples** only, in the **Plain** register, with Tech anchors present.)\n",
        "ontology_guards": "### E.10:6 - Ontology Guards\n\n#### E.10:6.1 - Tech register ontology guards\n\n> **Purpose.** This section stabilises the Tech register of the kernel lexicon by enforcing head‑anchored naming, explicit *object‑of‑talk*, I/D/S morphology, disciplined treatment of **Role / Holder**, and Domain usage consistent with **D.CTX** and **UTS**. It aligns with **F.4 Role Description (RCS/RSG)**, **F.11 Method Quartet Harmonisation**, and **F.17 UTS**. **Scope:** Guidance is **register‑agnostic** and applies to the whole FPF; examples are illustrative and MUST pass Minimal Generality & Domain Anchoring (MG-DA) and other rules of lexical governance pattern E*. This guidance applies to kernel and non‑kernel components (including Part G and patterns in Part C) and SHOULD be reused across extensions.\n> \n**Onto1 — Head‑anchoring**  *(use Kernel heads + pass LEX.TokenClass / I/D/S gates)*\n* **Rule:** The **head noun of a term MUST explicitly signal the kind** (`System`, `Holon`, `Role`, `Work`, `Episteme`, `Tradition`, `Lineage`, `Characteristic`, `Method`, `Profile`, `Description`, `Spec`, `Flow`, `Card`, `Pack`, `Dashboard`, …).\n* **Figurative heads** with obvious overload (“Tradition”, “family”, “process”, “function”) are **forbidden in the kernel**. Use **plain twins** only with a 1:1 Tech mapping and declare **`LEX.TokenClass`** for the Tech token. They **MAY** appear **only in the Plain register** as 1:1 twin‑mappings to a Tech token, but **MUST NOT** appear in the Tech register. Plain language should minimise lexical error from overloaded terms; use plain‑twin lexical guards.\n  * **Do:** `IncidentDashboard`, `MethodSpec`, `TraditionProfile`, `FlowDescription`.\n  * **Don’t:** `IncidentBoard`, `TDD Tradition`, `Production Process` (kernel), `Service Function` (kernel).\n\n **Onto2 — I/D/S on the surface (Intension/Description/Specification morphology)**  *(ref. E.10.D2)*\n* **Rule:** Any **intensional** object is a bare head: `Method`, `Tradition`, `Characteristic`. Any **description** appends **`…Description`**: `MethodDescription`, `TraditionDescription`. Any **testable specification** appends **`…Spec`** and presupposes acceptance criteria and harnesses (normative in **E.10.D2**). E.g., *Algorithm* is a species of `MethodDescription` for a computer (a system in the role of information transformer); **If** expressed in a formal language **and** bundled with acceptance tests, it is **`MethodSpec`** (per **F.11**). **If** expressed as pseudo‑code, it is **`MethodDescription`**.\n* **Extension:** Apply the same pattern to non‑method objects where appropriate: `FlowDescription`/`FlowSpec`, `SystemDescription`/`SystemSpec`.\n* **Do:** `SamplingMethod` - `SamplingMethodDescription` - `SamplingMethodSpec`.\n* **Don’t:** `SamplingAlgorithm` (when it is just prose), `SamplingProcessSpec` (head not signalling kind).\n\n**Onto3 — Roles, Holders, and Carriers (holonic)**  *(ref. F.4 / F.5)*\n* **Rule:** The playable intention is named **`…Role`** and described through **F.4 Role Description** (RCS/RSG), e.g., `SafetyOfficerRole`, `ReviewerRole`. The party **assuming a role** is the **Holder**. Use the **`Holder#Role:Context`** pattern to type the assumption (where `Context` is a `U.BoundedContext`), e.g., `Team‑Alpha (U.Holon) is Holder#SafetyOfficerRole:Plant‑Ops`. **Carrier** is **reserved for a system that bears a symbol of episteme** (`U.Episteme`, `Tradition`, `Lineage`, `Profile`, repertoire) **independent of any concrete role assumption**, e.g., `LeanTraditionCarrier`, `CalibrationLineageCarrier`. Avoid **`Artefact`** as a head in the kernel: it is ambiguous between a Carrier (e.g., document), a system “made by” some transformer, or an episteme abstracted from its carrier.\n* **Register note:** Job titles (`Reviewer`, `Owner`, `Lead`) belong in the **Plain** register and MUST twin‑map to explicit Tech `…Role` tokens.\n* **Why:** This resolves the inconsistent “role carrier vs role holder” usage: **use “Holder” for holonic role assumption**, keep **“Carrier”** for the *system that bears a symbol of episteme*. \n* **Migration note.** Legacy `…CarrierRole` **MUST be rewritten** to `Holder#…Role:Context`. Use SCR‑LEX to enforce the rewrite.\n* **Do:** `ReviewerRole` (or `AssessorRole`), `Holder#ReviewerRole:Journal‑Issue‑42` (or `Holder#AssessorRole:Procurement‑Lot‑42`); `LeanTraditionCarrier (U.Holon)`, independent of any particular role.\n**Don’t:** `Reviewer` (as a kernel type), `ReviewerCarrier` (to mean a role holder), `SystemReviewer` (role collapsed into a type).\n\n**Onto4 — Domain only as a catalog mark**  *(ref. E.10.D1 D.CTX; publish stitching on UTS)*\n* **Rule:** `Domain` is **not a kernel kind** and carries **no semantics, inheritance, or reasoning rights**. It is a **catalog mark** that groups several `U.BoundedContext` entries.\n* **Required stitching (see D.CTX & UTS).** Any use of `Domain` **MUST** present: 1. the enumerated list of `ContextId` in **D.CTX**, and 2. the corresponding **UTS strings** (F.17) with twin labels.\n* **“Discipline ≠ Domain.”** _Domain_ labels are **catalog‑only (D.CTX + UTS)**; **Discipline** is a **CG‑Spec‑governed holon** (`U.Discipline`). Cross‑use requires **Bridge (F.9) + CL**; **LexicalCheck** MUST fail texts that equate Domain with Discipline.\n* **Governance.** **No “Domain … governance”.** Rules of comparability/aggregation belong to **Discipline/CG‑Spec** (ComparatorSet, ScaleComplianceProfile (SCP), MinimalEvidence, Γ‑fold, CL‑routing), *not* to `Domain`. Prefer `DomainFamily` + stitching over inventing new “Domain” types.\n* **Do:** `DomainBundle: ClinicalSafety → {ContextId: AdverseEvents, DeviceLabelling, …} + UTS twins`.\n* **Don’t:** `ClinicalSafetyDomain` as a type with inheritance; `Domain Governance` sections in Tech.\n\n**Onto5 — Always state the **object‑of‑talk**\n* **Rule.** The definition or first line of a gloss **MUST state what the term is about**: a `U.Holon`/`U.System`, a `U.Episteme` (`Tradition`, `Lineage`, `Profile`), a `Role`, a `Work` execution, a `Characteristic`, or a `Carrier`.\n* **Do:** “**Object‑of‑talk:** `ReviewerRole` — a role intention playable by a holon within an editorial context.”\n* **Don’t:** “Reviewer — a person who …” (blurs kind and object‑of‑talk).\n\n**Onto6 — Bans and canonical rewrites**  *(mirror E.10 § 9 L‑rules; do not duplicate tables)*\n* `process / function / activity` → **`Work` / `MethodDescription` / `Flow`** (context‑dependent).\n* `Tradition` → **`Tradition`** (Tech); leave “Tradition” only as a Plain twin with an adjacent Tech label.\n* `domain` → **`DomainFamily` + {ContextId list} + UTS twins**.\n* legacy `…CarrierRole` → **`Holder#…Role:Context`**.\n* ambiguous `Owner` in role names → prefer **`StewardRole` / `CustodianRole` / explicit responsibility head**.\n* job titles (`owner`, `lead`, `champion`) in the kernel → **use explicit `…Role` names**; keep titles in Plain with twin‑labels.\n* **Do:** `FlowDescription: ReturnsHandling`, `Tradition: Test‑Driven`, `Holder#CustodianRole:Asset‑Ledger`.\n* **Don’t:** `Returns Process`, `TDD Tradition` (kernel), `Ledger Owner` (underspecified).\n\n**Worked mini‑examples across arenas**\n1. **Software engineering:** `BuildFlowDescription`, `CIHarnessSpec`; `Holder#MaintainerRole:Repo‑X`. Avoid `Build Process`, `Repo Owner`.\n2. **Applied research / experimentation:** `SamplingMethodSpec`, `CalibrationLineageCarrier`; `Holder#ReviewerRole:Grant‑Call‑Y`.  Avoid `Sampling Algorithm` (if prose), `Lab Owner`.\n3. **Production / service management:** `ShiftWork`, `SafetyOfficerRole`; `Holder#SafetyOfficerRole:Plant‑Ops`.  Avoid `Safety Officer` as a type, `SafetyDomain Governance`.\n4. **Operations research / optimisation:**  `RoutingMethodDescription`, `CostCharacteristic`; `Holder#ModelStewardRole:OR‑Program`.  Avoid `Routing Function`, `Model Owner`.\n5. **Healthcare / clinical ops:** `CarePathwayFlowDescription`, `MedicationAdministrationWork`; `Holder#AttendingPhysicianRole:Ward‑12`. Avoid `Care Process`, `Ward Owner`.\n6. **Finance & accounting:** `ReconciliationMethodSpec`, `JournalPostingWork`; `Holder#TreasuryStewardRole:Liquidity‑Book`. Avoid `Reconciliation Process`, `Account Owner` (underspecified).\n7. **Legal / compliance:** `RetentionPolicySpec`, `InvestigationWork`; `Holder#DataProtectionOfficerRole:Org‑X`. Avoid `Compliance Function`, `Data Owner` (underspecified).\n8. **Cloud / IT operations:** `IncidentFlowDescription`, `RunbookMethodSpec`; `Holder#OnCallEngineerRole:Service‑Y`. Avoid `Incident Process`, `Service Owner` (underspecified).\n9. **Logistics / supply chain:** `PickingWork`, `RoutingMethodSpec`; `Holder#DispatcherRole:Hub‑Z`. Avoid `Picking Process`, `Fleet Owner`.\n10. **Construction / civil engineering:** `PermitAcquisitionFlowDescription`, `InspectionMethodSpec`; `Holder#SiteStewardRole:Project‑Lot‑17`. Avoid `Inspection Process`, `Site Owner`.\n11. **Emergency response:** `TriageMethodDescription`, `EvacuationFlowDescription`; `Holder#IncidentCommanderRole:Event‑R`. Avoid `Triage Function`, `Incident Owner`.\n12. **Agriculture:** `IrrigationFlowDescription`, `SoilSamplingMethodSpec`; `Holder#FieldStewardRole:Plot‑17`. Avoid `Irrigation Process`, `Field Owner`.\n\n**Checklist before minting a KernelToken**\n* Head noun signals kind (Onto1).\n* I/D/S morphology correct (Onto2).\n* If role‑related: **Role vs Holder vs Carrier** separation observed; holonic scope explicit (Onto3).\n* Any Domain mention stitched to D.CTX and UTS; **no norms on Domain** (Onto4, Onto6).\n* Object‑of‑talk declared (Onto5).\n* SCR‑LEX rewrites checked / legacy forms migrated (Onto6).\n> **Note on registers.** Keep figurative or business‑casual terms in the **Plain** register only, with strict **twin‑label** links to the Tech token (LEX‑BUNDLE). In the **Tech** register, speak in KL‑CAL: **episteme‑about‑epistemes** (Tradition, Lineage, Profile), not in catalogue‑admin idioms.\n\n* **Onto‑Deon — Deontic lexicon guard (Core register)**  \n**Rule.** In the Conceptual Core, avoid using **“Standard”** as the head noun of an *intensional object* name unless the object is an explicit **deontic speech-act** under the **Gov** lens (cf. E.3).\n\nFor interface/boundary invariants and public commitments of **things** (holons, interfaces, ports), prefer intensional names like **InterfaceContract**, **ComplianceProfile**, **AcceptanceSpec**, **InteropProfile**, etc.\n\nUse the word **standard** for an **artefact** (Description/Specification) that is *intended to be complied with* (and that has explicit compliance checks).\n\nIf an intensional object is currently named `… Standard`, rename it to a proper intensional name, and (optionally) add a separate Description/Specification artefact that contains the standard text and the intended compliance checks.\n **Rewrite hints (Tech → Tech).**  \n `publication Standard` → `publication standard`;  \n `frame Standard` → `frame standard`;  \n `measurement Standard` → `measurement standard`;  \n `Method Interface Standard (MIC)` → `Method Interface Standard (MIS)` *(alias acceptable during transition)*;  \n `Boundary‑Inheritance Standard (BIC)` → `Boundary‑Inheritance Standard (BIS)` *(alias acceptable during transition)*.  \n **Rationale.** Keeps Core prose centred on **intensional objects** and their boundary invariants; reserves deontic obligations for governance contexts and **U.ServiceClause**‑like promises. Do **not** misuse “plane”: deontic speech‑acts are analysed via the **Gov** lens, while **ReferencePlane** remains `{world | concept | episteme}`.\n",
        "e.10:6.2___twin‑register_discipline_(tech_/_plain)": "### E.10:6.2 - Twin‑Register Discipline (Tech / Plain)\n\n**Plain twin (LEX).** A registry entry pairing the **authoritative Tech label** with a **display‑only Plain label** for one `U.Type` **in one `U.BoundedContext`**; governed by **PTG (Plain Twin Governance; in the LEX registry)** and referenced by `Twin‑Map ID (LEX)`. *“Plain twin” ≠ the **Plain register** (the register is where twins may be used; the twin is the 1:1 mapping).*\n**Convention.** In this spec, **Plain** (capitalized) names the register; **plain twin** (lowercase) names the 1:1 mapping entry.\n\n> **Rule R‑0 (Registers).** Every Kernel and Architheory concept has a **Tech label** (the testable semantic token) and an optional **Plain label** (didactic synonym). The **Tech label is authoritative**; the Plain label is permitted *only* in expository text and must map 1:1 to the Tech meaning inside the current **Context**.\n\n#### E.10:6.2.1 - Allowed pairs (normative table; examples)\n\n| **Tech (authoritative)** | **Plain (didactic)**                        | **Notes & guards**                                                                           |\n| ------------------------ | ------------------------------------------- | -------------------------------------------------------------------------------------------- |\n| `U.System`               | system, machine, team                        | “Service” **never** stands for `U.System`; reserve **Service** for `U.ServiceClause` (see L‑SERV). Avoid “service‑instance” as a Plain twin; prefer “system instance” if needed. |\n| `U.Episteme`             | body of knowledge, document, dataset, model | Pair must respect **Carrier vs Content** (A.7).                                              |\n| `U.Method`               | how‑to, procedure (abstract)                | Do **not** call this “process” (L‑PROC).                                                     |\n| `U.MethodDescription`    | recipe, SOP, playbook, code, spec‑text      | If testable, call out **Spec** explicitly per E.10.D2 (I/D/S).                               |\n| `U.Work`                 | run, execution, activity, job, case         | Never use “process” or “procedure” here.                                                     |\n| `U.Role`                 | role, hat, mask                             | Always **context‑indexed** per D.CTX.                                                        |\n| `U.ServiceClause`              | promise, offering, external Standard        | Never equate to provider system or API (L‑SERV).                                             |\n| `U.Capability`           | ability, capacity (within bounds)           | Separate from Role/Method/Work; must carry **envelope & measures**.                          |\n| `U.Dynamics`             | law of change, model of evolution           | Not a capability or a method.                                                                |\n\n**R‑1 (Plain first‑use).** At first use in a section, show **Tech label** and (optionally) the Plain twin: *“…a `U.Method` (the **how‑to**), described by a `U.MethodDescription` (the **recipe**) …”*\n**R‑2 (No unpaired Plain in CC).** Conformance Checklists must use **Tech labels** only.\n\nDomains can mint aliases inside their `U.BoundedContext` glossary; all aliases must map 1:1 to a Tech label (**SenseCell** row in the Context’s **Concept-Set Table**), and if exported across Contexts, via an **Alignment Bridge** (with **CL/Loss**).\n\n Make “plain twins” (reader‑friendly labels) **safe by construction**, not just style. The plain twin must **not** change kind, scope, or reader expectations versus the canonical Tech name; it is **display‑only** and **context‑local**.\n\n* **Tech name (tech)** — the canonical, kernel‑conformant label used in **normative** clauses (e.g., `U.RoleAssignment`, `TransformerRole`).\n* **Plain twin (plain)** — a didactic **display alias** permitted in **expository** prose and UI surfaces **inside one `U.BoundedContext`**.\n\n> **Principle:** *Meaning lives in the Tech name; the plain twin may never move meaning.* (Locality is enforced by `U.BoundedContext` and Bridges.)\n\n#### E.10:6.2.2 - Plain Twin Safety constraints (normative)\n\n**CC‑TWIN‑1 - One‑to‑one & local.**\nEach Tech name has **at most one** plain twin **per `U.BoundedContext`**; the same plain twin **MUST NOT** point at more than one Tech name in the same Context.\n\n**CC‑TWIN‑2 - Sense‑equivalence proof.**\nA plain twin **MUST** bind to the **same SenseCell** as its Tech name in that Context (F.3/F.7). Authors **MUST** record at least one **counter‑example test** showing how the twin could be misread and why it still passes **in this Context** (SenseCell notes).\n\n**CC‑TWIN‑3 - Head‑term discipline (HND).**\nThe plain twin **MUST** preserve the **head term** of the Tech name, or append an explicit bracketed head on **first use**:\n\n* Roles keep **“(role)”**, Services keep **“(service)”**, Methods keep **“(method)”**, Work keeps **“(work record)”**, Capability keeps **“(capability)”**.\n  *Examples:*\n  `TransformerRole` → “**Transformer (role)**”,\n  `U.ServiceClause` → “**Service (service)**”,\n  `U.Work` → “**work (work record)**”.\n\n**CC‑TWIN‑4 - Kind‑consistent.**\nA plain twin **MUST NOT** map across **Kinds** (C.3). If the twin’s everyday reading could denote a different Kind (e.g., *Tradition* = organization, corpus, domain), it is **forbidden** unless qualified by a bracketed head and **Context gloss** on first use (see CC‑TWIN‑7).\n\n **CC‑TWIN‑5 - Ambiguity stop‑list.**\nThe following base nouns are **reserved** and **MUST NOT** be used as unqualified plain twins: *Tradition, service, process, function, model, system, method, standard, library, dataset, evidence, activity, task, action*.\nThey are allowed **only** with an explicit head per **CC‑TWIN‑3** and a **Context gloss** (CC‑TWIN‑7). *(This list MAY be extended in the registry.)*\n\n**CC‑TWIN‑6 - No cross‑context by label.**\nPlain twins are **not portable**. Reuse in another `U.BoundedContext` requires a **Bridge** with CL and loss notes; names alone carry no authority.\n\n**CC‑TWIN‑7 - First‑use gloss.**\nAt first occurrence in a document or screen, a plain twin **MUST** be shown as **“Plain twin \\[Tech name] — Context gloss”**, e.g.:\n“**Transformer (role)** \\[**TransformerRole**] — *mask borne by a system to enact a method step in OR\\_2025*”.\n\n**CC‑TWIN‑8 - Normative surface ban.**\nPlain twins **MUST NOT** appear in **Conformance Checklists, predicates, type signatures, or acceptance clauses**. Only Tech names are normative. (Plain twins are strictly didactic.)\n\n**CC‑TWIN‑9 - Twin budget.**\n**At most one** plain twin per Tech name per Context. Synonym piles are prohibited (control vocabulary sprawl; see F.14).\n\n**CC‑TWIN‑10 - Registry entry & DRR.** \nEvery plain twin **MUST** have a **registry entry** (in the LEX registry) recording: `tech`, `plain`, `context`, `head`, **SenseFidelity = {3,2,1,0}**, ambiguity notes, counter‑examples, DRR id. Any change requires a **DRR**. \n\n**CC‑TWIN‑11 - Tests.**\n Twin entries **MUST** pass the **Twin Harness** (see F.15): *Head term*, *Kind consistency*, *SenseCell match*, *Stop‑list compliance*, and *First‑use gloss*.\n",
        "minimal_generality_&_domain_anchoring_(mg_da)_—_names_neither_parochial_nor_vacuous": "### E.10:7 - Minimal Generality & Domain Anchoring (MG-DA) — names neither parochial nor vacuous\n\n> **Principle (MG-DA).** A minted name is **as general as necessary and no more**, and its **head noun is anchored to the object‑of‑talk**. First classify the **NameToken (name of a concept: term, lexical unit) itself** using **`LEX.TokenClass`**, then apply the guardrails corresponding to that class: kernel tokens must unify **across domains**; discriminator/context tokens must make the **domain legible** *from the name itself*. Names too general to have obvious domain are **banned**. \n\n#### E.10:7.1 - `LEX.TokenClass` (meta‑lexical; not a USM Scope)\n**Definition.** `LEX.TokenClass : NameToken → {KernelToken | ContextToken | DiscriminatorToken}`.  \nThis is a **Characteristic on NameTokens** (symbols), used by the LEX registry and MG-DA lints.\nIt is **not** a USM scope and carries **no** truth/validity semantics.\n\n#### E.10:7.2 - `KernelToken` — Minimal Generality (MG‑K)\n**MG‑K1 (Tri‑domain witness, MUST).** Maintain a DRR/Glossary note with **≥ 3 heterogeneous arenas** where the invariants hold (e.g., manufacturing, healthcare, cloud ops). If you cannot, narrow to a Context name or move qualifiers into **RCS** (Role Characterisation Space).\n**MG‑K2 (No parochial nouns, MUST).** Kernel names **MUST NOT** contain domain nouns (*Ticket, Microservice, Patient, Developer*). Such nouns belong in **Context** or as **RCS Characteristics**.\n**MG‑K3 (No vacuity, MUST).** Avoid vacuous heads (*Thing, Event, Process, Resource*). Use existing kernel heads (`U.Holon`, `U.Work`, `U.Method`, `U.Resrc`, …).\n**MG‑K4 (Intent over mechanism, MUST).** Kernel type/role names encode **intent**, not mechanism. Mechanisms (algorithms, hardware form, recipe flavors) live in **RCS** or **Capability**.\n**MG‑K5 (Notation independence, SHOULD).** The intensional meaning is separable from any one notation/toolchain.\n**MG‑K6 (Refactoring safety, MUST).** If a name fails MG, do **not** mutate it silently. Record a DRR and apply F.13 **Lexical Continuity & Deprecation** (aliases; Bridges for Cross‑context mappings).\n\n#### E.10:7.3 - `DiscriminatorToken` / `ContextToken` — Domain Anchoring (DA‑D)\n**DA‑D1 (Object‑of‑talk anchoring, MUST).** The head noun names the **object being classified** (e.g., *Sense*, *Context*, *Role*, *Bridge*, *Characteristic*). Readers can answer “**X of what?**” without external context.\n**DA‑D2 (Characteristic, not axis, MUST).** Enumerated properties are named as **Characteristic**  within a **CharacteristicSpace** (MM‑CAL). Avoid spatial metaphors (*axis, dimension, plane, lane, tier, layer*) unless the metaphor is a **pattern‑defined primitive** in this spec.\n**DA‑D3 (Enum clarity, MUST).** If the term denotes an enumeration, (a) the value set is **small and closed**, (b) membership criteria are obvious from the definition, (c) the **object‑of‑talk** is explicit in the name (e.g., `SenseFamily`, not bare *Family*, *RowPlane* or overly general *Facet*).\n**DA‑D4 (Anti‑recipe, MUST).** Do not bake *how‑to* or local methods into discriminator names; those belong in `U.Method/MethodDescription` or **Capability**.\n**DA‑D5 (Mapping discipline, MUST).** Cross‑context readings go through a **Bridge** (F.9). Discriminator names must not suggest global identity.\n**DA‑D6 (Register discipline, SHOULD).** Keep normative tokens stable; synonyms live in **Plain** register only and must not appear in constraints/tests.\n**DA‑D7 (Ban generic combinators, MUST).** Reject vague composites like *NameUseMode*, *NamingScope*, *RowFacet/RowPlane/RowLane*. Each candidate must pass **DA‑D1** and **DA‑D3** (object‑anchored head and explicit **CharacteristicSpace**).\n\n#### E.10:7.4  - Global tests (apply after 7.2/7.3)\n**MG-DA‑T1 (Three‑arena witness).** If **`LEX.TokenClass`(t)=KernelToken**, you **MUST** provide the tri‑domain witnesses (7.2‑MG‑K1). Otherwise this is **SHOULD** (document at least one contrasting arena).\n**MG-DA‑T2 (Object‑of‑talk).** The head noun uniquely signals the subject area; avoid free‑floating metaphors. **MG-DA‑T3 (Anti‑recipe).** Remove mechanism/implementation words; relocate to Method/Capability/RCS.\n**MG-DA‑T4 (Enum clarity).** For enumerations, list the closed value set and its CharacteristicSpace.\n**MG-DA‑T5 (Collision & Uniqueness, MUST).** Before merge, run a **full‑text search** over the corpus and the **Reserved‑Names registry**. The candidate **MUST NOT** collide with any existing token used in another sense anywhere in FPF. If a collision exists, either rename or raise a DRR to deprecate the prior token.\n**MG-DA‑T6 (Teaching swap).** In didactic prose (E.10.D2), the term can be swapped in **without caveats**. \n**MG-DA‑T7 (Intensional ground, MUST).** The definition card states the intensional criterion for membership explicitly; reviewers can check membership without reading external narrative.\n\n#### E.10:7.5 - Compatibility with USM (how tokens and scopes meet)\n**USM applies to acts, not tokens.** Mint/rename/use are **LexicalActs** that carry a USM scope. `LEX.TokenClass` constrains **where** a token may be used via an **AllowedScopes** policy:\n**Conformance rule.** For any usage `u` of a token `t`: `LEX.TokenClass(t)=c  ⇒  USM.Scope(u) ∈ AllowedScopes(c).`\n\nThe LEX registry defines `AllowedScopes(c)` (e.g., `KernelToken` usage in normative kernel constraints is allowed; in Plain register outside a glossary is restricted; Context emissions of `KernelToken` require a Bridge/alias, etc.).\n\n**Audit.** Violations are flagged as **SCR‑LEX‑Sxx** (see acceptance tests below).\n\n#### E.10:7.6 - Metaphor guidance (non‑binding heuristics)\nPrefer **object‑anchored heads** to metaphors. If a metaphor is unavoidable, ensure it is (a) explicitly defined by a pattern here, and (b) unambiguous within the **NameClass**. Example families (use sparingly):\n* **Progression metaphors** (*level, tier, ladder*): only where a **gate/upgrade** is defined by the pattern.  \n* **Separation metaphors** (*lane, track*): only where parallel, non‑interfering flows are enforced by rules.  \n* **Grouping metaphors** (*family, class*): only for **small, closed enumerations** attached to a clearly named object‑of‑talk (e.g., `SenseFamily` rather than bare *Family*).\n\n#### E.10:7.7 - Short‑form and acronym discipline\n**SF‑1 (First expansion, MUST).** On first use, expand the term; place the short‑form in parentheses (e.g., “Minimal Generality & Domain Anchoring (**MG-DA**)”).  \n**SF‑2 (Uniqueness, MUST).** Register short‑forms in the **Reserved‑Names** list; run the collision check (7.4‑MG-DA‑T5).  \n**SF‑3 (Form, SHOULD).** Prefer typographic separators (**MG-DA**) to fused acronyms (**MGDA**). Use the fused form only in code or identifiers where punctuation is disallowed, and only after registration.\n\n#### E.10:7.8 - Examples (illustrative, canonical)\nPrefer **`U.ServiceClause`** (promise) over *BusinessService*; **`U.Capability`** over *Function*; **`U.Dynamics`** over *NaturalProcess*; **`U.WorkPlan`** over *ScheduleProcess*.  \nDo **not** mint *ETLService* at kernel level—model ETL as `MethodDescription`; the **Service** is “data delivered under acceptance.”\n\n#### E.10:7.9 - Acceptance & regression checks (LEX/USM)\n**SCR‑LEX‑S01 (TokenClass declaration).** Every normative token has a declared `LEX.TokenClass`.\n**SCR‑LEX‑S02 (Collision & uniqueness).** Full‑text + Reserved‑Names check passes (no other meaning in FPF).\n**SCR‑LEX‑S03 (Object‑of‑talk anchoring).** Heads name the object classified (DA‑D1).\n**SCR‑LEX‑S04 (CharacteristicSpace).** Enumerations declare their value set and space (DA‑D2/3).\n**SCR‑LEX‑S05 (USM compatibility).** For each LexicalAct, `USM.Scope ∈ AllowedScopes(LEX.TokenClass)`.\n**SCR‑LEX‑S06 (Slot/Ref suffix discipline).** Any token with suffix **`…Slot`** or **`…Ref`** is either (a) a **SlotKind**/**RefKind** declared under A.6.5, or (b) a episteme field whose type is a RefKind; no ValueKind or other type class may end with these suffixes.\n**RSCR‑LEX‑E01 (Banned generics).** Reject tokens matching the banned combinators list (DA‑D7).\n**RSCR‑LEX‑E02 (Metaphor hygiene).** If a metaphor is used, show the pattern that defines it; otherwise rename.\n**RSCR‑LEX‑E03 (Strategy token minting).** Reject new Kernel tokens named **Strategy**/**Policy** as kinds; model them as **lenses/flows/compositions** inside **G.5** or as **…Description/…Spec** in Contexts. (Prevents kernel overloading; aligns with C.22 “no minted Strategy head”.)\n",
        "morphology_&_lexical_form_(lex.morph)": "### E.10:8 - Morphology & Lexical Form (LEX.Morph)\n\n> **Principle.** Form follows **object‑of‑talk**. A token’s morphology (suffix/prefix/casing) must (a) express **what kind of thing** it names, (b) respect **MG-DA** (Minimal Generality & Domain Anchoring), and (c) pass **LEX.TokenClass** gates:\n> `LEX.TokenClass(token) ∈ {KernelToken | ContextToken | DiscriminatorToken}`.\n> Morphological choices never override **I/D/S layers** or **CHR\\:ReferencePlane** semantics.\n\n#### E.10:8.0 - Casing & basic forms\n\n**M‑0 (Casing and categories).**\nTypes & role kinds: **UpperCamelCase** (`IncisionOperatorRole`, `MethodDescription`).\nRelations/verbs: **lowerCamelCase** (`performedBy`, `isExecutionOf`, `bindsMethod`).\nIDs/instances: **flat with delimiters** (context‑defined) but never collide with type forms (e.g., `W#Seam134`, `ctx:Hospital.OR_2025`).\n**Register discipline:** normative tokens use the Technical register; Plain synonyms are allowed in prose only, never in constraints.\n\n\n#### E.10:8.1 - Reserved suffixes (gated by LEX.TokenClass and I/D/S)\n\n> **Use tables as a whitelist.** Rows indicate **when** a suffix is permitted and **what it means**. “Layer gate” prevents I/D/S confusion; “Examples” are illustrative.\n\n| **Suffix**              | **Kind named** (object‑of‑talk)            | **Layer gate**                       | **LEX.TokenClass gate**         | **Examples**                                      | **Forbidden misuses (typical)**                                       |\n| ----------------------- | ------------------------------------------ | ------------------------------------ | ------------------------------- | ------------------------------------------------- | --------------------------------------------------------------------- |\n| **`Role`**              | **Role kind** (intensional)                | I‑layer                              | KernelToken/ContextToken        | `TransformerRole`, `ApproverRole`                 | Appearing in BoM/mereology; mixing with run logs.                     |\n| **`Method`**            | **Abstract way of doing** (recipe type)    | I‑layer                              | KernelToken/ContextToken        | `SteriliseInstrumentMethod`                       | Versioning on `Method` (version the `MethodDescription` instead).     |\n| **`MethodDescription`** | **Recipe/description** (notation‑agnostic) | D‑layer                              | KernelToken/ContextToken        | `JS_Schedule_v4_MethodDescription`                | Calling it “process”; encoding runtime actuals here.                  |\n| **`…Spec`**             | **Testable specification** (acceptance‑bound) | S‑layer                              | KernelToken/ContextToken        | `MethodSpec`, `FlowSpec`, `SystemSpec`            | Using “Spec” without acceptance tests/harness; putting runtime actuals here. |\n| **`Work`**              | **Execution** (runs or kinds of runs)      | (run artefact; not I/D/S)            | KernelToken/ContextToken        | `SpeechActWork`, `W#Seam134`                      | Plans/schedules; design‑time recipes.                                 |\n| **`WorkPlan`**          | **Schedule of intent**                     | D‑layer (plan artefact)              | ContextToken                    | `MaintenanceWorkPlan_Q3`                          | Logging actuals; claiming execution.                                  |\n| **`Service`**           | **External promise object**                | I‑layer (Standarded intension)       | KernelToken/ContextToken        | `ObjectStorageService`, `PassportIssuanceService` | Naming teams/APIs as “Service”.                                       |\n| **`Capability`**        | **System ability**                         | I‑layer                              | KernelToken/ContextToken        | `ScheduleGenerationCapability`                    | Mislabeling roles or methods as capabilities.                         |\n| **`Dynamics`**          | **Law/model of change**                    | I‑layer                              | KernelToken/ContextToken        | `LotkaVolterraDynamics`                           | Using for abilities (`Capability`) or recipes (`Method`).             |\n| **`Observation`**       | **Observation record/kind**                | (run artefact; not I/D/S)            | ContextToken/DiscriminatorToken | `VibrationObservation`                            | Mixing with `MethodDescription` or `Evaluation`.                      |\n| **`Evaluation`**        | **Evaluation artefact**                    | D/S‑layer (epistemic episteme)              | ContextToken/DiscriminatorToken | `CalibrationEvaluation`                           | Using to name roles or methods.                                       |\n| **`EvidenceRole`**      | **Role in evidence assembly**              | I‑layer (role kind)                  | KernelToken/ContextToken        | `WitnessStatementEvidenceRole`                    | Using as a generic “evidence”.                                        |\n| **`Episteme`**          | **Epistemic knowledge unit** (structural)  | D/S‑layer                            | KernelToken/ContextToken        | `TraceabilityEpisteme`                            | Colliding with CHR **ReferencePlane** (never suffix “Plane”).         |\n| **`System`/`Holon`**    | **Substantial entity**                     | I‑layer                              | KernelToken/ContextToken        | `AnesthesiaSystem`, `OrderFulfillmentHolon`       | Using to denote Context or run artefact.                              |\n| **`Boundary`**          | **System boundary**                        | I‑layer                              | KernelToken/ContextToken        | `SterileFieldBoundary`                            | Using as a role or method.                                            |\n| **`Objective`**         | **Target state**                           | I/D‑layer (depends on formalization) | KernelToken/ContextToken        | `HemostasisObjective`                             | Encoding acceptance tests here (put tests in Spec/MethodDescription). |\n| **`Requirement`**       | **Obligation at acceptance**               | D/S‑layer                            | KernelToken/ContextToken        | `LatencyRequirement`                              | Using as a role or capability.                                        |\n| **`BoundedContext`**    | **Context card**                           | (meta‑structural; not I/D/S)         | ContextToken                    | `ITIL_2020_BoundedContext`                        | Treating Context as domain; minting `U.*` inside a Context.           |\n| **`Surface`**              | Publication/Interop surface (episteme)   | D/S-layer (publication)     | ContextToken                     | PublicationSurface, InteropSurface       | StructureSurface, MechanismSurface, PortfolioSurface |\n| **`Card`**                 | UTS/record unit (episteme)               | D-layer (publication)       | ContextToken                     | MethodCard, ExternalIndexCard            | Encoding runtime actuals; using as a ‘Service’  |\n \n| **Suffix** | **Lexical class** | **Meaning / Ontology** | **Where it lives** | **Examples / Notes** |\n|--- |--- |--- |--- |--- |\n| **Space** | Intensional kind | A typed **state space** (finite product of Characteristic×Scale slots); no procedures | Kernel A.19; CHR/space consumers | `CharacteristicSpace`, `CreativitySpace`. Edition of a Space is a **phase** of the episteme that defines it. |\n| **SpaceRef** | Pointer | Registry reference to a Space | Data fields / UTS | `CharacteristicSpaceRef`. Use **`.edition`** on the **Ref** when pinning a historical phase. |\n| **Map** | Intensional kind (method) | A **mapping method** from subjects to coordinates in a declared Space (encoder/featurizer) | Kernel/Method family (I‑layer), described/spec’d via I/D/S | `DescriptorMap` (declares invariances, corpus typing). Not a record or file. |\n| **MapRef** | Pointer | Registry reference to a **Map** | Data fields / UTS | `DescriptorMapRef`. Pin the method phase via **`DescriptorMapRef.edition`**. |\n| **Def** | S‑layer alias (CG‑Spec family) | A **definition/specification artifact** that fixes a **formula** or **distance** over a space; *synonym of …Spec* **within CG‑Spec registries only** | Part G (CG‑Spec family) | `DistanceDef` ≍ `DistanceSpec`. Prefer **…Spec** in new normative prose; **…Def** retained where already published. |\n| **DefRef** | Pointer | Registry reference to a **…Spec/…Def** | Data fields / UTS | `DistanceDefRef`. Use **`DistanceDefRef.edition`** to pin the exact formula edition. |\n| **Spec** | S‑layer | Testable invariants bound to acceptance harnesses | E.10 & A.21 | For stable, testable definitions; **normative** by default; S‑layer, Spec‑gated | Use for normative calculi and scoring/normalization specifications. |\n| **Slot** | Structural position | Named **argument position** in a relation/morphism signature (SlotKind in A.6.5) | Kernel A.6.0/A.6.5 | `DescribedEntitySlot`, `GroundingHolonSlot`. Always names a *position*; never used for ValueKinds or episteme fields. |\n| **Ref** | Pointer | **Reference/identifier** to a registry item of some ValueKind (RefKind in A.6.5), not the thing itself | Data fields / UTS; RefKind types | `U.EntityRef`, `U.HolonRef`; episteme fields `…Ref : U.EntityRef`. Reserved for **RefKinds** and episteme fields typed as them; `…Ref` **never** carries content and is never used for ValueKinds or SlotKinds. |\n| **Series** | Governance object | A **PhaseOf chain** (“editions”) for an episteme | Edition governance | `U.EditionSeries`. Holds immutability and provenance rules. |\n| **.edition** | Attribute (on **Ref**) | The **phase id** of the **referenced artifact**; attaches to `…Ref`, not to the artifact’s name | Data fields / UTS | Use `XRef.edition`, **not** bare `XEdition` fields. Lower camelCase for keys. |\n\n**Notes.**\n• **Kernel‑only ban list** remains in § 8.3.\n• **CHR guard:** the only token that may use the word *plane* is **CHR:ReferencePlane**.\n• **Axis/dimension metaphors** are deprecated; use **Characteristic / CharacteristicSpace** where an enumeration is intended (see § 7).\n\n**Not only suffix guard**\n* Suffixes are strongly related to kinds and **should** be clearly guarded by MG-DA.\n* Other morphemes (not only suffixes) also **must** respect kinds. For example, **Space is a geometric concept** — **never** use it as a suffix (`…Space…`) or other morpheme in beginning or in the middle of a term to name non‑geometric entities (e.g. prefer **Set/Kid/Kit** instead of **Space** where membership is intended).\n\n**L‑SURF — disciplined use of *Surface* **\n* **Definition.** *Surface* is reserved for **publication/interoperability surfaces** (UTS, shipping, interop) that present lawful, plane‑aware summaries for human/selector consumption. A **Surface is a bundle of views** (ISO 42010 sense) packaged for a stated **audience** and **purpose**, with declared **viewpoint**. Surfaces are **conceptual** (E.5.2); serialisations live in Annex/Interop. Surfaces package **D/S** projections produced via `Describe_ID` / `Specify_DS` (A.7) and do **not** change object ontology.\n* **Allowed:** `PublicationSurface`, `InteropSurface` (G.10/G.13).  \n* **Forbidden:** `StructureSurface`, `MechanismSurface`, any `…Surface` that denotes a structural, mechanistic or measurement object.  \n* **Preferred alternatives:** use `…Boundary` (structural border), `…View` (publication view), or `…Card` (UTS record).\n\n**L‑SPACE — disciplined use of *Space* **\n* Use *Space* only for **CHR‑grounded measurement/state constructs** (e.g., `CharacteristicSpace` per A.19). Do **not** coin generic `…Space` for sets/portfolios or publication artefacts. Publish portfolios/archives as **sets** via lawful selectors; surface them on UTS as **views/cards**, not as spaces. \n* **Field‑name guard (Kernel blocks).** In **Kernel conceptual blocks** (e.g., A.6.0/A.6.1 lists), **do not** name a field `…Space`; reserve *Space* to the **types** (CHR/ReferencePlane families). Use **BaseType** as the field name and let the referenced `U.Type` carry `…Space` where appropriate; otherwise, for set‑valued universes, use `…Set`.\n* Space is geomertic concept, neve use it even not as a suffix for naming non-geometric spaces (e.g. instead of Sets with membership)\n\n**L‑ROLE — disciplined use of *Role***\n* **Role** is always **Role Enactment for the `U.Holon`/`U.System` kind** (agentive use).\n* **Param‑slot / relation‑endpoint guard.** Do **not** use the morpheme **`Role`** for **formal parameter positions** in operator algebra declarations (`OperationAlgebra`) or Signature arguments. Reserve **`Role`** for **agentive kinds** only (A.2/F.4/F.6). Prefer SlotKinds + SlotSpecs (A.6.5) to type formal slots; if a didactic list is useful, use a `ValueKindView` (name→ValueKind) projection derived from SlotSpecs/SlotIndex. Same for similar situations (table columns, tuple placements): use MG-DA with domain‑**specific** terminology, never “Role”. \n\n#### E.10:8.2 - Forbidden suffixes & the DevOps, Data Governance and Repository-Workflow Lexical Firewall\n\n**M‑F (Forbidden in Kernel tokens).** In KernelToken names, do **not** use: *…Function*, *…Process*, *…Task*, *…Activity*. These are ambiguous or vacuous—map using § 6 typing rules (often to `Method`, `MethodDescription`, or `Work`).\n\n**M‑FW (Tool/file markers).** Tooling/file suffixes (*…API*, *…JSON*, *…YAML*, *…CI*, *…Kafka*, *…Postgres*) are **not** part of conceptual names. Place them in **Context** glossaries or operational configs (DevOps Lexical Firewall). Kernel names never carry tool/format/notation marks. It is pure conceptual, no data management and data governance intended.\n\n#### E.10:8.3 - Prefix discipline\n\n**M‑P1 (Reserved prefixes).** `U.` reserved for **Kernel types**; `Γ_` for algebraic operators; `CAL/LOG/CHR` for **architheory packages**. Never mint `U.*` inside a Context.\n\n**M‑P2 (Edition markers).** Apply explicit edition/version markers to **Contexts** and to `MethodDescription` / `Service`—**not** to `Method` (e.g., `BPMN_2.0_BoundedContext`, `JS_Schedule_v4_MethodDescription`, `PassportIssuanceService_v2025`).  Authors MAY annotate Context or Service names for didactics.\n**Norms (edition vs release vs version).**\n1) **edition** — the **content phase** of an episteme (Concept/Object/Symbol where Symbol‑only notation swaps do not force a phase). Lives in `U.EditionSeries`. Never embedded in labels (see R‑RD‑7); bind via data: `…Ref.edition`. \n2) **release** — a **Work** of making a **Carrier** public; may carry tags/dates; does **not** change episteme identity or phase.\n3) **version** — a **tooling/carrier** identifier (file/package/code). Use only in Tooling/Pedagogy families; not in Core names.\n\n**Property discipline.** When a field pins a referenced artifact’s phase, write it as **`<Thing>Ref.edition`** (dot notation), never as a standalone `…Edition` key. E.g., replace `DHCMethodEdition` with `DHCMethodRef.edition`.\n\n#### E.10:8.4 - Morphology tests (apply with § 7 MG-DA)\n\n**M‑1 (Slot test).** The candidate fits **one** slot in the Strict Distinction lattice (Object ≠ Description ≠ Carrier; Role ≠ Method ≠ Work). If not, **rename** or split.\n\n**M‑2 (Object‑of‑talk anchoring).** The head noun names the **object being classified** (Role/Method/Service/Work/Context/Characteristic). No free‑floating metaphors.\n\n**M‑3 (Family congruence).** Where eligibility clarity is needed, add a **Context‑specific characteristic** (RCS) as a qualifier (e.g., `NormativeStandardRole`). Do **not** fake families with bare metaphors (no `RowPlane`, `senseFamily`, `…Lane`).\n\n**M‑4 (Run vs design).** Use **`Work`** only for executions; use **`MethodDescription`** for recipes; never cross.\n\n**M‑5 (Kernel parochiality).** KernelToken names carry **no domain nouns**; push domain markers to Context or RCS.\n\n**M‑6 (Vacuity ban).** Avoid vacuous heads (*Thing, Event, Process, Resource*). Use established kernel heads (`U.Holon`, `U.Work`, `U.Method`, `U.Resrc`, …).\n\n**M‑7 (Notation independence).** Intensional meaning survives notation/tool swaps.\n\n**M‑8 (Collision & uniqueness).** Before merge, run **full‑text** + **Reserved‑Names** checks; the token must not collide with any other meaning anywhere in FPF (cf. § 7 MG-DA‑T5).\n\n#### E.10:8.5 - Alias hygiene\n\nAliases live **only** inside a **Context Glossary** and map to **one** technical label with an **equivalence** note (≡). No global aliases.\n\n#### E.10:8.6 - Compatibility with USM (acts vs tokens)\n\n**LEX applies to tokens; USM applies to acts.** Mint/rename/use are **LexicalActs** that carry a USM scope (e.g., ClaimScope, WorkScope). LEX constrains **where** a token form may appear via **AllowedScopes** policies:\n\n`LEX.TokenClass(t)=c  ⇒  USM.Scope(usage) ∈ AllowedScopes(c)`.\n\nExample: using a `KernelToken` in a Context constraint may require a Bridge/alias; logging `Work` inside a MethodDescription violates M‑4 and the policy.\n\n#### E.10:8.7 - Acceptance & regression checks (LEX/USM)\n\n* **SCR‑MOR‑S01 (Suffix whitelist).** Every normative token with a reserved suffix matches § 8.1 row semantics and passes Layer gates.\n* **SCR‑MOR‑S02 (Kernel bans).** KernelToken names contain none of the forbidden suffixes (§ 8.2).\n* **SCR‑MOR‑S03 (Prefixes).** Reserved prefixes obey § 8.3; no `U.*` minted in Context.\n* **SCR‑MOR‑S04 (Run/design gate).** `Work` appears only for executions; `MethodDescription` has no runtime actuals.\n* **SCR‑MOR‑S05 (Collision).** Full‑text + Reserved‑Names checks pass (no other sense of the token elsewhere).\n* **SCR‑MOR‑S06 (Object‑of‑talk).** Heads pass M‑2; no bare metaphors as heads.\n* **RSCR‑MOR‑E01 (DevOps firewall).** Tool/file suffixes quarantined to Context; none leak into KernelToken names.\n* **RSCR‑MOR‑E02 (USM compliance).** For each LexicalAct, verify `USM.Scope ∈ AllowedScopes(LEX.TokenClass)` (see § 7.5).\n\n#### E.10:8.8 - Autonomy lexicon (L‑AUTO )\n**Forbidden (Core):** bare “validity”, “actor/agent” (as free‑standing nouns), “kill switch”, “process” for behavior, “envelope” when used **as scope**.\n**Use instead:** *Scope (G)* for epistemic scope; *WorkScope* for capability bounds; *RoleAssignment* for who acts; *SpeechAct* for overrides; *SafeStop* instead of “kill switch”.\n**Named prefixes (policy & registry):**\n* `aut:` for AutonomyBudgetDecl fields (e.g., `aut:action_tokens`, `aut:risk_bands`);\n* `guard:` for guard checks bound to `AdmissibilityConditionsId`;\n* `ovr:` for override SpeechActs (`ovr:PauseAutonomy`, `ovr:ResumeAutonomy`, …).\n\n**Notes.**\n1) Scope‑sensitive guards **must** declare the **Γ_time** window selector used for admission checks.\n2) Proper names of patterns/components that already include “Agent/Agency” (e.g., *Agency‑CHR*, *Agent‑Tools‑CAL*) are permitted as **titled terms**; avoid re‑introducing “agent” as a free‑standing noun in new prose.\n\n#### E.10:8.9 - LEX-CHR-STRICT — Reserve *Characteristic* for CSLC-measurable aspects\n\n**Intent.** Prevent calling **non-measurable** objects (sets, statuses, scopes, policies, bridges, contexts, guards) “characteristics”.\n\n**Rule L-CHR-S1 (Reservation).** Use **Characteristic** **only** for variables that **declare a CSLC scale** (nominal/ordinal/interval/ratio) with admissible values/units/polarity (Part C.16/A.17–A.18).  \n**Rule L-CHR-S2 (USM).** `U.Scope` / `U.ClaimScope (G)` / `U.WorkScope` are **USM scope objects**, not Characteristics; they **must not** appear in any `CharacteristicSpace`.  \n**Rule L-CHR-S3 (Status).** ESG/RSG statuses and deontic/epistemic statuses — **not Characteristics**; its statuses/states.  \n**Rule L-CHR-S4 (Lexical classifiers).** Lexical classifiers/tags — **Facets**/**attributes**; do not name them as Characteristics, if not declared **CSLC**.\n**Checks.**  \n— **CC-L-CHR-1.** `scope characteristic(s)` is banned in Core/Context.  \n— **CC-L-CHR-2.** `CharacteristicSpace` near `Scope` — error.  \n— **CC-L-CHR-3.** Canonical rewrite: `F–G–R characteristics` → `F–G–R components`.\n\n#### E.10:8.10 - LEX‑QA‑1 — Using “‑ility/‑ilities” terms (availability, reliability, …)\n\n**Rule.** Tokens ending with **‑ility/‑ilities** or widely used quality names (**Availability, Reliability, Security, Safety, Scalability, Maintainability, Usability**, …) are **Quality‑Family labels**, not automatically CHR **Characteristics**.  \n\n**Authoring choice:**  \n— To use such a term as a **CHR** characteristic (axis), **bind** it to a **named `U.Characteristic` with one CSLC Scale** (A.18) and refer to that Characteristic in guards/UTS;  \n— Otherwise **publish a Q‑Bundle** (see **C.25**) that includes **Measures (CHR)** (the measurable slots) and, where relevant, **Scope** (USM set over `U.ContextSlice`) and windows/mechanism/status fields.  \n\n**Rationale.** Scope is **set‑valued** (USM) and **not** a CHR measurement; mechanisms/statuses are governance artefacts. Keeping them outside the CHR CSLC avoids illegal scalarisation and preserves set‑algebra semantics for scope.  (A.2.6 § 6.2; A.6.1; C.16/A.18). \n\n",
        "canonical_rewrites_for_overloaded_words_(lex_l‑rules;_normative)": "### E.10:9 - Canonical rewrites for overloaded words (LEX L‑rules; normative)\n\n> **What this section does.** LEX L‑rules standardise **how we speak** in Core/Context by mapping overloaded everyday words to **canonical FPF concepts**.\n> **What this section does not do.** It does **not** restate naming (see **§ 7 MG-DA**) or morphology/casing/suffix rules (see **§ 8 LEX.Morph**); it **depends** on them.\n> **Guards.** Tokens are classified by **`LEX.TokenClass ∈ {KernelToken, ContextToken, DiscriminatorToken}`** (§ 7.1). Only **CHR:ReferencePlane** may use the bare word *plane*; I/D/S are **layers**; enumerations are **Characteristics** in a **CharacteristicSpace** **only when a CSLC scale is declared; otherwise treat such slots as non-measurable attributes (not Characteristics)**.\n\n#### E.10:9.1 - Hard bans and canonical rewrites (single table; normative)\n\n> **Use this table mechanically.** “Ban” means the weak phrase is **not allowed** in Core prose/identifiers/diagrams unless the **canonical** appears alongside it (or as a registered Context alias). “Layer/Token gates” prevent I/D/S and TokenClass leaks (cf. § 8.1).\n\n| **L‑rule**   | **Weak / ambiguous word (Ban)**                   | **Canonical FPF target(s)**                                                                                                                                                                     | **Layer gate**                                                                       | **TokenClass gate**                         | **Notes**                                                                                            |\n| ------------ | ------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------ | ------------------------------------------- | ---------------------------------------------------------------------------------------------------- |\n| **L‑PROC**   | *process / procedure / function step*             | `U.Method` (abstract way‑of‑doing); `U.MethodDescription` (recipe/notation‑agnostic); `U.Work` (execution); `U.WorkPlan` (schedule)                                                             | I for `Method`; D for `MethodDescription`; run artefact for `Work`; D for `WorkPlan` | Kernel/Context for types; Context for runs  | “Industrial process” as **line role** → model system + `…Role`; chemistry in `Method`/`Dynamics`.    |\n| **L‑FUNC**   | *function*                                        | `U.Capability` (ability/envelope) **or** `U.ServiceClause` (promise) **or** `U.Method` (recipe) **or** `U.Work` (what happened)                                                                       | I for Capability/Service/Method; run for Work                                        | Kernel/Context                              | Never use *function* as a type name in Core.                                                         |\n| **L‑SERV**   | *service* used for team/system/API/ticket/process | `U.ServiceClause` = external **promise** (access + acceptance); providers/consumers are **roles** (`…#ServiceProviderRole`) on systems; API is `accessSpec : MethodDescription`; tickets are `U.Work` | I for Service; D for accessSpec; run for Work                                        | Kernel/Context/Discriminator (per artefact) | “API = service” is forbidden; map per row.                                                           |\n| **L‑SCHED**  | *schedule / plan / calendar* as execution         | `U.WorkPlan` (intent/window) vs `U.Work` (actuals/telemetry)                                                                                                                                    | D vs run                                                                             | Context                                     | Never attach actuals to a plan.                                                                      |\n| **L‑ACT**    | *activity / action / task* as type                | `U.Work` (execution); **steps** belong to `U.MethodDescription` (with `requiredRoles`, capability bounds)                                                                                       | run vs D                                                                             | Context                                     | Reserve verbs: *enact* (role/RSG), *execute* (Work), *actuate* (System), *approve* (SpeechAct Work). |\n| **L‑AGENT**  | *agent / actor / doer* (bare)                     | say “system **bearing** `…Role`”; use `U.AgentialRole` where needed                                                                                                                             | I                                                                                    | Kernel/Context                              | Org titles (Owner/Operator/Reviewer) live as **roles in a Context**.                                 |\n| **L‑OWNER**  | *owner of X* (global)                             | Ownership is a **Role** inside a `U.BoundedContext` (e.g., `OwnerRole:ITIL_2020`); SoD via `⊥`                                                                                                  | I                                                                                    | Context                                     | No global “owner” property in Kernel.                                                                |\n| **L‑CAP**    | *capability* for assignment/recipe/run/promise    | `U.Capability` only = ability with envelope; assignments are `…Role`; recipes `Method/MethodDescription`; runs `Work`; promises `Service`                                                       | I vs D vs run                                                                        | Kernel/Context                              | Holder of a Capability is a `U.System`.                                                              |\n| **L‑DYN**    | *process of diffusion / growth / learning*        | `U.Dynamics` (law/model of change)                                                                                                                                                              | I                                                                                    | Kernel/Context                              | Reserve for uncaused change models.                                                                  |\n| **L‑EVID**   | “paper/dataset proves/ensures”                    | `…#EvidenceRole:Context` on an **Episteme**; claims/scopes/polarity/timespan; provenance from `Work`                                                                                            | D/S                                                                                  | Context/Discriminator                       | Evidence is a **role binding**, not an actor.                                                        |\n| **L‑CTX**    | *context* (fuzzy trope)                           | `U.BoundedContext` (named card)                                                                                                                                                                 | —                                                                                    | Context                                     | Never use “depends on context” in Core; **name** the Context.                                        |\n| **L‑BRIDGE** | cross‑context equivalence “by same label”         | `U.Alignment` **Bridge** with relation kind, CL, loss notes                                                                                                                                     | —                                                                                    | —                                           | Same label ≠ same concept without a Bridge.                                                          |\n\n> **Red/Green pattern (example).** ✗ “The **process** ensures quality.” → ✓ “The **MethodDescription** defines steps; **Work** is **evaluated** against **RequirementRole**.”\n\n\n#### E.10:9.2 - Quick, lintable substitutions (mechanical helpers)\n\n> Editors may auto‑offer these rewrites; accept only if the transformed sentence passes **§ 7 MG-DA** and **§ 8 LEX.Morph** gates.\n\n| **Ban**                         | **Canonical rewrite**                                                                   |\n| ------------------------------- | --------------------------------------------------------------------------------------- |\n| “the process owner approves”    | `SystemX#ApproverRole:Context` **performs a SpeechAct Work** “approve …”                |\n| “the document enforces policy”  | `Policy_vN#RequirementRole:Context` **gates** Work; enforcement = **SpeechAct** + audit |\n| “our service runs nightly jobs” | Nightly **Work** **claimsServiceClause**(BatchProcessing); **Service** defines acceptance     |\n| “the API is the service”        | API = `accessSpec : MethodDescription`; **Service = promise** with acceptance           |\n| “capability assigned to team Y” | Team Y **plays** `Role`; the team (as system) **has Capability** C within envelope E    |\n| “process health green”          | StateAssertion for `ObserverRole`/`Service` KPI **passes** acceptance window            |\n| “function of component A fails” | **Work** performed by `SystemA#Role` **failed** acceptance (observations show …)        |\n| “context is unclear here”       | **Name** the `U.BoundedContext`; else split and Bridge                                  |\n\n\n#### E.10:9.3 - Acceptance tests (LEX‑AC)\n\nA text **passes** LEX if all answers are **Green**:\n\n1. **Context named.** Polysemous terms appear **inside a named `U.BoundedContext`** (or the page declares a local context card).\n2. **Right layer.** I/D/S layer respected: types/roles on I; recipes/docs on D; actuals on runs (cf. § 8.1 gates).\n3. **Promise vs ability vs performance.** `Service` (promise), `Capability` (ability), `Work` (performance) are not conflated.\n4. **No anthropomorphism.** Documents/datasets/models do not “do”; **Systems** do.\n5. **Scheduling hygiene.** No actuals on `WorkPlan`; all actuals live on `Work`.\n6. **Cross‑context reuse.** Any reuse across Contexts cites a **Bridge id** with CL & loss notes.\n7. **MG-DA ok.** New or refactored tokens pass **§ 7 MG-DA** (anchored head noun; collision check; CharacteristicSpace for enums).\n8. **Morphology ok.** Suffix/prefix/casing respect **§ 8 LEX.Morph** (e.g., `…Role`, `MethodDescription`, `Work`, reserved prefixes).\n9. **Banned tokens absent.** No *process/function/task/activity* in Kernel senses; no tooling/file suffixes in Kernel tokens.\n10. **State gating present (when needed).** Readiness is expressed via **RSG state** + **StateAssertion**, not vague “approved/ready”.\n\n\n#### E.10:9.4 - Coordination map (how LEX plugs into the rest of FPF)\n\n* **With E.10.D1 D.CTX (Context discipline).**\n  ULR–CTX‑1: Every Core meaning that can vary **names its `U.BoundedContext`**.\n  ULR–CTX‑2: Same‑spelled labels are **distinct senses** across Contexts; reuse requires a **Bridge** (F.9) with CL & loss notes.\n\n* **With E.10.D2 (I/D/S discipline).**\n  Speak in the **right I/D/S layer**. ULR–IDS‑1..3 apply (types/roles = I; descriptions/specs = D/S; work/state assertions = evaluations/occurrences). Upgrades D→S only when **checkable acceptance** exists.\n\n* **With A.2 / A.15 (Role–Method–Work alignment).**\n  Role = **assignment**; Method = **way‑of‑doing**; MethodDescription = **documented recipe**; Work = **dated occurrence**. Sentences must keep this split.\n\n* **With F‑cluster (Unification) & UTS (F.17).**\n  Harvest in one Context → **SenseCell** → **Concept‑Set row** with relation (`≡/⋈/⊂/⟂`) and losses. UTS is the human‑readable roll‑up.\n\n> **Acts vs tokens.** LEX applies to **tokens**; USM applies to **acts** (mint/rename/use). Conformance: `LEX.TokenClass(t)=c ⇒ USM.Scope(usage) ∈ AllowedScopes(c)` (see § 7.5).\n\n\n#### E.10:9.5 - Conformance checklist (LEX‑CC)\n\n1. **LEX‑CC‑1 (Bans).** Any banned token in Core/Arch fails unless the **canonical** appears (or the token is a registered Context alias).\n2. **LEX‑CC‑2 (Context).** Each polysemous term names its **`U.BoundedContext`**.\n3. **LEX‑CC‑3 (Layer/Morph).** Usage passes **§ 8** gates (suffix/prefix/casing) and I/D/S layer checks.\n4. **LEX‑CC‑4 (Bridge).** Cross‑context reuse cites **Bridge id** and CL; same‑spelled labels without a Bridge are non‑conformant.\n5. **LEX‑CC‑5 (MG-DA).** New tokens pass **MG-DA** tests, including **full‑text collision** and **Reserved‑Names** checks.\n6. **LEX‑CC‑6 (Service & evidence).** Service acceptance computed from **Work**; evidence is an **EvidenceRole** on an **Episteme** with provenance.\n7. **LEX‑CC‑7 (USM compatibility).** For each LexicalAct, `USM.Scope ∈ AllowedScopes(LEX.TokenClass)`.\n\n\n#### E.10:9.6 - Worked micro‑examples (short, cross‑domain)\n\n**Factory.**\n✗ “The **process** failed; the **service** restarted itself.”\n✓ `PLC_17#ObserverRole:PipelineOps` logged **Observations**;\n`CAB_Chair#ApproverRole:ChangeControl` **performed a SpeechAct** “approve restart”;\n`OpsBot#DeployerRole:CD_Pipeline_v7` **executed Work** `RestartRun‑4711` which **claimsServiceClause**(CoolingUtility);\npost‑run **Evaluation** shows the **Service** acceptance **passed**.\n\n**Cloud.**\n✗ “The **process owner** approved; the **API service** deployed.”\n✓ `ProductLead#AuthorizerRole:Rollout_2025` **performed a SpeechAct**;\n`sCG‑Spec_ci_bot#DeployerRole:CD_Pipeline_v7` **performed Work** `Deploy‑F123`;\nAPI = `accessSpec : MethodDescription#REST_v12`; **Service** “Feature Access” declares acceptance; telemetry **Work** shows **fulfilServiceClause**.\n\n**Research.**\n✗ “Dataset X **proves** the theory; the **process** is reproducible.”\n✓ `DatasetX#ModelFitEvidenceRole:Theory_Context` **supports** claim C within scope S;\nreproducibility via **StateAssertions** on `ReplicationEvidenceRole`;\nprocedures are `U.MethodDescription`; re‑runs are **Work**.\n\n\n**Editorial note.**\nThis section **inherits** § 7 **MG-DA** (anchored head nouns; Characteristic/CharacteristicSpace for enums; collision checks) and § 8 **LEX.Morph** (suffix/prefix/casing). It deliberately **omits** their details to avoid duplication.  The only legitimate uses of *plane* in the Core are **CHR:ReferencePlane** and the derived operators **CL^plane** and **Φ_plane**; policy flags MUST NOT introduce new “planes”. To distinguish pre‑operational vs operational states *within* **ReferencePlane=world**, use **WorldRegime ∈ {prep|live}** (formerly `PlaneRegime`).\n",
        "migration_playbook_—_turning_messy_language_into_ulr‑clean_prose_*(informative)*": "### E.10:10 - Migration playbook — turning messy language into ULR‑clean prose *(informative)*\n\n> A pragmatic **three‑pass** routine. Works with plain text, diagrams, or models; no tools required.\n\n#### E.10:10.1 - Pass 0 — *Pre‑flight (2 minutes per page)*\n\n0.1 **Name the Context card** you’re writing in (title, edition, scope note).\n0.2 For every new or renamed token, **declare `LEX.TokenClass`** ∈ {KernelToken, ContextToken, DiscriminatorToken}.\n0.3 Run **MG-DA pre‑check** (anchored head noun; no metaphor heads; if enum → declare its **CharacteristicSpace**).\n0.4 Run **collision/uniqueness**: full‑text grep + Reserved‑Names registry (see § 7). If collides → rename or DRR deprecate.\n\n#### E.10:10.2 - Pass 1 — *Harvest in the Context*\n\n1.1 **Underline overloaded words** (*process, service, function, workflow, ticket, approval, spec, plan,* …).\n1.2 For each, write a **one‑line intent** in Plain register (what object‑of‑talk is meant).\n1.3 Mark any cross‑Context reuse candidates.\n\n#### E.10:10.3 - Pass 2 — *Map to Core anchors (mechanical)*\n\n2.1 Replace underlined words via **§ 9 L‑rules** table:\n • recipe → **`U.Method` / `U.MethodDescription`**\n • scheduled run → **`U.Work` / `U.WorkPlan`**\n • promise → **`U.ServiceClause`**\n • ability → **`U.Capability`**\n • actor‑mask → **`…Role / RoleAssignment`**\n • document/evidence carrier → **`Episteme`** with **`EvidenceRole/RequirementRole`**\n2.2 Apply **LEX.Morph** (§ 8): suffix gates (`…Role/…Work/MethodDescription/Service`), casing, reserved prefixes.\n2.3 Pass **I/D/S layer** check: types/roles on I; recipes/docs on D; actuals on runs.\n2.4 Attach **Context tags** on first use; set **twin labels** (Tech/Plain) in the local Glossary.\n\n#### E.10:10.4 - Pass 3 — *Stitch & publish*\n\n3.1 Add **safe rewrites** for any anti‑patterns you found (use § 9.2 quick table).\n3.2 If sameness is needed across Contexts, create a **Bridge** (F.9) with relation kind, **CL**, and loss notes.\n3.3 Publish a one‑page **UTS** (F.17) for the Context (columns: Context, Tech label, Plain label, Kernel anchor, Warnings).\n3.4 Log a short **DRR** when renames/aliases occur (F.13), linking to grep results that motivated the change.\n\n",
        "ulr_conformance_prompts_*(normative,_concept‑only_questions)*": "### E.10:11 - ULR conformance prompts *(normative, concept‑only questions)*\n\n> Use these **prompts** during review. They reference § 7 (MG-DA) and § 8 (LEX.Morph) instead of repeating them.\n\n1. **Context prompt.** Does each potentially polysemous noun live inside a **named `U.BoundedContext`**?\n2. **Layer prompt.** Is each sentence in the correct **I/D/S layer** (I: type/role; D: description/spec; run: actuals)?\n3. **Token prompt.** For new/renamed tokens, is **`LEX.TokenClass`** declared and consistent with where the token appears?\n4. **Object‑of‑talk prompt.** Does the **head noun** name the object being classified (Role/Method/Service/Work/Context/Characteristic)?\n5. **Morphology prompt.** Do suffix/prefix/casing pass **LEX.Morph** gates (e.g., `…Role`, `MethodDescription`, `Work`)?\n6. **Promise vs ability vs performance.** Are **Service** (promise), **Capability** (ability), and **Work** (performance) distinct?\n7. **Plan vs execution.** Are **WorkPlan** windows separated from **Work** actuals?\n8. **Evidence prompt.** Do documents **hold roles** and **justify**, while **systems act**?\n9. **Bridge prompt.** If sameness spans Contexts, is there an explicit **Bridge** with **CL** and loss notes?\n10. **Collision prompt.** Did we run full‑text + Reserved‑Names checks (no other meaning of this token anywhere in FPF)?\n\n",
        "ulr_regression_cues_*(concept‑only_“diff”_triggers)*": "### E.10:12 - ULR regression cues *(concept‑only “diff” triggers)*\n\nRe‑review your prose when any of these happen:\n\n* **Context edition** changes → re‑affirm twin labels, Bridges, and acceptance wording.\n* **A role/type name grows** (“and/plus/‑‑”) → apply MG-DA: split or bundle (A.2).\n* **A “service” statement broadens scope** → check that **acceptance** terms cover the new target; else split the Service.\n* **Recipes gain/lose steps** → update **`MethodDescription`**, not `Service` or `Role` names.\n* **Evidence verbs creep into actor sentences** → re‑apply L‑rules (documents don’t act).\n* **New token minted** → ensure `LEX.TokenClass` declared; run collision checks; add CharacteristicSpace if enum.\n* **Suffix drift** (e.g., `…Work` on a plan) → fix via **LEX.Morph**.\n* **Cross‑Context reuse by label** appears → require a **Bridge** (F.9) or split senses.\n\n",
        "teaching_deck_—_the_ulr_quick_card_*(reusable_in_any_context)*": "### E.10:13 - Teaching deck — the ULR quick card *(reusable in any Context)*\n\n> **Say it cleanly, once (memorise):**\n> **Role** = assignment (mask) - **Method** = way‑of‑doing - **MethodDescription** = recipe (document) - **Work** = run (dated)\n> **Capability** = can‑do within bounds (envelope + measures) - **Service** = promise (access + acceptance)\n> **I/D/S are layers**; **documents don’t act**; **Contexts own meanings**; **Bridges** move meanings.\n\n**Name forms (allowed morphology):**\n• **Types/roles:** `<Noun><Role/Type>` (`IncidentCommanderRole`, `NormativeStandardRole`, `WorkItemType`).\n• **Statuses:** `<Noun>Status` inside the Context’s role space (`ApprovedStatus`) — status‑only; not enactable.\n• **No suitcase nouns:** avoid “and/plus/&” in names; use **bundles** (A.2) or separate roles.\n• **Acronyms:** first expansion + register; short‑form registered per **§ 7.7**.\n\n",
        "three_worked_micro‑examples_—_ulr_across_domains_*(informative)*": "### E.10:14 - Three worked micro‑examples — ULR across domains *(informative)*\n\n#### E.10:14.1 - Healthcare (OR context)\n\n**Messy:** “The surgical **process** is scheduled at 08:00; the SOP approves the incision and the **service** documents recovery.”\n**ULR rewrite:**\n“**WorkPlan** OR‑Case‑221 starts 08:00 and will execute **MethodDescription** `Incision_v4`.\n`SOP_OR_v4` holds **RequirementRole**; a **SpeechAct Work** by `QA_Officer#ApproverRole` authorises the run.\nThe hospital offers **Service** ‘Post‑op monitoring’ (access = ward protocol; acceptance = vitals envelope).”\n\n#### E.10:14.2 - Manufacturing (assembly line)\n\n**Messy:** “The welding **function** provides air‑tight seams; the **process** costs 3 min.”\n**ULR rewrite:**\n“`Robot_SN789` has **Capability** ‘execute `Weld_MIG_v3` within envelope E at measures M’.\n**Work** instances that **fulfil Service** ‘Provide seam S’ average 3 min; **acceptance** bounds are in `Seal_Acceptance.md`.\nThe **MethodDescription** is `Weld_MIG_v3`; the **Role** is `WelderRole`.”\n\n#### E.10:14.3 - Cloud/SRE (production Context)\n\n**Messy:** “The storage **service** wrote logs and the deployment **process** failed after 2 min.”\n**ULR rewrite:**\n“`sCG‑Spec_ci_bot#DeployerRole:CD_v7` performed **Work** ‘Deploy r4711’ (failed at T+120 s).\nThe platform offers **Service** ‘Object Storage’ (access = `S3_API_Spec_vX`; **acceptance** = durability/availability targets).\n`LogWriter` is a **System** bearing `TransformerRole` that wrote the records; *the service did not act*.”\n\n",
        "closing_notes_*(governance_&_purity)*": "### E.10:15 - Closing notes *(governance & purity)*\n\n* **Notation‑agnostic.** ULR is a **language constitution**, not a scanner or template. Apply it in prose, sketches, or formal models.\n* **Where checks live.** Convenience checks belong to Tooling; ULR itself stays notation‑agnostic. Conformance code lives in **SCR‑LEX / RSCR‑LEX** as referenced above.\n* **Acts vs tokens.** LEX applies to **tokens**; USM applies to **acts** (mint/rename/use). Conformance:\n  `LEX.TokenClass(t)=c  ⇒  USM.Scope(usage) ∈ AllowedScopes(c)` (§ 7.5).\n* **Guards honoured.** DevOps Lexical Firewall and Unidirectional Dependency remain intact.\n* **Reserved “plane”.** Only **`CHR:ReferencePlane`** uses the bare word *plane*; I/D/S are **layers**; all other category talk is expressed as **Characteristics** in a **CharacteristicSpace**.\n\n> **One‑line memory:** *“ULR keeps words honest so ideas stay composable.”*\n\n",
        "e.10:end": "### E.10:End\n  "
      },
      "content": "### E.10:End\n  ",
      "metadata": {},
      "part": "E",
      "cluster": null
    },
    {
      "id": "E.10.P",
      "title": "Conceptual Prefixes policy & registry",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## E.10.P - Conceptual Prefixes policy & registry\n **Intent.** Provide a compact, **notation‑neutral** registry and **minting policy** for *conceptual prefixes* — short shorthands that signal **cognitive namespaces** used throughout the Core.\n\n **Policy (normative).**\n1. **Purpose.** A conceptual prefix exists **to aid reasoning**, not to name files, serialisations, or APIs. It labels a **role in thought** (e.g., meta‑type, calculus operator, relation family).\n 2. **Anchoring.** Every prefix **MUST** be anchored to a **Core architheory**  (CAL/LOG/CHR) or Kernel construct and documented in its *Relations*.\n 3. **No tool lock‑in.** A prefix **MUST NOT** imply a particular notation or machine binding (see E.5.1–E.5.2).\n 4. **Minting rule.** New prefixes are introduced by a **DRR** (E.9) that demonstrates\n    (a) cross‑architheory need, \n    (b) non‑overlap with existing prefixes,\n    (c) alignment with Pillars **P‑1/P‑5**.\n 5. **Scope.** Prefixes are **globally reserved** within the Core; domain plugins  **MAY** mint local shorthands only inside their Contexts and **MUST NOT** collide with this registry.\n\n **Registered conceptual prefixes (Core).**\n* `U.` — **U.Types meta‑namespace** (holons & primitives). *Anchor:* Kernel Part A.\n* `Γ_` — **Calculus operator family** (by flavour: `Γ_sys`, `Γ_epist`, …). *Anchor:* Part B umbrella on Γ.\n* `ut:` — **Universal relation family** (e.g., `PartOf` sub‑relations). *Anchor:* A.14 (Mereology) — informative alias vocabulary.\n* `tv:` — **Trace & Validation vocabulary** (CT2R‑LOG): `tv:AliasOf`, `tv:groundedBy`. *Anchor:* B.3 (Trust & Assurance, LOG‑use). \n* `ev:` — **Evidence hooks** (bindings/roles). *Anchor:* A.10 / B.3 (Evidence Graph Referring).\n* `mero:` — **Mereology trace types** (internal labels: `SumTrace` / `SetTrace` / `SliceTrace`) used **informatively** in examples. *Anchor:* B.1 (Γ‑aggregation).\n\n**Conformance Checklist (E.10.P).**\n* **CC‑LEX‑P.1** New Core text **SHALL NOT** introduce an unregistered conceptual prefix.\n* **CC‑LEX‑P.2** Each occurrence of a registered prefix **SHALL** cite its anchor pattern on first use in a section.\n* **CC‑LEX‑P.3** Examples that expand a prefix into a concrete URI or syntax **MUST** mark the expansion *informative* and locate it in Tooling/Pedagogy.\n\n**Relations.** Constrains E.5.1 (Lexical Firewall) & E.5.2 (Notational Independence); Depends on E.9 (DRR).\n",
        "e.10.p:end": "### E.10.P:End\n  \n## E.10.D1 - Lexical Discipline for “Context” (D.CTX)\n\n> **One‑sentence summary.** Make the word **Context** unambiguous: in FPF it **only** denotes the formal primitive **`U.BoundedContext`**; remove the term **anchor**; reserve **Problem Frame** for situational narrative; treat **Domain** as an **informative family label**, not a type.\n\n**Status.** Discipline definitional pattern, architheory‑agnostic.\n**Depends on.** C‑6 *Strict Distinction*; C‑7 *Temporal Duality*; G‑1 *Minimal Generality*; G‑2 *Contextual Specification*.\n**Coordinates with.** E.10.U1 *Domain‑Family Landscape Survey*; E.10.U2 *Term Harvesting & Normalisation*; E.10.U7 *Concept‑Set Table*; E.10.U9 *Alignment/Bridge*; `RoleAssigning` patterns (e.g., E.10.U4).\n**Aliases (informative).** Context Discipline; No‑Anchor Rule.\n\n",
        "e.10.d1:1___intent_&_applicability": "### E.10.D1:1 - Intent & Applicability\n\n**Intent.** Eliminate ambiguity around “context” by (a) fixing **one** formal meaning—`U.BoundedContext`; (b) removing “anchor” from the vocabulary; (c) reserving **Problem Frame** for prose about situations; and (d) clarifying **Domain** as an **informative family** (workflow, provenance, services, …) that groups several `U.BoundedContext`s.\n\n**Applicability.** Mandatory across **all architheories** (Role Assignment & Enactment, Sys-CAL, KD-CAL, Kind-CAL, planned LCA-CAL). Apply at the start of any unification effort and whenever documentation introduces or refactors “context”, “domain”, “anchor”.\n\n**Non‑goals.** No governance, workflow, or tool mandates; no storage formats; no team roles.\n\n",
        "problem": "### E.10.D2:2 - Problem\n\n1. **Plane/layer mixing.** Intensions are routinely conflated with their documents and with runtime facts.\n2. **Name drift.** “Spec” gets used for any write‑up; “status” drifts between states of a role and epistemic/deontic statuses over knowledge units.\n3. **Didactic friction.** Inconsistent naming raises cognitive load and impedes reuse across architheories.\n4. **Unverifiable claims.** Without a clear gate to **–Spec**, normative wording appears without testability.\n",
        "forces": "### E.10.D2:3 - Forces\n\n| Force                        | Tension to resolve                                                                |\n| ---------------------------- | --------------------------------------------------------------------------------- |\n| **Simplicity vs rigour**     | Easy‑to‑learn naming vs the need for machine‑checkable invariants.                |\n| **Universality vs locality** | Kernel intensions must be universal; language and criteria are **Context‑local**. |\n| **Stability vs evolution**   | Names should be stable; artefacts must mature via **ΔF** along the **F** ladder cleanly. |\n",
        "solution": "### E.10.D2:4 - Solution — the I/D/S layer + a formal Spec‑gate\n\n#### E.10.D2:4.1 The triad (applies to **any** intensional `U.T`)\n\n**Terminology discipline (normative).** Say **I/D/S layers** when you mean the **stratified order with a Spec‑gate**; say **I/D/S triad** only to note **three‑ness without order or dependency**. **Do not call I/D/S a “plane”.** Reserve **plane** for uses explicitly defined elsewhere (e.g., **`CHR:ReferencePlane`** and status families).\n**Layer semantics (clarity).** **I‑layer** = **kernel/intensional type** (non‑epistemic; **not** a episteme) . **D‑layer** and **S‑layer** = **epistemic Knowledge Units** (KUs). The **Spec‑gate** upgrades a Description to a Specification only under declared checkability and harness conditions (unchanged).\n\nFor every intensional type `U.T`:\n\n* **Intension — `U.T`.**\n  The thing itself (e.g., `U.Role`, `U.Method`, `U.ServiceClause`, `U.System`, `U.Work`, `U.RCS`, `U.RSG`).\n  *It does **not** contain documents, checklists, or carriers; it is not a runtime event or a file.*\n\n* **Description episteme — `U.TDescription(@Context)`**\n  A **Context‑local** knowledge unit that **characterises** `U.T` with labels (Tech/Plain), glosses, and, when applicable, **Role Characterisation Space (`U.RCS`)**, **Role State Graph (`U.RSG`)**, and **state conformance checklists**.\n  *Readable, precise, didactic; may reference evaluation criteria but does not assert testable “shall”s by itself.*\n\n* **Specification episteme — `U.TSpec(@Context)`**\n  A **Context‑local** knowledge unit that states **testable invariants** for `U.T` and is **bound to an acceptance harness**.\n  *Normative, verifiable, suitable for SCR/RSCR (F.15).*\n\n> **Key phrasing discipline.** Intensions are **characterised by** (not “contain”) RCS/RSG/checklists, which **live in** the Description/Spec.\n> **Terminology guard.** To avoid collisions with **ReferencePlane** and other semantic planes, the I/D/S triad is referred to as **I/D/S Layers** (Intension Layer - Description Layer - Specification Layer). The word **plane** is reserved for **semantic planes** (Role/Status/Measurement/Type‑structure/Method/Work, etc.) and for the **ReferencePlane** field used in describedEntity/assurance.\n\n#### E.10.D2:4.2 The Spec‑gate (when “–Spec” is allowed)\n\nUse the **–Spec** suffix **only if all** of the following hold:\n\n1. **Formality F (C.2.3):** the artefact declares **F ≥ F4** (or a context-defined higher threshold) so predicates are checkable.\n2. **Verifiability:** invariants are stated as checkable predicates or thresholds.\n3. **Harness bound:** there is a linked **acceptance harness** (SCR/RSCR matrices per F.15).\n4. **Context anchoring:** all wording is explicitly local to a named `U.BoundedContext` (E.10.D1).\n\nIf any condition is missing, the artefact **must be** a `…Description`.\n\n#### E.10.D2:4.3 Where RCS/RSG and evaluations sit\n\n* **`U.RCS` (Role Characterisation Space)** and **`U.RSG` (Role State Graph)** are **intensional** types that structure the space of role characteristics and permissible state transitions.\n* Their **human presentation** (characteristics, dimensions, node labels, admissible transitions) lives in the **RoleDescription**, and becomes part of **RoleSpec** only when the transitions and state predicates are made **testable** and harness‑bound.\n* **`U.Evaluation`** operates on **evidence** against the conformance checklist (from the Description/Spec) to produce a **state attestation** (“X is in state S @Context within window W”).\n* **Epistemic/deontic statuses** (e.g., *Evidence*, *Requirement*, *Standard*) are **roles over Epistemes** (not states of the role). They are governed elsewhere (F‑R family) and must not be conflated with `U.RSG` state names.\n\n#### E.10.D2:4.4 Plain‑language memory hook\n\n> *Thing vs words vs rules.*\n> **The thing** (`U.Role`, `U.Method`) is clean and abstract.\n> **The words** (labels, glosses, RCS/RSG pictures, checklists) live in the **Description**.\n> **The rules** (testable “shall”s with harness) live in the **Specification**.\n> If you can’t test it, don’t call it **Spec**.\n",
        "e.10.d1:5___structure_—_minimal_reference_shapes_(informative)": "### E.10.D1:5 - Structure — Minimal reference shapes (informative)\n\n> Shapes shown **do not** prescribe formats; they are naming conventions.\n\n* **Context Id.** Stable short handle (e.g., `BPMN_2_0`, `PROV_O_2013`, `ITIL4_2020`, `NIST_RBAC_2004`, `SOSA_SSN_2017`).\n* **SenseCell.** `(ContextId, Local‑Sense)` where `Local‑Sense` is the Context‑local preferred label (from E.10.U2).\n* **ConceptSet Row.** A table row keyed by a row id; columns are `SenseCell`s per Context (E.10.U7).\n\n",
        "e.10.d1:6___core_invariants_(normative)": "### E.10.D1:6 - Core Invariants (normative)\n\n1. **LCTX‑INV‑1 (Uni‑meaning).** The word **Context** in formal text equals **`U.BoundedContext`**.\n2. **LCTX‑INV‑2 (No anchor).** The token **anchor** does **not** appear in normative prose; use **SenseCell** or **ConceptSet reference**.\n3. **LCTX‑INV‑3 (No domain contexts).** “Domain context” is invalid; use **Domain family** + list of `U.BoundedContext`s.\n4. **LCTX‑INV‑4 (Frames, not contexts).** Pattern headers use **Problem Frame** for narrative.\n5. **LCTX‑INV‑5 (No hierarchy).** Contexts are flat; relationships are declared **only** via E.10.U9 Bridges.\n6. **LCTX‑INV‑6 (Plane hygiene).** Contexts describe **context of meaning** for sources; they are not roles, statuses, executions, or types (C‑6).\n7. **LCTX‑INV‑7 (Time tags).** DesignRunTag is a **tag** on artefacts/sources; it does not multiply contexts.\n8. **LCTX‑INV‑8 (Language/edition).** Multilingual or multi‑edition handling follows D‑CTX‑7.\n\n",
        "conformance_checklist": "### E.10.D1:7 - Conformance Checklist (normative)\n\n* **CC‑LCTX‑1.** Grep‑style check: every “Context” in formal sections expands to **`U.BoundedContext`**.\n* **CC‑LCTX‑2.** The token **anchor** is absent from normative text; where needed, occurrences are replaced by **SenseCell** or **ConceptSet reference**.\n* **CC‑LCTX‑3.** Pattern headers use **Problem Frame**; none use “Context” for narrative.\n* **CC‑LCTX‑4.** References to meaning are in one of the **reference forms** (Sec. 5).\n* **CC‑LCTX‑5.** No file defines “domain context”; Domain appears only as an **informative family**.\n* **CC‑LCTX‑6.** No is‑a edges between contexts; any cross‑context relation is located in **E.10.U9**.\n* **CC‑LCTX‑7.** Language/edition handling matches **D‑CTX‑7** (separate Contexts when semantics can diverge).\n\n",
        "e.10.d1:8___anti‑patterns_&_remedies": "### E.10.D1:8 - Anti‑patterns & Remedies\n\n| Anti‑pattern                  | Symptom                                                           | Why harmful                          | Remedy (normative)                                                           |\n| ----------------------------- | ----------------------------------------------------------------- | ------------------------------------ | ---------------------------------------------------------------------------- |\n| **A1 Context-as-situation**   | “Context” used for narrative sections                             | Ambiguity                            | Use **Problem Frame**; reserve Context for `U.BoundedContext` (D‑CTX‑4).     |\n| **A2 Anchor-speak**           | “role anchor”, “ontology anchor”                                   | Redundant token; hides locality      | Replace with **SenseCell** or **ConceptSet(Row).Column** (D-CTX-2, D-CTX-8). |\n| **A3 Domain context**         | “Workflow domain context”, etc.                                   | Family ≠ formal context              | Use **Domain family** + explicit list of Context ids (D‑CTX‑3).              |\n| **A4 Context hierarchy**      | Context A “is‑a” Context B                                        | Leaks meanings; blocks loss policies | Remove hierarchy; use **E.10.U9 Bridge** with loss policy (D‑CTX‑6).         |\n| **A5 Time‑as‑context**        | “Runtime context” vs “Design context”                             | Multiplies Contexts incorrectly         | Use **TimeScope tags** (C‑7); keep one Context (D‑CTX‑5).                    |\n| **A6 Cross‑lingual blending** | Mixing language labels as one context despite divergent semantics | Hidden drift                         | Split Contexts per **D‑CTX‑7** or document shared semantics if truly bound.  |\n\n",
        "e.10.d1:9___worked_examples_(multi‑architheory)": "### E.10.D1:9 - Worked Examples (multi‑architheory)\n\n#### E.10.D1:9.1 Enactment — process vs activity (two context of meaning).\n\n* Use `BPMN_2_0:process` and `PROV_O_2013:activity` as **SenseCell**s.\n* In a Concept‑Set row, code the provisional relation `⋈` (overlap), not an equality.\n* Role Descriptions later reference **the specific SenseCell**, not “an anchor”.\n\n#### E.10.D1:9.2 Roles — behavioural mask vs access status.\n\n* `BPMN_2_0:participant` vs `NIST_RBAC_2004:role`.\n* Mark `⟂` (incompatible) in the Concept‑Set row to prevent conflation.\n* Any cross‑use requires E.10.U9 with explicit loss policy.\n\n#### E.10.D1:9.3 Services & evidence.\n\n* `ITIL4_2020:service` / `ITIL4_2020:service‑level‑objective` with KD‑CAL cells `SOSA_SSN_2017:observation`.\n* References in acceptance patterns point to **SenseCell**s; provenance stays within the PROV Context.\n\n",
        "e.10.d1:10___reasoning_primitives_(conceptual_judgements;_notation‑agnostic)": "### E.10.D1:10 - Reasoning Primitives (conceptual judgements; notation‑agnostic)\n\n> Pure **thinking moves**; no APIs, no storage, no governance.\n\n* **(J1) Context expansion.** `⊢ Context ≡ U.BoundedContext`\n  *Reading:* wherever “Context” appears in formal prose, it denotes `U.BoundedContext`.\n\n* **(J2) Anchor ban.** `uses(\"anchor\") ⊢ violation(D‑CTX‑2)`\n  *Reading:* usage of “anchor” flags a discipline violation.\n\n* **(J3) Sense reference.** `ref(ContextId, LocalLabel) ⊢ SenseCell(ContextId, Local‑Sense)`\n  *Reading:* a well‑formed reference identifies a SenseCell.\n\n* **(J4) Narrative frame.** `header(\"Context\") ⊢ replaceWith(\"Problem Frame\")`\n  *Reading:* headings “Context” in patterns must become “Problem Frame”.\n\n* **(J5) Domain family.** `label ∈ {workflow,…} ⊢ DomainFamily(label)`\n  *Reading:* Domain labels are families, not contexts.\n\n* **(J6) Time tag.** `stance ∈ {design, run} ⊢ TimeScopeTag(stance)`\n  *Reading:* time is a tag, not a new context.\n\n",
        "relations": "### E.10.D2:10 - Relations (with other patterns)\n\n**Builds on:**\n\n* **E.10.D1 — Lexical Discipline for “Context” (D.CTX).** Provides the *Context* primitive and bans “anchor” talk.\n* **A.7 — Strict Distinction (Clarity Lattice).** This pattern concretises SD for intension vs description/spec vs carrier vs work.\n* **C.2.3 — Unified Formality Characteristic (F).** Supplies the **F** anchors and **ΔF** moves that gate `…Spec`.\n\n**Constrains:**\n\n* **F.1–F.3 (Contexts → seeds → local senses).** Descriptions **must** cite context‑local senses (SenseCells) rather than global words.\n* **F.4–F.5 (role/service naming).** Tech/Plain labels on Descriptions obey F.5 morphology rules.\n* **F.8 (Service Acceptance Binding).** Evaluations of services read acceptance **from Description/Spec**, compare against Observations.\n* **F.9 (Alignment & Bridge).** No Description/Spec may imply Cross‑context equivalence; Bridges carry all Cross‑context semantics.\n* **F.15 (SCR/RSCR Harness).** Any `…Spec` must link to its harness; RSCR re‑checks verdict stability across editions/windows.\n\n**Is used by.**\n\n* **Part C architheories.** Sys‑CAL, KD‑CAL, Kind-CAL, Method‑CAL cite `…Description/…Spec` epistemes explicitly and consume **state attestations** from `U.Evaluation`.\n* **Part B trust calculus.** Uses the presence/absence of harnessed Specs and the windowed nature of attestations in confidence roll‑ups.\n",
        "e.10.d1:12___migration_notes_(conceptual_playbook)": "### E.10.D1:12 - Migration Notes (conceptual playbook)\n\n1. **Rename headings.** Replace any “Context” section title with **Problem Frame**.\n2. **Delete “anchor”.** Replace with **SenseCell** or **Concept‑Set** references.\n3. **Split domain vs context.** Where “domain context” appears, rewrite as **Domain family** + explicit list of `U.BoundedContext`s.\n4. **Audit references.** Ensure every semantic reference is `ContextId:LocalLabel` or `SenseCell(ContextId, …)` or Concept‑Set column.\n5. **Flatten contexts.** Remove any inheritance among contexts; move relations to **E.10.U9**.\n6. **Tag time.** Replace “design/runtime context” with **TimeScope tags**.\n7. **Language/edition pass.** Split or merge Contexts per **D‑CTX‑7**; document rationale.\n\n",
        "e.10.d1:13___acceptance_tests_(scr/rscr_stubs)": "### E.10.D1:13 - Acceptance Tests (SCR/RSCR stubs)\n\n**SCR — Static discipline checks**\n\n* **SCR‑DCTX‑S01.** No occurrence of the token **anchor** in normative sections.\n* **SCR‑DCTX‑S02.** All formal uses of “Context” resolve to **`U.BoundedContext`**.\n* **SCR‑DCTX‑S03.** Pattern headers contain **Problem Frame** instead of “Context”.\n* **SCR‑DCTX‑S04.** All semantic references use the forms in Sec. 5.\n* **SCR‑DCTX‑S05.** No “domain context” strings; Domain appears only as family metadata.\n* **SCR‑DCTX‑S06.** No is‑a or containment relations between contexts outside **E.10.U9**.\n\n**RSCR — Regression discipline checks**\n\n* **RSCR‑DCTX‑E01.** Adding a new family or edition does not introduce “domain context” or context hierarchies.\n* **RSCR‑DCTX‑E02.** Refactors of E.10.U1/U.2/U.7/U.9 do not re‑introduce “anchor”.\n* **RSCR‑DCTX‑E03.** Multilingual updates follow D‑CTX‑7 (split/merge rationale recorded informatively).\n",
        "e.10.d1:end": "### E.10.D1:End\n  \n## E.10.D2 - Intension–Description–Specification Discipline (I/D/S)\n\n*Definitional pattern — normative, notation‑agnostic*\n\n> **One‑sentence summary.** For every intensional FPF object (e.g., `U.Role`, `U.Method`, `U.System`, `U.Work`, `U.ServiceClause`), clearly distinguish the **thing itself** (*Intension*), its **context‑bound Description** (KU), and its **formal Specification** (KU). Use **–Spec** only when strict, testable invariants and an acceptance harness exist; otherwise use **–Description**. This keeps semantics clean, didactic, and testable across all architheories.\n\n**Status.** Definitional pattern, architheory‑agnostic.\n**Builds on:** A.7 **Strict Distinction (Clarity Lattice)**; E.10.D1 **D.CTX (Context ≡ U.BoundedContext)**; C.2.1 **U.EpistemeSlotGraph (DescriptionContext, IDS‑13)**; C.2.3 **Unified Formality Characteristic (F)**.\n**Coordinates with.** F.4 **Role Description**; F.5 **Naming Discipline**; F.10 **Evaluation**; F.15 **SCR/RSCR Harness**.\n**Non‑goals.** No editors, workflows, registries, or storage formats. No tooling commitments.\n",
        "e.10.d2:5___minimal_vocabulary_&_naming_discipline_(this_pattern_only)": "### E.10.D2:5 - Minimal vocabulary & naming discipline (this pattern only)\n\n**Core trio (per intensional `U.T`).**\n\n* **`U.T` — the Intension.**\n  Kernel object (e.g., `U.Role`, `U.Method`, `U.ServiceClause`, `U.System`, `U.Work`, `U.RCS`, `U.RSG`).\n  *Never* a document, *never* an event, *never* a file.\n\n* **`U.TDescription(@Context)` — the Description Episteme.**\n  Context‑local characterisation of `U.T`: Tech/Plain labels, gloss, notes; for roles, may **characterise** with an `U.RCS` (characteristics/traits), an `U.RSG` (states/transitions), and **state conformance checklists** (per state). *Readable; precise; not yet a set of testable “shall”s.*\n\n* **`U.TSpec(@Context)` — the Specification Episteme.**\n  Context‑local, **testable** invariant set for `U.T`, explicitly **bound to an acceptance harness** (SCR/RSCR matrices per F.15). Use **–Spec** only through the Spec‑gate (Sec. 4.2).\n\n**Suffix rules.**\n\n* Use **`…Description`** by default (M‑mode or F‑mode without harness).\n* Use **`…Spec`** *only* when **all** Spec‑gate conditions (Sec. 4.2) hold.\n* No alternative suffixes (“Profile”, “Definition”, “Guide”) inside the Core; such epistemes live in pedagogy/tooling layers, not in the I/D/S discipline.\n\n**Naming morphology (recap of F.5 as it applies here).**\n\n* Two registers: **Tech** and **Plain** labels on every Description/Spec.\n* Roles use **count nouns** (e.g., *Operator*); states use **state nouns** (e.g., *Approved*).\n* Statuses over knowledge (e.g., Evidence/Requirement) are **not** role states; they name **roles over Epistemes** (F‑R family), not nodes in `U.RSG`.\n\n**Context anchoring.**\nEvery Description/Spec is **local to** a `U.BoundedContext` (E.10.D1). Phrases in the episteme must read correctly once prefixed by the Context name (e.g., “(ITIL4) Acceptance criteria …”).\n\n**Carriers.**\n`U.Carrier` holds **encodings** of a Description/Spec; the Episteme’s identity is **not** the file. *Never* say “the role contains the checklist in the PDF”; say “the **RoleDescription** characterises the role with checklists; this **carrier** encodes them.”\n\n**Time stance.**\nDescriptions/Specs must declare DesignRunTag when inherent (e.g., RoleDescription is design‑time; state attestation via `U.Evaluation` is run‑time).\n",
        "e.10.d2:6___invariants_(normative)": "### E.10.D2:6 - Invariants (normative)\n\n**IDS‑1 (Plane purity).**\nAn intensional `U.T` **MUST NOT** be conflated with its Description/Spec or with any `U.Carrier` or `U.Work`.\n\n**IDS‑2 (Context locality).**\nEvery `…Description/…Spec` **MUST** name a `U.BoundedContext`. Wording inside is read **as‑local**; no global meaning is implied.\n\n**IDS-3 (Spec-gate).**\nA episteme **MUST NOT** use the **–Spec** suffix unless: *(a)* the artefact declares **`U.Formality = Fk` with k ≥ 4** per **C.2.3**, *(b)* invariants are testable predicates, *(c)* an acceptance harness is linked (F.15), *(d)* Context is explicit.\n\n**IDS‑4 (Characterisation verbs).**\nTexts **MUST** say: *“`U.Role` is **characterised by** `U.RCS`/`U.RSG` in the RoleDescription”*.\nThey **MUST NOT** say: *“the role **contains** the RCS/RSG”*.\n\n**IDS‑5 (RCS/RSG scope).**\n`U.RCS`/`U.RSG` are **intensional structures**. Their **presentations** (characteristics, state names, admissible transitions, checklists) live in the **RoleDescription**, and in **RoleSpec** only when transitions and state predicates are fully testable.\n\n**IDS‑6 (Evaluation semantics).**\n`U.Evaluation` **MUST** operate over evidence against conformance checklists from the Description/Spec and **MUST** produce a **state attestation** (who/what is in state *S* @Context within window *W*). Evaluation **does not** mutate the intensional object.\n\n**IDS‑7 (Status separation).**\nEpistemic/deontic statuses (Evidence/Requirement/Standard) are roles over **knowledge units**; they **MUST NOT** be used as state names in `U.RSG`.\n\n**IDS‑8 (Register discipline).**\nEvery Description/Spec **SHOULD** include both **Tech** and **Plain** labels. Symbolic aliases are optional and informative.\n\n**IDS‑9 (No stealth bridges).**\nDescriptions/Specs **MUST NOT** import meanings from other Contexts by shared labels. Cross‑context relations exist only as **F.9 Bridges**.\n\n**IDS‑10 (Window honesty).**\nWhen an evaluation is time‑bounded, the **window** **MUST** be stated in the attestation.\n\n**IDS‑11 (Ladder clarity).**\nA Description may mature into a Spec by satisfying IDS‑3; the opposite move requires a rationale (loss of testability) and must drop the **–Spec** suffix.\n\n**IDS‑12 (Didactic bound).**\nA RoleDescription **SHOULD** fit on one screen per state graph plus one screen of notes; sprawling documents belong to pedagogy, not to the core Description.\n",
        "e.10.d2:7___reasoning_primitives_(judgement_schemas,_notation‑free)": "### E.10.D2:7 - Reasoning primitives (judgement schemas, notation‑free)\n\n> Judgements are **mental moves**—they assert what follows when premises hold. They do **not** imply queries, storage, or workflows.\n\n1. **Description link (with DescriptionContext)**\n\n   ```\n   U.T, C, Vp ⊢ isDescriptionOf(TDesc, U.T, C, Vp)\n   ```\n\n   *Reading:* `TDesc` is the Context‑local Description of `U.T` in Context `C` under Viewpoint `Vp`. Its `subjectRef` decodes to `DescriptionContext = ⟨DescribedEntityRef(U.T), C, Vp⟩` (IDS‑13, C.2.1 §6.1).\n\n2. **Spec link (Spec‑gate, viewpoint‑local)**\n\n   ```\n   isDescriptionOf(TDesc, U.T, C, Vp) ∧ U.Formality(TSpec) ≥ F4\n      ∧ testableInvariants(TSpec) ∧ harnessBound(TSpec)\n      ∧ sameDescriptionContext(TSpec, TDesc)\n      ⊢ isSpecOf(TSpec, U.T, C, Vp)\n   ```\n\n   *Reading:* Only when F‑mode, testability, harness, and a matching `DescriptionContext` are present may we judge `TSpec` a Specification of `U.T` in `C` under Viewpoint `Vp`.\n\n3. **Role characterisation**\n\n  ```\n   isDescriptionOf(RoleDesc, U.Role, C, Vp)\n   ∧ characterises(RoleDesc, U.RCS) ∧ characterises(RoleDesc, U.RSG)\n   ⊢ characterisedBy(U.Role, {U.RCS, U.RSG}) @C\n  ```\n\n   *Reading:* The role is *characterised by* the RCS/RSG as presented in the Description (which is pinned to `(C, Vp)`), not that it “contains” them.\n\n4. **State conformance predicate**\n\n   ```\n   checklistFor(RoleDesc, state S) = χ\n   ∧ evidence E within window W\n   ⊢ conformsToState(E, χ, W) ⇒ attestation(subject ∈ S @C, W)\n   ```\n\n   *Reading:* Evidence satisfies the checklist for state `S`, yielding a state attestation.\n\n5. **Transition admissibility**\n\n   ```\n   U.RSG allows (S → S') @C\n   ∧ attestation(subject ∈ S @C, W)\n   ∧ conformsToState(E', checklistFor(S'), W')\n   ⊢ admissibleTransition(subject : S → S' @C)\n   ```\n\n   *Reading:* A move from `S` to `S'` is admissible when RSG permits it and `S'` is satisfied.\n\n6. **Status / state separation guard**\n\n   ```\n   statusOverKU(KU, σ) ∧ stateInRSG(ρ)\n   ⊢ σ ≠ ρ  (distinct planes)\n   ```\n\n   *Reading:* A status over a knowledge unit is not a role‑state.\n\n7. **No Cross‑context import**\n\n   ```\n   isDescriptionOf(TDescA, U.T, CA, VpA) ∧ isDescriptionOf(TDescB, U.T, CB, VpB) ∧ CA≠CB\n   ⊢ ¬equateByLabel(TDescA, TDescB)  (bridges required in F.9)\n   ```\n\n   *Reading:* Identical wording across Contexts (and Viewpoints) does not grant equivalence; only Bridges may relate them.\n",
        "e.10.d2:8___anti‑patterns_&_remedies": "### E.10.D2:8 - Anti‑patterns & remedies\n\n| ID   | Anti‑pattern                | Symptom                                                              | Why it harms thinking                     | Remedy (concept move)                                                                          |\n| ---- | --------------------------- | -------------------------------------------------------------------- | ----------------------------------------- | ---------------------------------------------------------------------------------------------- |\n| A‑1  | **Spec‑by‑name**            | Every write‑up is titled “Spec”.                                     | Inflates normativity; untestable claims.  | Apply **Spec‑gate** (IDS‑3). If any condition fails, rename to `…Description`.                 |\n| A‑2  | **Role contains RSG**       | “The role contains a state graph.”                                   | Plane mixing; mereological confusion.     | Use **characterised by** phrasing (IDS‑4); RSG presentation lives in RoleDescription/RoleSpec. |\n| A‑3  | **Status ≡ state**          | *Approved* (status over episteme)  appears as a node in the role graph.     | Cross‑plane conflation; logic errors.     | Keep **statuses** (over Epistemes) separate from **role states** (IDS‑7).                            |\n| A‑4  | **Stealth bridge**          | Copying state names across Contexts to imply sameness.                  | Hidden cross‑context import.              | Declare an **F.9 Bridge** or accept divergence (IDS‑9).                                        |\n| A‑5  | **Checklist = process**     | Treating conformance checklist as an execution workflow.             | Category error (design vs run).           | Checklists are **criteria** used by `U.Evaluation`; executions live under `U.Work`.            |\n| A‑6  | **Carrier identity**        | File path/version treated as “the spec itself.”                      | Identity drift; archival brittleness.     | Identity is the **KU**; `U.Carrier` is only an encoding (Sec. 5).                              |\n| A‑7  | **Windowless verdict**      | Attestations omit time window.                                       | Unreproducible results; stale judgements. | Require **window** in attestation (IDS‑10).                                                    |\n| A‑8  | **Over‑formal Description** | Description bloats into a standard; unreadable.                      | Violates didactics; blocks adoption.      | Enforce **one‑screen** discipline (IDS‑12); move exegesis to pedagogy.                         |\n| A‑9  | **Spec without harness**    | “Shall” statements with no linked acceptance matrices.               | Unverifiable normativity.                 | Bind to **SCR/RSCR harness** (F.15) or downgrade to Description (IDS‑3).                       |\n| A‑10 | **Global language leakage** | Description reads as universal definition rather than Context‑local. | Breaks locality; fuels conflicts.         | Prefix mentally with the Context; rewrite locally (IDS‑2).                                        |\n",
        "e.10.d2:9___worked_examples_(multi‑architheory,_didactic)": "### E.10.D2:9 - Worked examples (multi‑architheory, didactic)\n\n> Each vignette shows **intension ↔ Description/Spec ↔ Evaluation** with **context‑local** wording. No workflows; only thinking moves.\n\n#### E.10.D2:9.1 - Enactment (Role Assignment & Enactment line) — *Change Authority* role (ITIL 4 Context)\n\n**Contexts.** `ITIL4_2020` (services/deontics), `PROV_O_2013` (run‑time traces).\n**Intension.** `U.Role :: ChangeAuthority` — a behavioural mask that may be worn by a system (person/team/tool) to **authorise** a change.\n\n**RoleDescription\\@ITIL4.**\n\n* **Tech/Plain.** *ChangeAuthority* / “change approver”.\n* **RCS (characteristics).** CredentialLevel ∈ {L1,L2}; Scope ∈ {Service, Platform}; SeparationOfDuty ∈ {Clean, Violates}.\n* **RSG (states).** `Proposed → Designated → Authorized → Active → Suspended → Revoked`.\n* **State checklists (sketch).**\n\n  * *Authorized:* { valid nomination, SoD=Clean, credential ≥ required, mandate window set }.\n  * *Active:* *Authorized* ∧ { current shift/roster entry ∧ no conflicting active duty }.\n\n**Evaluations.**\n`U.Evaluation@ITIL4` over evidence (roster entries, mandate doc, SoD list, PROV Activities of approvals) yields **attestations**:\n\n* `subject=Team‑X ∈ Authorized@ITIL4 in ⟨2025‑08‑01, 2025‑12‑31⟩`.\n* Later, `subject=Team‑X ∈ Active@ITIL4 at 2025‑09‑14T10:05Z`.\n\n**Didactic hooks.**\n\n* The **role** is *characterised by* RCS/RSG in the **RoleDescription**; it **does not contain** them.\n* The **attestation** is a statement about state‑in‑window; it does **not** mutate the role.\n\n#### E.10.D2:9.2 - Method (Essence‑language Context) — *Backlog Refinement* method\n\n**Contexts.** `OMG_Essence_Language_2023` (method language), `PROV_O_2013` (runtime).\n**Intension.** `U.Method :: BacklogRefinement`.\n\n**MethodDescription\\@Essence.**\n\n* **Tech/Plain.** *BacklogRefinement* / “tidy backlog”.\n* **Inputs/Outputs (informative).** Work items (ideas) → clarified items (ready/not‑ready tags).\n* **RCS (characteristics).** Cadence ∈ {weekly, continuous}; CollaborationMode ∈ {sync, async}.\n* **RSG (states).** `Sketched → Defined → Adopted`.\n* **State checklist (Adopted).** { team agreed practice note exists, cadence set, entry/exit criteria published }.\n\n**Spec‑gate outcome.**\nNo acceptance harness yet → remains **MethodDescription**, **not** MethodSpec.\n\n**Run‑time echo.**\n`U.Work` instances (calendar sessions, chat threads) are traced in PROV; **Evaluation** can check whether an *Adopted* practice is being followed in window W without ever reifying the method as a workflow.\n\n#### E.10.D2:9.3 - Service (SLO/SLA) — *Calibration Service* (ITIL 4 + SOSA/SSN Contexts)\n\n**Contexts.** `ITIL4_2020` (service), `SOSA_SSN_2017` (observation), `ISO_80000_1_2022` (units).\n**Intension.** `U.ServiceClause :: CalibrationService`.\n\n**ServiceDescription\\@ITIL4.**\n\n* **Tech/Plain.** *CalibrationService* / “we calibrate your sensor”.\n* **Acceptance facet (informative).** *SLO: error ≤ 0.5% FS under ISO 80000 units*; **formal criteria live in** ServiceSpec only if harness exists.\n\n**Evaluation\\@ITIL4+SOSA.**\nObservations (SOSA) from test runs compared with thresholds → **ServiceEvaluation** attests *Met/Not‑Met* in a stated window.\nNo Cross‑context import: ISO units cited **as context‑local** references.\n\n#### E.10.D2:9.4 - Epistemic (KD‑line) — *Evidence status vs role state*\n\n**Contexts.** `PROV_O_2013` (provenance), `FPF_Evidence_Status` (status family).\n**Intensions.** `U.KnowledgeUnit :: Report_42`; `U.EvidenceStatus :: SupportsClaim`.\n\n**Separation.**\n\n* `SupportsClaim@C` is a **status over a Episteme** (classifies the report).\n* It is **not** a node of any role’s `U.RSG`.\n* `U.Evaluation` produces `attestation(Report_42 has EvidenceStatus=SupportsClaim@C, W)`.\n\n**Didactic point.**\nState names in *role* graphs do not duplicate **statuses**; planes stay disjoint.\n\n#### E.10.D2:9.5 - Control (Sys‑CAL line) — *Control‑Operator* role (IEC 61131‑3 Context)\n\n**Contexts.** `IEC_61131_3` (control languages), `ISA_95` (integration).\n**Intension.** `U.Role :: ControlOperator`.\n\n**RoleDescription\\@IEC61131‑3.**\n\n* **RCS.** StationLevel ∈ {Cell, Line}; TaskMode ∈ {Cyclic, Event}; AlarmPrivileges ∈ {Ack, Ack+Shelve}.\n* **RSG.** `Onboarded → Authorized → ConsoleActive → Paused → Suspended`.\n* **Checklists (ConsoleActive).** { Authorized ∧ current console login ∧ task watchlist loaded }.\n\n**Attestation (run‑time).**\n`subject=Operator‑A ∈ ConsoleActive@IEC at 2025‑09‑14T08:00Z` based on log evidence.\nNo “workflow” required in the Description.\n",
        "e.10.d2:11___migration_notes_(conceptual_refactor_playbook)": "### E.10.D2:11 - Migration notes (conceptual refactor playbook)\n\n> Goal: remove conflations and normalise names without changing underlying models.\n\n1. **Rename by default.** Any `XSpec` lacking a bound acceptance harness becomes **`XDescription`**. Keep content intact; change suffix and preface with a “Description, not Spec” note.\n2. **Promote selectively.** For epistemes that *are* testable and declare **F ≥ F4**, add harness links (F.15) and re-label as **`XSpec`** via the Spec-gate.\n3. **Fix the verbs.** Rewrite “Role contains RSG/RCS” → “Role is **characterised by** RSG/RCS in RoleDescription”.\n4. **Detach carriers.** Replace identity‑by‑file with **`U.Carrier` encodes …Description/Spec** wording.\n5. **Add Contexts.** Where a Description drifts globally (“the backlog refinement is…”), prefix with the Context and adjust wording to be **local**.\n6. **Split planes.** Move any Evidence/Requirement **statuses** out of role state lists; keep them as roles over **knowledge units**.\n7. **Window‑ise verdicts.** Ensure every evaluation statement adds an explicit **window** (instant or interval).\n8. **Document maturity.** **Declare each Description’s F** (C.2.3) and track **ΔF** promotions/demotions as part of change notes (no governance implied).\n",
        "e.10.d2:12___acceptance_tests_(scr/rscr_—_concept‑level)": "### E.10.D2:12 - Acceptance tests (SCR/RSCR — concept‑level)\n\n#### E.10.D2:12.1 Static conformance checks (SCR)\n\n* **SCR-D2-S01 (Suffix discipline).** Every episteme with suffix **–Spec** passes the **Spec-gate** (**F ≥ F4** ∧ testable invariants ∧ harness link ∧ Context named). Otherwise it bears **–Description**.\n* **SCR‑D2‑S02 (Characterisation verbs).** Texts never say an intension “contains” RCS/RSG; they say it is **characterised by** them via the Description/Spec.\n* **SCR‑D2‑S03 (Plane purity).** No episteme mixes role **states** and knowledge **statuses**; each appears only on its correct plane.\n* **SCR‑D2‑S04 (context‑locality).** Every Description/Spec names its `U.BoundedContext`; wording reads correctly when prefixed by the Context.\n* **SCR‑D2‑S05 (Two registers).** Tech **and** Plain labels present on all Descriptions/Specs.\n* **SCR‑D2‑S06 (Carrier separation).** Identity statements refer to Epistemes; files are referenced only as `U.Carrier` encodings.\n* **SCR‑D2‑S07 (Windowed evaluation).** All state attestations cite a window `W` (instant or interval).\n\n#### E.10.D2:12.2 Regression checks (RSCR)\n\n* **RSCR‑D2‑E01 (Spec demotion guard).** If a **–Spec** loses its harness or testability, it is demoted to **–Description**; diffs show no lingering “shall” claims.\n* **RSCR‑D2‑E02 (Bridge drift).** If two Contexts begin to share identical labels, verify no Descriptions/Specs imply Cross‑context identity; add or revise **F.9 Bridges** instead.\n* **RSCR‑D2‑E03 (Edition churn).** When a Context’s canon updates, previously valid attestations remain historical (windowed); new Specs/Descriptions cite the new edition.\n* **RSCR‑D2‑E04 (Verb hygiene).** Automated grep over corpus finds “contains RSG/RCS” phrasing; none remain after refactor.\n* **RSCR‑D2‑E05 (Status bleed).** Spot‑audit a random sample of role graphs to ensure no epistemic/deontic statuses appear as role states.\n\n*Didactic takeaway.*\nThink in three layers: **Intension** (what the thing *is*), **Description/Spec** (how we *state* its character and, when mature, *test* it), and **Evaluation** (what we can *attest* about it in a **window**). Keep Contexts local, planes separate, and “contains” out of your vocabulary.\n",
        "e.10.d2:13___author’s_pocket_guide_(carry‑in‑mind_rules)": "### E.10.D2:13 - Author’s pocket guide (carry‑in‑mind rules)\n\n> **Use these as thinking cues, not as paperwork.** Each cue is a one‑breath test you can apply while writing.\n\n1. **Name the Context.** Write “*Role (ITIL4)*”, “*Method (Essence‑language)*”, “*Execution (PROV)*”. Never speak global words.\n2. **Pick the *object-of-talk*.** Am I talking about an **intension** (Role/Method/Service), a **Description/Spec**, an **Evaluation**, or a **Carrier**? Stay on one object-of-talk per sentence.\n3. **Prefer –Description.** Use **`…Description`** by default. Switch to **`…Spec`** only after the **Spec‑gate** (testable invariants + harness + F‑mode).\n4. **Characterised by…** Say *“Role is **characterised by** RCS/RSG recorded in RoleDescription”*, never *“Role **contains** its states”*.\n5. **Window every verdict.** An Evaluation must read “*X ∈ State\\@context **in** W*”. No naked, timeless verdicts.\n6. **Status ≠ state.** Role **states** live in `U.RSG`; Evidence/Requirement **statuses** classify **knowledge units**. Do not mix.\n7. **Bridge later.** If two Contexts “feel the same”, write the itch down and leave it for **F.9 Bridge**.\n8. **Two registers.** Every Description/Spec has **Tech** and **Plain** labels; prefer the shortest tech term that matches the invariants.\n9. **Carrier humility.** Files and records are **Carriers** of Descriptions/Specs; they don’t *equal* the thing you reason about.\n10. **Spec = test.** If you can’t point to a harness that would falsify it, it isn’t a **Spec** yet.\n",
        "e.10.d2:14___phrasebook_&_pitfall_table_(say_this,_not_that)": "### E.10.D2:14 - Phrasebook & pitfall table (say this, not that)\n\n| Mistaken phrasing (avoid)              | Didactically correct phrasing (use)                                                                                  | Why                                                                                        |\n| -------------------------------------- | -------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------ |\n| “The Role **contains** its states.”    | “The **Role** is **characterised by** RCS/RSG **recorded in** the RoleDescription.”                                  | Roles are intensions; state graphs live in their **Descriptions/Specs** (knowledge plane). |\n| “MethodSpec (draft).”                  | “**MethodDescription** (Essence‑language Context); not a Spec yet.”                                                     | **–Spec** is reserved for testable artifacts that passed the Spec‑gate.                    |\n| “We proved the service meets the SLO.” | “**Evaluation** attests *Service ∈ Met\\@ITIL4 in W* based on observations and the **Acceptance harness**.”           | Evaluations produce **windowed attestations**, not timeless facts.                         |\n| “Evidence status is a role state.”     | “**Evidence status** classifies a **KnowledgeUnit**; **Role states** live in RSG. Different planes.”                 | Prevents status/state conflation.                                                          |\n| “The PDF is the Method.”               | “The PDF is a **Carrier** that **encodes** a **MethodDescription**.”                                                 | Carrier ≠ content.                                                                         |\n| “BPMN workflow = PROV activity.”        | “Add a **Bridge (F.9)** if needed; in F.1/F.2/F.3 we treat them as **context‑local** senses.”                           | No Cross‑context identity outside Bridges.                                                    |\n| “WorkSpec / WorkPlan (synonyms).”      | “**U.WorkPlan** (preferred). **WorkDescription** is an allowed alias; **WorkSpec** is deprecated.”                   | Aligns with the –Description/–Spec discipline.                                             |\n| “RoleSpec is our template.”            | “**RoleDescription** is our template; promote to **RoleSpec** once the harness exists.”                              | Keeps the Spec word meaningful.                                                            |\n| “Spec says the same in all Contexts.”     | “Each **Spec/Description** is **context‑local**; Cross‑context reuse requires an **Alignment Bridge** with CL/loss notes.” | Locality guard.                                                                            |\n",
        "e.10.d2:15___naming_&_alias_policy_(normative,_notation‑free)": "### E.10.D2:15 - Naming & alias policy (normative, notation‑free)\n\n#### E.10.D2:15.1 - Suffix discipline (recap).**\n\n* **Preferred default:** **`…Description`** for Role/Method/Service/Work.\n* **Reserved:** **`…Spec`** only if the item passed the **Spec‑gate** (F‑mode, testable invariants, harness id, Context named).\n* **Banned:** Using **–Spec** as a synonym for “detailed description”.\n\n#### E.10.D2:15.2 - Canonical/alias map (current edition).**\n\n| Concept (intension) | Preferred episteme name      | Allowed alias (equal scope)   | Deprecated alias | Notes                                                                                 |\n| ------------------- | ---------------------- | ----------------------------- | ---------------- | ------------------------------------------------------------------------------------- |\n| Role                | **RoleDescription**    | RoleCard *(Pedagogy only)*    | —                | *RoleCard* is informal (teaching layer), not a normative episteme name.                     |\n| Role (F‑mode)       | **RoleSpec**           | —                             | —                | Only after Spec‑gate.                                                                 |\n| Method              | **MethodDescription**  | —                             | **MethodSpec**   | Global rename complete; legacy references should be updated.                          |\n| Method (F‑mode)     | **MethodSpec**         | —                             | —                | Now reserved for harnessed, testable methods.                                         |\n| Work (schedule)     | **U.WorkPlan**         | **WorkDescription**           | **WorkSpec**     | *WorkSpec* alias removed; *WorkDescription* remains as didactic alias for *WorkPlan*. |\n| Service             | **ServiceDescription** | ServiceCard *(Pedagogy only)* | —                | As above: Card is informal only.                                                      |\n| Service (F‑mode)    | **ServiceSpec**        | —                             | —                | Requires acceptance harness id (F.15).                                                |\n\n#### E.10.D2:15.3 - Verb & morphology rules.**\n\n* **Verbs.** Use *characterised by*, *recorded in*, *encoded by*; avoid *contains*, *is stored in*, *is implemented by* when speaking at the conceptual level.\n* **Morphology.**\n\n  * Roles name **masks** as **count nouns** (*Operator, ChangeAuthority*).\n  * States as **state nouns/participles** (*Authorized, Active*).\n  * Status names are **classifiers over knowledge** (*SupportsClaim, NormativeStandard*).\n  * Descriptions/Specs use neutral nouns (*RoleDescription, MethodSpec*).\n\n#### E.10.D2:15.4 - Deprecations (effective now).**\n\n* **MethodSpec** (as a general name) → **MethodDescription** unless Spec‑gate is met.\n* **WorkSpec** (alias for WorkPlan) → **WorkDescription** (allowed alias), or **U.WorkPlan** (preferred).\n* Texts must avoid “contains RSG/RCS” phrasing (see RSCR‑D2‑E04).\n",
        "e.10.d2:16___quick_templates_(fill‑in‑mind,_not_forms)": "### E.10.D2:16 - Quick templates (fill‑in‑mind, not forms)\n\n> Copy these **lines** into your prose as thinking scaffolds. They are not schemas, fields, or checklists to fill; they are didactic prompts.\n\n#### E.10.D2:16.1 - Role (default).\n\n* *Intension.* `U.Role :: <TechName> in <ContextId>`.\n* *RoleDescription\\@context.* Tech/Plain: **`<TechName> / <PlainName>`**.\n\n* **RCS characteristics.** `<characteristic₁ ∈ {… }>; <characteristic₂ ∈ {… }>`.\n* **RSG nodes (→).** `<S₀ → S₁ → …  → Sₙ>`.\n* **State checklist (one node).** `<StateX : {criterion₁, …}>`.\n* *Evaluation attestation.* `subject=<Holder> ∈ <StateX>@<ContextId> in <Window> (evidence: <cue₁,…>)`. \n\n#### E.10.D2:16.2 - Method (Essence‑language Context).\n\n* *Intension.* `U.Method :: <TechName>`.\n* *MethodDescription\\@context.* Inputs/Outputs (informative), **RCS/RSG** (if you track adoption).\n* *Spec upgrade (optional).* “Becomes **MethodSpec** when harness `<id>` exists.”\n\n#### E.10.D2:16.3 - Service (acceptance‑bearing).**\n\n* *ServiceDescription\\@context.* Tech/Plain; **Acceptance facet** (informative until harnessed).\n* *Evaluation.* `Service ∈ Met/Not‑Met@context in <Window>` based on observations and acceptance criteria.\n\n#### E.10.D2:16.4 - Alignment reminder.\n\n* “No Cross‑context identity is implied; if needed, add **F.9 Bridge**: `<ContextA:TermA> ↔ <ContextB:TermB>` with CL/loss notes.”\n",
        "e.10.d2:17___didactic_distillation_(90‑second_script)": "### E.10.D2:17 - Didactic distillation (90‑second script)\n\n> **“Three layers; one context; no leakage.”**\n\n1. **Pick the Context.** Every word lives **inside** a `U.BoundedContext`.\n2. **Pick the I/D/S layer.** Speak about the **Intension (I)**, or about its **Description/Spec (D/S)**—but never mix layers. If your sentence also asserts describedEntity or evidence, **name the `ReferencePlane`** (`world|concept|episteme`).\n3. **Describe, then test.** Start with **Role/Method/ServiceDescription**. Only when you can **falsify** it with a harness do you call it a **Spec**.\n4. **State is attested.** Role **states** are attested by **Evaluations** as *“X ∈ State\\@context **in** W”*. Evidence/Requirement **statuses** classify **knowledge**, not roles.\n5. **Carriers carry.** PDFs and repos are **Carriers** of the Description/Spec; they aren’t the thing itself.\n6. **Bridges are explicit.** Cross‑context sameness is never assumed; you declare a **Bridge** with CL/loss.\n   Follow these six lines and SD (*Strict Distinction*) stops being an abstraction—you feel it in every sentence you write.\n",
        "e.10.d2:end": "### E.10.D2:End\n"
      },
      "content": "### E.10.D2:End\n",
      "metadata": {},
      "part": "E",
      "cluster": null
    },
    {
      "id": "E.12",
      "title": "Didactic Primacy & Cognitive Ergonomics",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## E.12 - Didactic Primacy & Cognitive Ergonomics\n",
        "problem": "### E.12:2 - **Problem**\n\nIf the framework's design prioritizes theoretical purity or formal completeness over cognitive ergonomics, it becomes vulnerable to two critical failure modes:\n\n1.  **Goodhart's Law:** When a measure (like `AssuranceLevel:L2`) becomes the primary target, it ceases to be a good measure of genuine understanding. Teams may start \"gaming the metrics,\" producing artifacts that are formally perfect but conceptually shallow or pragmatically useless.\n2.  **Cognitive Overload & Rejection:** The framework becomes so dense, jargon-laden, and procedurally complex that its users—the very agents it is meant to serve—either burn out or abandon it in favor of simpler, albeit less rigorous, methods. The \"Operating System for Thought\" devolves into a bureaucratic machine for certification.\n",
        "forces": "### E.12:3 - **Forces**\n\n| Force | Tension |\n| :--- | :--- |\n| **Formal Rigor vs. Human Usability** | How to build a system that is both formally sound and cognitively accessible, without sacrificing one for the other. |\n| **Intrinsic Complexity vs. Incidental Complexity**| How to distinguish the necessary cognitive load inherent in solving a difficult problem from the unnecessary friction imposed by a poorly designed framework. |\n| **Means vs. Ends** | How to ensure that the production of high-quality artifacts (the means) always serves the ultimate goal of enhancing an agent's cognitive capabilities (the end). |\n",
        "solution": "### E.12:4 - **Solution**\n\nFPF elevates **Didactic Primacy (Pillar P-2)** to a normative architectural principle, operationalized through two conceptual mechanisms designed to act as a permanent counterbalance to excessive formalism.\n\n#### E.12:4.1 - The Principle of Didactic Primacy (Expanded Definition)\n\nThe primary purpose of the FPF is to enhance the cognitive capabilities (`U.Capability`/`Mastery`) of an Agent (`U.Agent`) in service of its Objectives (`U.Objective`). The creation of artifacts with high assurance levels and epistemic scores is a *means to that end, not the end itself*. Any architectural decision that increases formal rigor at the cost of clarity or usability must be explicitly justified by a demonstrable gain in the agent's ability to reason effectively.\n\n#### E.12:4.2 - Mechanism 1: The Rationale Mandate\n\nEvery key assurance artifact (such as a `U.AssuranceCase` or `Proof`) **MUST** contain a mandatory, human-readable **`rationale`** component.\n\n*   **Nature:** The `rationale` is not a technical description but a narrative explanation.\n*   **Content:** It **MUST** answer the question: *\"How does achieving this level of formal assurance tangibly help the agent better understand the problem or make a more reliable decision?\"*\n*   **Purpose:** This mandate forces a moment of reflection, formally linking the act of formalization back to its pragmatic, cognitive purpose. An empty or perfunctory rationale indicates that the assurance work may be an exercise in formalism for its own sake.\n\n> **Didactic Note for Managers: The \"So What?\" Test**\n>\n> The Rationale Mandate is FPF's built-in \"So What?\" test. When your team presents a complex, formally verified artifact (`AssuranceLevel:L2`), the `rationale` is where they answer your fundamental question: \"This is impressive, but *so what*? How does this help us ship a better product, make a smarter investment, or avoid a critical risk?\" If the answer isn't clear and compelling in the `rationale`, the formal work may have been a waste of resources. It keeps your most brilliant minds focused on creating value, not just elegant proofs.\n\n#### E.12:4.3 - Mechanism 2: The Human-Factor Loop (HF-Loop)**\n\nTo provide a continuous, self-correcting mechanism against cognitive overload, FPF introduces a conceptual feedback loop.\n\n*   **Core Concept:** The HF-Loop is a formal method of inquiry designed to distinguish between the *essential complexity* of the problem being solved and the *incidental complexity* introduced by the FPF itself.\n*   **Trigger Concept:** A review is triggered when the **subjective cognitive workload** associated with using the framework exceeds a conceptual threshold. This is not about performance metrics, but about the perceived mental effort required to use FPF's concepts and structures.\n*   **Review Concept:** When triggered, a formal review is conducted by individuals in roles that specialize in human-centric perspectives, such as the **`Ethicist`** and **`UX Design Critic`**.\n*   **Output Concept:** The review produces a set of proposed **conceptual simplifications** or **didactic improvements** to the framework's patterns or architheories. These are then submitted as formal change proposals (DRRs).\n\n#### E.12:5 - **Conformance Checklist**\n\n*   **CC-E12.1 (Rationale Mandate):** Every `U.AssuranceCase` or `Proof` artifact at `AssuranceLevel:L2` **MUST** contain a non-empty `rationale` component that satisfies the \"So What?\" test.\n*   **CC-E12.2 (HF-Loop Trigger Condition):** Each architheory that defines a significant workflow **SHOULD** specify a conceptual condition for triggering an HF-Loop review, based on the principle of managing cognitive load.\n*   **CC-E12.3 (HF-Loop Review Mandate):** If a trigger condition is met, a review involving the designated human-centric roles **MUST** be initiated. Its outcome **MUST** be a documented set of conceptual refinement proposals.\n*   **CC-E12.4 (Didactic Primacy in DRRs):** Any DRR proposing a change to a normative pattern **MUST** include a section analyzing its impact on cognitive ergonomics and didactic clarity.\n\n#### E.12:6 - **Common Anti-Patterns and How to Avoid Them**\n\n| Anti-Pattern | Manager's View: What It Looks Like | How FPF Prevents It (Conceptually) |\n| :--- | :--- | :--- |\n| **The \"Ivory Tower\" Framework** | The FPF specification becomes a beautiful but impenetrable fortress of abstract logic that no practicing engineer can actually use. | The **HF-Loop** provides a formal channel for user feedback to drive conceptual simplification. The roles of `UX Design Critic` and `Ethicist` are constitutionally empowered to challenge complexity that does not serve a clear purpose. |\n| **The \"Meaningless Rationale\"** | The `rationale` field is filled with boilerplate text like \"To increase assurance,\" without any real connection to the problem. | The \"So What?\" test is part of the review process for L2 artifacts. A perfunctory `rationale` is grounds for rejecting the artifact's promotion to L2, forcing the author to articulate the *real* value of their formal work. |\n| **Glorifying Complexity** | A culture emerges where the most complex and difficult-to-understand models are considered the \"best,\" regardless of their utility. | The core principle of **Cognitive Elegance (P-1)** and the mechanisms in this pattern create a constant pressure towards simplicity and clarity. The framework formally values understanding over mere complexity. |\n\n#### E.12:7 - **Consequences**\n\n| Benefits | Trade-offs / Mitigations |\n| :--- | :--- |\n| **Guards FPF's Core Mission:** This pattern acts as an \"immune system,\" protecting the framework from devolving into sterile formalism and ensuring it remains a tool for enhancing thought. | **Introduces \"Softer\" Concepts:** Cognitive load and rationale quality are less quantifiable than formal proofs. *Mitigation:* FPF operationalizes them through a formal method. The HF-Loop is a structured inquiry, not an informal chat. |\n| **Empowers Human-Centric Roles:** It gives the `Ethicist` and `UX Design Critic` roles a concrete, constitutional function in the evolution of the framework. | - |\n| **Prevents User Burnout and Rejection:** The HF-Loop is an early warning system that detects when the framework is becoming too cumbersome, allowing for course correction before users become frustrated and abandon it. | - |\n| **Creates a Self-Simplifying System:** The pattern creates a formal pressure that forces FPF to evolve towards greater clarity and usability, balancing the drive for formal rigor. | - |\n\n#### E.12:8 - **Rationale**\n\nThis pattern operationalizes **Didactic Primacy (P-2)**, transforming it from a philosophical statement into an enforceable architectural Standard. The `Rationale Mandate` ensures that every act of formalization is tied to a clear purpose. The `Human-Factor Loop` ensures that the *cost* of using the framework is measured not just in resources, but in the most critical resource of all: the cognitive capacity of its users.\n\nThis pattern does not weaken the formal rigor established by other ADRs; it complements it. It guarantees that the powerful machinery of FPF is always directed towards a meaningful, human-relevant goal. It is the constitutional guarantee that FPF will remain, first and foremost, an \"Operating System for Thought.\"\n\n#### E.12:9 - **Relations**\n\n*   **Implements:** Pillar `P-2 Didactic Primacy`.\n*   **Complements:** `E.13 Pragmatic Utility & Value Alignment` (which focuses on the relevance of the *problem*, while this pattern focuses on the usability of the *framework*).\n*   **Is constrained by:** The overall governance process (DRRs), which is the vehicle for implementing the conceptual simplifications proposed by the HF-Loop.\n",
        "e.12:end": "### E.12:End\n"
      },
      "content": "### E.12:End\n",
      "metadata": {},
      "part": "E",
      "cluster": null
    },
    {
      "id": "E.13",
      "title": "Pragmatic Utility & Value Alignment",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## E.13 - Pragmatic Utility & Value Alignment\n",
        "problem": "### E.13:2 - **Problem**\n\nWithout a formal mechanism to keep the entire assurance apparatus tethered to real-world value, FPF risks enabling two critical failure modes:\n\n1.  **Formalism for Formality's Sake:** Teams become preoccupied with achieving high epistemic scores, producing elegant but useless artifacts. The framework is used to build beautiful solutions to the wrong problems.\n2.  **Proxy-Metric Distortion (Goodhart's Law):** Teams successfully optimize for a chosen proxy characteristic, but in doing so, they diverge from—or even actively undermine—the true, often qualitative, `U.Objective` that the proxy was intended to represent. The system becomes technically successful but pragmatically a failure.\n",
        "forces": "### E.13:3 - **Forces**\n\n| Force | Tension |\n| :--- | :--- |\n| **Measurability vs. Meaning** | How to use quantitative, measurable proxies for progress without losing sight of the qualitative, often un-measurable, goals that truly matter. |\n| **Abstraction vs. Application** | How to build and reason with abstract models without them becoming disconnected from any concrete, practical application. |\n| **Incremental Progress vs. Global Value** | How to ensure that local optimizations and incremental improvements are genuinely contributing to the overall value proposition of the holon. |\n",
        "solution": "### E.13:4 - **Solution**\n\nFPF elevates **Pragmatic Utility (Pillar P-7)** to a normative architectural principle, operationalized through two mandatory conceptual mechanisms.\n\n#### E.13:4.1 - The Principle of Pragmatic Utility (Expanded Definition)\n\nAny artifact created within the FPF is an instrument for achieving a specific, pragmatic `U.Objective`. The value of an artifact is determined solely by its **utility** in achieving that objective, not by its epistemic scores in isolation.\n\n#### E.13:4.2 - Mechanism 1: The Proxy-Audit Loop\n\nTo formally manage the risk of Goodhart's Law, FPF introduces a conceptual feedback loop to periodically review the alignment between proxy characteristics and their intended goals.\n\n*   **New Normative Relation:** A new relation, `isProxyFor: U.Characteristic → U.Objective`, is introduced. This relation **MUST** be used to explicitly declare when a measurable characteristic is serving as a proxy for a higher-level, often qualitative, goal.\n*   **Conceptual Audit Process:** Any characteristic marked with the `isProxyFor` relation is subject to a **periodic conceptual audit**.\n*   **Review Roles:** This audit is conceptually performed by the individual(s) in the **`Strategist`** role. They are tasked with answering the question: *\"Is optimizing for this proxy still reliably driving progress toward the actual `U.Objective` it represents, or have we observed a divergence?\"*\n*   **Output Concept:** If a divergence is identified, a high-priority `U.Method` for revising or replacing the proxy **MUST** be proposed.\n\n> **Didactic Note for Managers: Are You Climbing the Right Mountain?**\n>\n> The Proxy-Audit Loop is your compass. Your team's dashboards might show all green—metrics are improving, targets are being hit. But the audit loop forces a crucial question: \"Are these the *right* metrics?\"\n>\n> Imagine you are trying to improve \"customer satisfaction\" (`U.Objective`). You choose \"average call handle time\" as a proxy metric. Your team successfully drives this number down. But the Proxy-Audit reveals that customer satisfaction is actually *decreasing* because agents are rushing and providing poor service to meet the time target. The loop forces you to recognize this divergence and find a better proxy (e.g., \"first-call resolution rate\"). It ensures your team is not just climbing fast, but climbing the right mountain.\n\n#### E.13:4.3 - Mechanism 2: The Minimally Viable Example (MVE) Mandate\n\nTo enforce a pragmatic, value-first approach from the very beginning of a project, any new `U.System` or major system component **MUST** begin its development cycle with the creation of a **Minimally Viable Example (MVE)**.\n\n*   **Definition:** An MVE is a simple, end-to-end, working instance of the holon that demonstrates the achievement of at least one core, user-facing objective, however trivial. It is the FPF equivalent of a \"Hello, World\" for a complex system.\n*   **Assurance Requirement:** The MVE **MUST** achieve a minimum of **`AssuranceLevel:L1 (Substantiated)`**. This means the MVE cannot be a mere mock-up or a purely conceptual sketch; it must be supported by at least one piece of tangible evidence (e.g., a passing test case, a formal assertion), as defined in Pattern B.3.3.\n*   **Stege transition Precedence:** The development of the full-scale holon cannot proceed to `AssuranceLevel:L2` until the MVE has been created and has met its L1 requirement.\n",
        "conformance_checklist": "### E.13:5 - **Conformance Checklist**\n\n*   **CC-E13.1 (Proxy Declaration Mandate):** Any `U.Characteristic` used as a primary driver for an objective **MUST** be explicitly linked to that `U.Objective` via the `isProxyFor` relation.\n*   **CC-E13.2 (Proxy-Audit Mandate):** A formal Proxy-Audit review **MUST** be conducted at regular conceptual intervals (e.g., before each major release). The outcome of this review **MUST** be a documented episteme.\n*   **CC-E13.3 (MVE Mandate):** The development of any new `U.System` **MUST** be preceded by the creation of an MVE that satisfies the `AssuranceLevel:L1` requirement.\n*   **CC-E13.4 (MVE Traceability):** The full-scale `U.System` **MUST** maintain a formal traceability link (`isEvolutionOf`) to its originating MVE.\n",
        "anti_patterns": "### E.13:6 - **Common Anti-Patterns and How to Avoid Them**\n\n| Anti-Pattern | Manager's View: What It Looks Like | How FPF Prevents It (Conceptually) |\n| :--- | :--- | :--- |\n| **The \"Perfectly Engineered Irrelevance\"** | The team delivers a technically brilliant system that is formally verified and validated, but no one wants to use it because it doesn't solve a real problem. | **CC-E13.3** forces the team to build a working, end-to-end slice of value (the MVE) *first*. This grounds the entire project in a demonstrated solution to a real user need from day one. |\n| **The \"Metric Myopia\"** | The team becomes obsessed with improving a specific KPI, ignoring clear signs that this is not improving—and may even be harming—the overall user experience or business goal. | **CC-E13.2** mandates the Proxy-Audit Loop. This forces a periodic, strategic step-back, where the `Strategist` role is constitutionally required to ask, \"Are we still measuring what matters?\" |\n| **The \"Big Design Up Front\" Trap** | The team spends months creating a vast, abstract, and highly detailed model of a system before ever building a single working component. | The **MVE Mandate** prevents this. It forces an iterative, pragmatic \"build-to-learn\" approach, ensuring that models are always grounded in a working reality. |\n",
        "consequences": "### E.13:7 - **Consequences**\n\n| Benefits | Trade-offs / Mitigations |\n| :--- | :--- |\n| **Defense Against Goodhart's Law:** The Proxy-Audit Loop is a concrete, operational defense against the common failure mode of optimizing for the wrong thing. It forces regular, strategic reflection on the meaning of metrics. | **Introduces Strategic Overhead:** The Proxy-Audit Loop and the creation of an MVE require dedicated time for strategic thinking and early implementation. *Mitigation:* This is not an expense but a strategic investment. This upfront effort is designed to prevent the far greater cost of developing the wrong system over months or years. |\n| **Ensures Value-Driven Development:** The MVE Mandate guarantees that all major development efforts are grounded in a demonstrated, working solution to a real problem, however small. This prevents teams from investing significant resources in abstract models that have no proven path to practical application. | - |\n| **Prevents \"Analysis Paralysis\":** By requiring an early, working example, this principle encourages an iterative, pragmatic development style. It forces teams to build and learn, rather than over-specifying in a vacuum. | - |\n| **Positions FPF as an Engineering Discipline:** This pattern firmly anchors FPF as a tool for practical engineering, not just theoretical modeling. | - |\n",
        "rationale": "### E.13:8 - **Rationale**\n\nThis pattern operationalizes **Pragmatic Utility (P-7)**. While Pattern E.12 protects the *agent* from the cognitive overload of the framework, this pattern protects the *problem* from being lost in a sea of formal abstraction. It provides the necessary constitutional guardrails to keep the powerful formal methods of FPF focused on delivering tangible, real-world value.\n\nThe **MVE Mandate** ensures that every journey starts with a destination in sight. The **Proxy-Audit Loop** ensures that the compass used on that journey remains pointed in the right direction. Together, these mechanisms guarantee that knowledge generated within FPF is not only formally correct and epistemically reliable, but also meaningful, useful, and aligned with its intended purpose.\n",
        "relations": "### E.13:9 - **Relations**\n\n*   **Implements:** Pillar `P-7 Pragmatic Utility`.\n*   **Complements:** `E.12 Didactic Primacy & Cognitive Ergonomics`.\n*   **Provides context for:** The definition of `U.Objective` and `U.Characteristic` by establishing a formal link between them.\n",
        "e.10:end": "### E.10:End\n"
      },
      "content": "### E.10:End\n",
      "metadata": {},
      "part": "E",
      "cluster": null
    },
    {
      "id": "E.14",
      "title": "Human‑Centric Working‑Model",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## E.14 - Human‑Centric Working‑Model\n",
        "intent": "### E.14:1 - Intent\n\nEstablish a **single, human‑centric Working‑Model** that practitioners can read, discuss, and evolve **without exposure to formal machinery**.  \nEach statement **declares a justification stance** (`validationMode`) and, when assurance is sought, attaches **appropriate grounding** via one or more assurance shoulders — **Mapping**, **Logical**, **Constructive** — and **may additionally attach Empirical Validation** (evidence) as defined by the Trust & Assurance calculus. Empirical Validation can accompany any stance; it is **required** when the stance is *postulate*. Assurance shoulders sit **beneath** the Working‑Model and **never define its vocabulary**.\n \n+Put bluntly: *one model people work in; three assurance shoulders — plus empirical checks when the world is the judge.*\n",
        "problem": "### E.14:2 - Problem & Context\n\n+Teams need **one shared Working‑Model** to make decisions at speed. Historically this surface either:\n\n* **drifts into jargon**—different terms for the same thing, slash‑labels, partial overlaps; or\n* **calcifies into machinery**—too formal for day‑to‑day design and review.\n\nBoth failure modes create friction between two audiences:\n(1) **working users** (engineers, programme managers, policy owners) who need a **small, stable surface**, and\n(2) **assurance authors** (ontologists, methodologists, auditors) who need **proofs that the surface is sound**.\n\nE.14 resolves the impasse by **separating concerns**:\n\n* A **Working‑Model layer**: curated kinds and relations expressed in plain terms, governed by simple human rules.\n* A **three‑rung Assurance stack** beneath it—**Mapping**, **Logical**, **Constructive**—that carries the heavy arguments (concept alignment, relational semantics, generative traces) and **never leaks back** into the Working‑Model narrative.\n\nThis pattern dovetails with the framework’s unification stance (**small Working‑Model surface, rigorous foundations**) and with our constructional mereology commitments (**sum/set/slice** provide extensional identity), while keeping the Kernel minimal and meta‑only.\n",
        "forces": "### E.14:3 - Forces\n\n1. **Cognitive economy vs. semantic precision.**\n   Managers and engineers must navigate with a handful of names and relations; assurance authors must still certify that those names and relations **are unambiguous and extensional**.\n\n2. **Speed of change vs. guarantees.**\n   The Working‑Model must accommodate rapid iteration; the Assurance stack must **lag just enough** to check, without blocking practical progress.\n\n3. **Parsimony vs. expressivity.**\n   The Working‑Model should **not proliferate relation types or ad‑hoc categories**; fine‑grained distinctions live in the Assurance layers and are surfaced **only when they materially change a decision**.\n\n4. **Downward grounding vs. upward contamination.**\n   Grounding must always flow **down** (Working‑Model → Mapping → Logical → Constructive). No dependence **up** is allowed: proofs and traces never dictate wording or layout in the Working‑Model.\n\n5. **Trans‑disciplinary unification vs. local dialects.**\n   The Working‑Model must reconcile different disciplines’ habits **without erasing them**; Mapping captures dialects, while the Working‑Model exposes a **single usable choice**.\n\n6. **Auditability vs. readability.**\n   Every Working‑Model statement must be **auditable on request**, yet day‑to‑day views **hide the scaffolding** unless summoned.\n\n",
        "solution": "### E.14:4 - Solution\n\n#### E.14:4.1 - Human-Centric principles\n\n> **E.14‑P.1 – Working‑Model first, stance explicit.**  \n> Operate one **Working‑Model** for all human‑facing discussion. For **each** assertion, the author **SHALL declare** a justification stance (`validationMode`) and choose the **appropriate assurance shoulder(s)**: **Mapping** (term↔kind alignment via **Lang‑CHR** / D‑Projection), **Logical** (CT2R alias semantics, scope/constraints), **Constructive** (Γₘ generative trace), and **Empirical Validation** (evidence via `U.EvidenceRole` in a declared `U.BoundedContext`).\n\n> **E.14‑P.2 – Downward‑only dependency.**\n> Information **may** flow from the Working‑Model down into any Assurance layer; **no Assurance layer may impose vocabulary or shape back upward** into the Working‑Model.\n>\n> **E.14‑P.3 – Small surface, big proof.**\n> The Working‑Model exposes a **minimal set** of names (L‑1/L‑2 registers) and **a compact family of relations** used in everyday reasoning; precision and completeness are **proved below**.\n\n> **E.14‑P.4 – Human registers first.**\n> Terms in the Working‑Model are deliberately curated for **human legibility** (register‑badged, synonym‑aware). Synonym capture and language variance belong to Mapping; **only the chosen canonical label appears on the Working‑Model surface**.\n\n> **E.14‑P.5 – Justification modes are explicit.**  \n> Each Working‑Model relation **declares** `validationMode ∈ {axiomatic, inferential, postulate}`.  \n> _axiomatic_ → **Constructive** grounding (Γₘ trace via `tv:groundedBy`); _inferential_ → **Logical** grounding (reasoned chain, often KD‑CAL‑backed for epistemic ties); _postulate_ → **Empirical Validation** (evidence bundle with scope and timespan). Empirical Validation (**LA**) may also accompany _inferential_ or _axiomatic_ claims as real‑world confirmation. **Mapping** contributes **TA**, **Logical/Constructive** contribute **VA**, and **Empirical** contributes **LA** (per the Trust & Assurance calculus; no calculus variables appear on the Working‑Model surface).\n\n> **E.14‑P.6 – Parsimony at the surface.**\n> No new Working‑Model relation types are introduced if the existing Logical aliases plus Constructive grounding suffice to capture the intended meaning.\n\n> **E.14‑P.7 – Evidence is a first‑class support.**  \n> When *postulate* is chosen, authors **SHALL** attach an **evidence pointer** (Empirical Validation) appropriate to the claim and context, governed by `U.EvidenceRole` within a declared `U.BoundedContext`.  \n ",
        "layer_standard_&_downward_flow_(working‑model_→_assurance)": "### E.14:5 - Layer Standard & Downward Flow (Working‑Model → Assurance)\n\nThis section defines **what each layer is for**, **what it guarantees**, and **how a single Working‑Model statement is carried down**.\n\n#### E.14:5.1 - Working‑Model (what humans see)\n\n**Purpose.** A small, curated graph of kinds and relations that a mixed team can read at a glance.\n\n**Elements.**\n\n* **Kinds** — one **chosen concept** per node (no slash‑labels).\n* **Relations** — a short list intelligible to non‑specialists (e.g., *Component‑of*, *Member‑of*, *Aspect‑of*, plus a small number of cross‑disciplinary ties such as *Interface‑of* or *Constituent‑of*).\n* **Language register badges** — terms appearing on the surface are L‑1 or L‑2; L‑3/L‑4 remain in Mapping as synonyms or symbols.\n\n**Obligations.**\n\n* Every Working‑Model edge and node is **grounded downward** (see below).\n* The Working‑Model **does not display** constructor jargon, proof terminology, or evidence identifiers; those live in Assurance and are **callable on demand**.\n\n#### E.14:5.2 - Assurance‑1: Mapping (from words to kinds)\n\n**Role.** Consolidate human labels from varied sources and **bind them to the chosen kinds** used on the Working‑Model.\n\n**Guarantee.** For any Working‑Model label, there exists a **stable alignment** to exactly one kind; synonyms, abbreviations, locales and registers are recorded here, **not** on the surface. Mapping primarily raises **Typing Assurance (TA)** by consolidating synonyms/registers and binding tokens/labels to **one chosen kind**; calculus‑level metrics live outside Part E.\n\n**Deliverable.** A compact alignment table per scope that makes it obvious which **one label** the Working‑Model will show and which alternatives are tolerated in background sources.\n\n*(Rationale: Working teams speak many dialects; the Working‑Model speaks one. Mapping is the interpreter.)*\n\n#### E.14:5.3 - Assurance‑2: Logical (from Working‑Model relations to alias semantics)\n\n**Role.** Give each Working‑Model relation **a precise alias meaning** and **its admissible use‑cases**, keeping the surface vocabulary small.\n\n**Guarantee.** A Working‑Model edge such as *Component‑of* or *Aspect‑of* **carries one intended reading** (transitivity/antisymmetry expectations, scope notes), sufficient for auditors to assess whether the **use is legitimate** in a given context.\n\n**Deliverable.** A short set of alias rules: “When an edge is labeled *Component‑of* at the surface, it intends the structural reading that is later verified by construction.” The Logical layer is **the Standard** that ties human labels to accepted meanings (CT2R alias rules); it primarily contributes **Verification Assurance (VA)**. Calculus‑level symbols are not used in E‑patterns.\n\n*(Rationale: logical aliasing protects the small surface from relation proliferation while keeping meanings crisp.)*\n\n#### E.14:5.4 - Assurance‑3: Constructive (from meanings to generative traces)\n\n**Role.** Provide **extensional guarantees** by **constructing** the wholes, collections, and slices that Working‑Model relations speak about.\n\n**Guarantee.** For structural edges, **there exists a constructional narrative** (e.g., *sum*, *set*, *slice*) that, if told, would recreate the whole from its parts or the aspect from its bearer; this makes identity and containment **trackable and testable** across scales.\n\n**Deliverable.** A **single generative story** per structural link (axiomatic justification). For non-structural ties on the surface (e.g., epistemic links), Constructive may be absent; Logical/Empirical take the lead. Constructive contributes **VA** (extensional identity via Γₘ); for **structural** edges, `tv:groundedBy` **MUST** reference exactly one Γₘ trace.\n\n*(Rationale: constructional grounding turns everyday part‑whole talk into statements whose identity conditions are not left to taste.)*\n\n#### E.14:5.5 - Assurance‑4: Empirical Validation (from claims to observed world)\n\n**Role.** Record when and where a Working‑Model claim meets reality.  \n**Guarantee.** Every empirical binding names a **`U.BoundedContext`**, a **target claim/scope**, and a **timespan**; **staleness/refresh** are managed per context policy.  \n**Deliverable.** A `U.EvidenceRole` binding (status‑only) anchored into the Evidence–Provenance chain. Empirical Validation contributes **LA** (raises empirical **R** and constrains **G** to its validated envelope).\n\n#### E.14:5.6 - The downward grounding for a single surface statement\n\nConsider a Working‑Model arrow **A –Component‑of→ B**:\n\n1. **Mapping** shows that the words *A* and *B* are the chosen labels for their kinds; it retains tolerated synonyms and symbols in the background.\n2. **Logical** confirms that **Component‑of** on the surface means the **structural reading** with its ordinary mereological expectations; if the surface used *Member‑of* instead, Logical would similarly certify the intended reading and its boundaries.\n3. **Constructive** exhibits the **constructional narrative** (e.g., a _sum_ of parts resulting in **B** with **A** among them), which yields **axiomatic justification** for the structural edge, sets `validationMode=axiomatic`, and binds the edge via **`tv:groundedBy → Γₘ.sum|set|slice`**.\n4. **Empirical Validation** records the **evidence pointer** and scope that make the claim auditable within its `U.BoundedContext` (required for *postulate*; optional reinforcement for other stances).\n\nTogether, these three **ground the human arrow without leaking their machinery upward**. The Working‑Model remains simple; the Assurance stack carries the proof.\n",
        "archetypal_grounding": "### E.14:6 - Archetypal Grounding *(System / Episteme)*\n\n> **Tell–Show–Show.** The principle is stated once, then shown on a `U.System` case (structural) and on a `U.Episteme` case (knowledge‑bearing), in line with the authoring template.\n\n#### E.14:6.1 - `U.System` — Working‑Model first, Constructive grounding available\n\n* **Publication (Working‑Model).** Authors state structure using familiar relations (e.g., *Impeller* **ut\\:ComponentOf** *Pump*; *Pump* **ut\\:ComponentOf** *Skid*). Nothing else is required for readers to follow the design.\n* **Assurance (downward grounding).** When stronger assurance is sought, the same author **narrates** the constructive story of the whole as a composition of parts and, where appropriate, attaches a downward grounding to that narrative (sum / set / slice). The narrative remains concept‑level and notation‑neutral; order and time stay out of structure and are expressed in their own planes.\n* **Canonization move.** Readers continue to see Working‑Model relations as the primary surface; the constructive story is *supporting*, not *defining*.\n\n#### E.14:6.2 - `U.Episteme` — Working‑Model first; Logical/Mapping preferred; Empirical evidence as appropriate\n\n* **Publication (Working‑Model).** Authors connect meaning‑bearing artefacts using knowledge relations (e.g., **RepresentationOf**, **UsageOf**) in the same human‑oriented style.\n* **Assurance (downward grounding).** Here assurance typically flows to the **Logical** or **Mapping** shoulders (reasoned argument; type/lexical alignment). **Empirical Validation** is used where observation is the right currency (status‑only roles on epistemes); Constructive grounding is optional and used only where a structural interpretation is genuinely intended.\n* **Canonization move.** Again, Working‑Model text is the public form; assurance is attached deliberately and separately, without leaking method or time semantics into structure.\n\n**6.3 - Pattern lesson (both cases)**\nThe **Working‑Model layer remains the canonical publication surface** for authors and reviewers; **assurance layers** (Mapping / Logical / Constructive) are **opt‑in** and used purposefully, with grounding flowing **downwards** from the Working‑Model to the appropriate shoulder. This presentation respects the authoring template’s *Archetypal Grounding* requirement and keeps notational choices illustrative rather than defining. \n\n",
        "bias‑annotation_*(what_to_watch_for,_and_the_counter‑moves)*": "### E.14:7 - Bias‑Annotation *(what to watch for, and the counter‑moves)*\n\n| Bias (name)                       | Symptom in drafts                                                                           | Conceptual counter‑move                                                                                                                        | Where this is governed                                               |\n| --------------------------------- | ------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------- |\n| **Formalism capture**             | Treating a constructive narrative as “the real thing,” with **ut:\\*Of** reduced to a label. | Re‑assert Working‑Model primacy: publish in **ut:\\*Of**; attach assurance **downwards** only when needed.                                      | E.8 template; Notational‑Independence guard‑rail.                    |\n| **Canonical inversion**           | Demanding constructive grounding for epistemic links by default.                            | Keep the **progressive** stance: prefer Logical/Mapping assurance for knowledge claims; raise to Constructive only when structure is at issue. | Authoring template; Working‑Model pattern family.                    |\n| **Layer leakage (order/time)**    | Encoding sequence or phase as part–whole to “strengthen” claims.                            | Keep **order**/**time** in their planes; do not smuggle them into structure.                                                                   | Style/structure guidance in Part E; flavour separation in Γ‑family.  |\n| **Collection ↔ Composition swap** | Using **MemberOf** as if it implied **ComponentOf** identity.                               | Keep collections (*set*) distinct from assemblies (*sum*); do not upgrade membership to component status.                                      | Working‑Model mereology guidance (Part B/C linkage).                 |\n| **Notation lock‑in**              | Letting a diagram or syntax define meaning.                                                 | Apply **Notational Independence**: define semantics in prose (maths if needed); treat renderings as informative.                               | Notational‑Independence guard‑rail.                                  |\n| **Backwards dependency**          | Letting an assurance artefact redefine public terms.                                        | Preserve **unidirectional dependence**: Working‑Model terms do not derive their meaning from assurance artefacts.                              | Part E guard‑rails (dependency discipline).                          |\n| **Silent stance**                 | Publishing claims with no declared assurance stance.                                        | Declare the stance explicitly (e.g., working claim vs reasoned vs constructive).                                                               | Style/authoring discipline in Part E.                                |\n\n> **Reading reminder.** Bias checks are *conceptual* reading aids; they never introduce notational or tooling mandates.\n",
        "conformance_checklist": "### E.14:8 - Conformance Checklist *(normative; author‑facing duties for thought and prose)*\n\n| ID                                         | Requirement                                                                                                                                                                      | Purpose                                                       |\n| ------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------- |\n| **CC‑E14‑1 (Working‑Model primacy).**      | Authors **SHALL** publish claims in **Working‑Model** form (human‑oriented **ut:\\*Of** relations or equivalent domain statements) as the canonical surface for readers.          | Preserve human‑first canon and didactic clarity.              |\n|**CC‑E14‑2 (Downward grounding).** | When assurance is attached, grounding **SHALL** flow **downwards** from the Working‑Model to the appropriate assurance shoulder (**Mapping / Logical / Constructive / Empirical**) and **SHALL NOT** impose vocabulary back onto the Working‑Model. | Maintain plane separation and cognitive economy. |\n| **CC‑E14‑3 (Stance declaration).**         | For any claim where assurance matters, the author **SHALL** declare `validationMode` (*postulate / inferential / axiomatic*).                                                    | Make assurance intent explicit and readable.                  |\n| **CC‑E14‑4 (No order/time in structure).** | Authors **SHALL NOT** encode execution order, parallelism, or temporal coverage as part–whole; keep them adjacent in their own planes.                                           | Prevent layer leakage and category errors.                    |\n| **CC‑E14‑5 (Collection ≠ Composition).**   | Authors **SHALL** keep **membership** claims distinct from **component** claims; no implicit upgrade from collection to assembly.                                                | Guard extensional identity and reader expectations.           |\n| **CC‑E14‑6 (Notational independence).**    | Core meaning **MUST NOT** hinge on a specific diagram or syntax; any rendering present **SHALL** be marked informative.                                                          | Ensure longevity and cross‑discipline portability.            |  \n| **CC‑E14‑7 (Layer direction).**            | Authors **SHALL** avoid back‑defining Working‑Model terms by their assurance artefacts; dependence is one‑way (Working‑Model → Assurance).                                       | Preserve unidirectional dependence of layers.                 |\n| **CC‑E14‑8 (Template compliance).**        | Sections **SHALL** follow the canonical pattern order; *Archetypal Grounding* is mandatory for architectural patterns.                                                                            | Keep patterns comparable and auditable by reading.            |  \n| **CC‑E14‑9 (Progressive formality).**      | Authors **SHOULD** escalate assurance deliberately (from working claim to reasoned to constructive), and use **Empirical Validation** where observation is the right currency.    | Support the formality ladder without burdening early drafts.  |\n|**CC-E14-10 (Structural grounding handshake).** | For **structural** edges on the Working-Model, authors **SHALL** set `validationMode=axiomatic` and provide **Constructive** grounding with `tv:groundedBy → Γₘ.sum|set|slice` (see **Compose-CAL** and **CT2R-LOG**). Exactly **one** Γₘ trace is permitted per edge (CI rule alignment). | Aligns E.14 with CT2R-LOG and Compose-CAL; ensures extensional identity. |\n| **CC‑E14‑11 (Empirical bindings).**        | When `validationMode=postulate` (or when adding real‑world confirmation), authors **SHALL** bind evidence via `U.EvidenceRole` in a declared `U.BoundedContext` with an explicit **timespan** and provenance anchors. | Aligns with Evidence Graph Referring and empirical ageing policies. |\n| **CC-E14-12 (F-declaration).**             | Normative Working-Model artefacts **SHALL** declare `U.Formality = Fk` per **C.2.3** (**recommended F ≥ F3** for readable surfaces). Assurance artefacts **MAY** carry higher F; **min-F** applies to composites. | Aligns E.14 with the unified Formality characteristic; avoids legacy “tiers/modes”. |\n\n*All obligations above are **conceptual** and apply to thought and prose; they introduce no notational or data‑processing requirements.*\n\n**E — Conceptual Examples (no notation, no data handling)**\n\n1. **Assembly from parts → “Component Of”**\n   A pump skid is agreed to be nothing over and above its pump, frame, reservoir, and valve set considered together. Because the whole is conceptually *constructed* from those parts, the team may safely speak of each part as *Component Of* the skid. The justification is the construction itself: if any listed part were removed, the very same skid would no longer exist as that whole. This keeps identity extensional and makes the engineer‑facing alias (“Component Of”) truthful rather than conventional.\n\n2. **Parallel elements gathered → “Member Of”**\n   A test rig has four identical cartridges used in parallel. The rig treats them as a conceptual *gathering*; membership is fixed by inclusion in that gathering, not by sequence or timing. Speaking of each cartridge as *Member Of* the rig’s cartridge bank is then licensed by the same gathering act. Engineers can keep saying “member,” while architects know the warrant is the underlying construction of the bank as a collection, not an accidental tagging.\n\n3. **Focused facet carved → “Aspect Of”**\n   When the team talks about the *thermal envelope* of a reactor, they are not multiplying entities; they are taking the already‑agreed reactor and conceptually *carving out* its thermal facet for focused reasoning. Calling that carve‑out an *Aspect Of* the reactor is justified because the aspect owes its identity to the parent and the chosen facet, and nothing else. This licenses disciplined talk about “boundary,” “interface,” or “envelope” without mistaking them for independent systems.\n\n> **Notes across the examples**\n> • Everyday aliases (*Component Of, Member Of, Aspect Of*) remain the only labels engineers need to see; their truth is anchored by prior constructional choices.  \n> • Structural links draw on **Constructive** grounding; **epistemic links**—like “Representation Of” or “Usage Of”—may instead rely on **Empirical Validation** (evidence bundles) or **Logical** grounding appropriate to the claim.  \n\n**F — Resulting Context (after you apply the pattern)**\n\n**What improves**\n\n* **Single dial for containment.** Teams can ask one plain question—“what is inside what?”—and trust that all structural talk reduces to shared constructional choices rather than ad‑hoc relation lists. Ontologists keep rigorous warrants without burdening day‑to‑day readers.\n* **Extensional identity by default.** Wholes are the wholes they are because of the parts gathered; collections are the collections they are because of their members; aspects inherit identity from their parent and facet. This prevents silent drift when labels change.\n* **Layer harmony.** Engineer‑facing aliases live at the same level as other relation names, while their warrants live one step below, keeping human language clean and the generative basis auditable.\n\n**What to watch**\n\n* **Discipline at the structural tier.** A structural link that lacks a constructional warrant is conceptually unsafe. Conversely, forcing epistemic links to pretend they are structural over‑physicalises knowledge claims; for those, evidence or argument is the right currency.\n* **Author workload moves, not grows.** Day‑to‑day model authors stay with aliases; specification authors carry the burden of ensuring every structural statement really follows from a sum, a gathering, or a carve‑out. This is a conscious shift of complexity away from operations and into the pattern’s foundation.\n\n**Invariants you must preserve**\n\n* **Parsimony of constructors.** Build wholes by summing parts; build banks by gathering elements; focus facets by carving aspects. Do not invent extra generative acts for parallelism or time‑slicing; those concerns belong to other conceptual services.\n* **Two‑tier justification.** Structural talk rides on construction; epistemic talk rides on evidence or proof. Keep the boundary sharp so that later reasoning (about reliability, compliance, or policy) remains clear.\n\n**Known consequences**\n\n* **Stable queries, fewer surprises.** Because aliases are backed by shared constructions, teams from different disciplines can interoperate without renegotiating meanings at hand‑off.\n* **Audit trail without jargon.** Reviewers can trace every structural claim to a prior constructional choice, while everyday collaborators keep using familiar relation names.\n\n",
        "consequences": "### E.14:9 - Consequences\n\n| Benefits                                                                                                                                                      | Trade‑offs / Mitigations                                                                                                                                                     |\n| ------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **Human‑first clarity.** Readers see the **Working‑Model layer** as the canonical publication form; Assurance layers remain optional and purpose‑driven.      | **Extra author discipline.** Declaring the stance and (when needed) a short grounding narrative takes effort; mitigated by the authoring template and style guide.           |\n| **Progressive assurance.** Teams can start light and raise strictness deliberately (Mapping → Logical → Constructive) without changing the visible relations. | **Risk of “forever‑light.”** Some models may remain in low‑assurance stances; mitigated by the formal maturity ladder and reviewer prompts to escalate where risk warrants.  |\n| **Layer hygiene.** Order/time remain outside mereology; structural identity is neither overloaded nor diluted.                                                | **Split attention.** Authors must learn to keep planes distinct; mitigated by the Tell‑Show‑Show pedagogy across architectural patterns.                                             |\n| **Spec cohesion.** The same section order and safety subsections (Bias‑Annotation, Conformance Checklist) keep patterns comparable and auditable.             | **Tighter prose.** Patterns grow by a few concise checks; mitigated by the canonical template.                                                                               |\n\n> **Quotable closer.** *“One layer to speak, three layers to justify—only when needed.”*\n\n",
        "rationale": "### E.14:10 - Rationale\n\n**Why Working‑Model is canonical.** FPF privileges **human‑oriented relations** as the primary interface for thinking and communication. This satisfies didactic primacy while preserving conceptual integrity: formal work serves the human layer, not the other way around. The canonical template and style principles institutionalise this choice without inviting notation lock‑in.\n\n**Why grounding flows downward.** Mapping, Logical, Constructive, and Empirical supports are **assurance shoulders** that sit *beneath* the Working‑Model claim. Authors select the shoulder(s) that fit purpose and risk: type/lexical alignment (**TA**), reasoned consequence (**VA**), constructive reconstruction (**VA**), and real‑world confirmation (**LA**). This keeps the Kernel small, avoids plane‑mixing, and provides a clear path to stronger guarantees when warranted.\n\n**Why patterns teach before they tighten.** The Tell‑Show‑Show requirement couples each universal rule with System/Episteme illustrations, reducing cognitive load and preventing premature formalism. It is the didactic mechanism that makes Human‑Centric Canonization practical across disciplines.\n\n**Why no notation talk in Core.** Guard‑rails and the style guide prohibit tool jargon and notation dependence inside normative prose; meanings are given in words and mathematics, with any renderings treated as illustrative only. This preserves longevity and cross‑disciplinary portability.\n",
        "relations": "### E.14:11 - Relations\n\n**Builds on:**\n\n* **E.8 Authoring Conventions & Style Guide** — section order, style principles, and mandatory safety subsections used here.\n* **E.7 Archetypal Grounding** — the Tell‑Show‑Show rule applied in this pattern’s own Grounding section.\n* **C.2.3 Unified Formality Characteristic (F)** — declares the **F** scale and **ΔF** moves for progressive rigor; Working-Model artefacts **SHALL** declare **F** and remain notation-agnostic.\n\n**Coordinates with.**\n\n* **CT2R‑LOG — Working‑Model Relations & Grounding** — alias rules and `tv:groundedBy` Standard for edges grounded in Γₘ.   \n* **Compose‑CAL (Constructional Mereology)** — provides the constructive shoulder (Γₘ: **sum | set | slice**) used to ground structural edges.\n* **E.10 Lexical Discipline & Stratification** — ensures naming discipline and register hygiene when the human layer is published.\n\n**Constrains:**\n\n* All architectural patterns that publish relations **SHALL** present them in the Working‑Model layer and **MAY** attach assurance only as needed, preserving plane separation and notational independence. (Template conformance as per E.8.)\n\n**Informs.**\n\n* Part F unification practices (context of meaning, bridges, fit levels) by reinforcing the preference for human‑readable labels with explicit alignment notes rather than silent formal substitutions.\n",
        "e.14:end": "### E.14:End\n"
      },
      "content": "### E.14:End\n",
      "metadata": {},
      "part": "E",
      "cluster": null
    },
    {
      "id": "E.15",
      "title": "Lexical Authoring & Evolution Protocol  (LEX‑AUTH)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## E.15 - Lexical Authoring & Evolution Protocol  (LEX‑AUTH)\n\n> *Author patterns as evidence‑bearing epistemes, evolve them via governed open‑ended search, and publish an auditable trace that improves quality—not just compliance.*\n",
        "context": "### E.15:1 - Context\n\nFPF patterns are the **canon**: they define the generative rules that other artifacts depend on. Teams need to **change** patterns as the SoTA moves, but ad‑hoc edits lead to drift, weak comparability, and brittle downstream updates. We need a **method** that (a) *generates* better alternatives, (b) *selects* them against explicit quality/assurance targets, and (c) *publishes* a machine‑ and human‑checkable **trace** that can be replayed, audited, and re‑run. (Built to cohere with **DRR (E.9)**, **LEX‑BUNDLE (E.10)**, **Canonical Evolution Loop (B.4)**, **NQD/E‑E (C.18/C.19)**, **Evidence Graph Referring (A.10)**, **Trust (B.3)**, **F‑Suite validation (F.15)**.)\n",
        "problem": "### E.15:2 - Problem\n\nWithout a disciplined authoring protocol:\n\n* **One‑shot generation** dominates; there is no *evolutionary* path from vN → vN+1.\n* “Trace” degenerates into a proof‑of‑work: *a method ran*, not *quality improved*.\n* Pattern edits blur **lexicon vs. norms vs. examples**, breaking didactics and tool‑independence.\n* SoTA content is cited but not **integrated** via Bridges & CL; claims get over‑ported.\n",
        "forces": "### E.15:3 - Forces\n\n| Force                                       | Tension we must resolve                                                           |\n| ------------------------------------------- | --------------------------------------------------------------------------------- |\n| **Generativity vs Assurance**               | Open‑ended idea generation must not erode safety/traceability.                    |\n| **SoTA speed vs Canon stability**           | Frequent small updates must preserve conceptual integrity and roll‑up invariants. |\n| **Local meaning vs Global reuse**           | Context‑local meaning must cross contexts only via **Bridges** with CL penalties. |\n| **Notational independence vs Checkability** | Text must stay notation‑free yet be verifiable by Tooling harnesses.              |\n",
        "solution": "### E.15:4 - Solution — A *governed evolutionary* authoring method with a publishable **LEX‑AUTH Trace (LAT)**\n\nLEX‑AUTH defines **how** a pattern is **proposed, varied, selected, validated, and merged**, with artifacts and evidence fit to the FPF kernel.\n\n#### E.15:4.1 - Method (design‑time choreography)\n\n**Stage A — Frame & Scope (Context, Objectives, Invariants)**\n\n1. **Anchor** the work in a **`U.BoundedContext`** for the spec (e.g., `FPF/Core`), cite governing guard‑rails (**E.5.\\***), and state **objectives** for the change (e.g., clarity ↑, universality ↑, assurance cost ↓).\n2. **Declare the Delta‑Class** (see §4.3) and **impact radius** (dependent patterns, bridges, tests).\n3. **Fix acceptance targets** (see §4.4 Quality & SoTA metrics).\n\n**Stage B — Generate candidates (SoTA + NQD)**\n4. **Harvest SoTA** inputs (standards, rival patterns, lived domain idioms) and **bind** them as *evidence* via `U.EvidenceRole` with **claim/claim‑scope/timespan** (empirical vs deductive lines).\n5. **Generate candidate variants** using **NQD‑CAL** engines (Novelty/Quality/Diversity) with an **E/E policy** (explore↔exploit governor) to populate a **Pareto front** of pattern phrasings/structures. *(No single shot; multiple candidate clauses compete.)*\n\n**Stage C — Shape & Align (Structure, Bridges, USM)**\n6. **Shape** top candidates into the standard **architectural template** (Context → Problem → Forces → Solution → CC → Consequences → Rationale), obeying **LEX‑BUNDLE** (no tooling jargon; twin registers allowed).\n7. **Bridge across Contexts** explicitly (F.9): any imported definitions/claims declare **CL** and *loss notes*; propose scoped **narrowing** where needed.\n8. **Type scopes** with **USM (A.2.6)**: keep **ClaimScope (G)** distinct from **WorkScope**; no “applicability/envelope” smuggling.\n\n**Stage D — Validate & Decide (Assurance, Tests, DRR)**\n9. **Run the harness**: update **SCR/RSCR** (F.15), lint lexical rules (E.10), run **Γ‑consistency** and **RSG/SoD** checks where relevant.\n10. **Score** candidates on **Quality & SoTA metrics** (§4.4) and **assurance deltas** (Δ⟨F,G,R⟩).\n11. Record a **DRR** (E.9) with *options considered*, *trade‑offs*, chosen candidate, *blast‑radius*.\n12. **Merge** the winner; version pattern **SemVer** by Delta‑Class.\n\n**Stage E — Publish & Monitor**\n13. Publish the **LEX‑AUTH Trace (LAT)** (§4.2) with the pattern.\n14. Schedule **evidence refresh** windows and an **evolution watchpoint** (B.4 loop): when metrics or SoTA inputs decay, reopen Stage B.\n\n#### E.15:4.2 - The **LEX‑AUTH Trace (LAT)** — what it is and why it matters\n\nA LAT is **not** “we ran a script.” It is a **structured episteme** that lets others **reproduce quality gains** and **re‑run** the search when SoTA shifts.\n\n**LAT minimal contents (publish with the pattern):**\n\n1. **Context & version** (pattern id, context, SemVer, Delta‑Class).\n2. **Objective vector** (what we tried to improve: clarity, universality, assurance cost, etc.).\n3. **SoTA pack** (sources bound as `U.EvidenceRole` with claim/scope/time and polarity).\n4. **NQD settings** (emitters/lenses, diversity characteristics) + **E/E policy** used.\n5. **Candidate set** (top K variants with NQD scores + short deltas from baseline).\n6. **Bridge ledger** (all cross‑context imports with **CL** and loss notes).\n7. **Assurance delta** (Δ⟨F,G,R⟩ from baseline; penalties from CL applied).\n8. **Harness results** (checks passed/failed, test diffs).\n9. **DRR link** (decision rationale id).\n10. **Refresh policy** (evidence decay windows and triggers).\n\n**Uses of the LAT:**\n*Reproducibility* (re‑run B‑stages as SoTA changes), *assurance* (explicit impact on F/G/R), *portfolio health* (diversity/coverage), *teaching* (didactic before/after), and *cross‑context safety* (no silent imports).\nPublish the pattern with a DRR that carries a LAT pointer (id/URI). The LAT itself is a U.Work evidence pack (non‑normative), archived with edition and Γ_time.\n\n**Example of a LAT‑stub**\n```\nLAT:\n  context: FPF/Core, pattern: F.15, semver: x.y+1, delta-class: Δ‑2\n  objectives: {clarity↑, universality↑, assurance-cost↓}\n  SoTA-pack: {OpenAlex 2025‑Q3, SPECTER2‑23, DPP‑2019, MAP‑Elites‑2015+}\n  NQD-settings: {CharacteristicSpace: domain‑family × …, grid: CVT@k=16}\n  candidates: K=4 (wording of RSCR‑F04 & gates)\n  bridge-ledger: none (intra‑canon refs only)\n  assurance‑delta: ΔF=+, ΔG=+, ΔR=+ (after CL‑penalties=0)\n  harness: LEX‑BUNDLE lint pass; F‑suite pass; Γ‑consistency ok\n  DRR-id: DRR‑2025‑09‑DFCM‑roll‑in\n  refresh: F1‑Card edition refresh window = 6 mo\n```\n\n#### E.15:4.3 - What counts as “changed the pattern as a whole” — **Delta‑Classes & versioning**\n\nClassify the intended change **before** work starts (declared in DRR & LAT):\n\n* **Δ‑0 Lexical polish** — wording/ordering only; **no** change to CC or semantics. → *Patch* (x.y.**z**+1).\n* **Δ‑1 Didactic restructure** — narrative/layout; **unchanged** Conformance Checklist (CC). → *Minor* (**x.y**+1.0).\n* **Δ‑2 Normative refinement** — CC tightened/clarified; *semantics preserved* by test equivalence. → *Minor* (**x.y**+1.0) + **RSCR** required.\n* **Δ‑3 Semantic change** — CC **adds/removes** requirements; downstream contracts shift. → *Major* (**x**+1.0.0) + **impact review** + **bridges refresh**.\n\n> **Definition of “pattern changed as a whole”:** any **Δ‑2/Δ‑3** change (i.e., the **normative surface** or **semantics** changed) counts as a pattern change in the canonical corpus and triggers harness & bridge reviews.\n\n#### E.15:4.4 - Quality & SoTA metrics (selection lenses)\n\n**Mandatory lenses** (declare in LAT; higher is better unless noted):\n\n* **Clarity** (readability; plain‑register score from didactic rubric).\n* **Universality** (C‑1): *≥3 heterogeneous domains* anchored in the Archetypal section.\n* **Lexical discipline** (E.10): 0 violations (DevOps lexicon, process/function conflations).\n* **Assurance delta**: ΔF (formality), ΔG (scope clarity), ΔR (reliability after CL penalties).\n* **Bridge integrity**:  Bridge integrity (policy lens): declare minimum CL thresholds per Context policy; penalties route to R only (B.3/F.9); record policy‑id in LAT.\n* **Test conformance**: F‑suite pass; RSCR clean.\n* **Exploration health** (NQD): diversity coverage > threshold; no premature convergence.\n* **Didactic economy**: length vs density ratio within band; “Tell‑Show‑Show” present.\n\n**Optional lenses** (context‑specific): *Ethical/SoD guard strength; cross‑scale roll‑up integrity; aggregation proofs present;* etc.",
        "conformance_checklist": "### E.15:5 - Conformance Checklist (normative)\n\n**CC‑LA‑1 (Context anchoring).**\nEvery authoring run **MUST** declare a `U.BoundedContext`, Delta‑Class, objectives, and acceptance lenses **before** generating candidates.\n\n**CC‑LA‑2 (SoTA as evidence).**\nExternal inputs **MUST** be bound as `U.EvidenceRole` epistemes with **claim, claim‑scope, polarity, timespan** (formal/empirical lines). No raw links.\n\n**CC‑LA‑3 (Open‑ended generation).**\nAt least **K≥3** candidate variants **MUST** be generated via **NQD‑CAL** with a declared **E/E policy**; single‑shot edits violate LEX‑AUTH.\n\n**CC‑LA‑4 (Bridges & CL).**\nAny cross‑context reuse **MUST** appear in a **Bridge** with **CL** and *loss notes*. CL penalties apply to **R‑lane** when scoring.\n\n**CC‑LA‑5 (Harness).**\nThe candidate winner **MUST** pass **LEX‑BUNDLE** lint, **SCR/RSCR** tests, Γ‑consistency, and SoD/RSG gates where applicable.\n\n**CC‑LA‑6 (Assurance deltas).**\nThe LAT **MUST** publish Δ⟨F,G,R⟩ relative to baseline, explicitly accounting for CL penalties and any narrowed scopes.\n\n**CC‑LA‑7 (DRR).**\nA **DRR** entry is mandatory for Δ‑2/Δ‑3 changes; it records options considered, rationale, and impact radius.\n\n**CC‑LA‑8 (Refresh plan).**\nEmpirical evidence in the LAT **MUST** carry a **decay/refresh** window; a watchpoint **MUST** be scheduled in the Canonical Evolution Loop.\n\n**CC‑LA‑9 (Publication).**\nPublish the **pattern + LAT** together; past LATs are immutable. New runs produce new LATs.\n",
        "consequences": "### E.15:6 - Consequences\n\n**Benefits.**\n*Evolutive quality*: patterns improve through **search + selection**, not edits by fiat. *Auditability*: a re‑runnable **LAT** shows *why* the chosen variant won. *Safety*: cross‑context reuse is explicit and penalized appropriately. *Comparability*: Δ‑classes & SemVer let downstream readers predict blast‑radius.\n\n**Trade‑offs.**\nSome ceremony (LAT/DRR, NQD lenses) and maintenance (evidence refresh, bridge upkeep). These costs buy reproducibility and SoTA tracking.\n",
        "rationale": "### E.15:7 - Rationale & Links (informative)\n\nLEX‑AUTH extends the FPF constitution by **operationalising pattern evolution**: it plugs **B.4 Canonical Evolution Loop** into **E.9 DRR**, binds **SoTA** via `U.EvidenceRole` and **KD‑CAL**, drives **candidate generation** with **C.18 NQD‑CAL** under **C.19 E/E‑LOG**, enforces **lexical discipline** via **E.10 LEX‑BUNDLE**, and validates with **F.15** regression harnesses. Cross‑context safety is carried by **F.9 Bridges** with **CL penalties** in **B.3 Trust**. The whole remains **notation‑independent** (E.5.2) and stays within the **Core → Tooling → Pedagogy** dependency rule (E.5.3).\n",
        "operators_(authoring_deltas_you_are_allowed_to_apply)": "### E.15:8 - Operators (authoring deltas you are allowed to apply)\n\n* **Refine** (tighten CC without changing acceptance meaning).\n* **Split/Merge** (factor patterns; preserve links; update Bridges).\n* **Generalise/Constrain** (expand/restrict ClaimScope (G) with proofs or loss notes).\n* **Rephrase** (clarify language; leave CC untouched).\n\nEach operator carries a default **Delta‑Class** and test obligations.\n",
        "self‑application_work_log_(how_this_very_pattern_was_authored)": "### E.15:9 - Self‑application Work Log (how this very pattern was authored)\n\n> *This is **not** chain‑of‑thought; it is the required **`U.Work` evidence** for LEX‑AUTH.*\n\n**Context.** `FPF/Core` (Canon); **Delta‑Class:** Δ‑2 (normative refinement by addition of method & CCs).\n**Objectives.** Add an *evolutionary* authoring method; make trace *useful* (quality‑bearing); align with SoTA machinery already in spec.\n**SoTA pack (evidence bound).** Prior FPF kernel commitments to **DRR (E.9)**, **E.10 LEX‑BUNDLE**, **B.4 Evolution**, **C.18/C.19** NQD/E‑E, **F.15** harness, **F.9** Bridges, **B.3** Trust; these are treated as the authoritative internal SoTA for the Canon here.\n**NQD/E‑E.** Generated ≥3 alternative Solution sections; finalist chosen for clearer Δ‑classes and actionable LAT contents.\n**Bridges.** No cross‑external mapping; intra‑canon references only (CL=3).\n**Harness.** LEX‑BUNDLE lint (no tooling jargon), CCs unique/atomic, didactic “Tell‑Show‑Show” via Self‑application log, Universality criterion met by cross‑kernel applicability.\n**Assurance Δ.** F: + (explicit method & CCs); G: + (scope separation & Δ‑classes); R: + (LAT obligations + bridge penalties).\n**DRR.** Recorded: alternatives considered (lighter trace vs full LAT), chosen design (full LAT).\n**Refresh.** Reopen when SoTA (e.g., G‑suite authoring kit or CHR templates) evolves or when LAT misuse is seen in reviews.\n",
        "e.15:end": "### E.15:End\n"
      },
      "content": "### E.15:End\n",
      "metadata": {},
      "part": "E",
      "cluster": null
    },
    {
      "id": "E.16",
      "title": "RoC‑Autonomy Budget & Enforcement",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## E.16 - RoC‑Autonomy Budget & Enforcement\n\n**Intent.** Make any claim of autonomous behavior testable and enforceable via a published **AutonomyBudgetDecl**, **Guarded enactment**, **Override SpeechActs with SoD**, and a **Work‑anchored AutonomyLedger**. \n**Rule (summary).** If a Role/Method/Service claims autonomy, authors **MUST**: (i) publish an `AutonomyBudgetDecl` with `AdmissibilityConditionsId` and `OverrideProtocolRef`; (ii) gate Method steps with `requiresAutonomyBudget`; (iii) write a `AutonomyLedgerEntry` on every admitted Work; (iv) block on depletion until a `ResumeAutonomy` SpeechAct passes SoD; (v) surface autonomy fields in UTS rows.\n\n**Builds on:** A.2 / A.2.1 / A.2.5 / A.15 / A.21; B.3; C.16; E.8; E.10; E.18; F.4; F.6; F.8; F.15; F.17.\n**Coordinates with:** A.13 (Agential Role), C.9 (Agency‑CHR), C.24 (Agent‑Tools‑CAL) where applicable; G.4–G.5–G.8–G.9–G.10 (method authoring/selection/shipping).\n",
        "problem": "### E.16:2 - Problem\n\n* **Opaque autonomy.** Patterns assert “autonomous” behavior with no **budget** or **enforcement**.\n* **Un‑gated execution.** Methods can execute beyond authority or risk limits.\n* **Ad‑hoc overrides.** No standard **SpeechAct** for pausing/de‑scoping; SoD is unclear.\n* **Non‑portable publication.** **UTS (Unified Term Sheet)** rows cannot surface autonomy‑critical data for parity or selection.\n",
        "forces": "### E.16:3 - Forces\n\n| Force                          | Tension                                                                  |\n| ------------------------------ | ------------------------------------------------------------------------ |\n| **Creativity vs Safety**       | Exploration autonomy vs hard constraints and override duties             |\n| **Locality vs Comparability**  | Context‑local rules vs cross‑context selection (G‑suite)                 |\n| **Simplicity vs Auditability** | Lightweight authoring vs ledger‑grade evidence                           |\n| **Autonomy vs SoD**            | Helpful self‑action vs separation‑of‑duties and human‑in‑the‑loop points |\n",
        "bias_annotation": "### E.16:3.1 - Bias-Annotation\n\n**Lenses tested:** `Gov`, `Arch`, `Onto/Epist`, `Prag`, `Did`. **Scope:** Universal for any Role/Method/Service that claims autonomous operation (unsupervised decision or actuation) and is admitted via `AutonomyBudgetDecl` + Green‑Gate. It is **not** aimed at purely assistive “suggestion‑only” tools where each action is confirmed by a human at the point of execution.\n\n* **Gov.** Bias toward enforceable oversight (hard gates, SoD, canonical override SpeechActs). Mitigation: exploration autonomy is still allowed, but only inside an explicit budget and time window.\n* **Arch.** Bias toward gate‑and‑ledger structure (Green‑Gate + Work‑anchored `AutonomyLedger`). Mitigation: `telemetrySpecRef` can scope what is emitted when full deltas are unnecessary.\n* **Onto/Epist.** Bias toward typed, testable constraints (MM‑CHR tokens, explicit admissibility checks). Mitigation: budgets are optional‑field (`?`) so low‑risk contexts can start minimal and tighten over time.\n* **Prag.** Bias toward measurable quotas may under‑express “soft” autonomy goals. Mitigation: pair `decision_tokens` with `risk_bands` to capture non‑counting limits.\n* **Did.** Bias toward explicit mechanics increases authoring surface area. Mitigation: provide a default `AutonomyBudgetDecl` template and minimal harness cases in **F.15**.\n",
        "solution": "### E.16:4 - Solution — **Rule‑of‑Constraints (RoC) for Autonomy**\n\nThis RoC **applies whenever** a Role/Method/Service **claims autonomous operation** (any phrasing that implies unsupervised decision or actuation).\n\n**E.16‑S1 (Autonomy Budget — mandatory).**\nAny autonomy claim **MUST** publish an **AutonomyBudgetDecl** as a *named, versioned* object in the **same `U.BoundedContext`**:\n\n```\nAutonomyBudgetDecl {\n  id, version\n  scope: ClaimScope (G)                              // where this budget applies\n  budget: {                                          // all typed via MM‑CHR (C.16)\n    action_tokens?     : Unitful quota / rate\n    decision_tokens?   : Unitful quota / rate\n    risk_bands?        : CHR vector with acceptance bands\n    resource_caps?     : set of unitful caps (Γ_work categories)\n    time_window?       : Γ_time window & cadence\n  }\n  AdmissibilityConditionsId : PolicyIdRef                          // Aut-Guard policy naming gates & penalties\n  overrideProtocolRef : Episteme                     // SpeechAct & SoD for pause/resume/escalate\n  telemetrySpecRef? : Episteme                       // what to emit into AutonomyLedger\n  editionPins : { RoleRef?, MethodDescRef?, CHR refs, …  } \n}\n```\n\n**E.16‑S2 (Guarded enactment — Green‑Gate).**\nA **Method step** that *requires* autonomy **MUST** list `requires: [RoleX]` **and** `requiresAutonomyBudget: AutonomyBudgetDecl.id`. A **Work** instance is admissible *iff* at enactment time:\n\n* the performer’s **RoleAssignment** is valid and in an **enactable** RSG state (A.2.5);\n* the budget accounting for the **AutonomyBudgetDecl** indicates **tokens/limits remaining** for *this* budget in the declared **Γ_time** window (derived from the AutonomyLedger);\n* all **guard checks** defined by `AdmissibilityConditionsId` evaluate to **pass** (e.g., risk ≤ band, resource ≤ cap).\n\nFailing any gate **blocks** enactment (no “soft warnings” on Core surface).\n\n**E.16‑S3 (Autonomy Ledger).**\nAll admissible Work **MUST** record **AutonomyLedger entries**:\n\n```\nAutonomyLedgerEntry {\n  workId, performedBy: RoleAssignmentId\n  budgetId, version, time\n  deltas: { action_tokensΔ?, decision_tokensΔ?, riskΔ?, resourceΔ? }\n  guardVerdicts: { name → pass|fail }\n  pathIds: { PathId, PathSliceId }                  // for G‑suite parity/refresh\n}\n```\n\nThe ledger is **evidence**: attach to `U.Work` (A.15.1) and fold under **Γ_work** and **Γ_time** for reporting.\n\n**E.16‑S4 (Overrides — SpeechActs & SoD).**\nEvery budget **MUST** reference an **OverrideProtocolRef** that defines canonical **SpeechActs**:\n\n* **PauseAutonomy(budgetId)** — immediate stop of autonomy‑gated steps;\n* **ResumeAutonomy(budgetId)** — resume after conditions;\n* **NarrowAutonomy(budgetId, Δscope)** — apply stricter limits;\n* **Escalate(budgetId)** — handover to a declared **SupervisorRole**.\n\n**SoD:** The override caller **MUST NOT** be the same **RoleAssignment** that is consuming the budget (enforce `⊥` in the Context). All overrides are **Work** (SpeechActs) with **ledger entries** (zero or negative deltas as per policy).\n\n**E.16‑S5 (Depletion behavior).**\nWhen a budget **depletes** (no tokens / envelope exceeded / cap breached):\n\n* **Block** further autonomy‑gated steps in the **same Γ_time window**;\n* Emit **DepletionNotice** (SpeechAct), and either **Escalate** or **Park** per policy;\n* Only a **ResumeAutonomy** SpeechAct from an admissible Role (per SoD) may reopen the gate.\n\n**E.16‑S6 (Publication in UTS).**\nUTS rows that describe a **Role**, **Method**, **Service**, or **Selector** with autonomy **MUST** include:\n\n* `AutonomyBudgetDeclRef` (id & version);\n* `Aut-Guard policy-id (PolicyIdRef)`;\n* `OverrideProtocolRef`;\n* declared **Scope (G)** and **Γ_time** window;\n* edition pins for the referenced Role/Method/CHR.\n* *(optional, if a scale preference is declared)* `ScaleLensPolicyRef` and `ScaleLensOptIn ∈ {OptedIn, Neutral, OptedOut}`.\n\n**E.16‑S7 (Scale & selection — optional lens).**\nWhen autonomy interacts with open‑ended search (C.18/C.19), **budget consumption** and **guard violations** are **selection lenses** in Part G (G.5/G.9). Applying a **Scale‑Lens / Bitter‑Lesson** preference is **OPTIONAL**. Authors **MAY** declare a **ScaleLensPolicy** for the autonomy claim; when declared, it **MUST** state:\n* **Trigger criteria** — evidence that expected utility‑of‑scale is monotonic/non‑saturating on held‑out tasks, and a threshold at which scaling beats structured heuristics.\n* **Budget fit** — compute/latency/cost targets **within** the declared `AutonomyBudgetDecl` (Γ_time, resource_caps).\n* **Safety invariants** — guards and SoD remain **non‑weakened** under scaling; no policy may bypass E.16 gates.\n* **Fallback** — a degrade‑gracefully plan if scaling fails to clear the trigger criteria within budget.\nIf no **ScaleLensPolicy** is declared, selection remains **neutral** with respect to Bitter‑Lesson; RoC does **not** authorize ignoring scale‑safety guards under any policy.\n",
        "archetypal_grounding": "### E.16:5 - Archetypal grounding (Tell‑Show‑Show; human‑centric)\n\n**Show‑A (U.System — mobile robot).**\n`Robot_R7#NavigatorRole:Warehouse_2026` executes `Navigate_v3`.\n`AutonomyBudgetDecl`: `action_tokens=10 k steps/day`, `risk_bands={maxSpeed ≤ 1.2 m/s, minDist ≥ 0.5 m}`, `resource_caps={battery ≥ 20%}`; `AdmissibilityConditionsId=Aut‑Guard‑R7‑v1`; override via `PAUSE`, `RESUME`, `ESCALATE` SpeechActs by `FloorSupervisorRole ⊥ NavigatorRole`. Ledger entries decrement `action_tokens`, track `minDist`. Depletion at 0 tokens halts autonomous moves and pages supervisor.\n\n**Show‑B (U.ServiceClause — autonomous deploy).**\n`DeployerRole` performs step “Promote to prod” under `AutonomyBudgetDecl` with `decision_tokens=3/day`, `risk_envelope={error‑budget burn ≤ 2% / day}`, guard “all pre‑deploy checks pass”. Overrides only by `CABChair#AuthorizerRole ⊥ DeployerRole`.\n",
        "conformance_checklist": "### E.16:9 - Mini conformance checklist (cross‑E–F; author’s quick use)\n\n1. **Declare** `AutonomyBudgetDecl` (scope, budgets, AdmissibilityConditionsId, overrides).\n2. **Gate** steps with `requiresAutonomyBudget`.\n3. **Emit** an `AutonomyLedgerEntry` for each admitted Work.\n4. **Enforce SoD** on override SpeechActs; **block on depletion**.\n5. **Publish** UTS autonomy fields for any autonomy‑bearing Role/Method/Service.\n\n*(These five are sufficient for a working test harness in Part F.)*\n",
        "consequences": "### E.16:7 - Consequences\n\n* **Testability.** Autonomy is measurable (tokens/envelopes), audit‑ready (ledger), and stoppable (SpeechActs).\n* **Comparability.** UTS surfaces autonomy metadata for fair selection & parity.\n* **Safety.** Guards are hard gates; depletion halts further autonomy‑gated Work.\n",
        "e.16:7.1___sota‑echoing_(post‑2015_practice_alignment)": "### E.16:7.1 - SoTA‑Echoing (post‑2015 practice alignment)\n\n> Each item states **Adopt / Adapt / Reject**, and why. Vendor/tool tokens are kept as *informative*, not normative.\n\n1. **Corrigibility & safe interruptibility (2016→).**  \n   **Adopt/Adapt.** Work on safe interruption and “off‑switch” incentives argues that capable systems should remain *stoppable* and should not be rewarded for resisting oversight (Orseau & Armstrong, 2016; Hadfield‑Menell et al., 2017). E.16 adapts this into canonical **PauseAutonomy / ResumeAutonomy** SpeechActs plus **SoD** and *hard* gating on depletion.\n\n2. **AI safety as concrete operational hazards (2016→).**  \n   **Adopt.** “Concrete Problems in AI Safety” pushes instrumentation and testable safety constraints over informal assurances (Amodei et al., 2016). E.16 mirrors this by turning “autonomy” into a **budget + ledger + guards** contract that can be benchmarked and audited.\n\n3. **SRE error budgets & “stop the line” operations (2016→).**  \n   **Adopt/Adapt.** Error‑budget practice treats reliability as a measurable envelope that gates risky change when depleted (Beyer et al., *Site Reliability Engineering*, 2016; Höller et al., *The Site Reliability Workbook*, 2018). E.16 adapts the idea into `risk_bands` and depletion behavior that blocks autonomy‑gated steps until governed resume.\n\n4. **Risk management frameworks for AI systems (2023→).**  \n   **Adopt/Adapt.** Contemporary risk frameworks emphasize governance, continuous measurement, and traceable controls (NIST AI RMF 1.0, 2023; ISO/IEC 23894, 2023). E.16 adapts these into **UTS publication** + **Work‑anchored ledger evidence** for parity and audit.\n\n5. **Policy‑as‑code and provenance gating (2019→).**  \n   **Adopt.** Modern supply‑chain integrity systems emphasize *policy‑checked actions with verifiable provenance* (in‑toto, 2019→; SLSA, 2021→). E.16 echoes the same principle for autonomy: **no autonomy‑gated enactment without passing declared guards and emitting ledger evidence** (without importing any specific tooling).\n\n6. **Scaling laws & the Bitter Lesson (2019→).**  \n   **Adapt/Reject.** Empirical scaling work and the Bitter Lesson motivate considering compute‑heavy search when returns are monotonic (Sutton, 2019; Kaplan et al., 2020). E.16 adapts this into an **optional** ScaleLensPolicy (E.16‑S7) constrained by the *same* budgets and guards, and **rejects** any interpretation that lets “scale” bypass safety gates.\n",
        "anti_patterns": "### E.16:7.2 - Common Anti-Patterns and How to Avoid Them\n\n| Anti-pattern | Symptom | Why it fails | Repair |\n| --- | --- | --- | --- |\n| **Autonomy-by-label** | “Autonomous” is claimed but there is no `AutonomyBudgetDecl` or ledger | Autonomy becomes opaque; cannot be audited or compared | Require **E.16‑S1/S3**; reject publication without `AutonomyBudgetDeclRef` + version |\n| **Soft gates** | Budget/guards only warn; enactment proceeds anyway | Violates Safety and SoD; makes budgets non-enforceable | Make Green‑Gate **blocking** on Core surface (**E.16‑S2**) |\n| **Self‑override** | Same RoleAssignment consumes the budget and calls Resume/Narrow | Conflict of interest; SoD collapse | Enforce `⊥` between consumer and overrider (**E.16‑S4**) |\n| **Budget bypass via “scale”** | Scaling preference weakens guards or ignores caps | Undermines declared limits; breaks comparability | In ScaleLensPolicy, **guards/SoD must remain non‑weakened** (**E.16‑S7**) |\n| **Untyped quotas** | Tokens/caps are recorded without units, or units are mixed | Ledger becomes non-comparable; audits become meaningless | Type budgets and deltas via **MM‑CHR (C.16)**; keep unitful rates/quotas |\n| **Ledger-as-logging** | Logs exist but are not Work‑anchored (no workId/budgetId/version/pins) | Evidence is non-portable; cannot support parity/refresh | Require `AutonomyLedgerEntry` attached to `U.Work` with ids, versions, and edition pins |\n",
        "rationale": "### E.16:8 - Rationale & E‑/F‑/G‑links\n\n* **E.8** — follows the pattern template (Context → Problem → Forces → Solution → Grounding → CC → Consequences).\n* **E.10** — uses LEX‑BUNDLE: Scope via **ClaimScope (G)**, time via **Γ_time**, no “validity/process/actor/agent‑as‑noun” language; new lexical rule **L‑AUTO** added in edits below.\n* **Mint/reuse authority (policy-ids).** Mint/reuse authority is expressed via **F.8:8.1** (`PolicyIdRef`: `PolicySpecRef` + `MintDecisionRef?`) and explicit **GateCrossing** checks (**E.18**) evaluated by the active **GateProfile/GateFit** (**A.21**); no tier ladder is required.\n* **Part F** — integrates with **F.4** Role Description (RCS includes *AgencyLevel*; RSG gates), **F.6** Role Assignment & Enactment (Green‑Gate), **F.15** SCR/RSCR (harness includes depletion/override tests), **F.17** UTS (columns, incl. optional ScaleLens fields).\n* **Part G** — **G.4/G.5**: method authors must declare budgets & guards; **G.9** parity includes autonomy consumption & violations; **G.10** shipping requires UTS autonomy fields.\n",
        "e.16:end": "### E.16:End\n"
      },
      "content": "### E.16:End\n",
      "metadata": {},
      "part": "E",
      "cluster": null
    },
    {
      "id": "E.17.0",
      "title": "`U.MultiViewDescribing — Viewpoints, Views & Correspondences`",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## E.17.0 - `U.MultiViewDescribing — Viewpoints, Views & Correspondences`\n\n> **Tech‑name:** `U.MultiViewDescribing`\n> **Plain‑name:** multi‑view describing (viewpoints, views, correspondence for families of descriptions/specifications)\n\n**Status & placement.** Part E (Describing & Publication). Normative architectural pattern.\n**Builds on:** C.2.1 `U.EpistemeSlotGraph` (DescribedEntity/Viewpoint/View slots), A.6.2 `U.EffectFreeEpistemicMorphing`, A.6.3 `U.EpistemicViewing`, A.6.4 `U.EpistemicRetargeting`, A.7 (Strict Distinction; I/D/S vs Surface), E.10.D1 (Context), E.10.D2 (I/D/S discipline).\n**Used by:** E.17 (MVPK — publication as a specialisation of multi‑view describing for morphisms), E.17.1 `U.ViewpointBundleLibrary`, E.17.2 `TEVB`, E.18:5.12 (E.TGA engineering viewpoint families), domain‑specific description schemes (architecture, safety cases, governance, research). \n\n**Guard (lexical).**\n\n* `U.Viewpoint` is the ValueKind of `ViewpointSlot` and denotes **intensional viewpoint specs**, not surfaces or carriers. \n* `U.View` is an alias of `U.EpistemeView`, i.e. an **episteme‑level view**, not a document or file. Views are epistemes; Surfaces are carriers in L‑SURF.\n* `ViewFamilyId` is a lexical tag for **families of viewpoints** (e.g. TEVB), never for view kinds, MVPK `U.View`/`U.ViewFamily(-)` bundles or Surface kinds. MVPK face kinds remain `{PlainView, TechCard, InteropCard, AssuranceLane}`. \n",
        "problem": "### E.17.0:2 - Problem  *(informative, but sharp)*\n\nWithout `U.MultiViewDescribing`:\n\n1. **Viewpoints, views, and surfaces collapse.**\n   In practice, “architecture view”, “diagram”, “spec”, and “published deck” are used interchangeably. This:\n\n   * confuses *episteme* (`U.View`) with *carrier* (`U.Surface`),\n   * hides which **concerns and stakeholders** a description is written for,\n   * makes it impossible to check whether a given description family is “complete enough” for a chosen viewpoint library.\n\n2. **Descriptions float without viewpoints.**\n   Legacy I/D/S discipline distinguishes Intension vs Description vs Spec, but does not, on its own, forbid “view‑from‑nowhere” descriptions (no declared viewpoint). That contradicts the pragmatic stance encoded in C.2.1: **no episteme without concerns**.\n\n3. **Each domain reinvents multi‑view semantics.**\n   Architecture, safety cases, governance frameworks, and research workflows all use local notions of “view”, “viewpoint”, and “consistency between views”. Without a shared pattern:\n\n   * E.TGA, MVPK, and discipline packs introduce their own “view” laws, duplicating work;\n   * cross‑domain reasoning (e.g. mapping a safety view to an architecture view) becomes ad‑hoc;\n   * we cannot give a single formal story for consistency, correspondence, and EpistemicViewing across families of descriptions.\n\n4. **No place to attach correspondence.**\n   ISO 42010‑style *correspondences* and modern BX/consistency relations have nowhere canonical to live. We need a **CorrespondenceModel over families of D/S epistemes** that integrates with `U.EpistemicViewing`/`U.EpistemicRetargeting` and C.2.1’s slot graph.\n",
        "forces": "### E.17.0:3 - Forces  *(informative)*\n\n| Force                                  | Tension                                                                                                                                                                                |\n| -------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **Universality vs domain idioms**      | One pattern should handle engineering, safety, governance, research, etc. ↔ domain communities expect their own jargon (architecture description, safety case, dossier…).              |\n| **Viewpoint locality vs reuse**        | Viewpoints must be local to families of descriptions (`EoIClass`, Context) ↔ we want reusable **viewpoint bundles** (libraries) across projects and domains.                           |\n| **I/D/S strictness vs pragmatics**     | Intension ≠ Episteme; D/S are epistemes with DescriptionContext ↔ engineers think in “views over a system”, not in pure I/D/S algebra.                                                 |\n| **Slot discipline vs approachability** | C.2.1/A.6.5 give a clean SlotKind/ValueKind/RefKind discipline ↔ authors want to talk about “functional view” and “safety view” without carrying all slot jargon in didactic material. |\n| **Epistemic vs surface layers**        | Views (epistemes) must be clearly separated from PublicationSurface and carriers ↔ authors often conflate “viewpoint”, “view”, and “document”.                                         |\n| **Consistency vs incremental change**  | We want strong correspondence between views ↔ views evolve asynchronously; partial inconsistency must be representable and repairable (BX‑style).                                      |\n",
        "solution": "### E.17.0:4 - Solution — `U.MultiViewDescribing` as the universal multi‑view scaffold  *(normative core)*\n\n#### E.17.0:4.1 - Overview\n\n`U.MultiViewDescribing` organises **families of descriptions/specifications** for a shared entity‑of‑interest into a multi‑view structure with:\n\n* **explicit viewpoints** (`U.Viewpoint`) as intensional specs of stakeholders, concerns, allowed D/S kinds, and conformance rules; \n* **episteme‑level views** (`U.View = U.EpistemeView`) as view‑epistemes over those descriptions/specs; \n* a **CorrespondenceModel** capturing correspondences between D/S and their views across viewpoints.\n\nThe pattern is **parameterised by a class of described entities**:\n\n> **Parameter:** `EoIClass ⊑ U.Entity` — the class of entities‑of‑interest\n> (typical species: `U.Holon` for engineering holons, `U.Morphism` for morphism publication, `U.Episteme` for meta‑describing epistemes).\n\nAll members of a `U.MultiViewDescribing[EoIClass]` family share:\n\n* `DescribedEntitySlot` value in that `EoIClass`, and\n* a `BoundedContextRef` (E.10.D1) forming a **DescriptionScope** together with the entity. \n\nInformally:\n\n* Fix an entity `T ∈ EoIClass` and a bounded context `C`.\n* The **multi‑view family** for `<T,C>` consists of a set of `…Description` / `…Spec` epistemes, each under a declared viewpoint, plus their `U.View` views, together with a correspondence model relating them.\n\n#### E.17.0:4.2 - Core constructs\n\n##### E.17.0:4.2.1 - `EoIClass` and DescriptionScope\n\n1. **EoIClass.**\n   A `U.MultiViewDescribing` instance declares an `EoIClass ⊑ U.Entity` that acts as a **species‑level constraint** on the ValueKind of `DescribedEntitySlot`.\n\n   * In engineering species (TEVB) this is typically `U.Holon` restricted to `U.System` or `U.Episteme`. \n   * In MVPK, `EoIClass = U.Morphism`. \n\n2. **DescriptionScope (informal).**\n   For a fixed `T ∈ EoIClass` and `C : U.BoundedContext`, the **DescriptionScope** `Scope(T,C)` is the notional scope under which:\n\n   * all descriptions/specifications have `DescribedEntityRef = T` and `BoundedContextRef = C` in their DescriptionContext; \n   * all views (`U.View`) attached to this family preserve that `DescribedEntityRef` and `BoundedContextRef` (for D/S views).\n\n   Formal USM treatment of `U.DescriptionScope` is fixed in E.10/L‑SURF; here we only rely on the intuition “**we are describing this thing, in this context**”.\n\n##### E.17.0:4.2.2 - `U.Viewpoint` (intensional viewpoint spec)\n\n`U.Viewpoint` is already introduced in C.2.1 as the ValueKind of `ViewpointSlot`; E.17.0 fixes its **internal structure** for describing families. \n\n**Definition (normative, intensional).**\nA `U.Viewpoint` is an intensional specification:\n\n* `EoIClassSpec ⊑ U.Entity` — the class of entities this viewpoint is defined for (must be compatible with the family’s `EoIClass`);\n* `StakeholderFamilies : FinSet(U.RoleEnactor)` — stakeholder / RoleEnactor families the viewpoint speaks for (e.g. “safety engineers”, “operations teams”).\n* `Concerns : FinSet(U.Concern)` — concern set (qualities, risks, obligations) that matter under this viewpoint.\n* `AllowedEpistemeKinds : FinSet(U.EpistemeKindId)` — which D/S episteme kinds are admissible as **primary descriptions** and as **derived views** under this viewpoint (e.g. system‑level behaviour description, test harness spec, safety case, CG‑Spec slice).\n* `ConformanceRules` — a structured bundle of rules/tests describing when a D/S episteme or view **conforms** to the viewpoint, including:\n\n  * minimal content requirements (e.g. “must cover all safety‑critical functions”),\n  * admissible `U.EpistemicViewing` pipelines to derive views from base descriptions,\n  * allowed degrees of incompleteness and evidence requirements (link to GateProfiles/`OperationalGate(profile)` checks and Part F harnesses).\n\n**Slot alignment.**\n\n* `ViewpointSlot` has ValueKind `U.Viewpoint`, RefKind `U.ViewpointRef`; episteme fields are named `viewpointRef : U.ViewpointRef?`. \n* For D/S epistemes in a `U.MultiViewDescribing` family, `viewpointRef` is **mandatory** as part of `DescriptionContext`.\n\n##### E.17.0:4.2.3 - `U.View` (episteme‑level views)\n\n`U.View` is an alias for `U.EpistemeView`, a species of `U.Episteme` whose kind includes:\n\n* `ClaimGraphSlot` (often a sliced or projected ClaimGraph),\n* `DescribedEntitySlot`,\n* `ViewpointSlot`,\n* `ReferenceSchemeSlot` (and usually a `RepresentationSchemeSlot` in C.2.1+).\n\nNormatively:\n\n* A `U.View` in `U.MultiViewDescribing` is obtained via a `U.EpistemicViewing` morphism from some base D/S episteme in the family (see 4.3). It **shares the same `describedEntityRef`** and usually the same `BoundedContextRef`.\n* `ViewSlot` is reserved for **references to such views** in meta‑structures (e.g. correspondence models, MVPK view families), never for carriers.\n\n##### E.17.0:4.2.4 - `U.CorrespondenceModel` (view–view correspondence)\n\n`U.CorrespondenceModel` is an episteme (typically a `U.EpistemeCard`) whose ClaimGraph expresses **correspondence relations between D/S epistemes and/or views** within a DescriptionScope:\n\n* cross‑viewpoint correspondences (e.g. “this safety requirement is realised by this design element”),\n* structural/behavioural consistency conditions (BX‑style consistency relations),\n* change‑impact links (which views must be revisited when some view changes).\n\n`CorrespondenceModel` is **used, but not defined, by A.6.3**: species of `U.CorrespondenceEpistemicViewing` reference it when computing views that depend on multiple epistemes or representation regimes.\n\n#### E.17.0:4.3 - Multi‑view families and their laws (MVD‑0…MVD‑7)  *(normative)*\n\nWe now fix the laws that any `U.MultiViewDescribing[EoIClass]` instance must satisfy.\n\n##### E.17.0:4.3.0 - MVD‑0 - Family objects\n\nFor a fixed `EoIClass` and bounded context `C`, a **multi‑view family** for an entity `T ∈ EoIClass` consists of:\n\n* a (finite) set `D_S(T,C)` of D/S epistemes such that for each `E ∈ D_S(T,C)`:\n\n  * `E : U.Episteme` of some kind in `AllowedEpistemeKinds` of its viewpoint,\n  * `subjectRef(E)` decodes to `DescriptionContext(E) = ⟨DescribedEntityRef = T, BoundedContextRef = C, ViewpointRef(E)⟩`,\n  * `viewpointRef(E)` lies in the family’s viewpoint set `Σ ⊆ FinSet(U.Viewpoint)`;\n* a set `Views(T,C) ⊆ U.View` of view‑epistemes over those D/S epistemes, obtained by declared `U.EpistemicViewing` species (see MVD‑3);\n* zero or more `U.CorrespondenceModel` epistemes over `{D_S(T,C), Views(T,C)}`.\n\nFamilies are **scoped**: the same entity in a different `U.BoundedContext` belongs to a different family.\n\n##### E.17.0:4.3.1 - MVD‑1 - Viewpoint locality and totality for D/S\n\nFor any multi‑view family:\n\n1. **Viewpoint‑totality for D/S.**\n   Each D/S episteme in `D_S(T,C)` **MUST** have a `viewpointRef` either:\n\n   * explicitly populated, or\n   * deterministically derived from a `U.ViewpointBundle` the family declares (see E.17.1).\n\n   There are no “viewpoint‑free” D/S epistemes inside a `U.MultiViewDescribing` family.\n\n2. **Viewpoint locality.**\n   `ViewpointRef` values for `D_S(T,C)` must belong to a **finite viewpoint set `Σ`** declared for the family (locally or via a bundle). Cross‑family reuse happens **via bundles and Bridges**, not by silently sharing viewpoints across unrelated scopes.\n\n3. **DescriptionContext alignment.**\n   `DescriptionContext(E)` for any D/S episteme in the family must use the **same `DescribedEntityRef` and `BoundedContextRef`** as the family; any change of described entity or context is **outside this family** and must be expressed via `U.EpistemicRetargeting` and/or Context Bridges.\n\n#### E.17.0:4.3.2 - MVD‑2 - Views are EpistemicViewing results\n\nFor any `V ∈ Views(T,C)`:\n\n1. There exists a base episteme `E ∈ D_S(T,C)` and a morphism `v : E → V` such that:\n\n   * `v` is a species of `U.EpistemicViewing`, i.e. an **effect‑free, describedEntity‑preserving** episteme morphism;\n   * `describedEntityRef(V) = describedEntityRef(E) = T`,\n   * `BoundedContextRef(V) = BoundedContextRef(E) = C`,\n   * `viewpointRef(V)` is either:\n\n     * the same as `viewpointRef(E)` (internal normalisation), or\n     * a viewpoint in the same family `Σ`, with the change recorded in the family’s `CorrespondenceModel` (see MVD‑4).\n\n2. No view may be introduced “out of thin air”: every `U.View` in the family is traceable to at least one D/S episteme (or a finite diagram thereof) via a **documented EpistemicViewing pipeline**.\n\n3. Views **do not introduce new intensional commitments** about `T` beyond what is licensed by EFEM & EpistemicViewing laws (no new atomic claims about the same described entity). Strengthening Intension requires new D/S under A.7/E.10.D2, not a view.\n\n#### E.17.0:4.3.3 - MVD‑3 - Applicability profiles for viewings\n\nAny EpistemicViewing species used inside `U.MultiViewDescribing` **MUST**:\n\n* declare an Applicability profile as per EV‑6: permitted `EoIClass`, grounding, viewpoint ranges, and representation schemes; \n* for D/S epistemes in a family:\n\n  * **preserve** `DescribedEntityRef` and `BoundedContextRef` of `DescriptionContext`,\n  * either preserve `ViewpointRef` or change it **within the family’s viewpoint bundle**, with constraints recorded in `CorrespondenceModel`,\n  * never widen ClaimScope beyond EFEM/EpistemicViewing allowances.\n\nAny change of described entity (even “small”, e.g. subsystem→system) must be expressed via `U.EpistemicRetargeting` and is **not** a MultiViewDescribing view refinement.\n\n#### E.17.0:4.3.4 - MVD‑4 - CorrespondenceModel as the home of cross‑view correspondences\n\nWhen views or D/S epistemes under different viewpoints are meant to be **kept in correspondence** (in ISO 42010 or BX sense), the family **SHALL**:\n\n1. Provide a `U.CorrespondenceModel` episteme whose `ClaimGraph` captures correspondences and consistency relations over `{D_S(T,C), Views(T,C)}`.\n\n2. Ensure that any `U.CorrespondenceEpistemicViewing` that depends on multiple epistemes or representation schemes:\n\n   * references that `CorrespondenceModel`, and\n   * publishes witnesses (proof objects, trace links) that make diagrams commute up to declared isomorphism (oplax naturality allowed).\n\n3. Treat temporary inconsistency explicitly: there may be states where some correspondences are violated; this is represented as **facts in the correspondence ClaimGraph**, not as hidden weakening of viewing laws.\n\n#### E.17.0:4.3.5 - MVD‑5 - Separation from publication (MVPK)\n\n`U.MultiViewDescribing` is purely **epistemic**:\n\n* D/S epistemes and views live entirely in Ep‑space (`U.Episteme`);\n* it does **not** define PublicationSurface, carriers or rendering;\n* MVPK (E.17) sits **on top**:\n\n  * taking morphisms and/or D/S epistemes as input,\n  * using `U.EpistemicViewing` plus publication‑specific viewpoints,\n  * emitting `U.View` instances that then get attached to Surfaces via L‑SURF.\n\nMultiViewDescribing therefore **does not re‑define I→D/D→S** (`Describe_ID`, `Specify_DS`) and does not introduce any Work on carriers; those remain in A.7/E.10.D2 and E.17.\n\n#### E.17.0:4.3.6 - MVD‑6 - I/D/S alignment\n\nFor any `U.MultiViewDescribing` instance:\n\n1. Every `…Description` and `…Spec` episteme in the family must satisfy E.10.D2:\n\n   * be an episteme with `DescriptionContext = ⟨DescribedEntityRef, BoundedContextRef, ViewpointRef⟩`,\n   * be linked to a unique Intension via `isDescriptionOf` / `isSpecOf` with the additional `ViewpointRef` parameter.\n\n2. Viewings and correspondence operations **must not**:\n\n   * collapse Intension into episteme,\n   * confuse D/S with publication surfaces,\n   * reinterpret described entity without going through A.6.4 retargeting.\n\n#### E.17.0:4.3.7 - MVD‑7 - Slot discipline\n\nAll constructs in this pattern **SHALL** respect `U.RelationSlotDiscipline`:\n\n* SlotKinds (`DescribedEntitySlot`, `ViewpointSlot`, `ViewSlot`, `GroundingHolonSlot`, `ClaimGraphSlot`, `ReferenceSchemeSlot`) and their ValueKinds/RefKinds follow A.6.5 and C.2.1.\n* `*Slot` suffix is reserved for SlotKinds; `*Ref` for RefKinds/fields, never for Kinds or objects. \n* MultiViewDescribing patterns **must not** invent parallel slot disciplines for “roles in relations”; they reuse SlotKind as the notion of position.\n",
        "archetypal_grounding": "### E.17.0:5 - Archetypal grounding  *(informative)*\n\n1. **Engineering holon (TEVB).** \n   * `EoIClass = U.Holon` (restricted to `U.System`/`U.Episteme`).\n   * TEVB (E.17.2) supplies a viewpoint bundle with canonical engineering viewpoints: Functional, Structural, Role‑Enactor, Module‑Interface, etc.\n   * For a particular system `S` in context `C`, D/S epistemes include functional descriptions, structural designs, role‑enactment models, and interface specs.\n   * Views derived via EpistemicViewing include sliced safety views, performance‑focused views, and minimal runbooks.\n   * `CorrespondenceModel` records how functional elements are realised structurally, where hazards map to components, etc.\n\n2. **Morphism publication (MVPK).**\n   * `EoIClass = U.Morphism`.\n   * D/S epistemes capture the semantic characterisation of morphisms (pre‑/post‑conditions, CG‑Specs, CHR pins).\n   * Viewpoints are publication‑oriented (`PlainView`, `TechCard`, `InteropCard`, `AssuranceLane`); views are MVPK faces over those morphisms.\n   * CorrespondenceModel states how the same morphism appears as a simple narrative, a typed card with units, an interoperability card, and an assurance lane with evidence bindings — all without new claims.\n\n3. **Safety case vs architecture vs operations.**\n   * `EoIClass = U.Holon`.\n   * Viewpoints: SafetyCase, Architecture, Operations.\n   * Families tie together safety requirements, architectural structures, and operational procedures for the same plant `P` in context `C`.\n   * Views: a safety‑focused slice of the architecture description, an operational runbook annotated with safety invariants, etc.\n   * CorrespondenceModel expresses coverage and consistency between these views, enabling BX‑style repair when one side changes.\n",
        "conformance_checklist": "### E.17.0:6 - Conformance checklist (author’s quick use)  *(normative)*\n\nWhen defining a new `U.MultiViewDescribing` species or using it in a discipline pack:\n\n1. **Declare the EoIClass.**\n   *Explicitly state `EoIClass ⊑ U.Entity` and ensure all families restrict `DescribedEntitySlot` accordingly.*\n\n2. **Define the viewpoint set Σ.**\n   *List `U.Viewpoint` instances (possibly via a `U.ViewpointBundle`) with stakeholders, concerns, allowed EpistemeKinds, and conformance rules.*\n\n3. **Require DescriptionContext for D/S.**\n   *Ensure every `…Description`/`…Spec` episteme in the family has `DescriptionContext = ⟨DescribedEntityRef, BoundedContextRef, ViewpointRef⟩` and that `ViewpointRef ∈ Σ`.*\n\n4. **Specify admissible EpistemicViewing species.**\n   *List the `U.EpistemicViewing` profiles used to derive views; declare their Applicability profiles and assert they are describedEntity‑preserving (EV‑6).*\n\n5. **Attach CorrespondenceModel where needed.**\n   *Whenever cross‑view consistency matters, introduce a `U.CorrespondenceModel` episteme and reference it from any `U.CorrespondenceEpistemicViewing`.*\n\n6. **Separate describing from publication.**\n   *Check that pattern text does not treat I→D/D→S as “publication”, and that any talk of Surfaces/carriers is clearly delegated to MVPK/L‑SURF.*\n\n7. **Respect SlotKind/ValueKind/RefKind discipline.**\n   *Use `*Slot` only for SlotKinds, `*Ref` only for RefKinds/fields; avoid `Subject`/`Object` roots in episteme types; use `DescribedEntitySlot` and `viewpointRef` instead.*\n",
        "consequences": "### E.17.0:7 - Consequences  *(informative)*\n\n* **Unified multi‑view story across domains.**\n  Engineering descriptions, safety cases, governance dossiers, research artefacts — all become instances of the same multi‑view pattern, enabling coherent tooling and education.\n\n* **Explicit, testable viewpoints.**\n  Viewpoints move from vague labels (“architecture view”) to first‑class objects (`U.Viewpoint`) with stakeholder families, concerns, allowed D/S kinds, and conformance rules. This allows `OperationalGate(profile)` checks and better review practices.\n\n* **Views as disciplined projections, not new documents.**\n  `U.View` is an episteme generated by viewings, not a free‑floating PowerPoint. This constrains what tools are allowed to do when “generating views”, and prevents silent strengthening of commitments.\n\n* **Correspondence as a first‑class citizen.**\n  Consistency and traceability between views are expressed via ClaimGraphs in `U.CorrespondenceModel`, not as scattered hyperlinks or spreadsheet columns.\n\n* **Clean separation of describing vs publishing.**\n  `U.MultiViewDescribing` ends the long‑standing conflation between describing (I→D→S) and publication (D/S→Surface). MVPK becomes a clean specialisation on top, not a second I/D/S discipline.\n\n* **Slot‑level interoperability.**\n  C.2.1/A.6.5 slot discipline applies uniformly; new domains can introduce viewpoint bundles and multi‑view families without inventing new ontologies for “view positions” or “roles in relations”.\n",
        "rationale": "### E.17.0:8 - Rationale & SoTA‑echoing  *(informative)*\n\n* **ISO 42010 and viewpoint libraries.**\n  ISO 42010 distinguished *viewpoints* (stakeholders + concerns + conventions) from *views* (descriptions under those viewpoints) and introduced viewpoint libraries. `U.MultiViewDescribing` generalises this beyond “architecture descriptions” to **any descriptions/specifications**, with `EoIClass` parameter and explicit viewpoint bundles used by TEVB and MVPK. \n\n* **MBSE & SysML v2 views‑as‑queries.**\n  Modern MBSE treats views as **queries over shared models** with controlled rendering. That aligns with `U.EpistemicViewing` as a pure, describedEntity‑preserving morphism, and with `U.View` as an episteme view derived from D/S under a viewpoint.\n\n* **BX / model synchronisation.**\n  Bidirectional transformations literature treats consistency relations and repair as first‑class. `U.CorrespondenceModel` and `U.CorrespondenceEpistemicViewing` provide an FPF‑native home for such relations, ensuring that consistency rules live in ClaimGraphs and respect episteme morphism laws, rather than being buried in tool code. \n\n* **Optics and displayed categories.**\n  With C.2.1 and A.6.3, epistemes form a category fibred over described entities; viewings act like optics over the episteme slot graph. `U.MultiViewDescribing` is the **displayed‑category‑like** organisation of families indexed by `DescribedEntitySlot` and `ViewpointSlot`, making later categorical reasoning (e.g. structured cospans for view composition) straightforward.\n\n* **Hybrid symbolic/latent representations.**\n  By treating `U.RepresentationScheme` and `U.RepresentationOperation` as episteme components, families can mix symbolic specs, diagrams, code, and latent representations (e.g. LLM‑based summaries) while staying within the same multi‑view discipline and EpistemicViewing laws.\n",
        "relations": "### E.17.0:9 - Relations  *(informative summary)*\n\n* **Builds on C.2.1 `U.EpistemeSlotGraph`.**\n  Uses `DescribedEntitySlot`, `ViewpointSlot`, `ViewSlot`, `ClaimGraphSlot`, `ReferenceSchemeSlot` as the structural backbone for descriptions, views, and correspondence.\n\n* **Builds on A.6.2–A.6.4.**\n  Families rely on `U.EffectFreeEpistemicMorphing` for view‑producing morphisms, `U.EpistemicViewing` for describedEntity‑preserving views, and `U.EpistemicRetargeting` for moves that change the described entity (outside a given family).\n\n* **Constrains E.17 (MVPK).**\n  MVPK is a **publication‑specialised MultiViewDescribing for morphisms**: its viewpoints are publication viewpoints; its ViewFamily is a special case of `Views(T,C)` with `T` a morphism; its laws must respect MVD‑0…MVD‑7.\n\n* **Constrains E.17.1 / E.17.2.**\n  `U.ViewpointBundleLibrary` and TEVB provide concrete viewpoint bundles populating `Σ` for particular `EoIClass` (e.g. engineering holons), but they must treat viewpoints as `U.Viewpoint` values in `ViewpointSlot`, not as ad‑hoc tags. \n\n* **Coordinates with E.10.D2 (I/D/S) and E.10 LEX‑BUNDLE.**\n  Ensures every D/S episteme in a family has a DescriptionContext, keeps “Describe/Specify” distinct from “Publish”, and respects lexical guards around `View`, `Viewpoint`, `Surface`, `ViewFamilyId`, `*Slot`, `*Ref`.\n\n* **Coordinates with B.5.* / F‑cluster.**\n  Viewpoints’ stakeholder families and concerns link naturally with RoleEnactment (B.5.\\*) and Part F role descriptions, assignments, harnesses — without overloading `U.Role` as a coordinate in I/D/S or episteme slots.\n",
        "e.17.0:end": "### E.17.0:End\n"
      },
      "content": "### E.17.0:End\n",
      "metadata": {},
      "part": "E",
      "cluster": null
    },
    {
      "id": "E.17.1",
      "title": "`U.ViewpointBundleLibrary — Reusable Viewpoint Bundles`",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## E.17.1 - `U.ViewpointBundleLibrary — Reusable Viewpoint Bundles`\n\n> **Tech‑name:** `U.ViewpointBundleLibrary`\n> **Plain‑name:** viewpoint bundle library (reusable viewpoint families)\n\n**Status & placement.** Part E (Describing & Publication). Normative architectural pattern.\n\n**Builds on:**\nA.6.2–A.6.4 (Episteme morphism classes),\nA.6.5 `U.RelationSlotDiscipline` (SlotKind/ValueKind/RefKind discipline),\nA.7 (Strict Distinction; I/D/S vs Surface),\nE.7 (Archetypal Grounding),\nE.10 (LEX‑BUNDLE, especially naming discipline for `ViewFamilyId`),\nE.10.D1/D2 (Context and I/D/S discipline),\nE.17.0 `U.MultiViewDescribing`.\n\n**Used by:**\nE.17.2 (TEVB — Typical Engineering Viewpoints Bundle),\nE.18:5.12 (E.TGA engineering viewpoint families),\nfuture domain‑specific viewpoint packs (architecture, governance, safety, research).\n\n**Guard (lexical & ontological).**\n\n* A **viewpoint bundle** is a family of `U.Viewpoint` values (intensional specs) plus metadata; it is **not** a collection of `U.View`, `PublicationSurface`, or files.\n* `ViewFamilyId` is a lexical tag that names a **viewpoint family** (bundle), never:\n  * a `U.View` kind,\n  * an MVPK face/surface kind,\n  * nor a file/folder label in L‑SURF.\n* `EngineeringVPId` / `PublicationVPId` remain separate (E.18:5.12, E.17); E.17.1 does **not** collapse engineering and publication viewpoints into one id.\n* Bundles are **intensional catalogue objects**: they specify reusable viewpoint families that `U.MultiViewDescribing` instances may import; they do not define new episteme kinds or surface kinds.\n",
        "problem": "### E.17.1:2 - Problem  *(informative)*\n\nWithout a dedicated pattern for viewpoint bundle libraries:\n\n1. **Each domain bakes its own “viewpoint sets”.**\n   E.TGA, MVPK, safety‑case disciplines, and governance packs tend to introduce local notions such as “engineering views”, “assurance views”, “governance decks” without a shared representation. Viewpoints drift, and cross‑domain mapping becomes opaque.\n\n2. **Viewpoint identity is unstable.**\n   A team may call something “functional view” in one project and “capability view” in another, even though the underlying concerns, stakeholders, and conformance rules are identical. The same `U.Viewpoint` is re‑invented and slightly renamed, making long‑term consistency and automation harder.\n\n3. **MultiViewDescribing cannot easily reuse families.**\n   `U.MultiViewDescribing` allows an arbitrary finite set of viewpoints Σ for each `<T,C>` (entity, context). Without a standard way to say “Σ is the TEVB engineering family” or “Σ is the governance‑risk bundle”, each family has to list viewpoints explicitly and locally.\n\n4. **ISO 42010 viewpoint libraries remain external.**\n   There is no canonical place in FPF where ISO‑style viewpoint libraries (for architecture descriptions) can be represented as first‑class objects and aligned with FPF’s `U.Viewpoint`, I/D/S discipline, and episteme morphisms.\n\n5. **Lexical aliases leak into semantics.**\n   Names like “Functional”, “SafetyCase”, or “Regulatory” may be used both as:\n\n   * intensional viewpoint specs; and\n   * ad‑hoc labels on documents, files or MVPK faces.\n     Without a clear lexical discipline, this causes confusion about what exactly is being reused.\n\nE.17.1 addresses these issues by introducing `U.ViewpointBundleLibrary` as the place where **reusable viewpoint families** are defined, named, and versioned.\n",
        "forces": "### E.17.1:3 - Forces  *(informative)*\n\n| Force                                     | Tension                                                                                                                                                                       |\n| ----------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **Reuse vs local fit**                    | Organisations want shared viewpoint families (engineering, safety, governance) ↔ projects need to tweak or subset them for specific contexts and maturity levels.             |\n| **Domain idioms vs neutral core**         | Domains carry their own jargon (architecture, safety case, regulatory dossier) ↔ FPF needs a neutral `U.Viewpoint` core to support cross‑domain reasoning and tooling.        |\n| **Stability vs evolution**                | Viewpoint families must be stable enough to support long‑term automation and training ↔ they must evolve as practices and standards evolve.                                   |\n| **Intensional vs artefact layers**        | Viewpoint families talk about concerns and conformance rules ↔ teams routinely attach the same name to concrete documents or MVPK faces.                                      |\n| **Engineering vs publication viewpoints** | Engineering viewpoints govern how a holon is described ↔ publication viewpoints govern how those descriptions are exposed as surfaces; we need both, without collapsing them. |\n| **Library size vs cognitive load**        | Rich libraries with many viewpoint families increase flexibility ↔ authors must still be able to choose and understand a small subset in each project.                        |\n",
        "solution": "### E.17.1:4 - Solution — `U.ViewpointBundleLibrary`  *(normative core)*\n\n#### E.17.1:4.1 - Overview\n\n`U.ViewpointBundleLibrary` is the **architectural home for reusable viewpoint families**.\n\n* A **viewpoint library** is a collection of **viewpoint bundles**; each bundle names and packages a finite family of `U.Viewpoint` values that are intended to be reused together.\n* Each **viewpoint bundle**:\n\n  * is identified by a `ViewFamilyId` lexical tag;\n  * constrains an `EoIClass ⊑ U.Entity` for which its viewpoints are valid;\n  * enumerates a finite set Σ of `U.Viewpoint` definitions;\n  * may carry archetypal grounding cards (E.7) and alignment notes (e.g., ISO 42010 mappings).\n\n`U.MultiViewDescribing[EoIClass]` then uses such bundles as **providers of Σ** for families of descriptions/specifications:\n\n* for a fixed entity `T ∈ EoIClass` and bounded context `C`, a `U.MultiViewDescribing` family may declare:\n\n  * that its viewpoint set Σ is **imported from** a specific `ViewFamilyId`, possibly with a finite subset selection; or\n  * that Σ is locally defined (no bundle) — still allowed, but less reusable.\n\nTEVB (E.17.2) and E.TGA E.18:5.12 are species of this pattern for engineering holons.\n\n#### E.17.1:4.2 - Core constructs\n\n##### E.17.1:4.2.1 - `U.ViewpointBundleLibrary` (library object)\n\n**Tech:** `U.ViewpointBundleLibrary` (kernel/species type).\n**Plain:** viewpoint library.\n\nA `U.ViewpointBundleLibrary` is a **catalogue of viewpoint bundles**, with at least:\n\n* `libraryId : LibraryId` — lexical identifier of the library (e.g. `FPF.Core.Viewpoints`, `OrgX.EngineeringViewpoints`).\n* `bundles : FinSet(U.ViewpointBundle)` — finite or countable set of bundles it provides.\n* `editionId : EditionId` — edition of the library, subject to the usual LEX‑AUTH / LAT discipline (E.15).\n* optional `scopeTags` and governance metadata (owner, change‑control).\n\n**Normative constraints.**\n\n1. Within a given `U.ViewpointBundleLibrary` edition, `ViewFamilyId` values **SHALL be unique**.\n2. Libraries **SHALL NOT** define new kernel episteme kinds or surface kinds; they only package `U.Viewpoint` values and metadata.\n3. Libraries **MAY** be specialised:\n\n   * a core FPF library (e.g. TEVB, generic governance bundles);\n   * organisational libraries extending or subsetting core bundles.\n\n##### E.17.1:4.2.2 - `U.ViewpointBundle` and `ViewFamilyId` (viewpoint family)\n\n**Tech:** `U.ViewpointBundle` (species type), `ViewFamilyId` (lexical id).\n**Plain:** viewpoint family, bundle of viewpoints.\n\nA `U.ViewpointBundle` is a **family of compatible viewpoints** packaged for reuse. Minimal structure:\n\n* `viewFamilyId : ViewFamilyId` — lexical id for the family (e.g. `VF.TEVB.ENG`, `VF.GovRisk`, `VF.ResearchMethod`).\n* `EoIClassSpec ⊑ U.Entity` — class of entities this family is meant for (must be compatible with each viewpoint’s `EoIClassSpec`).\n* `viewpoints : FinSet(U.Viewpoint)` — finite, non‑empty set of `U.Viewpoint` values (typically referenced via `U.ViewpointRef` in episteme cards).\n* optional `ArchetypalCards : FinSet(U.ArchetypalGroundingRef)` — grounding cards per viewpoint (E.7).\n* optional `AlignmentNotes` — e.g., ISO 42010 mappings, domain standard references.\n\n**Normative constraints.**\n\nVBL‑1. **EoIClass compatibility.**\nFor every `vp ∈ viewpoints`:\n\n* `vp` **SHALL** resolve to a `U.Viewpoint` whose `EoIClassSpec` refines `EoIClassSpec` of the bundle (`EoIClassSpec(vp) ⊑ EoIClassSpec(bundle)`).\n\nVBL‑2. **Finite, named family.**\n\n* `viewpoints` **SHALL** be finite and non‑empty.\n* Each `U.Viewpoint` **SHOULD** carry a stable `ViewpointId` (lexical id) distinct from `ViewFamilyId`.\n* The same `U.Viewpoint` **MAY** appear in multiple bundles (e.g. a general “Regulatory” viewpoint in both engineering and governance bundles).\n\nVBL‑3. **Lexical non‑collision.**\n\n* `ViewFamilyId` **MUST NOT** be used as:\n\n  * a `U.ViewId` / `U.ViewFamily(-)` id in MVPK,\n  * a `SurfaceKind` or carrier kind in L‑SURF,\n  * a generic `ViewpointId` without qualifier (E.18:5.12).\n* Libraries **SHOULD** adopt naming schemes that make the distinction clear, e.g. `VF.*` for families, `VP.*` for viewpoints, `PV.*` for publication viewpoints.\n\nVBL‑4. **Intensionality.**\n\n* A `U.ViewpointBundle` is **intensional**: it talks about the family of `U.Viewpoint` specs and their intended use; it does **not** contain any D/S epistemes, `U.View` instances, or `PublicationSurface` artefacts.\n* Any concrete document or MVPK face referencing a family **SHALL** do so through its `ViewFamilyId` and per‑view `ViewpointId`, not by embedding the bundle.\n\n##### E.17.1:4.2.3 - Binding bundles into `U.MultiViewDescribing`\n\n`U.MultiViewDescribing[EoIClass]` organises families of descriptions/specifications for a fixed `<T,C>` (entity, context) with a finite viewpoint set Σ.\n\n**Binding rule (informal).**\n\n* Given a `U.ViewpointBundleLibrary` and a bundle with `EoIClassSpec` compatible with the family’s `EoIClass`, a `U.MultiViewDescribing[EoIClass]` instance **MAY** declare:\n\n  * `ViewFamilyId` — the bundle that provides its “canonical” viewpoint set;\n  * `ActiveViewpoints ⊆ viewpoints(bundle)` — the subset actually used in this `<T,C>` family.\n\n**Normative constraints.**\n\nVBL‑5. **Bundle import.**\nFor any `U.MultiViewDescribing[EoIClass]` instance that declares a `ViewFamilyId`:\n\n* its viewpoint set Σ **SHALL** be a finite subset of the `viewpoints` of that bundle;\n* every D/S episteme in the family **SHALL** have `viewpointRef` in Σ (as required by E.17.0 / E.10.D2);\n* every `U.View` attached to that family under E.17.0 **SHALL** preserve `viewpointRef` from Σ.\n\nVBL‑6. **Multi‑bundle coordination.**\nA single `<T,C>` family **MAY** rely on more than one bundle (e.g. TEVB + a safety bundle). In that case:\n\n* the family **SHALL** declare how Σ is partitioned by `ViewFamilyId` (e.g. engineering vs safety);\n* any CorrespondenceModel in the family that links views across families **SHALL** cite the relevant `ViewFamilyId` values.\n\nVBL‑7. **No implicit bundles.**\nIf a `U.MultiViewDescribing` family does **not** declare a `ViewFamilyId`, its Σ is considered **local**. Such families are valid but:\n* provide no guarantee of reuse in other projects;\n* may be required, by organisational policy, to migrate to a library bundle before external publication.\n",
        "archetypal_grounding": "### E.17.1:5 - Archetypal grounding  *(informative)*\n\n#### E.17.1:5.1 - TEVB engineering viewpoints (preview species)\n\n*Context.*\nAn engineering organisation wants a **standard family of viewpoints** for describing holons (`U.System` or `U.Episteme`) in E.TGA and MVPK.\n\n*Bundle shape (TEVB, to be defined fully in E.17.2).*\n\n* `viewFamilyId = VF.TEVB.ENG`\n* `EoIClassSpec = U.Holon` (with species restriction “is `U.System` or `U.Episteme`”)\n* `viewpoints = {VP.Functional, VP.Procedural, VP.RoleEnactor, VP.ModuleInterface, …}`\n\nEach `VP.*` is a `U.Viewpoint` with:\n\n* `StakeholderFamilies` drawn from engineering RoleEnactors (design, operations, safety);\n* `Concerns` tuned to capability, process, structure, and interface questions;\n* `AllowedEpistemeKinds` pointing to E.TGA‑level descriptions/specs;\n* `ConformanceRules` linked to CV/GF check catalogues.\n\nThe bundle is defined once, in a shared library; E.TGA E.18:5.12 then **imports** `VF.TEVB.ENG` and maps these viewpoints to E.TGA constructs without re‑defining them.\n\n#### E.17.1:5.2 - Governance & risk bundle\n\n*Context.*\nA governance team wants a reusable set of viewpoints across projects: “Risk”, “Control”, “Compliance”, “Operations”.\n\n*Bundle shape.*\n\n* `viewFamilyId = VF.GovRisk`\n* `EoIClassSpec = U.Holon` (holons representing services or programmes)\n* `viewpoints = {VP.Risk, VP.Control, VP.Compliance, VP.Operations}`\n\nThe same bundle is used:\n\n* in a MultiViewDescribing family for a specific service holon;\n* in a publication context where MVPK faces for governance reports reference `VF.GovRisk` and specific `VP.*` ids.\n\nArchetypal grounding cards (E.7) illustrate each viewpoint with a 1‑page “Tell–Show–Show” example.\n",
        "conformance_checklist": "### E.17.1:6 - Conformance checklist  *(normative)*\n\n| ID                                           | Requirement                                                                                                                                                                          | Practical test                                                                             |\n| -------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------ |\n| **CC‑VBL‑0 (Unique ViewFamilyId)**           | Within a library edition, each `ViewFamilyId` is unique and refers to exactly one `U.ViewpointBundle`.                                                                               | Scan library metadata; no duplicates; foreign keys resolve.                                |\n| **CC‑VBL‑1 (EoIClass compatibility)**        | For every bundle, all `U.Viewpoint` members have `EoIClassSpec` refining the bundle’s `EoIClassSpec`.                                                                                | Check `EoIClassSpec(vp) ⊑ EoIClassSpec(bundle)` for each `vp`.                             |\n| **CC‑VBL‑2 (Bundle‑backed families)**        | Any `U.MultiViewDescribing` family that declares a `ViewFamilyId` uses Σ equal to a finite subset of that bundle’s `viewpoints`; all D/S epistemes and views use `viewpointRef ∈ Σ`. | For each family, inspect Σ and `viewpointRef` fields; verify subset and coverage.          |\n| **CC‑VBL‑3 (No surface hijack)**             | `ViewFamilyId` never appears as a `SurfaceKind`, MVPK face kind, or carrier type.                                                                                                    | Token scan of schemas and configs; no matches outside library metadata.                    |\n| **CC‑VBL‑4 (Archetypal grounding coverage)** | For bundles intended for non‑expert authors, each viewpoint has at least one `U.ArchetypalGrounding` reference.                                                                      | For each such bundle, check that `ArchetypalCards` cover all `viewpoints`.                 |\n| **CC‑VBL‑5 (Edition discipline)**            | Libraries and bundles are editioned; changes in viewpoint membership or semantics create new editions rather than silently mutating existing ones.                                   | LAT / change log shows edition bumps for breaking changes; older editions remain readable. |\n\n",
        "e.17.1:7___cross‑cutting_constraints_&_naming_discipline__*(normative)*": "### E.17.1:7 - Cross‑cutting constraints & naming discipline  *(normative)*\n\n1. **E.10 / A.6.5 alignment.**\n   `U.ViewpointBundleLibrary` **SHALL** follow LEX‑BUNDLE and `U.RelationSlotDiscipline`:\n   * separate **Tech** and **Plain** registers in names and prose;\n   * respect the `*Slot`/`*Ref` conventions from A.6.5 (no `ViewFamilySlot` here; `ViewFamilyId` is a lexical token, not a SlotKind);\n   * treat `U.Viewpoint` as the ValueKind for `ViewpointSlot` and `U.ViewpointRef` as its RefKind (no new SlotKinds for viewpoint families);\n   * avoid overloading `view`, `viewpoint`, `Surface`, `carrier`.\n\n1. **Engineering vs publication viewpoint ids.**\n   * Engineering viewpoint families (TEVB, E.TGA E.18:5.12) use `EngineeringVPId` for `U.Viewpoint` in the bundle.\n   * Publication viewpoint families (MVPK) use `PublicationVPId` for MVPK viewpoint ids.\n   * A bundle **MAY** contain engineering viewpoints, publication viewpoints, or both, but the id namespaces **SHALL** be disambiguated (e.g. `VP.Eng.*` vs `VP.Pub.*`).\n\n1. **ISO 42010 mapping.**\n   * An ISO 42010 “viewpoint library” becomes a `U.ViewpointBundleLibrary` edition.\n   * Individual ISO viewpoints correspond to `U.Viewpoint` values inside one or more bundles.\n   * ISO “architecture descriptions” correspond to concrete combinations of `U.MultiViewDescribing` families + MVPK surfaces that import those bundles; E.17.1 does not define architecture itself.\n\n1. **Archetypal grounding linkage.**\n   * For any bundle that is intended for non‑expert authors, each `U.Viewpoint` in `viewpoints` **SHOULD** have at least one `U.ArchetypalGrounding` card (E.7) referenced from the bundle.\n   * These cards are didactic only; they do not alter the semantics of the viewpoints.\n\n1. **Tooling hooks.**\n   * Tools **MAY** treat `ViewFamilyId` as a primary key for viewpoint selection widgets, template libraries, or documentation navigation.\n   * Tools **MUST NOT** infer semantics from the shape of `ViewFamilyId`; semantics come from the `U.Viewpoint` definitions.\n",
        "consequences": "### E.17.1:8 - Consequences  *(informative)*\n\n| Benefit                                    | Why it matters                                                                                                           | Trade‑offs / Mitigations                                              |\n| ------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------ | --------------------------------------------------------------------- |\n| **Reusable viewpoint families.**           | Teams and tools can share a common understanding of “functional view”, “risk view”, etc., across projects and domains.   | Requires governance of libraries and editions (E.15).                 |\n| **Cleaner MultiViewDescribing instances.** | Families can say “we use TEVB+GovRisk” instead of spelling out Σ by hand.                                                | Local Σ are still allowed; migration to bundles may be an extra step. |\n| **Better ISO 42010 alignment.**            | ISO viewpoint libraries become first‑class, mappable objects in FPF.                                                     | Needs careful mapping work per architecture sub‑domain.               |\n| **Terminology hygiene.**                   | Distinguishing ViewFamilyId from ViewpointId and from surfaces reduces confusion in tooling and documentation.           | Enforced via LEX‑guards and CI checks.                                |\n| **Cross‑domain reasoning.**                | The same bundle can be referenced from E.TGA, MVPK, and discipline packs, enabling consistent cross‑view correspondence. | Libraries must stay small and curated to avoid cognitive overload.    |\n",
        "rationale": "### E.17.1:9 - Rationale & SoTA‑echoing  *(informative)*\n\n* **ISO 42010 (Edition 2) viewpoint libraries.**\n  ISO 42010 generalises *system‑of‑interest* to *entity‑of‑interest* and allows viewpoint libraries that define reusable viewpoint sets for architecture descriptions. `U.ViewpointBundleLibrary` adopts this idea but generalises it beyond architecture to any `EoIClass`, and connects it to FPF’s explicit `U.Viewpoint`, I/D/S discipline, and episteme morphisms.\n\n* **MBSE and SysML v2 view definitions.**\n  Modern MBSE practice treats views as **queries over models** governed by named viewpoints, often organised into libraries or profiles. `U.ViewpointBundleLibrary` provides a neutral representation of such libraries so that SysML‑like stacks can be integrated without hard‑coding their terminology into the core.\n\n* **Safety and assurance cases.**\n  Safety‑case frameworks (e.g. GSN‑based) implicitly rely on recurrent viewpoints (“hazard analysis”, “mitigation design”, “evidence aggregation”). Embedding them into bundles allows assurance‑oriented Viewpoint families to be reused and linked to Part F harnesses and stance declarations (`DesignRunTag`/`Locus`).\n\n* **Governance and research workflows.**\n  Governance / audit frameworks and research pipelines similarly rely on recurring perspectives (e.g. “internal validity”, “external validity”, “reproducibility”). Viewpoint bundles allow these perspectives to be captured once and referenced across many MultiViewDescribing instances.\n\nOverall, `U.ViewpointBundleLibrary` is the mechanism by which **post‑2015 multi‑view practice** (viewpoint libraries, reusable view definitions) is integrated into the FPF stack without compromising strict I/D/S separation or the episteme slot discipline of C.2.1/A.6.5.\n",
        "relations": "### E.17.1:10 - Relations  *(informative summary)*\n\n* **Builds on C.2.1 `U.EpistemeSlotGraph`.**\n  Uses `ViewpointSlot` / `ViewSlot` as the structural anchors for viewpoints and views; bundles provide reusable values for `ViewpointSlot`.\n\n* **Builds on A.6.2–A.6.4.**\n  Viewpoint bundles do not change episteme morphism laws; they parameterise which `U.EpistemicViewing` pipelines are admissible under a given viewpoint family.\n\n* **Builds on A.7 / E.10.D2.**\n  Description/specification epistemes remain I/D/S‑disciplined; bundles only constrain the `viewpointRef` part of `DescriptionContext`.\n\n* **Builds on E.7.**\n  Archetypal grounding cards for viewpoints are organised and referenced via bundles, making didactic examples reusable.\n\n* **Constrains E.17.0 `U.MultiViewDescribing`.**\n  Families that declare a `ViewFamilyId` must draw Σ from the corresponding `U.ViewpointBundle` (VBL‑5/6).\n\n* **Constrains E.17 (MVPK).**\n  MVPK viewpoint sets for publication **SHOULD** be declared as bundles in a library; MVPK faces must not treat `ViewFamilyId` as a surface kind.\n\n* **Constrains E.17.2 (TEVB) and E.18:5.12 (E.TGA engineering viewpoint families).**\n  TEVB must be expressed as one or more `U.ViewpointBundle` instances; E.TGA E.18:5.12 maps engineering viewpoints by referring to those bundles, not by defining its own opaque ids.\n\n* **Coordinates with E.10 (LEX‑BUNDLE) and E.15 (LEX‑AUTH).**\n  `ViewFamilyId` and `ViewpointId` naming, editioning and evolution follow lexical and authoring protocols; migrations between library editions are tracked in LATs.\n",
        "e.17.1:end": "### E.17.1:End\n"
      },
      "content": "### E.17.1:End\n",
      "metadata": {},
      "part": "E",
      "cluster": null
    },
    {
      "id": "E.17.2",
      "title": "`TEVB — Typical Engineering Viewpoints Bundle`",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## E.17.2 - `TEVB — Typical Engineering Viewpoints Bundle`\n\n> **Tech‑name:** `TEVB` (Typical Engineering Viewpoints Bundle, bundle id `VF.TEVB.ENG`)\n> **Plain‑name:** typical engineering viewpoints bundle for holons\n> **Tag:** Archetypal species of `U.ViewpointBundle` for engineering holons\n\n**Status.** New; archetypal, notation‑agnostic species of `U.ViewpointBundle` / `U.ViewpointBundleLibrary`.\nIt is an engineering‑level bundle over holons; it does not itself constitute an architecture framework or architecture‑specific viewpoint library. Architecture‑focused viewpoint bundles are introduced as separate `U.ViewpointBundle` species that may import TEVB.\n\n**Builds on.**\n* **E.17.0 — `U.MultiViewDescribing`.** Supplies the generic notion of `U.Viewpoint`, `U.View`, and `ViewFamily` over an `EoIClass ⊑ U.Entity` (here: `EoIClass = U.Holon`).\n* **E.17.1 — `U.ViewpointBundleLibrary`.** Provides the generic `U.ViewpointBundle`/`ViewFamilyId` structure; TEVB is a concrete bundle (`VF.TEVB.ENG`) in the core library.\n* **A.1 — Holon.** Holon kinds `U.System` and `U.Episteme` as the typical engineering entities‑of‑interest.\n* **A.6.2–A.6.4 — Episteme morphisms.** `U.EffectFreeEpistemicMorphing`, `U.EpistemicViewing`, `U.EpistemicRetargeting` as the generic morphism classes behind engineering views.\n* **A.7 / E.10.D2 — Strict Distinction & I/D/S.** I/D/S discipline and DescriptionContext; engineering descriptions/specifications under TEVB are D/S‑epistemes with explicit `ViewpointRef`.\n* **C.2.1 — `U.EpistemeSlotGraph`.** Provides `DescribedEntitySlot`, `ViewpointSlot`, `ViewSlot` and the slot discipline (A.6.5) used by TEVB‑aligned descriptions/specs.\n\n**Used by.**\n* **E.18:5.12 — E.TGA viewpoint map.** As a canonical consumer, E.TGA binds its engineering transduction families (Functional, Procedural, Role‑Enactor/Device‑Structure, Module‑Interface) to TEVB viewpoints `VP.Functional`, `VP.Procedural`, `VP.RoleEnactor`, `VP.ModuleInterface`.\n* **E.17 (MVPK).** Publication of engineering morphisms uses TEVB engineering viewpoints on the description/spec side and PublicationVPs on the Surface side.\n* **Engineering description/spec patterns.** System, method, module/interface and role‑related description/spec patterns for holons (`U.System`, `U.Episteme`) refer to TEVB when declaring their `ViewpointRef`.\n* **ISO‑aligned architecture‑description bundles.** Future species patterns for architecture‑specific viewpoint bundles reuse TEVB as the canonical engineering view family (Functional vs Structural etc.) over systems and their epistemes.\n\n**Guard (lexical & ontological).**\n1. **Engineering scope only.** TEVB applies to `EoIClass = U.Holon` with typical cases `U.System` and `U.Episteme`. Using TEVB viewpoints for non‑holonic entities (e.g., pure data structures, abstract theories) requires an explicit species‑level justification; by default it is a conformance violation.\n2. **Viewpoint vs Surface.** `VP.Functional`, `VP.Procedural`, `VP.RoleEnactor`, `VP.ModuleInterface` are **viewpoints** (intensional `U.Viewpoint` specifications), **not** Surface kinds. They MUST NOT be used as carrier/Surface names (those remain `{PlainView, TechCard, NormsCard, InteropCard, AssuranceLane, …}` under L‑SURF).\n3. **EngineeringVPId vs PublicationVPId.** `VP.*` in this pattern are **EngineeringVPId** values (E.18:5.12) and SHALL NOT be reused as PublicationVPs in MVPK. MVPK must introduce separate `PublicationVPId` symbols, linked to TEVB viewpoints only through correspondences.\n4. **No new role coordinates in I/D/S.** TEVB references stakeholder groups via `U.RoleEnactor` families but does not introduce `U.Role` as a coordinate in I/D/S signatures (E.10.D2). Role semantics remain confined to RoleEnactment patterns (A.15, F‑R family).\n5. **No extra viewpoints inside TEVB.** TEVB defines a **fixed core set** of four engineering viewpoints. Other labels such as “Assurance‑Oriented”, “Interop‑Oriented”, “Information/Data‑Oriented”, “Operational/Deployment”, “Mission/Context” may appear only as **lexical aliases** in E.18:5.12 (e.g. as `ViewFamilyId` / `AliasInViewFamilies` values for transduction species). They MUST NOT extend `TEVB.EngBundle.viewpoints` and MUST NOT be interpreted as additional `U.Viewpoint` kinds in this bundle; when SoTA or local practice demands explicit assurance, information, or mission viewpoints, these SHALL be provided as **separate `U.ViewpointBundle` species** that can be imported alongside TEVB rather than by mutating `VF.TEVB.ENG`.\n6. **Not an architecture framework.** TEVB is an engineering‑level viewpoint bundle; architecture‑specific viewpoint bundles and architecture frameworks MUST be introduced as separate `U.ViewpointBundle` species that may import TEVB. They MUST NOT redefine `VF.TEVB.ENG` as an “architecture viewpoint library” or extend it with architecture‑only viewpoints.\n",
        "problem": "### E.17.2:2 - Problem  *(informative)*\n\nWithout TEVB, several failure modes recur:\n1. **Inconsistent “functional/structural/behavioural” vocabularies.** Different teams define “functional view” or “process view” differently, even within one organisation; E.TGA E.18:5.12 then has to guess how to map transduction graphs onto whichever interpretation is currently in play.\n2. **Architecture frameworks leak into the kernel.** 4+1‑style and similar architectural frameworks get hard‑coded as if they were universal; FPF loses its holonic neutrality and becomes biased to a particular school.\n3. **Viewpoints conflated with surfaces and files.** “Functional view” is used both for the underlying viewpoint and for a concrete document or dashboard; MVPK faces, E.TGA transduction families, and I/D/S disciplines become entangled.\n4. **Role leakage into I/D/S.** Engineering views that are about role‑enactors are written directly in terms of `U.Role`, blurring the boundary between RoleEnactment (A.15) and description/spec layers, and breaking A.7/E.10.D2.\n5. **Poor reuse across systems.** Even when organisations want to reuse the same engineering views across products, plants, or models, there is no canonical bundle to import; each programme recreates “its own” functional/structural views.\n\nTEVB makes engineering viewpoint families **first‑class reusable bundles** and pins them to an explicit `EoIClass` (engineering holons) so that E.TGA, MVPK and discipline‑packs can align on the same vocabulary.\n",
        "forces": "### E.17.2:3 - Forces  *(informative)*\n\n| Force                                       | Tension                                                                                                                                                                       |\n| ------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **Universality vs domain idioms**           | We need engineering viewpoints that work for *any* holon (hardware/software/socio‑technical), yet remain recognisable to practitioners steeped in domain‑specific frameworks. |\n| **Parsimony vs expressiveness**             | A small, stable **NQD‑front** set of engineering view families (Function, Behaviour/Process, Role‑Enactor, Module‑Interface) vs the temptation to proliferate specialised views for every stakeholder group or quality attribute. |\n| **Neutral core vs architecture frameworks** | FPF core must stay neutral and not encode a specific framework (4+1, DoDAF, etc.), while still being compatible with them.                                                    |\n| **Consistency vs organisational autonomy**  | Central TEVB definitions must be stable, yet individual organisations need room to refine concerns and episteme kinds within the bundle.                                      |\n| **I/D/S clarity vs convenient shortcuts**   | Viewpoints must not re‑introduce `Role` as a coordinate in I/D/S, nor blur Description/Spec/Surface distinctions, even though practitioners informally mix these.             |\n\nTEVB resolves these by fixing a **minimal engineering bundle** and leaving customisation to **species patterns and ViewpointBundleLibrary entries** that refine concerns and allowed episteme kinds without changing the core families.\n",
        "solution": "### E.17.2:4 - Solution — TEVB as a core `U.ViewpointBundle` for holons  *(normative)*\n\n#### E.17.2:4.1 - TEVB bundle identity\n\nTEVB is the **core engineering viewpoint bundle** over holons.\n\n* **Bundle object.** There exists a canonical `U.ViewpointBundle` instance:\n\n  ```\n  TEVB.EngBundle : U.ViewpointBundle\n  ```\n\n* **ViewFamilyId.**\n\n  ```\n  TEVB.EngBundle.viewFamilyId = VF.TEVB.ENG\n  ```\n\n  `VF.TEVB.ENG` is reserved for **“Typical Engineering Viewpoints (Engineering)”** in the FPF core ViewpointBundleLibrary.\n\n* **EoIClassSpec (holon scope).**\n\n  TEVB is parameterised by\n\n  ```\n  TEVB.EngBundle.EoIClassSpec =\n    { h : U.Holon | holonKind(h) ∈ {U.System, U.Episteme} }\n  ```\n\n  That is, TEVB applies to holons that are either `U.System` or `U.Episteme`. Other holon kinds MAY be added by species patterns but MUST be justified and documented; the default conformance profile assumes systems and epistemes.\n\n* **Library placement.**\n\n  TEVB lives in the core viewpoint library:\n\n  ```\n  TEVB.Library : U.ViewpointBundleLibrary\n  TEVB.Library.libraryId = FPF.Core.Viewpoints\n  TEVB.Library.bundles ⊇ { TEVB.EngBundle }\n  ```\n\n  Additional organisational libraries MAY import and specialise TEVB, but SHALL NOT redefine `VF.TEVB.ENG` with incompatible semantics.\n\n* **Viewpoint set.**\n\n  TEVB defines a **finite set of canonical engineering viewpoints**:\n\n  ```\n  TEVB.EngBundle.viewpoints =\n    { VP.Functional, VP.Procedural, VP.RoleEnactor, VP.ModuleInterface }\n  ```\n\nThe selection `{VP.Functional, VP.Procedural, VP.RoleEnactor, VP.ModuleInterface}` is the current **NQD‑frontier** for engineering holon viewpoints in Part G: it realises a Function–Behaviour–Structure‑plus‑Role (`F–B–S+R`) cut that is non‑dominated against candidate families including explicit information/data, assurance/safety, and mission/context viewpoints under the N/U/C/D axes (C.18, G.0). Part G records the SoTA candidate set and rejected alternatives; TEVB only fixes the **core four** where each `VP.* : U.Viewpoint` is defined below. These four are the **only** viewpoints in the core TEVB bundle.\n\n  > **Note.** Other ViewFamilyId values used in E.TGA (e.g., *Assurance‑Oriented*, *Interoperability‑Oriented*, *Information/Data‑Oriented*, *Operational/Deployment*, *Mission/Context*) remain **lexical families only** for transduction species (E.18:5.12). They do not add viewpoints to TEVB; they are orthogonal to TEVB’s `viewpoints` set.\n\n#### E.17.2:4.2 - TEVB engineering viewpoints\n\nEach TEVB viewpoint is a `U.Viewpoint` with:\n* `viewpointId : ViewpointId` (concrete identifier, e.g., `VP.Functional`);\n* `EoIClassSpec` **inherited from the bundle** (`U.Holon` with `System`/`Episteme` kinds);\n* `StakeholderFamilies : FinSet(RoleEnactorFamilyId)` — families of `U.RoleEnactor` that are the primary audience;\n* `Concerns : FinSet(ConcernId)` — engineering concerns this viewpoint foregrounds;\n* `AllowedEpistemeKinds : FinSet(U.EpistemeKindRef)` — description/spec kinds admissible under this viewpoint (all obeying I/D/S discipline and C.2.1 slot discipline);\n* `ConformanceRules : FinSet(RuleId)` — references to checklist items in conformance packs (CV/GF/engineering checklists).\n\nThe subsections below fix the **normative intent and minimal field profiles** for each TEVB viewpoint. Species patterns and discipline‑packs may refine `Concerns`, `AllowedEpistemeKinds` and `ConformanceRules`, but MUST preserve the intent.\n\n##### E.17.2:4.2.1 - `VP.Functional` — capability & transduction viewpoint\n\n**Intent.** Look at a holon in terms of **what it can do** under roles: capabilities, transductions, and functional responsibilities, rather than in terms of modules or procedures.\n\n* **viewpointId.**\n\n  ```\n  VP.Functional : ViewpointId  // EngineeringVPId\n  ```\n\n* **EoIClassSpec.**\n  Same as the bundle: `U.Holon` with `System`/`Episteme` kinds.\n\n* **StakeholderFamilies (typical examples).**\n  Actual `StakeholderFamilies : FinSet(U.RoleEnactor)` values are defined in RoleEnactment discipline packs; labels below are informal.\n  * System engineering leads and architects (e.g. SysEng‑lead enactors).\n  * Product owners / capability owners.\n  * Reliability / performance engineers when reading capability envelopes.\n\n* **Concerns (typical).**\n  * Capabilities and functions provided by the holon (`CapabilityConcerns`).\n  * Behaviour under roles (`RoleBehaviourConcerns`).\n  * Non‑functional envelopes: throughput, latency, availability, energy, safety (`NFPEnvelopeConcerns`).\n  * Compositional semantics of functions/transductions (`TransductionCompositionConcerns`).\n\n* **AllowedEpistemeKinds (shape).**\n  `VP.Functional` admits descriptions/specifications whose **DescribedEntitySlot** is a holon’s **capability/Method/Mechanism** under a role, e.g.:\n  * `SystemFunctionalDescription`, `SystemFunctionalSpec` (species of `U.EpistemeKind` describing system‑level capabilities and their interconnection).\n  * `TransductionDescription`, `TransductionSpec` (E.TGA functional lanes).\n  * `ServiceCapabilityDescription`, `ServiceCapabilitySpec` (when a holon is in Service role).\n\n  All such epistemes MUST:\n  * obey I/D/S discipline: `…Description`/`…Spec` as D/S‑layers for `U.Method`/`U.Mechanism`/`U.ServiceClause`;\n  * make their `DescriptionContext = ⟨DescribedEntityRef, BoundedContextRef, ViewpointRef⟩` explicit, with `ViewpointRef = VP.Functional`.\n\n* **ConformanceRules (examples).**\n  * Functional flows are **total** over their declared domain (no implicit dangling capabilities).\n  * Transductions are typed at interfaces (A.6.0, A.6.1) and respect A.6.2/A.6.3 purity/conservativity.\n  * When functional views participate in retargeting patterns (e.g. structural reinterpretation species based on `U.EpistemicRetargeting`), they MUST satisfy the relevant retargeting constraints from A.6.4; concrete consumer patterns (such as E.TGA structural reinterpretation, E.18) MAY impose additional rules.\n\n* **SoTA echo (informative).** `VP.Functional` corresponds to the “functional view” in ISO‑aligned architecture descriptions and domain reference architectures (functional viewpoints in IoT and space reference architectures, functional/logical layers in sector frameworks), and to the **Function** axis in FBS‑style design ontologies. It is also the natural home for SysML/SysML‑v2 capability and logical architecture models and for “logical view” slices in 4+1‑style frameworks, once recast into holon/capability terms.\n\n##### E.17.2:4.2.2 - `VP.Procedural` — process & control viewpoint\n\n**Intent.** Look at a holon in terms of **how behaviours are sequenced and controlled**: workflows, state machines, operational procedures, and control logic.\n\n* **viewpointId.**\n\n  ```\n  VP.Procedural : ViewpointId  // EngineeringVPId\n  ```\n\n* **EoIClassSpec.**\n\n  Same as the bundle.\n\n* **StakeholderFamilies (typical).**\n  * Operations and run‑time owners (`OperationsEnactorFamily`).\n  * Control engineers and automation specialists (`ControlEngineerEnactorFamily`).\n  * Safety engineers concerned with procedural correctness (`SafetyEngineerEnactorFamily`).\n\n* **Concerns (typical).**\n  * Control flow and ordering of actions (`OrderConcerns`).\n  * State‑machine behaviour and lifecycle (`StateLifecycleConcerns`).\n  * Concurrency, synchronisation, and error handling (`ConcurrencyConcerns`).\n  * Operational modes and transitions (startup, shutdown, degraded modes) (`OperationalModeConcerns`).\n\n* **AllowedEpistemeKinds (shape).**\n  `VP.Procedural` admits descriptions/specifications where the **DescribedEntitySlot** is a method/process/control Behaviour for the holon, e.g.:\n  * `MethodDescription`, `MethodSpec` for operational procedures (A.3.1–A.3.2).\n  * `ControlLogicDescription`, `ControlLogicSpec` (IEC 61131‑3 style step diagrams/statecharts).\n  * `WorkflowDescription`, `WorkflowSpec` (business processes, orchestration logic).\n\n  These epistemes:\n  * must respect the **order discipline** (Γ_method, Γ_ctx) and A.15 (Role–Method–Work alignment);\n  * must carry I/D/S‑conformant DescriptionContext with `ViewpointRef = VP.Procedural`.\n\n* **ConformanceRules (examples).**\n  * Pre/post‑conditions at step boundaries are explicit and type‑checked (A.3.1/A.3.2, Γ_method).\n  * No embedding of Work or calendars inside procedural descriptions (A.7/E.10.D2).\n  * Failure modes and recovery actions are declared and traceable to safety analyses (F.15 harnesses where relevant).\n\n* **SoTA echo (informative).** `VP.Procedural` captures the dynamic/process dimension found in SoTA architecture and MBSE practice: process views in 4+1, operational/behavioural views in defence and enterprise frameworks, behaviour diagrams in SysML (activity, sequence, state, interaction), and procedure/control‑oriented models in industrial standards. TEVB abstracts this into a notation‑agnostic “behaviour over time” viewpoint for holons.\n\n##### E.17.2:4.2.3 - `VP.RoleEnactor` — role & device‑structure viewpoint\n\n**Intent.** Look at a holon in terms of **who/what plays which roles** and **how physical/organisational structure supports those roles**. This viewpoint covers both socio‑technical role assignments and “device view” readings of transduction graphs (E.TGA).\n\n* **viewpointId.**\n\n  ```\n  VP.RoleEnactor : ViewpointId  // EngineeringVPId\n  ```\n\n* **EoIClassSpec.**\n\n  Same as the bundle.\n\n* **StakeholderFamilies (typical).**\n  * Organisational designers and operations managers (`OrgDesignEnactorFamily`).\n  * Safety and compliance officers concerned with separation of duties (`SegregationOfDutyEnactorFamily`).\n  * Hardware/system engineers concerned with which devices carry which functions (`DeviceEngineerEnactorFamily`).\n\n* **Concerns (typical).**\n  * Which holons enact which roles under which contexts (`RoleEnactmentConcerns`).\n  * Allocation of capabilities to devices/subsystems (`CapabilityAllocationConcerns`).\n  * Organisational constraints: segregation of duties, responsibilities, escalation paths (`GovernanceConcerns`).\n  * Device‑view readings of functional graphs (E.TGA Device‑View).\n\n* **AllowedEpistemeKinds (shape).**\n  `VP.RoleEnactor` admits descriptions/specifications where the **DescribedEntitySlot** is a **role structure or capability allocation** associated with the holon, e.g.:\n  * `RoleDescription`, `RoleSpec` (F.4, F.18) for human or system roles.\n  * `RoleEnactmentDescription` for mappings `Holder#Role:Context` (A.15).\n  * `DeviceAllocationDescription` mapping functions/transductions to physical modules or devices.\n\n  As with other TEVB viewpoints, these are D/S‑epistemes with `DescriptionContext.ViewpointRef = VP.RoleEnactor`.\n\n* **ConformanceRules (examples).**\n  * Role vs Method vs Work vs Capability separation is upheld (A.7, A.15).\n  * Device‑view reinterpretation from functional flows MUST be expressed as `U.EpistemicRetargeting` with an explicit `KindBridge` witness (A.6.4). Specific retargeting schemes (for example, E.TGA’s structural reinterpretation in E.18) may add further constraints but are not fixed by TEVB itself.\n  * No “role as behaviour” conflation: Roles are masks, behaviours remain Methods/Work.\n\n* **SoTA echo (informative).** `VP.RoleEnactor` aligns with the allocation/responsibility and resource/organisational view clusters seen across MBSE frameworks: allocation views in UAF/NAF, role‑responsibility matrices and RACI‑style artefacts, and “who/what plays which role” slices in usage and operational viewpoints. Many post‑2015 reference architectures treat this axis implicitly; TEVB makes it explicit and holon‑centred while remaining compatible with socio‑technical and device‑allocation practices.\n\n##### E.17.2:4.2.4 - `VP.ModuleInterface` — module & interface viewpoint\n\n**Intent.** Look at a holon in terms of its **modules, interfaces, and structural composition**: what parts exist, how they connect, and how their contracts are specified.\n\n* **viewpointId.**\n\n  ```\n  VP.ModuleInterface : ViewpointId  // EngineeringVPId\n  ```\n\n* **EoIClassSpec.**\n  Same as the bundle.\n\n* **StakeholderFamilies (typical).**\n  * Hardware and software architects responsible for structure (`StructureArchitectEnactorFamily`).\n  * Integration and test engineers (`IntegrationEngineerEnactorFamily`).\n  * Lifecycle and maintenance planners looking at replaceable units (`MaintenancePlannerEnactorFamily`).\n\n* **Concerns (typical).**\n  * Module decomposition and containment (mereology) (`ModuleMereologyConcerns`).\n  * Interfaces and contracts — ports, APIs, physical connectors (`InterfaceConcerns`).\n  * Dependency structures and allowed couplings (`DependencyConcerns`).\n  * Replaceability and variation points (`VariabilityConcerns`).\n\n* **AllowedEpistemeKinds (shape).**\n  `VP.ModuleInterface` admits descriptions/specifications where the **DescribedEntitySlot** is a **structural architecture** of the holon, e.g.:\n  * `SystemStructureDescription`, `SystemStructureSpec` (module/connector descriptions).\n  * `ModuleInterfaceDescription`, `ModuleInterfaceSpec` (signature, contracts, physical interface definitions).\n  * E.TGA‑style interface/port descriptions over `Signature`/`Mechanism` graphs.\n\n  These epistemes describe the carrier (structure) rather than capability. Functional↔physical reinterpretations between `VP.Functional` and `VP.ModuleInterface` are expressed via `U.EpistemicRetargeting` + `KindBridge` (A.6.4, E.18).\n\n* **ConformanceRules (examples).**\n  * Interfaces are typed and explicitly bound to standards where applicable (A.6.0, F‑specs).\n  * No inlining of Methods/Work into structure (strict separation of structure vs behaviour).\n  * Reinterpretations from functional views into structure MUST respect the applicable `U.EpistemicRetargeting`/Bridge constraints (A.6.4). When combined with a concrete retargeting scheme (e.g. E.TGA structural retargeting, CC‑TGA‑06‑EX), that scheme’s additional rules also apply.\n\n* **SoTA echo (informative).** `VP.ModuleInterface` matches the structural/implementation/deployment families that dominate SoTA architecture descriptions: development and physical views in 4+1, construction/deployment viewpoints in IoT reference architectures, logical/physical architecture layers in UAF/NAF and RASDS‑style frameworks, and structural and interface‑focused models in SysML‑based MBSE. TEVB treats all of these as specialisations of a single holonic “modules and interfaces” viewpoint.\n",
        "archetypal_grounding": "### E.17.2:5 - Archetypal grounding  *(informative)*\n\nA minimal TEVB instantiation looks as follows:\n\n```\nTEVB.EngBundle :\n  U.ViewpointBundle {\n    viewFamilyId   = VF.TEVB.ENG\n    EoIClassSpec   = { h : U.Holon | HolonKind(h) ∈ {System, Episteme} }\n    viewpoints     = { VP.Functional, VP.Procedural, VP.RoleEnactor, VP.ModuleInterface }\n    LibraryRef     = FPF.Core.Viewpoints\n  }\n```\n\nEach `VP.*` viewpoint is a `U.Viewpoint` as in E.17.0, with:\n\n* `viewpointId ∈ {VP.Functional, VP.Procedural, VP.RoleEnactor, VP.ModuleInterface}`,\n* `EoIClassSpec` inherited from `TEVB.EngBundle`,\n* `StakeholderFamilies`, `Concerns`, `AllowedEpistemeKinds`, `ConformanceRules` aligned with the subsections above.\n\n**Engineering holon (example).**\n\nLet `Plant_X : U.System` be a production plant, and `ControlStack_X : U.Episteme` be its control and optimisation stack as a holon.\n\n* Under `VP.Functional`, `Plant_X` is viewed as a bundle of capabilities and transductions: material/energy/product flows, optimisation functions, safety envelopes.\n* Under `VP.Procedural`, `Plant_X` is viewed as sets of procedures and control sequences: startup/shutdown, normal operation, emergency handling.\n* Under `VP.RoleEnactor`, `Plant_X` is viewed as networks of role‑enactors: human operators, controllers, subsystems enacting roles in SOPs and safety cases.\n* Under `VP.ModuleInterface`, `Plant_X` is viewed as modules and interfaces: equipment units, pipelines, control modules, buses, and their interfaces/contracts.\n\nEach of these is a **family of D/S‑epistemes** with `DescriptionContext = ⟨DescribedEntityRef(Plant_X or ControlStack_X), BoundedContextRef, ViewpointRef=VP.*⟩` and TEVB ensures that E.TGA and MVPK can rely on this common structure.\n",
        "conformance_checklist": "### E.17.2:6 - Conformance checklist  *(normative)*\n\n**CC‑TEVB‑1 (Bundle identity).**\nAny artefact claiming to be “TEVB engineering viewpoints” MUST:\n\n* refer to `viewFamilyId = VF.TEVB.ENG`,\n* have `EoIClassSpec = {h : U.Holon | HolonKind(h) ∈ {System, Episteme}}`,\n* enumerate `viewpoints = {VP.Functional, VP.Procedural, VP.RoleEnactor, VP.ModuleInterface}` and no others.\n\n**CC‑TEVB‑2 (Viewpoint definition).**\nEach `VP.*` viewpoint MUST be a well‑formed `U.Viewpoint` per E.17.0:\n\n* `viewpointId` equal to one of the four engineering IDs,\n* `EoIClassSpec` equal to the bundle’s,\n* `StakeholderFamilies`, `Concerns`, `AllowedEpistemeKinds`, `ConformanceRules` explicitly declared.\n\n**CC‑TEVB‑3 (DescriptionContext completeness).**\nEvery D/S‑episteme participating in a TEVB‑managed multi‑view family for a holon MUST have a `DescriptionContext = ⟨DescribedEntityRef, BoundedContextRef, ViewpointRef⟩` with:\n\n* `DescribedEntityRef` referencing a `U.System` or `U.Episteme`,\n* `ViewpointRef ∈ {VP.Functional, VP.Procedural, VP.RoleEnactor, VP.ModuleInterface}`,\n* `BoundedContextRef` pointing to the engineering context (E.10.D1).\n\n**CC‑TEVB‑4 (Separation from PublicationVPs).**\n`VP.*` identifiers from TEVB MUST NOT be used as `PublicationVPId` in MVPK. Publication viewpoints live in MVPK and may **correspond** to TEVB engineering viewpoints via `CorrespondenceModel`, but are separate symbols.\n\n**CC‑TEVB‑5 (No Role coordinate in I/D/S).**\nTEVB‑aligned descriptions/specs MAY reference `U.RoleEnactor` families in `StakeholderFamilies` but SHALL NOT add `Role` or `RoleEnactor` as axes in I/D/S signatures beyond what A.7/E.10.D2 already provides. Role semantics stay in RoleEnactment patterns; TEVB just selects concerns.\n\n**CC‑TEVB‑6 (Alignment with consumer viewpoint maps).**\nWhen a pattern defines engineering viewpoint families named “Functional”, “Procedural”, “Role‑Enactor (Device‑Structure)”, or “Module‑Interface” over the same `EoIClass` and claims TEVB alignment (for example, E.TGA E.18:5.12 viewpoint map), it MUST bind them to TEVB viewpoints as follows:\n\n* “Functional” → `VP.Functional`,\n* “Procedural” → `VP.Procedural`,\n* “Role‑Enactor (Device‑Structure)” → `VP.RoleEnactor`,\n* “Module‑Interface” → `VP.ModuleInterface`.\n\nAny deviation MUST be explicitly documented as a species‑level extension and MUST NOT reuse `VF.TEVB.ENG`.\n",
        "rationale": "### E.17.2:7 - Rationale & SoTA echoing  *(informative)*\n\n#### E.17.2:7.1 - NQD‑grounded choice of the core four\n\nPart G’s NQD discipline treats candidate viewpoint families as points in an N/U/C/D quality space (Use‑Value, Constraint‑Fit, Novelty, Diversity_P). Applied to a SoTA‑harvested candidate set of engineering viewpoints (Functional, Behavioural/Procedural, Structural/Module, Allocation/Role, Information/Data, Assurance/Safety, Mission/Context, Deployment/Operational, Business/Usage), this yields a small Pareto frontier for *engineering holon* viewpoints. On that frontier, the `F–B–S+R` cut implemented by `{VP.Functional, VP.Procedural, VP.RoleEnactor, VP.ModuleInterface}` is the minimal set that:\n* spans the Function–Behaviour–Structure ontology used in contemporary design theory while adding an explicit allocation/responsibility axis;  \n* aligns with the “functional/process/structural/deployment” clusters recurrent in standards and architecture frameworks;  \n* stays neutral with respect to domain‑specific qualities (`‑ilities`) and business/mission framing, which are captured in separate Q‑bundles and governance/viewpoint packs rather than in TEVB itself.\n\nOther candidates (e.g. dedicated information, assurance, or mission viewpoints) remain important but either duplicate concerns already captured by TEVB (when specialised to engineering holons) or are better modelled as orthogonal quality bundles (C.25) or non‑engineering bundles (business/governance packs). TEVB therefore pins only the core four and leaves the rest to specialised families.\n\n#### E.17.2:7.2 - Alignment with post‑2015 engineering practice\n\n* Modern architecture standards built on ISO/IEC/IEEE 42010 describe viewpoint libraries in which functional, behavioural/process, structural/deployment, and business/usage concerns are the dominant clusters; sector RAs such as IoT RA 30141 and space‑domain RAs provide explicit functional and construction/implementation viewpoints alongside business/usage and trustworthiness viewpoints. TEVB reuses the functional and construction/structural clusters as `VP.Functional` and `VP.ModuleInterface`, while treating business and trustworthiness as separate bundles.  \n* Model‑based systems engineering practice (INCOSE MBSE guidance, SysML v2 “views‑as‑queries”, UAF/NAF view grids) converges on a small set of core diagram families: structure vs behaviour vs allocation/responsibility vs requirements/mission. TEVB’s `VP.Procedural` and `VP.RoleEnactor` correspond to the behaviour and allocation/responsibility axes, respectively, and are designed to be notation‑neutral over SysML/UAF/UML/Capella‑style models.  \n* The FBS family of design ontologies (Function–Behaviour–Structure and extensions) provides a widely used conceptual basis for separating what a system is for, what it does over time, and what it consists of. TEVB’s four viewpoints intentionally implement an FBS+R split at the holon level: `VP.Functional` ≈ Function, `VP.Procedural` ≈ Behaviour, `VP.ModuleInterface` ≈ Structure, with `VP.RoleEnactor` capturing the explicit mapping from functions/behaviours to role‑enacting carriers.  \n* Within FPF itself, E.TGA’s “viewpoint families” (Functional, Procedural, Role‑Enactor/Device‑Structure, Module‑Interface, plus assurance/interoperability/data/operational/mission aliases) are harmonised by letting the **core four** be TEVB viewpoints and treating the rest as lexical or bundle‑level overlays, not as new kernel viewpoints.\n\n#### E.17.2:7.3 - Why TEVB stays small\n\nTEVB is deliberately *not* a complete architecture framework. It gives FPF a stable, holon‑centred engineering bundle that:\n* is small enough to keep in working memory and to govern via EpistemeSlotGraph discipline;  \n* is expressive enough to host mappings from SoTA architecture frameworks (4+1, domain‑specific RAs, UAF/NAF grids, SysML‑based MBSE method kits);  \n* can be safely combined with additional `U.ViewpointBundle` species (safety/assurance packs, business/mission packs, information/data packs) without mutating the core four;\n* sits conceptually **below** architecture‑specific viewpoint libraries, which are introduced as separate `U.ViewpointBundle` species layering TEVB with mission/quality/business viewpoints instead of redefining TEVB.\n\nAs SoTA evolves, new bundles can be added or TEVB can gain a new edition with a revised NQD‑frontier, but the TEVB‑A edition fixed here remains the archetypal engineering bundle for holons.\n",
        "relations": "### E.17.2:8 - Relations  *(informative)*\n\n* **Builds on.** E.17.0 (`U.MultiViewDescribing`), E.17.1 (`U.ViewpointBundleLibrary`), A.7/E.10.D2 (I/D/S), C.2.1 (EpistemeSlotGraph), A.6.2–A.6.4 (episteme morphisms).\n* **Constrains.** E.18:5.12 (E.TGA viewpoint map), engineering description/spec patterns, MVPK engineering publication profiles.\n* **Coordinates with.** L‑SURF/L‑PUBSURF (Surface kinds), F‑R family (Role, RoleDescription, RoleSpec), F.18 (naming discipline for ViewFamilyId / ViewpointId / EngineeringVPId / PublicationVPId).\n* **Non‑goals.** TEVB does not prescribe modelling notations (SysML, BPMN, IEC 61131‑3, etc.), storage formats, or tool APIs. It only fixes the **conceptual viewpoint bundle** that such tools must respect when claiming FPF alignment.\n",
        "e.17.2:end": "### E.17.2:End\n"
      },
      "content": "### E.17.2:End\n",
      "metadata": {},
      "part": "E",
      "cluster": null
    },
    {
      "id": "E.17",
      "title": "Multi‑View Publication Kit (for Morphisms)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## E.17 - Multi‑View Publication Kit (for Morphisms)\n\n> **Tech‑name:** `U.MultiViewPublicationKit` (**MVPK**)  \n> **Plain‑name:** Multi‑view publication kit (for morphisms)  \n> **Signature (conceptual form):**  `MVPK : (U.Morphism, Σ_viewpoints) ↦ U.ViewFamily` with per‑viewpoint components\n> `ViewObj_s : U.Object → U.ViewObj_s` and `Emit_s(-) : U.Morphism → U.ViewMorph_s`,\n> such that `(ViewObj_s, Emit_s)` forms a functor `U → View_s(U)`. For each `s ⪯ t`, a **reindexing coercion**\n> `PromoteView[s→t]_X : ViewObj_s(X) → ViewObj_t(X)` exists and is **natural in `X`**: for every `f : X → Y`,\n> `PromoteView[s→t]_Y ∘ Emit_s(f) = Emit_t(f) ∘ PromoteView[s→t]_X` (see Laws §6.2).\n> **Notation:** `Σ_viewpoints` is abbreviated as `Σ` where convenient.\n> **Twin‑register aliases (naming discipline):**\n> • **Tech:** `Emit_PlainView`, `Emit_TechCard`, `Emit_InteropCard`, `Emit_AssuranceLane`; `PromoteView[s→t]_-`.  \n> • **Plain:** `PlainView(x)`, `TechCard(x)`, `InteropCard(x)`, `AssuranceLane(x)`; “Promote to *t*”.\n\n> **USM binding (overview):** `PublicationScope` is a **USM‑class** object that parameterizes MVPK; see §5.0.  \n> **Episteme level.** MVPK treats each face as a `U.View` in the sense of C.2.1/E.17.0 (species `U.EpistemeView`). For a morphism `f`, every `Emit_s(f)` is such a view whose `DescribedEntitySlot`/`DescriptionContext` target is `f : U.Morphism` and whose `viewpointRef` is a publication `U.Viewpoint` (`PublicationVPId`) drawn from a `U.ViewpointBundle` (E.17.1/E.17.2). Slot discipline (`ViewSlot`/`ViewRef`) is inherited from C.2.1/A.6.5 and is not redefined in MVPK.\n",
        "intent": "### E.17:1 - Intent\n\nProvide a **disciplined, compositional way to publish morphisms** (arrows) across multiple didactic faces (views/cards) **without adding semantics**, while keeping **viewpoints** (the specifications that constrain views) explicit and auditable. Authors get a small **view‑pack** that, when applied to any `U.Morphism` (including compositions), yields a **family of views** that commute with arrow composition and respect edition/measurement pinning (Part F/G).\n",
        "problem": "### E.17:3 - Problem\n\n1. **Semantic drift in publication.** Unchecked “presentations” introduce claims not present in the D/S‑epistemes about the arrow (epistemes with `DescriptionContext = ⟨DescribedEntityRef, BoundedContextRef, ViewpointRef⟩` in the sense of E.10.D2/E.17.0).    \n2. **Non‑compositionality.** Publishing `g∘f` yields surfaces that don’t match composing the surfaces of `f` and `g`.    \n3. **View vs viewpoint confusion.** A single template is treated as “the view”, with no declared concerns or conformance rules.    \n4. **Unpinned numbers.** Numeric claims lack unit/scale/reference‑plane and **edition pins** (Part F/G), undermining auditability.    \n",
        "forces": "### E.17:4 - Forces\n\n| Force | Tension |\n| --- | --- |\n| **Compositionality vs legibility** | Preserve arrow laws across views ↔ keep each view didactic and audience‑appropriate. |\n| **Neutral naming vs domain idioms** | Use vocabulary stable across domains ↔ allow local templates (SOPs, APIs, checklists). |\n| **Surface orthogonality (A.7)** | Publication must not mutate I/D/S semantics ↔ authors expect “rich presentations”. |\n| **Evidence discipline** | Views must cite CG‑Spec/CHR anchors ↔ authors want compact cards. |\n",
        "solution": "### E.17:5 - Solution — the **MVPK Kit**\n\n#### E.17:5.0 - USM anchoring (normative)\n* **PublicationScope (USM).** `U.PublicationScope` is defined in **USM** (A.2.6 §6.5) analogously to `U.WorkScope` and `U.ClaimScope` as a **set‑valued scope object** over `U.ContextSlice`. In MVPK, every emitted `U.View` SHALL declare a `U.PublicationScope` that bounds where that face is admissible.  \n  * **Non‑overload rule.** `U.PublicationScope` MUST NOT encode viewpoint choice, MVPK profile selection, or Publication Characteristics (PC); those are governed by `PublicationVPId`/`U.Viewpoint` and MVPK profile rules (§5.1/§5.2/§5.5).\n* **Scope lineage.** `U.PublicationScope` participates in the same USM lineage regime as `U.WorkScope`/`U.ClaimScope` (Δ‑moves, editioning and migration rules); MVPK emits faces **under** a declared `PublicationScopeId`.\n* **MVPK profile (kit configuration).** The canonical MVPK profiles (MVPK‑Min/Lite/SetReady/Max) fix:\n  * (a) the **viewpoint index** `Σ` and its partial order `⪯`,\n  * (b) the admissible **Publication characteristics (PC)** and required **pinning contracts**,\n  * (c) any cross‑Context/plane constraints (Bridge/CL policies) applicable to emitted faces.\n* **L, P, D, E quartet.** The canonical MVPK‑Max profile enumerates exactly four **face kinds**: `PlainView (P)`, `TechCard (T)`, `InteropCard (I)`, `AssuranceLane (A)`. If a program elects to retain the mnemonic **(L, P, D, E)** tuple, it MUST map it 1‑to‑1 onto these **face kinds** and SHALL NOT introduce additional kinds without a USM extension.\n\n#### E.17:5.1 - Terminology (normative)\n\n* **View** (`U.View`): an episteme‑level view (`U.EpistemeView` in the sense of C.2.1/E.17.0) produced *under* a publication viewpoint. In MVPK each face (`PlainView`, `TechCard`, `InteropCard`, `AssuranceLane`) is such a `U.View` whose `DescribedEntitySlot`/`DescriptionContext` target is a `U.Morphism` and whose `viewpointRef` is a publication `U.Viewpoint`.  \n  Every MVPK `U.View` **SHALL** declare:  \n  `SurfaceKind ∈ {PublicationSurface, InteropSurface}`, `PublicationVPId : U.ViewpointRef`, references to the underlying D/S‑epistemes produced by `Describe_ID`/`Specify_DS` in A.7/E.10.D2, and a `U.PublicationScope` (USM §6.5).  \n  Any materialization/rendering is separate **Work on SCR/RSCR carriers** and is not part of `U.View`.\n* **Publication vs presentation vs rendering vs representation (guard):**    \n    * **Publication** = typed projection from existing D/S‑epistemes about a morphism onto a `U.View`/`PublicationSurface` via species of `U.EpistemicViewing` (A.6.3) under the I/D/S discipline of A.7/E.10.D2.        \n    * **Presentation** = rhetorical arrangement of a published carrier; **notation‑neutral**, adds no claims and is **not** a Surface kind.        \n    * **Rendering** = display/layout of a carrier, purely graphical/formatting; **Work on carriers** (A.7), not a Surface kind.        \n    * **Representation** = episteme↔referent relation (C.2.1/A.6.2–A.6.4); **not** a surface act. Use **publication** and **view** here; treat presentation/rendering as **Work on carriers** (A.7).\n* **ISO mapping note.** ISO **viewpoint** → `PublicationVPId` (publication layer); **engineering viewpoint** → `EngineeringVPId` (E.TGA E.18:5.12). An ISO **view** may be a single MVPK face; “bundles” are packaging only.\n* **No‑mechanism equivalence:** MVPK **is not** a mechanism; any operational toil (build/render/upload) is **separate Work by a system on carriers** (A.7; see **Laws 5 — No Γ‑leakage** in §6).\n* **ViewpointSpec (`U.Viewpoint`)** — a typed specification that declares stakeholders, concerns, conformance rules, allowed **Publication Characteristics**, and pinning requirements per profile. The index set `Σ` consists of identifiers of `U.Viewpoint` instances, typically drawn from `U.ViewpointBundle` species (E.17.1/E.17.2) (see §5.3).\n\n#### E.17:5.2 - Allowed surfaces at Part E (L‑SURF discipline)\nPart E restricts the term *Surface* to **PublicationSurface** and **InteropSurface**. Concrete faces SHALL be named **…View / …Card / …Lane**. \n\n**USM linkage (normative).** Every `U.View` **SHALL** declare a `U.PublicationScope` (USM §6.5).  \nFor a view **about an episteme** `E`: `PublicationScope(view_E) ⊆ ClaimScope(E)`.  \nFor a view **about a capability** `C`: `PublicationScope(view_C) ⊆ WorkScope(C)`.  \nCross‑context views **SHALL** cite Bridge + CL; **CL penalties apply to R only** (scope membership unchanged).\n\n**L‑PUBSURF naming discipline**\n * Allowed surface kinds: **PublicationSurface**, **InteropSurface**.\n * Concrete faces MUST be named **…View / …Card / …Lane**.\n* The tokens **carrier/bearer/holder** MUST NOT name a `U.View` or any publication entity.  \n  Use **`U.View`** (PlainView / TechCard / InteropCard / AssuranceLane) for conceptual publication faces.  \n  Reserve **carrier** exclusively for **SCR/RSCR** (symbol/document/data carriers) and **Work on carriers**.\n* Avoid geometric metaphors (axis/dimension) for publication artifacts; use **Characteristic/CharacteristicSpace** only when referring to CHR‑MM entities.\n* **Non‑collision guard.** `ViewFamilyId` (lexical tag for viewpoint families) MUST NOT be used to name any `U.View` or surface kind; MVPK face kinds remain **{PlainView, TechCard, InteropCard, AssuranceLane}** only.\n\n**MVPK‑Max viewpoints (normative; exactly four; governed by the MVPK profile):**\n* `PlainView` (explanatory prose view)    \n* `TechCard` (typed catalog card)    \n* `AssuranceLane` (evidence bindings/lanes)\n* `InteropCard` (conceptual interoperability view; **mapping to concrete exchange formats lives in Annex/Interop; Part E does not specify schemas**)\n\n**Lean profiles (small‑team friendly, optional; as MVPK kit profiles):**\n* **MVPK‑Min (F0–F1):** Σ = {`PlainView`, `TechCard‑Lite`}. `AssuranceLane` omitted. No interop face.\n* **MVPK‑Lite (F1–F3):** Σ = {`PlainView`, `TechCard‑Lite`, `AssuranceLane‑Lite` gated by crossing trigger}. `InteropCard` only if external consumers exist.\n* **MVPK‑SetReady (F3–F5):** add `InteropCard` when replayability or external interchange is required (details outside Part E).\n* **Profile‑upgrade triggers:** (i) cross‑Context/plane reuse; (ii) QD/OEE replay needs; (iii) external consumption.\n* **“‑Lite” variants (definition):** A *‑Lite* face removes optional fields only (never claims), keeps the same typing as its full counterpart, and MUST retain pins for any numeric content. Upgrading from *‑Lite* to full is a monotone **add‑fields** operation (no retractions).\n\n#### E.17:5.3 - The kit (constructs)\n\n1. **Object component** `ViewObj_s` for each viewpoint (see §5.1), to make types explicit.  \n2. **Viewpoint set** `Σ : FinSet(U.Viewpoint)` with declared **partial order** `⪯` for formality/refinement (default chain: `PlainView ⪯ TechCard ⪯ InteropCard`; `AssuranceLane` is **orthogonal** and not ordered with respect to others).  \n3. **Emitters** `Emit_s(-) : U.Morphism → U.ViewMorph_s` (one per `s ∈ Σ`).\n4. **Coherence** (laws §6) + **Pin Characteristics** policy (UnitType/ScaleKind/ReferencePlane/EditionId) for any numeric/comparable content, grounded in CHR/UNM.    \n5. **Interop anchors (conceptual)** for `InteropCard` (concerns/semantics only); **any concrete schema/exchange mapping is outside Part E** (Annex/Interop).\n\n**Result:** `MVPK(f, Σ)` returns `U.ViewFamily(f)` whose components are `Emit_s(f)`. Reindexing across `s ⪯ t` is mediated by total object‑level coercions `PromoteView[s→t]_X` (see §6.2).\n\n#### E.17:5.4 - Intensional I/O vs Publication (normative convention)\n1) **I/O are intensional.** The **Input/Output** sections of a morphism describe **intensional** data types (I/D/S) only; they do **not** depend on any publication face.  \n2) **No duplication on faces.** MVPK faces **do not duplicate** I/O lists; they publish a **minimal profile**: **presence‑pins**, **CG‑Spec/CHR anchors**, and **EditionId** only.  \n3) **Signature reserved to intensional.** Use **“Signature”** exclusively for intensional objects (`U.Signature`, `U.PrincipleFrame`, …). On faces, avoid “signature” and use **TechName/PlainName**.  \n4) **Lawful orders, return sets.** Whenever a face shows **selection or comparison**, it **returns sets / lawful partial orders** and **never hides scalarization**; cite a **ComparatorSetRef** for any total order.  \n5) **Bridge routing, penalties.** Crossings go via **Bridge + CL**; publish **Φ(CL)/Φ_plane** ids; penalties route to **R only** (never F/G).  \n6) **Carrier anchoring & lanes.** On first mention, anchor carriers (**SCR/RSCR**); keep **Work occurrences** distinct from **epistemic claims** via lanes.  \n7) **Publication ≠ execution.** No time/resource semantics on faces; any build/render/upload is separate **Work**.\n\n#### E.17:5.5 - Pin & Publication characteristics (normative; never “axes”)\n**Intent.** Make pinning and publication‑time measurement claims explicit, typed, and auditable without importing geometric metaphors. This section introduces **Publication characteristics** (PC) as CHR‑grounded, publication‑level facets that can legally appear on MVPK faces.\n\n**Terminology (aligned with CHR‑MM & UNM).**\n* **Characteristic** (`U.Characteristic`): a measured aspect as defined in CHR‑MM (entity/relation characteristic with a chosen **Scale**).  \n* **CharacteristicSpace** (`U.CharacteristicSpace`): a CHR‑typed product of slots used by dynamics/measurement theories (A.19).  \n* **Publication characteristic** (`U.PubCharacteristic`, **PC**): a **declarative facet** that a view/card/lane may expose *about a morphism* under a stated **Viewpoint**. Each PC is **backed by** CHR/CG‑Spec artifacts and **pinned** by {unit/scale/reference‑plane/edition}. PCs are **not** geometry and do **not** define “axes”.\n\n**PC catalog (initial set).** MVPK defines a minimal open set of PCs that are frequently surfaced:\n* **PC.Number** — numeric/comparable entries (thresholds, budgets, counts). **Pins required:** unit, scale, reference‑plane, edition.  \n* **PC.EvidenceBinding** — bindings to evidence carriers and policies (e.g., PathSliceId, BridgeId, CL notes).  \n* **PC.ComparatorSetRef** — an explicit comparator family for lawful partial orders on faces.  \n* **PC.CharacteristicSpaceRef?** — optional pointer when a face needs to cite the **space** in which a claim is interpreted (e.g., dominance on a declared space).  \nThe catalog **MAY** be extended (see “Extensibility” below); PCs **must** remain declarative (no embedded mechanisms).\n\n**Norms (E17‑PC).**\n* **E17‑PC‑1 (CHR grounding).** Every PC that yields numeric/comparable content **SHALL** cite CHR/CG‑Spec anchors and carry pins {unit, scale, reference‑plane, edition}.  \n* **E17‑PC‑2 (Lexical discipline — no geometry).** Faces and PCs **MUST NOT** use “axis”, “dimension”, or geometric metaphors; use **Characteristic**, **slot**, **CharacteristicSpace** where applicable (**E.10**; see also A.19).  \n* **E17‑PC‑3 (No hidden arithmetic).** Faces **MUST NOT** smuggle aggregation/normalization; any such logic lives in **CG‑Spec** (UNM/NormalizationMethod) and is cited by **…Ref.edition**.  \n* **E17‑PC‑4 (Plane & crossing).** When a PC depends on **ReferencePlane** or crosses planes/contexts, the face **SHALL** cite `BridgeId` and **CL** policy‑ids; penalties route to the **R‑channel only**.  \n* **E17‑PC‑5 (Edition pinning).** PCs that rely on maps or distances **SHALL** pin `DescriptorMapRef.edition`, `DistanceDefRef.edition`, and, if used, `CharacteristicSpaceRef.edition` / `TransferRulesRef.edition`.  \n* **E17‑PC‑6 (Viewpoint scope).** Each PC instance declares the **Viewpoint** under which it is valid; promotion `PromoteView[s→t]` **MUST NOT** strengthen claims; at most, it reindexes or annotates.  \n* **E17‑PC‑7 (Comparator/SetSemantics edition).** `PC.ComparatorSetRef` and any `SetSemanticsRef` **SHALL carry edition identifiers**; cards MUST be re‑emitted upon edition change with migration notes.\n\n**Surfaces & responsibilities.**\n* **PlainView** MAY include **PC.Number** iff fully pinned; otherwise it uses **compare‑only** language.  \n* **TechCard** SHOULD carry **PC.Number**, **PC.ComparatorSetRef**, and **PC.CharacteristicSpaceRef?** when faces enable lawful ordering.  \n* **AssuranceLane** SHALL carry **PC.EvidenceBinding** and the pins for any numeric claims it relays.  \n* **InteropCard** MAY reference PCs conceptually but SHALL remain notation‑neutral in Part E (schemas map in Annex/Interop).\n\n**Rationale.** MVPK is a publication discipline, not a measurement calculus. By naming **Publication characteristics** and pinning them to CHR/UNM, we:\n1) prevent geometric leakage (no “axes”);  \n2) keep publication neutral yet auditable;  \n3) enable lawful set/ordering behavior on faces via explicit **ComparatorSet**;  \n4) make plane/crossing obligations first‑class and checkable by declared publication checks / **OperationalGate(profile)** GateChecks.\n\n**Extensibility.**\n* **E17‑PC‑Ext‑1 (Open catalog).** New PCs MAY be added under `U.PubCharacteristic` provided they are declarative and CHR/UNM‑grounded.  \n* **E17‑PC‑Ext‑2 (Kinding).** New PCs MUST declare `kind ∈ {Number, EvidenceBinding, SelectorHint, …}` and a **pinning contract**.  \n* **E17‑PC‑Ext‑3 (Twin‑register names).** Supply **Tech** and **Plain** twins; avoid tokens that collide with E.10 bans; do not coin “…Space” names for publication artifacts.  \n* **E17‑PC‑Ext‑4 (Edition discipline).** If a PC depends on a definitional artifact, **edition‑pin** the reference (`…Ref.edition`) and document migration rules.\n\n**Adding invariants (procedure).**\n1) Place **new invariants** for PCs in **CG‑Spec** (S‑layer), not on faces; supply acceptance tests.  \n2) Version any affected **CharacteristicSpace**; publish embeddings if semantics change; never mutate slots in place.  \n3) Update the relevant **GateChecks / GateProfiles** (A.21/A.26; incl. GateCrossing/CrossingSurface checks from **E.18/A.27**) to warn/block on invariant violations; never weaken functorial laws.\n4) **Document** edition/migration rules; extend §9 with a conformance item and provide **Lean‑profile downgrade** (advisory vs block) where applicable.\n\n#### E.17:5.6 - Author ergonomics (non‑normative)\n*Quick path for authors (three steps and a micro‑template):*\n1. **Declare Σ and profile.** Choose `{PlainView, TechCard, …}` and whether faces are full or *‑Lite*.\n2. **Pin once, reuse everywhere.** Attach `{UnitType, ScaleKind, ReferencePlane, EditionId}` to the arrow; cards reference these pins by ID (no duplication).\n3. **Emit & verify.** Generate all faces from the arrow.\n\n*Guidance:* treat *‑Lite* as **field‑drop only**; never add claims in *‑Lite*. \n",
        "laws_(normative)": "### E.17:6 - Laws (normative)\n\nFor any composable arrows `X —f→ Y —g→ Z` in `U`, and any `s, t ∈ Σ_viewpoints`:\n\n1. **Functoriality & typing (per‑viewpoint).**  \n    * (a) **Identity:** `Emit_s(id_X) = id_{ViewObj_s(X)}`.    \n    * (b) **Composition:** `Emit_s(g∘f) = Emit_s(g) ∘ Emit_s(f)`.    \n    * (c) **Typing (totality):** if `f : X → Y` then `Emit_s(f) : ViewObj_s(X) → ViewObj_s(Y)` is **total**; ill‑typed composites must be fixed via `ViewObj_s`, not by weakening laws.    \n    * *Intuition:* every viewpoint acts functorially on arrows; publication does not break arrow algebra.\n2. **Reindexing coherence (monotone refinement + naturality).**    \n    * (a) If `s ⪯ t` then the `t`‑view **refines** the `s`‑view for the same morphism (**no content extension**; increased formality/typing only).    \n    * (b) For each `s ⪯ t` there are **object‑components** `PromoteView[s→t]_X : ViewObj_s(X) → ViewObj_t(X)` natural in `X`, i.e., for every `f : X → Y`  \n      `PromoteView[s→t]_Y ∘ Emit_s(f) = Emit_t(f) ∘ PromoteView[s→t]_X`.    \n    * (c) **Coherence:** `PromoteView[s→s]_X = id_{ViewObj_s(X)}`, and if `s ⪯ t ⪯ u` then `PromoteView[s→u]_X = PromoteView[t→u]_X ∘ PromoteView[s→t]_X` for all `X`.         \n    * *Defaults:* `PlainView ⪯ TechCard ⪯ InteropCard`.    \n    * *Note:* `AssuranceLane` is **orthogonal** to the chain; it binds **evidence‑about‑claims** and MUST NOT introduce new claims **of** the morphism. \n3. **D/S sourcing & EpistemicViewing compatibility (A.7/E.10.D2, A.6.2–A.6.3, E.17.0).**    \n    * (a) Inputs to `Emit_s(-)` are **existing D/S‑epistemes** about the same arrow (for example, `MethodDescription`, `MethodSpec`) produced by `Describe_ID` and `Specify_DS`/`Formalize_DS` in A.7/E.10.D2. MVPK does **not** redefine or collapse these I→D→S morphisms.  \n    * (b) Each `Emit_s(-)` SHALL be realised as a species of `U.EpistemicViewing` (A.6.3) over those D/S‑epistemes: describedEntity‑preserving, effect‑free and conservative in the sense of A.6.2/A.6.3. Publication adds no new commitments beyond what is present in the referenced D/S‑epistemes.  \n    * (c) Edition governance respects `U.EditionSeries`/UTS; rows remain the identity anchors for names; MVPK faces MUST be (re‑)emitted when the underlying D/S editions change.\n4. **Pin discipline (Part F/G).**  \n     * Any numeric/comparable content in a view SHALL pin {UnitType, ScaleKind, ReferencePlane}. **EditionId MAY be coarse at Lean profiles**; if units/scale are unknown, **declare ordinal/compare‑only** and **forbid arithmetic** until CHR pins are available.  Pins upgrade monotonically with profile and risk.\n5. **No Γ‑leakage (publication independence).**  \n    Publication morphisms carry **no** Γ\\_method / Γ\\_time / Γ_work semantics. Any build/render/upload toil is **separate Work by a system on carriers** (A.7).    \n     **Lean assurance lane:** `AssuranceLane‑Lite` MAY expose only presence bits for {PathId/PathSlice?, Γ_time window?, BridgeId?}; unknowns propagate (tri‑state) with an explicit {degrade|abstain|sandbox} policy note.\n6. **Carrier provenance.**  \n    Every emitted view records its **SCR/RSCR ids** on first occurrence (A.7 §5.6).\n7. **Isomorphism preservation.**    \n    * If `f` is an isomorphism in `U`, then `Emit_s(f)` is an isomorphism in `View_s(U)`; inverses map accordingly.  \n8. **Cross‑Context/plane bridging.**    \n    * If a view crosses contexts or reference planes, it **SHALL** cite the **Bridge + CL policy ids** (A.7 §5.8, “Bridge routing”). Such crossings MUST be explicit on `TechCard` and `AssuranceLane`.\n9. **Totality of publication morphisms.**    \n    * Publication maps are total on their domains; when a composition in a view would be ill‑typed, the author **must** fix the object mapping (via `ViewObj_s`) rather than weakening functoriality or reindexing laws.\n10. **PublicationScope discipline (subset & composition).**  \n    * (a) **Subset law:** If a view `v` is about episteme `E` then `PublicationScope(v) ⊆ ClaimScope(E)`; if about capability `C` then `PublicationScope(v) ⊆ WorkScope(C)`.  \n    * (b) **No widening by refinement:** If `s ⪯ t`, then promotion `PromoteView[s→t]` MUST NOT widen `PublicationScope`.  \n    * (c) **Compositional bound:** For composable arrows `X —f→ Y —g→ Z`,  \n      `PublicationScope(Emit_s(g∘f)) ⊆ PublicationScope(Emit_s(g)) ∩ PublicationScope(Emit_s(f))`.\n",
        "structure_&_participants": "### E.17:7 - Structure & participants\n```\n                 Σ_viewpoints\n                      │\n            ┌─────────┴─────────┐\n            │                   │\n        Emit_s(-)           Emit_t(-)      … (family)\n            │                   │\nU :  X ──f──▶ Y ──g──▶ Z    X ──f──▶ Y ──g──▶ Z \n        U.ViewMorph        U.ViewMorph\n            │                   │\n        Emit_s(f),…         Emit_t(f),…\n```\n* **Author** chooses `Σ_viewpoints` (declared concerns + conformance rules).    \n* **MVPK** emits `U.ViewFamily(f)` for each arrow `f`.    \n* **Gate‑based validation** (via declared publication checks / OperationalGate(profile) GateChecks) verifies that pins/anchors/IDs are present and that MVPK laws are respected.\n",
        "examples_(sota‑echoing)": "### E.17:8 - Examples (SoTA‑echoing)\n\n1. **Composite service pipeline (Interop + Assurance).**  \n    `f: Parse → Normalize`, `g: Normalize → Score`.\n    `InteropCard(g∘f)` is an interoperability **view** whose path set equals the **relational composition** of the two cards; `AssuranceLane(g∘f)` cites test artefacts as evidence **carriers** with edition pins. (Carriers, not semantics; concrete envelope formats are outside Part E.)\n2. **Control loop morphism (Tech + Plain).**\n    * For `h: Setpoint → Actuation`, `TechCard(h)` is a typed card with units; `PlainView(h)` narrates the same mapping with no new claims. (Monotone formalization echoes refinement‑typed stacks.)\n3. **Optics‑style compositional views.**\n    * Treat each `Emit_s(–)` as a **profunctor optic** from arrow semantics to its projection; then (by optics laws) `Emit_s(g∘f) = Emit_s(g) ∘ Emit_s(f)`. *Modern echo:* profunctor/optic literature (2017–2019) establishes precisely the kind of **compositional view** MVPK requires.  \n",
        "conformance_checklist": "### E.17:9 - Conformance checklist (normative)\n\n| ID | Requirement | Practical test |\n| --- | --- | --- |\n| **CC‑MVPK‑0 (Lean publication guard)** | For Lean profiles, a minimal guard runs: (i) set‑returning selection present; (ii) ReferencePlane present; (iii) any crossing cites BridgeId+CL with penalties routed to R only. | Validation report shows presence bits; penalties route to R only. |\n| **CC‑MVPK‑1 (Viewpoint explicit)** | Each view declares its **Viewpoint** (stakeholders, concerns, conformance) as a publication `U.Viewpoint`. | Cards show `PublicationVPId` (or equivalent publication‑viewpoint field) and concerns. |\n| **CC‑MVPK‑2 (Functoriality)** | `Emit_s(id)` is identity; `Emit_s(g∘f) = Emit_s(g)∘Emit_s(f)`. | Compose two cards and diff with the card of the composite. |\n| **CC‑MVPK‑3 (No content extension)** | `PlainView`, `TechCard`, and `InteropCard` add **no new claims** beyond the underlying D/S‑epistemes. | Red‑line vs D/S episteme output (`Describe_ID`/`Specify_DS`) shows only formatting/indexing. |\n| **CC‑MVPK‑3b (Boundary claim‑set integrity)** | If a published arrow is a boundary/interface/protocol and an A.6.B routed claim set exists (`L-* / A-* / D-* / E-*`), then any normative text on faces **MUST** be traceable to that claim set (prefer claim‑ID citations); faces **MUST NOT** become a second contract. | Lint flags uncited normative clauses; faces reduce to {claim‑ID citations + informative commentary}. |\n| **CC‑MVPK‑4 (Pins & anchors)** | Numbers/thresholds pin {… }. **Lean exception:** at MVPK‑Min/Lite profiles, EditionId MAY remain coarse; ordinal claims are legal only as compare‑only (no means/z‑scores). | Validation shows pins present or compare‑only mode engaged. |\n| **CC‑MVPK‑4b (Lean assurance)** | If `AssuranceLane‑Lite` is used, presence bits for {PathSliceId?, BridgeId?} suffice; full artefact lists are deferred. | Presence bits visible; deferred artefacts marked TODO. |\n| **CC‑MVPK‑4c (I/O vs publication)** | Faces **do not** restate I/O; they carry **presence‑pins + anchors + EditionId** only. | Face inspection shows no I/O duplication. |\n| **CC‑MVPK‑4d (Lawful orders)** | Any selection/comparison on faces **returns sets / lawful partial orders** with a **ComparatorSet** citation. | No hidden scalarization; ComparatorSetRef present. |\n| **CC‑MVPK‑4e (Signature on faces — banned)** | The term **“signature”** is **not used** on faces; use **TechName/PlainName**. | Token scan: no “signature” on faces. |\n| **CC‑MVPK‑4f (PC discipline)** | Any numeric/comparable publication uses **Publication characteristics** (PC) and carries pins {unit, scale, reference‑plane, edition}. | Cards show PC fields + pins; validation passes. |\n| **CC‑MVPK‑4g (No axis/dimension)** | Faces avoid “axis/dimension/plane” metaphors except **ReferencePlane**; use CHR terms (**Characteristic/slot/CharacteristicSpace**). | Lexical check flags none; only `ReferencePlane` appears. |\n| **CC‑MVPK‑4h (Edition pins on defs)** | Where maps/distances/spaces are cited, the face pins `DescriptorMapRef.edition`, `DistanceDefRef.edition`, and `CharacteristicSpaceRef.edition?`. | Validation shows edition fields populated. |\n| **CC‑MVPK‑4i (Crossings gated)** | Plane/Context crossings cite **Bridge + CL** policies; penalties route to **R‑channel** only. | IDs present; routing verified in harness logs. |\n| **CC‑MVPK‑4j (PublicationScope present)** | Each view **declares `U.PublicationScope`** (USM §6.5). | Field present; presence‑bit green. |\n| **CC‑MVPK‑4k (Subset‑of underlier)** | For views about epistemes/capabilities, `PublicationScope ⊆ ClaimScope/WorkScope`; reindexing **does not widen** it. | Subset witness passes; promotion diff shows no widening. |\n| **CC‑MVPK‑5 (Carrier anchoring)** | First mention includes **SCR/RSCR** ids. | SCR ids visible on the card. |\n| **CC‑MVPK‑6 (Γ‑separation)** | No cost/time/data‑spend on publication morphisms. | CI shows proofs/witness artefacts; gate validation passes. |\n| **CC‑MVPK‑7 (Reindexing monotone)** | If `s ⪯ t`, then `Emit_s(x) ⪯ Emit_t(x)`. | `TechCard` ≤ `InteropCard` (more structure, same claims). |\n| **CC‑MVPK‑8 (Surface discipline)** | Only **PublicationSurface/InteropSurface** are used; faces named …**View/…Card**. | Token scan; no “rendering/presentation” as surface kinds. |\n| **CC‑MVPK‑9 (Reindexing naturality)** | Reindexing coercions `PromoteView[s→t]` exist, are total, and commute with composition. | Witness shows `PromoteView[s→t]_Z ∘ Emit_s(g∘f) = (Emit_t(g) ∘ Emit_t(f)) ∘ PromoteView[s→t]_X`. |\n| **CC‑MVPK‑10 (Iso‑preservation)** | Isomorphisms in `U` remain isomorphisms under each viewpoint. | Cards show mapped inverses or an iso‑witness. |\n| **CC‑MVPK‑11 (Typing & totality)** | Ill‑typed composites are rejected at `ViewObj_s` rather than weakening functoriality. | Type‑check fails early; no “best‑effort” composition in cards. |\n| **CC‑MVPK‑12 (Bridge+CL on crossings)** | Any cross‑Context/plane view cites **Bridge + CL** policy ids. | IDs present on `TechCard`/`AssuranceLane`. |\n",
        "anti‑patterns_(with_fixes)": "### E.17:10 - Anti‑patterns (with fixes)\n\n1. **“Presentation logic” as semantics.**  \n    *Fix:* Move any logic to `Describe_ID`/`Specify_DS` or CG‑Spec/KD‑CAL; keep views declarative; publication adds **zero** claims.    \n2. **Publishing only objects.**  \n    *Fix:* MVPK **acts on arrows**. Always emit views for `g∘f`, not just for objects `X, Y, Z`.    \n3. **Unpinned numbers.**  \n    *Fix:* Reject card; supply **pins** and CG/CHR anchors.    \n4. **Viewpointless views.**  \n    *Fix:* Define Viewpoint; attach concerns + conformance; re‑emit.    \n5. **Interop ≡ Tech duplication.**  \n    *Fix:* `InteropCard` may refine typing/shape but cannot contradict `TechCard` (reindexing monotone).    \n",
        "consequences": "### E.17:11 - Consequences\n\n| Benefit | Why it matters | Trade‑off / Mitigation |\n| --- | --- | --- |\n| **Arrow‑level traceability.** | Composition preserved across views enables chain‑of‑evidence on pipelines. | Slight authoring overhead → MVPK templates. |\n| **Audit‑ready surfaces.** | Pins + CHR anchors make numeric claims verifiable. | Gate‑based validation performs checks. |\n| **Terminology hygiene.** | Clear View vs Viewpoint, Publication vs Presentation. | Enforce L‑SURF tokens in CI. |\n| **Notation independence.** | Viewpoints talk concerns, not tools. | Provide adapters to local stacks. |\n",
        "sota_echoing": "### E.17:12 - SoTA-echoing (post‑2015; conceptual pointers)\n\n* **Profunctor/optic accounts (2017–2019).** Establish **compositional “views”** that compose like arrows—mirrors MVPK’s functorial law.    \n* **Refinement‑typed ecosystems (2016→).** Units/scale at type level echo **pin discipline**.    \n* **Interoperability & evidence envelopes.** External standards exist, but **their concrete formats live outside Part E** (see Annex/Interop for examples and mappings).\n\n(References are illustrative exemplars of practice; MVPK remains notation‑agnostic.)\n",
        "relations": "### E.17:13 - Relations\n\n* **Builds on:** A.7/E.10.D2 (Strict Distinction & I/D/S discipline), A.6.2–A.6.3 (episteme morphisms, `U.EffectFreeEpistemicMorphing` / `U.EpistemicViewing`), E.17.0 (`U.MultiViewDescribing`), E.8 (Authoring conventions), E.10 (LEX‑BUNDLE incl. L‑SURF), Part F/G (UTS, CG‑Spec, CHR pins).    \n* **Constrains:** Any surface‑emitting automation; must treat publication as a species of `U.EpistemicViewing` over existing D/S‑epistemes, not as a new I→D→S mechanism.    \n* **Coordinates with:** B‑operators (no Γ‑leakage), C‑cluster (selection/archives: views are publication faces, not selections), **CHR‑MM** (measurement semantics), **UNM** (normalization families).\n",
        "minimal_authoring_template_(e‑level)": "### E.17:14 - Minimal authoring template (E‑level)\n\n**Header:** `MVPK v⟨edition⟩ — Σ = {PlainView ⪯ TechCard ⪯ InteropCard, AssuranceLane ⟂}`  \n**For each arrow `f`:** emit `{Emit_s(f) | s ∈ Σ}` (or use the plain aliases `{PlainView(f), TechCard(f), …}`) with: **PublicationScope**, ViewpointId, pins, CHR/CG anchors, SCR ids, Bridge+CL ids (if crossing), and—if composite—machine‑checkable witnesses that `Emit_s(g∘f) = Emit_s(g)∘Emit_s(f)` **and** for each `s ⪯ t` the naturality square `PromoteView[s→t]_Y ∘ Emit_s(f) = Emit_t(f) ∘ PromoteView[s→t]_X`.\n",
        "manager’s_one‑page_review_(copy‑paste)": "### E.17:15 - Manager’s one‑page review (copy‑paste)\n\n> “We publish every **morphism** under a declared **set of viewpoints** using **MVPK**. Each **view** is **functorial** (identities, composition), **adds no new claims**, and pins **unit/scale/reference‑plane/edition** with **CHR/CG** anchors. **Interop** views clarify concerns/semantics only (concrete exchange lives outside Part E); **Assurance** cites evidence carriers (SCR). Any cross‑Context/plane view cites **Bridge+CL** (Φ→R only). Publication toil is **Work on carriers**, not a mechanism change.” \n",
        "e.17:end": "### E.17:End\n"
      },
      "content": "### E.17:End\n",
      "metadata": {},
      "part": "E",
      "cluster": null
    },
    {
      "id": "E.18",
      "title": "Transduction Graph Architecture** (E.TGA)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## E.18 - Transduction Graph Architecture** (E.TGA)\n\n> **Tech‑name:** **E.TGA** (pattern label)\n> **Plain‑name:** Architecture of the transduction graph\n> **Twin labels:** Tech / Plain per E.10; faces emitted via E.17 MVPK (no schemas in Part E). \n",
        "intent": "### E.18:1 - Intent\n\nProvide a **notation‑independent** architecture for graphs whose vertices are **morphisms (transductions)** and whose edges are **typed transfers**. The architecture is **agnostic to the concrete morphism set** and equips the graph with **publication, comparability, crossing, and budget** disciplines so that **flows** are **valuations over paths** within the same object. Faces appear via **MVPK**; numeric/comparable publication carries **pins** with **Bridge/CL** notes; Φ/CL^plane penalties remain in **R**.  \n*Style note:* wording follows the **counterfactual register** of FPF: invariants are stated as model conditions, not deontic obligations (per E.8 style and the assignment).\n",
        "problem": "### E.18:3 - Problem\n\n1. **Morphisms ≠ Graph.** A catalog of morphism‑level patterns (e.g., UNM, Selector, Work, Refresh) does not, by itself, explain **how the whole graph is built, constrained, and audited**.\n2. **Flow proliferation.** Multiple “reference flows” can be authored; readers need **one orchestration** that keeps them legal and comparable **without privileging any single flow**.\n3. **Unsafe publication.** Faces re‑list I/O, hide scalarization, or omit edition/plane pins; cross‑Context reuse lacks **Bridge/CL** citation; **plane penalties** leak to F/G. \n4. **Cycles without norms.** Selection↔Planning loops run without explicit **budget (Γ_time)**, **FreshnessRequest**, or **slice‑scoped** refresh; `FinalizeLaunchValues` (launch‑value slot filling) is performed too early (outside `U.Work` (`U.WorkEnactment`)). \n",
        "forces": "### E.18:4 - Forces\n\n| Force                                            | Tension                                                                                                                                                                    |\n| ------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **Universality vs specialization**               | One architecture must host supply chains, water networks, ML functionals, and the assignment’s “first‑principles → work” path, **without** baking in any one morphism set. |\n| **Publication neutrality vs auditability**       | Keep faces notation‑neutral and non‑mechanistic ↔ require **pins**, **ComparatorSet**, **Bridge/CL**, and **PublicationScope**.                                            |\n| **Set legality vs business pressure for totals** | Preserve **return‑sets / lawful partial orders** ↔ stakeholders demand single numbers.                                                                                     |\n| **Cross‑Context reuse vs safety**                | Enable reuse across `U.BoundedContext` ↔ enforce **Bridge/CL** with **R‑only penalties**.                                                                                  |\n| **Agility vs reproducibility**                   | Permit evolving CG‑Spec/UNM/Comparator editions ↔ require **edition pins** and **re‑emission** on change.                                                                  |\n| **Cycles vs convergence**                        | Allow Selection↔Planning iteration ↔ impose **budget** and **slice‑scoped** refresh to prevent thrash.                                                                     |\n",
        "solution": "### E.18:5 - Solution — the E.TGA kit (graph model + choreography)\n\n#### E.18::5.1 - S1 - Graph object (conceptual)\n\nDefine a **typed, editioned, directed multigraph**\n`TransductionGraph := (V, E, τ_V, τ_E, Γ_time, Bridge, CL, TransportRegistry^Φ)`\nwith:\n\n* **Vertices `V`:** instances of `U.Morphism` (open world). Common specialisations **include but are not limited to** the assignment’s set: `U.FormalSubstrate`, `U.PrincipleFrame`, `U.Mechanism`, `U.ContextNormalization (UNM)`, `U.SelectionAndTuning`, `U.WorkPlanning`, `U.Work`, `U.EvaluatingAndRefreshing`. This list is **illustrative**, not exhaustive—the graph **does not depend** on this particular set.\n* **Edges `E`:** a **single edge kind `U.Transfer`** (typed) carrying artifacts/tokens; all **plane/Context/edition** changes occur **only at nodes via `OperationalGate(profile)`** with **Bridge + CL** annotations; penalties **→ R only**. Transport conversions pin **Φ‑policies** and editions.\n* **Scopes:** `Γ_time` (budgets, horizons), `PublicationScope` for faces (E.17), and **slice ids** for refresh (G.11).\n\n **CtxState (PS‑projection; closed slots):** `CtxState = ⟨L, P, E⃗, D⟩` is the **projection of E.17 Publication Scope**.\n **Slot definitions (normative):**\n  • `L := Locus` — an element of a partially ordered **ContextSlice** poset; addresses *where* claims apply (disciplinary / organizational / holonic slice).\n  • `P := ReferencePlane` — the reference plane/units registry id; **no plane/unit declarations or translations** occur in CV; crossings remain gated (A.21).\n  • `E⃗ := Edition vector` — a **partial map** `edition_key ↦ EditionId` over named families `{CG‑Spec, ComparatorSet, UNM.TransportRegistryΦ}` and optional `{DescriptorMapRef, DistanceDefRef, CharacteristicSpaceRef}` when cited.\n  • `D := DesignRunTag` — `design(T^D)` or `run(T^R)`, used by **LaunchGate** and acceptance/telemetry duties.\n **Invariants.** Raw `U.Transfer` preserves `CtxState` (`⟨L,P,E⃗,D⟩`): it does **not** write/update any CtxState slot; any CtxState write/update (or entry to `U.WorkEnactment`) occurs at `OperationalGate(profile)`.\n **Extension discipline.** Any extra slot beyond ⟨L,P,E⃗,D⟩ **SHALL** be registered in the **E.17/LEX “CtxState Extension Registry”** with slot‑id, intent, partial‑order law (neutral/absorbing), and SquareLaw compatibility; unregistered extensions are non‑conformant.\n **Data‑shape location.** Concrete record shapes for `PathId/PathSliceId`, Γ‑pins, and lineage remain in A.22 `FlowSpec`; E.TGA fixes that **flow = valuation** and that `CtxState` is preserved across raw transfers.\n\n * **Kinds:** `U.Transduction(kind∈{Signature, Mechanism, Work, Check, StructuralReinterpretation})`.  \n  **Exact identification (no TGA‑local taxonomy):**  \n  — `Signature` **≡** **A.6.0** `U.Signature` (universal, law‑governed declaration).  \n  — `Mechanism` **≡** **A.6.1** `U.Mechanism` (law‑governed application over a SubjectKind/BaseType).  \n  — `Work` **≡** **A.15** `U.WorkEnactment` (world‑contact; `FinalizeLaunchValues` only here).  \n  — `Check` **≡** `OperationalGate(profile)` (universal **gate**; A.* patternisation pending; CC‑TGA catalog applies).  \n  — `StructuralReinterpretation` **≡** a species of **A.6.4** `U.EpistemicRetargeting` used as a graph node in E.TGA. **All retargeting semantics** (slot‑level discipline, `DescribedEntitySlot`/`GroundingHolonSlot` behaviour, invariants, Bridges, witnesses) come from **C.2.1** and **A.6.2–A.6.5**; E.TGA does **not** introduce a TGA‑local variant of retargeting.  \n  `OperationalGate ≔ U.Transduction(kind=Check)` with DecisionLog aggregation.  \n  The only extra discipline E.TGA adds for `StructuralReinterpretation` is **graph‑local**: CtxState and GateCrossing behaviour are governed by **CC‑TGA‑06‑EX** and **CC‑TGA‑11** (projection‑preserving w.r.t. `⟨L,P,E⃗,D⟩`, PathSlice‑local, and “no plane/unit change without a gate”). \n\n> **MVPK integration (import).** Every vertex with an external surface is published via **MVPK** faces (`PlainView`, `TechCard`, `AssuranceLane`, `InteropCard`) under a declared **PublicationScope** (E.17). E.TGA **reuses** MVPK’s publication laws (pins, lawful‑order discipline, “no new numeric claims / no I/O re‑listing”) and only adds graph‑level constraints in S3 and **CC‑TGA‑09/10**; it does **not** define a second, local publication semantics. \n\n**GateCrossing (normative)**\n**Definition.** A **GateCrossing** is the typed transition at a node that writes/updates any of:\n  (i) `U.BoundedContext` (**Context**), (ii) **ReferencePlane**, (iii) any member of the **Edition vector** `E⃗` (e.g., `CG‑Spec`, `ComparatorSet`, `UNM.TransportRegistryΦ`, `DescriptorMapRef`, `DistanceDefRef`, `CharacteristicSpaceRef`), (iv) **DesignRunTag** (`T^D↔T^R`), or (v) **Kind/describedEntity** (only under `StructuralReinterpretation` subject to **CC‑TGA‑06‑EX**).\n**Invariants.** Raw `U.Transfer` preserves `CtxState`; a GateCrossing occurs at exactly one `OperationalGate(profile)` (SquareLaw applies).\n**Required pins (minimum).** `BridgeCard + UTS row`; `CL` for scope bridges; `CL^plane` for plane crossings; `CL^k` with `bridgeChannel=Kind` for kind transitions; `PublicationScopeId`; `PathSliceId`; Γ‑pins on compare/launch faces.\n**Canonical reference.** `CrossingRef := ⟨GateId, channel, from, to, UTS.RowId, PathSliceId⟩`. Any DecisionLog entry whose rationale depends on a crossing **SHALL** cite `CrossingRef`.\n**CrossingSurface (normative)**\n**Definition.** A **CrossingSurface** is the published bundle that makes a GateCrossing **auditable and replayable** (crossing visibility). It includes:\n* the canonical **`CrossingRef`**;\n* the matching **UTS row** (**`UTS.RowId`**) for the crossing;\n* the required pins **`PublicationScopeId`** and **`PathSliceId`**;\n* where a Bridge is involved: the **BridgeCard** (F.9) and its disclosed fields (`BridgeId`, `bridgeChannel`, **CL** and loss notes; **`CL^k`** when `bridgeChannel=Kind`; **`ReferencePlane(src,tgt)`**);\n* where planes differ: **`CL^plane`** and the active **`Φ_plane`** as a **`PolicyIdRef`** (policy-id + resolvable refs; F.8:8.1);\n* the active penalty policy identifiers **`Φ(CL)`** (and **`Ψ(CL^k)`** if used) as **`PolicyIdRef`** bundles (policy-id + `PolicySpecRef` + `MintDecisionRef?`; F.8:8.1);\n* any additional pins mandated by the active **GateProfile** / GateChecks (A.21) for this crossing.\n\n**Obligation.** Every **GateCrossing MUST publish its CrossingSurface**. Missing or non‑conformant CrossingSurface is a **blocking** defect for downstream consumption (selectors, acceptance, audits).\n\n**Term separation.** **Transfer** denotes the sole edge kind `U.Transfer` (graph edges). **Transport** denotes Φ‑governed conversion **policies/registries** (**`TransportRegistry^Φ`** under UNM). Wording “reuse via Transport” refers to registries/policies, not to an additional graph edge.\n\n#### E.18:5.2 - S2 - Flows as valuations (paths + state + guards)\n* A **Flow** is a **valuation** `ν` over `U.Transfer` edges and cut‑sets, paired with an **admissible path** `p = v₀ → … → v_k`. The valuation assigns tokens/states under `CtxState` and records publication events under a declared `PublicationScopeId`. **The concrete pins and identifiers (`PathId`, `PathSliceId`, Γ_time on compare/launch faces) are specified in A.22 `FlowSpec` and A.25 `Sentinel & SubFlow`.** This reflects the “graph ≠ flow” norm (flow = valuation), with gates placed exactly on GateCrossings.  \n* **Admissible path (definition).** A path `p` is **admissible** iff:  \n  (a) node/edge types match the declared `τ_V, τ_E`;  \n  (b) any write/update to any member of `⟨L,P,E⃗,D⟩` (or kind‑retargeting under `StructuralReinterpretation`) appears at **exactly one** `OperationalGate(profile)`;  \n  (c) each GateCrossing on `p` has a **SquareLaw witness** (CC‑TGA‑23) and, where applicable, a **SquareLaw‑retargeting witness** (CC‑TGA‑06‑EX);  \n  (d) no hidden crossings occur across raw transfers;  \n  (e) Γ‑pins are present on compare/launch faces;  \n  (f) `T^D↔T^R` occurs **only** at `LaunchGate`.\n\n* `U.Transfer` preserves `CtxState` (`⟨L,P,E⃗,D⟩`) and carries **Assurance‑operations** only (see S3b); any crossing of locus/plane/editions or `T^D↔T^R` is placed at `OperationalGate(profile)`.\n* A **PathSlice** is a **slice‑scoped execution window** used for refresh/telemetry; faces pin `PathSliceId`; **re‑emission** happens when any pinned edition changes or `SliceRefresh` is triggered by sentinel rules.\n\n> **Consequences.** The assignment’s “reference flow” is simply one `p` in `TransductionGraph`. Other domains (supply chain, water network, NN functional) instantiate different `p` on the **same architecture**.\n> \n**Why \"flow = valuation\" doesn't kill the \"something is flowing\" intuition**\nThere are two complementary perspectives:\n* **Lagrangian (intuitive):** \"water particles\" run through pipes; you \"track\" tokens.\n* **Eulerian (architectural):** you define a **function on edges** (\"how much/what passes through each edge under a given regime\"), with gate laws. E.TGA deliberately fixes the **Eulerian semantics of flow** at the architectural level: \"flow (= valuation) + publication log\", while the dynamics of \"movement\" show up as **re-valuation** over a **PathSlice** (the execution/republishing window) under gate rules and the SquareLaw. This yields comparability, reproducibility, and slice-local refresh.\n\n#### E.18:5.3 - S3 - Publication discipline (faces)\n\nE.TGA **imports E.17** wholesale **and associates MVPK faces with `PublicationScope` (USM)**.  \n**MVPK remains the normative source** for:\n* the set of face kinds (`PlainView`, `TechCard`, `InteropCard`, `AssuranceLane`),\n* pin discipline and Publication Characteristics (PC),\n* “no new numeric claims / no I/O re‑listing / no Γ‑semantics on faces”.\n\nE.TGA **does not re‑specify** these laws; it only adds **graph‑level obligations** for faces emitted over transduction paths:\n\n1. **Crossings on faces.** When a face participates in a GateCrossing (S1.b/S9), it **SHALL** cite `BridgeId + UTS row + CL` and publish **Φ(CL)/Φ_plane RuleId**; **penalties remain in R‑lane**.\n2. **Gate‑requirement on cited editions.** Any face that references editions of `CG‑Spec` / `ComparatorSet` / `UNM.TransportRegistryΦ` includes **`BridgeCard + UTS row`**; faces without this are treated as **non‑consumable downstream**.  (delegated tests → A.27/A.34)  \n3. **ComparatorSet & set returns (graph‑scope).** Any `ComparatorSet` and `SetSemanticsRef` used along a transduction path **SHALL** carry **edition identifiers**; flows **re‑emit** faces on edition change; faces with comparison **return sets / lawful partial orders** (no hidden scalarization), reusing MVPK’s lawful‑order discipline.\n4. **Γ_time on compare/launch faces.** All compare/launch faces on E.TGA paths pin `Γ_time`; implicit *latest* is illegal. The **shape and evaluation** of `Γ_time` live in A.26; E.TGA only mandates presence. **CHR avoids acceptance thresholds** (*NoThresholdsInCHR*); thresholding and launches surface in G‑patterns and `U.Work`.  (delegated tests → A.32/A.33). **Unknowns remain tri‑state (`pass|degrade|abstain`) and fold per GateProfile (A.21/A.26).**  \n\n> **Reminder.** MVPK already bans “signature” on faces, I/O re‑listing, arithmetic on faces, and unpinned numeric content (E.17 §5.4–5.5). E.TGA **does not weaken or override** those rules; it only constrains how they are used along transduction paths.\n\n**Lean publish‑mode (AssuranceLane‑Lite).** Lean affects **faces only** (`PlainView`/`AssuranceLane` minimal), not checks; publication shows `GateProfile`, `GateCheckRef[]`, and `DecisionLogRef`; the underlying GateChecks list remains unchanged.\n\n**Decision stability & idempotency (delegated).** Gate decisions are **idempotent** under a congruence relation over inputs; the **witness and equivalence criteria** are specified in **A.41 DecisionLog**. E.TGA **does not** prescribe storage formats, key shapes, or hashing schemes.\n\n**KindBridge admissibility (publication).**  \nTreat a step as a **describedEntity/kind** transition (including `StructuralReinterpretation` under CC‑TGA‑06‑EX) **iff** the **UTS row**:\n  — satisfies the **minimal Bridge row** obligations of A.27 (identity, `ReferencePlane`, `CL/CL^plane`, edition‑pins for `CG‑Spec` / `ComparatorSet` / `UNM.TransportRegistryΦ`, `ComparatorSetRef`, `BridgeId`, `Φ‑RuleIds`), and  \n  — is additionally marked as a **KindBridge** per C.3 (`bridgeChannel=Kind`, `CL^k`, mapping or signature‑translation, order‑preservation claims, loss notes, definedness area, determinism).  \nOtherwise this KindBridge explanation does not apply (the step falls back to a gated crossing). When the gate owns the crossing, `CrossingRef` is surfaced and linked from the `DecisionLog`.\n\n#### E.18:5.4 - S4 - Assurance‑operations on `U.Transfer` (counterfactual admissibility)\nOn `U.Transfer` edges, an operation is interpreted as a **declarative assurance‑operation** **iff** it is one of  \n`ConstrainTo(rule)` - `CalibrateTo(map|standard)` - `CiteEvidence(anchor)` - `AttributeTo(agent|role)`; otherwise this explanation does not apply.\nUnder this interpretation, `CtxState⟨L,P,E⃗,D⟩` is preserved.  \nIf an effect entails a plane/unit change, the assurance‑operations explanation does not apply and the step is handled as a gated crossing (`OperationalGate(profile)+Bridge+UTS`).  \nIf Φ assigns penalties, they appear in the R‑lane; otherwise no penalties are surfaced here.\n\n#### E.18:6.5 - S5 - Comparability & aggregation (normalize‑then‑compare; counterfactual form)\n\nThe comparison explanation applies under the following admissibility conditions:\n\n* If a path segment intends to compare/aggregate, it is admissible as a comparison **only when** UNM precedes it; UNM is **method‑independent**, publishes **TransportRegistry^Φ** and **CG‑Spec** anchors, and faces cite those editions; otherwise this comparison explanation does not apply.\n* If the comparator defines a **lawful partial order**, then returns are **sets/archives** (Pareto/Archive); if a **total order** is declared, it is the one provided by the comparator; otherwise set semantics apply and covert scalarization is out of scope here.\n* If a claim is **ordinal‑only**, then only comparisons are surfaced; arithmetic transforms (e.g., means/z‑scores) are out of scope of this explanation and belong to declared comparators or downstream policy.\n\n**Edition‑aware artifacts (e.g., QD archives) MUST pin `DescriptorMapRef.edition` / `DistanceDefRef.edition` (and `CharacteristicSpaceRef.edition` when applicable); refresh is slice‑local.**  (delegated tests → A.34/A.37)  \n\n#### E.18:5.6 - S6 - Cycle discipline (Selection ↔ Planning)\n\n* The architecture centers the loop between `U.SelectionAndTuning` and `U.WorkPlanning`.\n* The loop operates under a local **budget / max_iter** in `Γ_time`; at expiry, the selector emits the **current `CandidateSet`** and **`MethodTuning`** with a **partial‑optimality** flag; further improvement rolls into the **next `PathSlice`**.\n* **UNM occurs before the loop**; if measurements are missing/stale, UNM emits a **FreshnessRequest** which is **planned** in `U.WorkPlanning` and **executed** in `U.Work`. Transfers, units, and calibrations are surfaced publication‑wise as `CalibrateTo(map|standard)` and pinned to `TransportRegistry^Φ` (**R‑channel only** for penalties).\n* **WorkEnactment is the only site for launch‑value slot filling** (`FinalizeLaunchValues / FinalizeLaunchValuesOnlyInWork`). \n> **Refresh orchestration.** Telemetry from `U.WorkEnactment` and publications are **slice‑scoped**, editions re‑pinned, faces **re‑emitted**. \n\n#### E.18:5.7 - S7 - Selector semantics (G.5) & parity harness (G.9)\n\n* **Selectors return sets.** Default **DominanceRegime** is `ParetoOnly`; **IlluminationSummary** (telemetry summary) and any coverage/regret (telemetry metrics) are **report‑only telemetry** (reported), excluded from dominance **unless** a CAL policy promotes them (policy‑id in SCR).\n\nIf `PortfolioMode=Archive`, a **QD archive** may be returned; when generation is in scope, pairs `{environment, method}` are managed under declared **EnvironmentValidityRegion** and **TransferRulesRef**; parity artefacts and `PathSliceId` are pinned on publication. Details of comparator semantics and archive pinning live in **A.28/A.34**.\n\n#### E.18:5.8 - S8 - Guard ownership and handling (USM §1.2)\n* **USM.CompareGuard**/**USM.LaunchGuard** **publish `GuardOwnerGateId`**. Guard failures are **events** aggregated by the owner gate (not GateChecks).\n* **Ownership rules:** (i) `USM.LaunchGuard.owner = LaunchGateId(U.WorkEnactment)`; (ii) inside a Subflow, `USM.CompareGuard.owner = OperationalGate(InSentinel)`; Join‑nodes cannot own guard pins.\n\n**GateProfile data shape (cross‑reference).** The **entire data shape** (SoD/quorum, declassify, budgets, TOCTOU/freshness windows, editions vector, scopes) is **specified in A.26**. E.TGA **only names** the structure and defers its fields to A.26.\n\n**Bridge‑aware guards (cross‑reference).** USM guards apply bridge‑translation semantics (`translate(Bridge, Scope)`) with CL penalties in R‑lane; the conceptual macro is defined in **A.24 USM.Guards**.\n\n**Error/timeout/unknown (profile‑bound).** GateCheck errors/timeouts fold to **`degrade`** under `Lean|Core` and to **`block`** under `SafetyCritical|RegulatedX`; `unknown` follows the GateCheck’s intensional rule (safety‑default: `degrade`). **The DecisionLog shape and the idempotency witness are defined in A.41; E.TGA does not define storage or key structures.**  \n\n#### E.18:5.9 - S9 - Transport & crossings\n* Cross‑Context or cross‑plane edges appear as **GateCrossings** that include a **Bridge** with **CL** policy; **Φ(CL)/Φ_plane** are published; penalties route **to R only**; **Scope membership** (USM) is unchanged by crossings. **SquareLaw is checked within a single `DesignRunTag`; a `T^D↔T^R` change is modelled as a pair of coordinated gates with `DesignRunTagFrom/To` and an external enactor (see A.29).** \n* When *describedEntity/kind* changes across a boundary, declare an explicit **KindBridge (`CL^k`)** in addition to plane/context CL; cross‑context reuse of UNM **must** go via `Transport`, with any `CL^plane` penalties routed to **R‑lane** only.\n\n#### E.18:5.10 - S10 - Non‑mechanism boundary\n\n* Publication is a **typed projection**, not execution. Any build/render/upload is **Work on carriers**; **no Γ‑semantics** may leak into faces. \n\n#### E.18:5.11 - S11 - Coordination thread (optional)\nIntroduce **CoordinationFlow** as a named thread laid over `U.TransductionFlow__P2W`; crossings with production flow go via **Bridge+UTS**; coordination publishes **LexicalView** labels only and adds **no checks** or mechanisms.\n\n#### E.18:5.12 - S12 - Viewpoint families → E.TGA constructs (neutral, holonic)\n\nE.TGA does not mint new viewpoint or view kinds. It **imports** the generic multi‑view machinery of E.17.0 `U.MultiViewDescribing`, bundles from E.17.1, and the TEVB engineering bundle from E.17.2. S12 only describes how these existing `U.Viewpoint` / `U.ViewpointBundle` ids are *used* in transduction graphs and in `UTS.ViewpointMap`; intent/concern semantics live in E.17.0–E.17.2.\n\n**Two‑layer use of TEVB and MVPK (ISO 42010 summary, no local re‑definition).**\n\n* **Engineering viewpoints.** For engineering holons, E.TGA assumes a TEVB bundle with `ViewFamilyId = VF.TEVB.ENG`. `EngineeringVPId` is one of `{VP.Functional, VP.Procedural, VP.RoleEnactor, VP.ModuleInterface}`, and TEVB is the normative source for their semantics. E.TGA does not refine these viewpoints.  \n* **Publication viewpoints.** Publication viewpoints come from MVPK (E.17); `PublicationVPId` is a `MVPK.ViewpointId` that governs faces under a `PublicationScope`.  \n* **Architecture description.** Under ISO 42010, an architecture description for a holon is: (i) an E.TGA transduction graph over that holon, plus (ii) MVPK faces emitted for its morphisms, with correspondences per E.17.0 linking each face to the engineering view(s) it implements. Crossings and penalties follow E.TGA’s gating rules (S9; CC‑TGA‑11/23) but do not change viewpoint semantics.  \n* **Separation of roles.** `VP.*` from TEVB are **EngineeringVPId** values only; they are not surfaces. `PublicationVPId` values live in MVPK. The mapping between them is entirely via ISO‑style correspondences and the `UTS.ViewpointMap`; E.TGA does not define a second notion of viewpoint.\n\n**Entities‑of‑interest (summary).**\n\n* **EoI‑ENG.** The engineering entity described by TEVB/E.TGA is a holon (`U.System` or `U.Episteme`) per TEVB’s `EoIClassSpec`. E.TGA does not broaden or narrow this set.  \n* **EoI‑PUB.** MVPK may treat the *architecture description* itself as an entity‑of‑interest; publication viewpoints for that AD are defined in MVPK, not here. E.TGA only requires that such faces honour MVPK discipline and E.TGA’s crossing rules.\n\n**Naming rules (aligned with E.17.0/E.17.1/E.17.2).**  \n* `ViewFamilyId` is the `U.ViewpointBundle.viewFamilyId` (e.g. `VF.TEVB.ENG` for TEVB); its lexical and ontological discipline is governed by E.17.1.  \n* `EngineeringVPId : ViewpointId` is always a `U.ViewpointId` drawn from some bundle (for TEVB, one of `{VP.Functional, VP.Procedural, VP.RoleEnactor, VP.ModuleInterface}`). E.TGA never defines new `VP.*` ids.  \n* `PublicationVPId : ViewpointId` is a `MVPK.ViewpointId` defined in E.17; TEVB viewpoints are **never** reused as publication viewpoints (per TEVB guard and MVPK).  \n* The legacy unqualified column name `ViewpointId` MUST NOT be used. Where it exists, it is interpreted as `PublicationVPId` and is DEPRECATED (sunset when E.23 is published).\n\n**Terminology guards (no local semantics).**\n* Within S12, “viewpoint”, “view” and “correspondence” have exactly the meanings given in E.17.0; “publication surface” means an MVPK face (`PlainView`, `TechCard`, `InteropCard`, `AssuranceLane`) under some `PublicationVPId`.  \n* Faces are **carriers for views**: a face is part of a view only when linked via an ISO‑style `CorrespondenceRef` to an engineering `U.View` under some `EngineeringVPId`; S12 does not add extra conditions beyond E.17.0/E.17.2.  \n* Labels such as “Functional view”, “Procedural view”, “Role‑Enactor view”, “Module‑Interface view” in this section are lexical aliases for TEVB viewpoints; they MUST NOT be interpreted as extra viewpoint kinds or as surface types.\n\n**Purpose.** Provide a neutral (F.18) mapping from TEVB engineering *viewpoint families* — bundle `VF.TEVB.ENG` with `VP.Functional / VP.Procedural / VP.RoleEnactor / VP.ModuleInterface` — to E.TGA constructs so that the same holon can be described functionally, procedurally, structurally, or as a module‑and‑interface architecture **without changing the underlying graph**. S12 does not introduce new `U.Viewpoint` or `U.View` kinds; it reuses those defined in E.17.0/E.17.2.\n\n**Holon target.** The mapping applies to any holon, with the constraint that only `U.System` enacts `U.Work` (A.3/A.15). Supervisory and structural hierarchies remain distinct (B.2.5).\n\n**Viewpoint family → primary E.TGA constructs (TEVB‑aligned)**  \n*All four families referenced below are TEVB engineering viewpoints; the “what …” clauses are interpretive glosses for how they *use* E.TGA constructs. Formal intent/concerns/allowed episteme kinds remain in TEVB (E.17.2).*\n1) **Function‑Oriented View (`EngineeringVPId = VP.Functional`, capability‑flow)** — “what transformation is achieved under roles”\n    * **Flow substrate:** `U.TransductionFlow__P2W` through nodes `SubstrateFormalization → OntologyAuthoring → CHRAuthoring → PrincipleFraming → MechanismRealization → UNM.Usage (ContextNormalization) → SelectionAndTuning ↔ WorkPlanning → WorkEnactment → EvaluatingAndRefreshing`.\n    * **Publication:** MVPK publication surfaces per E.17; comparable claims pin to `CG‑Spec/ComparatorSet` editions; crossings surface via `Bridge+UTS` and `CL/CL^plane` (penalties → **R‑lane** only). \n    * **Checks:** A.20 (CV) inside transformations; A.21 (GateFit) at gates; enforce CSLC/No‑Hidden‑Scalarization per A.28. \n    *  **Holonic note:** `U.Episteme` does not *act*; it is used by systems acting on carriers; `U.Work` appears only for `U.System`. \n2) **Procedure‑Oriented View (`EngineeringVPId = VP.Procedural`, step/time storyboard)** — “what steps occur and when”\n    * **Artifacts:** `U.WorkPlan` (A.15.2) for intent/schedule; `U.WorkEnactment` for enactment.\n    * **Boundary:** entry into `U.WorkEnactment` is via `OperationalGate(profile)` with `USM.LaunchGuard`; `DesignRunTag` separates design time from run time; `DesignRunTagFrom/To` appear only at gates. \n    * **Holonic note:** Applies to any `U.System` scope (single holon or a supervised sub‑holon cluster); supervisory layering is handled by roles rather than structural mereology (B.2.5).\n3) **Role‑Enactor / Device‑Structure View (`EngineeringVPId = VP.RoleEnactor`)** — “what carrier/ports/constraints exist; who typically enacts it”\n    * **Artifacts:** Module *interfaces* are `Signature` nodes; module realizations are `MechanismRealization` nodes; inter‑module dependencies traverse `U.Transfer`, with gates on crossings. \n    * **Publication:** MVPK faces are **typed projections**, not executable artifacts; faces add **no new numeric claims** (E.17). Constraints and compatibility appear as CV checks (A.20). \n    * **Holonic note:** Structural mereology (part/whole of the carrier) is modeled in Part A; E.TGA ties interface/exposure semantics to morphisms and gates.\n    * **Device‑View reading (Transduction↔Transductor).** The same capability‑flow MAY be read as a **device** that performs the transduction (**transductor**) without changing the graph: model with `Signature` + `Mechanism` only; do **not** introduce extra edge kinds. If describedEntity retargets (function↔element), use `StructuralReinterpretation` with a **`KindBridge (CL^k)`** on **UTS** and a **SquareLaw‑Retargeting witness**; preserve `⟨L,P,E⃗,D⟩` and treat it as a non‑crossing (**CC‑TGA‑06‑EX**; witness shape §4.7).  \n    * **Role‑label guard.** `TypicalEnactorRoleName` is **pedagogical only** and MUST NOT be used as a GateFit role; GateFit uses `U.Role` (A.21).\n4) **Module‑Interface View (`EngineeringVPId = VP.ModuleInterface`, physical/logical architecture)** — “what modules exist and how they contract across interfaces”\n    * **Artifacts:** Module *interfaces* are `Signature` nodes; module realizations are `Mechanism` nodes; inter‑module dependencies traverse `U.Transfer`, with gates on crossings. \n    * **describedEntity note:** Functional↔element reinterpretation follows the **Device‑View reading** rule above (Role‑Enactor family) and **CC‑TGA‑06‑EX**; see **§4.7** for the retargeting witness shape and CV witness linkage.\n    * **Holonic note:** The same module may appear as a holon in multiple views; supervisory loops (B.2.5) remain orthogonal to structural composition.\nThis is an expandable list of viewpoint families; TGA is intentionally viewpoint‑neutral. Additional engineering bundles beyond TEVB (safety, mission, information, …) are introduced as separate `U.ViewpointBundle` species via E.17.1/E.17.2; S12 does not define them.\n\n**Alias families for transduction species (LEX‑only).**\n*Scope.* Authors MAY declare `AliasesInViewFamilies[]` for `U.Transduction` species so readers can recognise familiar engineering view families. All semantics come from the referenced bundles (typically TEVB) and MVPK; aliases are purely lexical.\n\n*Norms.*\n1. Each `U.Transduction` species MAY publish `AliasesInViewFamilies[]` — an open list of records  \n   `{ ViewFamilyId, EngineeringVPId?, Alias : TechASCII }`.  \n   * If `ViewFamilyId = VF.TEVB.ENG`, then `EngineeringVPId` MUST be one of `{VP.Functional, VP.Procedural, VP.RoleEnactor, VP.ModuleInterface}` (TEVB; CC‑TEVB‑1/6).  \n   * Other `ViewFamilyId` values MUST denote `U.ViewpointBundle` instances defined elsewhere (e.g. safety/assurance/information bundles), not ad‑hoc local families.\n2. Aliases are LEX‑only: **no arithmetic, no new claims, no check participation, no `CtxState` slot writes/updates (incl. `DesignRunTag`)**. They do not create MVPK faces.  \n3. Aliases MUST NOT be used as `PublicationVPId`; publication viewpoints remain in MVPK.  \n4. Twin registers are allowed (Tech/Plain) per E.10; naming follows F.18 local‑first discipline.  \n5. Do not name transductions by operands/effects (operation ≠ operand).  \n6. `TypicalEnactorRoleName` MAY be added for pedagogy; it SHALL NOT be used as a GateFit role (GateFit uses `U.Role` only).  \n7. Morphology: ASCII TitleCase; conjunctions via `And`; for composite actions use `XingAndYing` (or `XAndYing` if grammar requires).  \n8. The P2W reference species table (SubstrateFormalization … EvaluatingAndRefreshing with functional/procedural aliases and `TypicalEnactorRoleName`) is **informative** and does not change kind or viewpoint semantics.\n\n**Deliverable — `UTS.ViewpointMap` (normative, TEVB‑aligned).**  \nPublish a UTS block named `ViewpointMap` that ties engineering viewpoints (from bundles such as TEVB) to E.TGA constructs and MVPK faces.\n\n*Minimum row schema (per row).*\n* `ViewFamilyId` — `U.ViewpointBundle.viewFamilyId` (e.g. `VF.TEVB.ENG` for TEVB, or another bundle id).  \n* `EngineeringVPId : ViewpointId` — a viewpoint from that bundle (for TEVB, one of `{VP.Functional, VP.Procedural, VP.RoleEnactor, VP.ModuleInterface}`).  \n* `PublicationVPId : ViewpointId?` — MVPK publication viewpoint id that governs faces implementing this engineering view (optional if not publishing).  \n* `TargetHolon ∈ {U.System, U.Episteme}` *(extended species may add `{U.ServiceClause|U.MethodFamily}`; if `TargetHolon ≠ U.System`, no `U.Work` enactment appears).*  \n* `PrimaryTGAConstructs` — nodes/edges/gates actually used for this `(ViewFamilyId, EngineeringVPId, TargetHolon)` (typically one of the four families above).  \n* `Crossings{BridgeId, CL/CL^plane?}` — crossings involved; penalties route to R‑lane only.  \n* `EditionPins{…}` whenever comparable claims appear (bind to CG‑Spec/ComparatorSet editions; any face citing editions includes `BridgeCard + UTS` row per MVPK/UNM).  \n* `SenseCells[]` (≥ 2 per row), each citing Context name + edition (F.17/E.10 discipline; UTS‑wide coverage rules still apply).  \n* *(REQUIRED when publishing)* `CorrespondenceRef[]` — ISO 42010 correspondences linking emitted faces to the engineering view(s) they implement; may cross architecture descriptions.  \n* *(RECOMMENDED)* `ConcernsCovered[]` — ISO 42010 stakeholder concerns addressed by this row via GateProfiles/check catalogues.\n\n**Conformance (S12‑scoped).**  \n(i) `UTS.ViewpointMap` exists.  \n(ii) For each holon that claims TEVB alignment, there are ≥ 4 rows whose `{ViewFamilyId, EngineeringVPId}` cover `{VF.TEVB.ENG × {VP.Functional, VP.Procedural, VP.RoleEnactor, VP.ModuleInterface}}` (per CC‑TEVB‑1/6).  \n(iii) Rows that surface editions also include `BridgeCard + UTS` rows per A.27; edition‑bearing faces that lack such rows MUST NOT be used for downstream consumption.  \n(iv) Each row has ≥ 2 `SenseCells` and the sheet meets global UTS coverage rules.  \n(v) Any `TargetHolon = U.System` that reaches `U.Work` shows `LaunchGate` with `DesignRunTag` consistency.  \n(vi) Crossings referenced in `ViewpointMap` follow CC‑TGA‑11; comparability along the mapped paths follows CC‑TGA‑10.  \n(vii) Rows MUST NOT use an unqualified `ViewpointId`; they MUST use `EngineeringVPId` and/or `PublicationVPId` explicitly.  \n(viii) When faces are published, `CorrespondenceRef[]` MUST be present and resolvable to `U.Viewpoint` ids.  \n(ix) Additional bundles (e.g. assurance, information, mission) MAY appear as extra `ViewFamilyId` values but MUST be declared as `U.ViewpointBundle` species; they do not extend `VF.TEVB.ENG`.\n",
        "archetypal_grounding": "### E.18:6 - Archetypal Grounding (Tell–Show–Show; concise)\n\n*Show‑A (Supply chain).* Nodes: procurement → inbound QC (UNM) → selection (supplier set; lawful order) ↔ planning (lotting/schedule; budget) → execution (receipts; **WorkEnactment enacts (world‑contact)**) → refresh (quality telemetry; re‑emit faces). Crossings: vendor Context via **Bridge/CL**; penalties **→ R only**; comparators pinned to CG‑Spec edition. \n\n*Show‑B (Neural‑net functional).* Nodes: formal substrate (typed tensor ops) → mechanism (combinator algebra) → UNM (dataset normalization; **TransportRegistry^Φ**) → selection (architecture/hyperparam set; Pareto set over accuracy@ratio & FLOPs@ratio) ↔ planning (compute budget horizon) → Work (training runs; Δ anchored) → refresh (parity inserts; slice‑scoped). Faces pin **DescriptorMapRef.edition / DistanceDefRef.edition** when QD metrics are shown; illumination remains a **report-only telemetry metric** by default. \n\n> *Post‑2015 SoTA echoes (illustrative):* **TAMP/MPC**, **MAP‑Elites / QD (incl. CMA‑ME)**, **refinement‑typed stacks**, **profunctor optics**. **Worked‑examples and Tell–Show–Show vignettes move to A.31/A.34/A.37; E.TGA keeps only the carcass‑level alignment.**\n",
        "conformance_—_**unified_checklist_(normative)**": "### E.18:7 - Conformance — **Unified checklist (normative)**\n\n| ID | Requirement | Practical test |\n|----|-------------|----------------|\n| **CC‑TGA‑01 — Single edge kind** | The graph uses exactly one edge kind `U.Transfer`; all plane/Context/edition transitions occur only at nodes via `OperationalGate(profile)`. | Model lint finds no auxiliary edge kinds for unit/plane changes; crossings sit on declared gates. |\n| **CC‑TGA‑02 — Nodes are morphisms** | Nodes are intensional `U.Transduction(kind∈{Signature,Mechanism,Work,Check,StructuralReinterpretation})`. This enumeration is a **minimal roles baseline**. **Domain‑specific species are open‑world** and non‑exhaustive; they bind to one of these kinds. Adding a **new kind** requires an explicit E.TGA update. `StructuralReinterpretation` nodes are **projection‑preserving** (no mutation of `⟨L,P,E⃗,D⟩`) and carry CV/GF obligations per A.20/A.21/A.45. **Mapping to A.\\*** (normative): the enumeration is **not** a TGA‑local taxonomy; each `kind` is identified 1‑to‑1 with its A.\\* anchor: `Signature→A.6.0`, `Mechanism→A.6.1`, `Work→A.15`, `Check→OperationalGate` (until a dedicated A.\\* pattern is published). **Disambiguation:** `Signature (kind)` ≠ `KindSignature` (C.3.2) and ≠ `A.6.A Architheory Signature` view. | Type registry shows at least the listed kinds; additional species map to one of them; checks realized as `OperationalGate` (see CC‑TGA‑06‑EX/11). **Lint:** registry/table exposes `{species → {kind, KindDefinition}}`; missing or mismatched `KindDefinition` fails. |\n| **CC‑TGA‑03 — Identity, composition, functorial faces** | Identities exist; path composition associative; publication is functorial: `Emit_s(t₂∘t₁)=Emit_s(t₂)∘Emit_s(t₁)`. | Pick two‑step path; MVPK faces commute (Square witness). |\n| **CC‑TGA‑04 — Graph spec** | Spec declares `τ_V, τ_E`, `Γ_time`, Transport/Bridge registries. | Spec file shows typed registries and Γ policy. |\n| **CC‑TGA‑05 — CtxState pins** | `CtxState=⟨L,P,E⃗,D⟩` is pinned on ports/tokens; raw `U.Transfer` does **not** write/update it. | Along a raw transfer, ⟨L,P,E⃗,D⟩ is preserved. |\n| **CC‑TGA‑06 — Operational gates only** | Any write/update to any member of ⟨L,P,E⃗,D⟩ or entry into `U.WorkEnactment` is mediated by `OperationalGate(profile)` with aggregated `DecisionLog`. | Diff CtxState across edges; if any member differs, exactly one gate exists with DecisionLog. |\n| **CC‑TGA‑06‑EX (strictly limited) — Projection retargeting without gate** | A node of kind **`StructuralReinterpretation`** MAY retarget the **published projection** without invoking `OperationalGate` **only if all hold**: **(a)** `⟨L,P,E⃗,D⟩` is preserved; **(b)** any **describedEntity** change has a **KindBridge** (`CL^k`) entry on MVPK/**UTS**; **(c)** a **SquareLaw‑retargeting witness** is present (on UTS); **(d)** the operation is **PathSlice‑local** (`PathSliceId` pinned); **(e)** **no plane/unit change** occurs (plane/unit changes remain gated); **(f)** **CV.ReinterpretationEquivalence** (A.20) is `pass`; **(g)** **NoHiddenScalarization** — if the step concerns a comparable return shape, set/partial‑order semantics are preserved and comparators remain ref‑only (cf. A.28). | UTS row includes `bridgeChannel=Kind` and `CL^k`; SquareLaw‑retargeting witness present; PathSliceId pinned; CV status recorded; no scalarization detected. |\n| **CC‑TGA‑07 — CV⇒GF activation predicate** | Until **aggregated `ConstraintValidity` = `pass`**, all **GateFit** checks return `abstain`. | Simulate CV failure ⇒ GateFit `abstain`. |\n| **CC‑TGA‑08 — LaunchGate discipline (incl. pre‑run barrier)** | Each `U.WorkEnactment` has exactly one `LaunchGate` owning `USM.LaunchGuard`; **mandatory** checks: `FreshnessUpToDate`, `DesignRunTagConsistency`. If preceding step’s CV ≠ `pass`, LaunchGate decision is `block` (cause logged). | Owner resolution `GuardOwnerGateId = LaunchGateId(U.WorkEnactment)`; CV≠pass ⇒ `block` with log. |\n| **CC‑TGA‑09 — MVPK publication discipline** | Every surfaced node uses MVPK; faces carry `PublicationScopeId`, presence‑pins, **edition ids**, Γ pins; **no I/O duplication** or arithmetic; faces add no new numeric claims. | Cards show `PublicationScopeId`; pins present; no “signature”/math on faces. |\n| **CC‑TGA‑10 — Normalize→Compare (CSLC)** | Any comparison cites **UNM/CG‑Spec** editions and **ComparatorSetRef**; ordinal claims are compare‑only; partial orders return sets; edition‑aware artifacts (QD/archives) pin `{DescriptorMapRef, DistanceDefRef, CharacteristicSpaceRef?}.edition`; **any face citing editions includes `BridgeCard + UTS row`**. **NoHiddenScalarization — detection criteria:** (1) return shape is **set/poset**, not scalar; (2) `ComparatorSetRef` is present and edition‑pinned; (3) MVPK faces add **no new numeric claims**; (4) any summarisation is **order‑preserving & set‑valued**; otherwise conformance fails. | Faces show comparator pins; archive pins present; linter rejects edition cites without UTS; scalarisation checks pass.\n| **CC‑TGA‑11 — Crossings gated** | Cross‑Context/plane crossings publish **BridgeId + UTS + CL/CL^plane** and are mediated by `OperationalGate(profile)`; **Φ/Φ_plane penalties → R‑lane only**; describedEntity change publishes **KindBridge (CL^k)**. **Exception (StructuralReinterpretation):** a **projection‑only** describedEntity retargeting is surfaced **without** a gate **iff** **CC‑TGA‑06‑EX** holds; then the UTS row includes `bridgeChannel=Kind`, `CL^k`, and a **retargeting witness**; any plane/unit change falls back to a gated crossing; `PathSliceId` is pinned; UNM reuse cross‑context continues via `Transport`. | Crossing surfaces show Bridge/UTS/CL pins; penalties routing audited. |\n| **CC‑TGA‑12 — Set‑returning selection** | `U.SelectionAndTuning` returns sets/archives under declared comparators (`ParetoOnly` by default) — no covert scalarization. | Selector output is a set/archive; policy id present if escalated. |\n| **CC‑TGA‑13 — Budgeted Selection↔Planning loop** | The loop declares **budget / max_iter**; on expiry selector publishes partial‑optimal set + `MethodTuning`; next **PathSlice** scheduled. | Logs show budget stop and slice rollover. |\n| **CC‑TGA‑14 — UNM before loop & Freshness lifecycle** | UNM runs before selection; stale/missing inputs produce **FreshnessTicket/FreshnessRequest** planned in `WorkPlanning` and executed in `WorkEnactment`; calibrations appear as `CalibrateTo(map|standard)` with Φ pins. | Ticket state machine Issued→Planned→Executed→Closed; calibrations pinned. |\n| **CC‑TGA‑15 — FinalizeLaunchValues only in WorkEnactment** | Only `U.WorkEnactment` performs `FinalizeLaunchValues` and fills launch‑value slots. | Any earlier attempt blocks at LaunchGate; a `FinalizeLaunchValues` witness is present in Work. |\n| **CC‑TGA‑16 — Guard ownership & semantics** | `USM.CompareGuard`/`USM.LaunchGuard` publish owner gate; guards are **events**, not GateChecks; failures are aggregated by owner’s gate per profile. | Guard pins show owner; GuardFail routed to owner’s DecisionLog. |\n| **CC‑TGA‑17 — Assurance ops on Transfer** | On `U.Transfer` only `ConstrainTo/CalibrateTo/CiteEvidence/AttributeTo`; none write/update `⟨L,P,E⃗,D⟩`. | Edge audit shows ops; CtxState unchanged across the edge. |\n| **CC‑TGA‑17a — Assurance ops contracts (normative)** | **ConstrainTo(region|policy)**: tightens declared region/policy; **pre**: region⊆current; **post**: `⟨L,P,E⃗,D⟩` unchanged; **idem.** and **monotone** under composition. **CalibrateTo(map|standard)**: attaches **editioned** calibration map/standard with Φ‑policy id; lawful per CG‑Spec; **post**: `⟨L,P,E⃗,D⟩` unchanged; **idem.** on same edition; penalties **→ R only**. **CiteEvidence(anchor)**: binds carriers via **SCR/RSCR**; adds no numeric claims; **idem.**; missing carriers ⇒ **abstain**. **AttributeTo(role|source)**: provenance only; decision algebra unaffected; **idem.** Hidden GateChecks, plane/unit changes, or edition writes on edges are **forbidden**. | Contracts visible on edge audit; violations fail lint. |\n| **CC‑TGA‑18 — Flow = valuation & slice‑local refresh** | A flow declares valuation `ν` over `U.Transfer` plus `PublicationScopeId` and `PathSliceId`; **sentinel‑bounded** refresh; re‑emit on edition change or sentinel rule. | FlowSpec shows ν; sentinel bump triggers slice‑local recompute. |\n| **CC‑TGA‑19 — Γ_time on compare/launch** | All compare/launch faces pin `Γ_time`; no implicit *latest*. | Face audit shows Γ pins; LaunchGate blocks on stale. |\n| **CC‑TGA‑19a — Γ_time pin shape (normative)** | The `Γ_time` pin is one of: `snapshot(t)`, `interval[t1,t2]` (closed), or `policy(Γ_timeRuleId)` that resolves to either; CV computations record the **resolved time basis** in `DecisionLog` and do not widen Γ at publication time. | DecisionLog shows basis; linter rejects missing/implicit Γ. |\n| **CC‑TGA‑20 — Lean publish‑mode ≠ weaken** | `AssuranceLane‑Lite` affects faces only; required GateChecks for the active profile remain intact. | Gate in Lean/Core shows minimal pins; GateChecks list unchanged. |\n| **CC‑TGA‑21 — Decision stability & idempotency witness** | Gate decisions are stable under the equivalence relation defined in **A.41**; a **witness of equivalence** is present on the DecisionLog surface; any change that breaks equivalence requires re‑aggregation. **Minimum lexeme (CV‑relevant surfaces):** `EquivalenceWitness := { keys, E⃗, Γ_time(basis), PathSliceId?, ReturnShapeClass, ComparatorSetRef?, profile }`. | Modify any input outside the declared equivalence ⇒ re‑aggregation; DecisionLog records the witness (A.41); lexeme present.\n| **CC‑TGA‑21a — Decision join (publication algebra)** | Aggregation over GateChecks is the **idempotent, commutative, associative join** on the lattice `abstain ≤ pass ≤ degrade ≤ block` with **neutral = `abstain`** and **absorbing = `block`**. The algebra is conceptual; publications surface only (i) the aggregated **GateDecision** and (ii) its **GateDecisionRationale** recorded in the **DecisionLog**. A **GateDecisionExplanation** is an optional human‑readable narrative derived from the GateDecisionRationale; it is **not** a decision and MUST NOT be used as one. If aggregated `ConstraintValidity ≠ pass` or the active profile suppresses narratives, any GateFit‑oriented GateDecisionExplanation **does not apply**. | Review a gate with multiple GateChecks: the aggregated decision matches the lattice join; no per‑check arithmetic is introduced on faces. |\n| **CC‑TGA‑22 — Errors/unknowns fold by profile** | Errors/timeouts fold to `degrade` under `Lean|Core` and to `block` under `SafetyCritical|RegulatedX`; `unknown` folds per GateCheck policy (safety‑default: `degrade`). | DecisionLog shows folds; profile switch changes fold behavior accordingly. |\n| **CC‑TGA‑23 — SquareLaw on crossings** | For every GateCrossing, `gate_out ∘ transfer = transfer' ∘ gate_in`; LaunchGate case is mandatory. | MVPK shows commuting square; inconsistency yields `block|degrade` per profile. |\n| **CC‑TGA‑24 — UNM single‑writer** | `CG‑Spec`, `ComparatorSet`, `UNM.TransportRegistryΦ` editions are authored only by `UNM.Authoring` (others ref‑only). | Authorship cards: UNM is sole writer; others have refs only. |\n| **CC‑TGA‑25 — Evidence lanes & DecisionLogs** | AssuranceLane surfaces GateProfile, GateCheckRef list, edition pins, aggregated decision, `DecisionLogRef`; **evidence pins follow a two‑layer scheme**: **carriers** are pinned via **`SCR/RSCR`**, and **value annotations** are surfaced under **`VALATA (VA/LA/TA)`**. | Gate surfaces include these pins; logs retrievable. |\n\n> **Coupling note.** `CC‑TGA‑07 (CV⇒GF)` and `CC‑TGA‑21a (Decision join)` together ensure that any GateFit‑scoped GateCheckRef **returns `abstain`** until the aggregated CV status equals `pass`; CV/GF separation remains intact. \n> **Authoring note (scope of E.TGA vs A.*):** Detailed, mechanism‑level checks and most publication content are specified in the **A.* patterns** (A.20…A.42). E.TGA fixes only carcass‑level obligations above.\n\n**Glossary (additions)**  \n* *Open‑world species* — non‑exhaustive domain‑level specializations of `U.Transduction` that map to the minimal kind set.  \n* *Signature (TGA kind)* — `U.Transduction(kind=Signature)`; **identical to** **A.6.0** `U.Signature` (universal block). **Not** a `C.3.2 KindSignature`.  \n* *Architheory Signature (A.6.A)* — family‑specific **view** and discipline that **specialises** A.6.0 for architheories; the universal A.6.0 block remains the source of truth.  \n* *KindSignature (C.3.2)* — intensional definition of a `U.Kind` (intent/extent, F); **unrelated** to TGA kinds; never a `genus`.  \n* *Species (domain‑level)* — typed specialisations `speciesOf(kind=…)` that **MUST** declare `KindDefinition=A.*` id (e.g., `kind=Mechanism; KindDefinition=A.6.1`).  \n* *KindBridge (`CL^k`)* — a compatibility surface on UTS for describedEntity/kind transitions; required by CC‑TGA‑06‑EX and crossings (CC‑TGA‑11).\n* *Eulerian interpretation* — operational stance where a flow is treated as a valuation over `U.Transfer` and edges perform assurance‑only operations (no token‑passing semantics).\n* **GateCheckRef shape (publication lexeme, normative here).** Where GateChecks are surfaced, a **GateCheckRef** is a record\n  `GateCheckRef := { aspect, kind, edition, scope }` with:\n  `aspect ∈ {ConstraintValidity, GateFit}`, `kind ∈ GateCheckKind`, `edition ∈ Editions`, and `scope ∈ {lane | locus | subflow | profile}`. \n* **GateDecision / GateDecisionRationale / GateDecisionExplanation (terminology).**\n  — **GateDecision** — the aggregated lattice value produced by `OperationalGate(profile)` for a specific `{GateProfile, GateCheckRef[]}`.\n  — **GateDecisionRationale** — the minimal structured support **for that GateDecision**: per‑check outcomes, profile‑bound folds, and surfaced evidence/witness references on the DecisionLog; it records **why the GateDecision is admissible** under the active profile.\n  — **GateDecisionExplanation** — an optional human‑readable narrative derived from the GateDecisionRationale; it **does not carry decision status**. While aggregated `ConstraintValidity ≠ pass`, GateFit‑scoped checks return `abstain`; any GateFit‑oriented GateDecisionExplanation **does not apply**.\n> **Clarity note.** **GateDecision ≠ GateDecisionExplanation**; narratives are optional and derivative of GateDecisionRationale.\n\n* **GateFit (aspect, not an entity).** GateFit names the **aspect** of checks that evaluate **profile‑fit**; there is no separate GateFit entity. “Gate decision under GateFit” means “the gate’s decision computed from GateChecks with `aspect=GateFit`”.\n\n  This shape is publication‑level only; it introduces no new execution steps and no arithmetic on faces.  (Couples to A.20/A.21 without duplicating their check catalogs.)\n* *VALATA (VA/LA/TA)* — value‑annotation scheme used on **AssuranceLane**; **carriers** are referenced via **SCR/RSCR**; detailed obligations live in A.10/A.29. Included here so evidence pins are self‑describing in E‑level texts.\n* *Transfer vs Transport* — **Transfer** = the sole graph edge kind `U.Transfer`. **Transport** = Φ‑policy/registry‑defined conversions (`TransportRegistry^Φ`) referenced by UNM; “reuse via Transport” refers to the latter.\n* *GateCrossing* — a typed node transition that writes/updates a CtxState slot or the kind‑channel; see **S1.b** for the normative list and required pins.\n* *Admissible path* — a typed path obeying the GateCrossing discipline (no hidden crossings; witnesses present), Γ‑pinned on compare/launch, and `T^D↔T^R` only at `LaunchGate`; see **S2**.\n",
        "gating_profiles_(applied_to_e.tga)": "### E.18:8 - Gating Profiles (applied to E.TGA)\n\n> Gating is expressed as **publication‑gating** per E.17 profiles. The graph model aligns with the **CC items** listed for the chosen profile; higher profiles include all lower‑profile items.\n\n| Profile                          | Required CC‑items                                         | Additional notes                                                                               |                                                                  |\n| -------------------------------- | --------------------------------------------------------- | ---------------------------------------------------------------------------------------------- | ---------------------------------------------------------------- |\n| **Lean**                         | 01–06, 08–09, 11–12, 15, 19–21, 25                                                                                                           | Minimal MVPK presence; LaunchGate keeps `FreshnessUpToDate` & `DesignRunTagConsistency`. |\n| **Core**                         | **Lean** + 07, 10, 13–14, 16–18, 22–23, 24                                                                                                  | Adds CV⇒GF order, CSLC pins, budgeted loop, guards, valuation/sentinel refresh, error folds, SquareLaw, UNM single‑writer. |\n| **Safety‑Critical / RegulatedX** | **Core** + profile‑specific GateChecks (safety envelope, regulator id/editions) with stricter folds per **CC‑TGA‑22**; SquareLaw audits tightened | — |\n\n**Recommended defaults (non‑normative, tie‑in to A.26).** Profiles inherit along a `PathSlice`; local overrides may only **add** GateChecks; weakening requires a new `PathSlice` via sentinel (cf. A.26/A.25).\n",
        "tga_lex_discipline_(registration)": "### E.18:9 - TGA LEX discipline (registration)\nRegister Tech tokens (ASCII) used by this architecture with twin‑labels: `U.TransductionGraph`, `U.TransductionFlow`, `StructuralReinterpretation`, `OperationalGate`, `GateProfile`, `GateCheckRef`, **`GateCheckKind`**, `DecisionLog`, `USM.CompareGuard`, `USM.LaunchGuard`, `KindBridge`, `SubflowRef`, `FlowEmbed`, `SentinelId`, `PathSliceId`, `SliceRefresh`, `FinalizeLaunchValues`, `VALATA`. Add an ASCII alias **`CLKind`** ↔ Plain `CL^k` (cf. `CLPlane` ↔ `CL^plane`). Reference MVPK E.17 naming for faces.  \n**CtxState Extension Registry.** Register any extra CtxState slot beyond ⟨L,P,E⃗,D⟩ with: slot id, informal intent, partial‑order law (with neutral/absorbing), SquareLaw compatibility note, and the owning Gate profile(s) that may change it. Absence of registration ⇒ **non‑conformant**.\n",
        "consequences": "### E.18:10 - Consequences\n\n**Benefits.**\n\n1. **Universality with discipline:** one edge kind and explicit gates eliminate “second process ladders” and make cross‑domain flows (ML, supply‑chain, TAMP/MPC, scientific workflows) uniformly analyzable and auditable.\n2. **Comparability & replayability:** CSLC and edition‑pinned comparators prevent covert scalarization and enable lawful set returns and reproducible decisions.\n3. **Locality of change:** sentinel subflows restrict refresh to affected `PathSlice`s; large graphs remain stable under frequent edition bumps.\n4. **Clean design/run fold:** LaunchGate and `DesignRunTagConsistency` stop premature launch‑value slot filling; acceptance and telemetry live where they occur (`U.Work`).\n5. **Assurance visibility:** MVPK makes GateProfile/DecisionLog surfaces locally checkable and cacheable for the same `{PathSlice, GateChecks, Editions}`.\n\n**Trade‑offs.**\na) **Higher upfront modeling cost:** explicit Bridge/UTS pins and GateProfiles demand care; mitigated by Lean profile and templates.\nb) **Longer edge surfaces:** MVPK faces are verbose by design; Lean surfaces can be used for low‑risk segments.\nc) **Tooling alignment:** some incumbent DAG‑only orchestrators conflict with budgeted cycles and set‑return semantics; adapters must project E.TGA semantics to their interop layer (never the other way round).\n",
        "rationale": "### E.18:10 - Rationale\n\nE.TGA enforces **strict separation of concerns** (carcass‑level only); **specialized semantics live in A.* patterns**:\n\n* **What the graph is:** typed intensional morphisms and a single transport edge `U.Transfer`.\n* **Where/when it may cross contexts:** **only** at `OperationalGate(profile)`, with Bridge+UTS, CL/CL^plane, and Φ routed to R‑lane.\n* **How comparability works:** UNM authors units/planes/transports (single writer) and selectors operate **only** on normalized, edition‑pinned comparators, returning sets/archives—not totals. **Edition‑aware pins and archive semantics are tested in A.28/A.34/A.37 (not repeated here).**\n* **How change propagates:** sentinel‑bounded `PathSlice` refresh; editions are monotone; LaunchGate is the only binder of launch‑values.\n\nThis arrangement guarantees **functorial publication** (commuting squares on crossings) and **orthogonality** of inner technical validity (ConstraintValidity) to context fit (GateFit), which in turn makes gate aggregation **order‑independent** and cements the CV⇒GF activation predicate.\n",
        "sota‑echoing_(post‑2015,_multi‑tradition)": "### E.18:11 - SoTA‑Echoing (post‑2015, multi‑Tradition)\n\n> Each item states **Adopt / Adapt / Reject**, and why. Vendor/tool tokens are kept as *informative*, not normative.\n\n1. **Applied category theory (compositional open systems).**\n   **Adopt.** Monoidal composition and wiring justify “nodes as morphisms, edges as carriers” and functorial publication of faces; they also provide algebraic laws for joining subflows. (Fong & Spivak, *Seven Sketches in Compositionality*, 2019).\n\n2. **Operads / wiring diagrams / hypergraph categories.**\n   **Adopt/Adapt.** Typed ports and decorated cospans model interfaces and “Bridge” junctions; we adapt the operadic composition to require CL/Φ pins on every crossing (publication‑level requirement not present in the math). (Spivak, *Operads of Wiring Diagrams*, 2021; Baez & Fong, *A Compositional Framework for Passive Linear Circuits*, 2015).\n\n3. **Open‑graph/string‑diagram rewriting.**\n   **Adapt.** Rewriting systems capture subflow refactors, but E.TGA binds rewrites to edition bumps and sentinel scopes rather than global rewrites, to preserve auditability and replay. (Bonchi et al., *Graphical Linear Algebra*, 2019; Kissinger—survey lineage).\n\n4. **Publication discipline & artefact portability.**  \n**Adopt.** Edition‑pinning and immutable registries echo contemporary reproducibility practice; E⃗ stays explicit and compositional at the publication layer.\n\n5. **Reproducibility & content addressability.**  \n   **Adopt.** Edition‑pinning and immutable registries echo modern content‑addressable reproducibility (conceptual); E⃗ stays explicit and compositional at the publication layer.\n\n6. **TAMP/MPC (integrated planning and control).**\n   **Adopt/Adapt.** The budgeted Selection↔Planning loop follows contemporary TAMP practice; MPC‑style freshness/constraint checks motivate **FreshnessUpToDate** as a hard LaunchGate module and “bind‑in‑Work‑only”. (Garrett, Lozano‑Pérez, Kaelbling, *Integrated Task and Motion Planning*, 2021; Rawlings et al., MPC updates).\n\n7. **Quality‑Diversity (QD) search.**\n   **Adopt.** QD (e.g., CMA‑ME, 2020) justifies **set‑return** and archive semantics in `U.SelectionAndTuning`; E.TGA bans covert scalarization that would collapse archives to single “bests”.\n\n8. **Profunctor optics (modular projections).**\n   **Adopt/Adapt.** Optics motivate view/projection discipline behind MVPK faces; we adapt by forbidding MVPK faces from introducing new claims (they are pure projections, not transformations). (Pickering, Gibbons, Wu, **Profunctor Optics**, 2019).\n\n*Cross‑tradition note.* Items 1–3 (category‑theoretic), 4–5 (publication/reproducibility concepts), 6 (controls/robotics), 7 (evolutionary search), and 8 (PL/semantics) jointly anchor E.TGA across multiple traditions, per E.8.\n",
        "bias‑annotation_(per_e.8_sg‑bias_slot)": "### E.18:12 - Bias‑Annotation (per E.8 SG‑bias slot)\n\n* **Acyclic‑bias risk.** Tooling accustomed to DAGs may discourage legal feedback loops; E.TGA explicitly permits loops with budget/sentinel controls (CC‑TGA‑13,‑18).\n* **Scalarization‑bias risk.** Cultural defaults to single‑score rankings can suppress Pareto/QD sets; E.TGA requires lawful orders and return‑sets (CC‑TGA‑10,‑12).\n* **Interop‑dominance risk.** File/format ecosystems (CWL/RO‑Crate/lineage) can leak into semantics; E.TGA places them in **InteropCard** and keeps intensional semantics in nodes/gates.\n* **Over‑formalization risk.** Category‑theoretic formalisms can obscure operational guard‑rails; E.TGA grounds crossings in Bridge/UTS/CL/Φ pins and SquareLaw audits (CC‑TGA‑11,‑17).\n* **Retrospective rewrite risk.** Global rewrites break replay; E.TGA confines them to edition bumps and slice‑local refresh (CC‑TGA‑16).\n\n**Mitigations.** Profile‑gated publication, audit of `DecisionLog`, mandatory edition pins, Lean‑to‑Core upgrade paths, and conformance tests tied to PathSlice replay.\n",
        "relations": "### E.18:13 - Relations (explicit pattern‑to‑pattern edges)\n\n> Directed edges (→) are typed as **builds_on / constrains / hosts / specializes / publishes_on / requires / provides_checks_for**.\n\n**Foundations**\n* **E.TGA →builds_on→ E.17 MVPK (for Morphisms).** Faces, pins, lanes, functorial publication, Lean/Core/Regulated profiles.\n* **E.TGA →builds_on→ A.6.0 U.Signature / A.6.1 U.Mechanism.** Node kinds and intensional content boundaries.\n* **E.TGA →builds_on→ A.7 Strict Distinction (I/D/S vs Surface).** No new claims on faces; faces project morphisms.\n\n**Flow semantics & checks**\n* **E.TGA →hosts→ A.20 U.Flow (ConstraintValidity scope).** CV checks live inside transformations; no declaration/translation of planes/units in CV; **error/timeout/unknown folds** follow **CC‑TGA‑22** as the **minimum default** (profiles may be stricter).\n  **Terminology discipline (A.20 boundary).** In CV scope, publications use **status/witness** language; **GateDecisionRationale/GateDecisionExplanation** are reserved for gating and do not apply to CV.\n* **E.TGA →hosts→ A.21 GateProfilization (GateFit scope).** **GateFit-scoped GateChecks** are aggregated by `OperationalGate(profile)` with CV⇒GF activation; the **enumeration and publication shape** of GateChecks live in **A.21**. **Equivalently:** a GateFit decision different from `abstain` appears only when aggregated `ConstraintValidity = pass`; otherwise the **GateDecisionExplanation (GateFit‑oriented)** does not apply.\n* **E.TGA →requires→ USM.CompareGuard / USM.LaunchGuard.** Guards publish scope & ownership; guard failures route to owner gate.\n* **E.TGA →constrains→ F.* (Bridge+UTS, CL/CL^plane, Φ→R).** A transition is treated as a **Crossing** iff `Bridge+UTS` and the appropriate `CL/CL^plane` are surfaced; otherwise this crossing explanation does not apply. Where Φ defines penalties, they appear in the R‑lane only.\n* **Operational interpretation (default): Eulerian.** A flow is a **valuation** over `U.Transfer`; edges carry **assurance‑only operations** (see CC‑TGA‑17); no token‑passing semantics are assumed.\n\n**UNM & comparability**\n* **E.TGA →constrains→ UNM.Authoring / UNM.Usage.** Single‑writer for `CG‑Spec/ComparatorSet/UNM.TransportRegistryΦ`; normalize‑then‑compare is mandatory.\n* **E.TGA →constrains→ G.5 SelectionAndTuning.** Set‑returning, comparator‑pinned decisions, no hidden scalarization; `MethodTuning` without launch‑value slot filling.\n* **E.TGA →constrains→ G.11 EvaluatingAndRefreshing.** EditionBumpProposal, two‑phase commit in UNM.Authoring, path‑local refresh.\n\n**Work boundary**\n* **E.TGA →requires→ A.15 U.WorkEnactment (`FinalizeLaunchValuesOnlyInWork`).** Single point of `FinalizeLaunchValues`; `FreshnessUpToDate` hard at LaunchGate; acceptance/telemetry published here.\n\n**Structure & reuse**\n* **E.TGA →specializes→ U.TransductionFlow (and its family).** The graph architecture is the common substrate on which flow patterns (e.g., P2W, EvaluatingAndRefreshing) are defined; E.TGA ensures their crossings, guards, and MVPK faces are coherent.\n* **E.TGA →publishes_on→ E.17 MVPK views** (`PlainView`, `TechCard`, `InteropCard`, `AssuranceLane`) for every edge/node where publication occurs; Lean mode allowed only as per profile.\n",
        "conformance_evidence_(how_to_show_you_comply)": "### E.18:14 - Conformance evidence (how to show you comply)\n\n1. **Model lint:** run static checks for CC‑TGA‑01…25 (edge kind, gates on crossings, CV⇒GF, guard ownership, single‑writer UNM, SquareLaw).\n2. **Publication audit:** sample a commuting square and a sentinel‑bounded subflow; verify pins and DecisionLog behavior on *block/degrade*.\n3. **Replay test:** freeze editions; re‑run selection on a PathSlice; observe identical return‑sets; apply a bump; see only affected `PathSlice`s refresh.\n4. **StructuralReinterpretation probe:** construct a minimal reinterpretation step; confirm `CL^k` with `bridgeChannel=Kind` on UTS, a SquareLaw‑retargeting witness on UTS, `PathSliceId` pinned, **CV.ReinterpretationEquivalence=pass**, and absence of hidden scalarization.\n\n[20]: https://webstore.ansi.org/preview-pages/ISO/preview_ISO%2B23247-1-2021.pdf?srsltid=AfmBOooAUXpg38IpkTlUFtcCpaMVOjivkewJWDIUd1VemIJO91abNEkG \"INTERNATIONAL STANDARD ISO 23247-1\"\n",
        "e.18:end": "### E.18:End\n"
      },
      "content": "### E.18:End\n",
      "metadata": {},
      "part": "E",
      "cluster": null
    },
    {
      "id": "E.19",
      "title": "Pattern Quality Gates: Review & Refresh Profiles",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## E.19 - Pattern Quality Gates: Review & Refresh Profiles\n\n> **Type:** Architectural pattern\n> **Status:** Stable\n> **Normativity:** Normative\n",
        "problem": "### E.19:2 - Problem\n\nWithout a unified, explicit review pattern:\n\n* Different reviewers optimize for formal/template compliance and miss deeper ontological, semantic, and naming issues, producing bureaucratic output that does not improve the enforceable contract.\n* Authors “optimize for the visible checklist” and miss hidden obligations (lexical discipline, Bridge hygiene, SoTA‑Echoing quality, scope claims, delta‑class impact).\n* Legacy patterns accumulate “conceptual bit-rot” and diverge from current practice, current terminology, or current internal invariants.\n* The specification’s normative surface becomes harder to trust: compliance becomes a matter of reviewer taste rather than a repeatable gate.\n",
        "forces": "### E.19:3 - Forces\n\n| Force                                   | Tension                                                                             |\n| --------------------------------------- | ----------------------------------------------------------------------------------- |\n| **Uniformity vs Fit**                   | One universal checklist is simple ↔ different pattern kinds carry different risks.  |\n| **Rigor vs Editorial cost**             | Deep audits increase quality ↔ they must remain feasible for routine updates.       |\n| **Stability vs Evolution**              | Canon should stay stable ↔ it must absorb new SoTA and correct mistakes.            |\n| **Conceptual purity vs Enforceability** | Core must stay tooling‑agnostic ↔ gates must still be actionable and auditable.     |\n| **Local meaning vs Reuse**              | Patterns must remain context‑anchored ↔ authors want to reuse ideas across domains. |\n| **Freshness vs timelessness**           | Some claims should be evergreen ↔ others decay and must be refreshed on cadence.    |\n",
        "solution": "### E.19:4 - Solution — Profile-based gates for admission and refresh\n\nEstablish **Pattern Quality Gates (PQG)**: a conceptual review mechanism that applies **profiles of checks** rather than a single monolithic checklist.\n\nA **Pattern Check Profile (PCP)** is a named bundle of check families. Profiles are **additive**: every review applies a baseline profile, then adds risk-driven profiles as needed.\n\n**Terminology note (disambiguation).** PQG/PCP are editorial review constructs in the authoring plane (Part E). They are distinct from enactment/runtime gating constructs such as `OperationalGate(profile)` / `GateProfile` (A.21), which govern Work transitions and gate decision policies elsewhere in FPF.\n\n**Mint vs reuse.** This pattern mints **PQG**, **PCP**, and the profile IDs **PCP‑BASE/MOD/PRAG/NORM/SOTA/BRIDGE/TERM/DEONT/REFRESH**. It reuses existing FPF terms (e.g., **Delta‑Class**, **DRR**, **Bridge**, **CL**, **SoTA Synthesis Pack**) without changing their meanings.\n\n#### E.19:4.1 - Define the review target\n\nA review **SHOULD** propose revisions to a target pattern (including didactic restructuring) that positively affect downstream usage and interoperability. Formal/template defects (e.g., non‑compliance with E.8 structure or not conforming to RFC deontic terminology) have lower review priority than semantic/ontological defects or non‑SoTA Solutions, but they also **MUST** be corrected.\n\nE.g. if the header block is missing or incomplete, **continue with ontology and semantic review first**. Treat missing header fields as a mechanical defect to patch (PCP‑BASE #7), not as a reason to stop.\n\nThe run **SHOULD** give best-known **Delta‑Class (Δ‑0…Δ‑3)** and record an initial **impact radius** (dependent patterns/tests/relations that need be changed due to pattern norms), using existing definitions where available (e.g., the LEX‑AUTH protocol).\n\n#### E.19:4.2 - Apply the baseline profile to every run\n\nEvery run MUST include **PCP‑BASE**, reviewer depth SHOULD prioritize the load-bearing surfaces in E.19:4.2.1.\n\n1. **Internal coherence (problem ↔ contract ↔ solution)**\n   The Conformance Checklist matches Problem statement and the Solution (no “orphan requirements” and no “unclaimed obligations”).\n2. **Lexical discipline & reserved vocabulary**\n   Terms and registers follow lexical rules; ambiguous “everyday” synonyms do not silently replace kernel vocabulary.\n3. **SoTA‑Echoing minimum compliance (E.8)**\n   SoTA‑Echoing satisfies the E.8 obligations applicable to the pattern kind (Architectural vs Definitional), including post‑2015 sourcing and explicit adopt/adapt/reject stances. If a SoTA Synthesis Pack exists for the topic, SoTA‑Echoing binds to it rather than forking an untracked narrative; any divergence of pattern norms from contemporary practice is explicitly stated as such. SoTA‑Echoing **MUST** be non‑decorative: the Solution and other load‑bearing sections **MUST** align with the declared SoTA stance, or explicitly justify any divergence.\n4. **Cross-pattern compatibility & impact radius**\n   Relations are consistent with declared dependencies and dependents; declared scope/impact is compatible or explicitly limited.\n5. **Didactic grounding**\n   Archetypal Grounding is present and teaches the concept with concrete anchors, not only abstractions.\n6. **Template & section integrity**\n   This is lowest priority for review depth and **SHOULD NOT** consume effort that would displace ontology/semantics/modularity/slots/SoTA checks. \n7. **Modularity & contradiction hygiene**\n   The pattern **SHOULD NOT** be overloaded or expands obligations/dependencies  significantly. Checks include: scope hygiene, split/refactor recommendation when warranted, and contradiction scan against neighbor patterns in Relations. Pattern should respect balance of coheiseveness and coupling of its content among other patterns in FPF. If pattern define specialization it should not show mix of slots/parameters of different levels. \n\n##### E.19:4.2.1 - Triage: spend depth on load-bearing surfaces without making reviews heavier\n\nPQG is meant to increase *semantic and ontological trust*, not to turn every review into an exhaustive editorial audit on form. To keep reviews feasible while improving the important parts:\n\n* Treat **load-bearing surfaces** as the primary depth targets:\n  * the pattern’s **Conformance Checklist** (the enforceable contract): keep items universal, cognitively ergonomic, not overly prohibitive, and avoid duplicating checks that belong to other patterns (modularity),\n  * **deontic clauses** (`MUST/SHALL/SHOULD/MAY`) that define obligations on the authoring/validation plane (not laws of nature or mathematical facts; ensure an explicit conformance subject),\n  * **admissibility constraints** (`Invariant:` / `Well‑formedness constraint:`) that define valid models (cardinality, typing/kinds, totality) and are written as non‑deontic predicates (no RFC keywords inside the predicate),\n  * **definitions and mint/reuse decisions** (new terms, renamed terms, scope claims baked into names, names that are not overloaded and are properly chosen),\n  * **cross-context / cross-plane claims** (Bridge hygiene and “sameness” assertions),\n  * **SoTA** (when the pattern claims state‑of‑the‑art rather than a popular‑but‑outdated solution or vocabulary),\n  * **modularity and Slot discipline of A.6.5** that provide evolvability of FPF,\n  * **absence of contradictions in a pattern**,\n  * **Relations** that define compatibility and impact radius.\n* Treat **low-signal surfaces** as “scan-level” unless they change meaning: headings/formatting, micro-typos, stylistic polish, and non-load-bearing narrative refactors, compliance to deontic RFC.\n* **Do not block semantic review on template and RFC compliance defects.** Missing header block fields (E.8 H‑5), missing canonical sections, or a missing footer marker are fixable integrity defects. Patch them quickly and continue with the load-bearing surface checks in the same run.\n* **Report ordering (impact-first).** In run outputs and remediation patches, prioritize fixes on ontology, semantic, modularity and SoTA-related load-bearing surfaces first; group low-signal formatting/typos into a single hunk at the end unless they change meaning.\n\n#### E.19:4.3 - Add risk-driven profiles\n\n**PCP‑PRAG (Pragmatic utility & adoption)** — Trigger: the pattern is Normative and claims practice guidance.\nChecks include: minimally viable example, non-decorative Consequences/Anti-Patterns, and an explicit “So what?” adoption test.\n\n**PCP‑REFRESH (Staleness & compatibility refresh)** — Trigger: staleness signals are present (e.g., outdated SoTA rows, renamed/superseded Relations targets, terminology drift, or an explicit refresh window in LAT/DRR).\nChecks include:\n\n* refresh‑sensitive claims are identified (time‑bounded or ecosystem‑bounded) and either (a) updated with post‑2015 evidence **and** matching Solution changes, or (b) explicitly scope‑limited and labeled as historical lineage,\n* Relations are updated to current pattern IDs; deprecations/renames are handled via explicit continuity notes (no silent relabeling),\n* the run records a Delta‑Class and impact radius; if the refresh causes Δ‑2/Δ‑3, it emits/updates a DRR pointer and triggers any required harness/Bridge refresh obligations defined elsewhere (E.15/F.15/F.9).\n\nTrigger overrides are permitted but intentionally rare: a run MAY override a triggered profile only when it can show the trigger’s risk is genuinely absent *in this case*, and the record MUST name (a) why the trigger is a false positive here and (b) what compensating check(s) were applied instead.\n\n**PCP‑NORM (Normative contract integrity)** — Trigger: the pattern introduces or changes normative requirements, introduces new conformance items, or shifts downstream obligations.\nChecks include:\n\n* **Delta‑Class (Δ‑0…Δ‑3)** and **impact radius** are explicit (what breaks, who depends on this),\n* requirements are testable in principle (conceptually), scoped, and non-contradictory,\n* downstream patterns cited in Relations are compatible with the new contract.\n* where the change is Δ‑2/Δ‑3 or a new normative pattern is being admitted: a DRR exists and references the PQG findings (pointer is sufficient; no duplicated prose).\n\n**PCP‑SOTA (Evidence & SoTA alignment)** — Trigger: the pattern’s Solution asserts “best practice”, “state-of-the-art”, or introduces new synthesis claims.\nChecks include:\n\n* each “best practice / SoTA” claim in the Solution is explicitly **bound** to SoTA‑Echoing rows (or to SoTA Synthesis Pack identifiers when used), rather than floating as ungrounded prescription,\n* novel synthesis is not presented as established SoTA: it is either (a) framed as a scoped hypothesis with explicit limits, or (b) promoted into/registered as a SoTA Synthesis Pack entry before the pattern is admitted as normative guidance,\n* where traditions disagree materially, the pattern surfaces the disagreement and states why it adopts/adapts/rejects (instead of silently selecting one tradition),\n* refresh‑sensitive claims (those likely to decay) are explicitly marked with scope limits, timespan notes, or lineage labeling when appropriate.\n\n**PCP‑BRIDGE (Cross‑context/plane reuse integrity)** — Trigger: the pattern imports claims, terms, or norms across contexts, disciplines, or reference planes.\nChecks include:\n\n* explicit Bridge usage where required (no silent identity by spelling),\n* Congruence / loss is surfaced where applicable,\n* any cross-plane reuse is explicitly acknowledged and its penalties do not leak into unrelated assurances.\n\n**PCP‑TERM (Terminology & naming protocol)** — Trigger: the pattern introduces new terms, new U.Types, new “unified names”, or redefines existing labels.\nChecks include:\n\n* “mint vs reuse” decision is explicit,\n* naming follows the local-first naming protocol and avoids scope smuggling (roles/metrics/stages baked into labels; overloaded words used as terms with a local sense). Remediation **SHOULD** use F.18,\n* deprecated aliases and continuity rules are respected.\n\n**PCP-DEONT (Deontic clause hygiene - RFC keywords)** - Trigger: the pattern mismatch admissibility (like in laws in physics) and deontic laws (like in law enforcement). \nChecks include:\n* Deontic requirements are expressed with RFC-style keywords (see H‑8); \n* obligations are not smuggled into prose as informal imperatives. Admissibility/validity constraints are stated non‑deontically as `Invariant:` / `Well‑formedness constraint:` predicates and referenced from the Conformance Checklist when enforceable. \n* **Subject discipline for RFC keywords.** If a sentence uses RFC keywords, its grammatical subject **MUST** be an agent or a publishable artefact (author, reviewer, tool, model, record, validator). RFC keywords **MUST NOT** modify modeled‑world entities (e.g., “Earth”, “RoleAssignment”, “Role”, “holon”) — express those as `Invariant:` / `Well‑formedness constraint:` predicates instead, and (if needed) reference them from CC items.\n\n#### E.19:4.4 - Decision outcomes\n\nA PQG run **MUST** end with (a) a remediation patch (English, unified diff, fenced) and (b) a compact list of blocking findings.\n\n**Remediation payload (patch-first).** The run MUST provide concrete remediation proposals as a unified diff patch in English in a fenced code block (if patch is huge, acceptable have it in separate file to have all needed details without need to excess brevity), accompanied by a short commentary stating (a) the explicit misses found and (b) any remaining work that was intentionally deferred. This is a user interchange convention, not a tool mandate.\n\n**Report ordering (impact-first).** The patch is the primary artifact. In the short commentary, list findings in descending order of expected impact on semantic trust (load-bearing surfaces first). Template/formatting-only issues belong at the end unless they hide missing content.\n\n**Budget discipline (anti‑lint‑worship).** If the run identifies semantic defects in load-bearing surfaces, remediation MUST prioritize those fixes; purely mechanical edits (formatting, micro-typos) MUST be minimized and MUST NOT dominate the patch by volume.\n\n**Noise discipline.** The run record is a human-facing audit trail. It **SHOULD** be sparse: list findings, deferrals, and decisions; do **not** paste full PASS output. No need emitting per-check “passed” lines; only found problems and remediation/fixes matter.\n",
        "archetypal_grounding": "### E.19:5 - Archetypal Grounding — Tell–Show–Show: System / Episteme\n\n| Scenario | `U.System` grounding | `U.Episteme` grounding |\n|---|---|\n| **Tell** | A safety-critical engineering team proposes a new pattern describing how to gate a subsystem before deployment. The draft looks polished, but it quietly imports domain terms, assumes cross-team equivalences, and introduces obligations that are not listed in its own checklist. | A research group refreshes an older pattern that summarizes how to evaluate evidence strength. The pattern still reads well, but its SoTA references and terminology no longer match current practice, and its Relations point to patterns that were renamed or superseded. |\n| **Show (failure without PQG)** | Reviewers focus on whether the idea is good and whether the template exists. The pattern is admitted, but later users disagree on what it requires because the Conformance Checklist is incomplete and key constraints are only in prose. | The pattern remains unchanged because “nothing looks broken”. Over time, it becomes a conceptual fossil: newcomers treat it as current guidance, but it encodes an outdated stance and stale vocabulary. |\n| **Show (repair with PQG profiles)** | PCP‑BASE finds missing internal coherence (requirements in prose not reflected in CC). PCP‑TERM finds naming drift and scope-smuggling in new terms. PCP‑BRIDGE finds implicit cross-context identity claims without explicit alignment. The pattern is revised before admission, and the final CC becomes the canonical contract. | Patch provided explicit decision: updated SoTA‑Echoing with post‑2015 guidance and appropriate Solution changes, limit the scope to “historical lineage” where appropriate, and update Relations to current dependencies. The refreshed pattern becomes trustworthy again, and any remaining historical material is clearly labeled as such. |\n",
        "bias_annotation": "### E.19:6 - Bias-Annotation\n\nLenses tested: **Gov**, **Arch**, **Onto/Epist**, **Prag**, **Did**. Scope: **Universal** (applies to all patterns and all clusters).\n\nBias risks and mitigations:\n\n* **Governance bias (Gov):** reviewers may over-prioritize “compliance posture” and under-prioritize teaching value.\n  *Mitigation:* PCP‑BASE includes didactic grounding and internal coherence checks and priority for ontology and semantics, not to form.\n* **Epistemic monoculture (Onto/Epist):** SoTA‑Echoing can become single-tradition name-dropping.\n  *Mitigation:* require explicit multi-tradition coverage and usage of F.18 for neutral naming.\n* **Pragmatic bias (Prag):** a pattern can be “correct” yet unusable.\n  *Mitigation:* consequences and anti-patterns remain mandatory sections, surfacing trade-offs and misuse paths.\n* **Didactic bias (Did):** narrative quality can be mistaken for truth.\n  *Mitigation:* conformance and SoTA‑Echoing sections bind claims to explicit obligations and lineage.\n",
        "conformance_checklist": "### E.19:7 - Conformance Checklist\n\n| ID | Requirement | Purpose |\n| --- | --- | --- |\n| **CC‑E19‑1 (Baseline is mandatory).** | Every PQG run **MUST** apply **PCP‑BASE** to the review target. | Ensures a uniform minimum gate across all pattern kinds. |\n| **CC‑E19‑2 (Profile selection is auditable).** | The run record **MUST** state (a) the selected PCPs, (b) the trigger(s) for each non‑BASE profile, and (c) any override decisions. Any override of a triggered profile **MUST** record why the trigger is a false positive and what compensating check(s) were applied instead. | Makes depth decisions repeatable and reviewable. |\n| **CC‑E19‑3 (Delta‑Class & impact for breaking change levels).** | If the run proposes or accepts a change that is **Δ‑2/Δ‑3** (per E.15), the run record **MUST** include Delta‑Class, an impact radius, and a DRR pointer; it **MUST** confirm that required harness/Bridge refresh obligations are triggered where applicable. | Keeps evolution controlled and compatible with downstream dependencies. |\n| **CC‑E19‑4 (Contract coherence is enforced).** | Remediation **MUST** eliminate “orphan” obligations and “unclaimed” requirements by aligning the target pattern’s Conformance Checklist, deontic clauses, and admissibility constraints with its Solution. | Preserves the CC as the enforceable contract surface. |\n| **CC‑E19‑5 (Triage & noise discipline).** | The run **SHOULD** prioritize load‑bearing surfaces (e.g. CC, content of deontic clauses and content of admissibility constraints, definitions, Relations, SoTA, modularity) and keep purely mechanical edits (e.g. RFC format of deontic clauses) minimal. Template defects **MUST** be fixed before admission (or before closing a refresh run) but **MUST NOT** be used to skip semantic review. | Improves semantic trust without turning review into lint and RFC compliance worship. |\n| **CC‑E19‑6 (Patch-first output).** | The run output **MUST** include a remediation patch (English, unified diff, fenced) and a compact list of blocking findings, ordered by semantic impact (load‑bearing surfaces first). | Ensures actionability and consistent reporting. |\n",
        "anti_patterns": "### E.19:8 - Common Anti-Patterns and How to Avoid Them\n\n| Anti-pattern                       | Symptom                                                          | Why it fails (force violated)                           | How to avoid / repair                                                |\n| ---------------------------------- | ---------------------------------------------------------------- | ------------------------------------------------------- | -------------------------------------------------------------------- |\n| **Verdict-only review**            | The run ends with “pass/fail” and prose complaints, but no proposed edits. | Raises editorial cost; reduces repeatability.           | Require a remediation payload: patch-first proposed edits + short commentary; treat the patch as the primary artifact. |\n| **Single giant checklist**         | Review becomes a long, unfocused ritual that few complete.       | Increases cost; reduces fit and rigor in practice.      | Use a minimal baseline plus triggered profiles.                      |\n| **Template-only compliance**       | All headings exist, but obligations are vague and untestable.    | Looks uniform; fails enforceability and auditability.   | Enforce normative clause hygiene and CC/Solution coherence.          |\n| **SoTA name-dropping**             | SoTA‑Echoing is a list of buzzwords with no stance.              | Breaks evidence lineage; invites monoculture.           | Require adopt/adapt/reject with reasons per item.                    |\n| **Terminology drift by “synonym”** | Authors swap kernel terms for nicer-sounding words.              | Increases ambiguity; harms cross-pattern composability. | Apply PCP‑TERM and require explicit mini-definitions on first use.   |\n| **Typos-first review (lint worship)** | Review time goes to formatting and micro-edits while the normative surface, terms, Bridges, modularity, slot discipline and SoTA stance are barely checked. | Raises editorial cost without raising semantic trust. | Use the triage rule: treat load-bearing surfaces as depth targets; satisfy mechanical checks via auditable lint/harness traces when available. |\n",
        "consequences": "### E.19:9 - Consequences\n\n| Benefits                                                                         | Trade-offs / Mitigations                                                                   |\n| -------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------ |\n| **Repeatable admission decisions** — reviewers share a common gate language.     | More explicit editorial work; mitigated by a small baseline and triggered profiles.        |\n| **Higher trust in the normative surface** — CC becomes the enforceable contract. | Authors must align prose and CC carefully; mitigated by coherence checks.                  |\n| **Controlled evolution** — runs prevent conceptual bit-rot.              | Periodic workload; mitigated by prioritizing high-dependency and high-risk patterns first. |\n| **Less hidden drift** — terminology and cross-context reuse become explicit.     | Some drafts will be delayed; mitigated by early profile selection during authoring.        |\n",
        "rationale": "### E.19:10 - Rationale\n\nPatterns are both **teaching artifacts** and **normative contracts**. A specification that grows without explicit quality gates becomes a patchwork: locally good, globally inconsistent. A profile-based gate is the smallest structure that keeps reviews repeatable while remaining sensitive to risk and pattern kind.\n\nThe baseline profile protects cross-pattern comparability and editorial sanity. Triggered profiles keep depth where it matters: norms, SoTA claims, cross-context reuse, terminology changes, and legacy refresh.\n",
        "sota_echoing": "### E.19:11 - SoTA-Echoing — post-2015 review/validation practice alignment\n\n**Evidence binding note.** If a SoTA Synthesis Pack exists for review/validation or refresh discipline in your Context, cite it and keep this section consistent with it; otherwise treat the table below as a provisional seed that should not be duplicated elsewhere without an explicit update record.\n\n| Claim (E.19 need)                                                      | SoTA practice (post‑2015)                                                                                   | Primary source (post‑2015)                                                                  | Alignment with E.19                                                                       | Adoption status                                                                                              |\n| ---------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------ |\n| Reviews need explicit criteria, not informal taste.                    | Move from folklore validation to explicit validation methods and documented criteria.                       | Riehle et al. (2020), “Pattern Discovery and Validation Using Scientific Research Methods”. | PCPs make criteria explicit; CC coherence is enforced.                                    | **Adopt.** Keep methods lightweight but explicit.                                                            |\n| A stable structure improves comparability and reduces ambiguity.       | Standards specify required viewpoints/concerns and consistency rules for descriptions.                      | ISO/IEC/IEEE 42010:2022 (architecture description).                                         | PCP‑BASE includes structural integrity and internal consistency.                          | **Adopt/Adapt.** Adopt conformance mindset; adapt to pattern-language template and didactic grounding.       |\n| Pattern writing benefits from explicit guidance plus critique culture. | Pattern-language communities emphasize clear template usage, consequences, and critique for quality.        | Iba (2021), “How to Write Patterns …” (PLoP 2021).                                          | Baseline checks enforce meaningful sections; anti-patterns make critique concrete.        | **Adopt.** Directly supports admission quality.                                                              |\n| “Living” guidance needs refresh discipline.                            | Reporting/review guidance is updated and versioned; reviewers must track changes and report deltas clearly. | Page et al. (2021), PRISMA 2020 statement and explanation papers.                           | Runs require explicit decisions and deltas in SoTA‑Echoing. | **Adapt.** Use the “versioned guidance + explicit deltas” principle without importing tool/process mandates. |\n",
        "relations": "### E.19:12 - Relations\n\n* **Builds on:**\n\n  * `E.8` (authoring conventions; canonical section order; SoTA‑Echoing obligations)\n  * `E.10` (lexical discipline and reserved vocabulary)\n  * `E.9` (design rationale records for changes that affect semantics)\n  * `E.15` (authoring/evolution protocol; harness mindset; refresh planning)\n  * `A.6.1.5` (Slot discipline)\n* **Coordinates with:**\n\n  * `F.8` (mint vs reuse decisions)\n  * `F.18` (local-first naming protocol)\n  * `F.9` (cross-context alignment discipline)\n  * `F.15` (conceptual harness and regression framing)\n  * `G.11` (refresh/decay orchestration principles, where applicable)\n",
        "e.19:end": "### E.19:End\n\n\n# **Part F — The Unification Suite (U‑Suite): Concept‑Sets, SenseCells & Contextual Role Assignment**\n\n# Cluster F.I — context of meaning & Raw Material\n"
      },
      "content": "### E.19:End\n\n\n# **Part F — The Unification Suite (U‑Suite): Concept‑Sets, SenseCells & Contextual Role Assignment**\n\n# Cluster F.I — context of meaning & Raw Material\n",
      "metadata": {},
      "part": "E",
      "cluster": null
    },
    {
      "id": "F.0.1",
      "title": "Contextual Lexicon Principles",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## F.0.1 - Contextual Lexicon Principles\n\n> **One‑sentence summary.** All meanings in FPF are **local to a `U.BoundedContext`** (“Context of meaning”); terms are **spoken with their Context**, and any relation **across Contexts** exists **only** as an explicit **Alignment Bridge** with stated loss/fit.\n\n**Status.** Architectural pattern, architheory‑agnostic.\n**Builds on:** A.1.1 `U.BoundedContext` (formal frame); A.7 *Strict Distinction* (C‑6); A.8 *Universal Core* (C‑1); A.11 *Ontological Parsimony* (C‑5); A.4 *Temporal Duality* (C‑7); **E.10.D1 D.CTX** (lexical discipline for “Context”).\n**Coordinates with.** **F.1** (Context Map via Context Cards), **F.2** (local term capture), **F.3** (intra‑Context clustering), **F.7** (Concept‑Set Table), **F.9** (Alignment & Bridge), **B.3** (Trust & Assurance; CL penalties).\n\n> **Didactic note.** In the Tech register, **Context ≡ `U.BoundedContext`** (per E.10.D1). We use “Context of meaning” as a **metaphor only**; *Context* remains the normative short form for `U.BoundedContext`. The word **anchor** is not used in FPF.\n\n> **Didactic note.** In the Tech register, **Context ≡ `U.BoundedContext`** (per E.10.D1). We use “Context of meaning” as a **metaphor only**; *Context* remains the normative short form for `U.BoundedContext`. The word **anchor** is not used in FPF. The word *plane* is reserved to **CHR:ReferencePlane** only.\n\n**Terminology guard (normative, Part F).** The **row classifier** is **senseFamily**: {Role | Status | Measurement | Type‑structure | Method | Execution}. **Characteristic** (MM‑CHR) names measurable aspects only (A.17–A.19) and MUST NOT be used for row typing in Part F. Avoid the generic word **facet** in Part F; when unavoidable, reference **C.3.5 KindAT (informative facet)** or **Compose‑CAL `U.Facet`** explicitly. Only **CHR:ReferencePlane** is permitted (no bare “plane”); use **I/D/S layer** for intension/description/specification; use **stance** for design vs run.\n",
        "problem": "### F.0.1:1 - Problem Frame\n\nTrans‑disciplinary modelling fails without an explicit discipline for **where words mean what**.\n\n* **Semantic drift.** The same string (“process”, “role”, “service”) slides between domains and editions.\n* **Homonym collisions.** One label carries incompatible senses across fields.\n* **Hidden synonymy.** Different labels point to the same local sense, but the identity is unstated.\n* **Implicit globalism.** Meaning is treated as universal; integration silently re‑writes models.\n\nFPF resolves this by **localising** meaning first, then **explicitly translating** across locales.\n\n",
        "f.0.1:2___the_three_principles_(normative)": "### F.0.1:2 - The Three Principles (normative)\n\n#### F.0.1:2.1 - P‑S - **Source Localisation Principle** — *Speak with the Context.*\n\n**Rule.** Every term in a normative FPF artefact **MUST** be bound to a **specific `U.BoundedContext`** (its “Context of meaning”). The binding is explicit in text, notation, or table headers (e.g., **process (BPMN 2.0)**).\n\n**Implications.**\n\n* No free‑floating “global terms”.\n* A finite **Context Map** (see **F.1**) is chosen **before** naming work starts.\n* If a source intrinsically fixes time stance, the **design/run tag** is carried by the Context (C‑7).\n\n**Reasoning move (conceptual).**\n`Context(C) ∧ says(C, term t) ⊢ usable(t@C)`\n\n**Illustration (Enactment line).**\n`activity @ PROV‑O (run)` vs `task @ IEC 61131‑3 (run)` vs `process @ BPMN 2.0 (design)`.\n\n\n#### F.0.1:2.2 - P‑L - **Local Meaning Principle** — *Meaning lives inside the Context.*\n\n**Rule.** The **intended sense** of a term is established **inside its Context** as a **SenseCell**: a small, reconstructible unit of local meaning with **Tech/Plain labels** and a concise gloss. SenseCells are **lexical only** (C‑6): no behaviours, no deontics, no equations.\n\n**Implications.**\n\n* SenseCells are **Context‑scoped**; they do **not** cross Contexts.\n* Minimal generality (G‑1) and contextual specification (G‑2) govern naming inside the Context.\n* **Intra‑Context clustering** of raw mentions precedes any Cross‑context act (see **F.3**).\n\n**Reasoning move (conceptual).**\n`usable(t@C) ∧ fits(gloss, C) ⊢ SenseCell⟨t@C⟩`\n\n**Illustration (KD‑CAL).**\n`observation @ SOSA/SSN`: Tech “observation”, Plain “measurement act”; gloss “Result‑bearing act applying a Procedure…”.\n\n\n#### F.0.1:2.3 - P‑B - **Explicit Bridge Principle** — *across Contexts, only with a bridge.*\n\n**Rule.** Any relation between terms from **different** Contexts **MUST** be stated as an **Alignment Bridge** (see **F.9**): a named mapping between **SenseCell⟨-⟩** items with a declared **relation kind** (e.g., *overlaps*, *broader‑than*, *near‑equivalent*) and a **Congruence Level (CL)** for trust calculus (B.3).\n\n**Implications.**\n\n* No by‑name identity across Contexts; **string equality ≠ sense equality**.\n* Bridges carry **loss/fit notes** and are auditable; they can be revised by edition.\n* Concept‑Sets (F.7) are built **from bridged cells**, not from surface strings.\n\n**Reasoning move (conceptual).**\n`SenseCell⟨x@A⟩ ↔⟨rel, CL⟩ SenseCell⟨y@B⟩ ⊢ translatable(x@A, y@B, rel, CL)`\n\n**Illustration (Sys‑CAL × Enactment).**\n`actuation @ CTRL‑Text` ↔⟨near‑equiv, CL=2⟩ `control‑output @ IEC 61131‑3`.\n\n",
        "f.0.1:3___minimal_artefacts_(conceptual,_notationally_neutral)": "### F.0.1:3 - Minimal Artefacts (conceptual, notationally neutral)\n\n> These artefacts are **thought‑objects**; they specify **what must exist conceptually**, not how it is stored.\n\n#### F.0.1:3.1 - **Context Card** (for each `U.BoundedContext`)\n\nA terse descriptor used in the **Context Map** (F.1):\n\n* `id` (stable local handle) - `title` - `edition/year`\n* `family` (discipline family; informal) - `scope gist`\n* `timeStance?` (`design` / `run`, if inherent)\n* `trip‑wires` (few lexical caveats that often mislead, e.g., “*process*≠thermo process”)\n\n#### F.0.1:3.2 - **SenseCell** (unit of local meaning, inside one context)\n\n* `label.tech` / `label.plain` (two registers)\n* `gloss` (minimal generality, Context‑true)\n* `notes?` (warnings, edition shifts)\n* **No** behaviour/deontics/equations (C‑6)\n\n> **Where it comes from.** F.2 describes how SenseCells can be *derived* from local term evidence; F.0.1 only **requires** that local meaning be expressible as a SenseCell.\n\n#### F.0.1:3.3 - **Alignment Bridge** (between SenseCells from different Contexts)\n\n* `left: SenseCell⟨-@A⟩`, `right: SenseCell⟨-@B⟩`\n* `relation` (e.g., *equivalent‑under‑assumptions*, *overlaps*, *broader‑than*)\n* `CL` (Congruence Level; feeds B.3 Trust & Assurance)\n* `loss/fit` (explicit statement of what is lost or assumed)\n\n",
        "f.0.1:4___invariants_(normative)": "### F.0.1:4 - Invariants (normative)\n\n1. **I‑1 - Context‑qualified usage.** Every normative use of a term is **Context‑qualified** (directly or via table/section headers).\n2. **I‑2 - Local‑only cells.** A SenseCell belongs to **exactly one** Context.\n3. **I‑3 - senseFamily hygiene.** SenseCells are **lexical**; behaviour, deontics, measurements, proof steps live in their respective architheories (C‑6). \n4. **I‑4 - Time stance fidelity.** If a source fixes `design/run`, the Context Card **carries** it and SenseCells **inherit** it.\n5. **I‑5 - No implicit Cross‑context identity.** Cross‑context relations exist **only** as F.9 Bridges with `relation` and `CL`.\n6. **I‑6 - Parsimony & heterogeneity hook.** The Context Map is **finite**, **heterogeneous** (≥ 3 families per unification line), and **parsimonious** (F.1).\n\n",
        "f.0.1:5___reasoning_primitives_(judgement_schemata;_pure,_side‑effect‑free)": "### F.0.1:5 - Reasoning Primitives (judgement schemata; pure, side‑effect‑free)\n\n*These capture **allowable mental moves**; they do not prescribe storage, APIs, or workflow.*\n\n* **Context qualification**\n  `Context(C) ∧ mentions(C, s) ⊢ uses(s@C)`\n  *Reading:* If a string *s* is used under Context *C*, we treat it as the local term *s\\@C*.\n\n* **Local sense formation**\n  `uses(t@C) ∧ gloss_C(t) ⊢ SenseCell⟨t@C⟩`\n  *Reading:* A Context‑true gloss yields a SenseCell for *t* inside *C*.\n\n* **Admissible Cross‑context relation**\n  `SenseCell⟨x@A⟩ ∧ SenseCell⟨y@B⟩ ∧ declare(rel, CL) ⊢ Bridge(x@A, y@B, rel, CL)`\n  *Reading:* Only an explicit declaration generates a Bridge; no name‑matching inferences.\n\n* **Bridge‑to‑Concept‑Set hint** *(for F.7)*\n  `Bridge(x@A, y@B, rel≈equiv, CL≥k) ⊢ candidate_same_row(x, y)`\n  *Reading:* Strong, near‑equivalence bridges can *nominate* cells for one Concept‑Set row (final decision in F.7).\n\n",
        "f.0.1:6___didactic_metaphor_(informative)": "### F.0.1:6 - Didactic Metaphor (informative)\n\n* **Contexts.** Each `U.BoundedContext` is a **Context**; its **Context Card** is a sign on the door (name, edition, time stance, trip‑wires).\n* **Words in a Context.** A **SenseCell** is a dictionary entry pinned to that Context’s wall.\n* **Door‑to‑door links.** An **Alignment Bridge** is a labelled passage connecting two Contexts; a **CL** placard says how trustworthy that passage is.\n\n> *We first speak inside Contexts; only then decide which doors to connect—and with what warnings.*\n\n",
        "f.0.1:7___placement_&_flow": "### F.0.1:7 - Placement & Flow\n\n**F.0.1** is the **front door** of Part F. It enables:\n**F.1** (choosing Contexts with Context Cards) → **F.2** (deriving SenseCells inside each Context) → **F.3** (stabilising local senses) → **F.7** (building Concept‑Set rows) → **F.9** (stating Bridges).\n",
        "f.0.1:8___anti‑patterns_&_remedies": "### F.0.1:8 - Anti‑patterns & remedies\n\n| #       | Anti‑pattern (what goes wrong)   | Symptom in models                                          | Why harmful (conceptual)                            | Remedy (this pattern’s clause)                                                            |\n| ------- | -------------------------------- | ---------------------------------------------------------- | --------------------------------------------------- | ----------------------------------------------------------------------------------------- |\n| **A1**  | **Global term** (Contextless usage) | “process”, “service”, “role” used without a Context mark      | Meaning drifts; integration silently rewrites sense | **P‑S**: Always speak **term\\@context**; qualify via section/table headers if repeated       |\n| **A2**  | **String‑match identity**        | Equating *service* (ITIL) with *service* (web‑API) by name | String equality ≠ sense equality                    | **P‑B**: Cross‑context relations exist only as **Bridges** with `relation`+`CL`              |\n| **A3**  | **senseFamily mixing in SenseCell**    | Local glosses include behaviours, deontics, equations      | Violates **Strict Distinction** (C‑6); blocks reuse | **P‑L**: SenseCell is **lexical only**; behaviour/deontic math belongs to architheories   |\n| **A4**  | **Edition blur**                 | Citing “BPMN” or “ITIL” without edition                    | Underspecified Context; un‑auditable sense shift       | **Context Card** carries `edition/year`; treat materially changed editions as distinct Contexts |\n| **A5**  | **Context as type**              | Declaring “PROV‑O is‑a BPMN”                               | Implies inherited meanings between Contexts            | Contexts aren’t types; **no is‑a on Contexts** (E.10.D1). Use Bridges only                       |\n| **A6**  | **Bridge without loss/fit**      | Bridge declared as “equivalent” with no assumptions        | Users infer total identity; trust calculus blind    | **P‑B**: Bridge must state `relation` and `CL`, plus a brief **loss/fit** note            |\n| **A7**  | **Row from strings**             | Concept‑Set rows built from surface forms                  | Homonyms/synonyms contaminate rows                  | Build rows from **SenseCells**; add only cells connected by acceptable Bridges (F.7)      |\n| **A8**  | **Transitivity overreach**       | Chaining weak near‑equivalences as if exact                | Inflates sameness; hides mismatch                   | **Bridge composition** (Sec. 10): compose with **min‑CL** and keep relation weakening     |\n| **A9**  | **Domain ≡ Context**                | “Domain” name used as if it were a `U.BoundedContext`      | Domain families are informal; Contexts are formal      | Keep **Domain family** informative on Context Cards; meanings bind to **Contexts** only         |\n| **A10** | **Time‑stance confusion**        | Treating `design` and `run` senses as identical            | Crosses senseFamilies; erases execution/spec split         | Carry **time stance** on Context Cards; prefer `design‑spec‑of` / `run‑trace‑of` Bridges     |\n\n",
        "f.0.1:9___compact_worked_examples_(multi‑architheory)": "### F.0.1:9 - Compact worked examples (multi‑architheory)\n\n> *Each vignette shows (1) two Context Cards (abridged), (2) SenseCells inside Contexts, (3) the Bridge with relation & CL, and (4) a Concept‑Set hint (if any).*\n\n#### F.0.1:9.1 Enactment × Provenance — *process* vs *activity*\n\n* **Context A**: `BPMN_2_0` - *Business Process Model and Notation v2.0 (2011)* - *design*\n  **SenseCell⟨process\\@BPMN⟩**: Tech “process”; Plain “workflow process”; Gloss “graph of flow nodes/events executed by participants.”\n\n* **Context B**: `PROV_O_2013` - *W3C PROV‑O (2013)* - *run*\n  **SenseCell⟨activity\\@PROV⟩**: Tech “activity”; Plain “provenance activity”; Gloss “time‑bounded occurrence using/generating entities.”\n\n* **Bridge**: ⟨process\\@BPMN⟩ ↔⟨`design‑spec‑of`, **CL=2**, loss: “no concurrency semantics in trace”; fit: “maps to execution plan”⟩ ⟨activity\\@PROV⟩\n\n* **Concept‑Set hint**: *No* same‑row nomination (relation ≠ near‑equiv); instead, record a **design↔run** linkage.\n\n\n#### F.0.1:9.2 - Control × PLC runtime — *actuation* vs *control output*\n\n* **Context A**: `CTRL_Text_Classic` - *control theory primers* - *design*\n  **SenseCell⟨actuation\\@CTRL⟩**: Tech “actuation”; Plain “control output”; Gloss “signal applied to plant actuators.”\n\n* **Context B**: `IEC_61131_3` - *PLC languages* - *run*\n  **SenseCell⟨q‑output\\@IEC⟩**: Tech “control‑output”; Plain “PLC output”; Gloss “program‑produced output variable to field I/O.”\n\n* **Bridge**: ⟨actuation\\@CTRL⟩ ↔⟨`near‑equivalent`, **CL=2**, loss: “hardware/scan‑cycle specifics absent in CTRL”; fit: “semantics align under linear regime”⟩ ⟨q‑output\\@IEC⟩\n\n* **Concept‑Set hint**: *Candidate same‑row* (F.7) with note: “merge permitted at **CL≥2** threshold.”\n\n\n#### F.0.1:9.3 Measurement × Service — *observation* vs *service metric*\n\n* **Context A**: `SOSA_SSN_2017` - *sensing/observations* - *run*\n  **SenseCell⟨observation\\@SOSA⟩**: Tech “observation”; Plain “measurement act”.\n\n* **Context B**: `ITIL4_2020` - *services* - *(mixed)*\n  **SenseCell⟨slo‑metric\\@ITIL⟩**: Tech “service‑level metric”; Plain “service measure”; Gloss “quantity used to evaluate SLOs.”\n\n* **Bridge**: ⟨observation\\@SOSA⟩ ↔⟨`provides‑value‑for`, **CL=2**, loss: “organizational context not in SOSA”; fit: “metric results are measurement results.”⟩ ⟨slo‑metric\\@ITIL⟩\n\n* **Concept‑Set hint**: Not a same‑row case; this is a **role‑in‑use** relation (measurement feeds status evaluation).\n\n\n#### F.0.1:9.4 Type reasoning — *subclass‑of* (OWL) vs *is‑a (plain)*\n\n* **Context A**: `OWL2_Profiles` - *description logics*\n  **SenseCell⟨subclass\\@OWL⟩**: Tech “subclass‑of”; Plain “is‑a”.\n\n* **Context B**: `ENG_Glossary` - *engineering plain usage compendium*\n  **SenseCell⟨is‑a\\@ENG⟩**: Tech “is‑a (engineering)”; Plain “kind‑of”; Gloss “informal subsumption in specs.”\n\n* **Bridge**: ⟨subclass\\@OWL⟩ ↔⟨`near‑equivalent`, **CL=1**, loss: “OWL formal constraints absent in ENG”; fit: “intended subsumption semantics.”⟩ ⟨is‑a\\@ENG⟩\n\n* **Concept‑Set hint**: Keep separate rows unless the consuming artefact demands **formal** semantics.\n\n\n#### F.0.1:9.5 Deontics × Access — *permission* vs *role (RBAC)*\n\n* **Context A**: `ODRL_2_2` - *policy/deontics*\n  **SenseCell⟨permission\\@ODRL⟩**: Tech “permission”; Plain “allowed action”.\n\n* **Context B**: `NIST_RBAC_2004` - *access control*\n  **SenseCell⟨role\\@RBAC⟩**: Tech “access‑role”; Plain “permission set”.\n\n* **Bridge**: ⟨permission\\@ODRL⟩ ↔⟨`member‑of‑set‑in`, **CL=2**, loss: “contextual obligations not preserved”; fit: “RBAC roles aggregate permissions.”⟩ ⟨role\\@RBAC⟩\n\n* **Concept‑Set hint**: Not same row (different **kinds**); useful linkage for Enactment when binding duties to sessions.\n\n",
        "f.0.1:10___extended_reasoning_moves_(pure_judgement_schemata)": "### F.0.1:10 - Extended reasoning moves (pure judgement schemata)\n\n> *Judgements are conceptual entailments over Contexts, SenseCells, and Bridges. They carry no storage, workflow, or governance semantics.*\n\n#### F.0.1:10.1 - Context‑qualified use\n\n`Context(C) ∧ mentions(C, s) ⊢ uses(s@C)`\n*If s is used under Context C, we treat it as the local term s\\@C.*\n\n#### F.0.1:10.2 - Sense formation (local)\n\n`uses(t@C) ∧ gloss_C(t) ⊢ SenseCell⟨t@C⟩`\n*A Context‑true gloss yields a SenseCell inside C.*\n\n#### F.0.1:10.3 - Admissible Bridge (creation predicate)\n\n`SenseCell⟨x@A⟩ ∧ SenseCell⟨y@B⟩ ∧ A≠B ∧ rel∈R ∧ cl∈{0,1,2} ⊢ Bridge(x@A,y@B,rel,cl)`\n*Only explicit relation `rel` with Congruence Level `cl` constitutes a Bridge.*\n\n**Canonical relation set `R` (didactic catalogue):**\n`equivalent‑under‑assumptions` - `near‑equivalent` - `overlaps` - `broader‑than` - `narrower‑than` - `design‑spec‑of` - `run‑trace‑of` - `representation‑of` - `member‑of‑set‑in` - `provides‑value‑for`.\n\n#### F.0.1:10.4 - Bridge composition (attenuating)\n\n`Bridge(a,b,rel₁,cl₁) ∧ Bridge(b,c,rel₂,cl₂) ⊢ Bridge*(a,c,rel*,cl*)`\n\n* `cl* := min(cl₁, cl₂)` (do **not** inflate confidence)\n* `rel* := weaken(rel₁, rel₂)` (e.g., near‑equiv ∘ overlaps → overlaps)\n\n*Reading:* Chained passages degrade to the weakest link.\n\n#### F.0.1:10.5 - Non‑identity by stance\n\n`SenseCell⟨x@A(design)⟩ ∧ SenseCell⟨y@B(run)⟩ ∧ ¬declared(Bridge(x,y,near‑equiv,_)) ⊢ ¬same‑row(x,y)`\n*Different time stances forbid same‑row unless an explicit near‑equiv Bridge exists.*\n\n#### F.0.1:10.6 - Row viability (Concept‑Set candidacy)\n\n`Cells = {c₁…cₙ} ⊢ row‑viable(Cells) ⇔ connected(Cells, Bridges_{rel∈{equiv,near‑equiv}, cl≥k}) ∧ ¬contradiction(Cells)`\n\n*Reading:* A row is viable if its cells form a connected subgraph via sufficiently strong Bridges and contain no mutually exclusive links.\n\n#### F.0.1:10.7 - Contradiction sieve\n\n`Bridge(a,b,broader) ∧ Bridge(a,b,narrower) ⊢ contradiction(a,b)`\n*Incompatible relations across the same pair flag a contradiction for review (conceptually).*\n\n#### F.0.1:10.8 - Non‑bridge implication ban\n\n`name(x) = name(y) ∧ A≠B ⊢ ¬Bridge(x@A, y@B, _, _)`\n*String equality across Contexts never implies a Bridge.*\n\n",
        "f.0.1:11___scr/rscr_acceptance_checks_(conceptual)": "### F.0.1:11 - SCR/RSCR acceptance checks (conceptual)\n\n> *These checks are **content‑oriented**; they validate that a manuscript/model respects Part F principles. No process/tool assumptions are implied.*\n\n#### F.0.1:11.1 - SCR — Static conformance\n\n* **SCR‑F01 (Context‑qualified).** Every normative term is Context‑qualified (directly, or via a scoped header that unambiguously fixes the Context).\n* **SCR‑F02 (Local cells).** Each SenseCell belongs to **exactly one** Context; no cell aggregates Cross‑context **senses**.\n* **SCR‑F03 (senseFamily hygiene).** SenseCell glosses contain no behaviours/deontics/equations; those appear only in their architheories.\n* **SCR‑F04 (Bridges explicit).** Every Cross‑context relation appears as a Bridge with `relation` and `CL` and a short **loss/fit** note.\n* **SCR‑F05 (No string identity).** There is no use of string equality to stand in for Cross‑context identity.\n* **SCR‑F06 (Time stance fidelity).** Where a Context fixes `design/run`, the SenseCells and any Bridges reflect that stance explicitly.\n* **SCR‑F07 (Row viability).** Any Concept‑Set row shown is supported by a connected subgraph of Bridges with **CL ≥ threshold** and no contradictions.\n\n#### F.0.1:11.2 - RSCR — Regression & evolution\n\n* **RSCR‑F01 (Edition split).** When a source edition changes materially, SenseCells tied to the old edition remain; new cells bind to the new Context; Bridges are re‑assessed.\n* **RSCR‑F02 (Bridge stability).** If any Bridge endpoint changes gloss/stance, downgrade or retire the Bridge, documenting the **loss/fit** change.\n* **RSCR‑F03 (Composition guard).** When composing Bridges in a chain, the resulting `CL` never exceeds the minimal link; relation weakens monotonically.\n* **RSCR‑F04 (Heterogeneity + QD guard):** requires ≥3 domain‑families AND MinInterFamilyDistance ≥ δ_family (per the active F1‑Card edition), with QD‑triad evidence (publish Diversity_P and IlluminationSummary on the declared grid/kernel). Near‑alias pairs (per dSig rule) SHALL be flagged and excluded or merged before the guard is evaluated. Record the F1‑Card edition id.\n\n#### F.0.1:11.3 - Publish‑ready summary\n\nAn artefact is **ready** with respect to F.0.1 when:\n\n1. **SCR‑F01…F07** hold for all terms, cells, rows, and bridges it presents;\n2. **RSCR‑F01…F04** hold under simulated edition/stance changes;\n3. Every Cross‑context statement can be read as a **Bridge** or as a composition of Bridges with stated attenuation.\n\n",
        "f.0.1:12___quick_reference_(didactic)": "### F.0.1:12 - Quick reference (didactic)\n\n* **Context** = a `U.BoundedContext` with edition, scope, and (if inherent) time stance.\n* **SenseCell** = the minimal, lexical unit of meaning inside a Context (Tech/Plain labels + gloss).\n* **Bridge** = the only Cross‑context relation, labelled with `relation` and **CL**, plus a short loss/fit note.\n* **Concept‑Set row** = a didactic table row collecting **SenseCells** that are sufficiently the‑same‑thing under declared Bridges.\n\n> **Mental checklist:** *Name the Context → speak in the Context → connect Contexts only by labelled bridges → build rows from bridged cells.*\n",
        "f.0.1:end": "### F.0.1:End\n"
      },
      "content": "### F.0.1:End\n",
      "metadata": {},
      "part": "F",
      "cluster": null
    },
    {
      "id": "F.1",
      "title": "Domain‑Family Landscape Survey",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## F.1 - Domain‑Family Landscape Survey\n\n**“Fix the context of meaning before you name anything.”**\n**Status.** Architectural pattern, architheory‑agnostic.\n**Depends on.** E.10.D1 **Lexical Discipline for “Context” (D.CTX)**; **F.0.1 Contextual Lexicon Principles**; A.7 **Strict Distinction (Clarity Lattice)**; A.11 **Ontological Parsimony**.\n**Coordinates with.** F.2 **Term Harvesting & Normalisation**; F.3 **Intra‑Context Sense Clustering**; F.4 **Role Description**; F.9 **Alignment & Bridge Across Contexts**; **G.0–G.1** *(Scope/describedEntity handoff)*.  *(Bridges live only in F.9.)*\n\n**Aliases (informative).** *Contexts‑first survey*; *Context cut*.\n",
        "intent_&_applicability": "### F.2:1 - Intent & applicability\n\n**Intent.** Provide a **conceptual** (notation‑free) discipline for turning *Context‑internal usage* into **context‑local lexical units** ready for later reasoning—without Cross‑context merging and without slipping into governance or tooling. The result is a **small, auditable set of context‑local names and glosses** that faithfully reflect how the canon speaks.\n\n**Applicability.** Use whenever a unification line (from F.1) needs **actual words** to be referenced by patterns in Part C (architheories) or by Role Descriptions (F.4). Re‑enter F.2 when a canon/edition changes or when a new Context is admitted in F.1.\n\n**Non‑goals.** No global labels; no Cross‑context equivalence; no workflow or role descriptions; no storage/API talk. F.2 specifies **how to think**, not how to “run a pipeline”.\n\n",
        "problem": "### F.2:2 - Problem Frame\n\nEven with Contexts fixed (F.1), three mistakes recur:\n\n1. **Word‑centrism.** Treating a string as if it carried its meaning across Contexts (*process*, *role*, *service*).\n2. **Over‑normalisation.** Forcing one spelling/morphology across different canons, erasing Context‑specific cues.\n3. **Premature structure.** Smuggling behaviour, deontics, or type structures into what should remain **lexical**.\n\nF.2 prevents these by **localising** meaning and **naming** strictly **inside** each Context.\n\n",
        "forces": "### F.2:3 - Forces\n\n| Force                      | Tension to resolve                                                               |\n| -------------------------- | -------------------------------------------------------------------------------- |\n| **Uniformity vs locality** | Desire for consistent names vs Context‑specific idioms that must be preserved.      |\n| **Parsimony vs recall**    | Keep the harvested set small vs keep rare but pivotal terms that unlock bridges. |\n| **Didactics vs fidelity**  | Two‑register labels (tech/plain) vs fidelity to the canon’s own phraseology.     |\n| **Speed vs safety**        | Move fast to enable F.3/F.4 vs avoid any Cross‑context conclusion in F.2.           |\n\n",
        "core_idea_(didactic)": "### F.2:4 - Core idea (didactic)\n\n**Harvest *inside* each Context; name *in that Context’s idiom*; do not cross Contexts.**\nFor every Context (a **U.BoundedContext** from F.1), you gather **attested phrases** as *thought‑cues*, choose a **Local Normal Form (LNF)** that matches the Context’s idiom, attach a **two‑register label** (Tech/Plain), and write a **one‑sentence gloss**. That’s all. You do **not** claim sameness with any other Context; you do **not** embed behaviour or deontics; you do **not** mint U.Types here. These *local lexical units* will become **Local‑Senses** in F.3 and later addressable **SenseCells** (Context × Local‑Sense).\n\n",
        "minimal_vocabulary_(this_pattern_only)": "### F.2:5 - Minimal vocabulary (this pattern only)\n\n* **Context** — Tech‑register alias for **U.BoundedContext** (per E.10.D1).\n* **Attested phrase** — A short, verbatim cue from the canon that shows how a word is used **in this Context** (citation idea, not a record format).\n* **Local Normal Form (LNF)** — The Context‑specific canonical surface you will use when referring to the term in this Context (minimal editing: spelling/hyphenation/casing per the canon).\n* **Two‑register label** — **Tech** (engineer‑facing) and **Plain** (pedagogic) forms for the same Context‑local meaning.\n* **Gloss (one‑sentence)** — A **Context‑faithful** description of how the canon uses the term, at **minimal generality**.\n* **Local lexical unit** — The quintet *(Context, LNF, Tech, Plain, Gloss)*. This is F.2’s only outcome.\n* **Homonymy (signal)** — Awareness that the **same string** has **different local lexical units** across Contexts (no relation asserted).\n* **SenseCell** *(appears downstream)* — Address **(Context × Local‑Sense)** minted in F.3; mentioned here so you know what you’re preparing.\n\n> *Everything above is a way of thinking. None of it implies a database, statuses, or roles.*\n\n",
        "solution": "### F.2:6 - Solution — three mental moves (notation‑free)\n\n#### F.2:6.1 - Move A — **Localise the word**\n\n**Question to ask.** *“In which Context am I hearing this word?”*\n**Action (mental).** Point to a specific **Context** (from F.1). Grab 1–2 **attested phrases** that are representative **in this Context**.\n**Outcome.** You stop thinking “global word” and start thinking “context‑local usage”.\n\n*Micro‑cue.* If you cannot name the Context, do not harvest the word.\n\n\n#### F.2:6.2 -Move B — **Name it in the Context’s idiom**\n\n**Question to ask.** *“How would this Context itself write it?”*\n**Action (mental).** Choose the **LNF** (Context‑conformant spelling/hyphenation). Then write the **two‑register label** and a **one‑sentence gloss** that says **what the canon means here**—nothing more.\n**Outcome.** You have a **local lexical unit** *(Context, LNF, Tech, Plain, Gloss)*.\n\n*Micro‑cues.*\n• Prefer the canon’s head noun; keep canonical hyphens; avoid invented compounds.\n• The **Plain** label should help a non‑specialist; the **Tech** label should match engineers’ eyes.\n• The **Gloss** must fit on a single line; defer details to F.3.\n\n\n#### F.2:6.2 - Move C — **Fence it off**\n\n**Question to ask.** *“What must I refuse to conclude here?”*\n**Action (mental).** Explicitly **refuse** to: (1) compare across Contexts, (2) fold morphology that the canon treats as meaningful, (3) embed behaviour, deontics, or type structure.\n**Outcome.** A clean, **context‑local** lexical unit that will be safe to cluster in F.3 and safe to bridge (or not) in F.9.\n\n",
        "what_to_record_(conceptual,_not_clerical)": "### F.1:7 - What to record (conceptual, not clerical)\n\n**7.1 The two‑minute memory.**\nEverything you need to *think correctly later* fits on an eight‑line card. No registries, no workflows, no storage choices.\n\n**7.2 The Context Card (one‑screen sketch).**\n*(Each bullet is a thought, not a field.)*\n\n* **Name & edition.** *“BPMN 2.0 (2011)”* • *“W3C PROV‑O (2013)”* • *“ITIL 4 (2020)”*.\n* **Domain family.** *workflow* / *provenance* / *services* / *deontics* / *sensing* / *types* / *control* … *(informative only; never used to infer meaning).*\n* **Scope gist** *(didactic; ≠ `USM.ScopeSlice(G)`)*. One line that marks the **inside/outside** (“workflow **graphs & participants**”, “provenance **entities/activities/agents**”).\n* **Time stance** *(if inherent)*. Does the canon speak **design** (specifications, models) or **run** (occurrences, acts)?\n* **Lexical trip‑wires.** Known homonyms or false friends in this Context (*“process ≠ thermodynamic process”*, *“role (RBAC) ≠ behavioural role”*).\n* **Neighbour Contexts** *(informative)*. Close cousins that people often conflate (*BPMN ↔ PROV‑O*, *ITIL ↔ ODRL*).\n* **Recency note.** *Current* / *superseded* / *candidate* (only as a reminder to yourself which text you mean).\n* **Why this Context matters here.** One sentence linking to your unification line (“we will name Executions later; PROV‑O keeps them run‑time”).\n* **Diversity signature (dSig).** A 5‑characteristics discrete signature for `U.BoundedContext`: **[Sector, Function, Archetype, Regime, MetricFamily]**. Authors SHOULD pick from local discipline taxonomies. **Publish a `dSigSource` list (five refs/URIs, one per axis) on every Card**, falling back to free‑text only where no canonical term exists. Two Contexts are flagged as **Near‑Duplicate** when ≥3 characteristics match. Publish `dSig` and `dSigSource` on every Card.\n\n> *If your Card spills beyond a screen, you are collecting facts, not fixing meaning.*\n\nF1‑Card (normative artefact): { taxonomyRef, embeddingRef, DistanceDef, δ_family, confidenceBand, calibrationSet, edition, subFamilyDef? }. subFamilyDef (optional): declares the stable partitioning below a domain‑family (e.g., taxonomic sub‑fields or CVT clusters with parent family anchors).  When HET‑FIRST quotas refer to “sub‑family”, they MUST use this declared subFamilyDef.\nDeclare **DomainDistance** policy (cosine or transport) and δ_family threshold; version as part of DescriptorMapRef. Publish `confidenceBand` (e.g., CI90%) for the calibrated `δ_family`; treat numbers in examples as illustrative, not normative.\n",
        "invariants_(normative,_lightweight)": "### F.1:8 - Invariants (normative, lightweight)\n\n1. **Context ≡ U.BoundedContext.** In this pattern, *Context* always means **U.BoundedContext** (per E.10.D1).\n2. **Locality.** Words are **local to their Context**; no global meaning is implied or imported.\n3. **Heterogeneity.** Each unification line considers **≥ 3 distinct Domain families** (labels are informative only).\n4. **Parsimony.** Prefer few, canonical Contexts per family (1–3) that jointly expose the key sense splits.\n5. **No bridging here.** No equivalence or mapping is asserted between Contexts in F.1. (Bridges live in **F.9**.)\n6. **Design/run honesty.** If a canon fixes a DesignRunTag, note it. Do not reinterpret.\n7. **Didactic primacy.** Each Context Card must be readable by a thoughtful engineer in **under two minutes**.\n8. **Domain‑family neutrality.** Domain families **carry no semantics**; they SHALL NOT be used for inheritance, inference, or bridge implication.\n9. **Scope naming separation.** `Scope gist` on Cards is **didactic only**; formal *Scope/describedEntity* (=`USM.ScopeSlice(G)` ⊕ `describedEntity(GroundingHolon, ReferencePlane)`) is declared **in G.0–G.1**, not in F.1.\n10. **Diversity signature present.** Each Context Card PUBLISHES a `dSig` in the 5‑characteristics form.\n11. **Collision rule.** If any pair of Cards has `dSig` matching on ≥3 characteristics, mark **Near‑Duplicate** and either merge  into one slot or replace one by a Context from a different domain‑family. Record action in SCR.\n",
        "self‑checks_(mental,_not_procedural)": "### F.1:9 - Self‑checks (mental, not procedural)\n\n* **The mirror test.** Can you explain *why each Context is inside* your cut **in one breath**? If not, you are surveying for comfort, not for meaning.\n* **The homonym ping.** For each frequent word (*process*, *role*, *service*, *model*, *execution*), can you immediately list **the Contexts where it differs**? If not, add the missing Context.\n* **The bridge itch.** Feel a strong urge to say “these are the same”? Good. **Write the itch down** and refuse to scratch it here. That’s F.9’s job.\n* **The memory rule.** If your entire survey cannot be recalled **without opening a document**, it is too large.\n\n",
        "micro‑examples_(illustrative_only)": "### F.1:10 - Micro‑examples (illustrative only)\n\n*One unification line: Enactment (`U.RoleAssignment` + `U.RoleEnactment`) with sensing and execution.*\n\n* **BPMN 2.0 (2011)** — *workflow family*.\n  *Scope gist:* flow nodes, sequence flows, participants (design‑time).\n  *Trip‑wires:* “process” here is a **graph**; not a run.\n* **W3C PROV‑O (2013)** — *provenance family*.\n  *Scope gist:* **Activity** that uses/generates entities (run‑time).\n  *Trip‑wires:* “activity/process” here is a **temporal occurrence**.\n* **ITIL 4 (2020)** — *services family*.\n  *Scope gist:* service as value co‑creation; SLO/SLA (deontic talk nearby).\n  *Trip‑wires:* “incident/problem/practice” don’t equal workflow tasks.\n* **ODRL 2.2** — *deontics family*.\n  *Scope gist:* permissions, prohibitions, duties (design).\n  *Trip‑wires:* “duty/obligation” ≠ service guarantee mechanics.\n* **SOSA/SSN (2017)** — *sensing family*.\n  *Scope gist:* Observation as an act yielding a Result for a property.\n  *Trip‑wires:* “observation” ≠ “state”; it’s an **act** with a **procedure**.\n* **IEC 61131‑3** — *control languages family*.\n  *Scope gist:* tasks that **execute** programs (run‑time).\n  *Trip‑wires:* “task/execution” ≠ “workflow process”.\n\n> With only these Contexts fixed, later steps become almost mechanical: F.2 harvests terms **inside** each Context; F.3 clusters **within** each Context; F.4 names roles/statuses pointing to **SenseCells**; F.9 draws the bridges you refused to draw here.\n",
        "anti‑patterns_&_remedies": "### F.2:10 - Anti‑patterns & remedies\n\n| #       | Anti‑pattern                 | Symptom (in thought or prose)                                        | Why harmful                                                  | Remedy (conceptual move)                                                                                |\n| ------- | ---------------------------- | -------------------------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------- |\n| **A1**  | **Global normal form**       | One “canonical” label reused across Contexts.                           | Erases local meaning; invites stealth bridges.               | Keep **LNF per Context**; any Cross‑context relation belongs to **F.9** only.                                 |\n| **A2**  | **String = meaning**         | Assuming identical strings denote one concept across Contexts.          | Homonym collision (*process*, *role*, *service*).            | Always prefix mentally with the **Context**; treat same string in different Contexts as **different units**.  |\n| **A3**  | **Over‑normalisation**       | Folding hyphens/case/morphology “for consistency”.                   | Loses the canon’s idiom; breaks citations.                   | **Minimal edits** toward the Context’s idiom; never toward a global house‑style.                           |\n| **A4**  | **Headless multiword**       | Truncating to a head (“objective” for “service‑level objective”).    | Ambiguity; collapses scope.                                  | Preserve canonical **head‑modifier** as LNF when meaningful.                                            |\n| **A5**  | **Premature structure**      | Embedding behaviour, deontics, units, or type axioms into the gloss. | I/D/S layer mixing (violates A.7); biases later patterns.          | Gloss **usage**, not calculus; structural content belongs to architheories in Part C.                   |\n| **A6**  | **Cross‑context folding**       | “BPMN workflow ≈ PROV activity” written inside F.2.                   | Hidden bridge; unpriced losses.                              | No Cross‑context claims in F.2; write the **itch to bridge** for **F.9**.                                  |\n| **A7**  | **Edition blur**             | “BPMN” without year/profile; mixing excerpts across editions.        | Silent sense shift; unrepeatable reasoning.                  | Treat distinct editions as **distinct Contexts** in F.1, then harvest.                                     |\n| **A8**  | **Vendor‑dialect elevation** | Treating a DSL/keyword list as “the domain”.                         | Projectionism; narrow idiom dominates.                       | If needed, model the DSL as **one context among others**; keep heterogeneity from F.1.                     |\n| **A9**  | **Tail chasing**             | Harvesting hundreds of rare terms.                                   | Cognitive overload; dilutes signal.                          | Keep **head terms** that feed F.3/F.4/F.9; justify rare units by their bridging value.                  |\n| **A10** | **Fake symmetry**            | Tech and Plain labels are identical jargon.                          | Didactic failure.                                            | Make **Plain** genuinely explanatory; keep **Tech** faithful to the canon.                              |\n| **A11** | **Temporal fudge**           | Using run‑time words in design Contexts (or vice versa).                | Category drift; later contradictions.                        | Respect the Context’s **DesignRunTag** from its Card (F.1 §7.2).                                      |\n| **A12** | **Cross‑language collapse**  | Merging bilingual terms as one unit.                                 | Erases idiom‑specific signals; hides normative mapping gaps. | Treat each language edition as its **own Context** unless the canon declares a normative mapping.          |\n| **A13** | **Alias inflation**          | Inventing new local names “for clarity”.                             | Strays from the canon; hinders bridging.                     | Prefer the canon’s idiom; keep invented phrasings to the **Plain** register only.                       |\n| **A14** | **Role/status conflation**   | RBAC “role” glossed as behavioural role.                             | Cross‑family bleed; wrong assignment later.                         | Call out the Context in the label: **access‑role (RBAC)** vs **participant (BPMN)**; keep senses disjoint. |\n\n",
        "worked_examples_(multi‑architheory_cuts)": "### F.1:12 - Worked examples (multi‑architheory cuts)\n\n> Each example shows **the cut** (the Contexts you keep in view) and the **thinking pay‑off** you get *before* any harvesting, clustering, or bridging.\n\n#### F.1:12.1 Enactment (`U.RoleAssignment` + `U.RoleEnactment`) with sensing & execution (service acceptance)\n\n**Unification line.** Enactment + KD‑CAL (sensing) + Sys‑CAL (execution).\n\n**Contexts (six Cards).**\n\n1. **BPMN 2.0 (2011)** — workflow family; **design**; *graph of flow nodes, participants*.\n2. **PROV‑O (2013)** — provenance family; **run**; *Activity uses/generates Entities; Agents*.\n3. **ITIL 4 (2020)** — services family; **design**; *service, SLO/SLA vocabulary*.\n4. **ODRL 2.2** — deontics family; **design**; *permission / prohibition / duty*.\n5. **SOSA/SSN (2017)** — sensing family; **run**; *Observation as act with Result*.\n6. **IEC 61131‑3** — control languages; **run**; *tasks execute control programs*.\n\n**Thinking pay‑off (examples).**\n\n* You stop saying “*process uptime*” and think **Execution (IEC)** measured by **Observation (SOSA)** compared against **SLO (ITIL)**—three Contexts, three senses.\n* You mark a trip‑wire: **RBAC role** (not in this cut) is *not* a **behavioural role (BPMN participant)**.\n* You resist equating **PROV Activity** with **BPMN workflow**; later **F.9** may relate them with explicit loss.\n\n\n#### F.1:12.2 Method quartet with types & measurement (model state graph)\n\n**Unification line.** Method‑CAL + Kind-CAL + KD‑CAL.\n\n**Contexts (five Cards).**\n\n1. **SPEM 2.0 / ISO 24744** — methods family; **design**; *Method / MethodDescription language*.\n2. **OWL 2 (profiles)** — types family; **design**; *class, subclass, equivalent class*.\n3. **FCA corpus** — types family; **design**; *concept lattices*.\n4. **SOSA/SSN (2017)** — sensing family; **run**; *Observation / Procedure*.\n5. **ISO 80000‑1 (2022)** — metrology family; **design**; *quantity kinds, units*.\n\n**Thinking pay‑off.**\n\n* You keep **Method** (abstract how‑to) separate from **MethodDescription** (epistemic recipe) and **Execution** (run) because the Contexts already split design vs run.\n* You avoid treating **FCA “concept”** as a **U.Type**; later F.9 can bridge OWL classes to FCA concepts with cautions.\n\n\n#### F.1:12.3 Control & actuation with services (operational SLOs in plants)\n\n**Unification line.** Sys‑CAL + LCA‑CAL (planned) + services/deontics.\n\n**Contexts (five Cards).**\n\n1. **State‑space control texts** — control family; **design**; *controller/plant, feedback*.\n2. **IEC 61131‑3** — control languages; **run**; *task, program execution*.\n3. **ISA‑95** — integration family; **design**; *levelled layers, interfaces*.\n4. **ITIL 4 (2020)** — services family; **design**; *SLO/SLA*.\n5. **SOSA/SSN (2017)** — sensing family; **run**; *Observation*.\n\n**Thinking pay‑off.**\n\n* “**Actuation**” is recognised as **control output** (Sys‑CAL), not a *service promise*.\n* “**Incident**” (ITIL) is not a plant *fault* (Sys‑CAL); Contexts deter category errors.\n\n",
        "reasoning_primitives_(judgement_schemas,_notation‑free)": "### F.2:12 - Reasoning primitives (judgement schemas, notation‑free)\n\n> Read each as a **permitted mental move** over the outcomes of F.2.\n> Symbols: `R` = Context (U.BoundedContext), `u` = local lexical unit, `s` = surface string.\n\n1. **Localisation**\n   `heard(s) ∧ R chosen ⊢ localize(s,R)`\n   *You decide to hear `s` only **in** Context `R`.*\n\n2. **Context‑idiom normalisation**\n   `localize(s,R) ⊢ LNF_R(s) = ℓ`\n   *Within `R`, the **Local Normal Form** for `s` is `ℓ`.*\n\n3. **Unit formation**\n   `LNF_R(s)=ℓ ∧ labelTech=t ∧ labelPlain=p ∧ gloss=g ⊢ unit(u) = ⟨R,ℓ,t,p,g⟩`\n   *A **local lexical unit** is formed (quintet).*\n\n4. **Lexical‑only guard**\n   `unit(u) ⊢ lexicalOnly(u)`\n   *No behavioural/deontic/type math is attached to the gloss.*\n\n5. **Homonymy signal (Cross‑context)**\n   `LNF_Ra(s)=ℓa ∧ LNF_Rb(s)=ℓb ∧ Ra≠Rb ⊢ homonymy(s) ⊇ {Ra,Rb}`\n   *Same string across Contexts is flagged as **different** by default.*\n\n6. **Minimal generality check**\n   `unit(u) ⊢ minimal(u) ⇔ gloss(u) says no more than the Context’s usage requires`\n   *The gloss fits the Context; broader claims are withheld.*\n\n7. **Two‑register adequacy**\n   `unit(u) ⊢ didactic(u) ⇔ (tech(u) faithful) ∧ (plain(u) explanatory)`\n   *Tech stays canonical; Plain helps non‑specialists.*\n\n8. **No Cross‑context conclusion**\n   `unit(u@Ra), unit(v@Rb), Ra≠Rb ⊢ ¬(u ≡ v) (within F.2)`\n   *F.2 never asserts Cross‑context equivalence.*\n\n9. **Ready‑for‑F.3 signal**\n   `lexicalOnly(u) ∧ minimal(u) ∧ didactic(u) ⊢ readyF3(u)`\n   *A unit is suitable input for **intra‑Context clustering** in F.3.*\n\n",
        "f1‑card_example_(informative)": "### F.1:14 - F1‑Card example (informative)\n```\nF1-Card v2025‑Q3:\n  taxonomyRef: OpenAlex topics/fields (snapshot 2025‑08)\n  embeddingRef: SPECTER2(2023) fine‑tuned@OA‑2025‑08\n  DistanceDef: cosine on centroid embeddings (window 36 mo)\n  δ_family: 0.35 (calibrated on control set; CI90% [0.33,0.37])\n  calibrationSet: 120 labeled pairs (same vs different families)\n  edition: 2025‑Q3\n```",
        "relations": "### F.2:13 - Relations\n\n**Builds on:**\n**F.1** (Contexts fixed; heterogeneity/parsimony in place).\n**E.10.D1 D.CTX** (Context ≡ U.BoundedContext; “Problem Frame” reserved for narrative).\n**F.0.1** (Source - Local Meaning - Bridge‑Only Crossing).\n\n**Constrains:**\n**F.3** (Intra‑Context Sense Clustering): operates **only** on units **from one Context**; produces Local‑Senses and addressable **SenseCells**.\n**F.4** (Role Description Definition): may **cite SenseCells**, not raw strings.\n**F.9** (Alignment & Bridge): consumes **homonymy signals**; declares explicit Cross‑context mappings with loss policies.\n\n**Used by.**\nArchitheories in Part C when referencing domain idioms (labels stay **context‑local**).\n\n",
        "migration_notes_(conceptual)": "### F.2:14 - Migration notes (conceptual)\n\n1. **New edition appears.** Add a Context in F.1; harvest afresh in F.2 using that Context; do not overwrite earlier units.\n2. **Idiomatic update discovered.** If your LNF fought the canon’s idiom, **re‑LNF** within the same context; keep labels/glosses steady unless the canon itself differs.\n3. **Ambiguity inside a Context.** If use splits, **mint two units** with distinct glosses; F.3 will sort their relation (same/different Local‑Sense).\n4. **Language split.** Treat each language canon as its **own Context**; resist cross‑language merges in F.2.\n5. **Tail pruning.** If units accumulate without feeding F.3/F.4/F.9, drop them from the working set; keep head terms that carry bridges.\n6. **DSL quarantine.** If a tool dialect is unavoidable, keep it as one context among others; never let it define the idiom for other Contexts.\n\n",
        "acceptance_tests_(scr/rscr_—_concept‑level)": "### F.2:15 - Acceptance tests (SCR/RSCR — concept‑level)\n\n#### F.2:15.1 - Static conformance (SCR)\n\n* **SCR‑F2‑S01 (context‑locality).** Every unit cites a Context from F.1.\n* **SCR‑F2‑S02 (Idiomatic LNF).** Each LNF reflects the Context’s spelling/hyphenation/casing with **minimal edits**.\n* **SCR‑F2‑S03 (Two registers).** Each unit carries both **Tech** and **Plain** labels; if not, a reason exists tied to didactics.\n* **SCR‑F2‑S04 (Lexical‑only).** No gloss contains behaviour, deontics, measurement math, or type axioms.\n* **SCR‑F2‑S05 (No Cross‑context claims).** Nowhere does F.2 assert equivalence/similarity/subsumption across Contexts.\n* **SCR‑F2‑S06 (Minimal generality).** Glosses match the Context’s use; no globalisation.\n* **SCR‑F2‑S07 (Temporal honesty).** For Contexts with fixed DesignRunTag, units and glosses respect it.\n\n#### F.2:15.2 - Regression (RSCR)\n\n* **RSCR‑F2‑E01 (Edition split).** Introducing a new edition yields new units under a new Context; earlier units persist unchanged.\n* **RSCR‑F2‑E02 (Normaliser stability).** Adjusting an LNF does not silently widen/narrow the gloss.\n* **RSCR‑F2‑E03 (Language split).** Adding a second language yields a second Context; no bilingual collapse in F.2.\n* **RSCR‑F2‑E04 (No stealth bridges).** After updates, F.2 still contains **zero** Cross‑context identity claims; any mapping appears only in F.9.\n* **RSCR‑F2‑E05 (Head‑term focus).** Periodic check shows the unit set remains small and oriented to F.3/F.4/F.9 needs.\n\n",
        "didactic_distillation_(90‑second_teaching_script)": "### F.1:18 - Didactic distillation (90‑second teaching script)\n\n> “Before you name anything, **fix the context of meaning**. A *Context* is a **U.BoundedContext** tied to a specific canon—*BPMN 2.0*, *PROV‑O*, *ITIL 4*, *SOSA/SSN*, *IEC 61131‑3*, *OWL 2*. Words are **local to Contexts**: *process (BPMN)* is a workflow graph, *activity (PROV)* is a run‑time occurrence, *service (ITIL)* is a promise vocabulary. Cut the landscape so each unification line sees **at least three domain families**, with **one‑screen Cards** per Context (scope gist, time stance, trip‑wires). **Do not bridge** Contexts here—just write down the itch to bridge and defer it. Keep the cut **small enough to remember**. With Contexts fixed, harvesting (F.2), local clustering (F.3), role/status templates (F.4), and explicit Cross‑context bridges (F.9) become straightforward—and you avoid naming ghosts that come from words floating without walls.”\n",
        "f.1:end": "### F.1:End\n\n## F.2 — Term Harvesting & Normalisation\n\n**“Harvest words *inside Contexts*, name them in the Context’s own idiom, and stop there.”**\n**Status.** Architectural pattern, architheory‑agnostic.\n**Depends on.** E.10.D1 **Lexical Discipline for “Context” (D.CTX)**; **F.0.1 Contextual Lexicon Principles** (Source - Local Meaning - Bridge‑Only Crossing); A.7 **Strict Distinction**; A.11 **Ontological Parsimony**.\n**Coordinates with.** F.1 **Context Map via Context Cards**; F.3 **Intra‑Context Sense Clustering**; F.4 **Role Description**; F.9 **Alignment & Bridge Across Contexts**.\n**Aliases (informative).** *context‑local harvesting*; *Local normalisation*.\n\n",
        "guard‑rails_(normative,_lightweight)": "### F.2:7 - Guard‑rails (normative, lightweight)\n\n1. **context‑locality.** Every local lexical unit **MUST** cite a Context (U.BoundedContext from F.1).\n2. **Context‑idiom normalisation.** LNF **MUST** respect the Context’s idiom (spelling/hyphenation/casing) and use **minimal edits**.\n3. **Two registers.** Each unit **SHOULD** carry both **Tech** and **Plain** labels for didactics; if one is missing, justify.\n4. **Minimal generality (G‑1).** The gloss **MUST** be as specific as the Context’s canon requires—no broader.\n5. **I/D/S layer hygiene (A.7).** **MUST NOT** include behaviour equations, deontic rules, measurement math, or type axioms; those belong to architheories.\n6. **No Cross‑context claims.** **MUST NOT** assert equivalence, subsumption, or similarity with terms in other Contexts (F.9 only).\n7. **Edition honesty.** If the Context’s canon has multiple editions with shifting usage, treat them as distinct Contexts in F.1 before harvesting.\n8. **Parsimony.** Prefer **few, telling** lexical units over long tails; keep head terms that will power F.3/F.4/F.9.\n\n",
        "micro‑examples_(illustrative,_context‑local)": "### F.2:8 - Micro‑examples (illustrative, context‑local)\n\n> Each line is *one* local lexical unit. No relations are implied across lines.\n\n* **Context:** *BPMN 2.0 (2011)* — **LNF:** `process`\n  **Tech:** `process` - **Plain:** `workflow process`\n  **Gloss:** “Directed graph of flow nodes and sequence flows enacted by participants.”\n\n* **Context:** *PROV‑O (2013)* — **LNF:** `activity`\n  **Tech:** `activity` - **Plain:** `temporal occurrence`\n  **Gloss:** “Time‑bounded occurrence that uses and generates entities and is linked to agents.”\n\n* **Context:** *ITIL 4 (2020)* — **LNF:** `service‑level‑objective`\n  **Tech:** `service‑level‑objective` - **Plain:** `service target`\n  **Gloss:** “Target value for a service characteristic within a service promise vocabulary.”\n\n* **Context:** *NIST RBAC (2004)* — **LNF:** `role`\n  **Tech:** `access‑role` - **Plain:** `permission role`\n  **Gloss:** “Named grouping of permissions assignable via sessions.”\n\n* **Context:** *SOSA/SSN (2017)* — **LNF:** `observation`\n  **Tech:** `observation` - **Plain:** `measurement act`\n  **Gloss:** “Act applying a procedure to a feature of interest to produce a result.”\n\n* **Context:** *IEC 61131‑3* — **LNF:** `task`\n  **Tech:** `task` - **Plain:** `runtime program execution`\n  **Gloss:** “Cyclic or event‑driven execution unit for control programs.”\n\n",
        "didactic_heuristics_(informative)": "### F.2:9 - Didactic heuristics (informative)\n\n* **Keep the Context prefix in your inner speech.** Say “*process (BPMN)*”, “*activity (PROV)*”.\n* **Prefer head nouns.** If the canon says “service‑level objective”, do not shorten it to “objective”.\n* **Resist elegance that erases signal.** Hyphens and case often carry the Context’s culture; keep them.\n* **Gloss from use, not from opinion.** Quote in your mind, then compress; avoid importing definitions from neighbouring Contexts.\n",
        "worked_examples_(multi‑architheory,_context‑local_only)": "### F.2:11 - Worked examples (multi‑architheory, context‑local only)\n\n> Each line is a **local lexical unit** *(Context, LNF, Tech, Plain, Gloss)*.\n> No Cross‑context relation is implied. Later clustering (F.3) and bridges (F.9) may connect them.\n\n#### F.2:11.1 Enactment + sensing\n\n* **Context:** *BPMN 2.0 (2011)* — **LNF:** `process`\n  **Tech:** `process` - **Plain:** `workflow process`\n  **Gloss:** “Directed graph of flow nodes and sequence flows enacted by participants.”\n\n* **Context:** *PROV‑O (2013)* — **LNF:** `activity`\n  **Tech:** `activity` - **Plain:** `temporal occurrence`\n  **Gloss:** “Time‑bounded occurrence that uses and generates entities and links to agents.”\n\n* **Context:** *SOSA/SSN (2017)* — **LNF:** `observation`\n  **Tech:** `observation` - **Plain:** `measurement act`\n  **Gloss:** “Act applying a procedure to a feature of interest to produce a result.”\n\n* **Context:** *ITIL 4 (2020)* — **LNF:** `service‑level‑objective`\n  **Tech:** `service‑level‑objective` - **Plain:** `service target`\n  **Gloss:** “Target value for a service characteristic within a service promise vocabulary.”\n\n*Thinking pay‑off:* you can phrase “compare **observation** to **service‑level‑objective**” without importing workflow or provenance semantics.\n\n\n#### F.2:11.2 Sys‑CAL / LCA‑CAL + services\n\n* **Context:** *State‑space control texts* — **LNF:** `actuation`\n  **Tech:** `actuation` - **Plain:** `control output`\n  **Gloss:** “Signal applied to the plant to influence state/output.”\n\n* **Context:** *IEC 61131‑3* — **LNF:** `task`\n  **Tech:** `task` - **Plain:** `runtime program execution`\n  **Gloss:** “Cyclic or event‑driven execution unit for control programs.”\n\n* **Context:** *ITIL 4 (2020)* — **LNF:** `incident`\n  **Tech:** `incident` - **Plain:** `reported disruption`\n  **Gloss:** “Unplanned interruption or reduction in the quality of a service.”\n\n*Thinking pay‑off:* avoids calling a plant fault an “incident” unless you **cross Contexts later** with an explicit bridge.\n\n\n#### F.2:11.3 Kind-CAL + Method‑CAL + KD‑CAL\n\n* **Context:** *OWL 2 (profiles)* — **LNF:** `subclass‑of`\n  **Tech:** `subclass‑of` - **Plain:** `is‑a (type hierarchy)`\n  **Gloss:** “C ⊑ D: every instance of C is an instance of D.”\n\n* **Context:** *FCA corpus* — **LNF:** `formal‑concept`\n  **Tech:** `formal‑concept` - **Plain:** `extent–intent node`\n  **Gloss:** “Maximal (objects, attributes) pair under a Galois connection.”\n\n* **Context:** *SPEM 2.0 / ISO 24744* — **LNF:** `method`\n  **Tech:** `method` - **Plain:** `abstract way of doing`\n  **Gloss:** “Abstract how‑to independent of specification or execution.”\n\n* **Context:** *SOSA/SSN (2017)* — **LNF:** `procedure`\n  **Tech:** `procedure` - **Plain:** `measurement recipe`\n  **Gloss:** “Specification guiding how an observation is produced.”\n\n*Thinking pay‑off:* discourages treating an FCA “concept” as a `U.Type`, or a **procedure** as a **method** without later proof.\n\n",
        "didactic_distillation_(60‑second_script)": "### F.2:16 - Didactic distillation (60‑second script)\n\n> “In F.2 you **harvest inside Contexts**. For each Context, pick the canon’s own phrasing, choose a **Local Normal Form** in that idiom, add **Tech** and **Plain** labels, and write a one‑sentence **Gloss** that matches how that Context talks. Stop there. No bridging, no behaviour, no equations. If the same string appears in another Context, treat it as a **different unit**. These units feed F.3, where you’ll sort senses **within** a Context, and F.9, where you’ll relate Contexts explicitly. This keeps meaning local, names faithful, and later reasoning clean.”\n",
        "f.2:end": "### F.2:End\n"
      },
      "content": "### F.2:End\n",
      "metadata": {},
      "part": "F",
      "cluster": null
    },
    {
      "id": "F.3",
      "title": "Intra‑Context Sense Clustering",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## F.3 - Intra‑Context Sense Clustering\n\n**“Within one context, decide what ‘the same sense’ really is—before you ever cross Contexts.”**\n**Status.** Architectural pattern, architheory‑agnostic.\n**Depends on.** F.1 **Domain‑Family Landscape Survey**; F.2 **Term Harvesting & Normalisation**; E.10.D1 **Lexical Discipline for “Context” (D.CTX)**; A.7 **Strict Distinction**; A.11 **Ontological Parsimony**.\n**Coordinates with.** F.4 **Role Description**; F.7 **Concept‑Set Table**; F.8 **Mint or Reuse Decision**; F.9 **Alignment & Bridge Across Contexts**.\n**Aliases (informative).** *context‑local clustering*; *Sense consolidation*.\n\n",
        "intent_&_applicability": "### F.3:1 - Intent & applicability\n\n**Intent.** Consolidate the **context‑local lexical units** from F.2 into a **small set of Local‑Senses** that actually operate in that **one context (U.BoundedContext)**. Each Local‑Sense receives a crisp, didactic label pair (Tech/Plain) and a short sense statement. The result is an **addressable basis** for later uses (Role Assignment, tables, bridges) that is **still strictly context‑local**.\n\n**Applicability.** Apply **after** F.2 for any Context that will feed naming (F.4/F.5), decision gates (F.8), Cross‑context bridges (F.9), or exemplars in Part C. Use again whenever the canon (edition) **shifts usage** enough to split or merge senses **within the same context**.\n\n**Non‑goals.** No Cross‑context comparison or merging. No behaviour/deontics/type mathematics. No storage schemas or workflows. This is **pure sense‑making** inside one context.\n\n",
        "problem": "### F.3:2 - Problem Frame\n\ncontext‑local units (LNF + labels + gloss) from F.2 often **over‑ or under‑differentiate** meaning:\n\n1. **Over‑split:** superficial variants (*service‑level‑objective* vs *SLO*) treated as different “things”.\n2. **Under‑split:** one gloss covering **two selectional frames** or incompatible use‑cases.\n3. **Drift within a canon:** multi‑chapter texts use the same head differently unless the reader **consolidates** the intended sense.\n4. **Didactic mismatch:** engineer‑friendly label and plain label drift apart when units remain too granular.\n\nF.3 repairs this **inside the Context** by clustering “same sense” and distinguishing “different sense”, with **parsimony**.\n\n",
        "forces": "### F.3:3 - Forces\n\n| Force                     | Tension to resolve                                                                                               |\n| ------------------------- | ---------------------------------------------------------------------------------------------------------------- |\n| **Parsimony vs fidelity** | Few Local‑Senses ease teaching; too few dilute real distinctions the canon relies on.                            |\n| **Usage vs definition**   | Glosses should reflect **how the canon uses the word**, not an imported dictionary definition.                   |\n| **Labels vs idiom**       | Tech label must stay in the canon’s idiom; Plain label must help newcomers—without inventing a new sense.        |\n| **Stability vs openness** | Consolidated senses must be stable enough for Role Descriptions and tables, yet revisable when the canon’s use clearly splits. |\n",
        "core_idea_(didactic)": "### F.3:4 - Core idea (didactic)\n\n**Cluster by usage, not by string.**\nInside one context:\n\n* **Same sense** → **Local‑Sense**: a small, coherent usage‑region the canon treats as one idea (even if it has aliases or minor surface variation).\n* **Different sense** → **two Local‑Senses**: incompatible selectional frames, entailments, or role in the canon’s own statements.\n\nEach Local‑Sense becomes **addressable** when paired with its Context: **SenseCell = (Context × Local‑Sense)**. SenseCells are **context‑local coordinates**; they do not pre‑judge any Cross‑context mapping.\n\n",
        "minimal_vocabulary_(this_pattern_only)": "### F.3:5 - Minimal vocabulary (this pattern only)\n\n* **Context** — short for `U.BoundedContext` (per D.CTX).\n* **Unit** — a context‑local lexical unit from F.2 (LNF + Tech/Plain + gloss).\n* **Local‑Sense** — the **conceptual cluster** of Units deemed “same sense” **within that Context**.\n* **SenseCell** — the **address** for a Local‑Sense: *(Context, Local‑Sense)*. This is what later patterns will **cite**.\n* **Counter‑example** — a short, canonical sentence or use that **must not** be covered by the Local‑Sense; it sharpens the boundary.\n* **Usage cue** *(informative)* — a clue from usage (collocational patterns, paraphrases, entailments in the canon) that **suggests** merge or split. Cues **do not decide**; the canon’s intent does.\n\n",
        "solution": "### F.3:6 - Solution — how to think the clustering (notation‑free)\n\n> What follows are **mental moves**, not steps for a team. Use them as probes until the Context’s usage partitions itself naturally.\n\n**6.1 Consolidate aliases into one Local‑Sense.**\nIf Units differ only by **orthography, abbreviation, or canon‑blessed synonymy** and are **used interchangeably** in the Context’s own sentences, treat them as **one Local‑Sense**.\n*Example (ITIL):* *service‑level‑objective* and *SLO* → one Local‑Sense.\n\n**6.2 Split on incompatible selectional frames.**\nIf the same head pairs with **different kinds of arguments** or plays **different roles** in the canon’s statements (and those roles cannot both be true at once), split.\n*Example (BPMN):* *event* as **node type** vs as **occurrence narrative** in a tutorial → two Local‑Senses; adopt the **node type** sense if that is the normative layer.\n\n**6.3 Split on entailments that pull apart.**\nIf paraphrases lead to **different entailments** (e.g., one implies temporality, another structural position), you have two senses.\n*Example (PROV):* *activity* implies **time‑bounded use/generate**; it cannot be the same sense as a **static capability**.\n\n**6.4 Prefer sense minimality.**\nIf two candidate Local‑Senses never lead to **different conclusions** in the Context’s own use, merge them. If they sometimes do, split them—and record a **counter‑example** to keep the boundary crisp.\n\n**6.5 Keep Tech label idiomatic; Plain label helpful.**\nTech label stays as the canon speaks; Plain label conveys the **function** of the sense to a careful newcomer. Neither label may **broaden** the sense beyond usage.\n\n**6.6 Name only as much as you will use.**\nIf a fine-grained split has **no downstream consequence** (Role Descriptions, tables, bridges), prefer the coarser Local-Sense.\n\n",
        "outputs_(conceptual,_not_clerical)": "### F.3:7 - Outputs (conceptual, not clerical)\n\nF.3 yields, **per Context**:\n\n1. A **small set of Local‑Senses**, each with:\n\n   * **Label pair**: *Tech* (idiomatic) - *Plain* (didactic).\n   * **Sense line**: one‑sentence usage statement, in the Context’s voice.\n   * **Inside list** (informative): which Units from F.2 it consolidates.\n   * **Counter‑example** (optional but powerful): a short use that must **not** be included.\n1. A **SenseCell address** for each Local‑Sense: *(Context, Local‑Sense)*.\n\nThese are **thinking reference points** (cognitive only), not records or files. Later patterns **cite SenseCells by name**; nothing about storage is implied.\n\n",
        "invariants_(normative,_lightweight)": "### F.3:8 - Invariants (normative, lightweight)\n\n1. **context‑locality.** Every Local‑Sense belongs to **exactly one context**. No Cross‑context clustering.\n2. **Parsimony.** Local‑Senses are **few**; prefer the coarsest partition that preserves the canon’s distinctions.\n3. **Idiomatic Tech.** The Tech label **must** stay in the Context’s idiom; no house‑style overrides.\n4. **Didactic Plain.** The Plain label **must** aid comprehension **without adding scope**.\n5. **Usage‑first.** Sense lines reflect the **canon’s usage**, not imported taxonomies or external theories.\n6. **Counter‑examples rule.** If a counter‑example exists that the sense would wrongly include, **split**.\n7. **No behaviour math.** Sense lines contain **no** behavioural, deontic, metrological, or type calculus; those live in Part C.\n8. **Temporal honesty.** If the Context fixes **DesignRunTag**, the sense line respects it (e.g., PROV *activity* is **run‑time**).\n\n",
        "self‑checks_(mental_probes)": "### F.3:9 - Self‑checks (mental probes)\n\n* **Same‑conclusion test.** Do two candidate senses ever lead to **different conclusions** in the canon? If not, merge.\n* **Argument‑slot probe.** Replace arguments in canonical sentences; do both candidates still read true? If one fails, split.\n* **Label inversion.** Read the Plain label alone: does it tempt you to over‑generalise? If yes, tighten it.\n* **Counter‑example ping.** Can you state a **ten‑word** use that the sense must exclude? If you can, write it; if you cannot, your sense may be too broad.\n* **Memory rule.** Can you recall the Context’s Local‑Senses **without notes**? If not, you split too finely.\n",
        "anti‑patterns_&_remedies": "### F.3:10 - Anti‑patterns & remedies\n\n| #       | Anti‑pattern               | Symptom in thought                                                            | Why it harms                                            | Remedy (conceptual move)                                                                                          |\n| ------- | -------------------------- | ----------------------------------------------------------------------------- | ------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------- |\n| **A1**  | **String = Sense**         | Treating surface identity (*service*, *SLO*) as sameness of meaning.          | Collapses distinct uses; hides selectional differences. | Compare **selectional frames** and entailments inside the Context; merge only if conclusions never diverge.          |\n| **A2**  | **Cross‑context creep**       | Folding BPMN *process* with PROV *activity* while clustering **inside** BPMN. | Imports foreign usage; violates locality.               | Constrain attention to **one context**; postpone Cross‑context talk to F.9.                                             |\n| **A3**  | **Over‑granulation**       | Splitting minor orthographic variants (*service‑level‑objective* vs *SLO*).   | Adds friction; no conceptual gain.                      | Consolidate **canon‑blessed aliases** into one Local‑Sense.                                                       |\n| **A4**  | **Under‑granulation**      | One sense for incompatible roles (*event* as node‑type vs occurrence).        | Causes contradictory inferences later.                  | Split on **role/entailment** conflict; add a **counter‑example** to sharpen the cut.                              |\n| **A5**  | **Imported definitions**   | Borrowing dictionary glosses not used in the canon.                           | Drifts from the Context’s idiom; confuses labels.          | Ground every sense line in **statements the canon actually makes**.                                               |\n| **A6**  | **Label drift**            | Tech label in canon idiom; Plain label broadens scope.                        | Teaches the wrong thing; leaks meaning.                 | Keep **Tech** idiomatic; make **Plain** helpful yet strictly **within** the same usage.                           |\n| **A7**  | **Behaviour/math leakage** | Sense lines include runtime metrics, deontic rules, type axioms.              | Mixes I/D/S layers; duplicates Part C work.                   | Sense lines are **usage‑only**; no equations, no policies.                                                        |\n| **A8**  | **Edition blend**          | Mixing 2011 and 2020 usage under one Local‑Sense.                             | Hidden shifts; brittle bridges later.                   | If usage changed with edition, treat as **different Contexts** (F.1) or distinct Local‑Senses with **edition note**. |\n| **A9**  | **Collocate worship**      | Declaring sameness solely from similar nearby words.                          | Correlates ≠ causes; misses entailments.                | Use collocates as **cues**, then decide by **entailment/role** checks.                                            |\n| **A10** | **Temporal fudge**         | Treating a design‑time sense as if it were run‑time (or vice versa).          | Category errors at enactment.                           | Respect the Context’s **time stance**; keep senses aligned to *design* or *run* as declared in F.1.                  |\n\n",
        "local‑sense_cards_(one‑glance_form)": "### F.3:11 - Local‑Sense Cards (one‑glance form)\n\n> A **Local‑Sense Card** is a **one‑glance** sketch per sense in a Context. It teaches faster than prose lists and keeps senses crisp.\n\n**Fields (thought‑items, not fields to fill):**\n\n* **Context** (U.BoundedContext, edition)\n* **Label pair** — **Tech** (idiomatic) - **Plain** (didactic)\n* **Sense line** — one sentence in the Context’s voice\n* **Inside** — which F.2 Units it consolidates (names only)\n* **Counter‑example** — a short use that must **not** be included\n\n",
        "worked_examples_(multi‑architheory,_all_**intra‑context**)": "### F.3:12 - Worked examples (multi‑architheory, all **intra‑Context**)\n\n#### F.3:12.1 - BPMN 2.0 (workflow Context)\n\n**Card A — “process (graph)”**\n\n* **Label**: Tech **process** - Plain **workflow graph**\n* **Sense line**: A BPMN **graph of flow nodes and sequence flows** **specifying orchestration among participants** *(design‑time)*.\n* **Inside**: *process*, *process model*, *business process* (when used as diagram).\n* **Counter‑example**: *“This process took 5 minutes”* ← **runtime** occurrence, **not** this sense.\n\n**Card B — “event (node‑type)”**\n\n* **Label**: Tech **event (node)** - Plain **event symbol**\n* **Sense line**: A **node‑type** that marks starts, ends, and intermediates; typed by trigger/result.\n* **Inside**: *start event*, *message event*, *end event*.\n* **Counter‑example**: *“The outage event happened at 13:05”* ← narrative occurrence, **not** the node‑type.\n\n> **Outcome:** “Process uptime” is rejected as a BPMN sense; Execution belongs to another Context.\n\n\n#### F.3:12.2 - PROV‑O (provenance Context)\n\n**Card C — “activity (run)”**\n\n* **Label**: Tech **activity** - Plain **time‑bounded execution**\n* **Sense line**: An **occurrence** that **uses** and **generates** entities; linked to agents; has start/end.\n* **Inside**: *activity*, *execution* (when PROV authors use it).\n* **Counter‑example**: *“Sorting algorithm”* ← capability/method, **not** an occurrence.\n\n**Card D — “agent (provenance)”**\n\n* **Label**: Tech **agent** - Plain **provenance actor**\n* **Sense line**: Thing that bears **responsibility** for an activity’s effects (person, org, software).\n* **Inside**: *agent*.\n* **Counter‑example**: *“RBAC role”* ← access status, **not** a PROV agent.\n\n\n#### F.3:12.3 - ITIL 4 (services Context)\n\n**Card E — “service‑level objective”**\n\n* **Label**: Tech **SLO** - Plain **service target**\n* **Sense line**: A **target value/range** for a **service characteristic** used to define acceptable service.\n* **Inside**: *service‑level objective*, *SLO*.\n* **Counter‑example**: *“Actual availability 99.5%”* ← observation, **not** the target.\n\n**Card F — “incident”**\n\n* **Label**: Tech **incident** - Plain **service disruption**\n* **Sense line**: An **unplanned interruption** or reduction in quality of a service.\n* **Inside**: *incident*.\n* **Counter‑example**: *“Fault in plant sensor”* ← Sys‑CAL fault; different Context.\n\n\n#### F.3:12.4 - SOSA/SSN (sensing Context)\n\n**Card G — “observation (act)”**\n\n* **Label**: Tech **observation** - Plain **measurement act**\n* **Sense line**: An **act** applying a **Procedure** to a **FeatureOfInterest** to yield a **Result** for a property.\n* **Inside**: *observation*.\n* **Counter‑example**: *“Temperature is 20 °C”* ← **result value**, not the act.\n\n\n#### F.3:12.5 - OWL 2 (types Context)\n\n**Card H — “subclass‑of”**\n\n* **Label**: Tech **subclass‑of** (⊑) - Plain **is‑a (class)**\n* **Sense line**: A **class inclusion**: every instance of **C** is an instance of **D**.\n* **Inside**: *SubClassOf*, *is‑a* (when authors use it for classes).\n* **Counter‑example**: *rdf\\:type* (instance‑of) — not class inclusion.\n\n**Card I — “equivalent‑class”**\n\n* **Label**: Tech **equivalent‑class** - Plain **same class extension**\n* **Sense line**: Mutual class identity by extension; two labels for **the same** set of instances.\n* **Inside**: *EquivalentClasses*.\n* **Counter‑example**: *owl\\:sameAs* (individual identity), different predicate.\n\n\n#### F.3:12.6 - IEC 61131‑3 (control‑runtime Context)\n\n**Card J — “task (runtime)”**\n\n* **Label**: Tech **task** - Plain **program runner**\n* **Sense line**: A **cyclic or event‑driven** execution unit that **invokes programs** on schedule or trigger.\n* **Inside**: *task*.\n* **Counter‑example**: *“Control algorithm”* ← design/method, not the runtime task.\n\n",
        "reasoning_primitives_(judgement_schemas,_notation‑free)": "### F.3:13 - Reasoning primitives (judgement schemas, notation‑free)\n\n> Each schema captures a **safe mental move**. It implies no storage, API, or workflow.\n\n1. **Alias‑to‑sense consolidation**\n   `Context C ⊢ interchangeable(U₁,…,Uₖ) ⇒ Local‑Sense σ`\n   *Reading:* If Units are used interchangeably **by the canon** in **C**, consolidate them into one Local‑Sense **σ**.\n\n2. **Selectional‑frame split**\n   `C ⊢ frames(U) = F, frames(V) = G, F ∩ G = ∅ ⇒ split(U,V)`\n   *Reading:* In **C**, if the argument/role patterns do not overlap, treat as **different senses**.\n\n3. **Entailment divergence**\n   `C ⊢ entail(U) ≠ entail(V) on canonical paraphrases ⇒ split(U,V)`\n   *Reading:* If paraphrases lead to **different conclusions** in the canon, split.\n\n4. **Parsimony merge**\n   `C ⊢ no‑test distinguishes {U₁,…,Uₖ} ⇒ merge(U₁,…,Uₖ)`\n   *Reading:* If no canonical test yields a difference, merge into one sense.\n\n5. **Counter‑example trigger**\n   `C ⊢ ∃e: e should not be covered by σ ⇒ refine(σ)`\n   *Reading:* A crisp counter‑example forces a narrower sense (split or relabel).\n\n6. **Idiomatic Tech, faithful Plain**\n   `C ⊢ labelTech(σ) in idiom(C) ∧ labelPlain(σ) ⊆ usage(σ)`\n   *Reading:* Tech label speaks the canon; Plain label does not widen the sense.\n\n7. **SenseCell address**\n   `C ⊢ σ ⇒ SenseCell ⟨C,σ⟩`\n   *Reading:* Pair each Local‑Sense with its Context to form an address used downstream.\n\n8. **Temporal guard**\n   `stance(C)=design ⇒ forbid(run‑claims in σ)` (and symmetrically)\n   *Reading:* Sense lines must not cross the Context’s DesignRunTag.\n\n9. **Edition guard**\n   `C≠C′ (different editions with usage shift) ⇒ no‑merge(σ@C, τ@C′)`\n   *Reading:* Do not merge senses across Contexts when editions shift usage.\n\n10. **Completeness ping (optional)**\n    `frequent head w in C ∧ no Local‑Sense on w ⇒ consider(sense for w)`\n    *Reading:* If a common head lacks a sense, you may be missing a useful consolidation (within C).\n\n",
        "relations": "### F.3:14 - Relations\n\n**Builds on:**\nF.1 **Domain‑Family Landscape Survey** (Contexts fixed); F.2 **Term Harvesting** (Units ready); E.10.D1 **D.CTX** (Context discipline); A.7 **Strict Distinction**.\n\n**Constrains:**\n\n* **F.4 Role Description.** Role Descriptions **cite SenseCells**; they do **not** invent senses.\n* **F.7 Concept‑Set Table.** Rows are built from **SenseCells** (later Cross‑context assembly); intra‑Context clarity here prevents row bloat.\n* **F.8 Mint or Reuse Decision.** Decisions compare proposed names to **existing SenseCells** to avoid type inflation.\n* **F.9 Alignment & Bridge.** Bridges connect **SenseCell ↔ SenseCell** across Contexts; F.3 provides the stable endpoints.\n\n**Is used by.**\nPart C architheories to ground examples and invariants in **Context‑true** language.\n\n",
        "migration_notes_(conceptual)": "### F.3:15 - Migration notes (conceptual)\n\n1. **Usage clarifies → merge.** If two Local‑Senses never lead to different conclusions in the Context’s canon, **merge** and keep the narrower sense line.\n2. **Usage diverges → split.** If new reading reveals incompatible roles/entailments, **split** and attach a counter‑example to each side.\n3. **Edition change → new Context.** When a new edition **reframes** usage, treat it as a **separate Context** (F.1) and re‑cluster there.\n4. **Label upkeep.** If the Plain label tempts broadening, tighten it; if the Tech label drifts from idiom, restore the canon term.\n5. **Dormant sense.** If a Local‑Sense ceases to matter for any active line, leave it listed but mark it **low‑use** in your own notes; do not fold it into another unless rule 1 holds.\n6. **Bridge temptation.** Record tensions to bridge **elsewhere**; F.3 never resolves Cross‑context relations.\n\n",
        "acceptance_tests_(scr/rscr_—_concept‑level)": "### F.3:16 - Acceptance tests (SCR/RSCR — concept‑level)\n\n#### F.3:16.1 - Static conformance (SCR)\n\n* **SCR‑F3‑S01 (context‑locality).** Every Local‑Sense is paired with **exactly one context**; no Cross‑context clustering appears.\n* **SCR‑F3‑S02 (Label pair).** Each Local‑Sense has **Tech** (idiomatic) and **Plain** (didactic) labels; neither widens usage beyond the sense line.\n* **SCR‑F3‑S03 (Sense line fidelity).** Each sense line is **grounded in canonical statements** of the Context; no behaviour/deontic/math content.\n* **SCR‑F3‑S04 (Parsimony).** The set of Local‑Senses per Context is small enough to **recall unaided** by a careful mind.\n* **SCR‑F3‑S05 (Counter‑example presence).** For any ambiguous head, at least one **counter‑example** is recorded to guard the boundary.\n* **SCR‑F3‑S06 (Temporal honesty).** Where the Context has a declared stance, sense lines **respect design/run**.\n\n#### F.3:16.2 - Regression (RSCR)\n\n* **RSCR‑F3‑E01 (Merge soundness).** Every merge is justified by a **failed distinction test** (no selectional or entailment difference).\n* **RSCR‑F3‑E02 (Split necessity).** Every split cites a **role/entailment conflict** or a concrete **counter‑example**.\n* **RSCR‑F3‑E03 (Edition guard).** No Local‑Sense spans Contexts that differ by edition **with usage shift**.\n* **RSCR‑F3‑E04 (Label stability).** Changes to labels do **not** change sense; if they do, the change is treated as a split/merge per E01/E02.\n* **RSCR‑F3‑E05 (Downstream continuity).** After splits/merges, **SenseCell** references in F.4/F.7/F.9 remain **referentially clear** (new addresses are explicit; no silent aliasing).\n\n",
        "didactic_close_(60‑second_recap)": "### F.3:17 - Didactic close (60‑second recap)\n\n> **Within one context,** collect how the canon actually **uses** a head, not how we wish it did. **Merge** aliases that never lead to different conclusions; **split** uses that do. Give each consolidated use a crisp **Tech** label in the Context’s idiom and a faithful **Plain** label. The pair *(Context, Local-Sense)* is your **SenseCell**—the address later cited by Role Descriptions, tables, and bridges. No Cross‑context mergers here; that job belongs to F.9. Keep senses few, boundaries sharp, and labels honest.\n",
        "f.3:end": "### F.3:End\n"
      },
      "content": "### F.3:End\n",
      "metadata": {},
      "part": "F",
      "cluster": null
    },
    {
      "id": "F.4",
      "title": "Role Description (RCS + RoleStateGraph + Checklists)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## F.4 - Role Description (RCS + RoleStateGraph + Checklists)\n\n**“Name the mask or the badge — and say what it commits to — but only inside a Context.”**\n**Status.** Architectural pattern, architheory‑agnostic.\n**Depends on.** E.10.D1 **Lexical Discipline for “Context” (D.CTX)**; **E.10.D2 Intension–Description–Specification Discipline**; F.1 **Domain‑Family Landscape Survey**; F.2 **Term Harvesting**; F.3 **Intra‑Context Sense Clustering**; A.2.1 **`U.RoleAssignment`**; A.7 **Strict Distinction**; A.11 **Ontological Parsimony**.\n**Coordinates with.** F.5 **Naming Discipline for U.Types & Roles**; F.7 **Concept‑Set Table**; F.9 **Alignment & Bridge Across Contexts**; B.3 **Trust & Assurance Calculus** (for later status evaluation).\n**Aliases (informative).** *Mask/Badge card*; *role card* (plain only).\n",
        "intent_&_applicability": "### F.4:1 - Intent & applicability\n\n**Intent.** Provide a **conceptual template** for two kinds of assignables:\n\n* **Role Template** — a **behavioural mask** that a holder can wear **in a specific Context** (U.BoundedContext), shaping how it **acts** (via Method/Execution relations).\n* **Status Template** — an **epistemic or deontic badge** that a holder (or artefact, event, claim) can **bear** inside a Context, shaping how it is **treated** (evaluation, permission, standing).\n\nEach template is **grounded in a SenseCell** `⟨Context, Local‑Sense⟩` from F.3 and declares **minimal invariants** that later **assignments** must satisfy. No Cross‑context meaning is imported here.\n\n**Applicability.** Whenever you need to **speak precisely** about what it means to be *a Participant (BPMN)*, *hold an access‑role (RBAC)*, *be an Incident (ITIL)*, or *carry a Verified status (evidence line)*, before minting U.Types or drawing Cross‑context bridges.\n\n**Non‑goals.** No workflows, no storage, no editors. No equations for assurance or control; those live in Part B/C. This pattern describes **how to think and speak** about assignables — not how to manage files.\n",
        "problem": "### F.4:2 - Problem frame\n\nWithout explicit Role Descriptions:\n\n1. **Role/status conflation.** Access **role** (RBAC) treated as behavioural **mask** (BPMN participant); deontic **duty** treated as runtime **effect**.\n2. **Context drift.** A “role” quietly starts meaning different things across canons; later assignments contradict each other.\n3. **Hidden commitments.** We name a role/status but never state what **must hold** when it is assigned; downstream reasoning becomes arbitrary.\n4. **Premature unification.** A single template tries to straddle several Contexts; losses remain implicit.\n",
        "forces": "### F.4:3 - Forces\n\n| Force                         | Tension to resolve                                                                                                           |\n| ----------------------------- | ---------------------------------------------------------------------------------------------------------------------------- |\n| **Behaviour vs knowledge**    | A role changes how the holder **acts**; a status changes how the holder is **treated/assessed**. Keep **I/D/S layers** separate (E.10.D2; A.7). |\n| **Locality vs reuse**         | We want reusable templates, yet meanings are **context‑local** (E.10.D1, F.1).                                                   |\n| **Minimality vs sufficiency** | Invariants must be **few** and **decisive**; too many become pseudo‑procedures.                                              |\n| **Didactics vs fidelity**     | A one‑screen card must be **teachable** without betraying the canon.                                                         |\n\n",
        "minimal_vocabulary_(this_pattern_only)": "### F.4:4 - Minimal vocabulary (this pattern only)\n\n* **Context** — **U.BoundedContext** (per E.10.D1).\n* **Local‑Sense** — a consolidated sense in a Context (F.3).\n* **SenseCell** — the address `⟨Context, Local‑Sense⟩`.\n* **Role Template** — behavioural mask defined **in** a Context, later bound by **`U.RoleAssignment`**.\n* **Status Template** — epistemic/deontic badge defined **in** a Context, later asserted as a **claim** about a holder/artefact.\n* **Holder** — the thing that may wear a mask or carry a badge (e.g., a **U.System**, **U.MethodDescription**, **U.Work**, **U.Episteme**).\n",
        "core_idea_(didactic)": "### F.4:5 - Core idea (didactic)\n\n**A Role Description is a small card that says:**\n**(i)** *which Context’s sense it relies on* (**SenseCell**),\n**(ii)** *what label we use to speak about it* (Tech & Plain), and\n**(iii)** *what must hold* when someone **wears** the mask (Role) or **bears** the badge (Status).\n\nIt is **not** a definition by prose alone; it is a **pledge of invariants** — minimal, Context‑true, and later checkable.\n",
        "the_role_description_card_(one‑screen_sketch)": "### F.4:6 - The Role Description Card (one‑screen sketch)\n\n> Each bullet is a **thought‑item**, not a file field.\n\n**Header**\n\n* **Template kind:** **Role** | **Status**\n* **Label pair:** **Tech** (idiomatic) - **Plain** (didactic)  *(naming discipline in F.5)*\n* **SenseCell:** `⟨ContextId, Local‑Sense label⟩`\n\n**Applicability**\n\n* **Holder scope:** what can wear/bear it (e.g., *U.System*, *U.Work*, *U.MethodDescription*, *U.Episteme*).\n* **Time stance:** **design** / **run** aligned to the Context (F.1).\n* **Preconditions (Context‑true):** crisp conditions that must already be true in the Context’s idiom.\n\n**Invariants (minimal)**\n\n* **Behavioural invariants (Role)** *or* **Evaluation invariants (Status)** — 2–5 short lines stating what **must** hold after assignment/assertion, using the Context’s vocabulary and SenseCells where needed.\n* **Separation guard:** a one‑line reminder of what this template **does not** imply (prevents senseFamily mixing).\n\n**Consequences (informative)**\n\n* **Typical interactions:** which **Method/Execution/Observation** constructs (by SenseCell) this template usually touches — *names only*.\n* **Common misreads (trip‑wire):** 1–2 bullets to prevent known confusions.\n\n> **Memory rule:** If your card can’t be read in **under two minutes**, you are writing a manual, not a template.\n\n**Autonomy hooks (when Role may act autonomously)**\n* **RCS additions (illustrative):** `AgencyLevel ∈ {None, Assisted, Delegated, Autonomous}`, `SafetyCriticality ∈ {SC0..SC3}`.\n* **RSG gate:** mark which **states are enactable under autonomy** (cf. A.2.5); link to `AutonomyBudgetDeclRef`.\n* **References:** If autonomy is claimed for this Role, the Role Description **MUST** reference: `AutonomyBudgetDeclRef` (id, version), `Aut-Guard policy-id (PolicyIdRef)`, `OverrideProtocolRef`.\n* **Checklist:** include a **pre‑enactment** checklist item “Autonomy Green‑Gate passed” (guard verdicts present).\n",
        "normative_invariants_(template_discipline)": "### F.4:7 - Normative invariants (template discipline)\n\n1. **context‑local grounding.** Every Role Description **MUST** cite exactly one **SenseCell** as its semantic locus.\n2. **I/D/S layer separation.**\n   * A **Role Template** **MUST NOT** encode deontic, access, or measurement rules.\n   * A **Status Template** **MUST NOT** encode behaviour or control flow.\n3. **Time honesty.** The card’s stance (**design/run**) **MUST** match the Context’s stance (F.1).\n4. **Minimality.** Invariants **SHOULD** be the **fewest that decide** the assignment; avoid procedural sequences.\n5. **No Cross‑context smuggling.** A single card **MUST NOT** import foreign semantics; if two Contexts are needed, the relation is handled later in **F.9**.\n6. **Label fidelity.** **Tech** label **MUST** be idiomatic to the Context; **Plain** label **MUST** not widen the sense (F.3).\n7. **Binding Standard (roles).** A **Role Template** is the **design‑time mask**; at run‑time, a **`U.RoleAssignment`** creates **System‑in‑Role** instances that are subject to the card’s invariants.\n8. **Assertion Standard (statuses).** A **Status Template** is a **badge**; asserting it **commits** to the card’s evaluation invariants and to the Context’s way of checking them (later anchored via SenseCells, not formulas here).\n",
        "reasoning_primitives_(judgement_schemas,_notation‑free)": "### F.4:8 - Reasoning primitives (judgement schemas, notation‑free)\n\n> Conceptual moves only; no APIs, no data stores.\n\n1. **Template grounding**\n   `Template T cites SenseCell ⟨C,σ⟩ ⊢ meaning(T) is local to C`\n   *Reading:* The template’s meaning is **context‑local**.\n\n2. **Role assignability**\n   `holder h, RoleTemplate T, preconds_T(h) ⊢ assignable(h,T)`\n   *Reading:* If the **preconditions** hold for **h**, it is **eligible** to wear the mask **T**.\n\n3. **Role assignment obligation**\n   `assignable(h,T) ∧ bind(h,T: C) ⊢ invariants_T(h) must hold`\n   *Reading:* Once bound (via **`U.RoleAssignment`**), **h** must satisfy **T**’s behavioural invariants.\n\n4. **Status assertability**\n   `StatusTemplate S, evidence_in_C supports S for x ⊢ assertable(x,S)`\n   *Reading:* If evidence **in the Context C** supports **S** for **x**, the badge is **assertable** (details of evidence logic live in Part B).\n\n5. **Status consequence**\n   `assertable(x,S) ∧ assert(x,S) ⊢ evaluation_invariants_S(x)`\n   *Reading:* Once asserted, **S**’s evaluation invariants constrain how **x** is treated.\n\n6. **Separation guard**\n   `RoleTemplate T ⊢ not(deontic_implied(T))` - `StatusTemplate S ⊢ not(behaviour_implied(S))`\n   *Reading:* Wearing a mask doesn’t grant permissions; carrying a badge doesn’t define behaviour.\n\n7. **Bridge embargo**\n   `T cites ⟨C,σ⟩ ∧ C≠C′ ⊢ no‑equivalence(T@C, −) inside F.4`\n   *Reading:* No Cross‑context equivalence is asserted here; use **F.9** later.\n",
        "worked_examples_(multi‑architheory,_context‑true)": "### F.4:9 - Worked examples (multi‑architheory, Context‑true)\n\n> Illustrative cards only; names are **tech/plain labels**, not final U.Type IDs (F.5 will govern naming).\n\n#### F.4:9.1 - **Role Template:** *participant (workflow actor)* — Context: **BPMN 2.0 (2011)**\n\n* **Kind:** Role\n* **Label:** Tech **participant** - Plain **workflow actor**\n* **SenseCell:** `⟨BPMN_2_0, participant (actor in workflow)⟩`\n* **Holder scope:** **U.System** (organisation, team, service)\n* **Time stance:** **design**\n* **Preconditions:** Holder is addressable as a **lane/pool** in the workflow model.\n* **Behavioural invariants:**\n\n  1. Activities **assigned to** the participant appear in its lane/pool.\n  2. The participant **interacts** through message flows at its boundaries.\n  3. The participant **does not** define run‑time occurrence; it **structures** the model.\n* **Separation guard:** No permissions implied; no execution logs implied.\n* **Typical interactions (informative):** BPMN **process (graph)**; message **event (node)**.\n* **Common misreads:** ≠ **RBAC role**; ≠ **PROV Activity**.\n\n#### F.4:9.2 - **Status Template:** *access‑role membership* — Context: **NIST RBAC (2004)**\n\n* **Kind:** Status\n* **Label:** Tech **access‑role** - Plain **permission role**\n* **SenseCell:** `⟨NIST_RBAC_2004, role (permission grouping)⟩`\n* **Holder scope:** **U.System** (user/session)\n* **Time stance:** **run**\n* **Preconditions:** A defined set of **permissions** exists for the role.\n* **Evaluation invariants:**\n\n  1. If **x** carries this badge, **x**’s session inherits exactly the role’s **permissions**.\n  2. The badge **does not** describe behaviour in a workflow; it determines **access**.\n* **Separation guard:** No commitment about BPMN assignment; no deontic duties.\n* **Typical interactions (informative):** **permission**, **session** (RBAC).\n* **Common misreads:** ≠ **participant (BPMN)**; ≠ **person** as an ontological type.\n\n#### F.4:9.3 - **Status Template:** *incident (service disruption)* — Context: **ITIL 4 (2020)**\n\n* **Kind:** Status\n* **Label:** Tech **incident** - Plain **service disruption**\n* **SenseCell:** `⟨ITIL4_2020, incident (service quality drop)⟩`\n* **Holder scope:** **U.Work** (recorded occurrence affecting a service)\n* **Time stance:** **run**\n* **Preconditions:** A **service** exists with declared **SLOs/quality metrics**.\n* **Evaluation invariants:**\n\n  1. The occurrence **reduces** service quality below acceptable levels.\n  2. It triggers **restoration activities** per service practice (names only).\n* **Separation guard:** Not a plant **fault**; not a BPMN **event node**.\n* **Typical interactions:** **SLO** (ITIL), **Observation** (SOSA) — names only.\n* **Common misreads:** ≠ **problem** (root cause category).\n\n#### F.4:9.4 - **Role Template:** *task runner (control runtime)* — Context: **IEC 61131‑3**\n\n* **Kind:** Role\n* **Label:** Tech **task** - Plain **program runner**\n* **SenseCell:** `⟨IEC_61131_3, task (runtime execution unit)⟩`\n* **Holder scope:** **U.System** (controller CPU/task scheduler)\n* **Time stance:** **run**\n* **Preconditions:** A program is **registered** for cyclic/event execution.\n* **Behavioural invariants:**\n\n  1. Invokes assigned program according to **cycle/trigger**.\n  2. Provides **schedule constraints** (period/priority) to its program.\n* **Separation guard:** No claim about **deontic** guarantees or **service** targets.\n* **Typical interactions:** **Execution** (A.15 family), **Actuation** (Sys‑CAL).\n* **Common misreads:** ≠ **workflow task**; ≠ **algorithm** (design).\n",
        "anti‑patterns_&_remedies": "### F.4:10 - Anti‑patterns & remedies\n\n| #       | Anti‑pattern            | Symptom (in a card)                                                       | Why it harms thinking                                    | Remedy (conceptual move)                                                                                        |\n| ------- | ----------------------- | ------------------------------------------------------------------------- | -------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------- |\n| **A1**  | **Role⇄Status blur**    | A Role card says “grants permission”; a Status card dictates behaviour.   | **senseFamily mixing (Role vs Status)**; incoherent assignments.              | Move permission talk to a **Status**; keep Role invariants purely behavioural. Add a **separation guard** line. |\n| **A2**  | **Pan‑Context template**   | One card cites several canons implicitly (“BPMN/PROV process”).           | Imports meaning across Contexts; hides losses.              | Keep **one SenseCell per card**. If Cross‑context relation is needed, defer to **F.9 Bridge**.                     |\n| **A3**  | **Silent time flip**    | Card defined in a **design** Context asserts run‑time facts (or vice versa). | Violates F.1 time stance; produces category errors.      | Align **Time stance** to the Context; relocate run‑facts to status/evidence lines or to another Context.              |\n| **A4**  | **Procedural template** | Long “steps” instead of minimal invariants.                               | Becomes a method recipe, not an assignable mask/badge.   | Replace sequences with **decisive invariants** (2–5 lines) that must hold regardless of procedure.              |\n| **A5**  | **Permission leakage**  | A BPMN Role claims access rights “by wearing the mask”.                   | Conflates access with behaviour; weakens RBAC semantics. | State explicitly: **no permissions implied**. Bind access via a **Status** in the RBAC Context.                    |\n| **A6**  | **Evidence bake‑in**    | Status card encodes metrics/formulas.                                     | Smuggles Part B maths; reduces portability.              | Keep only **evaluation invariants** in Context language; actual checks live in Part B/C via SenseCells.            |\n| **A7**  | **Global label**        | Tech label chosen for cross‑discipline appeal (“Actor”) not Context idiom.   | Loses local meaning; harms F.3 clustering.               | Use **Context‑idiomatic Tech label**; provide a Plain label for teaching (F.5 governs labels).                     |\n| **A8**  | **Concept inflation**   | Multiple near‑duplicate cards for the same SenseCell.                     | Noise; brittle naming.                                   | Prefer **refinement** (see §11) or a single card with tighter invariants; avoid duplicates.                     |\n| **A9**  | **Holder sprawl**       | Holder scope lists unrelated kinds (“U.System or U.Work or U.Episteme”).  | Ambiguity at binding time.                               | Shrink **Holder scope** to the real carriers; if truly different, split cards.                                  |\n| **A10** | **Anchor relapse**      | Card talks about “anchors” or “global context.”                           | Re‑introduces banned jargon; confuses D.CTX.             | Replace with **Context** / **SenseCell**; never use “anchor”.                                                      |\n| **A11** | **Tooling creep**       | Mentions manifests, pipelines, editors.                                   | Violates E.5 guard‑rails; notational dependency.         | Remove all process/tool talk; keep card **concept‑only**.                                                       |\n| **A12** | **Bridge‑by‑label**     | Using identical labels to imply Cross‑context sameness.                      | Stealth equivalence; no loss policy.                     | Labels do not bridge. Any Cross‑context claim goes to **F.9** with a declared CL policy.                           |\n",
        "concept‑level_operators_(refinement_&_compatibility)": "### F.4:11 - Concept‑level operators (refinement & compatibility)\n\n> **Judgement schemas** — pure reasoning moves over cards. No APIs, no storage, no workflow.\n\nLet **`sense(T)`** denote the **SenseCell** cited by template **T**.\nLet **`inv(T)`** denote the set of **invariants** on T.\nLet **`senseFamily(T)`** ∈ {**Role**, **Status**}.\nLet **`stance(T)`** ∈ {**design**, **run**} (from the Context).\n\n#### F.4:11.1 - Same‑Context equivalence\n\n**Form.**\n`sense(T₁) = sense(T₂) ∧ inv(T₁) ⇔ inv(T₂) ⊢ T₁ ≡ T₂`\n\n**Reading.** Two cards in the **same Context** with logically equivalent invariants **co‑designate** the same assignable.\n\n*Tech cue.* Use this to **merge duplicates** conceptually without changing labels.\n\n#### F.4:11.2 - Refinement (strictness order)\n\n**Form.**\n`sense(T₁) = sense(T₂) ∧ inv(T₁) ⇒ inv(T₂) ⊢ T₁ ⪯ T₂`\n\n**Reading.** **T₁** is a **refinement** of **T₂** if its invariants **imply** those of **T₂** (same Context).\n\n*Effects.* Assigning **T₁** automatically satisfies **T₂**; the converse need not hold.\n\n#### F.4:11.3 - Incompatibility (mutual exclusion)\n\n**Form.**\n`sense(T₁) = sense(T₂) ∧ (inv(T₁) ∧ inv(T₂) ⇒ ⊥) ⊢ incompatible(T₁,T₂)`\n\n**Reading.** Two cards in the same Context are **mutually exclusive** if their invariants cannot co‑hold.\n\n*Use.* A conceptual **Separation‑of‑Duty** signal without governance.\n\n#### F.4:11.4 - Co‑wearability / co‑bearability\n\n**Form.**\n+`senseFamily(T₁)=senseFamily(T₂)=Role ∧ stance(T₁)=stance(T₂) ∧ ¬incompatible(T₁,T₂) ⊢ coWearable(T₁,T₂)`\n+`senseFamily(T₁)=senseFamily(T₂)=Status ∧ ¬incompatible(T₁,T₂) ⊢ stackable(T₁,T₂)`\n\n**Reading.** Within a Context, two Roles can be worn together (or two Statuses carried) when they **do not** conflict.\n\n#### F.4:11.5 - Time‑stance alignment\n\n**Form.**\n`stance(T)=design ⊢ inv(T) may not assert run‑facts`\n`stance(T)=run ⊢ inv(T) may not assert design‑commitments`\n\n**Reading.** Invariants must **respect** the Context’s DesignRunTag (F.1).\n\n#### F.4:11.6 - Binding/Assertion admissibility\n\n**Form. (Roles)**\n`holder h ∧ preconds_T(h) ⊢ assignable(h,T)`\n`assignable(h,T) ∧ bind(h,T) ⊢ inv(T)(h)`\n\n**Form. (Statuses)**\n`evidence_in_Context(C) supports S for x ∧ sense(S)=⟨C,σ⟩ ⊢ assertable(x,S)`\n`assertable(x,S) ∧ assert(x,S) ⊢ inv(S)(x)`\n\n**Reading.** Preconditions and evidence **gate** the act of wearing a mask or bearing a badge; once done, **invariants apply**.\n",
        "f.4:11.7___cross‑context_embargo_(inside_f.4)": "### F.4:11.7 - Cross‑context embargo (inside F.4)\n\n**Form.**\n`sense(T₁)=⟨C,−⟩, sense(T₂)=⟨C′,−⟩, C≠C′ ⊢ no‑relation(T₁,T₂) here`\n\n**Reading.** **F.4** never asserts Cross‑context relations. If a relation is desired, it becomes a **Bridge** in **F.9**.\n",
        "relations": "### F.4:12 - Relations (where this card sits)\n\n**Builds on:**\nE.10.D1 **D.CTX** (Context ≡ U.BoundedContext); F.1 (Contexts cut); F.2 (harvested terms); F.3 (Local‑Sense → **SenseCell**); A.2.1 **`U.RoleAssignment`**; A.7 **Strict Distinction**.\n\n**Constrains:**\n**F.5** (Naming): pairs **Tech/Plain** must reflect the **Context idiom** and avoid Cross‑context overreach.\n**F.7** (Concept-Set Table): rows reference **SenseCells**; Role Description cards **point to** those rows but never **create** cross-context identity.\n**F.8** (Mint or Reuse?): prefer **refinement (⪯)** over new cards; split cards rather than mixing senseFamilies.\n**F.9** (Alignment & Bridge): any relation across Contexts is **declared there**; Role Description cards remain context-local.\n\n**Is used by.**\nA.15 family (Role–Method–Work alignment) to interpret **System‑in‑Role** and **Work**; Part B evidence/status checks to interpret **evaluation invariants**.\n",
        "migration_notes_(conceptual_playbook)": "### F.4:13 - Migration notes (conceptual playbook)\n\n1. **Context update (edition split).** If the Context’s Local‑Sense changes, **fork** the card per new SenseCell; keep the old card as historically valid.\n2. **Family correction (Role/Status).** If a card mixes behaviour and deontics, **split** into one Role and one Status; move permission language to the Status.\n3. **Tighten by refinement.** When practice reveals a stricter understanding, prefer **T′ ⪯ T** over replacing **T**; this preserves existing assignments conceptually.\n4. **Rename safely (labels only).** If F.5 revises labels, change **Tech/Plain** wording; **SenseCell** and **invariants** remain untouched.\n5. **Scope correction.** If Holder scope was too wide, split into **parallel cards** with disjoint Holder scopes; avoid complex conditional invariants.\n6. **Bridge discovery.** Do **not** inject Cross‑context text into cards; record the relation as an **F.9 Bridge** (with CL policy), leaving the cards as they are.\n",
        "acceptance_tests_(scr/rscr_—_concept‑level)": "### F.4:14 - Acceptance tests (SCR/RSCR — concept‑level)\n\n#### F.4:14.1 - Static conformance (SCR)\n\n* **SCR‑F4‑S01 (Uni‑Context grounding).** Each card cites **exactly one SenseCell**.\n* **SCR‑F4‑S02 (Family honesty).** `senseFamily(T)` is **either** Role **or** Status; invariants match the family; a **separation guard** line is present.\n* **SCR‑F4‑S03 (Time honesty).** `stance(T)` matches the Context’s stance; no opposing‑stance claims appear.\n* **SCR‑F4‑S04 (Minimality).** Card lists **2–5** invariants; none are procedural step lists.\n* **SCR‑F4‑S05 (Label fidelity).** Tech label is **idiomatic to the Context**; Plain label does not widen meaning.\n* **SCR‑F4‑S06 (No Cross‑context import).** Invariants reference only the Context’s idiom or other **SenseCells** by **name** (no identity claims).\n* **SCR‑F4‑S07 (Holder clarity).** Holder scope is a **single coherent kind** (e.g., `U.System` or `U.Work`), not a grab‑bag.\n* **SCR‑F4‑S08 (No tooling/governance).** Card contains **no** mentions of manifests, pipelines, editors, or workflows.\n\n#### F.4:14.2 - Regression (RSCR)\n\n* **RSCR‑F4‑E01 (Edition churn).** When a Context edition changes, existing cards are **not overwritten**; new cards are added per SenseCell.\n* **RSCR‑F4‑E02 (Refinement safety).** If **T′ ⪯ T** is introduced, prior usages of **T** remain conceptually valid; no backward contradictions arise.\n* **RSCR‑F4‑E03 (senseFamily integrity).** No card changes senseFamily across revisions (Role↔Status) without an explicit **split** noted.\n* **RSCR-F4-E04 (Bridge discipline).** After adding an **F.9 Bridge**, Role Description cards remain **unchanged**; cross-context meanings do not seep back into cards.\n* **RSCR‑F4‑E05 (Label updates).** Label changes per **F.5** preserve SenseCell and invariants; tests treat them as **renames**, not semantic edits.\n",
        "didactic_distillation_(60‑second_close)": "### F.4:15 - Didactic distillation (60‑second close)\n\n> A Role Description card is a **Context-true** way to speak about an assignable: a **Role** (behavioural mask) or a **Status** (epistemic/deontic badge).\n> Each card names **one SenseCell**, gives a **Tech/Plain** label, states **minimal invariants**, and declares what it **does not** imply.\n> Cards never mix **Role/Status senseFamilies** and never cross **I/D/S layers**, never flip time stance, and never import other Contexts.\n> Inside one context, you can compare cards by **equivalence** (≡), **refinement** (⪯), **incompatibility**, and **co‑wearability**.\n> across Contexts, say nothing in the card; use a **Bridge** later.\n> Keep cards **one‑screen simple**: enough to decide assignments; nothing procedural; no tools; just clear thought.\n",
        "f.4:end": "### F.4:End\n"
      },
      "content": "### F.4:End\n",
      "metadata": {},
      "part": "F",
      "cluster": null
    },
    {
      "id": "F.5",
      "title": "Naming Discipline for U.Types & Roles",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## F.5 - Naming Discipline for U.Types & Roles\n\n**Status.** Definitional pattern, architheory‑agnostic.\n**Depends on.** E.10.D1 **Lexical Discipline for “Context” (D.CTX)**; **E.10.D2 Intension–Description–Specification (I/D/S)**; F.1 **Domain‑Family Landscape Survey**; F.2 **Term Harvesting & Normalisation**; F.3 **Intra‑Context Sense Clustering**; F.4 **Role Description Definition**; A.7 **Strict Distinction**; A.11 **Ontological Parsimony**; F.0.1 **context‑local Lexicon Principle (RLP)**.\n**Coordinates with.** F.7 **Concept‑Set Table**; F.8 **Mint or Reuse?**; F.9 **Alignment & Bridge**; F.13 **Term Registry & Deprecation**.\n**Aliases (informative).** *Context‑true naming*; *Two‑register labels*.\n\n",
        "intent_&_applicability": "### F.5:1 - Intent & applicability\n\n**Intent.** Provide a **small, normative code of naming** so that **U.Types** (Cross‑context categories) and **Role Descriptions** (context‑local Roles/Statuses) are labelled **clearly, locally faithful, and globally stable**, without importing tooling, workflows, or editorial process. Names are **consequences of meaning** fixed earlier (F.1–F.4), not badges invented to “stabilise” drifting words.\n\n**Applicability.** Use **whenever** you (a) mint or revise a **U.Type** name from a **Concept‑Set row** (F.7), or (b) assign labels to a **Role Description** (F.4). This pattern governs **what a good name must be**, not *how a team produces it*.\n\n**Non‑goals.** No registries, reviews, or hand‑offs. No style‑police for punctuation beyond conceptual clarity. No bridging or synonym decisions across Contexts (F.9 does that).\n\n",
        "problem": "### F.5:2 - Problem frame\n\nNaming errors cause structural errors:\n\n1. **Context denial.** A label hides its Context, inviting Cross‑context misuse (*“process”* used for both BPMN and PROV senses).\n2. **senseFamily blur.** Names conflate **Role** (behavioural mask) with **Status** (epistemic/deontic badge).\n3. **Over‑reach.** U.Types inherit jargon from one canon and sound global while being parochial.\n4. **Under-reach.** Role Description labels sound so generic that they pretend to be U.Types.\n5. **Unstable synonyms.** Labels drift to placate readers rather than reflect meaning fixed in SenseCells.\n\nThis code resolves these by **Context fidelity**, **senseFamily‑aware morphology**, and **two‑register pedagogy**.\n\n",
        "minimal_vocabulary_(this_pattern_only)": "### F.5:3 - Minimal vocabulary (this pattern only)\n\n* **Tech label** — the **Context‑idiomatic** name engineers expect *inside that Context*.\n* **Plain label** — a **teaching gloss** in simple English that does **not broaden** the sense.\n* **Symbolic alias** *(optional)* — conventional symbol if the canon uses one (e.g., “≤”).\n* **SenseCell** — the **(Context × Local-Sense)** address cited by a Role Description card (F.3–F.4).\n* **Concept‑Set row** — the Cross‑context table row that supports minting a **U.Type** name (F.7).\n\n",
        "core_idea_(didactic)": "### F.5:4 - Core idea (didactic)\n\n> **Name what the invariants already make true.**\n>\n> For Role Descriptions, **speak like the Context** (Tech), then **teach it** (Plain).\n> For U.Types, **speak like nobody’s Context**: pick the **neutral, minimal‑generality** label that best fits the **intersection** shown by your Concept‑Set row.\n\n",
        "normative_rules_—_role_descriptions_(context‑local_labels)": "### F.5:5 - Normative rules — Role Descriptions (context‑local labels)\n\nLet **T** be a Role Description in Context **C** with SenseCell `sense(T)=⟨C,σ⟩`.\n\n**R‑RD‑1 (Two registers).** Provide **both**:\n`Tech(T)` = the **Context‑idiomatic** phrase (exact canon wording if possible).\n`Plain(T)` = a brief, neutral explanation *that does not broaden meaning*.\n*Symbolic alias* is optional and purely informative.\n\n**R‑RD‑2 (No Context tags in labels).** Do **not** embed the Context name in the label (avoid “(BPMN)” in the label itself). Context is already carried by the **SenseCell**; keep labels clean.\n\n**R‑RD‑3 (senseFamily‑aware morphology).**\n— **Role** names are **countable nouns** for masks (e.g., *Participant*, *Operator*, *Reviewer*). Avoid verbs and gerunds. Add the suffix **“Role”** **only** if the Context idiom risks confusion with a substance or a status (e.g., *“Reviewer Role”* in a Context that also has a *“Reviewer Status”*).\n— **Status** names are **state nouns** or **adjectival‑noun collocations** (e.g., *Approved*, *Compliant*, *In‑Service*, *Access Role* (RBAC)). If a family of levels exists, encode the **level** (`Assurance L1`, `Readiness L2`) rather than inventing decorative adjectives.\n\n**R‑RD‑4 (Local idiom first).** Prefer the **canon’s term of art** even if it sounds narrower than a cross‑discipline cliché. The Plain label handles pedagogy; the Tech label honours the Context.\n\n**R‑RD‑5 (Minimal generality).** Choose the **narrowest label** whose invariants you actually assert. Do **not** “upgrade” *Task* to *Activity* or *Process* just to sound universal.\n\n**R‑RD‑6 (No permissions by stealth).** Role labels **must not** imply entitlement (*“Privileged Operator”* is a Status+Role mashup). Keep deontics in **Status** names in the **deontics Context**.\n\n**R‑RD‑7 (Edition‑neutral labels).** Do **not** bake edition/profile into labels. Edition lives in the **Context**; the card binds to a SenseCell that already encodes edition where needed.\n\n**R‑RD‑8 (Short and stable).** Favour **1–3 words**. Avoid rhetorical adjectives (*“robust, optimal, best‑practice”*).\n\n",
        "normative_rules_—_u.types_(cross‑context_labels)": "### F.5:6 - Normative rules — U.Types (Cross‑context labels)\n\nLet **U** be a U.Type minted from a **Concept‑Set row** (F.7) satisfying A.8 (≥3 domain families) AND MinInterFamilyDistance ≥ δ_family (from F1‑Card).\n\n+**R‑UT‑1 (Witnessed neutrality).** The Tech label **must not** be a term owned by one context when alternatives exist. Prefer **discipline‑neutral head nouns** (*Result, Reading, Execution, Evidence, Requirement, State, Type Node*). **Use** *Characteristic/Scale/Value/Level/Coordinate/Score/ScoringMethod* **only** when the U.Type denotes a **measurement‑sense** kind anchored in a declared **CharacteristicSpace**; otherwise avoid these measurement‑canon terms to prevent semantics bleed.\n\n**R‑UT‑2 (Minimal generality).** Name the **least upper sense** that all row witnesses share. If *Observation* and *Measurement* disagree, perhaps the U.Type is **Result** or **Reading**, not **Observation**.\n\n**R‑UT‑3 (No senseFamily mixing in names).** Do **not** name a U.Type with deontic or behavioural language (*“PermittedService”*, *“ResponsibleAgent”*). **Role/Status/Method/Execution** belong to **Role Descriptions (F.4)** or local senses; U.Types are *what‑it‑is* kinds, not *what‑it‑does* or *what‑is‑allowed*.\n\n**R‑UT‑4 (Head–modifier discipline).** Prefer **head nouns** with **light modifiers** over stacked compounds.\nGood: *Evidence Status*, *Requirement Status*, *Type Node*.\nRisky: *Multi‑stage‑workflow‑execution‑record* (compresses a scenario into a name).\n\n**R‑UT‑5 (No Context tags in names).** U.Types are **Context‑agnostic**; never append “(BPMN)”/“(PROV)”. Provenance for the row lives in F.7, not in the name.\n\n**R‑UT‑6 (Alias only for pedagogy).** Allow **Plain aliases** for teaching; **Tech label** is unique and stable. Synonym management belongs to **F.13**; do not invent alternates ad hoc.\n\n**R‑UT‑7 (Family coherence).** When minting a **family**, use **parallel shapes** (*… Status*, *… Level*, *… Characteristic* **only for measurement families with a declared CharacteristicSpace**) so related U.Types signal relation by form.\n\n**R‑UT‑8 (Symbolic names sparingly).** Symbols may be listed as *aliases* for readers of formal sections; they are **never** the U.Type’s Tech label.\n\n**R‑UT‑9 (No edition/version in name).** Versions live in the Concept‑Set evidence; the name denotes a **time‑robust kind**.\n\n",
        "twin_rules": "### F.5:7 - Twin rules\n\n**Mandatory Tech name.** Every `U.Type`/Role **MUST** declare a Tech name; plain twin is optional.\n**Role suffix invariant.** Role Tech names **MUST** end with `Role`; plain twin **MUST** keep “(role)” on first use.\n**No head elision.** Head terms **MUST NOT** be dropped in a way that changes expected Kind (e.g., _“Approval”_ ≠ _“Approver (role)”_).\n**One twin, one context.** At most one plain twin per Context; register in **E.10.P**.\n\n",
        "invariants_(normative,_lightweight)": "### F.5:8 - Invariants (normative, lightweight)\n\n**INV-F5-1 (Pair).** Every Role Description card and every U.Type **MUST** carry **Tech** and **Plain** labels; symbol is optional and informative.\n\n**INV-F5-2 (Context fidelity for Role Descriptions).** `Tech(T)` **MUST** be idiomatic for its Context; `Plain(T)` **MUST NOT** broaden `sense(T)`.\n\n**INV‑F5‑3 (Neutrality for U.Types).** `Tech(U)` **MUST** be discipline‑neutral with respect to the witness Contexts in its Concept‑Set row.\n\n**INV‑F5‑4 (senseFamily honesty).** Role Description **Role** labels are **behavioural masks**; Role Description **Status** labels are **states/badges**; neither sneaks in the other senseFamily.\n\n**INV‑F5‑5 (Minimality).** Labels **MUST** reflect the **minimal generality** supported by invariants (F.4 for Role Description, F.7 for U.Types).\n\n**INV-F5-6 (No Context tags).** Names **MUST NOT** embed Context/edition tags; that information resides in SenseCells (Role Description) and Concept-Set rows (U.Types).\n\n",
        "reasoning_primitives_(judgement_schemas,_notation‑free)": "### F.5:9 - Reasoning primitives (judgement schemas, notation‑free)\n\n> Pure mental checks; no tools implied.\n\n1. **Context-idiom check (Role Description).**\n   `T in Context C ⊢ idiomatic(Tech(T), C)`\n   *Reading:* The Tech label reads like the Context’s own term of art.\n\n2. **Plain‑safety check.**\n   `sense(T)=⟨C,σ⟩ ⊢ ¬broadens(Plain(T), σ)`\n   *Reading:* The Plain label explains without enlarging the sense.\n\n3. **Neutral‑witness check (U.Type).**\n   `witnessContexts(U)=R ⊢ neutral(Tech(U), R)`\n   *Reading:* The Tech label doesn’t privilege one witness Context’s jargon.\n\n4. **senseFamily form check (Role Description).**\n  `senseFamily(T)=Role ⊢ nounMask(Tech(T))`\n  `senseFamily(T)=Status ⊢ stateForm(Tech(T))`\n   *Reading:* The morphology matches the senseFamily.\n\n5. **Minimality proof.**\n  `inv(T) ⇒ nameScope(Tech(T)) ⊆ senseScope(sense(T))` (Role Description)\n   `rowWitnesses(U) ⇒ nameScope(Tech(U)) ⊆ intersectionScope(row)` (U.Type)\n   *Reading:* The name’s scope is **no wider** than what the invariants/witnesses support.\n\n6. **Collision ping.**\n  `similar(Tech(X), Tech(Y)) ∧ senseFamily(X)≠senseFamily(Y) ⊢ requireDisambiguatorOrSplit`\n  *Reading:* If two labels nearly coincide across senseFamilies, either add a **minimal** disambiguator (Role Description only, within Context idiom) or split concepts.\n\n",
        "micro‑examples_(illustrative)": "### F.5:10 - Micro‑examples (illustrative)\n\n**Role Description (BPMN Context).**\nTech: **Participant** - Plain: *actor in a workflow* - senseFamily: **Role**\n(*No “BPMN” in label; behaviour mask, not entitlement.*)\n\n**Role Description (RBAC Context).**\nTech: **Access Role** - Plain: *named permission set* - senseFamily: **Status**\n(*Deontic badge; not a behavioural mask.*)\n\n**Role Description (ITIL Context).**\nTech: **Service‑Level Objective** - Plain: *service target value* - senseFamily: **Status**\n(*Levelable family: SLO \\[target], SLI \\[indicator] handled in F.10/F.12 semantics, not in the label.*)\n\n**U.Type (from Concept‑Set row: SOSA Observation, PROV Activity (result‑bearing), ML Metric Reading).**\nTech: **Result** - Plain: *the produced value or record of a measurement/assessment*\n(*Neutral head noun when “Observation” is too Context‑coloured.*)\n\n**U.Type (from OWL class, FCA concept, taxonomy nodes).**\nTech: **Type Node** - Plain: *a node in a type hierarchy or lattice*\n(*Neutral across DL and FCA.)*\n",
        "anti‑patterns_&_remedies": "### F.5:11 - Anti‑patterns & remedies\n\n| #       | Anti‑pattern                | Symptom in labels                                                  | Why it harms thinking                                              | Remedy (rule‑backref)                                                                                               |\n| ------- | --------------------------- | ------------------------------------------------------------------ | ------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------- |\n| **A1**  | **Context tag leakage**        | `Participant (BPMN)`, `Activity (PROV)` baked into the label       | Labels pretend to carry provenance; duplicates appear across Contexts | **No Context tags in names.** Context is in the SenseCell / Concept‑Set, not the label. (R‑RD‑2, R‑UT‑5)                 |\n| **A2**  | **Globalised jargon**       | U.Type named `Observation` because SOSA uses it                    | Privileges one context; misleads DL/FCA readers                       | Pick neutral **head noun** (e.g., `Result`, `Reading`) when witnesses diverge. (R‑UT‑1, R‑UT‑2)                     |\n| **A3**  | **senseFamily mixing**      | `Privileged Operator`, `Compliant Reviewer Role`                   | Role + deontic Status fused; category error                        | Keep **Role** nouns for masks; put deontics in **Status** names, often in a deontics Context. (R‑RD‑3, R‑RD‑6)       |\n| **A4**  | **Verbified roles**         | `Observing`, `Controlling`, `Approving` as Role names              | Action words hide mask semantics; temporal confusion               | Use **countable nouns** for Roles: `Observer`, `Controller`, `Approver`. (R‑RD‑3)                                  |\n| **A5**  | **Edition coding**          | `SLO‑v4`, `Task‑IEC61131`                                          | Names fossilise an edition; brittle across time                    | Edition belongs to the **Context**; keep labels edition‑neutral. (R‑RD‑7, R‑UT‑9)                                     |\n| **A6**  | **Over-reach**              | Role Description `Activity` for a BPMN task, U.Type `Process` for run-time acts | Label outruns invariants; invites cross-context misuse                | Choose **minimal generality** that the invariants actually support. (R-RD-5, R-UT-2, INV-F5-5)\n| **A7**  | **Under‑reach / vagueness** | `Item`, `Thing`, `Record` for specific kins                        | No discriminative power; weak teaching                             | Prefer **discipline‑neutral yet informative** heads (`Type Node`, `Result`, `Requirement Status`). (R‑UT‑1, R‑UT‑4) |\n| **A8**  | **Symbol as name**          | U.Type named `λ` or `≤`                                            | Unsearchable; Context‑coloured conventions                            | Keep symbols **only as aliases**; Tech label is words. (R‑UT‑8)                                                     |\n| **A9**  | **Synonym spray**           | Multiple Tech labels for one U.Type                                | Fragmentation; alias drift                                         | One **Tech** label; further surface forms live in the **registry** (F.13). (R‑UT‑6, INV‑F5‑1)                       |\n| **A10** | **Compound overgrowth**     | `multi‑stage‑workflow‑execution‑record`                            | Encodes scenario in a name; unreadable                             | Use **head + light modifier**: `Execution Record` (if that is the U.Type at all). (R‑UT‑4)                          |\n| **A11** | **Context-idiom denial**       | Role Description in BPMN named `Actor` (imported from other Contexts) | Readers misapply foreign semantics                                 | Use the **Context’s term of art** in the Tech label; teach via Plain label. (R-RD-4)\n| **A12** | **Status as event**         | `Approval` status labelled `Approve`                               | Morphology hides state vs act                                      | Status labels are **state nouns** / **adjectival‑noun collocations**: `Approved`, `In Service`. (R‑RD‑3)           |\n| **A13** | **Bracketed twins**         | `Participant/Agent`, `Service/SLO` as single label                 | Two senses slipped into one card                                   | Pick **one** label per concept; the other lives as alias (F.13) or as a different card. (INV‑F5‑1, R‑UT‑6)          |\n| **A14** | **Family drift**            | `Assurance Rank`, `Assurance Tier`, `Readiness Level` mixed        | Readers fail to see relatedness                                    | Keep **family shape** parallel: `… Level`, `… Status`. (R‑UT‑7)                                                     |\n| **A15** | **Decorative adjectives**   | `Robust Process`, `Best‑practice Method`                           | Marketing words displace semantics                                 | Drop rhetoric; name the **kind**, not its quality. (R‑RD‑8)                                                        |\n\n",
        "worked_examples_(multi‑architheory)": "### F.5:12 - Worked examples (multi‑architheory)\n\n> Each example shows the **reasoning move** that leads to the label; no procedures, no tooling.\n\n#### F.5:12.1 - Role Description labels (context-local)\n\n**(a) BPMN Context — behavioural mask vs node word**\n\n* **SenseCell.** ⟨*BPMN 2.0*, local‑sense: lane/pool actor that enacts tasks⟩\n* **Decision.** Tech = **Participant** (Context idiom); Plain = *actor in a workflow*\n* **Why.** `Participant` is the mask; it is **not** the node (*Task*, *Event*). (R-RD-3, R-RD-4)\n\n**(b) RBAC Context — deontic badge**\n\n* **SenseCell.** ⟨*NIST RBAC*, local‑sense: named permission set assigned to sessions⟩\n* **Decision.** Tech = **Access Role**; Plain = *named permission set*\n* **Why.** It’s a **Status**, not a behavioural mask; deontic plane kept explicit. (R-RD-3, R-RD-6)\n\n**(c) ITIL Context — service target**\n\n* **SenseCell.** ⟨*ITIL 4*, local‑sense: target value for a service characteristic⟩\n* **Decision.** Tech = **Service‑Level Objective**; Plain = *service target value*\n* **Why.** Family will carry `… Level`, `… Indicator` in adjacent cards; avoids jargon drift. (R-RD-3, R-UT-7)\n\n**(d) IEC 61131-3 Context — run-time execution notion as Role Description?**\n\n* **SenseCell.** ⟨*IEC 61131‑3*, local‑sense: cyclic/event‑driven task unit⟩\n* **Decision.** For a Role Description **Status** of a run, label **Completed**, **Failed**, **Skipped** (Context idiom); avoid naming the **Work** itself here.\n* **Why.** The *record of work* is a **U.Type** elsewhere (A.15.1); Role Description in this Context carries **badges** of runs. (A.7 stance split; R-RD-3)\n\n#### F.5:12.2 - U.Type labels (from Concept‑Set rows)\n\n**Row R₁ (measurement‑sense):**\nSOSA: *Observation* • ML practice: *metric reading* • Metrology: *measurement result*\n\n* **Witness Contexts.** sensing; ML metrics; metrology\n* **Decision.** U.Type Tech = **Result**; Plain = *the produced value or record of a measurement/assessment*\n* **Why.** Neutral head noun covering all witnesses; avoids privileging SOSA’s *Observation*. (R‑UT‑1, R‑UT‑2)\n\n**Row R₂ (type‑structure):**\nOWL: *class* / *subclass* • FCA: *formal concept* (node in concept lattice)\n\n* **Witness Contexts.** DL; FCA\n* **Decision.** U.Type Tech = **Type Node**; Plain = *a node in a type hierarchy or lattice*\n* **Why.** Neutral over DL vs FCA; head‑modifier shape is stable. (R‑UT‑1, R‑UT‑4, R‑UT‑7)\n\n**Row R₃ (status family):**\nITIL: *incident status* • Safety cert.: *assurance level* • QA: *readiness level*\n\n* **Witness Contexts.** services; assurance; QA\n* **Decision.** Two U.Types: **Assurance Level**, **Readiness Level** (family‑coherent), plus **Requirement Status** (for normative clauses)\n* **Why.** Separates families; preserves level vs status distinction. (R‑UT‑7, R‑UT‑3)\n\n\n#### F.5:12.3 - Mixed scenario (service acceptance over execution traces)\n\n**Contexts in play.** IEC 61131‑3 (run), SOSA/SSN (sensing), ITIL 4 (services).\n\n1. **Role Description (ITIL)** — Tech: **Service-Level Objective**; Plain: *service target value*.\n2. **U.Type (from R₁)** — Tech: **Result** (to host measured values).\n3. **Role Description (IEC)** — Tech: **Completed** / **Failed** (Status on a run).\n4. **Name discipline payoff.** The sentence “*Compare IEC run **Results** against the ITIL **Service‑Level Objective***” is Context‑true without tags, because each label encodes its **senseFamily** and neutrality.\n\n",
        "migration_notes_(conceptual)": "### F.5:13 - Migration notes (conceptual)\n\n1. **When a Context changes edition.** Names stay; the **SenseCell** shifts to the new edition. Only change a label if the **sense** has changed; then **split** the card rather than mutate the name. (INV‑F5‑2, R‑RD‑7)\n\n2. **When a Concept‑Set row gains a new witness Context.** Re‑ask neutrality: if the Tech label now privileges a Context, **refactor to a more neutral head** (e.g., `Observation` → `Result`). (R‑UT‑1, R‑UT‑2)\n\n3. **Collision emergence.** If a **Role card** and a **Status card** converge phonetically (`Approver` vs `Approved`), keep both but add the **minimal morphological disambiguator** only where the Context idiom demands it (`Reviewer Role`). (R-RD-3)\n\n4. **Family hygiene.** As families grow, keep **parallel shapes** (`… Level`, `… Status`). If a legacy label breaks shape, add a **Plain alias** for teaching; don’t rename the Tech label without Concept‑Set pressure. (R‑UT‑7, R‑UT‑6)\n\n5. **Language variants.** Non-English canons keep **their own Tech labels** (idiomatic in that Context); the **Plain** label remains English in FPF unless the Part mandates localisation. (R-RD-4, INV-F5-1)\n\n6. **Symbol addition.** You may add a **symbolic alias** later for readers of formal sections; never promote a symbol to the Tech label. (R‑UT‑8)\n\n7. **De‑jargonising the Plain label.** If readers stumble, adjust **Plain** wording only; do **not** widen the sense. (Plain‑safety check)\n\n8. **Deprecation path.** If a label must change, publish the **new Tech + Plain**, keep the old as an **alias** in the registry (F.13), and leave the reasoning trail in the Concept‑Set row that forced the rename. (R‑UT‑6, F.13 linkage)\n",
        "acceptance_tests_(scr/rscr_—_concept‑level)": "### F.5:14 - Acceptance tests (SCR/RSCR — concept‑level)\n\n#### F.5:14.1 - Static conformance (SCR)\n\n* **SCR-F5-S01 (Two registers).** Every Role Description card and U.Type **has both** Tech and Plain labels; any symbol is marked **alias**.\n* **SCR-F5-S02 (Context fidelity for Role Descriptions).** For any Role Description `T` in Context `C`, `Tech(T)` appears idiomatic **in C**; `Plain(T)` does **not** broaden `sense(T)`.\n* **SCR‑F5‑S03 (Neutrality for U.Types).** For any U.Type `U`, its Tech label does **not** coincide with a witness Context’s proprietary term when alternatives exist.\n* **SCR‑F5‑S04 (senseFamily morphology).** Role labels are **countable nouns**; Status labels are **state nouns** / adjectival‑noun forms.\n* **SCR-F5-S05 (Minimal generality).** For each label, there exists a reading where the **name’s scope ⊆ invariant scope** (Role Description) or **⊆ row intersection** (U.Type).\n* **SCR‑F5‑S06 (No Context tags).** No label embeds Context or edition strings.\n* **SCR‑F5‑S07 (Family coherence).** Families that claim parity (e.g., Levels) show **parallel shapes** across members.\n\n#### F.5:14.2 - Regression checks (RSCR)\n\n* **RSCR‑F5‑E01 (Witness drift).** When a Concept‑Set row gains/removes a witness Context, re‑evaluate **neutrality**; if violated, refactor the Tech label to a more neutral head.\n* **RSCR-F5-E02 (Edition churn).** When a Context updates, Role Description labels remain stable unless the **sense** changed; if sense changed, **split** the card and keep aliases in F.13.\n* **RSCR‑F5‑E03 (Collision guard).** If two labels become confusable across **senseFamilies**, either add the **minimal** disambiguator (Role Description only, Context‑idiom) or separate the concepts.\n* **RSCR‑F5‑E04 (Rhetoric creep).** Periodic skim for decorative adjectives; remove them unless they encode formal levels or families.\n",
        "didactic_distillation_(60‑second_recap)": "### F.5:15 - Didactic distillation (60‑second recap)\n\n> **Name what is already true.**\n> Role Description labels **speak like the Context** (Tech) and **teach without widening** (Plain).\n> U.Type labels **speak like nobody’s Context**: neutral head nouns at **minimal generality**, shaped in **parallel families**.\n> **Never** glue Context tags or editions into names. **Never** mix senseFamilies in morphology.\n> If witnesses change, reconsider neutrality; if senses split, **split names**, don’t stretch them.\n> The label is the **last step of understanding**, not the first.\n\n",
        "f.5:end": "### F.5:End\n"
      },
      "content": "### F.5:End\n",
      "metadata": {},
      "part": "F",
      "cluster": null
    },
    {
      "id": "F.6",
      "title": "Role Assignment & Enactment Cycle (Six-Step)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## F.6 - Role Assignment & Enactment Cycle (Six-Step)\n\n**“Assign only what you can later justify by local meaning and observable facts.”**\n**Status.** Architectural pattern, architheory‑agnostic.\n**Depends on.** E.10.D1 **Lexical Discipline for “Context” (D.CTX)**; F.1 **Domain‑Family Landscape Survey**; F.2 **Term Harvesting & Normalisation**; F.3 **Intra‑Context Sense Clustering**; F.4 **Role Description**; F.5 **Naming Discipline**.\n**Coordinates with.** F.7 **Concept‑Set Table**; F.8 **Mint or Reuse?**; F.9 **Alignment & Bridge**; F.10 **Epistemic Status Mapping**; A.2.1 **U.RoleAssignment**; A.15.\\* **Role–Method–Work alignment**; KD‑CAL (observations, results).\n**Aliases (informative).** *Assign-and-verify mental loop*; *six-step role cycle*.\n",
        "intent_&_applicability": "### F.6:1 - Intent & applicability\n\n**Intent.** Provide a **minimal set of reasoning moves** that turn a **Role Description** (F.4), anchored in a **SenseCell**, into a **sound claim** about a concrete **holder**—either a **Role assignment** or a **Status assertion**—with **local meaning** (within one context) and a **clear path to evidence** (KD‑CAL). These are **mental moves**, not workflows or tools.\n\n**Applicability.** Any time you (a) bind a system to a **Role** mask, or (b) assert a **Status** about a system/artefact, **inside one U.BoundedContext**. Use when drafting models, reconciling vocabularies, or reading external canons.\n\n**Non‑goals.** No process charts, no registries, no governance roles. No Cross‑context equivalences (that is F.9). No operational runbooks—only conceptual judgements.\n",
        "problem": "### F.6:2 - Problem frame\n\nWithout disciplined Role Assignment & Enactment reasoning:\n\n1. **Sense‑family slippage.** Behavioural **Roles** and deontic/epistemic **Statuses** get mixed (keep them on distinct **senseFamilies**, per F.0.1).\n2. **Context drift.** A label is lifted from one canon and used as if universal.\n3. **Evidence vacuum.** Assignments are asserted with no thought to what could **show** they hold.\n4. **Time blur.** Design‑time masks are judged by run‑time traces (or vice versa).\n5. **Name inflation.** New labels are minted to patch noisy assignments.\n",
        "forces": "### F.6:3 - Forces\n\n| Force                       | Tension to resolve                                                                   |\n| --------------------------- | ------------------------------------------------------------------------------------ |\n| **Locality vs reuse**       | Keep meaning inside one context while still naming things once across examples.         |\n| **Clarity vs completeness** | State enough to be checkable without burying the reader in conditions.               |\n| **Design vs run**           | Keep **stance** coherent: design‑time bindings are judged by design artefacts; if you need run‑time verification, express it as a **run‑Status/Role** Template—without confusing **stances** (A.7). |\n| **Fact vs promise**         | Evidence (KD‑CAL) vs deontic expectations (service, policy) must not collapse.       |\n",
        "minimal_vocabulary_(this_pattern_only)": "### F.6:4 - Minimal vocabulary (this pattern only)\n\n* **Context** — shorthand for **U.BoundedContext** (per E.10.D1).\n* **SenseCell σ** — **address** **⟨Context C × Local‑Sense ℓ⟩** per F.3. (Informative: we write simply **σ**; it already contains **C**.)\n* **Role Description** — a **Role** or **Status** card anchored in a SenseCell (F.4).\n* **Holder** — the concrete system/artefact considered for a **Role** binding.\n* **Subject** — the referent of a **Status** assertion; determined by the Template (may or may not be the Holder).\n* **subject_of(τ, H)** — function yielding the **Subject** for Status assertions given Template **τ** (and, if needed, candidate **H**).\n* **Eligibility** — conditions on the Holder that *must* hold to apply the Template (F.4 invariants).\n* **Window** — the DesignRunTag or interval relevant to the claim (design/run; instant/period).\n* **Evidence shape** — the **Observation/Result/Procedure/Feature** pattern (KD‑CAL) that could confirm/refute the claim in its Context.\n",
        "pre‑conditions_(lightweight)": "### F.6:5 - Pre‑conditions (lightweight)\n\n1. The **Context** is in your F.1 cut; **Context ≡ U.BoundedContext**.\n2. The **Template** references a **SenseCell** in that Context (F.4).\n3. The **Holder** is identified (by type or instance) without relying on Cross‑context mappings.\n",
        "the_six_moves_(judgement_schemas,_notation‑free)": "### F.6:6 - The six moves (judgement schemas, notation‑free)\n\nEach move is a **thought you can justify**, expressed as `premises ⊢ conclusion`.\nAll moves are **context‑local** and **side‑effect free** (they assert knowledge; they do not modify artefacts).\n\n#### F.6:6.1 - M1 - Locate — *Fix the Context and the Template*\n\n**Form.**\n`Template τ anchored at SenseCell σ≡⟨C, ℓ⟩ ⊢ address(τ) = σ`\n\n**Reading.** Name the Context and the exact SenseCell that gives **local meaning** to the Template.\n**Note.** This forbids “floating” Roles/Statuses and prevents Context drift.\n\n#### F.6:6.2 - M2 - Stance — *Respect DesignRunTag*\n\n**Form.**\n`stance(C)=s ∧ stance(τ)∈{s, both} ⊢ compatible_stance(τ,C)`\n\n**Reading.** The Template’s DesignRunTag is **compatible** with its Context’s stance (design vs run).\n**Note.** Guards against judging a design‑mask by run‑traces or judging a run‑status by design artefacts.\n\n#### F.6:6.3 - M3 - Qualify — *Check Holder eligibility*\n\n**Form.**\n`Holder H ∧ eligibility(τ) holds in C ⊢ eligible(H, τ @ C)`\n\n**Reading.** Given the Template’s eligibility predicates (F.4), the Holder qualifies to be bound/assessed **in this Context**.\n**Note.** Typical predicates: **type membership**, **capability present**, **scope fit**; all context‑local.\n\n#### F.6:6.4 - M4 - Bind/Assert — *Make the Role Assignment / Status claim*\n\n**Role assignment (behavioural mask).**\n`eligible(H, τ @ C) ∧ window W ⊢ plays_role(H, τ : C) @ W`\n\n**Status assertion (epistemic/deontic state).**\n`eligible(H, τ @ C) ∧ window W ∧ S = subject_of(τ, H) ⊢ has_status(S, τ : C) @ W`\n\n**Reading.** Assert either a **Role** binding or a **Status** about the appropriate subject (system, artefact, service), within a **Window**.\n**Note.** The **subject** of a Status may differ from the Role holder (e.g., a *service* has SLO status; a *team* plays a Role).\n\n#### F.6:6.5 - M5 - Evidence — *Shape what would make it true/false*\n\n**Form.**\n`plays_role/has_status κ in C ⊢ evidence_shape(κ) = Σ(C)`\n\n**Reading.** From the Context’s semantics, state the **Observation/Result** pattern (KD‑CAL) that would confirm or refute the claim (**what**, **where**, **when**).\n**Note.** This is not an execution plan: it is a **conceptual test** tied to the Context’s vocabulary.\n\n#### F.6:6.6 - M6 - Conclude — *Issue a defensible verdict with confidence*\n\n**Form.**\n`evidence E fits Σ(C) ∧ invariants(τ) hold ⊢ holds(κ) with confidence γ ∈ [0,1]`\n\n**Reading.** If observed facts match the expected evidence shape and Template invariants stand, the assignment/status claim **holds** with some confidence (cf. B.3).\n**Note.** Confidence combines measurement adequacy (KD‑CAL) with any Context‑specific uncertainty; no Cross‑context boost is implied.\n\n#### F.6:6.7 - Autonomy admission (Green‑Gate) and ledger\n* **Before enactment:** If the Method step lists `requiresAutonomyBudget`, the enacting `U.RoleAssignment` **MUST** pass the **Autonomy Green‑Gate**: (i) active/enactable RSG state, (ii) budget tokens/envelope remain in the declared **Γ_time** window, (iii) all guards `pass`.\n* **On enactment:** Write an **AutonomyLedgerEntry** attached to the `U.Work`, with deltas and guard verdicts.\n* **On depletion:** Block further autonomy‑gated steps; emit a **DepletionNotice** (SpeechAct) and follow the `OverrideProtocolRef`.\n* **SoD:** Enforce `⊥` between autonomy consumer Role and override caller Role.\n",
        "core_invariants_(normative)": "### F.6:7 - Core invariants (normative)\n\n1. **Locality.** Every judgement is **about one context**. No Cross‑context equivalence is presumed or implied (that is F.9’s remit).\n2. **Strict splits.** (**a**) **senseFamily split:** **Role** ≠ **Status** (per F.0.1); (**b**) **stance split:** **design** ≠ **run** (A.7). Each judgement names its **senseFamily** and **stance**.\n3. **Eligibility before claim.** No binding or status without **eligible(H, τ @ C)**.\n4. **Window honesty.** Every claim states or inherits a **Window** consistent with `stance(τ)` and `stance(C)`.\n5. **Evidence‑ability.** Every claim must admit at least one **evidence shape** Σ in its Context (KD‑CAL compatible).\n6. **Name discipline.** Labels used in judgements follow F.5 (Tech/Plain registers; no Context tags inside names).\n",
        "reasoning_aides_(didactic)": "### F.6:8 - Reasoning aides (didactic)\n\n* **Context‑prefix speech.** Think and speak with the **Context prefix** when ambiguity lurks: *participant (BPMN)*, *role (RBAC)*, *activity (PROV)*.\n* **Window templates.** Prefer short phrases: *“during release‑R3 cutover”*, *“for the Q3 service period”*, *“at 2025‑08‑12T14:30Z”*.\n* **Evidence as shape words.** *Result of Observation of ⟨Characteristic⟩ on ⟨Feature⟩ by ⟨Procedure⟩ within W*—not a measurement script.  \n\n**“Assign only what you can later justify by local meaning and observable facts.”**\n",
        "anti‑patterns_&_remedies": "### F.6:9 - Anti‑patterns & remedies\n\n| #         | Anti‑pattern                   | Symptom                                                                                     | Why it harms reasoning                                                     | Remedy (conceptual move)                                                                                                     |\n| --------- | ------------------------------ | ------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------- |\n| **AP-1**  | **cross-context Binding**      | A single binding/assertion mixes two Contexts (status/role in C₁ justified by semantics in C₂) without an explicit Bridge. | Violates **Locality**; smuggles a Bridge (kind/CL/Loss) into the claim, making it hard to replay and easy to treat as free substitution. | Re-formulate strictly in one context. If cross-context support is essential, defer to **F.9 Bridge** and keep the assignment/status claim local. |\n| **AP‑2**  | **Role/Status Conflation**     | “Operator” modeled as a deontic grant; “SLO met” modeled as a Role.                         | Collapses **behavioural mask** and **epistemic/deontic state** (A.7).      | Re‑type the Template: **Role** for “can/does”, **Status** for “is/has (as a claim)”. Use **M4** accordingly.                 |\n| **AP‑3**  | **Window‑less Claims**         | Binding/assertion with no time stance or interval.                                          | Uncheckable; invites retrospective reinterpretation.                       | Make **Window** explicit (§6 M4). Inherit stance from the Context/Template if fixed; otherwise state it.                        |\n| **AP‑4**  | **Eligibility‑after‑the‑fact** | Declaring the claim, then back‑fitting eligibility to observed traces.                      | Confuses **necessary conditions** with **diagnostics**; risks circularity. | Perform **M3 Qualify** *before* **M4 Bind/Assert**; treat evidence only in **M5**/**M6**.                                    |\n| **AP‑5**  | **Global Label Illusion**      | Using bare labels (“process”, “agent”, “role”) as if universal.                             | Hides the Context; fuels homonym errors.                                      | Always recover **M1 Locate**: `address(τ)=⟨Context, SenseCell⟩`. Use F.5 naming discipline (Tech/Plain registers).              |\n| **AP‑6**  | **Evidence by Prestige**       | “Industry practice says …” offered instead of KD‑CAL‑shaped facts.                          | Replaces observable Results with authority talk.                           | State an **evidence shape Σ(Context)** in **M5**; later fill it with **Observation/Result** facts (KD‑CAL).                     |\n| **AP‑7**  | **Design/Run Inversion**       | Verifying a design‑time mask by design documents; verifying a run‑status with design specs. | Violates DesignRunTag; yields non‑falsifiable claims.                   | Apply **M2 Stance**: the Template’s stance must be compatible with the Context. Evidence follows the stance.                    |\n| **AP-8**  | **Premature Bridge**           | A Bridge is introduced as a shortcut (“align first, then claim”), instead of stating the assignment/status locally and adding a Bridge only when actually needed. | Makes the verdict hostage to an uncertain translation; Bridge Loss and CL penalties leak into the claim and can unnecessarily lower confidence. | Keep the assignment/status claim local; if needed, create an **F.9 Bridge** with loss notes and CL penalty. |\n| **AP‑9**  | **Token Proofs**               | Single anecdotal event taken as universal confirmation.                                     | Over‑generalises; ignores evidence windows and procedures.                 | In **M5**, include **Procedure** and **Window**; in **M6**, roll confidence γ from adequacy of sampling (KD‑CAL).            |\n| **AP‑10** | **Role Explosion as Patch**    | New Role minted for every exception.                                                        | Name bloat; brittle semantics.                                             | Re‑examine **eligibility** and **Window**; consider a **Status** to mark exceptions instead of new Roles.                    |\n| **AP‑11** | **Subject Drift**              | Status asserted on the wrong subject (team vs service; asset vs dataset).                   | Breaks referent clarity; evidence no longer matches.                       | Use **M4**’s split: **plays\\_role(H, …)** vs **has\\_status(subject(H), …)**; pick the correct subject kind.                  |\n| **AP‑12** | **Spec‑in‑Name**               | Cramming constraints into the label (“24x7‑Operator‑With‑Pager”).                           | Names become brittle; invariants become invisible.                         | Keep the label minimal (F.5); move constraints into **eligibility**/**invariants**.                                          |\n| **AP‑13** | **Non‑Local Evidence Shape**   | Evidence shape mentions constructs from another Context.                                       | Hidden Cross‑context import.                                                  | Rewrite Σ using only this Context’s vocabulary; if impossible, use **F.9** Bridge and keep Σ local.                             |\n",
        "worked_examples_(multi‑architheory)": "### F.6:10 - Worked examples (multi‑architheory)\n\n> Each example is a **context-local** assignment/status reasoning trace using **M1…M6**. cross-context relations, if any, are noted as *optional* bridges (F.9) but not relied upon.\n\n#### F.6:10.1 - Service availability status (ITIL + KD‑CAL)\n\n**Context.** *ITIL 4 (services family; design)*\n**Template (Status).* `SLO:availability≥99.9%` anchored at **SenseCell** ⟨ITIL4, “SLO (availability)”⟩.\n\n**M1 Locate.** `address(τ)=⟨ITIL4, SLO(availability)⟩`\n**M2 Stance.** `stance(ITIL4)=design`, `stance(τ)=design` ⇒ `compatible_stance(τ, ITIL4)`\n**M3 Qualify.** `eligible(Service S, τ@ITIL4)` if S is a published service with declared availability target.\n**M4 Assert.** `has_status(S, τ:ITIL4) @ W` where `W = Q1‑2025` (the evaluation period).\n**M5 Evidence shape Σ(ITIL4).** *Observation* of **availability characteristic** (MM‑CHR) for S, produced by a **Procedure** that samples uptime and computes the **Result** as ratio over `W`. (KD‑CAL/MM‑CHR terms only; no tool implied.)\n**M6 Conclude.** If Results across `W` give ≥ 99.9 % with adequate sampling and declared exclusions applied, `holds( has_status(S, τ:ITIL4) @ W ) with γ≈0.9`.\n*Optional bridge.* If uptime sensing vocabulary is expressed in **SOSA/SSN**, an **F.9 Bridge** may map ITIL’s “availability metric” to **ObservableProperty(availability)** with a declared CL penalty; the assignment/status claim itself remains ITIL-local.\n\n#### F.6:10.2 - Behavioural operator role (IEC 61131‑3 + Enactment)\n\n**Context.** *IEC 61131‑3 (control languages; run)*\n\\**Template (Role).* `Control‑Task‑Executor` anchored at **SenseCell** ⟨IEC61131‑3, “task executes program”⟩.\n\n**M1 Locate.** `address(τ)=⟨IEC61131‑3, task‑execution⟩`\n**M2 Stance.** `stance(IEC61131‑3)=run`, `stance(τ)=run` ⇒ compatible.\n**M3 Qualify.** Holder `PLC_7` qualifies if it hosts program `P` and is scheduled by task `T`.\n**M4 Bind.** `plays_role(PLC_7, τ:IEC) @ W` where `W = [08:00, 18:00] 2025‑06‑05`.\n**M5 Evidence shape Σ(IEC).** **Observation** of task schedule and program invocation logs as **Results** for features `T`/`P` during `W`; presence of expected cyclic/event‑driven triggers.\n**M6 Conclude.** If Results show the expected executions with no missed cycles beyond tolerance, `holds( plays_role(PLC_7, τ:IEC) @ W ) with γ≈0.8`.\n*Trip-wire.* Do **not** restate this as “PROV Activity” without **F.9**; keep the assignment/status claim IEC-local.\n\n#### F.6:10.3 - Dataset accuracy status (ISO/IEC 25024 + KD‑CAL)\n\n**Context.** *ISO/IEC 25024 (data‑quality; design)*\n\\**Template (Status).* `accuracy≥0.98` anchored at **SenseCell** ⟨ISO25024, “data accuracy”⟩.\n\n**M1 Locate.** `address(τ)=⟨ISO25024, data‑accuracy⟩`\n**M2 Stance.** `stance(Context)=design`, `stance(τ)=design` ⇒ compatible.\n**M3 Qualify.** Subject `Dataset D` has a defined **reference set** and sampling protocol.\n**M4 Assert.** `has_status(D, τ:ISO25024) @ W` where `W = “snapshot v2025‑04”`.\n**M5 Evidence shape Σ(ISO25024).** **Observation** of correctness of sampled records vs reference, **Procedure** per standard, **Result** as proportion correct with confidence interval.\n**M6 Conclude.** If CI lower bound ≥ 0.98, `holds( has_status(D, τ) @ W ) with γ≈0.85`.\n\n#### F.6:10.4 - Access vs behavioural: two claims, two Contexts\n\n**Contexts.** *NIST RBAC (access; design)* and *BPMN 2.0 (workflow; design)*.\n**Templates.** `DB‑Admin (RBAC status)` vs `Participant (BPMN role)`.\n\n**RBAC claim (Status).**\nM1…M6 yield `has_status(User U, RBAC:DB‑Admin) @ W_dir` with Σ(RBAC) = **Observation** of assignment state in the access model at time `W_dir`.\n\n**BPMN claim (Role).**\nM1…M6 yield `plays_role(Team T, BPMN:Participant) @ W_proc` with Σ(BPMN) = **Observation** that lanes/pools enact tasks during `W_proc`.\n\n**Lesson.** Two separate **context-local** claims — one **Status assertion** and one **Role assignment**; **no** implication that holding RBAC status entails playing the BPMN Role.\n",
        "relations": "### F.6:11 - Relations (with other patterns)\n\n**Builds on:**\nF.1 **Domain‑Family Landscape Survey** (Contexts fixed); F.2 **Term Harvesting** (local terms); F.3 **Intra‑Context Clustering** (SenseCells); F.4 **Role Description** (invariants, stance); F.5 **Naming Discipline** (labels).\n\n**Constrains:**\n**F.7** (Concept-Set Table): rows reference **SenseCells**; Role Description cards **point to** those rows but never **create** cross-context identity.\n**F.8 Mint or Reuse?** Uses outcomes of **Role/Status** claims to decide: a new **Role/Status** label only when existing Templates cannot express the claim with eligibility/Window adjustments.\n**F.9** (Alignment & Bridge): any relation across Contexts is **declared there**; Role Description cards remain context-local.\n**F.10 Epistemic Status Mapping.** Consumes **M6** confidences γ and Σ‑adequacy to roll up assurance.\n\n**Coordinates with.** **MM‑CHR** (characteristics, scales) wherever *Characteristic/Scale* is used in evidence shapes.\n\n**Used by.**\nArchitheories (Part C) to anchor their examples: Sys‑CAL (execution/actuation roles), KD‑CAL (measurement statuses), Method‑CAL (execution claims for Methods/MethodDescription), Kind-CAL (typing claims remain outside Role Assignment & Enactment, but may inform eligibility predicates).\n",
        "migration_notes_(conceptual)": "### F.6:12 - Migration notes (conceptual)\n\n1. **Template refactor.** If a Template’s invariants change, **claims remain as‑is**; re‑evaluate **M6** on demand. Do not silently rewrite past claims.\n2. **Edition updates.** When a Context’s canon updates, treat it as a **new Context** if sense shifts; Claims anchored to the old Context stay valid for their Window.\n3. **Name revisions.** Renaming per F.5 does not alter **address(τ)=⟨Context, SenseCell⟩**; claims reference the address, not surface form.\n4. **Bridge introduction.** Adding an **F.9 Bridge** never upgrades an existing Role/Status claim; at most it enables *separate* translations with declared loss.\n5. **From exception to Status.** If recurring exceptions to a Role appear, prefer minting a **Status** Template that marks the exception rather than proliferating Roles.\n6. **Window tightening.** If evidence shows drift, narrow future **Windows**; past claims remain tied to their original Windows.\n",
        "acceptance_tests_(scr/rscr_—_concept‑level)": "### F.6:13 - Acceptance tests (SCR/RSCR — concept‑level)\n\n#### F.6:13.1 - Static conformance (SCR)\n\n* **SCR-F6-S01 (Local address).** Every assignment/status claim states `address(τ)=σ` where `σ` is a **SenseCell** (per F.3); no bare labels.\n* **SCR‑F6‑S02 (SenseFamily clarity).** Each claim is typed **Role** or **Status**, never both; subjects are of the correct kind. Claim records both **senseFamily** and **stance** explicitly or by inheritance.\n* **SCR‑F6‑S03 (Stance compatibility).** `stance(Context)` and `stance(τ)` are compatible (design/run).\n* **SCR‑F6‑S04 (Eligibility first).** For each claim, `eligible(H, τ@context)` is derivable prior to assertion.\n* **SCR‑F6‑S05 (Window explicit).** Each claim has a Window (explicit or inherited) consistent with stance.\n* **SCR‑F6‑S06 (Evidence‑ability).** For each claim, an **evidence shape Σ(Context)** is stated using only that Context’s vocabulary plus KD‑CAL/MM‑CHR primitives.\n* **SCR‑F6‑S07 (Locality guard).** No Cross‑context terms appear inside a claim; any reference to other Contexts is flagged as **F.9 Bridge (informative)**, not used to justify the claim.\n\n#### F.6:13.2 - Regression (RSCR)\n\n* **RSCR‑F6‑E01 (Edition stability).** Adding a new edition/Context does not mutate existing claims’ Contexts or Windows.\n* **RSCR‑F6‑E02 (Name stability).** Changing labels per F.5 leaves addresses and conclusions invariant.\n* **RSCR‑F6‑E03 (Bridge neutrality).** Introducing or revising an **F.9 Bridge** does not auto‑flip claim truth values; at most it enables explicit translations with loss notes.\n* **RSCR‑F6‑E04 (Evidence refresh).** When KD‑CAL procedures or **MM‑CHR characteristic scales** change, only **γ** is re‑evaluated; the claim’s semantics remain.\n",
        "didactic_distillation_(60‑second_recap)": "### F.6:14 - Didactic distillation (60‑second recap)\n\n> **Six moves.** (M1) *Locate* the Context & SenseCell; (M2) check **stance**; (M3) test **eligibility**; (M4) **bind/assert** with a **Window**; (M5) sketch the **evidence shape** in that Context; (M6) **conclude** with confidence γ.\n> **Two iron rules.** Keep it **context‑local**; keep **Role** and **Status** on their senseFamily.\n> **Pay-off.** Assignment/status claims become small, auditable thoughts: easy to teach, easy to check, and easy to relate—later—via explicit Bridges when you truly must step between Contexts.\n",
        "f.6:end": "### F.6:End\n"
      },
      "content": "### F.6:End\n",
      "metadata": {},
      "part": "F",
      "cluster": null
    },
    {
      "id": "F.7",
      "title": "Concept‑Set Table",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## F.7 - Concept‑Set Table\n\n**“Show one thing across Contexts—only where explicit bridges allow it.”**\n\n**Status.** Architectural pattern, architheory‑agnostic.\n**Depends on.** E.10.D1 **Lexical Discipline for ‘Context’** (Context ≡ `U.BoundedContext`); **F.0.1 senseFamily (normative)**; F.1 **Domain‑Family Landscape Survey**; F.2 **Term Harvesting**; F.3 **Intra‑Context Sense Clustering** (SenseCells); F.5 **Naming Discipline**; F.9 **Alignment & Bridge Across Contexts**.\n**Coordinates with.** F.4 **Role Description**; F.6 **Role Assignment & Enactment Cycle (Six-Step)**; Part C architheories (for examples), **MM‑CHR (for Characteristic)**.\n**Aliases (informative).** *Concept‑Set table*, *comparison grid*.\n\n",
        "intent_&_applicability": "### F.7:1 - Intent & applicability\n\n**Intent.** Provide a **single, didactic page** where each **row** presents **one Concept‑Set**—a *set of SenseCells from different Contexts that we are licensed (by explicit Bridges) to treat as “the same for a stated scope”*. Columns are **Contexts**; cells carry **local labels**. The table **does not invent equivalences**: it **summarises** already declared **F.9 Bridges**, exposing *scope, losses, and counter‑examples* at a glance.\n\n**Applicability.** Use whenever cross-context reading is necessary (naming U.Types, teaching contrasts, assignment/enactment-adjacent terminology). It is a **reading lens**, not a data model: **notation-free**, **governance-free**, **Context-loyal**.\n\n**Non‑goals.** No hidden merges. No “global terms”. No workflows or tool schemas. The table is a **conceptual display** of *licensed sameness* and *honest non‑sameness*.\n\n",
        "problem": "### F.7:2 - Problem frame\n\nWithout a disciplined Cross‑context view:\n\n1. **Silent equivalence.** Readers assume sameness by name alone (e.g., *process*).\n2. **Loss denial.** Mappings hide what is dropped (DesignRunTag, units, agency).\n3. **Name inflation.** New U.Types are coined to avoid facing heterogeneity.\n4. **Cognitive scatter.** Concepts drift across documents without one compact, teachable “where‑what‑how‑same” view.\n\n",
        "forces": "### F.7:3 - Forces\n\n| Force                          | Tension to resolve                                                                                            |\n| ------------------------------ | ------------------------------------------------------------------------------------------------------------- |\n| **Locality vs comparison**     | Meaning lives in Contexts; yet we must **compare** Contexts to reason across disciplines.                           |\n| **Didactics vs fidelity**      | A compact row is easy to grasp; it must still show **scope and loss** honestly.                               |\n| **Simplicity vs completeness** | A minimal grid aids memory; temptation to overload it with proofs and procedures must be resisted.            |\n| **Sameness vs difference**     | Some families **cannot** be unified; the table must support **contrast rows** without pretending equivalence. |\n\n",
        "core_idea_(didactic)": "### F.7:4 - Core idea (didactic)\n\nA **Concept‑Set** is a **finite set of addresses**\n\n$$\n\\text{CS}=\\{\\langle \\text{Context}_i,\\ \\text{SenseCell}_i\\rangle\\}_{i=1..n}\n$$\n\nthat FPF **treats as one** *for a declared scope* because there exist **F.9 Bridges** connecting these SenseCells pairwise (directly or via a short chain) with **congruence level** $\\text{CL}$ above a **threshold** suitable for that scope. The **table row** shows:\n\n* **FPF Label** *(Tech/Plain)* — the *didactic, FPF‑level* name chosen per F.5.\n* **Row Scope** — where “being one” is safe (e.g., *Naming-only*, *assignment/enactment-eligibility*, *KD-CAL metric*, *Type‑structure*).\n* **Row CL(min)** — the **minimum CL** of the Bridges that justify the row.\n* **Context columns** — each cell: the **local label** + (optional) short cue.\n* **Rationale (one line)** — why sameness is warranted *for this scope*.\n* **Counter‑examples (one line)** — where/why sameness **breaks**.\n\n> **Memory hook.** *A Concept‑Set row is a promise:* “You may **read across** these Contexts **this far—and no farther**.”\n\n",
        "minimal_vocabulary_(this_pattern_only)": "### F.7:5 - Minimal vocabulary (this pattern only)\n\n* **Context** — shorthand for `U.BoundedContext` (per E.10.D1).\n* **senseFamily** — **referenced from F.0.1**; not redefined here; used to **type** rows and to require **uniformity** within a row.\n* **SenseCell** — a **(Context × Local‑Sense)** address from F.3.\n* **Bridge (F.9)** — an explicit, declarative Cross‑context mapping with a **congruence level** **CL** and **loss note**.\n* **Characteristic (MM‑CHR)** — measurable comparandum defined in **MM‑CHR**; may be referenced in **Measurement/KD‑metric** rows; **do not** use “axis” only as a euphemism.\n* **Concept‑Set (row)** — a *licensed sameness* across Contexts, bounded by **Row Scope** and **Row CL(min)**.\n* **Contrast row** — a *non‑sameness* row: same surface across Contexts with **no** sufficient Bridges; teaches **difference**, not unity.\n\n",
        "the_table_(conceptual_layout)": "### F.7:6 - The table (conceptual layout)\n\n> One page. Fixed column order by Context. Each row fits in **five lines** max.\n\n```\nFPF Label (Tech / Plain) | Row Scope | Row CL(min) | [Context A] local label | [Context B] local label | [Context C] local label | Rationale | Counter‑examples\n```\n\n**Reading rules (didactic):**\n\n1. **Cells are local.** A cell is **not** a translation; it is the Context’s **own** label for its SenseCell.\n2. **Scope is king.** The FPF label only licenses sameness **within its Row Scope**. Outside that scope, treat cells as **different**.\n3. **Row CL(min) governs trust.** Lower CL ⇒ narrower applicability; **never** up‑scope a row without revisiting Bridges.\n4. **Rationale & counter‑examples** are **obligatory one‑liners**; if you need paragraphs, you need an F.9 walkthrough, not a row.\n\n**Didactic name rationale** “Giants' table’” that alludes to *standing on the shoulders of giants*: each row explicitly leans on authoritative context of meaning (**U.BoundedContext**) established by prior disciplines and not imagined. It does **not** mean a physically large table; the name signals epistemic humility and traceable reliance on those sources. \"We are like dwarfs on the shoulders of giants, so that we can see more than they, and things at a greater distance, not by virtue of any sharpness of sight on our part, or any physical distinction, but because we are carried high and raised up by their giant size.\" by Bernard of Chartres , d. c.1130, French philosopher.\n",
        "conceptual_construction_(thought_moves,_not_workflow)": "### F.7:7 - Conceptual construction (thought moves, not workflow)\n\n> The table is derived from earlier patterns; it **creates nothing new**.\n\n* **Sourcing.** Candidate cells come **only** from **SenseCells** (F.3).\n* **Licensing.** A row exists **iff** the relevant **Bridges (F.9)** already justify sameness at the chosen **Row Scope**.\n* **Bounding.** Prefer **2–4 Contexts** per row (parsimony); add more only if each adds a *distinct necessity* for the sameness claim.\n* **Typing.** A row is **typed by senseFamily**: Role, Status, Type‑structure, Measurement, etc. **Do not mix senseFamilies** in one row.\n* **Temporal honesty.** A row’s cells must share **compatible DesignRunTag**; if not, either split into two rows or mark a **contrast row**.\n\n",
        "invariants_(normative)": "### F.7:8 - Invariants (normative)\n\n1. **Context‑loyal cells.** Every non‑empty cell is a **SenseCell** address; no minted paraphrases.\n2. **Bridge sufficiency.** For a *Concept‑Set* row, **every pair** of filled cells is connected by an **F.9 Bridge path** whose **bottleneck CL** ≥ **Row CL(min)** printed for the row.\n3. **Scope declaration.** Each row **MUST** declare a **Row Scope** chosen from a small controlled set (e.g., *Naming-only*, *assignment/enactment-eligibility*, *KD-metric*, *Type-structure*).\n4. **senseFamily uniformity.** All cells in a row belong to the **same senseFamily** (Role **or** Status **or** Type-structure **or** Measurement…).\n5. **Temporal compatibility.** Either all cells share the **same stance**, or the row is a **contrast row** (no sameness claim).\n6. **Loss disclosure.** If any Bridge in the row has a **loss note**, the row **MUST** include a **counter‑example** that illustrates that loss in one line.\n7. **No stealth expansion.** Adding a new cell to a row **MUST NOT** lower the printed **Row CL(min)** without updating **Row Scope** or splitting the row.\n8. **Parsimony.** A row with only one filled cell is **forbidden** (that would be local talk, not a Cross‑context concept).\n9. **Didactic bound.** A row that cannot be read in **≤ 30 seconds** violates didactic primacy and must be split.\n\n",
        "micro‑illustrations_(safe_patterns)": "### F.7:9 - Micro‑illustrations (safe patterns)\n\n> Illustrative only; these presume corresponding **F.9 Bridges** exist with stated CL and losses.\n\n**(a) Subtyping across type‑formalisms (Type‑structure row)**\n\n| FPF Label                                  | Row Scope      | Row CL(min) | OWL 2             | Kind-CAL            | Rationale                                                        | Counter‑examples                                                         |\n| ------------------------------------------ | -------------- | ----------- | ----------------- | ------------------- | ---------------------------------------------------------------- | ------------------------------------------------------------------------ |\n| **is‑a (Tech)** / *type hierarchy* (Plain) | Type‑structure | CL = 3      | `rdfs:subClassOf` | `U.SubtypeRelation` | Both are partial‑order *class* subsumption used for inheritance. | FCA *concept* order is not a class subsumption; keep it out or CL drops. |\n\n**(b) “Observation result value” (Measurement row)**\n\n| FPF Label                           | Row Scope | Row CL(min) | SOSA/SSN                | ISO 80000‑1                    | ITIL 4                       | Rationale                                                                                           | Counter‑examples                                                |\n| ----------------------------------- | --------- | ----------- | ----------------------- | ------------------------------ | ---------------------------- | --------------------------------------------------------------------------------------------------- | --------------------------------------------------------------- |\n| **result‑value** / *measured value* | KD‑metric | CL = 2      | `sosa:Result` (literal) | `QuantityValue` (unit‑bearing) | *metric value* (service KPI) | Values can be read as numbers tied to a Characteristic; ITIL metric uses same notion when unitised. | ITIL “metric” may be composite indices (loss of unit fidelity). |\n\n**(c) Contrast row: “process” (no sameness)**\n\n| FPF Label              | Row Scope | Row CL(min) | BPMN 2.0              | PROV‑O                  | Thermodynamics           | Rationale                                                 | Counter‑examples                                                                   |\n| ---------------------- | --------- | ----------- | --------------------- | ----------------------- | ------------------------ | --------------------------------------------------------- | ---------------------------------------------------------------------------------- |\n| **process** (contrast) | —         | —           | *graph of flow nodes* | *time‑bounded activity* | *state‑space trajectory* | Same surface, **different** senses; no licensed sameness. | Any attempt to equate design‑graph with run‑occurrence fails stance compatibility. |\n\n",
        "anti‑patterns_&_remedies": "### F.7:10 - Anti‑patterns & remedies\n\n| #         | Anti‑pattern                | Symptom in a row                                                               | Why it breaks thinking                                               | Remedy (conceptual move)                                                                                          |\n| --------- | --------------------------- | ------------------------------------------------------------------------------ | -------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------- |\n| **AP‑1**  | **Bridge‑free sameness**    | Cells listed as “same” because their labels look alike; no cited Bridges.      | Violates locality; imports meaning across Contexts by name.             | A row **exists only** if backed by **F.9 Bridges**. Otherwise produce a **contrast row**.                         |\n| **AP-2**  | **Scope creep**             | Row labelled “Type-structure” but used to justify **assignment/enactment-eligibility** or KD metrics. | Scope licences are not transferable; inference leaks.                | Keep a **small controlled set of Row Scopes**. If use widens, **mint a new row** or **re-bridge** with higher CL. |\n| **AP‑3**  | **senseFamily mixing**      | One row mixes Role, Status, Measurement, and Type‑structure cells.             | Conflates senseFamily (F.0.1); readers cannot tell “what kind of sameness”. | **Type each row.** If two senseFamilys are needed, **split** into two rows.                                             |\n| **AP‑4**  | **Temporal blur**           | Cells with incompatible DesignRunTag declared “same”.                     | Design artefacts ≠ run occurrences; claims invert.                   | Either **harmonise stance** (choose only compatible cells) or publish a **contrast row**.                         |\n| **AP‑5**  | **Loss denial**             | Bridges carry loss notes, but the row omits counter‑examples.                  | Readers over‑trust; misuse outside safe scope.                       | Add a **one‑line counter‑example** that illustrates the loss.                                                     |\n| **AP‑6**  | **CL averaging**            | Row CL(min) computed as an average of heterogeneous Bridges.                   | The weakest link governs; averages overstate safety.                 | Row CL(min) is the **bottleneck** (minimum along connecting paths).                                               |\n| **AP‑7**  | **Overwide rows**           | 6–8 Contexts in one row; hard to read; subtle mismatches hide.                    | Violates didactic primacy; invites hidden losses.                    | **Parsimony**: 2–4 Contexts per row unless each extra cell has a **distinct necessity** you can state in one line.   |\n| **AP‑8**  | **Minted paraphrases**      | Cells reword a Context’s label instead of citing the SenseCell.                   | Hides locality; future drift becomes invisible.                      | **Cells are Context‑loyal.** Use the Context’s own SenseCell label.                                                     |\n| **AP‑9**  | **Duplicate rows by style** | Two rows with the same cell set but different FPF labels.                      | Name inflation; readers assume two distinct concepts.                | Keep **one row** per Concept‑Set per scope. Alternative labels appear as **aliases** in F.5, not new rows.        |\n| **AP‑10** | **Implied transitivity**    | A↔B and B↔C Bridges exist; row silently assumes A↔C at the same CL.            | Paths can reduce CL; semantics might not compose.                    | Compute CL for **A↔C via bottleneck**; if too low, either reduce **Row Scope** or **omit** the cell.              |\n\n",
        "worked_examples_(multi‑architheory)": "### F.7:11 - Worked examples (multi‑architheory)\n\n> Each example gives a **row** (compact), then a **reading** explaining scope and limits. All sameness claims presuppose suitable **F.9 Bridges** with the stated CL.\n\n#### F.7:11.1 - Behavioural actor across Contexts (naming‑only)\n\n| FPF Label (Tech / Plain)              | Row Scope   | Row CL(min) | BPMN 2.0        | PROV‑O    | Rationale                                                                               | Counter‑examples                                                                                      |\n| ------------------------------------- | ----------- | ----------- | --------------- | --------- | --------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------- |\n| **actor** / *party that participates* | Naming‑only | CL = 2      | **Participant** | **Agent** | Both denote a bearer that can be named as the party to which activities are attributed. | PROV **Agent** includes software agents; BPMN **Participant** is typically an organisation lane/pool. |\n\n**Reading.** The row licenses a **glossary‑level sameness** for didactic prose (“the actor”). It does **not** license modelling **identity** or inference across Contexts.\n\n\n#### F.7:11.2 - Execution occurrence (assignment/enactment-eligibility)\n\n| FPF Label                                       | Row Scope       | Row CL(min) | PROV‑O                                                           | IEC 61131‑3                                          | Rationale                                                                       | Counter‑examples                                                   |\n| ----------------------------------------------- | --------------- | ----------- | ---------------------------------------------------------------- | ---------------------------------------------------- | ------------------------------------------------------------------------------- | ------------------------------------------------------------------ |\n| **execution-occurrence** / *a run that happens* | assignment/enactment-eligibility | CL = 2      | **Activity** (time-bounded occurrence using/generating entities) | **Task execution** (cyclic/event-driven program run) | Both are **run-time** occurrences that can be referenced by `U.RoleEnactment` to ground **Work performed under an assignment**. | BPMN **Process** is a **design** graph; not an occurrence—exclude. |\n\n**Reading.** Safe to use as the **run-time occurrence that `U.RoleEnactment` points to** when we say “this Work was performed under an assignment”. Not safe to equate **all** PROV Activities with **all** PLC task runs for analytics.\n\n\n#### F.7:11.3 - Result value as KD‑metric (measurement)\n\n| FPF Label                           | Row Scope | Row CL(min) | SOSA/SSN             | ISO 80000‑1                      | ITIL 4           | Rationale                                                                                                | Counter‑examples                                               |\n| ----------------------------------- | --------- | ----------- | -------------------- | -------------------------------- | ---------------- | -------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------- |\n| **result‑value** / *measured value* | KD‑metric | CL = 2      | **Result** (literal) | **QuantityValue** (unit‑bearing) | **metric value** | A number representing a **Characteristic** at observation time; can be unitised and compared to targets. | ITIL “metric” may be a composite index; units may be implicit. |\n\n**Reading.** Licences **metric tables** that join observations to service targets; warns that composite KPIs may violate unit fidelity.\n\n\n#### F.7:11.4 - Subtype relation (type‑structure)\n\n| FPF Label                   | Row Scope      | Row CL(min) | OWL 2             | Kind-CAL            | Rationale                                     | Counter‑examples                                                                 |\n| --------------------------- | -------------- | ----------- | ----------------- | ------------------- | --------------------------------------------- | -------------------------------------------------------------------------------- |\n| **is‑a** / *type hierarchy* | Type‑structure | CL = 3      | `rdfs:subClassOf` | `U.SubtypeRelation` | Both are partial orders used for inheritance. | FCA **concept order** is not a class subsumption—exclude or publish another row. |\n\n\n#### F.7:11.5 - Contrast: “role” (access vs behaviour)\n\n| FPF Label           | Row Scope | Row CL(min) | NIST RBAC                 | BPMN 2.0                                 | Rationale                                                      | Counter‑examples                                                                   |\n| ------------------- | --------- | ----------- | ------------------------- | ---------------------------------------- | -------------------------------------------------------------- | ---------------------------------------------------------------------------------- |\n| **role** (contrast) | —         | —           | **Role** (permission set) | **Participant/Actor** (behavioural mask) | Same surface; **different senseFamilys** (Status vs Role/behaviour). | Any attempt to unify collapses deontics into behaviour; stance and effects differ. |\n\n**Reading.** This row **teaches difference**; it deliberately **does not** license sameness.\n\n",
        "reasoning_primitives_(judgement_schemas,_notation‑free)": "### F.7:12 - Reasoning primitives (judgement schemas, notation‑free)\n\n> All judgements are **pure** (no side effects). “Contexts” are `U.BoundedContext`. `SC(C)` denotes a SenseCell in Context `C`. `CL(X↔Y)` is the congruence level of the **best** Bridge path (F.9) between SenseCells `X` and `Y` (bottleneck along that path).\n\n#### F.7:12.1 - Row licensing\n\n**Form.**\n`S = {SC(C₁), …, SC(Cₙ)}, Scope = s, τ(s) = requiredCL ⊢ licensable(S,s) ⇔ (∀ i<j: CL(SC(Cᵢ)↔SC(Cⱼ)) ≥ requiredCL ∧ senseFamily (S) is uniform ∧ stance(S) compatible)`\n\n**Reading.** A set of cells **licenses** a row of scope `s` iff every pair is bridged at or above the **required CL** for that scope, all cells sit in the **same senseFamily**, and **DesignRunTag** is compatible.\n\n\n#### F.7:12.2 - Bottleneck CL for a row\n\n**Form.**\n`RowCL(S) = min_{i<j} CL(SC(Cᵢ)↔SC(Cⱼ))`\n\n**Reading.** The row’s CL is the **minimum** congruence level across all pairs (the weakest link).\n\n\n#### F.7:12.3 - Scope guard\n\n**Form.**\n`licensable(S,s) ∧ s ⊑ s' ⊢ licensable(S,s') only if RowCL(S) ≥ τ(s')`\n\n**Reading.** You may **tighten scope** (use the row for a stronger purpose) only if the row’s CL meets the **higher threshold** for that scope.\n\n\n#### F.7:12.4 - Contrast decision\n\n**Form.**\n`(∃ i<j: CL(SC(Cᵢ)↔SC(Cⱼ)) < τ(Naming‑only)) ⊢ publish‑contrast(S)`\n\n**Reading.** If even **Naming‑only** cannot be licensed, publish a **contrast row** instead of forcing sameness.\n\n\n#### F.7:12.5 - Row extension guard\n\n**Form.**\n`licensable(S,s) ∧ add SC(Cₖ) ⊢ licensable(S∪{SC(Cₖ)}, s) iff ∀ i: CL(SC(Cᵢ)↔SC(Cₖ)) ≥ τ(s)`\n\n**Reading.** You may add a new cell only if it bridges to **every existing cell** at the row’s scope.\n\n\n#### F.7:12.6 - Loss disclosure obligation\n\n**Form.**\n`licensable(S,s) ∧ (∃ i<j: lossNote on Bridge(SC(Cᵢ),SC(Cⱼ))) ⊢ row must carry ≥1 counter‑example`\n\n**Reading.** Any loss note on any supporting Bridge obliges the row to include a **counter‑example one‑liner**.\n\n",
        "relations": "### F.7:13 - Relations (with other patterns)\n\n**Builds on:**\nF.1 **Contexts fixed** → defines the column set; F.2 **Harvest** → supplies term material; F.3 **SenseCells** → provide cell addresses; F.5 **Naming Discipline** → provides the two‑register **FPF labels**; F.9 **Bridges** → legally justify each row.\n\n**Constrains:**\nF.4 **Role Description** — when a template cites an FPF label from the table, it **inherits the Row Scope**; no template may claim semantics beyond the row’s licence.\nF.6 **Role Assignment & Enactment Cycle (Six-Step)** — Move M‑4 (“choose label”) must reference a row if it wants Cross‑context reading.\n\n**Used by.**\nPart C architheories for didactic alignment pages; Part B trust calculus (B.3) may consume **Row CL(min)** when computing translation penalties.\n\n",
        "migration_notes_(conceptual)": "### F.7:14 - Migration notes (conceptual)\n\n1. **Bridge update.** If any supporting Bridge’s CL changes, recompute **Row CL(min)**. If it drops below the printed value, either **lower Row Scope**, **split** the row, or **retire** it.\n2. **New Context appears.** Do **not** auto‑expand rows. Test with **12.5**; add only if it brings a **distinct necessity**.\n3. **Sense revision inside a Context.** If a SenseCell splits (F.3), decide which child cell (if any) remains in the row; the rest may require **new rows** or a **contrast**.\n4. **Scope promotion.** To use a row for a stronger purpose (e.g., from **Naming-only** to **assignment/enactment-eligibility**), first ensure **Row CL(min) ≥ τ(new scope)**; otherwise construct **new Bridges** or **decline** promotion.\n5. **Deprecation.** If a row no longer meets its invariant, mark its FPF label as **retired** in F.5 and point to successor rows (if any).\n6. **Edition churn.** When a Context is superseded (F.1), either keep the cell (if semantics stable) or treat the successor as a **new Context** and re‑evaluate licensability.\n\n",
        "acceptance_tests_(scr/rscr_—_concept‑level)": "### F.7:15 - Acceptance tests (SCR/RSCR — concept‑level)\n\n#### F.7:15.1 - Static conformance checks (SCR)\n\n* **SCR‑F7‑S01 (Context‑loyal cells).** Every non‑empty cell references an existing **SenseCell** (F.3) in a declared Context (F.1).\n* **SCR‑F7‑S02 (Closure & bottleneck).** For each Concept‑Set row, **every pair** of cells has a Bridge path with CL ≥ **Row CL(min)** printed; **Row CL(min)** equals the **minimum** pairwise CL.\n* **SCR‑F7‑S03 (Typed & scoped).** Each row declares a **Row Scope** from the controlled set and is **senseFamily‑uniform** (Role **or** Status **or** Measurement **or** Type‑structure…).\n* **SCR‑F7‑S04 (Temporal compatibility).** Non‑contrast rows have **compatible** DesignRunTag across cells.\n* **SCR‑F7‑S05 (Loss disclosure).** If any supporting Bridge has a recorded loss, the row includes **≥1 counter‑example** line.\n* **SCR‑F7‑S06 (Parsimony).** Rows contain **2–4 Contexts** unless a one‑line necessity is stated for each extra Context.\n\n#### F.7:15.2 - Regression checks (RSCR)\n\n* **RSCR‑F7‑E01 (Bridge drift).** After any Bridge change (F.9), recompute **Row CL(min)**; flag rows whose scope is now overstated.\n* **RSCR‑F7‑E02 (Sense split).** After a SenseCell splits (F.3), ensure rows referencing it either pick a child cell or retire.\n* **RSCR‑F7‑E03 (Scope integrity).** No consumer pattern uses a row outside its declared **Row Scope**.\n* **RSCR‑F7‑E04 (No stealth growth).** Additions of cells never lower **Row CL(min)** silently; if they do, either split the row or reduce scope.\n\n",
        "didactic_distillation_(60‑second_teaching_script)": "### F.7:16 - Didactic distillation (60‑second teaching script)\n\n> “A **Concept-Set row** shows **one idea across Contexts**—but only where explicit **Bridges** license it. Columns are Contexts; cells are **their own labels**. The row prints a **scope** (‘Naming-only’, ‘assignment/enactment-eligibility’, ‘Type-structure’, ‘KD-metric’) and the **weakest CL** that justifies reading across. A **one‑line rationale** says why sameness is safe **here**; a **counter‑example** warns where it breaks. Keep rows small (2–4 Contexts), typed (don’t mix senseFamilies), and temporally honest (design vs run stance). If Bridges don’t suffice, publish a **contrast row** instead. The table doesn’t invent meaning; it **summarises licensed sameness** so readers can cross disciplines without smuggling assumptions.”\n",
        "f.7:end": "### F.7:End\n"
      },
      "content": "### F.7:End\n",
      "metadata": {},
      "part": "F",
      "cluster": null
    },
    {
      "id": "F.8",
      "title": "Mint or Reuse? (U.Type vs Concept-Set vs Role Description vs Alias)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## F.8 - Mint or Reuse? (U.Type vs Concept-Set vs Role Description vs Alias)\n\n**“Name only what thinking **requires**, and reuse everything else.”**\n\n**Status.** Architectural pattern, architheory‑agnostic.\n**Depends on.** E.10.D1 **Lexical Discipline for “Context” (D.CTX)**; A.7 **Strict Distinction**; A.11 **Ontological Parsimony**; A.8 **Universal Core**.\n**Coordinates with.** F.1 **Contexts (Contexts)**; F.2 **Harvest**; F.3 **SenseCells**; F.4 **Role Description**; F.5 **Naming Discipline**; F.7 **Concept‑Set Table**; F.9 **Alignment & Bridge**.\n**Aliases (informative).** *Mint‑vs‑Reuse gate*; *Naming governor*.\n\n",
        "intent_&_applicability": "### F.8:1 - Intent & applicability\n\n**Intent.** Provide a **minimal, conceptual decision lattice** that answers, for any modelling need:\n\n> “Do I **reuse** an existing label, add an **alias**, reference a **Concept‑Set row**, define a **Role Description**, or mint a **new U.Type**?”\n\nThe lattice enforces **locality of meaning** (Contexts), **senseFamily separation** (A.7), and **parsimony** (A.11) while remaining didactically simple.\n\n**Applicability.** Use whenever a new name seems “needed” in any architheory thread (**Role Assignment & Enactment**, Sys-CAL, KD-CAL, Kind-CAL, Method-CAL, LCA-CAL…).\n\n**Non‑goals.** No workflows, no roles, no storage. This is **thinking discipline**, not process guidance.\n\n",
        "problem": "### F.8:2 - Problem frame\n\nModellers tend to **mint names** when they actually need **reuse**, **aliasing**, or **explicit Cross‑context reading**. Consequences:\n\n1. **Name inflation.** Parallel labels for the same idea across Contexts.\n2. **senseFamily mixing.** Behavioural **Role** names that smuggle in deontic **Status** or measurement talk.\n3. **Hidden bridges.** Cross‑context sameness is implied by look‑alike words rather than declared (F.9).\n4. **Kernel sprawl.** New **U.Types** appear to plaster over local vocabulary gaps.\n\n",
        "forces": "### F.8:3 - Forces\n\n| Force                       | Tension to resolve                                                                            |\n| --------------------------- | --------------------------------------------------------------------------------------------- |\n| **Parsimony vs coverage**   | Avoid new names unless necessary, yet cover recurring Cross‑context readings.                    |\n| **Locality vs unification** | Keep senses **in‑Context**; when reading across, do it **explicitly** and only as far as needed. |\n| **Didactics vs fidelity**   | Give readers one label to hold, but never over‑state sameness (respect CL and scope).         |\n\n",
        "minimal_vocabulary_(used_in_this_pattern_only)": "### F.8:4 - Minimal vocabulary (used in this pattern only)\n\n* **Context** — `U.BoundedContext` (per D.CTX).\n* **SenseCell** — address of a **local sense** produced by F.3 (one context × one clustered sense).\n* **Concept‑Set row** — a **licensed Cross‑context reading** (F.7) of cells in one senseFamily with a declared **Row Scope** and **Row CL(min)**.\n* **senseFamily** — as defined in **F.0.1**; here used as the **typed discriminator for rows** restricted to {Role | Status | Measurement | Type‑structure | Method | Execution}. \n* **Role Description** — a **Role/Status** template anchored to a **single SenseCell** (F.4).\n* **Alias** — an **additional label** for an existing FPF label (within F.5), no new semantics.\n* **CL threshold τ(scope)** — the **minimum congruence level** needed for a row’s scope (e.g., τ(Naming-only) < τ(Assignment-eligibility) < τ(Type-structure)).\n\n",
        "the_decision_lattice_(conceptual,_notation‑free)": "### F.8:5 - The decision lattice (conceptual, notation‑free)\n\n> Read top‑to‑bottom; the **first satisfied** branch decides. At every step, **state the senseFamily** (Role / Status / Measurement / Type‑structure / Method / Execution) before you proceed.\n\n#### F.8:5.1 - Q0 — What is the **senseFamily** of your need?\n\n* If **uncertain**, return to F.1/F.3: stabilise the Context(s) and the local sense.\n* If **mixed**, split the need: one decision **per senseFamily** (A.7).\n\n#### F.8:5.2 - Q1 — Is there a **single Context** whose SenseCell already expresses it?\n\n* **Yes →** **Reuse** the **SenseCell**’s label **inside that Context**.\n\n  * If you need assignable behaviour or deontics on that sense: **define a Role Description** **anchored to that SenseCell** (F.4).\n* **No →** go to Q2.\n\n> *Example (engineer).* You want “**task execution**” in control software. In `IEC 61131‑3` there is a clear SenseCell for **task execution**. **Reuse** that label; if you need responsibilities (“who monitors runs”), define a **Role Description** anchored to this SenseCell.\n\n#### F.8:5.3 - Q2 — Do you need to **read across Contexts** (same senseFamily)?\n\n* **No →** stay within one context; if your desire is merely a nicer label, consider an **Alias** (Q3).\n* **Yes →** check F.7 for a **Concept‑Set row** covering your cells **in this senseFamily** with adequate **Row Scope** and **Row CL(min)**.\n\n  * **Found & sufficient →** **Reuse the row’s FPF label** at that scope.\n  * **Not found or insufficient →** either (a) **publish a contrast** (teach difference), or (b) propose a **new row** but only after F.9 Bridges exist at **τ(scope)**.\n\n> *Example (manager).* You want one label for the **actor** in workflow and provenance prose. F.7 has a **Naming‑only** row mapping *BPMN Participant* ↔ *PROV Agent* at CL = 2. **Reuse** “actor” **at Naming‑only** scope; do **not** infer identity in models.\n\n#### F.8:5.4 - Q3 — Is this **only a wording preference** for an existing FPF label?\n\n* **Yes →** add an **Alias** in F.5 (Tech register and/or Plain register), no semantics changed.\n* **No →** go to Q4.\n\n> *Example (researcher).* You prefer “**is‑a**” to “**subclass‑of**” in Type pages. That is an **Alias** for the same concept; no new row, no new U.Type.\n\n#### F.8:5.5 - Q4 — Does your need recur across Contexts in a way **not captured** by current rows, **with Bridges** already available at the required CL?\n\n* **Yes →** propose a **new Concept‑Set row** (F.7): small (2–4 Contexts), **one senseFamily**, declare **Row Scope** and **Row CL(min)**, include a **counter‑example** if any Bridge has loss notes.\n* **No →** go to Q5.\n\n> *Example (engineer).* You repeatedly compare **runtime occurrence** in PROV with **PLC task runs**. F.9 Bridges exist at CL = 2. Propose **row “execution-occurrence”** at **assignment/enactment-eligibility** scope (not Type-structure).\n\n#### F.8:5.6 - Q5 — Are you describing a **kernel‑level notion** missing from the catalogue, **not** reducible to existing rows or Role Descriptions, and **present across ≥ 3 domain families** (A.8)?\n\n* **Yes →** propose a **new U.Type** (rare). Supply:\n  (i) the minimal **intensional definition**; (ii) cross‑family evidence (≥ 3 Contexts, **distinct families**); (iii) how it **doesn’t** duplicate an existing U.Type.\n* **No →** you **do not mint** a new type. Re‑express the need in terms of **Context reuse**, **row reuse**, **Alias**, or a **Role Description**.\n\n> *Example (researcher).* You think we need **U.InfluenceEdge** (causal tendency). If it appears as a stable, **senseFamily‑specific** notion across **control**, **epistemic inference**, and **methods** (≥ 3 families), and cannot be formed from existing `U.Relation` subtypes, it **may** qualify. Otherwise, treat it as a **pattern** or a **row**.\n\n",
        "scope_thresholds_(default_τ)_—_**how_much_sameness**_you’re_allowed_to_claim": "### F.8:6 - Scope thresholds (default τ) — **how much sameness** you’re allowed to claim\n\n| Row / Use Scope     | What it licenses                                                                              | Default τ (minimum CL) | Typical consumers                         |\n| ------------------- | --------------------------------------------------------------------------------------------- | ---------------------: | ----------------------------------------- |\n| **Naming‑only**     | Shared label in prose, diagrams, and primers; **no inference**.                               |                  **1** | Pedagogy, glossary, didactic figures.     |\n| **Assignment-eligibility** | Safe to reference the row’s target as the **thing a `U.RoleAssignment` may point to** (e.g., a run, a value). | **2** | F.4 Role Description, acceptance narratives. |\n| **KD‑metric**       | Treat cells as the **same measured outcome** (unit‑compatible, procedure‑compatible).         |                  **2** | Measurement summaries, SLO tables.        |\n| **Type‑structure**  | Treat cells as the **same structural relation** (e.g., subtyping) with inheritance semantics. |                  **3** | Kind-CAL pages, structural proofs.        |\n\n> **Guard.** You may **tighten** scope (e.g., from Naming-only → Assignment-eligibility) **only** if the **Row CL(min)** meets the **higher τ**.\n\n",
        "micro‑examples_(didactic_triad)": "### F.8:7 - Micro‑examples (didactic triad)\n\n#### F.8:7.1 - For engineers — “Do we need a new **Execution** label?”\n\n* **Need.** “We want to refer to **what actually happened** in both provenance logs and PLC runtime.”\n* **senseFamily.** Execution - **stance.** run.\n* **Contexts.** `PROV‑O` (Activity), `IEC 61131‑3` (task run).\n* **Row?** F.7 has **execution-occurrence** at **assignment/enactment-eligibility**, CL = 2.\n* **Decision.** **Reuse** that row’s label at **Assignment-eligibility**; **no** new U.Type; define Role Descriptions **anchored to each Context** as needed.\n\n#### F.8:7.2 - For managers — “Can we call them all **actors**?”\n\n* **Need.** A single everyday word in the spec to denote “the responsible party”.\n* **senseFamily.** Role (behavioural mask in prose).\n* **Contexts.** `BPMN 2.0` (Participant), `PROV‑O` (Agent).\n* **Row?** **Naming‑only** row “actor”, CL = 2.\n* **Decision.** **Reuse** “actor” **in prose only**; keep Context‑loyal labels in formal sections. No Role Description minted unless tied to one context.\n\n#### F.8:7.3 - For researchers — “New **U.Type** for ‘Work Scope’?”\n\n* **Need.** Kernel notion capturing **feasible performance region** across systems.\n* **Test A.8.** Appears in **control** (reachable sets), **services** (operating envelope), **measurement** (confidence bands): **≥ 3 families?**\n* **Reduction test.** Can it be expressed as a **row** + existing `U.Relation` + KD‑CAL constructs?\n* **Decision.** If **not reducible** and **cross‑family stable**, propose **new U.Type** with minimal definition; otherwise, prefer a **row** or a **pattern**.\n\n",
        "invariants_(normative,_lightweight)": "### F.8:8 - Invariants (normative, lightweight)\n\n1. **Context‑first.** Every decision cites at least one **Context**; no global senses.\n2. **senseFamily purity.** A single decision covers **one senseFamily**. Mixed needs are split.\n3. **Row honesty.** Any Cross‑context reuse occurs **via a Concept‑Set row** at or above **τ(scope)**; no stealth equivalence.\n4. **Role Description anchoring.** Role Descriptions are **single-Context**, **single-cell** anchors (F.4).\n5. **Alias modesty.** Aliases **never** change semantics and live under F.5.\n6. **Kernel restraint.** New **U.Types** are **rare**; A.8 **(≥ 3 families)** is mandatory, and duplication with existing U.Types must be ruled out.\n\n",
        "f.8:8.1___mint/reuse_discipline_for_**policy_ids**_(normative_addendum)": "### F.8:8.1 - Mint/Reuse discipline for **policy-ids** (normative addendum)\n\nFPF treats **policy-ids** (e.g., `Φ(CL)`, `Φ_plane`, `Ψ(CL^k)`, `Aut-Guard`, `EmitterPolicyRef`, `InsertionPolicyRef`, Acceptance clause ids) as **first-class, versioned tokens**. They are not “just strings”, and they are not governed by tier ladders or implied authority.\n\n**PolicySpecRef.** A **resolvable reference** to the normative definition of a policy-id (“what does this policy-id mean?”). At minimum it:\n* identifies the policy-id,\n* pins an immutable edition (or equivalent digest), and\n* can be located from the same publication bundle (MVPK / UTS / EvidenceGraph anchors).\n\n**MintDecisionRef.** A **resolvable reference** to the decision record that introduced (minted) a policy-id into a declared namespace/registry. For **normative** policy-ids this is typically a **DRR id** (E.9) or an equivalent change decision record. For **purely local, non-exported** policy-ids it MAY be a Gate `DecisionLog` entry (A.21) if that local-only scope is explicit.\n\n**PolicyIdRef (canonical bundle).**  \n`PolicyIdRef := { policy_id, PolicySpecRef, MintDecisionRef? }`.\n\n**Rules.**\n1. **No silent policy-id minting.** If a publication introduces a *new* policy-id (not previously present in the declared namespace/registry), it **MUST** surface a `PolicyIdRef` whose:\n   * `PolicySpecRef` is edition-pinned, and\n   * `MintDecisionRef` is resolvable from the publication’s DRR/DecisionLog links.\n2. **Reuse is reference-only.** If a publication **reuses** an existing policy-id, it **MUST** surface a `PolicySpecRef` (and **SHOULD** preserve the prior mint decision link where available). It **MUST NOT** restate policy semantics *as if* minting a new policy-id.\n3. **GateCrossing checkability.** Any GateCrossing/CrossingSurface that surfaces policy-ids **MUST** include `PolicyIdRef` (or an equivalent “policy-id + resolvable refs” structure) so GateChecks can verify resolvability and pin consistency (E.18/A.21/G.6:H8).\n4. **Authority is policy, not tiers.** “Who may mint” vs “who may reuse” is expressed by the referenced **policy specs** and **mint decisions** (and enforced by the active GateProfile/GateChecks), not by fixed tier labels.\n\n\n",
        "quick_reference_(one‑glance_map)": "### F.8:9 - Quick reference (one‑glance map)\n\n| You feel you need…                          | Likely action                  | Why                                              |\n| ------------------------------------------- | ------------------------------ | ------------------------------------------------ |\n| A convenient everyday word across two Contexts | **Reuse a Naming‑only row**    | Keeps prose simple without smuggling inference.  |\n| An assignable mask with invariants          | **Role Description (single Context)** | Roles/Statuses attach to **local** senses.       |\n| The same measured outcome across Contexts      | **Reuse a KD‑metric row**      | Units/procedures aligned at CL ≥ 2.              |\n| A unifying schema relation (e.g., is‑a)     | **Reuse a Type‑structure row** | Structural inference preserved at CL ≥ 3.        |\n| A nicer label for the same FPF concept      | **Alias in F.5**               | Style only; zero semantics.                      |\n| A brand‑new primitive concept               | **New U.Type (rare)**          | Only if cross‑family, irreducible, kernel‑level. |\n",
        "anti‑patterns_&_remedies": "### F.8:10 - Anti‑patterns & remedies\n\n| #         | Anti‑pattern               | Symptom                                                                            | Why it harms thinking                              | Remedy (conceptual move)                                                                                                                         |\n| --------- | -------------------------- | ---------------------------------------------------------------------------------- | -------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------ |\n| **AP‑1**  | **Row‑less sameness**      | Declaring “these mean the same” across Contexts without citing a **Concept‑Set row**. | Imports meaning implicitly; no CL guard.           | If Cross‑context reuse is desired, **reuse an existing row** at a declared **scope** (F.7), else **publish the contrast** and defer to F.9 Bridges. |\n| **AP-2**  | **Scope creep**            | Using a **Naming-only** row to justify **Assignment-eligibility** or structural inferences. | Over-claims sameness; breaks τ(scope).             | Respect **scope thresholds** (τ). Upgrade only when **Row CL(min) ≥ τ(new scope)**; otherwise stay Naming-only.                                  |\n| **AP‑3**  | **Alias with payload**     | Introducing an Alias that subtly changes intent or senseFamily.                          | Hides semantics behind wording; confuses senseFamilies.   | Aliases (F.5) are **style only**. If semantics change, choose **row reuse** or **Role Description** instead.                                         |\n| **AP-4**  | **Role-Description-to-row anchoring** | Role Description points to a **row** rather than a **single SenseCell**.       | Masks locality; **assignments** become cross-context by stealth. | Role Descriptions **must anchor to one SenseCell** (F.4). Use rows only in prose or aggregated views.                                                |\n| **AP‑5**  | **Kernel inflation**       | Proposing a new **U.Type** because a convenient label is missing.                  | Duplicates the kernel; violates parsimony.         | Apply A.8: require **≥ 3 domain families** and **irreducibility**; otherwise **Alias** or **row**.                                               |\n| **AP‑6**  | **senseFamily mixing**           | One name that conflates Role, Status, Measurement, or Type‑structure.              | Collapses A.7 Strict Distinction.                  | **Split by senseFamily** first (Q0). Decide **per senseFamily**.                                                                                             |\n| **AP‑7**  | **Bridge‑by‑string**       | Treating identical surface forms as equivalent senses across Contexts.                | Homonym trap; ignores local sense.                 | Equivalence only via **F.9 Bridge** + **row**; never by string.                                                                                  |\n| **AP‑8**  | **Row without loss notes** | Publishing a row where Bridges indicate mismatches, but row text is silent.        | Readers assume full equivalence.                   | Include **counter‑example** and **loss sketch** in the row’s narrative (F.7).                                                                    |\n| **AP‑9**  | **CL laundering**          | Citing a high‑scope row based on old high CL while Bridges have since weakened.    | Invalidates downstream claims.                     | When CL falls below τ(scope), **downgrade row scope** (e.g., to Naming‑only) or **split row**.                                                   |\n| **AP‑10** | **Global normal form**     | Seeking one canonical wording across all Contexts **as if** meaning were global.      | Erases locality; fuels hidden merges.              | Keep normalisation **per Context** (F.2/F.3). Cross‑context sameness lives in **rows** with scope.                                                     |\n\n",
        "reasoning_primitives_(judgement_schemas,_notation‑free)": "### F.8:11 - Reasoning primitives (judgement schemas, notation‑free)\n\n> Each item states a **mental entailment**. No storage, no roles, no workflows. Symbols: `C` = Context, `σ` = SenseCell, `R` = Concept‑Set row, `SF` = senseFamily, `τ` = scope threshold, `CL` = congruence level.\n\n1. **senseFamily split**\n   `need(n) ∧ mixedSF(n) ⊢ split(n) into {n₁…nₖ} by senseFamily`\n   *You cannot decide for mixed senseFamilies; decide per senseFamily.*\n\n2. **Cell reuse**\n   `∃ C,σ : expresses(n,SF)@σ ⊢ reuseLabel(σ) in C`\n   *If a single Context’s SenseCell already says it, reuse it locally.*\n\n3. **Assignment-eligibility**\n   `reuseLabel(σ) ∧ needAssignable(SF ∈ {Role,Status}) ⊢ mintRoleDescription(σ)`\n   *When you need assignable behaviour/deontics for a local sense, mint a Role Description anchored to that sense.*\n\n4. **Row reuse**\n   `crossContexts(n,SF) ∧ ∃ R: covers(R,SF) ∧ CL(R) ≥ τ(scope) ⊢ reuseRow(R,scope)`\n   *For Cross‑context readings, reuse a row at a scope whose τ is met.*\n\n5. **Alias suffices**\n   `sameIntent(n,label₀) ∧ stylePreference(n,label₁) ⊢ alias(label₀,label₁)`\n   *If it’s only wording, add an Alias; no semantics move.*\n\n6. **Row proposal**\n   `recurrentCross(n,SF) ∧ bridgesCL(cells(n)) ≥ τ(scope) ∧ ¬∃R ⊢ proposeRow(cells,scope)`\n   *If the need recurs and Bridges support the scope, propose a new row.*\n\n7. **Kernel minting (rare)**\n   `kernelCandidate(n) ∧ crossFamily≥3 ∧ irreducible(n) ⊢ proposeUType(n)`\n   *Only if the notion is cross‑family and cannot be reduced to cells+rows+existing U.Types.*\n\n8. **Scope downgrade**\n   `reuseRow(R,scope) ∧ CL(R)↓ < τ(scope) ⊢ downgradeScope(R)`\n   *If CL falls, lower the row’s licensed scope.*\n\n9. **Row rejection**\n   `conflictEvidence(rowCells) ∧ lossUnbounded ⊢ rejectRow`\n   *If bridges show open‑ended loss, do not publish a row; teach the contrast.*\n\n",
        "extended_worked_examples_(multi‑architheory)": "### F.8:12 - Extended worked examples (multi‑architheory)\n\n#### F.8:12.1 - **Execution, observation, and acceptance** (engineers)\n\n**Need.** A reusable label for “what actually happened and how it was checked against the promise”.\n**senseFamilies.** Execution (stance: run); Measurement (KD); Status (accept/reject).\n\n**Contexts.**\n`IEC 61131‑3` (task run), `PROV‑O` (Activity), `SOSA/SSN` (Observation), `ITIL 4` (SLO/SLA).\n\n**Reasoning.**\n\n* `Execution`: `IEC` SenseCell (task run) and `PROV` SenseCell (Activity). There exists a **row** *execution-occurrence* at **Assignment-eligibility** with CL = 2 → **reuse row** at **Assignment-eligible** scope; do not infer Type-structure.\n* `Measurement`: `SOSA` Observation cell; no Cross‑context needed → **reuse cell**.\n* `Status`: `ITIL` SLO/SLA cell; **Role Description** “SLO‑Target” anchored to ITIL cell.\n\n**Outcome.** Prose may say: “This **execution-occurrence** (row\\@assignment/enactment-eligibility) was **observed** (SOSA cell) and **evaluated against the SLO** (ITIL cell).” No new U.Type; no hidden merges.\n\n\n#### F.8:12.2 - **Actor across workflow and provenance** (managers)\n\n**Need.** A single everyday label for “the responsible party” in diagrams.\n**senseFamily.** Role (behavioural mask in prose/diagrams).\n\n**Contexts.** `BPMN 2.0` (Participant), `PROV‑O` (Agent).\n\n**Reasoning.** A **Naming‑only** row “actor” exists, CL = 2. **Reuse the row** at Naming‑only.\nIf assignable behaviour is needed in a model, **mint Role Description** anchored to **BPMN Participant** (not to the row).\n\n**Outcome.** Diagrams show “actor”; formal sections reference `Participant` or `Agent` as appropriate.\n\n\n#### F.8:12.3 - **Accuracy across metrology and data quality** (researchers)\n\n**Need.** Treat “accuracy” consistently across ISO 80000 (metrology) and ISO/IEC 25024 (data quality).\n**senseFamily.** Measurement.\n\n**Contexts.** `ISO 80000‑1` (quantity/units), `ISO/IEC 25024` (data quality).\n\n**Reasoning.** Bridges indicate **related but not identical** definitions; procedures differ. Existing **KD‑metric** row “accuracy” has CL = 2 with **loss note**: *population vs instrument focus*. **Reuse row** at KD‑metric scope for dashboards; **do not** use the row to justify interchange of procedures.\n\n**Outcome.** One label in reports; method sections still cite the context‑local procedure.\n\n\n#### F.8:12.4 **Subtype relation across OWL and a curated taxonomy** (formalists)\n\n**Need.** Present “is‑a” uniformly across OWL 2 classes and a domain taxonomy.\n**senseFamily.** Type‑structure.\n\n**Contexts.** `OWL 2` (SubClassOf), `Taxonomy_X` (curated “is‑a” edges).\n\n**Reasoning.** F.7 row “subtype‑order” exists at **Type‑structure scope** with CL = 3 (only after verifying acyclicity & anti‑symmetry in `Taxonomy_X`). If the curated taxonomy contains cycles, **downgrade** to Naming‑only or reject the row.\n\n**Outcome.** When CL≥3, you may **reuse row** for structural proofs; else teach differences.\n\n",
        "relations": "### F.8:13 - Relations (with other patterns)\n\n* **Builds on:** E.10.D1 (D.CTX) **Context ≡ U.BoundedContext**; F.1 Contexts; F.2 Harvest; F.3 SenseCells.\n* **Constrains:**\n\n  * **F.4 Role Description:** **one SenseCell per Role Description**; no row anchoring.\n  * **F.5 Naming:** Aliases are style‑only; no semantics movement.\n  * **F.7 Concept‑Set:** rows must declare **Scope** & **Row CL(min)** and carry **loss notes**.\n  * **F.9 Bridges:** any row proposal presupposes Bridges at or above τ(scope).\n* **Used by.** All architheories (Part C) whenever new labels are contemplated.\n\n",
        "migration_notes_(conceptual)": "### F.8:14 - Migration notes (conceptual)\n\n1. **Old “anchor” language.** Replace legacy “anchor” with: **SenseCell** (local sense) + **Role Description** (assignable Standard) + (optionally) **Concept‑Set row** (Cross‑context reading).\n2. **Over-strong rows.** If a row was used for **assignment/enactment-eligibility** or **Type-structure** but **CL drops**, **downgrade row scope** to **Naming-only** in prose; adjust examples.\n3. **Split rows.** If one row covers cells whose Bridges diverge, **split** into two narrower rows with explicit loss notes.\n4. **Alias proliferation.** Collapse redundant Aliases under a single F.5 entry; keep both registers (Tech/Plain).\n5. **Proto‑types.** Suspect kernel inflation? Attempt **reduction**: SenseCell + row + existing U.Type. Only if irreducible across ≥ 3 families, reopen as a U.Type candidate.\n\n",
        "acceptance_tests_(scr/rscr_—_concept‑level)": "### F.8:15 - Acceptance tests (SCR/RSCR — concept‑level)\n\n#### F.8:15.1 - Static conformance (SCR)\n\n* **SCR‑F8‑S01 (senseFamily purity).** Every decision record names **one senseFamily**; mixed needs are split.\n* **SCR‑F8‑S02 (Proper anchoring).** Every Role Description cites **one SenseCell**; **no row** is used as a assignment/enactment anchor.\n* **SCR‑F8‑S03 (Row scope).** Whenever a row is reused, its **Scope** is stated and **Row CL(min) ≥ τ(scope)** holds.\n* **SCR‑F8‑S04 (Alias modesty).** Aliases introduced in F.5 do **not** claim new semantics or change senseFamily.\n* **SCR‑F8‑S05 (Kernel restraint).** Any new U.Type proposal includes **≥ 3 domain families** of evidence and an **irreducibility** note.\n\n#### F.8:15.2 - Regression (RSCR)\n\n* **RSCR‑F8‑E01 (CL drift).** If any Bridge’s CL changes, re‑evaluate dependent rows; **downgrade or split** where τ(scope) is no longer met.\n* **RSCR-F8-E02 (Row overuse).** Scan examples: no case uses **Naming-only** rows to justify **Assignment-eligibility** or **Type-structure** claims.\n* **RSCR‑F8‑E03 (Alias creep).** Ensure no Alias has accreted senseFamily‑specific semantics; if it has, migrate to a **row** or **Role Description**.\n* **RSCR‑F8‑E04 (Kernel hygiene).** New U.Type proposals are rejected if a **SenseCell + row** construction suffices.\n\n",
        "didactic_distillation_(90‑second_teaching_script)": "### F.8:16 - Didactic distillation (90‑second teaching script)\n\n> “When you feel like coining a new name, pause. **Which senseFamily** are you in—Role, Status, Measurement, Type‑structure, Method, or Execution? If a **single Context’s SenseCell** already says it, **reuse** that label. If you need an assignable Standard, **mint a Role Description** anchored to that SenseCell. If you must read **across Contexts**, reuse a **Concept‑Set row**—but only **at a stated scope** and only if its **CL meets the threshold** (τ). If it’s just a nicer wording, add an **Alias** (style only). Only in the rare case of a cross‑family, **irreducible** notion do you **mint a new U.Type**. Never let Naming‑only rows justify  **Assignment-eligibility** or structural inference, and never let identical strings force equivalence. This is not process—it’s **discipline of thought**: reuse what exists, declare scope when you bridge, and mint new primitives only when the kernel truly needs them.”\n",
        "f.8:end": "### F.8:End\n"
      },
      "content": "### F.8:End\n",
      "metadata": {},
      "part": "F",
      "cluster": null
    },
    {
      "id": "F.9",
      "title": "Alignment & Bridge across Contexts",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## F.9 - Alignment & Bridge across Contexts\n\n**“Translate across Contexts; never collapse them.”**\n**Status.** Architectural pattern, architheory‑agnostic.\n**Builds on:** E.10.D1 (Context discipline: Context ≡ U.BoundedContext); **F.0.1 (senseFamily & StatusModality guard; Bridge‑only crossing)**; F.1 (Contexts fixed); F.2/F.3 (Cells exist); F.7 (rows depend on Bridges); F.8 (thresholds τ).\n\n**Coordinates with.** B.3 **Trust & Assurance Calculus** (uses CL penalties); **A.6.1 U.Mechanism** (Transport clause for cross‑context use; penalties route to **R/R_eff** only; **F/G** invariant); Part C architheories (apply Bridges in formal claims).\n**Aliases (informative).** *Context‑to‑Context translator*; *Sense bridge*.\n",
        "intent_&_applicability": "### F.9:1 - Intent & applicability\n\n**Intent.** Provide a **conceptual discipline** for relating **SenseCells** from **different Contexts (U.BoundedContext)**. A **Bridge** states *what kind* of relationship holds, *how far* it holds (via **CL: Congruence Level**), and *what is lost* during the translation. Bridges **permit carefully scoped reuse** (e.g., a Concept‑Set row) while **forbidding silent equivalence**.\n\n**Applicability.** Use **whenever** an author needs to **read across Contexts**—to reuse a familiar label, to connect design‑time and run‑time notions, to compare two standards’ terms, or to justify a row in the Concept‑Set table. This pattern is **not** storage, workflow, or governance; it codifies **thinking moves**.\n\n**Non‑goals.** No global meaning; no tool/API; no editor roles. Bridges are **semantic relations between local senses**, not pipelines, not processes.\n\n",
        "problem": "### F.9:2 - Problem frame\n\nCross‑context work fails in predictable ways:\n\n1. **String‑equals fallacy.** Identical surfaces (“process”, “role”, “accuracy”) taken as identical meaning.\n2. **Scope creep.** A naming convenience is stretched to assignment or structural claims.\n3. **DesignRunTag jumping.** Design artefacts are substituted for run‑time occurrences (or vice‑versa).\n4. **Direction amnesia.** Narrower/broader relations treated as symmetric.\n5. **Loss blindness.** Differences (units, granularity, preconditions) are left unstated, contaminating downstream reasoning.\n\nBridges cure these by **making relation, direction, loss, and strength explicit**.\n\n",
        "forces": "### F.9:3 - Forces\n\n| Force                           | Tension to resolve                                                                       |\n| ------------------------------- | ---------------------------------------------------------------------------------------- |\n| **Locality vs reuse**           | Senses are context‑local, yet people need a common label to talk across Contexts.              |\n| **Simplicity vs fidelity**      | Few Bridge kinds are teachable; too few will hide real mismatches.                       |\n| **Safety vs utility**           | Allow some substitution when safe; forbid it when loss is unbounded.                     |\n| **senseFamily purity vs explanation** | Substitution must preserve **senseFamily**; explanation may span **senseFamilies** without implying sameness. |\n\n",
        "core_idea_(didactic)": "### F.9:4 - Core idea (didactic)\n\n**A Bridge is a declared translator between two local senses.**\nIt always names **(a)** the two **SenseCells**, **(b)** a **Bridge‑kind** (what relation), **(c)** a **direction** (if non‑symmetric), **(d)** a **CL** (how strong), and **(e)** **Loss Notes** (what fails to carry). Some Bridges **permit substitution** in limited scopes; others **permit only explanation**.\n\n",
        "minimal_vocabulary_(this_pattern_only)": "### F.9:5 - Minimal vocabulary (this pattern only)\n\n* **Context** — shorthand for **U.BoundedContext** (per E.10.D1).\n* **SenseCell** — the pair *(Context × Local‑Sense)* from F.3.\n* **Bridge** — a conceptual relation between two SenseCells with kind, direction, CL, and loss notes.\n* **CL (Congruence Level)** — ordinal strength (0…3) of a Bridge (see §7).\n* **Scope** — the **licensed use** of a Cross‑context reading (as in F.7/F.8):\n\n* **Naming‑only** (talk consistently),\n* **Role Assignment & Enactment-eligibility** (assignable constraints/roles/status reuse),\n* **Type‑structure** (safe structural inference).\n* **senseFamily** — the semantic category (Role, Status, Measurement, Type‑structure, Method, Execution…) per F.0.1 (normative Part F guard).\n\n",
        "bridge_kinds_(sensefamily‑aware)": "### F.9:6 - Bridge kinds (senseFamily‑aware)\n\n> **Two families** of Bridges: **Substitution Bridges** (senseFamily‑preserving; can support Concept‑Set rows) and **Interpretation Bridges** (explanatory; **not** for substitution).\n\n#### F.9:6.1 - Substitution Bridges (sense‑preserving)\n\nThese relate **SenseCells of the same senseFamily** and may license **limited substitution**:\n\n1. **Equivalence (≈)** — *near‑identity of sense*. Symmetric. Rare.\n   *Use:* May support **Type‑structure** rows when CL=3 and invariants match.\n   *Loss Notes:* usually “none” or “profiling differences”.\n\n2. **Narrower‑than (⊑)** / **Broader‑than (⊒)** — *proper inclusion of sense*. Directional.\n  *Use:* Safe to substitute **narrower → broader** in **Naming-only** and sometimes **Role Assignment & Enactment**; **broader → narrower** is unsafe.\n   *Loss Notes:* “loses special cases X”.\n\n3. **Partial‑overlap (⋂)** — *non‑empty intersection, neither includes the other*.\n  *Use:* **Naming-only** at best. **Never** justifies Role Assignment & Enactment / Type-structure.\n   *Loss Notes:* “A-only senseFamily”, “B-only senseFamily”.\n\n4. **Disjoint (⊥)** — *explicit contrast*.\n   *Use:* For **didactic warnings**; not a reuse license.\n   *Loss Notes:* n/a (it asserts incompatibility).\n\n#### F.9:6.2 - Interpretation Bridges (cross‑senseFamily, explanatory)\n\nThese **do not allow substitution** but **explain connections** across senseFamilies:\n\n5. **Design‑spec ↔ Run‑trace (⇄ᴅʀ)** — a design concept relates to its run‑time occurrence.\n   *Example:* *BPMN\\:Process* ⇄ᴅʀ *PROV\\:Activity*.\n   *Use:* Explain pipelines (design → execution → provenance). No Concept‑Set rows.\n   *Loss Notes:* “graph vs event”, “control‑flow vs temporal extent”.\n\n6. **Measure‑of / Evidence‑for (→ᴍᴇᵃ)** — a measurement SenseCell evidences or quantifies another **senseFamily** (e.g., a Requirement clause).\n   *Example:* *SOSA\\:Observation* →ᴍᴇᵃ *ITIL\\:SLO fulfilment*.\n   *Use:* Explain evaluation. No substitution.\n\n7. **Policy‑implies / Obliges (→ᴅᵉᵒ)** — a deontic statement constrains another **senseFamily**.\n   *Example:* *ODRL\\:Duty* →ᴅᵉᵒ *Service behaviour*.\n   *Use:* Explain constraint propagation.\n\n> **Rule of thumb.** If you want **rows** or **substitution**, you need a **Substitution Bridge** on the **same senseFamily**. If you want to **explain** why artefacts relate without claiming sameness, use **Interpretation Bridges**.\n\n",
        "cl_scale_and_scope_thresholds": "### F.9:7 - CL scale and scope thresholds\n\nCL expresses how safely meaning carries over.\n\n| CL    | Name              | Intuition                                            | Typical loss         | Row scope allowed (τ thresholds) |\n| ----- | ----------------- | ---------------------------------------------------- | -------------------- | -------------------------------- |\n| **0** | **Opposed**       | Intentionally contrastive or disjoint                | n/a                  | none                             |\n| **1** | **Comparable**    | Talk under a shared label; senses differ materially  | material sense divergence | **Naming‑only** (τₙₐₘₑ=1)        |\n| **2** | **Translatable**  | Bounded loss; consistent examples & counter-examples | small, stated losses | **Role Assignment & Enactment-eligibility** (τRAE=2)     |\n| **3** | **Near‑identity** | Invariants match; no material counter‑example        | profile‑level only   | **Type‑structure** (τᵗʏᴘᴇ=3)     |\n\n* **Thresholds (normative):**\n\n  * Publishing a **Naming‑only** row requires **CL ≥ 1** across the row’s Cells.\n * Publishing a **Role Assignment & Enactment-eligible** row requires **CL ≥ 2** and **same senseFamily**, and **compatible stance**..\n  * Publishing a **Type‑structure** row requires **CL = 3** **and** matched invariants (acyclicity, anti‑symmetry, units, etc.).\n\n* **Penalty use (informative):** B.3 may convert **CL** into an assurance **penalty** when a Cross‑context claim is made.\n\n",
        "the_bridge_card_(one‑screen_sketch)": "### F.9:8 - The Bridge Card (one‑screen sketch)\n\n> A **thought‑format** (not a form). Every bullet can be said in a sentence.\n\n* **Cells.** `σA@contextA` ↔ `σB@contextB`.\n* **senseFamily.** *Role / Status / Measurement / Type‑structure / Method / Execution …*\n* **Kind.** *≈ / ⊑ / ⊒ / ⋂ / ⊥ / ⇄ᴅʀ / →ᴍᴇᵃ / →ᴅᵉᵒ*.\n* **Direction.** *A→B* (if non‑symmetric) or *A↔B*.\n* **CL.** *0–3* with a short **why**.\n* **Loss Notes (bullets).** What fails to carry (units, scope, granularity, preconditions, time stance).\n* **Counter‑example.** The crispest case where substitution would mislead.\n* **Allowed use.** *Naming-only / Role Assignment & Enactment-eligible / Type-structure / Explanation-only*.\n* **Didactic hook.** The helpful sentence a careful engineer can remember.\n\n*If your Bridge Card doesn’t fit on a screen, you’re describing the Contexts, not the Bridge.*\n\n",
        "invariants_(normative)": "### F.9:9 - Invariants (normative)\n\n1. **Locality first.** A Bridge relates **SenseCells**, never Contexts or strings.\n2. **senseFamily discipline.** **Substitution Bridges must be senseFamily‑preserving**. **Interpretation Bridges** may cross senseFamilies but **never** license substitution.\n3. **Direction clarity.** If the kind is non‑symmetric (⊑/⊒), **state direction** explicitly.\n4. **CL honesty.** Assign **CL** only if you can state at least one **counter‑example** (CL≤2) or explain its absence (CL=3).\n5. **Loss visibility.** Every Bridge carries **Loss Notes** (even “none”).\n6. **Row dependence.** A Concept‑Set row’s **scope** is **bounded by the weakest CL** among its participating Bridges (F.7/F.8).\n7. **No senseFamily jump by stealth.** You **must not** use an Interpretation Bridge to justify a **row** or **substitution**.\n8. **Time DesignRunTag honesty.** If a Context fixes **design/run**, the Bridge must respect or explicitly declare stance relations (e.g., ⇄ᴅʀ).\n9. **Kernel restraint.** Bridges **cannot** be used to promote ad‑hoc sameness into a new **U.Type**; A.11 applies.\n10. **Non‑inheritance of Contexts.** Bridges **do not** imply “is‑a” between Contexts (E.10.D1).\n\n",
        "micro‑examples_(illustrative,_one‑liners)": "### F.9:10 - Micro‑examples (illustrative, one‑liners)\n\n1. **Participant vs Agent (workflow vs provenance)**\n   *Cells:* `BPMN:Participant` ↔ `PROV:Agent` • *senseFamily:* Role • *Kind:* ⋂ (overlap) • *CL:* 2 • *Loss:* participation vs attribution scopes differ • *Use:* **Naming‑only** (“actor”).\n\n2. **Process (design) vs Activity (run)**\n   *Cells:* `BPMN:Process` ⇄ᴅʀ `PROV:Activity` • *senseFamily:* Method ↔ Execution • *Kind:* **Design‑spec ↔ Run‑trace** • *CL:* 2 • *Loss:* graph vs event; concurrency vs temporalization • *Use:* **Explanation‑only**.\n\n3. **Observation vs SLO check**\n   *Cells:* `SOSA:Observation` →ᴍᴇᵃ `ITIL:SLO‑fulfilment` • *senseFamily:* Measurement → Status • *Kind:* Measure‑of • *CL:* 2 • *Loss:* sampling window; target definition • *Use:* **Explanation‑only**.\n\n4. **Subtype across OWL and curated taxonomy**\n   *Cells:* `OWL:SubClassOf` ≈ `TaxonomyX:is‑a` • *senseFamily:* Type‑structure • *Kind:* ≈ • *CL:* 3 *(only if TaxonomyX is acyclic & anti‑symmetric)* • *Loss:* profile differences • *Use:* **Type‑structure** rows allowed.\n\n5. **Accuracy (metrology vs data‑quality)**\n   *Cells:* `ISO80000:accuracy` ⋂ `ISO25024:accuracy` • *senseFamily:* Measurement • *Kind:* overlap • *CL:* 2 • *Loss:* instrument vs dataset perspective • *Use:* **Naming‑only** row “accuracy”; methods stay context‑local.\n",
        "anti‑patterns_&_remedies": "### F.9:11 - Anti‑patterns & remedies\n\n| ID        | Anti‑pattern                     | Symptom                                                                           | Why it breaks thinking                              | Remedy (conceptual move)                                                                                    |\n| --------- | -------------------------------- | --------------------------------------------------------------------------------- | --------------------------------------------------- | ----------------------------------------------------------------------------------------------------------- |\n| **AP‑1**  | **String‑equals ≡ sense‑equals** | Same surface used across Contexts with silent identity claims.                       | Violates locality; invites false substitution.      | Always state a **Bridge kind**; if unsure, default to **⋂ overlap** with **Naming‑only** scope.             |\n| **AP-2**  | **Stealth substitution**         | “We’ll just treat A like B for now.”                                              | Hidden policy with unknown loss; leaks into Role Assignment & Enactment.    | Publish a **Bridge Card** with **Loss Notes** and **CL**; if CL<2, substitution remains **forbidden**.      |\n| **AP‑3**  | **Stance jump by wording**        | “Activity (PROV) is a Process (BPMN).”                                            | Design ↔ run confusion; swaps graphs for events.    | Use **⇄ᴅʀ design↔run Interpretation Bridge**, **not** ≈/⊑; keep **Explanation‑only** scope.                 |\n| **AP‑4**  | **Symmetry hallucination**       | Treating ⊑/⊒ as if they were symmetric.                                           | Narrows broadened, broadens narrowed; unsafe reuse. | Record **direction** explicitly; only **≈** is symmetric.                                                   |\n| **AP-5**  | **Disjoint but reused**          | Declare ⊥ then still borrow labels or Role Description constraints (RCS/RSG).     | Contradiction between declaration and use.          | Either retract ⊥ or stop reuse; if a thin thread exists, rename as **contrastive explanation** (no row).    |\n| **AP‑6**  | **CL without counter‑example**   | “These are CL=3” with no invariant check.                                         | Inflates trust; permits structural rows wrongly.    | For **CL=3**, cite the **matching invariants**; otherwise, demote to **CL=2** and add counter‑example.      |\n| **AP‑7**  | **Bridge inflation**             | Dozens of nearly identical Bridges between the same Contexts.                        | Noise masks the few material alignments.            | Prefer **one Bridge per pair of Cells per senseFamily**; fold variants into **Loss Notes**.                       |\n| **AP-8**  | **Row outruns Bridge**           | Concept-Set row claims Role Assignment & Enactment-eligibility where some participating Bridges are CL=1. | Row scope exceeds weakest link.                     | Apply **weakest-link rule** (F.7/F.8): row scope ≤ **min(CL)**; otherwise split the row.                    |\n| **AP‑9**  | **Bridge as new U.Type**         | Using a Bridge to justify minting a new universal Type.                           | Re‑globalises meaning; breaks A.11 parsimony.       | Keep Types context‑local; where reuse is needed, use **rows** + Bridges, not new primitives.                   |\n| **AP‑10** | **Silent unit/scale mismatch**   | Mapping measurements without unit/scale notes.                                    | Hidden dimensional error.                           | Record units/scales in **Loss Notes**; if units can’t be related, the kind is **⊥** or **⋂ (Naming‑only)**. |\n\n",
        "worked_cross‑architheory_examples_(didactic)": "### F.9:12 - Worked cross‑architheory examples (didactic)\n\n#### F.9:12.1 - Service acceptance (design) vs executions & observations (run)\n\n* **Cells & Contexts**\n  `ITIL4:SLO` *(Status, design)* ← **→ᴍᴇᵃ** — `SOSA:Observation(availability)` *(Measurement, run)*\n  `BPMN:Process` *(Method, design)* ⇄ᴅʀ — `IEC61131:Task‑Execution` *(Execution, run)*\n* **Narrative**\n  Availability SLOs are **evaluated** by observations of task executions. No substitution: SLO ≠ observation; process ≠ execution.\n* **Bridge Cards (sketch)**\n  *ITIL\\:SLO ←→ᴍᴇᵃ SOSA\\:Observation* • **CL=2** • Loss: sampling window, clock skew.\n  *BPMN\\:Process ⇄ᴅʀ IEC\\:Execution* • **CL=2** • Loss: control‑flow vs temporalization, concurrency collapse.\n* **Permitted use**\n  Explanation‑only; Concept‑Set rows may be **Naming‑only** (“availability”) with **CL≥1** label coherence across Contexts.\n\n\n#### F.9:12.2 - Behavioural role vs access role\n\n* **Cells & Contexts**\n  `BPMN:Participant` *(Role)* ⋂ `NIST‑RBAC:Role` *(Status)*\n* **Narrative**\n  Both talk about “who acts”, but one is **behavioural mask** in a workflow, the other **permission grouping**.\n* **Bridge**\n  **Kind:** overlap (⋂), **CL=2**; Loss: assignment moment, enforcement locus, multiplicity.\n* **Permitted use**\n* **Naming-only** row “actor”; **no Role Assignment & Enactment reuse** across senseFamilies.\n\n\n#### F.9:12.3 - Equivalence of subtype notions for structural rows\n\n* **Cells & Contexts**\n  `OWL2:SubClassOf` *(Type‑structure)* ≈ `TaxX:is‑a` *(Type‑structure curated)*\n* **Bridge**\n  **Kind:** ≈, **CL=3** **iff** curated taxonomy is **acyclic & anti‑symmetric** and uses class‑level reasoning.\n* **Permitted use**\n  **Type‑structure** rows allowed (τᵗʏᴘᴇ); Loss: OWL profile limitations (RL/EL/QO).\n\n\n#### F.9:12.4 - Accuracy (metrology) vs accuracy (data‑quality)\n\n* **Cells & Contexts**\n  `ISO80000:measurement‑accuracy` *(Measurement)* ⋂ `ISO25024:data‑accuracy` *(Measurement)*\n* **Bridge**\n  **Kind:** overlap, **CL=2**; Loss: “true value” notion differs (instrument vs dataset), scale transformations.\n* **Permitted use**\n  **Naming‑only** row “accuracy” used for reports; no shared methods.\n\n\n#### F.9:12.5 - Setpoint (control) vs target (service)\n\n* **Cells & Contexts**\n  `CTRL:text:setpoint` *(Status/Control)* ⊥ `ITIL:target` *(Status/Service)*\n* **Bridge**\n  **Kind:** disjoint (⊥) • Rationale: physical reference value vs business objective; different target kinds (control parameters vs requirement clause).\n* **Permitted use**\n  Didactic contrast only; prevents accidental substitution in SLO calculus.\n\n#### F.9:12.6 - Role substitution & CL gating (RoleAssignment/enactment scope)\n\n> **Use.** A worked, role‑focused restatement of Bridge usage for the recurring question:\n> “May `Role_B@B` satisfy `Role_A@A` for `requiredRoles` / enactment checks?”\n\n**Rule.** **No Cross‑context substitution by name.** If a step in **Context A** needs `Role_A`, and the performer only holds `Role_B` in **Context B**, an explicit **Bridge** **MUST** be used that states how `Role_B@B` relates to `Role_A@A`, with direction, **CL**, and **loss notes**.\n\n##### F.9:12.6.1 - Directional substitution (role‑oriented shorthand)\n\nA Bridge may assert, *directionally*:\n\n* **`substitutesFor(Role_B@B → Role_A@A)`** with a CL and a list of **kept** and **lost** characteristics (for roles: typical losses are RCS characteristics and/or RSG nuances).\n* The reverse direction **does not** follow unless declared (F.9:13.7).\n\n##### F.9:12.6.2 - CL → gating policy (didactic default)\n\n| **CL** | Meaning (intuitive)                     | **Permit** | **Guard**                                                                            | **Block** |\n| :----: | --------------------------------------- | :--------: | ------------------------------------------------------------------------------------ | :-------: |\n|  **3** | Near‑isomorphic sense; no material loss |    Yes     | None beyond ordinary gates (e.g., window + RSG state)                                |     —     |\n|  **2** | Close but with stated losses            |    Yes     | Require **extra evidence** (e.g., additional checklist item) **or** a named reviewer |     —     |\n|  **1** | Distant analogy; risky                  | Exception  | Only by explicit **Waiver SpeechAct** naming the Bridge + loss rationale             |  Default  |\n|  **0** | Incompatible                            |     No     | —                                                                                    |    Yes    |\n\n*Notes.* The **substitution licence** is defined in **F.9:13.2–13.3** (Role‑Assignment/Enactment‑eligible substitution requires **CL≥2**; naming‑only is **CL≥1**).  \nCL penalties route to assurance (R) per **B.3**; safety‑critical policies may require CL≥2 by default (D.2).\n\n##### F.9:12.6.3 - Typical bridges (worked patterns)\n\n* **BPMN Task ↔ PROV Activity.**  \n  `substitutesFor(Task@BPMN → Activity@PROV)` with **CL=2**; **lost:** BPMN control‑flow guards; **kept:** “bounded occurrence consuming/producing entities.”  \n  *Effect.* A Work logged as `Activity@PROV` may satisfy a step requiring a `Task@BPMN` **iff** an extra guard enforces the BPMN pre‑/post‑conditions.\n\n* **Essence Alpha‑State ↔ RoleStateGraph state.**  \n  `substitutesFor(“Alpha.State:Ready”@Essence → “Ready”@RSG)` with **CL=2**; **lost:** Alpha‑specific narrative criteria; **kept:** checklist‑based readiness.  \n  *Effect.* A team may reuse Essence states as labels in RSG, but still maintains local checklists as **StateAssertions**.\n\n* **ITIL Service Owner ↔ RBAC Administrator.**  \n  Typically **CL=1** and **directional** (Administrator\\@RBAC → ServiceOwner\\@ITIL) **rejected** unless a policy Bridge enumerates compensating controls.  \n  *Effect.* Prevents “ops admin = service owner” conflations without an explicit waiver.\n\n##### F.9:12.6.4 - Bridge invariants (role‑relevant reminders)\n\n* **Local first.** Substitution never overrides in‑Context role algebra (`≤`, `⊥`, `⊗`).\n* **Loss honesty.** If a Bridge’s loss notes indicate that a dropped characteristic is required by a step, substitution is invalid (regardless of CL).\n* **No silent inversion.** Direction is explicit; substitution does not reverse unless declared (F.9:13.7).\n",
        "reasoning_primitives_(judgement_schemas)": "### F.9:13 - Reasoning primitives (judgement schemas)\n\n> **All judgements are conceptual.** They license or forbid specific *thinking moves*—not API calls, not workflows.\n\n#### F.9:13.1 - Bridge declaration\n\n`⊢ Bridge(σA@RA, σB@RB) : ⟨senseFamily, kind, dir, CL, Loss, scope⟩`\n\n*Reading:* There exists a declared Bridge between SenseCells `σA` and `σB` with stated attributes.\n\n\n#### F.9:13.2 - Substitution licence (senseFamily‑preserving)\n\n`Bridge(σA,σB): ⟨senseFamily f, kind∈{≈,⊑,⊒}, dir A→B, CL≥2, Loss L⟩ ⊢ A↠B @f (Role Assignment & Enactment-eligible)`\n\n*Reading:* A **Substitution Bridge** on the same senseFamily with **CL≥2** licenses **Role-Assignment/Enactment-level** substitution **in the stated direction**. (Type-structure requires **CL=3**.)\n\n\n#### F.9:13.3 - Naming‑only licence\n\n`Bridge(σA,σB): ⟨kind∈{≈,⊑,⊒,⋂}, CL≥1⟩ ⊢ A⇝B (Naming‑only)`\n\n*Reading:* A Bridge with **CL≥1** supports using a shared label in prose or Concept-Set **Naming-only** rows, without structural or Role Assignment & Enactment commitments.\n\n\n#### F.9:13.4 - Prohibition by kind\n\n`Bridge(σA,σB): ⟨kind=⊥⟩ ⊢ ¬(A↠B) ∧ ¬(row(A,B))`\n\n*Reading:* **Disjoint** forbids substitution and rows; only contrastive teaching is allowed.\n\n\n#### F.9:13.5 - Interpretation embargo\n\n`Bridge(σA,σB): ⟨kind∈{⇄ᴅʀ,→ᴍᴇᵃ,→ᴅᵉᵒ}⟩ ⊢ Explanation‑only`\n\n*Reading:* **Interpretation Bridges** never license substitution or rows.\n\n\n#### F.9:13.6 - Weakest‑link rule for rows\n\n`row R uses {Bridge_i} ⊢ scope(R) = min_i(scopeAllowed(Bridge_i)) ∧ CL(R)=min_i(CL_i)`\n\n*Reading:* The **row scope** and **row CL** are bounded by the weakest participating Bridge.\n\n\n#### F.9:13.7 - Direction guard\n\n`Bridge kind=⊑ with dir A→B ⊢ ¬(B↠A)`\n\n*Reading:* Narrower→Broader does **not** invert; only A may substitute into B under the stated scope.\n\n\n#### F.9:13.8 - SenseFamily purity\n\n`Bridge scope=Role Assignment & Enactment-eligible ⊢ senseFamily(A)=senseFamily(B) ∧ stance(A)=stance(B)`\n\n*Reading:* Role Assignment & Enactment-level substitution requires **same senseFamily** and same stance (run-time or design time).\n\n\n#### F.9:13.9 - Loss accumulation\n\n`A↠B with Loss L₁ ∧ B↠C with Loss L₂ ⊢ A↠C allowed only if same senseFamily ∧ CL=min(CL₁,CL₂) ∧ Loss ⊇ (L₁∪L₂)`\n\n*Reading:* Chained substitution is rarer; if used, **accumulate Loss** and respect the **minimum CL**. When in doubt, avoid chaining across Contexts.\n\n",
        "relations": "### F.9:14 - Relations\n\n**Builds on:** E.10.D1 (Context discipline: Context ≡ U.BoundedContext); **F.0.1 (senseFamily guard; Bridge‑only crossing)**; F.1 (Contexts fixed); F.2/F.3 (Cells exist); F.7 (rows depend on Bridges); F.8 (thresholds τ).\n\n**Constrains:**\n\n* **F.7 Concept‑Set Table:** each Cross‑context row must name supporting **Bridges**; row scope ≤ weakest Bridge.\n* **F.8 Mint or Reuse?:** reuse choices reference **CL** and **kind**; no reuse without a Bridge.\n* **Part C architheories:** formal claims that span Contexts cite Bridges and respect senseFamily/StatusModality & CL constraints.\n* **B.3 Trust & Assurance Calculus:** may interpret **CL** as a penalty factor in Cross‑context reasoning.\n\n",
        "migration_notes_(conceptual)": "### F.9:15 - Migration notes (conceptual)\n\n1. **Edition shift in a Context.** Re‑read affected **Cells**; if sense moved, split the Bridge or **lower CL**; keep the older Bridge for historical claims.\n2. **New evidence of mismatch.** Add a **counter‑example**; **decrease CL** or change **kind** (e.g., from ≈ to ⊑ or ⋂).\n3. **Convergence over time.** When invariants demonstrably match, and counter‑examples evaporate, **raise CL** cautiously; for **CL=3**, cite invariants.\n4. **senseFamily refactor.** If a Cell’s senseFamily was mis‑typed, fix the senseFamily first in F.3, then revisit Bridges; **Interpretation** is safer than forced substitution.\n5. **Row under‑protected.** If a row’s scope exceeds the weakest Bridge, either **split the row** by Context or **downgrade scope** to Naming‑only.\n6. **Bridge sprawl.** Consolidate near‑duplicates into one Bridge with richer **Loss Notes**; retire the rest.\n\n",
        "acceptance_tests_(scr/rscr_—_concept‑level)": "### F.9:16 - Acceptance tests (SCR/RSCR — concept‑level)\n\n#### F.9:16.1 - Static conformance (SCR)\n\n* **SCR‑F9‑S01 (Well‑typed).** Every Bridge names **two SenseCells**, each bound to a **Context** from F.1, and states **senseFamily**, **kind**, **dir** (if needed), **CL**, **Loss**, **scope**.\n* **SCR‑F9‑S02 (senseFamily discipline).** Any Bridge that licenses **Role/Enactment-eligible** substitution is **senseFamily‑preserving** and **kind ∈ {≈,⊑,⊒}**.\n* **SCR‑F9‑S03 (Loss visibility).** Every Bridge has **non‑empty Loss Notes** (the word “none” is allowed only with **CL=3** and stated invariants).\n* **SCR‑F9‑S04 (Counter‑example hygiene).** Bridges with **CL≤2** carry at least one **counter‑example**; Bridges with **CL=3** cite **matching invariants**.\n* **SCR‑F9‑S05 (Row compliance).** Every Concept‑Set row shows a **scope** no greater than the **minimum CL** across its supporting Bridges; no row relies on **Interpretation** Bridges.\n\n#### F.9:16.2 - Regression (RSCR)\n\n* **RSCR‑F9‑E01 (Edition churn).** When a Context’s edition changes, re‑validate all Bridges touching it; **flag CL drift** and update rows’ scopes if needed.\n* **RSCR‑F9‑E02 (Counter‑example drift).** New counter‑examples lower **CL**; deletions do not automatically raise **CL**.\n* **RSCR‑F9‑E03 (senseFamily drift).** If a Cell’s senseFamily is corrected, all Bridges crossing that Cell are re‑typed; any substitution that would now cross senseFamilies is **invalidated**.\n* **RSCR‑F9‑E04 (Weakest‑link enforcement).** Adding a low‑CL Bridge to a row **reduces** the row’s scope; if the row’s published scope would exceed the new minimum, **split** or **downgrade** the row.\n\n",
        "didactic_distillation_(90‑second_script)": "### F.9:17 - Didactic distillation (90‑second script)\n\n> “A **Bridge** translates between **local senses** from different **Contexts**. It always declares **what relation** (≈, ⊑, ⋂, ⊥, or an **interpretation** like design↔run), **how strong** (CL 0–3), **which way** (for ⊑/⊒), and **what is lost**. **Substitution** is allowed only on the **same senseFamily** and only with **CL≥2**; **Type‑structure** needs **CL=3**. **Interpretation Bridges** explain, never substitute. Rows in the Concept‑Set table obey the **weakest‑link**: their scope cannot exceed the lowest CL among their Bridges. When editions change or counter‑examples surface, **lower CL** or change **kind**; if two senses truly converge and invariants match, raise to **CL=3**—rarely, and with reasons. Translate across Contexts; never collapse them.”\n",
        "f.9:end": "### F.9:End\n"
      },
      "content": "### F.9:End\n",
      "metadata": {},
      "part": "F",
      "cluster": null
    },
    {
      "id": "F.10",
      "title": "Status Families Mapping (Evidence • Standard • Requirement)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## F.10 - Status Families Mapping (Evidence • Standard • Requirement)\n\n**“Keep statuses in their native modality; translate between Contexts explicitly.”**\n**Status.** Architectural pattern, architheory‑agnostic.\n**Builds on:** E.10.D1 **D.CTX** (Context ≡ `U.BoundedContext`); F.1 (Contexts), F.2 (Seeds), F.3 (Local‑Senses → SenseCells), F.4 (Role Description **Status** templates), F.9 (Bridges).\n**Coordinates with.** B.3 **Trust & Assurance Calculus** (interprets CL penalties); Part C architheories: **KD‑CAL** (measurement semantics), **Norm‑CAL** (deontic logic), **Method‑CAL** (DesignRunTag).\n\n",
        "intent_&_applicability": "### F.10:1 - Intent & applicability\n\n**Intent.** Provide a **simple, Context‑first way** to express and compare **status meanings** across disciplines **without collapsing modalities** (*epistemic* vs *deontic*). We focus on three pervasive **status families**:\n\n1. **EvidenceStatus** (what the world **shows**) — epistemic modality.\n2. **StandardStatus** (what a canon **sanctions**) — deontic (curatorial) modality.\n3. **RequirementStatus** (what an obligation is **doing**) — deontic (compliance) modality.\n\nEach status meaning is **local to a Context** (`U.BoundedContext`). Cross‑context relationships appear **only** via **Bridges** (F.9) with a declared **kind** and **CL** (congruence level).\n\n**Applicability.** Whenever models mix observations, standards, and obligations: service acceptance from uptime measurements; safety proofs against normative checklists; ML model “validated” vs “approved for use”.\n\n**Non‑goals.** No workflows, no tool states, no editorial lifecycles. This pattern defines **conceptual meaning and safe reasoning moves**, not procedures.\n\n",
        "problem": "### F.10:2 - Problem frame\n\nWithout a modality‑aware mapping of statuses:\n\n* **Homonym traps.** *Validated* in metrology ≠ *validated* in software QA; *approved* in a standard ≠ *compliant* to a requirement.\n* **Design/run bleed.** Design‑time “approved method” is used as if it proved run‑time “meets SLO”.\n* **False substitution.** *Observed availability 99.95%* is silently treated as *SLO satisfied* without declaring the translation.\n* **Name inflation.** New U.Types minted to stabilise drifting status words instead of fixing Contexts and Bridges.\n\n",
        "forces": "### F.10:3 - Forces\n\n| Force                                     | Tension to resolve                                                                             |\n| ----------------------------------------- | ---------------------------------------------------------------------------------------------- |\n| **Local fidelity vs Cross‑context reuse**    | Keep native Context meanings, yet enable explanation and (sometimes) substitution.                |\n| **Didactic simplicity vs status variety** | Many status schemes exist; we need a **small spine** that admits Context synonyms.                |\n| **Design vs run**                         | Standards speak design; evidence speaks run; requirements span both; do not swap them.         |\n| **Safety vs utility**                     | Substitution is powerful but risky; explanation is safer but weaker. Make the choice explicit. |\n\n",
        "core_idea_(didactic)": "### F.10:4 - Core idea (didactic)\n\n**Three families, two modalities, one habit.**\nTreat every status word as a **SenseCell with a declared StatusModality** and **inside one Context**. When you must relate statuses across Contexts, **declare a Bridge** (F.9) that says *what kind of relation*, *how strong (CL)*, *which way (if narrower/broader)*, and *what is lost*. Prefer **explanation** Bridges; permit **substitution** only when kind/CL allow it.\n\n**Reading an Episteme.** For every `U.Episteme`, read _Object_ (what it is about), _Concept_ (model/postulates), _Symbol_ (carriers). **Statuses classify the Episteme;** enactment remains with `U.System` and `U.Work`. (Formal identity rules: see **KD‑CAL**.)\n",
        "minimal_vocabulary_(this_pattern_only)": "### F.10:5 - Minimal vocabulary (this pattern only)\n\n* **StatusFamily.** Sub‑typing inside **senseFamily=Status**: one of **EvidenceStatus**, **StandardStatus**, **RequirementStatus**.\n* **StatusCell.** A **SenseCell** whose meaning is a status with a declared **StatusModality ∈ {epistemic, deontic}**\n* **StatusModality.** The mode of a StatusCell: **epistemic** or **deontic**. Use this term instead of the bare word *modality* per E.10 LEX rules.\n* **Polarity.** The orientation of a status relative to a claim/obligation: **Positive** (supports/satisfies), **Negative** (contradicts/violates), **Neutral/Undetermined**.\n* **Window.** The **applicability span** of a status (temporal or conditional), e.g., “Q3‑2025”, “under load ≥ 70%”.\n* **Target.** What the status is **about**: a **claim** (epistemic), an **artefact or method** (standard), a **clause** (requirement).\n* **Bridge (F.9).** The only legal way to relate StatusCells across Contexts; declares **kind** (≈, ⊑, ⊒, ⋂, ⊥, or an Interpretation arrow), **CL**, and **Loss**; **substitution is modality‑preserving**.\n\n> **StatusModality guard.** EvidenceStatus is **epistemic**; StandardStatus & RequirementStatus are **deontic**. **Role Description Status** templates (F.4) bind to these **StatusModalities**; **no mixing**. The bare token *modality* is against E.10/LEX); this pattern uses **StatusModality**.\n\n",
        "the_spine:_three_local_ladders_(context‑native,_small_and_renameable)": "### F.10:6 - The spine: three local ladders (Context‑native, small and renameable)\n\n> The following ladders are **didactic spines**. Each Context may rename levels or insert thin sub‑levels, but Bridges must state how they align to this spine (kind & CL). Names appear in **Tech** / **Plain** register.\n\n -   **Episteme‑as‑actor (forbidden).** Never attribute **Work** to an Episteme; only Systems act.\n    \n-   **Requirement vs Hypothesis.** “Desired property/goal” is **not** `Requirement` status; use hypothesis/target + evaluation.\n    \n-   **Mereology ≠ Provenance.** Part‑whole edges never justify claims; use EPV‑DAG with carriers.\n\n\n#### F.10:6.1 - EvidenceStatus (epistemic statusModality)\n\n**Levels (from weaker to stronger):**\n\n1. **Observed** / *Seen once.*\n2. **Measured** / *Quantified under a declared procedure.*\n3. **Corroborated** / *Seen independently (≥ 2 distinct sources/procedures).*\n4. **Replicated** / *Repeated by others under varied conditions.*\n5. **Refuted** *(negative polarity)* / *Counter‑evidence overrides prior levels.*\n6. **Inconclusive** *(neutral)* / *Insufficient signal.*\n\n**Context alignment examples (illustrative):**\n`SOSA/SSN:Observation` ↦ **Observed/Measured**; `GxP validation datapack` may map to **Replicated** (if protocol diversity holds) with **CL stated**.\n\n**Invariants (context‑local):**\n*Replicated ⇒ Corroborated ⇒ Measured ⇒ Observed.* Negative (**Refuted**) cancels positives **within the same Window**.\n\n\n#### F.10:6.2 - StandardStatus (deontic/curatorial statusModality)\n\n**Levels (design‑time stance):**\n\n1. **Candidate** / *Proposed, under review.*\n2. **Draft** / *Working text, not normative.*\n3. **Approved** / *Normative in this Context/edition.*\n4. **Deprecated** *(negative)* / *Discouraged; may be removed.*\n5. **Superseded** *(negative)* / *Replaced by a newer edition/profile.*\n\n**Context alignment examples:**\n`ISO profile: Published International Standard` ↦ **Approved**; `IETF RFC (Proposed Standard)` ↦ **Draft/Approved** depending on local policy; **CL must be declared** on the Bridge.\n\n**Invariants:**\nAt most one positive stance at a time **per Context & edition**; **Superseded** implies **Approved** held in a prior Window.\n\n\n#### F.10:6.3 - RequirementStatus (deontic/compliance statusModality)\n\n**Levels (run‑aware stance toward an obligation):**\n\n1. **Applicable** / *The clause binds in this Window.*\n2. **Inapplicable** / *Clause does not bind under stated conditions.*\n3. **Satisfied** *(positive)* / *Met within Window.*\n4. **Violated** *(negative)* / *Not met within Window.*\n5. **Waived** *(neutral/administrative)* / *Binding suspended with justification.*\n6. **Pending** *(neutral)* / *Awaiting evaluation or evidence.*\n\n**Context alignment examples:**\n`ITIL4:SLO achieved` ↦ **Satisfied**; `ODRL:Duty fulfilled` ↦ **Satisfied**; `ODRL:Prohibition breached` ↦ **Violated**.\n\n**Invariants:**\nFor the **same clause and Window**, **Satisfied** and **Violated** are **mutually exclusive**. **Applicable** is a **precondition** for either; **Waived** switches off the precondition temporarily.\n\n#### F.10:6.4 - Contextual Citation Operators (pointer)\n\n**Citation operators (context‑scoped).** Authors MAY use the **typed edges** `supports`, `refutes`, `dependsOn`, `supersedes` **inside a single Context** when expressing how an `Evidence`/`Standard` status applies. **Formal semantics live in B.3.2 (Evidence & Validation Logic).** Cross‑Context use requires a declared **Bridge** (F.9) and carries CL/Loss penalties.\n\n",
        "solution": "### F.10:7 - Solution — how meanings connect (conceptual, notation‑free)\n\n**S‑1. Anchor status meanings per Context.**\nEvery status word (*validated*, *approved*, *compliant*) is treated as a **StatusCell** inside a specific Context. The **ladder position** is determined **locally** (e.g., “validated (metrology)” aligns to **Replicated** with CL stated; “validated (software)” may align to **Corroborated**).\n\n**S‑2. Attach statuses to the right Targets.**\n*EvidenceStatus → Claim or Quantity; StandardStatus → Method/Artefact; RequirementStatus → Clause.*\nThis prevents swapping “how we measure” with “what we promise”.\n\n**S‑3. Translate via Bridges, not by name.**\nExample: **Measured availability (SOSA)** →ᴍᴇᵃ **SLO clause (ITIL)** with **CL=2**, Loss: sampling window & clock skew. This supports **explanation**; **substitution** (“Satisfied”) requires **same StatusModality**, a stricter Bridge kind (F.9) **and** a declared evaluation rule (from the Service pattern), not from F.10.\n\n**S‑4. Keep design/run honest.**\n**StandardStatus** is design‑stance; **EvidenceStatus** is run‑signal; **RequirementStatus** spans both. Use **Interpretation Bridges** (F.9) for design↔run readings, not equivalence.\n\n**S‑5. Prefer explanation over substitution.**\nIf a Bridge cannot reach **CL≥2** on the **same senseFamily**, do **not** substitute. Use **Naming‑only** rows or **explanations**; keep Role Descriptions (F.4) out of harm’s way.\n\n",
        "invariants_(normative,_lightweight)": "### F.10:8 - Invariants (normative, lightweight)\n\n1. **Modality purity.** A StatusCell’s **StatusModality** is explicit and **must not change** during reasoning; cross‑modality claims require an **Interpretation Bridge** (F.9).\n2. **Target typing.** A status **must name its Target kind** (claim / artefact / clause). Inferences that ignore the Target kind are invalid.\n3. **Window discipline.** Every positive/negative status **names a Window**; contradictions are detected **within the same Window** only.\n4. **Local monotonicity.** Within one context, **stronger** EvidenceStatus implies all **weaker** positives for the same Target & Window.\n5. **Mutual exclusivity (requirement).** For a given clause & Window: **not** (Satisfied ∧ Violated).\n6. **No free promotion.** **StandardStatus** (Approved) **does not** entail **RequirementStatus** (Applicable or Satisfied).\n7. **Bridge gate.** Any Cross‑context comparison or reuse of a status **must cite a Bridge** (kind, CL, Loss); otherwise only **context‑local** reading is permitted.\n8. **Weakest‑link propagation.** When multiple Bridges contribute to a Cross‑context interpretation, the **effective CL** is the **minimum** (cf. F.7/F.9).\n9. **Naming restraint.** Status labels used across Contexts **without** a Bridge are **Naming-only** and **non-operative** for Role Assignment & Enactment decisions.\n",
        "micro‑illustrations_(snapshots,_not_procedures)": "### F.10:9 - Micro‑illustrations (snapshots, not procedures)\n\n* **Metrology → Service.**\n  *Observed uptime (SOSA)* with Window “July” plus Bridge **→ᴍᴇᵃ** to *SLO clause (ITIL)* yields: **we can explain** why “Satisfied” might hold **if** the Service pattern’s evaluation rule says so. F.10 itself **does not** declare “Satisfied”.\n\n* **QA vs GxP “validation”.**\n  *Validated (software QA Context)* aligns to **Corroborated** (CL=1–2).\n  *Validated (GxP Context)* aligns to **Replicated** (CL=2–3) with Loss: environment diversity.\n  Equating them needs **≈** with **CL stated** or they remain separate.\n\n* **“Approved model” ≠ “Compliant outcome”.**\n  **StandardStatus: Approved** for a **MethodDescription** does **not** imply **RequirementStatus: Satisfied** for a production clause. It only permits use; evidence must still speak.\n",
        "anti‑patterns_&_remedies": "### F.10:10 - Anti‑patterns & remedies\n\n| #         | Anti‑pattern                                 | Symptom                                                                        | Why it harms reasoning                                                               | Remedy (conceptual move)                                                                                                                                                                                                                       |\n| --------- | -------------------------------------------- | ------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **AP‑1**  | **“Validated ⇒ Approved ⇒ Compliant” chain** | A single word *validated* is treated as proving approval and compliance.       | Collapses **statusModalities** (epistemic → deontic); ignores Targets & Windows.               | Keep **EvidenceStatus** about **claims**, **StandardStatus** about **artefacts/methods**, **RequirementStatus** about **clauses**. Use **two Bridges** (evidence→requirement via interpretation + standard→requirement via policy), never one. |\n| **AP‑2**  | **Run‑time proves design‑time**              | A month of logs is cited as “therefore the method is approved.”                | Directional fallacy; design‑time approval is curatorial, not measured.               | Separate **design vs run**. Evidence may justify a **proposal** Bridge to *Approved* only in Contexts where such promotion exists; otherwise keep **explanation‑only**.                                                                           |\n| **AP‑3**  | **“Approved model” ⇒ “SLO satisfied”**       | Governance stamp is cast as automatic service compliance.                      | **StandardStatus** does not entail **RequirementStatus**; the latter needs evidence. | Require **EvidenceStatus** on the clause’s **Window**, then apply the **evaluation rule** (Service pattern).                                                                                                                                   |\n| **AP‑4**  | **Synonym drift of status labels**           | *Verified/validated/approved* used interchangeably across Contexts.               | Homonymy across Contexts; weakens claims.                                               | Treat each status word as a **StatusCell** tied to its Context; relate only via **Bridge(kind, CL, Loss)**.                                                                                                                                       |\n| **AP‑5**  | **No Window**                                | Status claimed without time/condition (“Compliant.”).                          | Unfalsifiable; blocks conflict detection.                                            | Every positive/negative status **names a Window**; contradictions checked per Window.                                                                                                                                                          |\n| **AP‑6**  | **Double truth**                             | *Satisfied* and *Violated* asserted for same clause silently.                  | Violates mutual exclusivity; hides differing Windows.                                | Force **Window discipline**; if Windows coincide, at least one assertion must retract.                                                                                                                                                         |\n| **AP‑7**  | **Substitute by name**                       | “SOSA Observation = ITIL SLO check”.                                           | Cross‑context equality without Loss accounting.                                         | Prefer **explanation Bridges**; allow **substitution** only when **same statusModality**, **kind ∈ {≈,⊑,⊒}**, **CL≥project threshold**, **Windows aligned**.                                                                                            |\n| **AP‑8**  | **Evidence escalation without diversity**    | One lab repeats itself and calls it “replicated”.                              | Confuses **repetition** with **independent replication**.                            | In EvidenceStatus, **Replicated** demands **independent** settings/sources; else keep at **Corroborated**.                                                                                                                                     |\n| **AP‑9**  | **Clause‑less compliance**                   | “Compliant” with no clause named.                                              | Target missing; cannot evaluate.                                                     | Every RequirementStatus **points to a clause** (Target).                                                                                                                                                                                       |\n| **AP‑10** | **Negative erased by summary**               | A later summary lists *Satisfied* but omits earlier *Violated* in same Window. | Cherry‑picks; breaks auditability.                                                   | Apply **Weakest‑link**: within a Window, **negative outranks** prior positives for the same clause.                                                                                                                                            |\n| **AP‑11** | **Bridge‑free roll‑up**                      | Cross‑context dashboards aggregate statuses as if native.                         | Hidden Cross‑context semantics; CL unknown.                                             | Each Cross‑context line **must cite Bridges**; roll‑up shows the **effective CL (min)**.                                                                                                                                                          |\n| **AP‑12** | **Status explosion**                         | New bespoke statuses minted to match every tool state.                         | Pollutes lexicon; blurs statusModalities.                                                      | Map tool states to the **nearest ladder level** in the local context; keep tool terms as **Naming‑only** where needed.                                                                                                                            |\n",
        "worked_examples_(multi‑architheory)": "### F.10:11 - Worked examples (multi‑architheory)\n\n> Each example names **Contexts**, shows **StatusCells** on their native ladders, and draws **only the Bridges that F.10 allows**.\n\n#### F.10:11.1 - Service acceptance from run‑time evidence\n\n**Contexts.** *SOSA/SSN (2017)* — sensing; *ITIL 4 (2020)* — services; *ODRL 2.2* — deontics (optional).\n\n**Local statuses.**\n\n* `SOSA:Observation(uptime)` → **EvidenceStatus: Measured**, Window **July**.\n* `ITIL:SLO(\"99.9% monthly\")` → **RequirementStatus** Target = clause *SLO‑99.9*, Window **July**.\n* `ITIL:Practice(\"Monitoring pipeline\")` → **StandardStatus: Approved** (design‑time).\n\n**Bridges.**\n\n* **Interpretation**: `Measured(uptime@July)` **→ᴍᴇᵃ** `SLO‑99.9` (kind = ⊑, CL = 2, Loss: sampling bias, clock skew).\n* **Evaluation rule** (Service pattern, local to ITIL Context): returns **Satisfied** iff *mean uptime ≥ threshold* across Window.\n\n**Result.** We may **explain** the **Satisfied** conclusion for *SLO‑99.9\\@July*; we **do not** assert StandardStatus⇒RequirementStatus. If logs later show outages, a **Violated\\@July** replaces **Satisfied\\@July** (mutual exclusivity + Window discipline).\n\n\n#### F.10:11.2 - Safety controller: design approval vs run‑time duty\n\n**Contexts.** *State‑space control texts* — design; *IEC 61131‑3* — run; *Norm‑CAL profile (safety layer)* — deontics.\n\n**Local statuses.**\n\n* `ControllerSpec(v3)` — **StandardStatus: Approved** in the **Norm‑CAL** Context.\n* `PLC:Task(log@Q3)` — **EvidenceStatus: Corroborated** for *response time ≤ 50 ms*, Window **Q3**.\n* `Duty(\"Emergency stop ≤ 100 ms\")` — **RequirementStatus** clause in Norm‑CAL.\n\n**Bridges.**\n\n* **Interpretation**: `Corroborated(response@Q3)` **→** `Duty` check (kind = ⊑, CL = 2, Loss: sensor latency).\n\n**Result.** The **duty** may be **Satisfied\\@Q3** with explanation. *Approved spec* **alone** never yields *Satisfied*; it authorises deployment but does not prove compliance.\n\n\n#### F.10:11.3 - ML model: validation vs fairness requirement\n\n**Contexts.** *ML validation canon* — design/run hybrid; *Policy Context (fairness charter)* — deontics; *SOSA/metrics* — sensing.\n\n**Local statuses.**\n\n* `Model v12: cross‑val AUC=0.92` → **EvidenceStatus: Corroborated** (Windows: CV folds).\n* `Policy: “Demographic parity Δ ≤ 0.1”` → **RequirementStatus** clause.\n* `“Validation SOP v5”` → **StandardStatus: Approved** (governance method).\n\n**Bridges.**\n\n* `Measured(Δ@Aug)` **→ᴍᴇᵃ** `Policy clause` (⊑, CL = 2, Loss: sampling variance).\n\n**Result.** **Satisfied\\@Aug** (if Δ≤ 0.1 in production Window) is justifiable. Cross‑val AUC does **not** decide fairness; only **production Δ** does.\n\n\n#### F.10:11.4 - Medical device log: refutation\n\n**Contexts.** *SOSA/clinical observations*; *Regulatory profile*.\n\n**Local statuses.**\n\n* `Observation: adverse event` → **EvidenceStatus: Observed\\@Week 34**.\n* `Requirement: “No AE in first 30 days”` → **RequirementStatus** clause.\n\n**Bridge & outcome.**\n\n* Observation **→ Interpretation Bridge** to clause check (**kind: Interpretation**, **CL=3**).\n* **Violated\\@Week 34** overrides any earlier **Satisfied\\@Week 34** (Weakest‑link; same Window).\n\n",
        "reasoning_primitives_(judgement_schemas,_notation‑free)": "### F.10:12 - Reasoning primitives (judgement schemas, notation‑free)\n\n> **Premises ⊢ conclusion.** No side effects. All moves are **mental** and **Context‑aware**.\n\n1. **StatusModality classification**\n   `σ is a StatusCell ⊢ statusModality(σ) ∈ {epistemic, deontic}`\n   *Reading:* Every status sits on exactly one statusModality.\n\n2. **Target typing**\n   `σ ⊢ targetKind(σ) ∈ {claim, artefact/method, clause}`\n   *Reading:* Evidence→claim; Standard→artefact/method; Requirement→clause.\n\n3. **Window requirement**\n   `σ has polarity ∈ {positive, negative} ⊢ window(σ) ≠ ∅`\n   *Reading:* Pos/neg statuses must name a Window.\n\n4. **Local ladder monotonicity (evidence)**\n   `Replicated(τ,W) ⊢ Corroborated(τ,W) ⊢ Measured(τ,W) ⊢ Observed(τ,W)`\n   *Reading:* Stronger implies weaker within the same Window.\n\n5. **Requirement exclusivity**\n   `clause κ, window W ⊢ ¬(Satisfied(κ,W) ∧ Violated(κ,W))`\n   *Reading:* A clause cannot be both satisfied and violated in one Window.\n\n6. **Windowed refutation**\n   `Refuted(τ,W) ⊢ cancels {Observed,Measured,Corroborated,Replicated}(τ,W)`\n   *Reading:* Negative evidence cancels positives only in the same Window.\n\n7. **Explanation Bridge**\n   `σ@C, τ@D, Bridge(C,D, kind∈{≈,⊑,⊒,⋂}, CL, Loss), sameStatusModality ⊢ explains(σ ⇒ τ) with ⟨CL,Loss⟩`\n   *Reading:* Cross‑context explanation is permitted when statusModalities match.\n\n8. **Substitution permission (guarded)**\n   `explains(σ ⇒ τ) ∧ kind∈{≈,⊑,⊒} ∧ CL≥θ ∧ windowsAligned ⊢ maySubstitute(σ→τ)`\n   *Reading:* Substitution is allowed only above a **project‑declared threshold θ** (see F.7) and aligned Windows.\n\n9. **Cross‑statusModality embargo**\n   `statusModality(σ) ≠ statusModality(τ) ⊢ explains(σ ⇒ τ) requires Interpretation kind`\n   *Reading:* Crossing statusModalities is **interpretation** only; no direct substitution.\n\n10. **Observation→Requirement clause (SOSA, Work outcomes)**\n   `SOSA:Observation about Work outcomes ⊢ may interpret(RequirementClause κ) via Bridge(kind=Interpretation, CL, Loss); produces Evaluation(κ, Window); substitution forbidden`\n   *Reading:* Observations inform clause evaluation within a Window; they never become RequirementStatus. Use F.12 for the verdict pipeline.\n\n11. **Weakest‑link CL**\n   `{explains(σᵢ ⇒ τ) with CLᵢ} ⊢ effectiveCL(⋀ᵢ σᵢ ⇒ τ) = minᵢ(CLᵢ)`\n   *Reading:* Multiple Bridges compose by the minimum CL.\n\n12. **Naming‑only safeguard**\n   `noBridge(C,D) ⊢ crossContextUse(σ@C ⇒ τ@D) = namingOnly`\n   *Reading:* Without a Bridge, only **explanatory prose** is allowed—no status inferences.\n\n13. **DesignRunTag honesty**\n   `statusModality=deontic ∧ targetKind=artefact/method ∧ window=W ⊢ doesNotDecide(clause κ @ W)`\n   *Reading:* Approval of a method never decides a clause’s satisfaction for a run‑time Window.\n",
        "relations": "### F.10:13 - Relations\n\n**Builds on:**\nE.10.D1 **D.CTX** (Context discipline); F.1 (Contexts in view); F.2–F.3 (Seeds→Local‑Senses→SenseCells); F.4 (Role Description **Status** template with statusModality/target/window slots); F.7 (Bridge taxonomy & CL semantics); F.9 (Bridge artefact).\n\n**Constrains:**\n\n* **F.4 (Role Description Status):** a Role Description Status **must** select a **StatusFamily**, **StatusModality**, **target kind**, and **Window**.\n* **F.8 (Naming):** status labels reused across Contexts **must** be marked as **Context‑scoped**; global synonyms forbidden.\n* **Part C architheories:** KD‑CAL provides measurement semantics for EvidenceStatus; Norm‑CAL provides clause logic for RequirementStatus; Method‑CAL frames DesignRunTag for StandardStatus.\n\n**Used by.**\nService Acceptance (F.12), Assurance roll‑ups (B.3), any cross‑domain conformance narrative.\n\n",
        "migration_notes_(conceptual)": "### F.10:14 - Migration notes (conceptual)\n\n1. **New status word appears.** Treat it as a **StatusCell** in its Context; place it on the local ladder; only then consider Bridges.\n2. **Edition changes.** If a Context redefines a status, **fork the StatusCell** (new SenseCell) and relate old↔new via a **Bridge** (often ⊑/⊒ with Loss).\n3. **Threshold tuning.** The project sets **θ** (minimum CL for substitution). Lowering θ widens reuse but increases risk; document the choice in F.7 terms.\n4. **Clause redesign.** If a requirement clause changes, keep old **Windows** intact; new clause starts a new Target; do **not** rewrite history.\n5. **Explode→compress.** When many bespoke tool statuses pile up, **map** them to the nearest ladder level in their Contexts; keep tool labels as **Naming‑only**.\n6. **Bridge hardening.** If explanation Bridges are used frequently, reconsider experiments that could raise **CL** enough to permit substitution—or accept explanation as sufficient and stop short of substitution.\n\n",
        "acceptance_tests_(scr/rscr_—_concept‑level)": "### F.10:15 - Acceptance tests (SCR/RSCR — concept‑level)\n\n#### F.10:15.1 - Static conformance (SCR)\n\n* **SCR‑F10‑S01 (Modality & Target).** Every StatusCell declares **StatusModality** and **target kind**; none cross modalities.\n* **SCR‑F10‑S02 (Windowed polarity).** Every positive/negative StatusCell instance bears a **Window**.\n* **SCR‑F10‑S03 (Local order).** EvidenceStatus instances satisfy **monotonicity**; RequirementStatus enforces **mutual exclusivity** per clause+Window.\n* **SCR‑F10‑S04 (Bridge citation).** Any Cross‑context comparison cites a **Bridge(kind, CL, Loss)**; absent that, mark as **naming‑only**.\n* **SCR‑F10‑S05 (Substitution guard).** Any substitution claim checks **same StatusModality**, **kind ∈ {≈,⊑,⊒}**, **CL≥θ**, **Windows aligned**.\n* **SCR‑F10‑S06 (Weakest‑link).** Where multiple Bridges feed one conclusion, the displayed **effective CL** is the **minimum**.\n\n#### F.10:15.2 - Regression (RSCR)\n\n* **RSCR‑F10‑E01 (Edition churn).** Adding a new edition of a Context **does not** retro‑change past status conclusions; only new Windows see new meanings.\n* **RSCR‑F10‑E02 (Threshold change).** If θ changes, re‑evaluate only **substitution** conclusions; **explanations** remain valid.\n* **RSCR‑F10‑E03 (Bridge drift).** When a Bridge’s CL/Loss changes, recompute affected **effective CL**; substitution conclusions below θ revert to **explanation**.\n* **RSCR‑F10‑E04 (Contradiction catch).** Adding a negative status within a Window **cancels** prior positives for the same clause (or raises a flagged contradiction if both persist).\n\n",
        "didactic_distillation_(90‑second_script)": "### F.10:16 - Didactic distillation (90‑second script)\n\n> **Three families, two modalities.** *Evidence* tells us what the world **shows** (Observed→Measured→Corroborated→Replicated; Refuted cancels) — **epistemic**; *Standard* tells us what a canon **sanctions** (Candidate→Draft→Approved→Deprecated→Superseded) — **deontic**; *Requirement* tells us what an obligation is **doing** (Applicable/Inapplicable; Satisfied/Violated; Waived/Pending) — **deontic**.\n> Every status is a **StatusCell inside one Context** with exactly one **StatusModality**, a **Target**, and a **Window**.\n> When you must relate status meanings across Contexts, **draw a Bridge** that states the **kind** (≈, ⊑/⊒, ⋂, ⊥ or Interpretation), the **CL** (strength), and the **Loss** (what you ignore). Prefer **explanation**; allow **substitution** only when statusModalities match, kind permits, **CL≥θ**, and Windows align.\n> Keep **design vs run** stance honest: approval is **design‑time**, evidence is **run‑time**, requirements **span both**. With this habit, “validated”, “approved” and “compliant” stop being a muddle of synonyms and become **precise, local meanings** you can compare **safely** and **audibly**.\n",
        "f.10:end": "### F.10:End\n"
      },
      "content": "### F.10:End\n",
      "metadata": {},
      "part": "F",
      "cluster": null
    },
    {
      "id": "F.11",
      "title": "Method Quartet Harmonisation",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## F.11 - Method Quartet Harmonisation\n\n**“Keep the *how* (Method), the *recipe* (MethodDescription), the *happening* (Work/Execution), and the *control push* (Actuation) in their own Contexts—then relate them explicitly.”**\n\n**Status.** Architectural pattern, architheory‑agnostic.\n**Builds on:** E.10.D1 **D.CTX** (Context discipline); A.3/**A.3.1**/**A.3.2** (Transformer Constitution; `U.Method`, `U.MethodDescription`); A.15/**A.15.1** (`U.Work` as record of occurrence); Sys‑CAL (control/actuation semantics); KD‑CAL (observation).\n**Coordinates with.** F.1–F.3 (Contexts, Seeds → SenseCells), F.4 (Role Description), F.5 (Naming), F.6 (Role Assignment & Enactment Cycle (Six-Step)), F.7/F.9 (Bridges), F.10 (Status families & Windows).\n**Aliases (informative).** *Method/Spec/Work/Actuation split*; *design/run harmonisation*.\n\n",
        "intent_&_applicability": "### F.12:1 - Intent & applicability\n\n**Intent.** Provide a **conceptual binding** that turns a *service promise* (SLO/SLA clause) into a **clear, local, time‑bounded judgement** about **actual Work**, using **Observations** as evidence and **explicit Bridges** where Cross‑context notions must meet. The result is a **Status** (Satisfied/Violated/Inconclusive) that attaches to the **clause‑about‑that‑Work‑in‑that‑Window**.\n\n**Applicability.** Any situation where a service is promised (availability, latency, safety margin, response time, quality gate, compliance duty) and its fulfilment must be decided from what occurred. Works across digital services, industrial control, laboratory processes, clinical pathways, logistics, etc.\n\n",
        "problem": "### F.12:2 - Problem frame\n\n1. **Plan ≠ proof.** Diagrams and playbooks are treated as if they demonstrated fulfilment.\n2. **Signal ≠ outcome.** Control signals (Actuation) are mistaken for the service outcome experienced by the consumer.\n3. **Global meanings.** *Availability*, *incident*, *latency* are used as if universal, ignoring context‑local senses.\n4. **Unstated translation.** Metrics from one canon are mapped to clauses from another without declaring losses.\n5. **Timeless verdicts.** Judgements are asserted with no explicit Window (day, month, batch).\n\n",
        "forces": "### F.12:3 - Forces\n\n| Force                                | Tension to resolve                                                                                        |\n| ------------------------------------ | --------------------------------------------------------------------------------------------------------- |\n| **Promise vs. occurrence**           | Service is defined as an external **promise** (A.2.3), yet acceptance must reference **Work** (run‑time). |\n| **Locality vs. integration**         | Meanings are **context‑local**; still we must compare across services, plants, and monitors.                 |\n| **Parsimony vs. realism**            | We want a small binding scheme, yet domains differ (percentiles, downtime minutes, control margins).      |\n| **Evidence vs. privacy/feasibility** | Observations prove outcomes; sometimes only proxies exist.                                                |\n\n",
        "core_idea_(didactic)": "### F.12:4 - Core idea (didactic)\n\n**Bind promises to runs with measurements in time.**\nAcceptance is a **quadruple of anchors** (all context‑local):\n\n1. **ClauseCell** — a deontic/Standardual **SenseCell** stating the promise (*availability ≥ 99.9%*, *MTTR ≤ 60 min*, *temperature within band*).\n2. **WorkCell** — a **SenseCell** for the **Work** that enacted the service in the relevant situation.\n3. **MeasureCell** — a **SenseCell** for the **Observation/Characteristic** used as evidence (KD‑CAL).\n4. **Window** — the explicit period in which the judgement is made (F.10).\n\nA **Predicate** compares the **Measure** against the **Clause** within the **Window**.\nThe **Status** (Satisfied/Violated/Inconclusive) attaches to **ClauseCell\\@Window about WorkCell**, never to a plan.\n\n",
        "minimal_vocabulary_(this_pattern_only)": "### F.12:5 - Minimal vocabulary (this pattern only)\n\n* **ClauseCell.** A context‑local deontic/Standardual concept (*SLO*, *obligation*, *target*), typically from *services/deontics* Contexts (e.g., **ITIL 4**, **ODRL**).\n* **WorkCell.** A context‑local run‑time occurrence (PROV **Activity**, IEC **Task Execution**, etc.).\n* **MeasureCell.** A context‑local observation concept (KD‑CAL **Observation** over a **Characteristic** with a **Scale/Unit**).\n* **Window.** A time envelope (calendar month, batch, incident interval, shift) per F.10.\n* **Predicate.** A clause‑shape: threshold, percentile, count‑within‑limit, band‑conformance, etc.\n* **Bridge.** An explicit Cross‑context relation with **kind/CL/Loss** (F.7/F.9).\n\n> **Context discipline.** Terms like *availability*, *activity*, *task*, *observation* are always read as **context‑local**. Cross‑use requires a **Bridge**.\n\n",
        "solution": "### F.11:6 - Solution — the quartet lens (notation‑free)\n\n> *Not steps for a team—**lenses for a thinker**. Use them to sanity‑check any statement about “how”, “script”, “run”, or “signal”.*\n\n#### F.11:6.1 - The **stance split** (design vs run)\n\n* If the claim is about **what should be done** or **how it is described**, you are on the **design stance** (Method/MethodDescription).\n* If the claim is about **what happened** or **what was emitted**, you are on the **run stance** (Work/Actuation).\n* **Guard rule.** Never let a conclusion cross stances without (a) an explicit Bridge kind (*interpretation* vs *substitution*), and (b) an acceptable CL (F.7/F.9, F.10).\n\n#### F.11:6.2 - The **recipe/idea split**\n\n* **Method** is the **idea**; **MethodDescription** is the **recipe** describing that idea.\n* Different recipes may describe the **same** method (profiles, languages, levels of detail); one recipe may encode **several** methods (composite SOP).\n* **Naming guard.** Keep labels distinct: *compressive‑strength test* (Method) vs *ASTM C39‑18* (MethodDescription).\n\n#### F.11:6.3 - The **happening** (Work) with **signal** (Actuation)\n\n* **Work** is the **occurrence** (a PROV *Activity*, an IEC *Task* executing a program, a lab run).\n* **Actuation** is the **control output** (setpoint, PWM command, valve open %) emitted **during** Work.\n* You can have Work **without** Actuation (analysis job), or Actuation **without** a complex Method (manual push). Many scenarios have **both**.\n\n#### F.11:6.4 - The **Role Assignment & Enactment touch-points**\n\n* **Roles** (F.4) bind **who enacts** the Method at run‑time (behavioural masks), **not** what permissions they hold (RBAC is a different Context).\n* **Statuses** (F.10) bind to the right box: *Approved* → MethodDescription; *Measured/Observed* → Work; *Satisfied/Violated* → Requirement clause about the Work’s outcomes within a **Window**.\n\n",
        "harmonisation_map_(context‑first)": "### F.11:7 - Harmonisation map (Context‑first)\n\n> Examples of **local SenseCells** and **safe Bridges**. *You may keep the exact Contexts from your F.1 cut.*\n\n**Design (ideas & recipes).**\n\n* *SPEM/ISO 24744 Context*: `SenseCell{Method}` = *Activity Definition / Task Definition*; `SenseCell{MethodDescription}` = *Process Description / WorkProduct* (as recipe).\n* *BPMN 2.0 Context*: `SenseCell{MethodDescription}` = *Process (diagram)* as **design‑time** recipe (do not confuse with run).\n* *OWL/Kind-CAL Context*: labels for Method kinds (type taxonomies) when needed (naming, not behaviour).\n\n**Run (occurrences & outputs).**\n\n* *PROV‑O Context*: `SenseCell{Work}` = *Activity* (time‑bounded occurrence).\n* *SOSA/SSN Context*: Observations **about** Work results (feeds EvidenceStatus).\n* *IEC 61131‑3 Context*: `SenseCell{Work}` = *Task executes Program* (runtime); `SenseCell{Actuation}` = *Output command / setpoint* emitted by the program.\n\n**Typical Bridges (with intent).**\n\n* `BPMN:Process (design)` **≈** `SPEM:Process Definition` (design↔design; CL depends on modelling profile; Loss: expressiveness gaps).\n* `IEC:Task execution` **⊑** `PROV:Activity` (run↔run; Loss: control‑specific timing semantics, scan cycles).\n* `Actuation (IEC)` **⋂** `Activity (PROV)` (intersection: the *sub‑intervals* where outputs are emitted).\n* `SOSA:Observation` **interprets** `Requirement clause` (F.10) about **Work outcomes** (**cross‑StatusModality: epistemic→deontic; never substitution**; declare **Bridge(kind=Interpretation, CL, Loss)**).\n\n",
        "invariants_(normative)": "### F.12:8 - Invariants (normative)\n\n1. **Design/run split.** Clauses live on the **design stance**; judgements live on the **run stance** about **Work** (F.11).\n2. **Context locality.** All terms are **context‑local**; Cross‑context meaning flows **only** across declared **Bridges**.\n3. **Observation‑only evidence.** Verdicts require **Observations** that **about‑refer** to Work outcomes; **Actuation** and **Approvals** are not sufficient.\n4. **Window explicitness.** Every verdict carries a **Window**; no timeless acceptance.\n5. **Predicate declared.** The Clause’s **Predicate** is explicit; no hidden aggregation or default percentile.\n6. **Non‑retroactivity.** Updating clauses or specs does not alter past verdicts; re‑evaluation must be explicit.\n7. **One‑Work focus.** A verdict references a **specific Work** (or a defined population of Works) matched to the Clause’s scope.\n8. **Loss honesty.** Each Bridge states **kind/CL/Loss**; stronger claims require stronger Bridges or same‑Context alignment.\n\n",
        "micro‑examples_(didactic,_cross‑architheory)": "### F.11:9 - Micro‑examples (didactic, cross‑architheory)\n\n1. **Data pipeline deploy (software).**\n   *Method*: “Delta‑load transform”. *MethodDescription*: `etl_delta.py@v3`. *Work*: nightly run 2025‑07‑14. *Actuation*: none.\n   *Statuses*: Spec **Approved** (governance Context); Work **Measured** (rows processed) → Evidence for SLO (F.10).\n\n2. **Valve control (industrial).**\n   *Method*: PID tuning heuristic. *MethodDescription*: SOP sheet + IEC program. *Work*: PLC task cycle 18:00–18:30. *Actuation*: PWM duty sequence.\n   *Bridge*: `IEC:Task` ⊑ `PROV:Activity` (CL=2). Observed setpoint tracking **interprets** requirement “settling time ≤ 5 s”.\n\n3. **Clinical assay (lab).**\n   *Method*: ELISA. *MethodDescription*: Kit IFU v7. *Work*: run batch #B217. *Actuation*: pipetting robot commands.\n   *Statuses*: Spec **Approved** ≠ batch **Satisfied** (requires evidence at batch Window).\n",
        "anti‑patterns_&_remedies": "### F.12:10 - Anti‑patterns & remedies\n\n| #       | Anti‑pattern                    | Symptom in practice                                                                          | Why it breaks thinking                          | Remedy (conceptual move)                                                                                                                                 |\n| ------- | ------------------------------- | -------------------------------------------------------------------------------------------- | ----------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **A1**  | **Plan‑as‑proof**               | A BPMN or runbook is cited as if it proved the SLO was met.                                  | Design artefacts are **not** occurrences.       | Apply **R1 locus** + **R2 evidence**: attach the verdict to **ClauseCell\\@Window about WorkCell** and require **Observations** of outcomes.              |\n| **A2**  | **Signal‑as‑outcome**           | Control **Actuation** (setpoint writes, approvals) treated as evidence of delivered service. | Commands are intentions, not results.           | Accept only **MeasureCell** that **about‑refer** to the **same Work**; if a control signal is used as proxy, declare a **Bridge(kind=proxy, CL, Loss)**. |\n| **A3**  | **Windowless verdict**          | “We met the SLA” with no stated period or scope.                                             | Unfalsifiable; mixes populations.               | Enforce **R5 Window**: every verdict names a **Window** (month, batch, incident interval).                                                               |\n| **A4**  | **Global words**                | *Availability*, *latency* used without a Context.                                               | Collides senses across disciplines.             | Speak with **Context prefixes** (F.1). Cross‑context reuse demands a **Bridge** (F.9).                                                                         |\n| **A5**  | **Percentile mirage**           | p95 computed on a pooled year while the clause is monthly.                                   | Predicate and Window misaligned.                | **R3 Predicate** + **R5 Window**: compute the statistic **per Clause’s Window**.                                                                         |\n| **A6**  | **Proxy blindness**             | Synthetic probes stand in for user experience with no limitations stated.                    | Proxies miss geography, jitter, or pathologies. | Declare **Bridge(kind=proxy, CL, Loss)**. If proxy coverage is too weak, the verdict is **Inconclusive**.                                                |\n| **A7**  | **Scope drift (Work mismatch)** | Measured another product’s or region’s traffic but judged the whole service.                 | Evidence is about the wrong **Work**.           | Tie **MeasureCell** to the **same WorkCell** (or a stated population‑of‑Works) as the Clause scopes.                                                     |\n| **A8**  | **Retroactive renorm**          | A new clause or recalibrated monitor silently rewrites past verdicts.                        | Violates temporal honesty.                      | Enforce **Non‑retroactivity** (Inv‑6): past verdicts stand; new rules apply forward.                                                                     |\n| **A9**  | **Silent units**                | “Latency ≤ 120” with no unit or scale.                                                       | Ambiguous thresholds.                           | **KD‑CAL discipline**: state **Characteristic, Scale, Unit** on **MeasureCell**.                                                                         |\n| **A10** | **Hidden aggregation**          | “Global availability” but only a subset of regions/slices was covered.                       | Over‑claims evidence.                           | State the **aggregation scope** explicitly or confine the verdict to the observed subset; otherwise **Inconclusive**.                                    |\n| **A11** | **Status on the service**       | Tagging the abstract service as “Satisfied”.                                                 | Loses the describedEntity of the judgement.           | Attach to **ClauseCell\\@Window about WorkCell**; the service concept remains a promise vocabulary (A.2.3).                                               |\n| **A12** | **Bridge‑by‑name**              | Equating *Activity* ≡ *Process* because both say “process”.                                  | Assumes global meaning.                         | Use **F.9 Bridge** with **kind/CL/Loss**; or keep them distinct.                                                                                         |\n\n",
        "worked_examples_(extended,_multi‑architheory)": "### F.11:11 - Worked examples (extended, multi‑architheory)\n\n> Each scenario names Contexts (from your F.1 cut), identifies the quartet boxes, and shows safe Cross‑context moves.\n\n#### F.11:11.1 - ML service rollout (software + services + sensing)\n\n* **Contexts:** *SPEM/ISO 24744* (design), *PROV‑O* (run), *SOSA/SSN* (sensing), *ITIL 4* (services).\n* **Quartet:**\n\n  * **Method:** *Canary deployment strategy*.\n  * **MethodDescription:** *Canary plan document with traffic slices and rollback rules* (design Context).\n  * **Work:** *Two canary runs 2025‑08‑02 10:00–12:00* (PROV‑Activities).\n  * **Actuation:** *Traffic‑shifting commands* (if modeled, they are outputs inside Work; optional in pure software).\n* **Statuses (F.10):** *Spec Approved*; *Work Observed* (latency/err‑rate via SOSA Observations); *SLO clause Satisfied* in Window if measured ≤ thresholds.\n* **Bridge(s):** *BPMN (if used) Process (design)* → *PROV Activity (run)* **Interpretation**, CL=2, **Loss:** path vs time granularity.\n\n**Pay‑off:** No one infers SLO satisfaction from a plan. Evidence is about **Work**; the plan stays design‑time.\n\n\n#### F.11:11.2 - Industrial furnace control (control + sensing + services)\n\n* **Contexts:** *State‑space control texts* (design), *IEC 61131‑3* (run), *PROV‑O* (run), *SOSA/SSN* (sensing), *ITIL 4* (services).\n* **Quartet:**\n\n  * **Method:** *PID with feed‑forward*.\n  * **MethodDescription:** *Controller tuning sheet + program description*.\n  * **Work:** *PLC task cycles 14:00–14:30* (IEC *Task executes Program*), **Bridged** as **PROV Activity**.\n  * **Actuation:** *Setpoint & valve duty cycle outputs* emitted during Work.\n* **Statuses:** *Spec Approved*; *Work Observed* (temperature curve); requirement *settling time ≤ 5 s* **Satisfied** if the observation within Window meets it.\n* **Bridge(s):** `IEC:Task` ⊑ `PROV:Activity` (CL=2, **Loss:** scan‑cycle semantics). `SOSA:Observation` **interprets** requirement clause (CL=3).\n\n**Pay‑off:** Separates **doing** from **pushing**, and both from **measuring**; compliance judged where it belongs.\n\n\n#### F.11:11.3 - Clinical assay\n\n* **Contexts:** *SPEM/ISO 24744* (design), *Lab assay canon* (design/run split as per discipline), *PROV‑O* (run), *SOSA/SSN* (sensing).\n* **Quartet:**\n\n  * **Method:** *ELISA*.\n  * **MethodDescription:** *Kit IFU v7 (instructions for use)*.\n  * **Work:** *Batch B217 performed 2025‑06‑21* (PROV Activity).\n  * **Actuation:** *Pipetting robot commands* (optional detail).\n* **Statuses:** *Spec Approved*; *Work Observed* (absorbance readings); *Quality gate Satisfied* within batch Window.\n* **Bridge(s):** IFU (design) **interprets** Activity (run) for acceptance (CL=2, **Loss:** deviations allowed per kit tolerances).\n\n**Pay‑off:** A clean line from recipe → run → measurement → decision, without role/status conflation.\n\n\n#### F.11:11.4 Incident response (services + enactment)\n\n* **Contexts:** *ITIL 4* (services/design), *BPMN 2.0* (design), *PROV‑O* (run).\n* **Quartet:**\n\n  * **Method:** *Triage‑first incident handling*.\n  * **MethodDescription:** *Incident workflow diagram + playbook*.\n  * **Work:** *Handling INC‑3421, 09:10–10:02* (PROV Activity).\n  * **Actuation:** none (unless modeling command invocations as outputs).\n* **Statuses:** *Spec Approved*; *Work Observed* (timestamps, response time); *SLO “MTTR ≤ 60 min”* **Satisfied** within the incident Window.\n* **Bridge(s):** BPMN (design) → PROV (run) **Interpretation**, CL=2, **Loss:** gateways vs real‑time branching.\n\n**Pay‑off:** MTTR claims are tied to **Work**, not to the playbook.\n\n",
        "reasoning_primitives_(judgement_schemas)": "### F.11:12 - Reasoning primitives (judgement schemas)\n\n> Pure **mental moves**; no storage or workflow is implied.\n\n1. **Box classifier**\n   `statement s, Contexts fixed ⊢ box(s) ∈ {Method, MethodDescription, Work, Actuation}`\n   *Reading:* Classify any claim by its **box** (design idea, design recipe, run occurrence, control output).\n\n2. **Stance firewall**\n   `box(s) ∈ {Method,MethodDescription} ⊢ s ∉ {claims about Work outcomes}`\n   *Reading:* A design‑time (stance) statement does **not** assert a run‑time (stance) outcome.\n\n3. **Followed‑recipe judgement**\n   `Work w, MethodDescription m ⊢ follows(w,m) ∈ {exact, variant, none}`\n   *Reading:* A Work may follow a recipe **exactly**, with a **variant**, or **not at all**; later inferences must respect this value.\n\n4. **Enactment link**\n   `Work w, Method h ⊢ enacts(w,h)`\n   *Reading:* The occurrence enacts the abstract Method (even if several specs describe it).\n\n5. **Actuation inclusion**\n   `Actuation a, Work w ⊢ occursWithin(a,w)`\n   *Reading:* Control outputs are **within** (or are parts of) a Work interval.\n\n6. **Observation binding** (KD‑CAL handshake)\n   `Observation o about outcome(x) during Window W of Work w ⊢ evidenceFor(w, clause(x,W))`\n   *Reading:* Measurements about a Work outcome within a Window serve as evidence for clauses **about that Work**.\n\n7. **Clause evaluation** (F.10 handshake)\n   `evidenceFor(w,clause) ⊢ status(clause,w) ∈ {Satisfied, Violated, Inconclusive}`\n   *Reading:* A clause about Work yields a status via the observation set.\n\n8. **Context locality**\n   `term t, Context C ⊢ meaning(t)@C is local`\n   *Reading:* A term’s sense is **local** to its Context; Cross‑context claims require Bridges.\n\n9. **Bridge application** (F.7/F.9)\n   `Bridge B: (X@A) ~kind,CL,Loss~ (Y@B); fact about X ⊢ transferableTo(Y) with penalty(CL,Loss)`\n   *Reading:* Facts may transfer across Contexts only along a declared Bridge, with the stated penalty.\n\n10. **Version non‑retroactivity**\n    `MethodDescription m updated → m' ⊢ ∀ past Work w: follows(w,m')=none (unless w references m')`\n    *Reading:* New recipes don’t rewrite history.\n\n11. **Composite reasoning**\n    `MethodDescription m = m1 ; m2, Work w executes steps w1,w2 ⊢ enacts(w1,m1) ∧ enacts(w2,m2)`\n    *Reading:* Composition on design does not force composition on run, but when it aligns you may relate sub‑runs to sub‑methods.\n\n12. **SLO locus guard**\n    `SLO clause about service outcome ⊢ attachesTo(Work-window), not MethodDescription`\n    *Reading:* Service obligations concern **what happened** within a Window, not the existence of a plan.\n\n",
        "relations": "### F.12:13 - Relations (with other patterns)\n\n* **Builds on:**\n  **F.1** (Contexts): keeps all meanings **local**.\n  **F.2–F.3**: provide the **SenseCells** that become Clause/Work/Measure anchors.\n  **F.5**: ensures labels for Clause/Work/Measure and Windows are didactically clear.\n  **F.7–F.9**: supply **Bridge** kinds / **CL** and loss semantics.\n  **F.10**: defines **Status** families and **Window** constructs.\n  **F.11**: protects **Method / MethodDescription / Work / Actuation** distinctions.\n\n* **Uses (Part C architheories).**\n  **KD‑CAL** (Observation/Characteristic/Scale/Unit).\n  **Sys‑CAL** (Work/Actuation Contexts).\n  **Kind-CAL** (type labels for populations or cohort selection).\n\n* **Constrains:**\n  Later reporting and assurance rules (B.3) must **not** collapse CL/Loss; they report them alongside status.\n\n",
        "migration_notes_(conceptual)": "### F.12:14 - Migration notes (conceptual)\n\n1. **Clause revisions.** Introduce a **new ClauseCell**; keep old verdicts intact (Non‑retroactivity).\n2. **Monitor changes.** Update or replace **Bridges** (kind/CL/Loss). Future verdicts use the new Bridge; past ones are annotated, not rewritten.\n3. **Scope corrections.** If evidence was about the wrong **Work**, retire the verdict and restate the quadruple; do **not** patch by redefining the Clause.\n4. **Unit harmonisation.** When scales/units change, apply **KD‑CAL** conversions inside the Measure’s Context; if Cross‑context mapping is needed, declare a **Bridge**.\n5. **Population refinement.** If a Clause’s quantifier is refined (e.g., per‑region → per‑AZ), treat each as a new ClauseCell or a new Window partition; avoid hidden re‑baselining.\n6. **Proxy retirement.** When direct Observations become available, prefer them; keep earlier proxy‑based verdicts with their CL/Loss notes.\n\n",
        "acceptance_tests_(scr/rscr_—_concept_level)": "### F.11:15 - Acceptance tests (SCR/RSCR — concept level)\n\n#### F.11:15.1 - Static conformance checks (SCR)\n\n* **SCR‑F11‑S01 (DesignRunTag honesty).** Every normative claim about outcomes is attached to **Work** (with Window), not to **Method/MethodDescription**.\n* **SCR‑F11‑S02 (Box placement).** Labels and statuses appear on the correct box (e.g., *Approved* on MethodDescription only).\n* **SCR‑F11‑S03 (Actuation inclusion).** All Actuation statements are modeled as **within** a Work interval.\n* **SCR‑F11‑S04 (Context discipline).** Each quartet term is expressed as a **SenseCell** with its Context; no Cross‑context identity is asserted here.\n* **SCR‑F11‑S05 (Bridge guard).** Any Cross‑context reasoning among quartet terms references an explicit **Bridge** with **kind/CL/Loss**.\n\n#### F.11:15.2 - Regression checks (RSCR)\n\n* **RSCR‑F11‑E01 (Spec update).** When a MethodDescription changes, previous Works remain valid and unchanged; their statuses don’t shift unless re‑evaluated with explicit rationale.\n* **RSCR‑F11‑E02 (Bridge drift).** If a Context updates, revisit Bridges that touch quartet terms; adjust **CL/Loss** only via F.7/F.9.\n* **RSCR‑F11‑E03 (Status drift).** Adding new statuses does not move them across boxes (e.g., no new “Work‑Approved”).\n* **RSCR‑F11‑E04 (Signal creep).** Introducing new Actuation details does not erase or replace Work context.\n\n",
        "didactic_distillation_(90‑second_script)": "### F.11:16 - Didactic distillation (90‑second script)\n\n> “When you talk about *how something is done*, decide which of the **four boxes** you mean.\n> **Method** is the **idea** (the way). **MethodDescription** is the **recipe** (the description). **Work** is the **happening** (what actually occurred). **Actuation** is the **control push** (signals emitted during Work).\n> Keep **design** and **run** as distinct **stances**. Plans and approvals live in the **design stance**; measurements and obligations live in the **run stance** within **Windows**.\n> Words like *process*, *task*, *activity*, *command* are **context‑local**—say *process (BPMN)*, *activity (PROV)*, *task (IEC)*. If you must relate them, draw a **Bridge** and declare its **kind**, **CL**, and **Loss**.\n> For compliance, don’t point at the plan—point at **Work**, show **Observations**, and judge clauses in **F.10**.\n> Hold this quartet in your head and you’ll stop mixing plans with facts, signals with outcomes, and names across Contexts. + Everything else—naming (F.5), `U.RoleDescription` (F.4) and `U.RoleAssignment`/`U.RoleEnactment` (A.2.1/F.6), Bridges (F.7/F.9)—falls into place.\n",
        "f.11:end": "### F.11:End\n\n## F.12 — Service Acceptance–Work Evidence Link\n\n**“Judge promises on what happened, not on what was planned.”**\n**Status.** Architectural pattern, architheory‑agnostic.\n**Builds on:** F.1 **context of meaning (U.BoundedContext)**; F.2 **Term Harvesting**; F.3 **Intra‑Context Sense Clustering**; F.5 **Naming Discipline**; F.7/F.9 **Bridges & CL**; F.10 **Status Families & Windows**; F.11 **Method Quartet Harmonisation**; A.2.3 **U.ServiceClause**.\n**Coordinates with.** KD‑CAL (Observation/Characteristic/Scale); Sys‑CAL (Work/Actuation contexts).\n**Non‑goals.** No team workflows, no tooling, no editorial procedures. This pattern specifies **how to think** about acceptance, not how to store or operate systems.\n\n",
        "the_binding,_as_five_mental_rules_(notation‑free)": "### F.12:6 - The binding, as five mental rules (notation‑free)\n\n**R1 — Locus rule.**\nA service verdict **attaches to the Clause**, scoped by a **Window**, **about a specific Work**:\n`status(ClauseCell, WorkCell, Window) ∈ {Satisfied, Violated, Inconclusive}`.\n*Reading:* We do not place “Satisfied” on the plan or on the whole service concept.\n\n**R2 — Evidence rule.**\nOnly **Observations** (MeasureCell) that **refer to the outcome of the same Work** and **lie within the Window** may support the verdict.\n*Reading:* Control commands and approvals are not evidence of outcome.\n\n**R3 — Predicate rule.**\nEvery ClauseCell is read with a **Predicate** schema that defines how Measures decide:\n\n* **Threshold:** `value ≥/≤ target`.\n* **Percentile:** `Pₚ(value) ≤ target`.\n* **Ratio/Share:** `good_time / total_time ≥ target`.\n* **Count‑within‑limit:** `count(events of type E) ≤ target`.\n* **Band:** `min(value) ≥ L ∧ max(value) ≤ U`.\n\n**R4 — Bridge rule.**\nIf Clause, Work, and Measure live in **different Contexts**, apply declared **Bridges** with **kind**, **CL**, and **Loss** notes.\n*Reading:* Without a Bridge, do not presume transferability of meanings.\n\n**R5 — Window rule.**\nEvery verdict is **time‑bounded**. Changing the Window can change the result; **no retroactivity** from new clauses or specs (cf. F.10).\n\n",
        "clause_templates_(conceptual_schemata)": "### F.12:7 - Clause templates (conceptual schemata)\n\n> These are **shapes of meaning**, not data fields.\n\n1. **Availability (share‑of‑time)**\n\n* **ClauseCell:** *service availability ≥ 99.9% monthly* (services Context).\n* **MeasureCell:** *uptime indicator* over **Work** (KD‑CAL).\n* **Predicate:** `good_time/total_time ≥ 0.999`.\n* **Window:** calendar month.\n* **Bridge:** from monitor semantics → consumer‑perceived availability (**kind:** proxy; **CL:** 2; **Loss:** blind to partial degradations).\n\n2. **Latency (percentile)**\n\n* **ClauseCell:** *p95 latency ≤ 120 ms during incidents* (services Context).\n* **MeasureCell:** *response time observation* for the same **Work episode** (KD‑CAL).\n* **Predicate:** `P95(latency) ≤ 120ms`.\n* **Window:** incident interval.\n* **Bridge:** from request‑level telemetry → service‑level promise (**kind:** aggregation; **CL:** 2; **Loss:** sampling bias).\n\n3. **Safety margin (band)**\n\n* **ClauseCell:** *temperature ∈ \\[L,U] during batch* (deontics/quality Context).\n* **MeasureCell:** *process temperature observation* (KD‑CAL).\n* **Predicate:** `min ≥ L ∧ max ≤ U`.\n* **Window:** batch run interval (Work).\n* **Bridge:** not needed if Measure and Clause are in the same Context; otherwise declare.\n\n4. **MTTR (count‑within‑limit + duration)**\n\n* **ClauseCell:** *MTTR ≤ 60 min per incident*.\n* **MeasureCell:** *timestamps of Work phases* (start fix → restore).\n* **Predicate:** `restore_time − start_fix ≤ 60 min`.\n* **Window:** each incident’s **Work** interval.\n* **Bridge:** BPMN design steps → PROV Work **Interpretation** (CL=2; **Loss:** gateways ≠ real branching).\n\n",
        "micro‑examples_(didactic,_multi‑domain)": "### F.12:9 - Micro‑examples (didactic, multi‑domain)\n\n#### F.12:9.1 - SaaS uptime (services + sensing)\n\n* **Contexts:** *ITIL 4* (Clause), *PROV‑O* (Work), *SOSA/SSN* (Measure).\n* **ClauseCell:** *availability ≥ 99.9% monthly*.\n* **WorkCell:** *service provision* Activities during June.\n* **MeasureCell:** *uptime observation* from synthetic probes.\n* **Predicate:** share‑of‑time ≥ 0.999.\n* **Bridge:** probe result → user availability (**kind:** proxy; **CL:** 2; **Loss:** regional gaps).\n* **Verdict:** *Satisfied (June)* if the ratio holds; **attaches to Clause\\@June about those Works**.\n\n#### F.12:9.2 - Furnace band (industrial control)\n\n* **Contexts:** *quality/deontics canon* (Clause), *IEC 61131‑3/PROV* (Work), *KD‑CAL* (Measure).\n* **ClauseCell:** *product temperature within \\[720,740] °C during soak*.\n* **WorkCell:** *soak phase* Work interval.\n* **MeasureCell:** thermocouple Observations (KD‑CAL).\n* **Predicate:** band conformance.\n* **Bridge:** IEC task interval → PROV Activity (**Interpretation**, CL=2).\n* **Verdict:** *Violated* if any measured value exits the band.\n\n#### F.12:9.3 - Incident MTTR (services + enactment)\n\n* **Contexts:** *ITIL 4* (Clause), *PROV‑O* (Work).\n* **ClauseCell:** *MTTR ≤ 60 min per incident*.\n* **WorkCell:** each incident’s handling Activity.\n* **MeasureCell:** timestamps (Observed facts) of start‑fix and restore events.\n* **Predicate:** duration ≤ 60 min.\n* **Bridge:** BPMN steps → PROV Activity (**Interpretation**, CL=2).\n* **Verdict:** *Satisfied* if the measured interval meets the target.\n",
        "extended_worked_examples_(multi‑architheory)": "### F.12:11 - Extended worked examples (multi‑architheory)\n\n> Each example identifies **Contexts**, the **quadruple** ⟨ClauseCell, WorkCell, MeasureCell, Window⟩, any **Bridge(s)**, and the **Predicate**. The verdict attaches to *ClauseCell\\@Window about WorkCell*.\n\n#### F.12:11.1 - CDN latency across regions (services + sensing + types)\n\n* **Contexts.** *ITIL 4* (Clause), *PROV‑O* (Work), *SOSA/SSN* (Measure), *OWL 2* (type labels).\n* **ClauseCell.** *p95 end‑user latency ≤ 200 ms per region per month*.\n* **WorkCell.** *delivery Activities* per region during the month (PROV).\n* **MeasureCell.** *response‑time Observations* tagged by region and path (SOSA/SSN).\n* **Predicate.** For each region in the Window, `P95(latency) ≤ 200 ms`.\n* **Bridges.** *probe→user* (**kind**: proxy; **CL** 2; **Loss**: last‑mile bias).\n* **Verdict.** Region‑wise statuses; a global “all‑regions met” is the **logical AND** of region statuses (declare this aggregation explicitly).\n* **Manager cue.** “Green map ≠ one green verdict”; acceptance is **per Clause per Window per Work population**.\n\n#### F.12:11.2 - Stroke care: door‑to‑needle (method + enactment + status)\n\n* **Contexts.** *clinical guideline canon* (Clause), *PROV‑O* (Work), *SOSA/SSN* (Measure), *F.10* (status windows).\n* **ClauseCell.** *90% of ischemic‑stroke episodes achieve door‑to‑needle ≤ 30 min per quarter*.\n* **WorkCell.** Population of **patient‑episode Activities** started in the quarter.\n* **MeasureCell.** Timestamps **Observation** of *door* and *needle* events (KD‑CAL).\n* **Predicate.** `|{episodes with (needle−door ≤ 30)}| / |{episodes}| ≥ 0.9`.\n* **Bridges.** *EHR event semantics → PROV Activity* (**Interpretation**, **CL** 2; **Loss**: missing triage tags).\n* **Verdict.** If data gaps exceed a declared tolerance, status is **Inconclusive** rather than “Satisfied by assumption”.\n\n#### F.12:11.3 - Cold‑chain warehouse (control + sensing + deontics)\n\n* **Contexts.** *quality/deontics canon* (Clause), *IEC 61131‑3/PROV* (Work), *SOSA/SSN + ISO 80000‑1* (Measure).\n* **ClauseCell.** *temperature ∈ \\[2,8] °C for ≥ 99.5% of each day*.\n* **WorkCell.** The warehouse’s **daily storage Activity**.\n* **MeasureCell.** Thermistor **Observations** with calibrated units (KD‑CAL/ISO 80000‑1).\n* **Predicate.** `(good_time / 24h) ≥ 0.995`.\n* **Bridges.** *sensor position → product exposure* (**kind**: proxy; **CL** 2; **Loss**: stratification).\n* **Verdict.** *Violated* if any day fails; annotate **Loss** to communicate assurance limits.\n\n#### F.12:11.4 - SaaS incident MTTR (services + enactment)\n\n* **Contexts.** *ITIL 4* (Clause), *PROV‑O* (Work).\n* **ClauseCell.** *MTTR ≤ 60 min per incident*.\n* **WorkCell.** Each incident’s handling **Activity**.\n* **MeasureCell.** **Observations** of start‑fix and restore timestamps.\n* **Predicate.** `(restore − start_fix) ≤ 60 min`.\n* **Verdict.** Per incident; a quarter’s report is an explicit aggregation of incident‑scoped verdicts.\n\n",
        "reasoning_primitives_(judgement_schemas,_notation‑free)": "### F.12:12 - Reasoning primitives (judgement schemas, notation‑free)\n\n> These are **mental inferences**; they neither read nor write artefacts. Each reads “if these thoughts hold, you may safely conclude …”.\n\n1. **Clause–Work match**\n   `covers(ClauseCell, WorkCell) ⊢ admissible(ClauseCell, WorkCell)`\n   *Reading:* The Clause speaks **about** the kind of Work under judgement (scope alignment).\n\n2. **Window adequacy**\n   `Window is explicit ∧ Window intersects WorkCell-occurrence ⊢ admissible(Window)`\n   *Reading:* There is a concrete time envelope; the Work actually occurred within it.\n\n3. **Evidence sufficiency**\n   `Observations E about WorkCell within Window ⊢ sufficient(E)`\n   *Reading:* There exists a non‑empty set of outcome **Observations** relevant to the Work and Window.\n\n4. **Evidence insufficiency → Inconclusive**\n   `¬sufficient(E) ⊢ status = Inconclusive(ClauseCell, WorkCell, Window)`\n   *Reading:* Absent admissible evidence, do not guess; mark **Inconclusive**.\n\n5. **Predicate evaluation**\n   `sufficient(E) ∧ eval(Predicate, E) = true ⊢ status = Satisfied(ClauseCell, WorkCell, Window)`\n   `sufficient(E) ∧ eval(Predicate, E) = false ⊢ status = Violated(ClauseCell, WorkCell, Window)`\n   *Reading:* The **Predicate** (threshold/percentile/share/band/…) decides directly from E.\n\n6. **Bridge discipline**\n   `usesCrossContexts(ClauseCell, WorkCell, MeasureCell) ∧ Bridges B declared ⊢ admissible(B)`\n   `usesCrossContexts … ∧ ¬admissible(B) ⊢ status = Inconclusive`\n   *Reading:* Cross‑context comparisons require explicit **Bridges**; without them, **Inconclusive**.\n\n7. **CL aggregation (assurance hint)**\n   `Bridges B = {b₁…bₖ} ⊢ effectiveCL = min(CL(bᵢ))`\n   *Reading:* The weakest Bridge governs the assurance level communicated with the verdict (advisory to B.3 calculus).\n\n8. **Population clauses**\n   `Clause quantifies over population W = {w₁…wₙ} ⊢ status = agg({status(Clause, wᵢ, Window)})`\n   *Reading:* For “≥ p%”‑style clauses, compute per‑Work verdicts, then apply the Clause’s quantifier.\n\n9. **Non‑retroactivity**\n   `newClause or newMonitor after Window ⊢ doesNotAlter(status@Window)`\n   *Reading:* Later changes do not rewrite past verdicts.\n\n10. **Conflict exposure**\n    `two admissible Bridge sets ⇒ conflicting statuses ⊢ escalate as Inconclusive, expose Loss notes`\n    *Reading:* If equally defensible translations disagree, the honest outcome is **Inconclusive** plus an explanation.\n\n",
        "acceptance_tests_(scr/rscr_—_concept‑level)": "### F.12:15 - Acceptance tests (SCR/RSCR — concept‑level)\n\n#### F.12:15.1 - Static conformance (SCR)\n\n* **SCR‑F12‑S01 (Quadruple present).** Every acceptance statement names **ClauseCell**, **WorkCell**, **MeasureCell**, and **Window**.\n* **SCR‑F12‑S02 (context‑locality).** Each of the three Cells cites a **Context** (U.BoundedContext).\n* **SCR‑F12‑S03 (Evidence admissibility).** The **Observation(s)** are **about** the **same Work** and lie within the **Window**.\n* **SCR‑F12‑S04 (Predicate explicit).** The **Predicate** shape is stated (threshold/percentile/share/band/…) with any needed aggregation scope.\n* **SCR‑F12‑S05 (Bridge discipline).** Any Cross‑context use declares **Bridge(kind, CL, Loss)**.\n* **SCR‑F12‑S06 (Status trichotomy).** The verdict is exactly one of **{Satisfied, Violated, Inconclusive}** and attaches to **ClauseCell\\@Window about WorkCell**.\n* **SCR‑F12‑S07 (Unit honesty).** MeasureCell specifies **Characteristic, Scale, Unit** (KD‑CAL).\n* **SCR‑F12‑S08 (Temporal honesty).** No verdict is asserted without a **Window**; no clause retroactively changes past verdicts.\n\n#### F.12:15.2 - Regression checks (RSCR)\n\n* **RSCR‑F12‑E01 (Bridge update).** When a **Bridge CL** changes, past verdicts stand; future verdicts **reference the new CL**; reports surface the difference.\n* **RSCR‑F12‑E02 (Edition churn).** When a Context’s canon updates, Cells reference the **edition**; old verdicts remain bound to their original editions.\n* **RSCR‑F12‑E03 (Scope drift guard).** If the Work population definition changes, verdicts are not silently re‑interpreted; new verdicts cite the new population.\n* **RSCR‑F12‑E04 (Window partition).** Changing from monthly to weekly windows creates **new** verdicts; monthly summaries are expressed as explicit aggregations of weekly statuses.\n* **RSCR‑F12‑E05 (Proxy retirement).** When direct Observations replace proxies, the status computation is re‑run **forward‑only**; past proxy‑based verdicts retain their CL/Loss annotations.\n\n\n#### F.12:15.3 Didactic distillation (60‑second recap)\n\n> **Bind promises to runs with measurements in time.**\n> Name the **Clause**, the **Work** it talks about, the **Measure** of what actually happened, and the **Window**. Evaluate the Clause’s **Predicate** on Observations **about that Work in that Window**. If any concept crosses Contexts, declare a **Bridge** with **kind/CL/Loss**. The verdict (**Satisfied/Violated/Inconclusive**) attaches to **Clause\\@Window about Work**, never to a plan or to the abstract service.\n",
        "f.12:end": "### F.12:End\n"
      },
      "content": "### F.12:End\n",
      "metadata": {},
      "part": "F",
      "cluster": null
    },
    {
      "id": "F.13",
      "title": "Lexical Continuity & Deprecation",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## F.13 - Lexical Continuity & Deprecation\n\n**“Change names without changing history.”**\n**Status.** Architectural pattern, architheory‑agnostic.\n**Builds on:** F.1 **context of meaning**; F.2 **Term Harvesting**; F.3 **Intra‑Context Clustering (SenseCell)**; F.5 **Naming Discipline**; F.7 **Concept‑Set (row) construction**; F.8 **Mint‑or‑Reuse decision**; F.9 **Bridges**; F.10 **Status windows**.\n**Coordinates with.** Part C CALs when canon editions change (Sys/KD/Type/Method/LCA).\n**Non‑goals.** No registries, workflows, editors, or storage formats. No by‑name Cross‑context equivalence. No silent rewrites of old texts.\n\n",
        "intent_&_applicability": "### F.13:1 - Intent & applicability\n\n**Intent.** Provide a **conceptual discipline** for evolving labels (for **SenseCells**, **Concept‑Set rows**, and **Role Description names**) so that:\n\n* new names **clarify** without erasing what earlier texts meant;\n* aliases remain **local to Contexts**;\n* genuine sense changes cause **explicit splits/merges** (F.7/F.9), not cosmetic renames.\n\n**Applicability.** Whenever you consider **renaming**, **aliasing**, **deprecating**, or **retiring** any label in FPF: a SenseCell label in a Context, a Concept‑Set row label, or a Role Description name.\n\n",
        "problem": "### F.13:2 - Problem frame\n\nUnification efforts rot when names drift faster than senses or, worse, when senses change under a constant name.\n\n* **Silent relabeling.** A new label is introduced as if nothing changed; readers cannot connect past to present.\n* **Alias bloat.** Synonyms accumulate without discipline; reading becomes guesswork.\n* **Cross‑context aliasing.** A single alias is made to stand for different Contexts (“global slang”), defeating locality.\n* **Retroactive edits.** Old texts are silently rewritten to today’s names, corrupting provenance.\n\n",
        "forces": "### F.13:3 - Forces\n\n| Force                          | Tension to resolve                                                                           |\n| ------------------------------ | -------------------------------------------------------------------------------------------- |\n| **Continuity vs truthfulness** | Preserve readers’ continuity yet surface real sense changes (no paint‑over).                 |\n| **Locality vs convenience**    | Keep aliases **inside Contexts** even when a catchy global name tempts reuse.                   |\n| **Simplicity vs coverage**     | Avoid giant synonym lists while still catching the one or two legacy names people will meet. |\n| **Didactics vs formality**     | Make the mapping teachable without inventing new low‑level artefacts or processes.           |\n\n",
        "core_idea_(didactic)": "### F.13:4 - Core idea (didactic)\n\n**Treat names as lenses, not objects.**\nThe **thing that persists** is the *sense* (a **SenseCell** inside a Context, or the *Cross‑context alignment* embodied by a **Concept‑Set row**, or a **Role Description** that points to such sense). Names are **lenses** we look through. When the lens improves, we **record a continuity relation** between lenses; when the underlying sense changes, we **split/merge the thing**, then name accordingly.\n\n> **Contexts keep names local.**\n> A label (including aliases) always belongs to **one context** or to **one Concept‑Set row**. Cross‑context similarity is handled by **Bridges** (F.9), never by shared names.\n\n",
        "minimal_vocabulary_(this_pattern_only)": "### F.13:5 - Minimal vocabulary (this pattern only)\n\n* **Legacy label** — a previously used label in the same Context (or same Concept‑Set row / Role Description).\n* **Preferred label** — the current **F.5‑conformant** label for that item.\n* **Alias** *(context‑local)* — a **read‑path** from a legacy label to the preferred one **inside the same Context** (or the same row/template). For writing, prefer the current label.\n* **Continuity relation** — a small set of **relations over labels** (below) that capture whether a change is *just wording* or a *real sense change*.\n* **Epoch note** — an **informative** time marker (“used before 2024‑07”) attached to a legacy label to help readers of old texts. (No storage format implied.)\n\n",
        "solution": "### F.13:6 - Solution — Continuity, not “registries”\n\nRather than maintain a tool or workflow, **think with five continuity relations**. Use the *least strong* relation that tells the truth.\n\n#### F.13:6.1 - Continuity relations (normative meanings)\n\n1. **`renames(label_old → label_new)`** — *wording improved, sense unchanged*.\n   *Use when:* Same **SenseCell** / same **Concept‑Set row** / same **Role Description**; only the surface form changed to satisfy F.5 (morphology, disambiguation, plain/tech harmony).\n   *Effect:* `label_old` becomes a **context‑local alias** of `label_new`; both resolve to the **same thing**. Past texts remain valid.\n\n2. **`aliases(label_legacy ↔ label_pref)`** — *legacy synonym kept for reading*.\n   *Use when:* A common historical synonym exists **in the same Context** for the **same SenseCell**.\n   *Effect:* Two‑way **read‑path** only; **writing uses `label_pref`**. Keep at most **one** legacy alias per register to avoid bloat.\n\n3. **`splits(label_old ⇒ {label_A, label_B})`** — *one label covered multiple senses; now separated*.\n   *Use when:* Your **SenseCell** was really two local senses; F.3 has **split** them; or a **Concept‑Set row** is refactored into two rows.\n   *Effect:* `label_old` is **deprecated** (read‑path allowed to a **disambiguation note**); new writing uses `label_A`/`label_B`. No claim that either *continues* the old label wholesale.\n\n4. **`merges({label_A, label_B} ⇒ label_new)`** — *two labels now recognized as one sense*.\n   *Use when:* F.3 shows **same SenseCell**; or two Concept‑Set rows collapse after F.9 raised CL sufficiently.\n   *Effect:* `label_A` and `label_B` become **aliases** of `label_new`. Keep one **epoch note** on each legacy label.\n\n5. **`retires(label_old)`** — *name withdrawn without successor*.\n   *Use when:* The label proved misleading and **no single successor** exists (e.g., it spanned different Contexts, or it was metaphorical).\n   *Effect:* Only a **read‑warning** remains (“avoid in new writing; see Contexts X/Y”). Readers are pointed to **Bridges** or to multiple rows.\n\n> **Important:** All five relations are **context‑local** (SenseCell level) or **row‑local** (Concept‑Set). **Never** use them to “alias” across Contexts. If a change crosses Contexts, it is not a rename; it requires a **Bridge** (F.9) and often a **split/merge of rows** (F.7).\n\n",
        "invariants_(normative)": "### F.13:7 - Invariants (normative)\n\n1. **Locality of alias.** `aliases(-)` and `renames(-)` operate **within one context** (SenseCell) or **within one Concept‑Set row / Role Description**.\n2. **Truth over comfort.** If the **sense changed**, use `splits`/`merges` (and possibly adjust rows/Bridges), **not** `renames`.\n3. **Non‑retroactivity.** Past texts remain phrased as written; continuity only **adds read‑paths**, never rewrites.\n4. **Alias parsimony.** per Context and per row, keep **≤ 1** legacy alias per register (Tech/Plain); prefer the one readers will most likely encounter.\n5. **Prefer present for writing.** In normative writing, use the **current preferred label** (F.5). Aliases are for **reading comprehension**.\n6. **Bridge discipline.** If a label shift would require crossing Contexts to “explain”, it is **not a rename**; use **F.9 Bridge** and, if needed, refactor the **Concept‑Set row(s)**.\n7. **Epoch honesty.** When declaring continuity, attach a **succinct epoch note** (“pre‑2023 usage”) if it aids readers.\n\n",
        "self‑checks_(mental,_not_procedural)": "### F.13:8 - Self‑checks (mental, not procedural)\n\n* **Same‑sense test.** Can you point to the **same SenseCell** (or same row) before and after? If yes → `renames`/`aliases`. If no → `splits`/`merges`.\n* **Context test.** Does the change stay **inside one context**? If it needs two Contexts to explain, it’s a **Bridge**, not a rename.\n* **Reader test.** What two legacy strings would a newcomer actually meet in old texts? Keep **those two** as aliases; drop the rest.\n* **History test.** Does your “continuity” require editing old claims? If yes, you’re attempting a **retroactive rewrite**—stop.\n* **Didactic test.** Can you explain the continuity relation in **one sentence**? If not, you are hiding a sense change.\n\n",
        "micro‑examples_(illustrative)": "### F.13:9 - Micro‑examples (illustrative)\n\n#### F.13:9.1 - Pure rename inside a Context (ITIL → clearer plain label)\n\n*Context:* **ITIL 4 (services)**.\nOld: **“SLO” (plain: *service target*)** → New: **“service‑level objective” (plain unchanged)**.\n**Relation:** `renames(\"SLO\" → \"service‑level objective\")`.\n**Why:** F.5 morphology & expansion; SenseCell unchanged (same clause semantics).\n**Effect:** Old guidance remains readable; new writing spells out the term.\n\n#### F.13:9.2 - Alias for a common legacy synonym (Sys‑CAL)\n\n*Context:* **state‑space control (design)**.\nPreferred: **“actuation”**. Legacy: **“control output”**.\n**Relation:** `aliases(\"control output\" ↔ \"actuation\")`.\n**Why:** Same SenseCell; legacy term appears in older textbooks.\n**Effect:** Readers resolve to the SenseCell; new texts use “actuation”.\n\n#### F.13:9.3 - Split of a muddled local sense (Enactment)\n\n*Context:* **BPMN 2.0**.\nLegacy label **“process”** was used to mean both **“collaboration”** and **“executable process”** in a team’s prose.\n**Relation:** `splits(\"process\" ⇒ {\"collaboration\",\"executable‑process\"})`.\n**Effect:** The single Concept‑Set row becomes two; old label is deprecated with a disambiguation note.\n\n#### F.13:9.4 - Merge after clustering raised confidence (Kind-CAL row)\n\nTwo Concept‑Set rows **{“DBaaS”, “Database‑Service”}** converge after F.3 within the same context profile and F.9 raised CL.\n**Relation:** `merges({\"DBaaS\",\"Database‑Service\"} ⇒ \"Database‑Service\")`.\n**Effect:** “DBaaS” becomes a legacy alias with an epoch note.\n\n#### F.13:9.5 - Not a rename: Cross‑context temptation (forbidden)\n\n*Contexts:* **BPMN (design graph)** vs **PROV‑O (run activity)**.\nTemptation: “Let’s rename *process* to *activity*.”\n**Diagnosis:** Cross‑context; **different SenseCells**.\n**Action:** **No continuity relation.** Keep labels; if needed, declare a **Bridge** (F.9) explaining design→run mapping with CL/Loss.\n",
        "anti‑patterns_&_remedies": "### F.13:10 - Anti‑patterns & remedies\n\n| #       | Anti‑pattern               | Symptom in texts                                                      | Why it harms thinking                                          | Remedy (conceptual move)                                                                                                         |\n| ------- | -------------------------- | --------------------------------------------------------------------- | -------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------- |\n| **A1**  | **Cross‑context rename**      | “Let’s rename *process (BPMN)* to *activity (PROV)*.”                 | Erases Context boundaries; hides loss; violates locality.         | **Do not rename across Contexts.** Keep both labels; if you must relate them, declare a **Bridge** (F.9) with CL/loss.              |\n| **A2**  | **Retroactive rewrite**    | Old passages silently updated to new names.                           | Breaks provenance; misleads readers about what was meant then. | **Non‑retroactivity.** Past texts stand; add **read‑paths** via `renames/aliases`; attach **epoch notes** when helpful.          |\n| **A3**  | **Alias flood**            | Long lists of synonyms for comfort.                                   | Raises ambiguity; dilutes teaching signals.                    | **Alias parsimony.** Keep ≤ 1 legacy alias per register (Tech/Plain) **inside the same Context or row**.                            |\n| **A4**  | **Paint‑over rename**      | Rename used where sense actually changed.                             | Confuses continuity with revision; hides splits.               | Use **`splits`** (or **`merges`**), not `renames`. If Contexts diverge, adjust **rows** (F.7) and **Bridges** (F.9).                |\n| **A5**  | **Global alias**           | One catchy word reused as alias in several Contexts.                     | Creates a pseudo‑global dictionary; invites category errors.   | **Local aliases only.** If a word appears in many Contexts, treat it as **homonymous**; keep Context‑prefixed speech.                  |\n| **A6**  | **Euphemism treadmill**    | Frequent cosmetic renames (“modernising” labels) with no gain.        | Cognitive noise; readers lose confidence in names.             | Apply the **Same‑sense test**. If gain is marginal, **do nothing**; if clarity improves materially, one **`renames`** is enough. |\n| **A7**  | **Grandfather everything** | Never deprecate confusing legacy labels.                              | Drags ambiguity forward; blocks sharper distinctions.          | When a label truly misleads and has no single successor, **`retires`** with a short **pointer note** to Contexts/rows.              |\n| **A8**  | **Row drift via rename**   | Concept‑Set row is relabeled while its membership silently changes.   | Hides that the set changed; breaks Cross‑context alignment.       | First **split/merge rows** (F.7) as needed; only then `renames` the row **if** its intension stayed.                             |\n| **A9**  | **Bridge‑by‑alias**        | Using an alias to hint two Contexts are “the same.”                      | Smuggles translation without CL/loss.                          | **No Cross‑context aliasing.** If similarity matters, **Bridge** explicitly (F.9) and keep labels separate.                         |\n| **A10** | **Acronym absolutism**     | Treating acronyms as preferred labels everywhere (“SLO” in any Context). | Obscures Context‑specific senses; hurts didactics.                | Prefer **expanded** labels as preferred (F.5); keep acronym as context‑local **alias** only where historically dominant.            |\n| **A11** | **Temporal fudge**         | Rename used to imply design↔run shift (“execution ≈ process”).        | Conflates time stances; erases important dualities.            | Keep **design/run** explicit on labels or glosses; if mapping is needed, do so in **F.9**.                                       |\n| **A12** | **Over‑canonicalisation**  | Forcing a single “perfect” label across all rows/Contexts.               | Centralises language; breaks heterogeneity guard.              | Let each Context/row keep its **own preferred label**; put unification pressure only into **rows** and **Bridges**.                 |\n\n",
        "extended_examples_(multi‑architheory)": "### F.13:11 - Extended examples (multi‑architheory)\n\n#### F.13:11.1 - KD‑CAL × Services — *metric target* labels over time\n\n* **Contexts:** *ITIL 4 (services, design)*; *SOSA/SSN (sensing, run)*.\n* **Before:** Role Description used **“SLO”** (plain “target”) and readers often saw **“service target”**.\n* **Move:** `renames(\"SLO\" → \"service‑level objective\")` (Context: ITIL). Keep `aliases(\"service target\" ↔ \"service‑level objective\")`.\n* **Why:** Same local sense; clearer morphology for F.5; SOSA/SSN labels untouched.\n* **Pay‑off:** Runtime **Observations** (SOSA) are later compared to **service‑level objective** clauses (ITIL) without Cross‑context aliasing.\n\n#### F.13:11.2 - Sys‑CAL × LCA‑CAL — separating *execution* vs *actuation*\n\n* **Contexts:** *IEC 61131‑3 (run)*; *state‑space control texts (design)*.\n* **Temptation:** Rename **“task execution”** to **“actuation”** “to sound control‑ish”.\n* **Diagnosis:** Different Contexts; different SenseCells (program run vs control output).\n* **Move:** **No rename.** Keep labels; later add **Bridge** “`execution (IEC)` *produces* signals that realise `actuation (control)`” with CL stating partial coverage.\n* **Pay‑off:** Plant narratives stop calling programs “actuators”; runtime vs control semantics stay crisp.\n\n#### F.13:11.3 - Kind-CAL × Method‑CAL — false merge avoided\n\n* **Contexts:** *OWL 2 (types, design)*; *SPEM 2.0 (methods, design)*.\n* **Issue:** A row labeled **“Class”** tried to absorb **“WorkProductKind”** by a `renames`.\n* **Diagnosis:** Not same sense; different calculi (type vs artefact category).\n* **Move:** **Split the row**: `splits(\"class\" ⇒ {\"type‑class\",\"work‑product‑category\"})`.\n* **Pay‑off:** Downstream Role Descriptions can point to the correct **SenseCell** without redefining ontological commitments.\n\n#### F.13:11.4 - Enactment × KD‑CAL — retiring a misleading metaphor\n\n* **Context:** *BPMN 2.0 (design)*.\n* **Legacy:** Team jargon **“heartbeat”** used for a **timer event**. Newcomers confuse it with **sensor heartbeats** (KD‑CAL).\n* **Move:** `retires(\"heartbeat\")` in BPMN Context with note “use **timer event**; ‘heartbeat’ refers to sensor liveness in KD‑CAL”.\n* **Pay‑off:** Two different ecosystems stop colliding on the same catchy word.\n\n#### F.13:11.5 - Concept‑Set row refactor after rising CL\n\n* **Rows:** `{“DBaaS”, “Database‑Service”}` representing service notions across several Contexts.\n* **F.3 + F.9 outcome:** High CL; evidence of same Cross‑context alignment.\n* **Move:** `merges({\"DBaaS\",\"Database‑Service\"} ⇒ \"Database‑Service\")` at **row level**. Both legacy labels become row‑local aliases with epoch notes.\n* **Pay‑off:** One clearer row label; old articles still understandable.\n\n",
        "reasoning_primitives_(judgement_schemas,_notation‑free)": "### F.13:12 - Reasoning primitives (judgement schemas, notation‑free)\n\n> Each judgement is a **pure thought**: premises ⇒ safe conclusion. No storage, no workflow, no roles.\n\nLet **`ContextOf(ℓ)`** be the Context of label **ℓ** (when ℓ names a SenseCell); **`rowOf(ℓ)`** the Concept‑Set row (when ℓ names a row); **`senseOf(ℓ)`** the SenseCell it denotes (if local); **`pref(thing)`** the current preferred label of a SenseCell / row / Role Description.\n\n#### F.13:12.1 - Same‑sense & same‑place\n\n`ContextOf(ℓ₁)=ContextOf(ℓ₂) ∧ senseOf(ℓ₁)=senseOf(ℓ₂) ⊢ mayRename(ℓ₁→ℓ₂)`\n*Reading:* If two labels denote **the same SenseCell in the same Context**, a rename is legitimate.\n\n#### F.13:12.2 -Local alias\n\n`ContextOf(ℓ₁)=ContextOf(ℓ₂) ∧ senseOf(ℓ₁)=senseOf(ℓ₂) ⊢ aliases(ℓ₁↔ℓ₂)`\n*Reading:* Legacy synonym can be kept **as a read‑path**; writing uses `pref`.\n\n#### F.13:12.3 - Split detection\n\n`coversMultipleLocalSenses(ℓ) ⊢ splits(ℓ ⇒ {ℓA,ℓB,… })`\n*Reading:* If one label straddles several local senses, declare a split and prefer the new precise labels.\n\n#### F.13:12.4 - Merge admission\n\n`ContextOf(ℓA)=ContextOf(ℓB) ∧ senseOf(ℓA)=senseOf(ℓB) ⊢ merges({ℓA,ℓB} ⇒ ℓN)`\n*Reading:* Once F.3 shows identity of sense **within** a Context, merging labels into one preferred label is safe.\n\n#### F.13:12.5 - Retirement\n\n`misleading(ℓ) ∧ ¬∃ℓ' sameSense(ℓ,ℓ') ⊢ retires(ℓ)`\n*Reading:* If a label misleads and has **no single** successor, retire it and point readers to relevant Contexts/rows.\n\n#### F.13:12.6 - Cross‑context guard\n\n`ContextOf(ℓ₁) ≠ ContextOf(ℓ₂) ⊢ ¬mayRename(ℓ₁→ℓ₂)`\n*Reading:* Different Contexts forbid rename/alias; any relation goes to **Bridge** (F.9).\n\n#### F.13:12.7 - Writing discipline\n\n`thing t ⊢ writeWithPreferred(t) = pref(t)`\n*Reading:* Normative prose uses the **current** preferred label; aliases are for reading.\n\n#### F.13:12.8 - Reading resolution\n\n`legacyLabel ℓ ⊢ readResolve(ℓ) = ⟨thing, pref(thing), epoch?⟩`\n*Reading:* A reader can mentally resolve a legacy label to the **thing** and its present name, with epoch hint if needed.\n\n#### F.13:12.9 - Alias budget\n\n`aliasesFor(thing, register=r) = A ⊢ |A| ≤ 1`\n*Reading:* Keep at most one legacy alias per register (Tech/Plain) for any one thing.\n\n#### F.13:12.10 - Row‑level continuity\n\n`rowOf(ℓA)=rowOf(ℓB)=R ∧ intension(R) stable ⊢ mayRenameRow(R,ℓB)`\n*Reading:* A row label can change if the **row’s membership/intension** did not change; otherwise refactor rows first (F.7).\n\n",
        "relations": "### F.13:13 - Relations\n\n**Builds on:**\nF.1 **context of meaning** (keeps locality), F.2 **Harvesting** (provides attested strings), F.3 **Clustering** (establishes SenseCells), F.5 **Naming Discipline** (supplies preferred labels), F.7 **Concept‑Set rows**, F.8 **Mint‑or‑Reuse**, F.9 **Bridges**, F.10 **Status windows**, F.11 **Method harmonisation**, F.12 **Service acceptance**.\n\n**Constrains:**\n\n* **F.5 (Naming):** may select preferred labels **only** after applying these continuity relations.\n* **F.7 (Rows):** row relabels require row **intension** stability; otherwise use **split/merge rows**.\n* **F.9 (Bridges):** Cross‑context changes must **not** be expressed as renames/aliases.\n\n**Used by.**\nAll Part C architheories when editions shift; all examples and tutorials when teaching with legacy terminology.\n\n",
        "migration_notes_(conceptual_playbook)": "### F.13:14 - Migration notes (conceptual playbook)\n\n1. **Ask the same‑sense question first.** If the underlying **SenseCell/row** is unchanged, prefer `renames`; else reach for `splits/merges`.\n2. **Keep it inside the Context.** If your explanation crosses Contexts, stop—this is **Bridge** territory (F.9), not a rename.\n3. **Prefer clarity over fashion.** Rename only when the new label **removes a real ambiguity** (F.5 criteria), not to chase style.\n4. **Limit nostalgia.** Admit **one** legacy alias in each register that readers will most likely meet; leave the rest to footnotes in examples.\n5. **Deprecate with kindness.** When retiring a label, add a one‑line **pointer note** (e.g., “see `timer event` in BPMN; ‘heartbeat’ in KD‑CAL means sensor liveness”).\n6. **Rows before names.** If a rename request coincides with a shift in what the row covers, **refactor rows** (F.7) first, then choose labels.\n7. **Edition bumps.** When a canon updates, check labels used in that Context: if definitions shift, it’s a **split/merge**; if not, you may `renames` for style/uniformity.\n8. **Teach the delta.** In primers, show a **mini table** with legacy → preferred pairs only where readers will encounter both.\n\n",
        "acceptance_tests_(scr/rscr_—_concept‑level)": "### F.13:15 - Acceptance tests (SCR/RSCR — concept‑level)\n\n#### F.13:15.1 - Static conformance (SCR)\n\n* **SCR-F13-S01 (context-local continuity).** Every `renames/aliases` relates labels **within the same context** or the **same row/Role Description**; none cross Contexts.\n* **SCR‑F13‑S02 (Truthfulness).** For each `renames`, there exists an unchanged **SenseCell/row**; otherwise the move is rejected.\n* **SCR‑F13‑S03 (Alias budget).** For any one thing and register, the number of legacy aliases is **≤ 1**.\n* **SCR‑F13‑S04 (Non‑retroactivity).** No requirement or suggestion to rewrite past texts is present; continuity is expressed as **read‑paths**.\n* **SCR‑F13‑S05 (Row integrity).** A row rename occurs only when the row’s **intension** is stable; if membership changed, a **row split/merge** is documented (F.7).\n* **SCR‑F13‑S06 (Bridge discipline).** No alias/rename is used to imply Cross‑context sameness; any such relation is deferred to **F.9**.\n\n#### F.13:15.2 - Regression (RSCR)\n\n* **RSCR‑F13‑E01 (Edition drift audit).** When a canon edition changes, all labels from that Context are checked against definitions; moves are `renames` if senses stable, else `splits/merges`.\n* **RSCR‑F13‑E02 (Alias creep check).** Periodically ensure alias budgets remain within **≤ 1 per register**; surplus aliases are pruned.\n* **RSCR‑F13‑E03 (Bridge leak check).** Scan continuity notes for Cross‑context hints; any such case is converted into a **Bridge** or deleted.\n* **RSCR‑F13‑E04 (Didactic continuity).** Sampling of examples shows that readers can **resolve** legacy labels to current ones without confusion (via the continuity notes).\n\n",
        "didactic_distillation_(60‑second_script)": "### F.13:16 - Didactic distillation (60‑second script)\n\n> **Names are lenses.** The *thing* that persists is the **sense** (a SenseCell in a Context, a Concept‑Set row, a Role Description). When you improve a lens, use **`renames`** or **`aliases`** **inside that same place**. When the *thing* changes, say so with **`splits/merges`**—and adjust rows/Bridges accordingly. **Never rename across Contexts.** Keep at most **one** legacy alias per register. Do **not** rewrite history; give readers **read‑paths** and brief epoch notes. With this discipline, you can clarify language without erasing meaning, and your models keep both **continuity** and **truth**.\n",
        "f.13:end": "### F.13:End\n"
      },
      "content": "### F.13:End\n",
      "metadata": {},
      "part": "F",
      "cluster": null
    },
    {
      "id": "F.14",
      "title": "Anti‑Explosion Control (Roles & Statuses)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## F.14 - Anti‑Explosion Control (Roles & Statuses)\n\n**“Name less, express more.”**\n\n**Status.** Architectural pattern, architheory‑agnostic.\n**Depends on.** F.1 **context of meaning**; F.2 **Harvesting**; F.3 **Local Sense Clustering**; F.4 **Role Description**; F.5 **Naming Discipline**; F.7 **Concept‑Set Table**; F.8 **Mint‑or‑Reuse**.\n**Coordinates with.** F.10 **Status Windows & Mapping**; F.11 **Method Quartet Harmonisation**; F.12 **Service Acceptance Binding**; F.13 **Lexical Continuity**.\n**Aliases (informative).** *Role/Status economy*; *Explosion guard*.\n\n",
        "intent_&_applicability": "### F.14:1 - Intent & applicability\n\n**Intent.** Prevent the uncontrolled growth of **Roles** and **Statuses** by privileging **reuse**, **bundling**, **explicit separation‑of‑duties (SoD)**, and **applicability windows** over minting new names. Keep the vocabulary **small, crisp, and composable** while remaining faithful to local meanings fixed by Contexts (F.1) and SenseCells (F.3).\n\n**Applicability.** Whenever a new Role/Status is proposed, a team merges two lines of work, or a domain shifts its jargon. Use this pattern before adding rows to the Concept‑Set Table (F.7) or new Role Descriptions (F.4).\n\n**Non‑goals.** No org charts, no RBAC policies, no process roles. This pattern describes **mental moves** for architectural naming, not governance machinery.\n\n",
        "problem": "### F.14:2 - Problem frame\n\nLeft unchecked, Role/Status vocabularies tend to **diverge**:\n\n1. **Synonym stacks.** *Reviewer*, *Approver*, *Validator*, *Verifier* minted separately despite overlapping responsibilities.\n2. **Modifier creep.** *Night‑Operator*, *Shift‑Operator*, *Remote‑Operator* proliferate where one Role plus a window would suffice.\n3. **SoD leakage.** New names invented to **evade** an intended separation (*Requestor‑Approver* as one Role).\n4. **Status paintjobs.** *Compliant*, *At‑Risk*, *Grace*, *Waived*, *Temporarily‑Breached*—labels multiply where a **single Status × window** model would be clearer.\n5. **Context blending.** A control‑Context *Actuator* gets treated as an Enactment *Execution* Role; a deontic *Duty* becomes a runtime *Status*.\n\nExplosion harms didactics and increases alignment cost (F.9).\n\n",
        "forces": "### F.14:3 - Forces\n\n| Force                           | Tension to resolve                                                                                     |\n| ------------------------------- | ------------------------------------------------------------------------------------------------------ |\n| **Expressiveness vs parsimony** | We must name real distinctions, but each new name increases cognitive load.                            |\n| **Locality vs uniformity**      | Roles/Statuses are **context‑local**; yet we need a stable Cross‑context story through Concept‑Set rows.     |\n| **Safety vs convenience**       | SoD constraints protect systems, but people seek convenience through composite roles.                  |\n| **Temporal honesty**            | Many “new” Statuses are actually the **same** Status seen in different **windows** (design/run/grace). |\n\n",
        "minimal_vocabulary_(this_pattern_only)": "### F.14:4 - Minimal vocabulary (this pattern only)\n\n* **Role Description** (F.4): a **Role** (behavioural mask) or **Status** (epistemic/deontic standing) tied to a **SenseCell**.\n* **Concept‑Set row** (F.7): a Cross‑context **intent** (“what we count as one thing”) aligned by SenseCells.\n* **Bundle** (this pattern): a **named composition** of Role Descriptions that are meant to be used together by design (e.g., {Requester, Approver} for change control). A Bundle is a **concept**, not a package.\n* **SoD Constraint** (this pattern): a **conceptual rule** stating that two Roles **must not** be played by the same Holder in the **same window**.\n* **Window** (F.10): an **claim scope** (time stance, holon level, run segment) that delimits when a Role/Status holds.\n\n",
        "core_idea_(didactic)": "### F.14:5 - Core idea (didactic)\n\n**Use four levers before minting a name:**\n\n1. **Reuse the row.** If the intent matches an existing Concept‑Set row and the local SenseCell is already present, **use it**.\n2. **Bundle, don’t blur.** When two Roles must travel together, **name the Bundle**, not a new hybrid Role.\n3. **Declare SoD, don’t fuse.** When Roles must stay apart, **state the SoD** instead of minting a “super‑role.”\n4. **Window, don’t multiply.** When a Status looks different across time/scale, keep **one Status** with **explicit windows**.\n\n",
        "solution": "### F.14:6 - Solution — the control cabinet (conceptual, notation‑free)\n\n#### F.14:6.1 - Reuse by row (first lever)\n\n* **Move.** If a proposal matches the **intension** of an existing row (F.7), adopt its Role Description or add a local SenseCell **inside that row**.\n* **Pay‑off.** Names don’t proliferate; Cross‑context tables stay thin.\n\n**Example (services).** *Service‑availability‑compliance* already exists as a row. New labels *SLO‑Met* / *Uptime‑OK* **reuse** that row; SOSA/SSN Observations later feed it (F.12).\n\n\n#### F.14:6.2 - Bundle instead of hybrid (second lever)\n\n* **Move.** When practice always pairs two Roles, define a **Bundle** `{RoleA, RoleB}`.\n* **Not a hybrid.** Do **not** coin *RoleAB*; you’ll erase SoD options and obscure responsibilities.\n\n**Example (enactment).** `{Requester, Approver}` is a Bundle. *Request‑Approver* (one Role) is **not** allowed; it contradicts intended checks.\n\n\n#### F.14:6.3 - Separate by SoD, don’t evade (third lever)\n\n* **Move.** Record **SoD constraints** where separation matters (“Requester ⟂ Approver in run window”).\n* **Why here.** SoD belongs to **semantics**, not org policy; it protects structure across Contexts and times.\n\n**Example (methods).** `{Author ⟂ Reviewer}` in the **review window**. A proposal *Senior‑Reviewer* to “do both” is rejected; the **Bundle** remains `{Author, Reviewer}` with SoD.\n\n\n#### F.14:6.4 - Window the Status (fourth lever)\n\n* **Move.** Keep a single Status and attach **windows** for *grace*, *evaluation*, *active*, *archival*.\n* **Avoid.** *Compliant*, *At‑Risk*, *Grace* as separate Status types.\n\n**Example (acceptance).** **Compliance** Status has readings per window:\n\n* *evaluation window:* “pending check”,\n* *active window:* “met / breached”,\n* *grace window:* “temporarily tolerated breach”.\n  One Status; clear windows.\n\n\n#### F.14:6.5 - Factor modifiers as facets, not names\n\n* **Move.** Treat qualifiers (shift, locality, domain) as **facets** of the same Role/Status or as **windows**, not new types.\n\n**Example (operations).** *Operator* with **window facet** `timeOfDay = night`—not a new Role *Night‑Operator*.\n\n",
        "invariants_(normative)": "### F.14:7 - Invariants (normative)\n\n1. **context‑locality.** Each Role Description remains tied to a **SenseCell** in a **single Context** (F.3, F.4).\n2. **Row preference.** New Role Descriptions **SHOULD** map to an existing row; new rows (F.7) require F.8 justification.\n3. **No hybrid Roles.** If two Roles are conceptually distinct, they **must not** be fused into one to bypass SoD. Use **Bundle + SoD**.\n4. **Windowed statuses.** Status proliferation across time/scale **MUST** be expressed as **windows** of a single Status family (F.10).\n5. **Bundle clarity.** A Bundle **names only composition**; it does not inherit or redefine member semantics.\n6. **Minimal modifier naming.** Adding a modifier to a label **MUST** pass F.5 tests; prefer facets/windows over new Role/Status names.\n7. **Concept‑first.** No invariant relies on organization charts or access policies; **semantics precede governance**.\n\n",
        "reasoning_primitives_(judgement_schemas)": "### F.14:8 - Reasoning primitives (judgement schemas)\n\n> Pure mental moves; no tools, no workflows.\n\nLet **`rowOf(τ)`** be the Concept‑Set row of template **τ**, **`senseOf(τ)`** its SenseCell, **`win(τ)`** its window set.\n\n1. **Row reuse admissibility**\n   `intent(τₙ) ≡ intent(row r) ∧ ∃σ: senseOf(σ) in r ⊢ reuseRow(τₙ → r)`\n   *Reading:* If the proposed template’s intent matches an existing row with a local SenseCell, reuse the row.\n\n2. **Bundle recommendation**\n   `alwaysTogether{α,β} ∧ distinct(α,β) ⊢ bundle({α,β})`\n   *Reading:* If two distinct Roles occur together by design, name the Bundle.\n\n3. **SoD necessity**\n   `conflictRisk{α,β} ∧ sameHolder ∧ sameWindow ⊢ SoD(α ⟂ β)`\n   *Reading:* If the same Holder in the same window would create a conflict, require SoD.\n\n4. **Hybrid rejection**\n   `SoD(α ⟂ β) ⊢ forbid(hybrid(α,β))`\n   *Reading:* A SoD pair cannot be fused into one Role.\n\n5. **Windowing over multiplication**\n   `status σ showsVariantsAcross(w₁,…,wₖ) ⊢ keepOneStatus(σ) ∧ win(σ)={w₁,…,wₖ}`\n   *Reading:* Variants across time/scale become windows, not new Status names.\n\n6. **Facet over rename**\n   `modifier m changes circumstance ¬ essence ⊢ preferFacet(τ,m)`\n   *Reading:* If a modifier alters circumstances only, represent it as a facet/window.\n\n",
        "micro‑examples_(engineer_/_manager_/_researcher_lenses)": "### F.14:9 - Micro‑examples (engineer / manager / researcher lenses)\n\n#### F.14:9.1 - Enactment (change control)\n\n* **Proposal.** *Requester‑Approver* as a single Role “to move faster.”\n* **Moves.** SoD(`Requester ⟂ Approver`) + **Bundle** `{Requester, Approver}`.\n* **Result.** Same throughput, preserved checks, no hybrid Role.\n\n#### F.14:9.2 - Services (SLO evaluation)\n\n* **Proposal.** New Status *At‑Risk*.\n* **Moves.** Keep **Compliance** Status; add **grace window** and a **forecast facet** (informative) if needed.\n* **Result.** One Status with windows; fewer names, clearer timelines.\n\n#### F.14:9.3 - KD‑CAL (evidence)\n\n* **Proposal.** *Pre‑validated* between *Verified* and *Validated*.\n* **Moves.** Use **Status chain** within one family: `Verified → Validated`; represent uncertainty as **confidence** (F.10), not another Status.\n* **Result.** Clean ladder; no extra label.\n\n#### F.14:9.4 - Sys‑CAL (plant ops)\n\n* **Proposal.** *Night‑Operator*, *Remote‑Operator*.\n* **Moves.** **Role:** Operator; **facets/windows:** `timeOfDay`, `presenceMode`.\n* **Result.** One Role, portable qualifiers.\n\n#### F.14:9.5 - Method quartet (reviews)\n\n* **Proposal.** *Senior‑Reviewer* to bypass `{Author ⟂ Reviewer}`.\n* **Moves.** Keep SoD; if seniority matters, introduce **Assurance Level** facet (F.10) on the **review decision**, not a new Role.\n* **Result.** Separation preserved; trust expressed as a Status property, not a Role type.\n",
        "anti‑patterns_&_remedies": "### F.14:10 - Anti‑patterns & remedies\n\n| #       | Anti‑pattern                             | Symptom in models                                                                            | Why it harms thinking                                             | Remedy (conceptual move)                                                                                                          |\n| ------- | ---------------------------------------- | -------------------------------------------------------------------------------------------- | ----------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------- |\n| **A1**  | **Hybrid Role minting**                  | *Request‑Approver*, *Dev‑Ops‑Engineer* as one Role.                                          | Erases intended checks; conceals distinct responsibilities.       | **Bundle** `{Requester, Approver}` + **SoD** (`Requester ⟂ Approver`). Keep Roles distinct; name the cooperation, not the fusion. |\n| **A2**  | **Modifier‑as‑type**                     | *Night‑Operator*, *Remote‑Operator*, *On‑call‑Reviewer*.                                     | Name proliferation for circumstantial qualifiers.                 | Keep **Role = Operator/Reviewer**; express *night/remote/on‑call* as **facets or windows** (F.10).                                |\n| **A3**  | **Window‑as‑type**                       | *Compliant*, *At‑Risk*, *Grace*, *Breached* as separate Status types.                        | Paints temporal phases as different essences; breaks comparisons. | One **Status family** (e.g., **Compliance**) with **windows**: *evaluation / active / grace / archival* (F.10).                   |\n| **A4**  | **Row drift**                            | New Concept‑Set row for *Uptime‑OK* when **Service‑Availability‑Compliance** already exists. | Splits one intent across rows; Cross‑context tables get wide.        | **Reuse the row** (F.7) if intent matches; add local **SenseCell** if needed.                                                     |\n| **A5**  | **SoD evasion via “trusted” super‑role** | *Senior‑Reviewer* allowed to both author and review.                                         | Conflicts of interest reintroduced under prestige.                | Keep **SoD(Author ⟂ Reviewer)**; if trust matters, attach **Assurance Level** to the *decision* (Status facet), not a new Role.   |\n| **A6**  | **cross-context fusion**                    | One Role Description mixes *Execution (IEC)* with *Duty (ODRL)* semantics.                       | Violates locality; meanings leak across Contexts.                    | Keep each **Role Description** tied to a **SenseCell** (F.4). cross-context reasoning uses **Bridge** (F.9).         |\n| **A7**  | **Synonym carousel**                     | *Validator* vs *Verifier* vs *Checker* minted separately in the same Context.                   | Cognitive noise; ambiguous separation.                            | Choose **one label** via F.5; keep others as **aliases** in **Lexical Continuity** (F.13), not new templates.                     |\n| **A8**  | **Org-chart mirroring**                  | Roles cloned from a company chart (*Squad-Lead*, *Tribe-Lead*) as generic **Role Descriptions**. | Organisation-specific names masquerade as semantics.              | Map local titles to **Bundles** of generic Roles (e.g., `{Planner, Coordinator}`), or treat as **aliases** (F.13). |\n| **A9**  | **KPI‑as‑Status inflation**              | *Latency‑Good*, *Latency‑Bad*, *Latency‑Poor* as Status types.                               | Encodes numeric thresholds as separate essences; brittle.         | One **Quality Status** with **metric threshold** in its window definition (F.10/F.12); keep adjectives out of type names.         |\n| **A10** | **Traffic‑light mania**                  | *Red/Amber/Green* Status types reused across unrelated families.                             | False unification across different intents; color ≠ meaning.      | Keep canonical **Status name** (e.g., **Compliance**); use **presentation** as a separate concern; colors are not types.          |\n| **A11** | **Bundle masquerading as Role**          | *Change‑Manager* invented to hide `{Requester, Approver, Implementer}`.                      | Collapses structure; SoD becomes optional.                        | Name the **Bundle** and its **SoD** explicitly; keep Roles atomic.                                                                |\n| **A12** | **State‑as‑Status sprawl**           | *Pre‑validated*, *Validated*, *Re‑validated*, *De‑validated*.                                | States are temporal positions on one ladder.                      | Define one **Validation Status** with **state ladder** and **windows**; use **Assurance Level** as a facet if needed.             |\n| **A13** | **Contextless Role Description**            | Role Description without a SenseCell anchor.                                                     | Floating meaning; later bridges cannot be made explicit.          | Tie every **Role Description** to a **SenseCell** (F.4). If none fits, use F.8 to decide: **new row** or **rename/reuse**.        |\n| **A14** | **Profile‑driven clones**                | *API‑Approver*, *Data‑Approver*, *Model‑Approver* as different Roles.                        | Scales by surface area; loses the shared essence.                 | One **Approver** Role with a **scope facet** (`objectType=API/Data/Model`).                                                       |\n\n",
        "worked_examples_(multi‑architheory)": "### F.14:11 - Worked examples (multi‑architheory)\n\n#### F.14:11.1 - Enactment + Services + KD‑CAL — “SLO compliance without label sprawl”\n\n**Contexts.** ITIL 4 (services), SOSA/SSN (sensing), PROV‑O (run).\n**Intent.** Track SLO compliance with minimal Status vocabulary.\n\n* **Naïve proposal.** Statuses: *Compliant*, *At‑Risk*, *Breached*, *Grace*, *Waived*.\n* **Moves (F.14).** Keep **Compliance** as one **Status family**; define **windows**: *evaluation* (prediction against forecast), *active* (actuals vs target), *grace* (tolerated breach). **Waiver** becomes a **deontic Status** in ODRL Context, not part of Compliance.\n* **Outcome.** One Status + windows; observations (SOSA) and provenance (PROV) feed the *active* window; service policy (ITIL/ODRL) defines *grace*.\n\n#### F.14:11.2 - Method‑CAL + Enactment — “Reviews with SoD and Bundle”\n\n**Contexts.** SPEM/ISO 24744 (methods), Enactment lexicon.\n**Intent.** Prevent authors reviewing their own work while keeping names lean.\n\n* **Naïve proposal.** Roles: *Author*, *Self‑Reviewer*, *Peer‑Reviewer*, *Senior‑Reviewer*.\n* **Moves.** Roles **Author**, **Reviewer** only; **SoD(Author ⟂ Reviewer)** in the **review window**. If practice needs two reviewers, mint **Bundle** `{Reviewer, Reviewer₂}`; express **seniority** as a **facet** on the *decision* (Assurance Level), not a new Role.\n* **Outcome.** Two Roles, one Bundle, one SoD; no hybrid Role; assurance is visible as a property of the review result.\n\n#### F.14:11.3 - Sys‑CAL + LCA‑CAL + Services — “Operations without role fragments”\n\n**Contexts.** IEC 61131‑3 (execution), state‑space control texts (actuation), ITIL 4 (services).\n**Intent.** Staff coverage across shifts and locations without ten operator types.\n\n* **Naïve proposal.** *Night‑Operator*, *Remote‑Operator*, *Local‑Operator*, *Shift‑Lead*, *On‑call‑Operator*.\n* **Moves.** **Role** = **Operator**; add **facets/windows**: `timeOfDay`, `presenceMode`, `dutyCycle`. If coordination is distinct, mint **Coordinator** Role; when both occur together, **Bundle** `{Operator, Coordinator}`; keep **SoD** where needed (e.g., `Operator ⟂ Approver` for production change).\n* **Outcome.** One Role + small facet set + Bundle; clean hooks to execution and actuation semantics.\n\n#### F.14:11.4 - KD‑CAL + Kind-CAL — “Evidence ladder without new labels”\n\n**Contexts.** KD‑CAL (evidence), OWL 2/FCA (types).\n**Intent.** Express proof maturity without inflating Status names.\n\n* **Naïve proposal.** *Candidate‑Evidence*, *Preliminary‑Evidence*, *Verified‑Evidence*, *Validated‑Evidence*.\n* **Moves.** Keep one **Evidence Status** ladder (`Collected → Verified → Validated`); use **Assurance Level** facet (numeric or ordinal) and **windows** for in‑review vs active. Align *types* in a **row**; do not mint new Status names for granularity.\n* **Outcome.** Short vocabulary, clear ladder, quantitative facet where nuance is needed.\n\n",
        "relations": "### F.14:12 - Relations (with other patterns)\n\n* **Builds on:** F.1 (Contexts), F.2 (Harvesting), F.3 (Local Clustering), F.4 (Role Description), F.5 (Naming).\n* **Constrains:**\n\n  * **F.7 (Concept‑Set Table):** prefer **row reuse**; new rows require F.8 justification.\n  * **F.8 (Mint‑or‑Reuse):** apply **four levers** (reuse, bundle, SoD, window) before minting.\n  * **F.10 (Status Windows & Mapping):** encode temporal/scale variation as **windows**, not new Status types.\n  * **F.12 (Service Acceptance Binding):** bind acceptance to the **Compliance** Status family; avoid ad‑hoc status labels.\n  * **F.13 (Lexical Continuity):** prior names become **aliases**; do not carry forward inflated vocabularies as new types.\n* **Used by.** Architheory examples across Part C to keep Role/Status vocabularies tight.\n\n",
        "migration_notes_(conceptual_playbook)": "### F.14:13 - Migration notes (conceptual playbook)\n\n1. **Map to rows.** For each existing Role/Status, identify its **Concept‑Set row**; if two names share an intent, **collapse** to one row (keep other names as **aliases**, F.13).\n2. **Extract SoD.** Replace “super‑roles” with **Bundles** plus explicit **SoD**; where conflict exists, SoD is **normative**, not cultural.\n3. **Demote modifiers.** Convert adjectival Role types into **U.Facet** (per Compose‑CAL) or **windows** on the base Role.\n4. **Window statuses.** Merge Status families split by time/scale into **one Status + windows**; move waived/exempt notions to the **deontic Context** if applicable.\n5. **Re‑use before minting.** When encountering a gap, scan rows for a near‑match; only if intent genuinely differs, open a **new row** (F.8).\n6. **Preserve continuity.** Keep historic labels as **aliases** under the consolidated template (F.13); do not rewrite past texts.\n7. **Rehearse the cut.** After consolidation, you should be able to recite the entire Role/Status vocabulary **from memory**; if not, reduce again.\n\n",
        "acceptance_tests_(scr/rscr_—_concept‑level)": "### F.14:14 - Acceptance tests (SCR/RSCR — concept‑level)\n\n#### F.14:14.1 - SCR — Static conformance\n\n* **SCR‑F14‑S01 (Row reuse).** Every newly proposed Role Description either **references an existing row** or includes a clear **F.8 justification** for a new row.\n* **SCR‑F14‑S02 (No hybrids).** No Role Description’s label or definition **conflates** two Roles that stand in a declared **SoD** relation.\n* **SCR‑F14‑S03 (Windowed statuses).** Each Status family that shows temporal/scale variation is expressed as **one Status + windows** (not multiple Status types).\n* **SCR‑F14‑S04 (Facet over modifier).** Role names do not encode circumstantial modifiers; such modifiers appear only as **facets/windows**.\n* **SCR‑F14‑S05 (Context locality).** Every Role Description is anchored to **exactly one SenseCell**; no Cross‑context semantics inside a single template.\n* **SCR‑F14‑S06 (Bundles are pure).** Every **Bundle** is a **set of templates** with **no additional semantics** beyond membership and referenced **SoD**.\n\n#### F.14:14.2 - RSCR — Regression (evolution)\n\n* **RSCR‑F14‑E01 (Vocabulary slope).** Over a given interval, the count of distinct Role/Status templates **does not increase** unless matched by **row justifications** (F.8).\n* **RSCR‑F14‑E02 (SoD integrity).** Adding templates does not introduce a label that **circumvents** any existing **SoD** relation.\n* **RSCR‑F14‑E03 (Window integrity).** When windows are refined, **Status type count** remains constant; only window definitions change.\n* **RSCR‑F14‑E04 (Alias discipline).** When labels change, prior names are recorded as **aliases** (F.13); no silent type multiplication.\n\n",
        "didactic_distillation_(90‑second_script)": "### F.14:15 - Didactic distillation (90‑second script)\n\n> **Name less, express more.** Before minting a new Role or Status, try **four levers**:\n> **(1) Reuse the row** — if the intent already exists, adopt it and add your local SenseCell.\n> **(2) Bundle, don’t blur** — when two Roles travel together, **Bundle** them; keep **SoD** if they must stay apart.\n> **(3) Declare SoD, don’t fuse** — conflicts of interest are solved with **SoD**, not with “trusted” super‑roles.\n> **(4) Window, don’t multiply** — one **Status** can wear different **windows** (evaluation/active/grace); that’s not four Status types.\n> Keep modifiers as **facets**, not names; keep every Role Description **context‑local** via its SenseCell. If your vocabulary no longer fits in a thoughtful mind, you have an **explosion**—return to the levers and reduce.\n",
        "f.14:end": "### F.14:End\n"
      },
      "content": "### F.14:End\n",
      "metadata": {},
      "part": "F",
      "cluster": null
    },
    {
      "id": "F.15",
      "title": "SCR/RSCR Harness for Unification",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## F.15 - SCR/RSCR Harness for Unification\n\n**“Prove locality and parsimony first; only then prove composition.”**\n**Status.** Architectural pattern, architheory‑agnostic.\n**Builds on:** E.10.D1 **Lexical Discipline for “Context” (D.CTX)**; F.0.1 **Foundational Principles**; F.1–F.14.\n**Coordinates with.** B.3 **Trust & Assurance Calculus** (for CL use on Bridges).\n\n",
        "intent_&_applicability": "### F.15:1 - Intent & applicability\n\n**Intent.** Provide a **minimal, notation‑free harness of conceptual checks** that tells you whether a unification slice is **sound**: Contexts are fixed and diverse (F.1), terms are harvested and clustered **inside** Contexts (F.2–F.3), Role Descriptions **point to one SenseCell** (F.4), names obey discipline (F.5), rows are reused instead of multiplied (F.7–F.8), bridges are **explicit and penalised** (F.9), statuses vary by **windows** not type proliferation (F.10), and cross‑line bindings (F.11–F.12) respect locality.\n**Applicability.** Use whenever you declare or revise any of: Context cards, Local‑Senses, SenseCells, Concept‑Set rows, Role Descriptions, Bridges, Status windows.\n**Non‑goals.** No registries, workflows, or storage formats. No team roles. No metrics dashboards. This is **thinking discipline**, not governance.\n\n",
        "problem": "### F.15:2 - Problem frame\n\nWithout a unification harness:\n\n1. **Locality leaks.** Cross‑context equivalence creeps in “by name”.\n2. **Row sprawl.** Concept‑Set tables grow laterally with near‑duplicates.\n3. **Role/Status inflation.** Adjectival or temporal variants become new types.\n4. **Silent rewrites.** New editions overwrite old meanings without a trace.\n5. **Unstable bridges.** Cross‑context relations harden into dogma without CL or loss statements.\n\n",
        "forces": "### F.15:3 - Forces\n\n| Force                      | Tension to resolve                                                    |\n| -------------------------- | --------------------------------------------------------------------- |\n| **Parsimony vs coverage**  | Keep vocabularies small yet expressive across multiple Contexts.         |\n| **Locality vs reuse**      | Preserve context‑local meaning while enabling Cross‑context comparison.     |\n| **Stability vs evolution** | Allow new editions and rows without erasing prior sense.              |\n| **Clarity vs formality**   | Checks must be teachable in minutes yet strong enough to catch drift. |\n\n",
        "core_idea_(didactic)": "### F.15:4 - Core idea (didactic)\n\nThe harness is a **two‑tier net of assertions**:\n\n* **SCR — Static Conformance Rules.** context‑local and cross‑artefact checks that must hold **now**.\n* **RSCR — Regression & Stability Rules.** Checks that must hold **across changes** (editions, rows, names).\n\nAll checks are expressed as **judgement schemas** (premises ⊢ conclusion). They **never** prescribe artefact formats, roles, or workflows.\n\n",
        "minimal_vocabulary_(this_pattern_only)": "### F.15:5 - Minimal vocabulary (this pattern only)\n\n* **Unification line (L).** The thematic cut you are pursuing (e.g., Enactment + Sensing + Execution).\n* **Check.** A content‑level assertion about Contexts, senses, rows, Role Descriptions, bridges, or windows.\n* **Witness.** A **thoughtful minimal example** that makes a check concrete (e.g., one seed, one bridge pair).\n* **Slice.** The small set of objects under scrutiny together (Contexts in view, the row you’re adding, the Role Description that uses it, and any bridge it needs).\n\n",
        "objects_under_check": "### F.15:6 - Objects under check\n\n1. **Contexts** — `U.BoundedContext` cards (F.1).\n2. **Local‑Sense** — clustered sense inside one context (F.3).\n3. **SenseCell** — *(Context × Local‑Sense)* address (F.3/F.4).\n4. **Concept‑Set row** — a cross‑projection hypothesis of “the same thing” (F.7).\n5. **Role Description** — Role/Status definition pointing to **one** SenseCell (F.4).\n6. **Bridge** — explicit Cross‑context relation with CL and loss notes (F.9).\n7. **Windows** — temporal/scale views for a Status family (F.10).\n8. **Aliases** — name continuity commitments (F.13).\n9. **Bundles & SoD** — reuse levers that replace hybrid roles (F.14).\n\n",
        "solution": "### F.15:7 - Solution overview — the harness as a lattice of checks\n\nThe harness arranges checks in three clusters:\n\n* **S‑Local.** context‑local sanity (anchoring, clustering, two‑register labels).\n* **S-Cross.** Cross-artefact coherence (row reuse, single-cell **Role Description**, bridge discipline, window honesty).\n* **R‑Evo.** Evolution continuity (no silent rewrites, no vocabulary creep, bridge re‑validation).\n",
        "scr_—_static_conformance_rules_(s‑local)": "### F.15:8 - SCR — Static conformance rules (S‑Local)\n\n> All S‑Local rules are **Context‑internal** and derive only from F.1–F.5.\n\n**SCR‑F15‑S1 (Anchored term).**\n`Seed σ has context C ⊢ C ∈ Contexts(L)`\n*Reading:* Every harvested seed lives in a Context that is **deliberately in view** for your line (F.1, F.2).\n\n**SCR‑F15‑S2 (Edition trace).**\n`Occurrence ω supports σ ⊢ ω carries edition+location`\n*Reading:* A Local‑Sense can be mentally reconstructed from attestations (F.2).\n\n**SCR‑F15‑S3 (Intra‑Context clustering).**\n`Local‑Sense λ clusters {σᵢ} ⊢ ∀i: context(σᵢ)=context(λ)`\n*Reading:* No Cross‑context items inside a Local‑Sense (F.3).\n\n**SCR‑F15‑S4 (Two registers).**\n`Local‑Sense λ ⊢ label(λ)=⟨tech,plain, symbol?⟩ ∧ plain≠∅ ∧ tech≠∅`\n*Reading:* Both engineering and plain labels exist; symbol (if any) is purely informative (F.2/F.3/F.5).\n\n**SCR‑F15‑S5 (Minimal gloss).**\n`gloss(λ) framed at minimal necessary generality`\n*Reading:* The gloss neither smuggles behaviour/deontics nor globalises the sense (F.2/F.5).\n\n**SCR‑F15‑S6 (Context‑local normal form).**\n`normalize_C(surface)=n ⊢ n used only within C`\n*Reading:* No global normal form at this stage (F.2).\n\n",
        "scr_—_static_conformance_rules_(s‑cross)": "### F.15:9 - SCR — Static conformance rules (S‑Cross)\n\n> S‑Cross rules tie Contexts, rows, Role Descriptions, bridges, and windows together **without** breaking locality.\n\n**SCR-F15-S7 (Single-cell Role Description).**\n`Role Description τ ⊢ anchor(τ)=one SenseCell ⟨C,λ⟩`\n*Reading:* Every Role Description points to exactly **one** SenseCell; no mixed semantics (F.4).\n\n**SCR-F15-S8 (Name discipline).**\n`Role Description τ ⊢ name(τ) obeys F.5`\n*Reading:* Labels follow the agreed morphology, register pairing, and minimal generality (F.5).\n\n**SCR‑F15‑S9 (Row sufficiency).**\n`Row ρ lists cells {⟨Cᵢ,λᵢ⟩} ⊢ |distinct(Cᵢ)| ≥ 2`\n*Reading:* A row is meaningful only if it spans **at least two Contexts** (F.7).\n\n**SCR‑F15‑S10 (Row purity).**\n`Row ρ ⊢ no cell contains Cross‑context clustering`\n*Reading:* Each cell is a **single** SenseCell, not a pre‑merged bundle (F.7).\n\n**SCR‑F15‑S11 (Reuse before mint).**\n`Proposed row ρ' overlaps intent(ρ) ⊢ prefer reuse(ρ) ∨ document F.8 decision`\n*Reading:* Rows are reused by default; new rows require a mint‑or‑reuse rationale (F.7–F.8).\n\n**SCR‑F15‑S12 (Bridge is explicit).**\n`C₁≠C₂ ∧ relation asserted between λ₁,λ₂ ⊢ Bridge β: ⟨⟨C₁,λ₁⟩ ↔ ⟨C₂,λ₂⟩, kind, CL, loss⟩`\n*Reading:* Cross‑context relations appear **only** as Bridges with declared kind (≡, ⊑, ⊒, ⟂), Congruence Level, and loss notes (F.9; B.3 for CL semantics).\n\n**SCR‑F15‑S13 (Bridge locality).**\n`Bridge β ⊢ cells belong to different Contexts`\n*Reading:* You never bridge **within** a Context; that’s clustering (F.3/F.9).\n\n**SCR‑F15‑S14 (Window honesty).**\n`Status family Σ varies by time/scale ⊢ windows(Σ) define variation; no new Status types introduced`\n*Reading:* Temporal and scale variation appears as **windows**, not as new types (F.10).\n\n**SCR-F15-S15 (SoD preservation).**\n`Bundle B = {τ₁,τ₂,…} with SoD(τᵢ ⟂ τⱼ) ⊢ no single **Role Description** fuses τᵢ,τⱼ`\n*Reading:* Separation‑of‑Duties is a **normative constraint**, not a label tweak (F.14).\n\n**SCR‑F15‑S16 (Binding coherence).**\n`Service‑Acceptance binding references Status Σ and Execution E ⊢ Σ anchored; E anchored; comparison defined via Bridge(s) if Cross‑context`\n*Reading:* Acceptance compares **anchored** executions and statuses, with any Cross‑context step made explicit (F.12 + F.9).\n\n> **SCR/RSCR “Twin Harness” tests**\n\n**SCR‑TWIN‑01 - Head term check.** Plain twin preserves/declares the head per **CC‑TWIN‑3**.  \n**SCR‑TWIN‑02 - Kind check.** Plain twin maps to the same **Kind** as the Tech name (C.3).  \n**SCR‑TWIN‑03 - SenseCell check.** Twin and Tech resolve to the same **SenseCell**; record counter‑example(s).  \n**SCR‑TWIN‑04 - Stop‑list check.** If the base noun is in the **Ambiguity stop‑list**, require bracketed head + gloss or **fail**.  \n**SCR‑TWIN‑05 - Normative surface check.** No plain twins in CC blocks, signatures, or acceptance clauses.  \n**RSCR‑TWIN‑06 - Drift audit.** On Context or glossary edits, re‑run twin harness; degrade or deprecate if SenseFidelity falls.  \n**RSCR‑TWIN‑07 - Bridge audit.** If a twin is copied across Contexts, ensure a **Bridge** exists; record **CL** and loss notes.\n\n > **Examples & Anti‑examples**\n\n**Good (role with head):**\n* Tech: `TransformerRole` → Plain: **“Transformer (role)”** — passes Head & Kind checks.\n*  Tech: `IncidentCommanderRole` → Plain: **“Incident commander (role)”**.\n\n**Good (episteme status with head):**\n* Tech: `U.EvidenceRole` → Plain: **“Evidence (status)”** — first mention includes head.\n\n**Borderline (allowed with gloss):**\n* Tech: `U.Episteme` → Plain: **“Tradition (episteme)”** — **only** with first‑use gloss, e.g., _“Tradition (episteme) \\[U.Episteme\\] — a body of knowledge within IAU\\_2006”_. (Without the head/gloss this is **forbidden** due to ambiguity.) \n\n**Forbidden:**\n* Tech: `U.Episteme` → Plain: **“Tradition”** (bare) — fails **CC‑TWIN‑4/5**.\n* Tech: `U.ServiceClause` → Plain: **“API”** — fails Kind and head checks (API is an access **method**, not the **promise**).\n* Tech: `U.RoleAssignment` → Plain: **“Appointment”** — banned term; conflates governance speech‑act with the binding object.\n\n> **Migration guidance (lightweight)**\n1.  **Inventory.** List current plain twins per Context.\n2.  **Score.** Assign **SenseFidelity** (0–3) and add counter‑examples; demote or deprecate any with score <2.\n3.  **Head & gloss.** Add bracketed heads and first‑use glosses for all surviving twins.\n4.  **Register.** Create/update entries in **E.10.P**; link a **DRR** for each change.\n5.  **Lint.** Enable the **Twin Harness** in CI to block new ambiguous twins.\n",
        "judgement_schemas_(core_moves)": "### F.15:10 - Judgement schemas (core moves)\n\n> Representative mental moves; each “fires” one cluster of SCRs.\n\n1. **Anchoring**\n   `Seed σ : context C, C ∈ Contexts(L) ⊢ anchored(σ)`  *(S1)*\n\n2. **Local clustering**\n   `∀σ∈Σ: context(σ)=C ⊢ cluster_C(Σ) = Local‑Sense λ`  *(S3)*\n\n3. **Role-Description anchoring**\n   `Role Description τ names ⟨C,λ⟩ ⊢ singleCell(τ)`  *(S7)*\n\n4. **Row reuse**\n   `intent(ρ') ≈ intent(ρ) ⊢ reuse(ρ) ∨ justify_mint(ρ')`  *(S11)*\n\n5. **Bridge assertion**\n   `C₁≠C₂ ∧ compare(⟨C₁,λ₁⟩,⟨C₂,λ₂⟩) ⊢ Bridge(CL,kind,loss)`  *(S12–S13)*\n\n6. **Windowing**\n   `Status Σ exhibits temporal/scale variance ⊢ define windows(Σ); forbid Σ‑splitting`  *(S14)*\n\n7. **SoD guard**\n  `SoD(τᵢ ⟂ τⱼ) ⊢ ¬exists Role Description υ that conflates {τᵢ,τⱼ}`  *(S15)*\n\n",
        "micro‑witnesses_(illustrative)": "### F.15:11 - Micro‑witnesses (illustrative)\n\n**11.1 Activity vs Task (PROV‑O ↔ IEC 61131‑3).**\nContexts: `PROV‑O (run)`, `IEC 61131‑3 (run)`.\nLocal‑Senses: *activity(prov)*, *task(iec)*.\n*Fire:* S7 (**Role Description** “Execution” points to **one SenseCell**), S12 (Bridge: **overlap**, CL=2, loss: *IEC task may be cyclic; PROV activity need not be periodic*), S13 (Contexts differ), S14 (Status windows for compliance later, not new types).\n\n**11.2 Service Acceptance (ITIL 4 ↔ SOSA/SSN).**\nContexts: `ITIL 4 (design)`, `SOSA/SSN (run)`.\nRow: **Service‑Availability** with cells ⟨ITIL\\:SLO availability⟩, ⟨SOSA\\:observation of uptime⟩.\n*Fire:* S9 (row spans ≥2 Contexts), S12 (Bridge kind: *measure-for-target*, CL=3, loss: *sampling bias*), S16 (binding coherence), **S-RoleDesc-SingleCell**.\n\n",
        "relations": "### F.15:12 - Relations (with other patterns)\n\n**Builds on:** E.10.D1 (Context semantics), F.1–F.14.\n**Constrains:** Any addition to F.1–F.14 is **publish‑ready** only if all relevant **SCR** here evaluate **true** on its slice.\n**Feed:** B.3 may use Bridge CL and loss notes to adjust assurance.\n",
        "rscr_—_regression_&_stability_rules_(r‑evo)": "### F.15:13 - RSCR — Regression & Stability Rules (R‑Evo)\n\n> These rules speak about **changes over time**. They are expressed as **judgement schemas** that compare two conceptual snapshots: `@t0` and `@t1`. No storage, no workflows—just content assertions.\n\n**Notation.**\n`X@t0` — object X before change • `X@t1` — after change • `Δ(X)=⟨…⟩` — described difference • `same(…) / new(…) / retired(…)` — conceptual status.\n\n\n#### F.15:13.1 - Contexts & editions\n\n**RSCR‑F15‑E1 (No silent replacement).**\n`Context C@t0 : edition e0, C@t1 : edition e1, e1≠e0 ⊢ either newContext(C,e1) ∨ explicitRecency(C,e1)`\n*Reading:* A new edition becomes a **new Context** if sense shifts; otherwise keep one context and mark recency. Never overwrite meaning.\n\n**RSCR‑F15‑E2 (Trip‑wire carry‑over).**\n`C@t1 derives from C@t0 ⊢ tripWires(C@t1) ⊇ review(tripWires(C@t0))`\n*Reading:* Known confusions are re‑checked and re‑stated (or explicitly dropped with a sentence why).\n\n\n#### F.15:13.2 - Local‑Senses & SenseCells\n\n**RSCR‑F15‑E3 (Reconstitutable seeds).**\n`Local‑Sense λ@t0, Δ(occurrences) → λ@t1 ⊢ λ@t1 still reconstructible from attestations@t1`\n*Reading:* After changes in attestations, the Local‑Sense remains **auditably rebuildable**.\n\n**RSCR‑F15‑E4 (No Cross‑context creep).**\n`SenseCell ⟨C,λ⟩@t0 → @t1 ⊢ context(λ@t1)=C`\n*Reading:* A SenseCell never migrates across Contexts through edits.\n\n\n#### F.15:13.3 - Concept‑Set rows\n\n**RSCR‑F15‑E5 (Row identity).**\n`Row ρ@t0 with cells {⟨Cᵢ,λᵢ⟩} → ρ@t1 with {⟨Cᵢ,λᵢ'⟩} ⊢ ρ “same” iff intent(λᵢ')≈intent(λᵢ) ∀i`\n*Reading:* A row is the **same** row only if each cell still means *the same thing* in its Context. Otherwise, mint a **new row** and retire the old (F.7–F.8).\n\n**RSCR‑F15‑E6 (Row shrink‑before‑split).**\n`ρ@t1 loses a cell due to edition split ⊢ prefer keep ρ@t0 + add new row ρ' rather than mutating ρ silently`\n*Reading:* When a Context splits meaning, preserve history: **add** instead of rewriting.\n\n\n#### F.15:13.4 - Role Descriptions (Role/Status)\n\n**RSCR-F15-E7 (Single-cell continuity).**\n`Role Description τ@t0 → τ@t1 ⊢ anchor(τ@t1)=one SenseCell ∧ (sameCell ∨ justifiedSwitch)`\n*Reading:* A **Role Description** keeps pointing to **one** SenseCell; switching cells requires a **one-sentence** rationale tied to the row you reuse (F.4, F.8).\n\n**RSCR-F15-E8 (Alias-then-rename).**\n`name(τ@t0) → name(τ@t1) ⊢ create alias(name@t0→name@t1) unless semantics changed`\n*Reading:* If only the **name** improves, create an **Alias** (F.13). If semantics change, **mint a new Role Description** instead.\n\n\n#### F.15:13.5 - Bridges\n\n**RSCR‑F15‑E9 (Re‑validate on movement).**\n`Bridge β: ⟨⟨C₁,λ₁⟩ ↔ ⟨C₂,λ₂⟩, CL, loss⟩ @t0; any λᵢ mutates @t1 ⊢ β re‑examined; CL may drop; loss updated`\n*Reading:* Any end‑cell change **forces** a fresh look; default is **more caution** (CL non‑increasing unless newly justified).\n\n**RSCR‑F15‑E10 (No bridge drift to identity).**\n`series of edits turns β(kind≠≡) → β(kind=≡) ⊢ require new witness set`\n*Reading:* Equivalence (≡) is special: it needs a **fresh witness**; you cannot slide into ≡ by minor edits.\n\n\n#### F.15:13.6 - Status windows & SoD\n\n**RSCR‑F15‑E11 (Window stability).**\n`Status family Σ windows@t0 → @t1 ⊢ window set changes only if variance‑of‑meaning is shown`\n*Reading:* Add or remove windows **only** when meaning genuinely varies across time/scale—never for convenience (F.10).\n\n**RSCR‑F15‑E12 (SoD invariance).**\n`SoD(τᵢ ⟂ τⱼ) @t0 → @t1 ⊢ SoD preserved; no new Role Description conflates τᵢ,τⱼ`\n*Reading:* Separation‑of‑Duties remains in force through changes (F.14).\n\n",
        "anti‑patterns_the_harness_catches_(and_the_fix)": "### F.15:14 - Anti‑patterns the harness catches (and the fix)\n\n| Code   | Anti‑pattern            | Symptom                                  | Why it breaks                         | Harness catch → Fix                                                                              |\n| ------ | ----------------------- | ---------------------------------------- | ------------------------------------- | ------------------------------------------------------------------------------------------------ |\n| **H1** | **Row‑of‑one**          | Row spans a single Context                  | No cross‑projection; fake unification | **S9** fails → either add the second cell or drop the row                                        |\n| **H2** | **Bridge‑by‑name**      | “Same name” assumed across Contexts         | Imports meaning; hides loss           | **S12** missing → assert an explicit Bridge with CL+loss or withdraw the claim                   |\n| **H3** | **Silent edition swap** | “BPMN” changed to 2.0 → 2.1 without note | Retcons past statements               | **E1** fails → mint a new Context or mark recency; never overwrite                                  |\n| **H4** | **Locality blur**       | Local‑Sense mixes two Contexts              | Cross‑context clustering                 | **S3/S6** fail → split back by Context; keep per‑Context normal forms                                  |\n| **H5** | **Window‑as‑type**      | New Status type for weekend vs weekday   | Type inflation; hides time stance     | **S14/E11** fail → represent as windows, not types                                               |\n| **H6** | **SoD bypass**          | Bundle fuses mutually exclusive roles    | Hidden duty conflict                  | **S15/E12** fail → keep roles separate; use Bundle only as reuse map                             |\n| **H7** | **Alias-as-merge**      | Alias used to smuggle semantic change    | Loses history; misleads readers       | **E8** fails → if semantics changed, mint new Role Description; keep old with alias note only for pure rename |\n| **H8** | **CL optimism**         | Most Bridges set to high CL by default   | Over‑trust; brittle reuse             | **E9/E10** → demand witnesses; prefer conservative CL                                            |\n\n",
        "worked_“dry‑runs”_(composite_slices)": "### F.15:15 - Worked “dry‑runs” (composite slices)\n\n> Each dry‑run shows **how the checks fire** when something evolves. These are **thinking rehearsals**, not procedures.\n\n#### F.15:15.1 - New edition of ITIL (services) arrives\n\n**Slice.** Contexts: ITIL 4(2020)@t0 → ITIL 4(2024)@t1; Row: *Service-Availability*; **Role Description**: `AvailabilityStatus`; Bridges: to SOSA/SSN observations.\n\n**Fire.**\nE1 (**no silent replacement**): decide **new Context** ITIL 4(2024) because SLO definitions narrowed.\nE5 (**row identity**): row *Service‑Availability*@t1 **new** (cells now ⟨ITIL2024\\:SLO⟩ + ⟨SOSA\\:obs⟩). Retire old row with note.\nE9 (**bridge re‑validate**): sampling assumptions changed → **lower CL** by one and update loss note (*new calc window*).\nE7 (**single-cell Role Description**): `AvailabilityStatus` still points to exactly one cell (ITIL2024\\:SLO). Name unchanged → **no alias** needed.\n\n**Pay‑off.** History is preserved; reuse remains safe; acceptance bindings (F.12) still compare anchored things.\n\n\n#### F.15:15.2 - Rename a Role Description without changing meaning\n\n**Slice.** **Role Description** `IncidentStatus`@t0 → `ServiceIncidentStatus`@t1; same SenseCell.\n\n**Fire.**\nE8 (**alias‑then‑rename**): create **Alias** `IncidentStatus → ServiceIncidentStatus` (F.13).\nS8 (**name discipline**): new name fits the suffix rules (F.5).\n\n**Pay‑off.** Readers find both names; semantics untouched.\n\n\n#### F.15:15.3 - Tighten a Bridge (weak overlap → equivalence)\n\n**Slice.** Bridge β between ⟨OWL\\:subclass⟩ and ⟨FCA\\:order‑edge⟩ was *overlap, CL=2*. New formal result proves equivalence in the covered fragment.\n\n**Fire.**\nE10 (**no drift to identity**): to move from overlap→≡, present a **new witness set** (fragment constraints).\nS12 (**bridge explicit**): update β(kind=≡, CL=3) with precise scope/loss (“only within acyclic concept lattices with…”)\n\n**Pay‑off.** Equivalence is **scoped and auditable**, not hand‑waved.\n\n\n#### F.15:15.4 - Window misuse detected\n\n**Slice.** Team proposes *PeakHoursAvailabilityStatus* as a new Status type.\n\n**Fire.**\nS14/E11 (**window honesty**): reject new type; define a **window** for *peak hours* on `AvailabilityStatus`.\n\n**Pay‑off.** No type explosion; the evaluation logic in F.12 stays uniform.\n\n",
        "migration_cues_(conceptual)": "### F.15:16 - Migration cues (conceptual)\n\n1. **When in doubt, fork—not overwrite.** New edition? **Add a Context** unless you can argue sense identity in one sentence.\n2. **Name pain → aliases, not merges.** If a label confuses, **rename with an alias**; if meaning changed, **mint new**.\n3. **Rows age gracefully.** Never retrofit a row; **retire and re‑row** when any cell’s sense shifts.\n4. **Bridges get colder over time.** Prefer to **lower CL** when editions drift; raising CL needs fresh witnesses.\n5. **Windows absorb variation.** Resist splitting Status types; **window** by time/scale/phase.\n6. **Guard SoD early.** When binding composite responsibilities (F.14), check SoD before naming.\n7. **Teach the delta.** When things evolve, write one‑breath deltas (“what changed, why it matters”) as part of the example narrative—no registries implied.\n\n",
        "acceptance_summary_(“harness_green”)": "### F.15:17 - Acceptance summary (“Harness green”)\n\nA unification slice is **publish‑ready** when:\n\n1. **All SCR (S‑Local & S‑Cross) hold** for the current snapshot (Contexts, Local‑Senses, SenseCells, rows, Role Descriptions, Bridges, windows).\n2. **All RSCR (R‑Evo) hold** against the previous snapshot: no silent replacements; rows either unchanged or retired+reborn; Bridges re‑validated with CL non‑inflated without witnesses; windows adjusted only for real variance; SoD intact.\n3. **One micro‑witness per moving part** exists in the text (tiny example showing the check in action).\n4. **Memory rule still holds**: the active Context set for the line fits in a careful mind without external aids (F.1).\n\n",
        "didactic_distillation_(90‑second_teaching_script)": "### F.15:18 - Didactic distillation (90‑second teaching script)\n\n> “Use the harness to **think like a safety net**. First, the **SCR** threads: everything is **local** to a Context; **Role Descriptions** point to **one** SenseCell; rows actually **cross** Contexts; Bridges are explicit with CL and a loss note; windows capture variation without spawning new types. Then, the **RSCR** knots: never overwrite an edition—**fork the Context** or mark recency; keep rows stable by **retiring and re-rowing**; Bridges get **re-validated** (CL goes down unless you bring proof); renames become **aliases** unless meaning changes; **windows** absorb time/scale shifts; **SoD** stays intact. If you can pass these thoughts on a small slice—and explain each pass in **one breath**—your unification is green. No tooling, no roles, no dashboards. Just clean Contexts, honest rows, cautious bridges, and names that help minds meet.”\n",
        "f.15:end": "### F.15:End\n"
      },
      "content": "### F.15:End\n",
      "metadata": {},
      "part": "F",
      "cluster": null
    },
    {
      "id": "F.16",
      "title": "Worked‑Example Template (Cross‑Domain)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## F.16 - Worked‑Example Template (Cross‑Domain)\n\n**“Show the thought, not the tooling.”**\n**Status.** Architectural pattern, architheory‑agnostic.\n**Builds on:** E.10.D1 **Lexical Discipline for “Context” (D.CTX)**; F.1–F.15.\n**Coordinates with.** B.3 **Trust & Assurance Calculus** (CL on Bridges); Part C architheories (Sys‑CAL, KD‑CAL, Kind-CAL, Method‑CAL).\n\n",
        "intent_&_applicability": "### F.16:1 - Intent & applicability\n\n**Intent.** Provide a **single, didactic page template** for cross‑domain worked examples that makes every claim **local to a Context** (Context), every Cross‑context step **explicit via a Bridge**, and every named role/status **traceably tied** to one **SenseCell**. The template is **notation‑free** and **tool‑agnostic**; it captures **how to think** the example so others can replay it.\n\n**Applicability.** Use whenever you illustrate **any** FPF construct that spans more than one Context: **Role Assignment & Enactment** bindings, acceptance checks, measurement-driven claims, type alignment, control/actuation stories, etc.\n\n**Non‑goals.** No registries, workflows, editors, or storage formats; no step‑by‑step “team procedures.” This pattern shapes **the page a reader sees**, not how it was produced.\n\n",
        "problem": "### F.16:2 - Problem frame\n\nCross‑domain examples often fail in four predictable ways:\n\n1. **Global words.** *Process*, *role*, *service*, *execution* used without the Context, inviting drift.\n2. **Hidden bridges.** “It’s basically the same” across disciplines, with losses left implicit.\n3. **Name without sense.** A **Role Description** name appears with no visible tie to a SenseCell.\n4. **List without structure.** Facts line up but never meet in a single **Concept‑Set row**.\n\nThe template counters these by forcing **Contexts → senses → row → bridges**, in that order.\n\n",
        "core_idea_(didactic)": "### F.16:3 - Core idea (didactic)\n\nA robust worked example is a **compact theatre**:\n\n* **Stage** = a declared **unification line** (which threads of Part C are in play).\n* **Backdrop** = **Context set** (Contexts from F.1), each with a one‑line Card.\n* **Actors** = **SenseCells** (⟨Context, Local‑Sense⟩) you will actually use.\n* **Plot** = **one Concept‑Set row** where those cells stand as “the same thing” for this example.\n* **Cues** = **Role Descriptions** that reference exactly one SenseCell each.\n* **Cross‑talk** = **Bridges** across Contexts (with kind, CL, and loss).\n* **Timing** = **Windows** (if status varies across time/scale) and **SoD** (if duties must remain separate).\n* **Moral** = a handful of **harness checks** (F.15) that the reader can verify mentally.\n\n",
        "minimal_vocabulary_(this_pattern_only)": "### F.16:4 - Minimal vocabulary (this pattern only)\n\n* **Context / Context** — always **U.BoundedContext** (E.10.D1).\n* **Local‑Sense** — a sense clustered within one context (F.3).\n* **SenseCell** — address `⟨Context, Local‑Sense⟩`.\n* **Concept‑Set row (ρ)** — a Cross‑context alignment for “what we treat as one” in this example (F.7/F.8).\n* **Role Description (τ)** — a Role or Status that **points to one SenseCell** (F.4–F.6).\n* **Bridge (β)** — explicit Cross‑context relation with **kind** (≡ / overlaps / broader‑than / narrower‑than), **CL**, and **loss note** (F.9).\n* **Window** — a bounded interval (time/scale/phase) tied to a Status (F.10).\n* **SoD** — Separation-of-Duties constraint among **Roles** (F.14).\n\n",
        "the_one‑page_**worked‑example_canvas**": "### F.16:5 - The one‑page **Worked‑Example Canvas**\n\n> Each bullet is a **thought you make visible**, not a form field.\n\n1. **Title & claim.** A short name + one‑sentence claim you will demonstrate.\n   *Example:* *“Service Uptime as Evaluated by Runtime Executions”* — “We compare **Execution (IEC)** observations to **SLO (ITIL)** within a declared window.”\n\n2. **Unification line.** Which Part C threads are active.\n   *Example:* *Enactment + KD‑CAL (sensing) + Sys‑CAL (execution).*\n\n3. **Context set (compact Cards).** 3–6 Contexts from F.1 with one‑line scope and, if inherent, **design vs run** stance.\n   *Example:* *BPMN 2.0 (design: workflow graph); PROV‑O (run: Activity uses/generates); ITIL 4 (design: SLO/SLA); SOSA/SSN (run: Observation); IEC 61131‑3 (run: task executes).*\n\n4. **SenseCells in play.** List exactly the **Local‑Senses** you will use, each prefixed by its Context.\n   *Example:* ⟨**ITIL**: service‑level‑objective⟩, ⟨**SOSA**: observation⟩, ⟨**IEC**: execution‑task⟩, ⟨**PROV**: activity⟩.\n\n5. **The Concept‑Set row (ρ).** A **single line** that places the cells you treat as “the same” for the claim, with a one‑breath justification.\n   *Example row ρ:* { ⟨ITIL\\:SLO⟩ ↔ ⟨SOSA\\:observed‑availability⟩ } — *We treat “target availability” and “observed availability” as comparable magnitudes in a specific window.*\n\n6. **Bridges (β).** For any Cross‑context relation **not captured by ρ** (or that requires nuance), state **kind, CL, loss**.\n   *Example β₁:* ⟨**IEC\\:execution‑task**⟩ **overlaps** ⟨**PROV\\:activity**⟩, **CL=2**, *loss:* PROV lacks cyclic scheduling semantics.\n   *Example β₂:* ⟨**SOSA\\:observation**⟩ **narrower‑than** ⟨**ITIL\\:measurement**⟩, **CL=2**, *loss:* ITIL omits procedure metadata.\n\n7. **Role-Description hooks.** Name the Role/Status templates and the **one SenseCell** each references.\n   *Example:* `AvailabilityStatus` → ⟨ITIL\\:SLO⟩; `Execution` → ⟨IEC\\:execution‑task⟩; `EvidenceObservation` → ⟨SOSA\\:observation⟩.\n\n8. **Windows & SoD (if relevant).** Spell any **status windows** and any **SoD** you rely on.\n   *Example:* Window: *monthly, business‑hours*; SoD: *Operator* ⟂ *SLO‑Owner*.\n\n9. **Micro‑narrative (5–7 lines).** Walk the reader through the claim using **Context‑prefixed words** and the row/bridges above.\n   *Example (abridged):* “A **task (IEC)** runs the control program. Its **observations (SOSA)** yield availability over the *monthly* window. We compare those to the **SLO (ITIL)** in the same window. Where we refer to **activity (PROV)** we do so via **β₁** (overlap, CL=2). The row ρ is the locus of comparison; the Bridge **β₂** explains why ‘measurement’ in ITIL is broader than ‘observation’ in SOSA.”\n\n**Harness pings (F.15).** *S-Row-Cross*, **S-RoleDesc-SingleCell**, *E-NoSilentEdition*.\n    *Example:* *S‑Row‑Cross*, *S‑RoleDescription‑SingleCell*, *E‑NoSilentEdition*.\n\n> **Memory rule.** If your Canvas cannot fit on a single page (or one slide), the example is teaching the wrong thing.\n\n",
        "invariants_(normative)": "### F.16:6 - Invariants (normative)\n\n1. **Locality of meaning.** Every term in the narrative appears **with its Context** at first mention (*process (BPMN)*, *activity (PROV)*, …).\n2. **At least one row.** The example **MUST** include ≥ 1 **Concept‑Set row** spanning ≥ 2 Contexts.\n3. **Single-cell Role Description.** Every **Role Description** in the example **MUST** point to **one** SenseCell.\n4. **Explicit bridges.** Any Cross‑context step **not explained by the row** **MUST** appear as a **Bridge** with kind, CL, and loss.\n5. **Temporal honesty.** If a Context fixes **design vs run**, the narrative respects it.\n6. **Window discipline.** If comparison depends on time/scale/phase, a **window** is stated rather than minting a new Status type.\n7. **SoD integrity.** If duties are involved, **SoD** is explicit and unbroken.\n8. **Didactic parsimony.** One page, one claim, one row (or a tiny bundle of closely related rows).\n\n",
        "the_row_panel_(how_to_show_it_without_notation)": "### F.16:7 - The row panel (how to show it without notation)\n\nShow the row as a **compact two‑to‑five‑column list**:\n\n* **Column header** = Context.\n* **Cell** = `Local‑Sense label` (tech register; optional plain label on next line).\n* **Footline** (one line) = “row reason”—why these cells count as “the same thing **for this claim**.”\n\n*Example visual (linear text):*\n**ITIL 4:** *service‑level‑objective* | **SOSA/SSN:** *observed‑availability* → **Row reason:** *both quantify availability for the same window; units harmonised by KD‑CAL; procedural metadata differs (captured in loss of β₂).*\n\n",
        "worked_micro‑example_(didactic)": "### F.16:8 - Worked micro‑example (didactic)\n\n> **Title.** *Alarms Should Not Satisfy Uptime*\n> **Claim.** An **alarm‑only Execution (IEC)** cannot satisfy the **SLO (ITIL)** because **observation (SOSA)** windows exclude time in “alarm state.”\n\n**Contexts.** IEC 61131‑3 (run), SOSA/SSN (run), ITIL 4 (design).\n**SenseCells.** ⟨IEC\\:execution‑task⟩, ⟨SOSA\\:observation⟩, ⟨ITIL\\:SLO⟩.\n**Row ρ.** { ⟨ITIL\\:uptime‑SLO⟩ ↔ ⟨SOSA\\:observed‑availability⟩ } — comparable magnitudes in the *calendar‑month* window.\n**Bridge β.** ⟨IEC\\:alarm‑state⟩ **narrower‑than** ⟨SOSA\\:observation‑qualifier⟩, **CL=2**, *loss:* SOSA does not prescribe plant‑specific alarm semantics.\n**Role-Description hooks.** `AvailabilityStatus` → ⟨ITIL\\:SLO⟩; `EvidenceObservation` → ⟨SOSA\\:observation⟩.\n**Window.** *Calendar month, business‑hours*, exclusion: *alarm‑state intervals*.\n**Micro‑narrative (4 lines).** A **task (IEC)** runs; when the plant is in **alarm state**, **observations (SOSA)** are flagged and **excluded** from the availability window. We then compare the remaining interval to the **SLO (ITIL)** via row ρ. The Bridge β clarifies why the flag is a **qualifier** in SOSA, not a Status type in ITIL.\n**Harness pings.** *S‑Row‑Cross*, *S‑RoleDescr‑SingleCell*, *S‑Window*, *S‑TemporalHonesty*.\n\n",
        "relations": "### F.16:9 - Relations (with other patterns)\n\n**Builds on:**\nF.1 (Contexts), F.2–F.3 (terms & senses), F.4–F.6 (roles), F.7–F.8 (rows), F.9 (bridges), F.10 (windows), F.14 (SoD), F.15 (harness).\n\n**Constrains:**\nAny example placed in Part C or Part B **must** render its claim through this canvas (or a faithful reduction), so readers can run F.15 mentally.\n\n",
        "didactic_distillation_(60‑second_script)": "### F.16:10 - Didactic distillation (60‑second script)\n\n> “A good cross‑domain example fits on **one page**. First, name the **claim**. Then show the **Contexts** you’re using. List the **SenseCells** you will actually touch. Draw **one row** that makes them the same **for this claim**. Every Cross‑context nuance you can’t justify in that row becomes a **Bridge** with a **kind**, a **CL**, and a **loss** sentence. Point each **Role Description** to **one** cell. If time/scale matters, state the **window**; if duties matter, state **SoD**. Finish with two or three **harness pings** from F.15. That’s it—no tooling, no long procedures. The reader can now replay your thought and agree (or disagree) at the right place.”\n",
        "anti‑patterns_&_remedies": "### F.16:11 - Anti‑patterns & remedies\n\n| #         | Anti‑pattern               | Symptom in the page                                            | Why it breaks thinking                                         | Remedy (point to this template & sibling patterns)                        |\n| --------- | -------------------------- | -------------------------------------------------------------- | -------------------------------------------------------------- | ------------------------------------------------------------------------- |\n| **AP‑1**  | **Row‑less tour**          | A list of facts from many Contexts with no **Concept‑Set row**.   | Reader cannot see *what is treated as the same* for the claim. | Include **≥ 1 row ρ** spanning ≥ 2 Contexts (§5‑5, §6‑2).                    |\n| **AP‑2**  | **Stealth bridging**       | Phrases like “basically the same” with no Bridge.              | Imports meaning Cross‑context; hides losses.                      | State a **Bridge β** with **kind, CL, loss** (§5‑6, F.9).                 |\n| **AP-3**  | **Role-Description vagueness**          | A Role/Status named without a SenseCell.                       | Why it breaks thinking                                         | Remedy (point to this template & sibling patterns)                        |\n| **AP‑4**  | **Global words**           | *process, role, service* appear unprefixed.                    | Context‑less words drift mid‑example.                             | Prefix first mention with the **Context** (*process (BPMN)*) (§6‑1, E.10.D1). |\n| **AP‑5**  | **Window‑free comparison** | Numbers/targets compared with no stated window.                | Apples‑to‑oranges across time/scale.                           | Declare a **Window** for the Status (§5‑8, F.10).                         |\n| **AP‑6**  | **SoD leakage**            | Duties named but the same actor implicitly holds both.         | Violates Separation‑of‑Duties intent.                          | State **SoD** and keep duties disjoint (§5‑8, F.14).                      |\n| **AP‑7**  | **Design/run blur**        | A design‑time notion used as if it were a run‑time occurrence. | Category error; wrong Context claims.                             | Mark Context stance and keep claims in‑stance (§5‑3, §6‑5).                  |\n| **AP‑8**  | **Edition haze**           | “BPMN”, “ITIL” without edition/profile.                        | Debates about “what the book says”.                            | Put **name + edition** on each Card (§5‑3).                               |\n| **AP‑9**  | **CL silence**             | Bridge kind given, no CL or loss note.                         | Reader cannot assess translation risk.                          | Add **CL** and **loss** in every Bridge (§5‑6, B.3).                      |\n| **AP‑10** | **Over‑row**               | Ten cells glued into one row “for convenience”.                | Collapses distinct senses; unreadable.                         | Prefer **one tight row**; split into **two rows** if needed (§5‑5, §8).   |\n\n",
        "extended_worked_micro‑examples": "### F.16:12 - Extended worked micro‑examples\n\n> Each example fits the **one‑page canvas** (§5) and makes the **row** and **bridges** do the work.\n\n#### F.16:12.1 - Type alignment: OWL class vs FCA concept (design‑time only)\n\n**Title & claim.** *“Two Lenses on *Pump*: OWL class and FCA concept align for catalogue reasoning.”*\n**Unification line.** Kind-CAL (design) + FCA (design).\n**Contexts.** **OWL 2 (profiles)** — classes, `subClassOf` (design). **FCA corpus** — formal concepts, lattice order (design).\n**SenseCells.** ⟨OWL\\:class ‘Pump’⟩, ⟨FCA\\:formal‑concept ‘Pump’⟩.\n**Row ρ.** { ⟨OWL\\:Pump⟩ ↔ ⟨FCA\\:Pump⟩ } — *same practical extension in this product catalogue*.\n**Bridge β.** ⟨FCA\\:lattice‑order⟩ **overlaps** ⟨OWL\\:subclass‑order⟩, **CL=2**, *loss:* FCA intents may include context attributes not modeled in OWL restrictions.\n**Role-Description hooks.** `TypeLabel` → ⟨OWL\\:class⟩ (for naming), no runtime **Role Assignment/Enactment**.\n**Micro‑narrative (3 lines).** For catalogue queries, the **instances** covered by OWL class *Pump* match those of the FCA concept created from the same attributes; we treat them as one row. The **orderings** diverge in nuance (β), but not for membership in this example.\n**Harness pings.** *S‑Row‑Cross*, *S‑TemporalHonesty* (design only), *S‑Bridge‑Kind‑CL*.\n\n\n#### F.16:12.2 - Role vs permission: SoD in enactment vs access control\n\n**Title & claim.** *“Behavioral role (BPMN) is disjoint from access role (RBAC); keep duties separate.”*\n**Unification line.** Role Assignmnent and Enactment (design & run) + access/deontics (design).\n**Contexts.** **BPMN 2.0** — participant/lanes (design). **NIST RBAC (2004)** — roles/permissions (design).\n**SenseCells.** ⟨BPMN\\:participant⟩, ⟨RBAC\\:role⟩.\n**Row ρ.** — *(intentionally none)* — we do **not** treat them as the same.\n**Bridge β.** ⟨BPMN\\:participant⟩ **disjoint** ⟨RBAC\\:role⟩, **CL=3**, *loss:* none—*different dimensions* (behavioral mask vs permission grouping).\n**Role-Description hooks.** `Operator` → ⟨BPMN\\:participant⟩; `AccessRole` → ⟨RBAC\\:role⟩. **SoD:** `Operator` ⟂ `AccessRole‑Admin`.\n**Window.** Not applicable.\n**Micro‑narrative (3 lines).** We show SoD by prohibiting the same actor from holding **Operator** and **AccessRole‑Admin**. The disjoint **β** prevents leakage between behavioral masks and permission bundles.\n**Harness pings.** *S‑RoleDescr‑SingleCell*, *S‑SoD*, *S‑Bridge‑Disjoint*.\n\n\n#### F.16:12.3 - Method quartet: from MethodDescription to Work with observations\n\n**Title & claim.** *“Behavioral role (BPMN) is disjoint from access role (RBAC); keep duties separate.”*\n**Unification line.** **Role Assignment & Enactment** (design & run) + access/deontics (design).\n**Contexts.** **SPEM 2.0** (design: Method/MethodDescription), **PROV‑O** (run: Activity), **SOSA/SSN** (run: Observation), **ITIL 4** (design: SLO).\n**SenseCells.** ⟨SPEM\\:MethodDescription⟩, ⟨PROV\\:activity⟩, ⟨SOSA\\:observation⟩, ⟨ITIL\\:SLO⟩.\n**Row ρ.** { ⟨ITIL\\:SLO\\:build‑time⟩ ↔ ⟨SOSA\\:observed‑build‑duration⟩ } — *compare promised vs observed duration on the same window*.\n**Bridges.** β₁: ⟨SPEM\\:MethodDescription⟩ **narrower‑than** ⟨PROV\\:activity‑plan⟩, **CL=2**, *loss:* PROV lacks prescriptive structure; β₂: ⟨SOSA\\:observation⟩ **narrower‑than** ⟨ITIL\\:measurement⟩, **CL=2**, *loss:* ITIL abstracts from procedure.\n**Role-Description hooks.** `Operator` → ⟨BPMN\\:participant⟩; `AccessRole` → ⟨RBAC\\:role⟩. **SoD:** `Operator` ⟂ `AccessRole-Admin`.\n**Window.** *Release window: calendar week*.\n**Micro‑narrative (4 lines).** The **MethodDescription (SPEM)** implies a target **build‑time**; **Work (PROV activity)** occurs; **observations (SOSA)** provide actuals; we compare against the **SLO (ITIL)** via row ρ over the *calendar week* window. Bridges β₁–β₂ explain why plan/measure semantics do not collapse.\n**Harness pings.** *S‑Row‑Cross*, *S‑Window*, *S‑RoleDesc‑SingleCell*, *S‑TemporalHonesty*.\n\n",
        "reasoning_primitives_(judgement_schemas)": "### F.16:13 - Reasoning primitives (judgement schemas)\n\n> These are **mental checks** you can perform on any example page.\n\n1. **Row validity**\n   `cells(ρ) = {⟨Cᵢ,Sᵢ⟩} with |Contexts(ρ)| ≥ 2 ⊢ validRow(ρ)`\n   *Reading:* A row is valid only if it spans at least two Contexts and all entries are legitimate **SenseCells** (from F.3).\n\n2. **Bridge coverage**\n   `coRef(Ca,Cb) ∧ ¬sameRow(Ca,Cb) ⊢ requires β(Ca↔Cb)`\n   *Reading:* If two Contexts are co‑referenced in the narrative but their senses are not placed in the same row, an explicit **Bridge** is needed.\n\n3. **Role-Description single-cell**\n   `Role Description τ used ⊢ ∃!⟨C,S⟩ : ref(τ)=⟨C,S⟩`\n\n4. **Window sufficiency**\n   `compare(qᵢ@Cᵢ, qⱼ@Cⱼ) ⊢ windowDeclared`\n   *Reading:* Any Cross‑context quantitative comparison calls for a stated **Window**.\n\n5. **Temporal honesty**\n   `C has stance s ∈ {design, run} ⊢ claims@C must respect s`\n   *Reading:* Do not assert run‑facts in a design‑only Context, or vice versa.\n\n6. **SoD integrity**\n   `SoD(D₁ ⟂ D₂) ∧ assign(actor, D₁) ∧ assign(actor, D₂) ⊢ violation`\n   *Reading:* A declared SoD cannot be violated inside the example.\n\n7. **Bridge clarity**\n   `β given ⊢ kind(β) ∧ CL(β) ∧ loss(β)`\n   *Reading:* Every Bridge shows **kind**, **CL**, and a **one‑line loss**.\n\n8. **Edition clarity**\n   `card(C) ⊢ has(name, edition)`\n   *Reading:* Each Context Card specifies name + edition/profile.\n\n9. **Harness ping mapping**\n   `ping ∈ {S‑*, E‑*} ⊢ ping ⇒ subset of judgements above`\n   *Reading:* Each named harness check (F.15) has a clear reading in these judgements.\n\n",
        "acceptance_tests_(scr/rscr)": "### F.16:14 - Acceptance tests (SCR/RSCR)\n\n#### F.16:14.1 - Static conformance (SCR)\n\n* **SCR‑F16‑S01 (Row present).** The page contains **≥ 1** Concept‑Set row spanning **≥ 2 Contexts**.\n* **SCR‑F16‑S02 (Bridge explicit).** Every Cross‑context assertion not justified by a row is shown as a **Bridge** with **kind, CL, loss**.\n* **SCR-F16-S03 (Role-Description anchoring).** Each **Role Description** appearing in the page references **exactly one SenseCell**.\n* **SCR‑F16‑S04 (Context prefixes).** First mention of each ambiguous term is **Context‑prefixed**.\n* **SCR‑F16‑S05 (Window discipline).** Any numeric comparison across Contexts names a **Window**.\n* **SCR‑F16‑S06 (DesignRunTag).** Claims respect each Context’s **design/run** stance.\n* **SCR‑F16‑S07 (SoD).** If duties are named and SoD is relevant, **SoD is stated** and unviolated.\n* **SCR‑F16‑S08 (One‑page parsimony).** The example fits the **one‑page canvas**; if extended, each sub‑page still respects §6 invariants.\n\n#### F.16:14.2 - Regression (RSCR)\n\n* **RSCR‑F16‑E01 (Edition drift).** When a Context’s edition changes, the example either (a) is unaffected or (b) adds a note adjusting **β** or the **row**; no silent rewrites.\n* **RSCR‑F16‑E02 (Bridge re‑score).** If an upstream **CL** definition changes (B.3), affected Bridges on the page show the new CL and, if needed, an updated **loss** sentence.\n* **RSCR‑F16‑E03 (Row resilience).** If a SenseCell is split in F.3 (sense refinement), the example either keeps the same row using one child sense, or splits into two rows with a short justification.\n* **RSCR‑F16‑E04 (Window clarity).** If organisational cadence changes (e.g., from monthly to weekly), windows on the page are updated explicitly.\n\n",
        "migration_notes_(conceptual)": "### F.16:15 - Migration notes (conceptual)\n\n1. **Refactor long tutorials.** Extract the **claim**; pick **3–6 Contexts** (Cards); list the **SenseCells** you actually use; craft **one tight row**; surface any cross‑talk as **Bridges** with loss notes; delete everything else.\n2. **Split crowded rows.** If a row tries to carry more than \\~4 cells, split into two rows and write a **one‑line purpose** for each.\n3. **Stabilise vocabulary.** If you find yourself rewriting terms mid‑page, you likely forgot a Context; return to F.1 and add a Card.\n4. **Teach the bridge itch.** Leave “*these are the same*” feelings ungratified until you can articulate **kind, CL, loss** in one sentence.\n5. **DesignRunTag respect.** If a design‑only Context tempts you into runtime talk, move that part of the narrative into a **run‑Context** and Bridge as needed.\n6. **Keep the page living.** When upstream rows/bridges evolve (F.7–F.9), adjust the page *minimally* and call out the change in a margin note (conceptual, not procedural).\n\n",
        "teaching_variants_(all_obey_§6_invariants)": "### F.16:16 - Teaching variants (all obey §6 invariants)\n\n* **Two‑Context equivalence.** Smallest case: 1 row, 2 Contexts, **β (≡, CL=3)** to explain why they’re truly the same *for this claim*.\n* **Triangulation.** 1 row, 3 Contexts; typical for *measurement ↔ service ↔ execution*.\n* **Disjointness lesson.** No row; one **β (disjoint)** plus a short SoD story.\n* **Window primer.** Same sense across Contexts but different default windows; the page is about the **window choice**, not the term.\n\n",
        "didactic_checklist_(author’s_quick_scan)": "### F.16:17 - Didactic checklist (author’s quick scan)\n\n* One sentence **claim**?\n* **Contexts** (with editions) visible?\n* **SenseCells** named (tech & plain labels acceptable)?\n* **Exactly one** tight **row** (or two, each justified)?\n* All Cross‑context steps shown as **β(kind, CL, loss)**?\n* **Role Description → one SenseCell** each?\n* **Window** present where numbers meet?\n* **SoD** stated where duties appear?\n* Page fits a **single view**?\n\n",
        "closing_distillation_(30‑second_echo)": "### F.16:18 - Closing distillation (30‑second echo)\n\n> A strong worked example is a **one‑page alignment**: claim → Contexts → cells → **one row** → explicit **bridges** → Role-Description hooks → window/SoD if needed. No tooling, no process charts—just **visible thinking** that any careful reader can replay and critique at the right place.\n",
        "f.16:end": "### F.16:End\n\n"
      },
      "content": "### F.16:End\n\n",
      "metadata": {},
      "part": "F",
      "cluster": null
    },
    {
      "id": "F.17",
      "title": "Unified Term Sheet (UTS)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## F.17 - Unified Term Sheet (UTS)\n\n**“One table that a careful mind can hold.”**\n**Status.** Architectural pattern, architheory‑agnostic.\n**Builds on:** F.1–F.3 (Contexts → seeds → local senses), F.4 (Role Characterisation), F.5 (Naming), F.7 (Concept‑Set table), F.8 (Mint/Reuse decision), F.9 (Bridges), F.10–F.12 (Status & method/service bindings), F.15 (SCR/RSCR).\n**Coordinates with:** A.1.1 `U.BoundedContext`, A.7 **Strict Distinction**, A.8 **Heterogeneity**, A.11 **Ontological Parsimony**, A.15 **Role–Method–Work Alignment**.\n**Non‑goals.** No registries, workflows, editors, or storage formats. No by‑name Cross‑context equivalence. No “data pipeline.” This pattern prescribes **what a UTS is** and **how to judge it**, not how to generate files.\n",
        "intent_&_applicability": "### F.17:1 - Intent & Applicability\n\n**Intent.** Provide a **single, normative table**—the **Unified Term Sheet (UTS)**—that distils the output of F.1–F.12 into **human‑readable rows**. Each row expresses **one Concept‑Set** unified into **one FPF U.Type** with its **Tech/Plain names** and **cross‑context senses**. The UTS is the *front‑door view* that authors, engineers, and managers use; it replaces scattered notes and eliminates guesswork.\n\n**Applicability.** Produce a UTS **per architheory thread** (e.g., *Role Assignment & Enactment*, *Method quartet*, *Trust & Evidence*). Use it:\n\n* to **name** U.Types and their **Tech/Plain** labels (F.5),\n* to **teach** the mapping from familiar canons to unified concepts,\n* to **audit** coverage and heterogeneity (A.8), and\n* to **feed** examples in Parts A/C without re‑explaining terminology.\n\n**Why now.** Earlier F‑patterns define *how to think*. **F.17** defines *what you publish* so others can think with you.\n",
        "problem": "### F.17:2 - Problem Frame\n\nWithout a single sheet:\n\n1. **Locality is lost.** Mappings hide in prose; readers re‑globalise words.\n2. **Naming drifts.** Teams adopt ad‑hoc labels that collide later.\n3. **Coverage is opaque.** No quick check that coverage spans **≥ 3 domain families** across the sheet (A.8).\n4. **Didactic load spikes.** Each section re‑teaches the same terms.\n\n**UTS** fixes this by putting the **unification decision** and the **cross‑context evidence** on **one line** per concept.\n\n",
        "forces": "### F.17:3 - Forces\n\n| Force                             | Constraint in UTS                                                                                                   |\n| --------------------------------- | ------------------------------------------------------------------------------------------------------------------- |\n| **Didactic primacy vs. fidelity** | UTS keeps **two names** (Tech/Plain) and **one‑line rationale**, but never misstates a source meaning.              |\n| **Parsimony vs. recall**          | Each row is one concept; the UTS as a whole demonstrates heterogeneity across ≥ 3 domain families (A.8). Rows may cite fewer Contexts when the concept truly appears in fewer.                   |\n| **Locality vs. comparability**    | Senses are **Context‑scoped** (E.10.D1). Cross‑context relations are shown only as **explicit bridges** (F.9) with **CL**. |\n| **General usability**             | Sheet must be **legible on paper** and **memorisable** (block structure, stable row order).                         |\n\n",
        "core_idea": "### F.17:4 - Core Idea\n\n**A UTS is a Concept‑Set table with names.**\nEach **row** = one **Concept‑Set** unified into one **FPF U.Type** (the “what we mean”).\nEach **column family** shows **how this concept appears** in the chosen **contexts of meaning** (F.1).\n\nTwo **canonical layouts** are allowed (pick one or publish both):\n\n* **Layout A — Kernel‑first**: rows keyed by **FPF U.Type**; **Bounded‑Context Columns (BCC)**.\n* **Layout B — Base‑concept**: rows keyed by **Base concept** (EN/RU) of a discipline, then unified to **U.Type**; **Discipline Columns (DC)**.\n\nBoth layouts are normative; choose based on audience. In Layout A, comparability is by **BCC** (*Bounded‑Context Column*); in Layout B, comparability is by **DC** (*Discipline Column*); never conflate the two.\n",
        "minimal_vocabulary_(for_this_pattern)": "### F.17:5 - Minimal Vocabulary (for this pattern)\n\n* **UTS (Unified Term Sheet).** The published, human‑readable table per thread.\n* **Context.** Alias in Tech register for **`U.BoundedContext`** (E.10.D1). Normative unit of meaning; every SenseCell is scoped to a Context _(name + edition)._  \n* **Bounded‑Context Column (BCC).** A didactic column used **only in Layout A**; one column per **Context (`U.BoundedContext`)** from the F.1 cut; **not a model element**; the **header includes the Context name + edition**.  \n* **Discipline Column (DC).** A _discipline vantage_ used **only in Layout B** (e.g., _Operational Management_, _IT/Software_, _Physics_). A DC is **not** a **Bounded‑Context Column** and does not carry editions.  \n* **Concept‑Set (CSR).** One unified concept with pointers to its SenseCells.  \n* **SenseCell.** _(Context × Local‑Sense)_ address—how a Context “says that thing”.  \n* **Bridge / CL.** Explicit cross‑context mapping (F.9) with Congruence Level and Loss note.\n* **Plain Twin (LEX).** The LEX record pairing the **Unified Tech name** with its **Unified Plain name** for a U.Type; governed by **PTG** and referenced by `Twin‑Map Id (LEX)` (E.10 LEX‑BUNDLE).\n* **Block Plan.** Didactic grouping of rows to keep the sheet memorizable.  \n* **Unified Tech name / Unified Plain name.** Dual‑register names chosen per F.5; the **Tech name is the neutral, unified term** for the U.Type, not a borrowed Context name.\n\n> **Discipline.** “Context” always means **`U.BoundedContext`** (E.10.D1). No global words.\n",
        "row_schema_(normative)": "### F.17:6 - Row Schema (normative)\n\nEvery UTS row **MUST** carry the following fields (verbatim headings recommended):\n\n| Field                     | Purpose                                                                                               |\n| ------------------------- | ----------------------------------------------------------------------------------------------------- |\n| **# / Block**             | Stable id and didactic block (see §7).                                                                |\n| **FPF U.Type**            | Canonical kernel type (e.g., `U.Work`).                                                               |\n| **Unified Tech name**     | Short technical name used in spec prose (F.5).                                                        |\n| **Unified Plain name**    | Everyday name for non‑specialists (F.5).                                                              |\n| **Plain‑Twin Governance (PTG) (optional)** | Stance for the Unified Plain twin: {**Strict**, **Guarded**, **Provisional**}; use when additional discipline of the Plain twin is required (E.10 LEX‑BUNDLE). |\n| **Twin‑Map Id (LEX) (optional)** | Identifier of the Tech↔Plain twin record in the LEX‑BUNDLE; cite when `PTG ≠ Strict` or when multiple candidate twins exist. |\n| **FPF Description**       | One‑line definitional gist (no examples).                                                             |\n| **SenseCells (by context)** | Per selected Context: the local term(s) or construct that best realises the concept (one cell per Context). |\n| **Bridges (CL/Loss)**     | For any cross‑context relation, record the F.9 Bridge with **CL** and a 2–6‑word loss note; if identity, mark **CL=3 (identity)**. |\n| **Unification Rationale** | One sentence: why these senses are the same *conceptually*.                                           |\n| **Notes (optional)**      | Brief DesignRunTag or trip‑wire hints (e.g., “design vs run”).                                     |\n\n**Constraint.** “SenseCells (by **Context**)” **MUST** cite **at least three** distinct **Contexts** overall across the sheet for the thread (A.8). A single row may show fewer if the concept truly appears in fewer contexts; coverage is a property of the whole UTS.\n\n**Discipline:** Every SenseCell **must** cite the **Context name + edition** (e.g., _“BPMN 2.0 (2011): Activity instance”_).\n\n#### F.17:6.1 - NQD Fields (normative; when applicable)\n\nIf a UTS row **describes** a **Generator/Selector/Portfolio** (design‑time or run‑time artefact), it **MUST** add the following fields. These are *publication* fields, not tooling‑specific formats.\n\n| Field | Purpose |\n| --- | --- |\n| **N (Novelty)** | Lawful novelty claim tied to `CharacteristicSpaceRef` + `DistanceDefRef` (declare metric/pseudometric & invariances; cite edition ids). |\n| **U (Use‑Value)** | Declared acceptance/test value under the active **CG‑Frame** (units & scale typed per MM‑CHR). |\n| **C (ConstraintFit)** | Feasibility against **ResourceEnvelope/RiskEnvelope** (and relevant deontic/ethics clauses); no `unknown→0` coercion. |\n| **D\\_P (Portfolio Diversity)** | Diversity contribution relative to the **current PortfolioPack** (`ArchiveConfig`, grid/binning, K‑capacity, dedup). |\n| **E/E‑LOG policy‑id (PolicyIdRef)** | Edition id of the explore/exploit governor policy that governed generation/selection budgets. |\n\n**Note.** These fields *extend* the Row Schema; they do not change SenseCells/Bridges/Names. Rows that are *purely definitional* (no generator/selector/portfolio semantics) do not carry §6.1.\n\n#### F.17:6.2 - Autonomy fields (when applicable)\nAdd the following columns (nullable; **required** when autonomy is claimed by the row’s subject):\n* `AutonomyBudgetDeclRef` (id, version)\n* `Aut-Guard policy-id (PolicyIdRef)`\n* `OverrideProtocolRef`\n* `Scope (G)` (autonomy scope)\n* `Γ_time` (admission window selector)\n* *(optional)* `ScaleLensPolicyRef`\n* *(optional)* `ScaleLensOptIn ∈ {OptedIn, Neutral, OptedOut}`\n**Note.** These fields are required for UTS rows that describe a **Role**, **Method**, **Service**, or **Selector** with autonomy claims; optional fields make **Bitter‑Lesson/Scale‑Lens** an explicit **opt‑in** with published criteria.\n",
        "block_plan_(didactic_grouping)": "### F.17:7 - Block Plan (didactic grouping)\n\nA UTS **MUST** declare a **Block Plan**—the sequence of blocks that group rows. Blocks are **thread‑specific**. Example **Block Plan** for *Role Assignment & Enactment* (matches your earlier tables):\n\n* **Block A - Context & Roles** — `U.BoundedContext`, `U.Role`, `U.RoleAssignment`, `U.Capability`.\n* **Block B - Method & Description** — `U.Method`, `U.MethodDescription`, Access/Acceptance descriptions (fields of `U.ServiceClause`).\n* **Block C - Execution & Schedule** — `U.Work`, `U.WorkDescription`, `U.Observation`.\n* **Block D - Service & Deontics** — `U.ServiceClause`, `U.SpeechAct`, `U.Commitment`, `U.ServiceClauseClause`, `U.ServiceClauseEvaluation`.\n* **Block E - Carriers & Bridges** — `U.Carrier`, *Alignment (Bridge entry)*.\n* **Block R - Knowledge Units & Statuses** — `U.Episteme`, `U.EvidenceRole`, `U.StandardStatus`, `U.RequirementStatus`, `U.DefinitionRole`, `U.AxiomaticCoreRole`.\n\n> **Rule.** Block names are **didactic**, not ontological. Do **not** infer mereology or subtyping from blocks.\n",
        "column_families_(two_canonical_layouts)": "### F.17:8 - Column Families (two canonical layouts)\n\n#### F.17:8.1 - Layout A — Kernel‑first (U.Type as rows)\n\n**Columns:**\n\n* `FPF U.Type - Unified Tech name - Unified Plain name - Plain‑Twin Governance (PTG) - Twin‑Map Id (LEX) - FPF Description` *(left rail; `PTG`/`LEX` are optional)*\n* **Bounded‑Context Columns (BCC)** — one column per **Context (`U.BoundedContext`)** from the F.1 cut; each header shows _name + edition_: e.g., **OMG BPMN 2.0**, **W3C PROV‑O**, **ITIL 4**, **NIST RBAC**, **W3C SOSA/SSN**, **OMG Essence (Language)**, **DEMO/DEMO‑EO**, **PMBOK 7**, **CM/BPM (CMMN/BPMN)**, **IEC 61131‑3**, **ODRL 2.2**, **ISO 80000‑1 / Metrology** … *(your chosen 12 Contexts)*\n* `Bridges (CL/Loss)`\n* `Unification Rationale`\n* `Notes`\n  \nDo not mix **Discipline Columns (DC)** in Layout A. Columns here are only **Bounded‑Context Columns (BCC)**.\n\n#### F.17:8.2 - Layout B — Base‑concept pivot (discipline columns)\n\n**Columns:** Base concept - Scale‑map - Unified Tech name - **Unified Plain name** - Plain‑Twin Governance (PTG) - Twin‑Map Id (LEX) - Formal U.Type - **Discipline Columns (DC)** (e.g., Operational Management / IT/Software / Physics / …) - Rationale - Notes.\n\n* `Base concept (EN / RU)`\n* `Scale‑map (Σ / Π / μ)` *(optional; see §9.4)*\n* `Unified Tech name`\n* `Unified Plain name`\n* `Plain‑Twin Governance (PTG)` *(optional)*\n* `Twin‑Map Id (LEX)` *(optional)*\n* `Formal U.Type`\n\n* **Discipline Columns (DC)** (choose 3–5): e.g., **Operational Management**, **IT/Software**, **Physics**, **Science/Theory**, **Math/Proof**, **Literature**, **Religion** *(or other discipline columns suited to the thread)*\n * `Unification Rationale`\n* `Notes`\n \n> **Guidance.** Publish **Layout A** for kernel users and spec authors; publish **Layout B** for cross‑disciplinary onboarding and teaching.\n> **Clarification — Plain vs Base concept.** In Layout B the `Base concept (EN/RU)` is a **discipline vantage** aid and **does not substitute** for the single **Unified Plain name** in the left rail. Do not mint alternative unified‑plain synonyms inside DC cells; flag homonym risks with ⚡ in `Notes`.\n",
        "invariants_(normative_constraints)": "### F.17:9 - Invariants (normative constraints)\n\n1. **Locality.** Every SenseCell is **Context‑scoped** (E.10.D1). No global synonyms.\n2. **Bridges only via F.9.** Cross‑context equivalence appears **only** as an explicit Bridge with **CL**. Any row citing > 1 **Context** must state at least one Bridge.\n3. **Heterogeneity.** Across the UTS, coverage must involve **≥ 3 domain families** (F.1 Step 2; A.8).\n4. **Scale‑map tags (optional but disciplined).** If used in Layout B:\n   * **Σ (Summative):** concept’s quantitative properties aggregate across a population of executions/holders.\n   * **Π (Conjunctive/Compositional):** concept composes by required conjunction (all‑of), not by averaging.\n   * **μ (Micro/Atomic):** concept is inherently micro‑level (per single execution/holder).\n     *(Tags aid teaching; they do not change semantics.)*\n5. **Strict Distinction.** Use `U.Method` vs `U.MethodDescription`, `U.Work` vs `U.WorkDescription`, `U.Role` vs `U.RoleCharacterisation` correctly; do **not** collapse intensional objects with their descriptions.\n6. **Dual register.** Every row has **Tech** and **Plain** labels per F.5.\n7. **One‑breath rationale.** The `Unification Rationale` is a **single sentence** explaining the conceptual sameness despite local wording.\n8. **Unified naming neutrality.** The **Unified Tech name** is the neutral FPF choice per F.5; it is **not** lifted wholesale from any single Context unless the Concept‑Set justification (F.7) shows identity.  \n9. **Column discipline.** Layout A uses **Bounded‑Context Columns (BCC)** only; Layout B uses **Discipline Columns (DC)** only. Mixing is non‑conformant.\n10. **Plain‑twin discipline.** The single **Unified Plain name** lives in the left rail; BCC/DC cells carry senses only. Any additional Plain aliases are managed in LEX (tv:\\*) and never minted per column.\n",
        "how_to_compile_(conceptual_moves,_not_a_workflow)": "### F.17:10 - How to Compile (conceptual moves, not a workflow)\n\n**M1 - Fix contexts (F.1).** Declare the **12 (±)** contexts for this thread.\n**M2 - Harvest & cluster (F.2–F.3).** Identify candidate senses per Context; cluster *within* Contexts; mint **SenseCells**.\n**M3 - Form Concept‑Sets (F.7).** For each “the‑same‑thing” across Contexts, create one **CSR**; attach SenseCells.\n**M4 - Name (F.5).** Choose **Tech/Plain** labels; assert the **FPF U.Type** (or propose a new one via F.8).\n**M5 - Bridge (F.9).** Where Cross‑context relations are not exact, assert Bridges with **CL** and a short **Loss** note.\n**M6 - Place rows into blocks (§7).** Keep the sheet memorisable.\n**M7 - Write one‑line `FPF Description` and the `Rationale`.**\n**M8 - Run acceptance harness (F.15).** Apply the UTS checks in §11.\n\n> **Note.** These are **thought moves**. No tooling is implied or required.\n",
        "acceptance_harness_(scr/rscr)_for_a_uts": "### F.17:11 - Acceptance Harness (SCR/RSCR) for a UTS\n\n#### F.17:11.1 - Static Conformance Rules (SCR‑UTS)\n\n* **SCR‑UTS‑01 (Row completeness).** Each row contains: `U.Type`, `Tech`, `Plain`, `FPF Description`, `SenseCells (≥ 1)`, `Rationale`.\n* **SCR‑UTS‑02 (Dual register).** Each row has both Tech and Plain labels; Tech is used in spec prose, Plain in didactics.\n* **SCR‑UTS‑03 (Locality discipline).** Every SenseCell is cited **with its Context name & edition**.\n* **SCR‑UTS‑04 (Heterogeneity).** Across the sheet, the set of referenced Context spans **≥ 3 domain families**.\n* **SCR‑UTS‑05 (Bridge honesty).** All cross‑context sameness claims are expressed via an F.9 **Bridge** with a **CL** score; if identity, mark **CL=3** and note “identity/no loss” rather than omitting the bridge.\n* **SCR‑UTS‑06 (One‑breath rationale).** The rationale is ≤ 35 words and states the **conceptual invariant** that unifies the row.\n* **SCR‑UTS‑07 (Block parsimony).** Block Plan uses **≤ 7 blocks**; each block’s rows can be recited from memory by a careful reader.\n* **SCR‑UTS‑08 (Strict Distinction).** No row description conflates Method↔MethodDescription, Work↔WorkDescription, Role↔RoleCharacterisation.\n* **SCR‑UTS‑09 (Unified naming).** Each row’s **Unified Tech name** complies with F.5 rules (dual register, minimal generality, morphology); it is not a mere alias of one Context unless justified by an F.9 Bridge with **CL=3**.\n* **SCR‑UTS‑10 (Column discipline).** **Layout A:** all non‑left‑rail columns are **Contexts** with editions. **Layout B:** all non‑left‑rail columns are **discipline columns**. No cross‑use.\n* **SCR‑UTS‑11 (Plain‑twin hygiene).** The **Unified Plain name** appears **once** in the **left rail** (**tv:primary**). Neither BCC (Layout A) nor DC (Layout B) cells may introduce alternative **unified** Plain synonyms; use the ⚡ marker in `Notes` to flag homonym risk where needed.\n\n#### F.17:11.2 - Regression Rules (RSCR‑UTS)\n\n* **RSCR‑UTS‑A (Edition churn).** When a Context’s edition changes, old SenseCells remain addressable; new cells are added; **no silent rewrites**.\n* **RSCR‑UTS‑B (Name stability).** Tech labels change only with a documented F.5 decision; Plain labels may evolve didactically if the Tech name stays.\n* **RSCR‑UTS‑C (Coverage drift).** Adding/removing rows **must not** reduce family heterogeneity below §9.3.\n* **RSCR‑UTS‑D (Loss drift).** If new evidence changes a Bridge’s CL/Loss, the row updates both the CL and the 2–6 word loss note.\n* **RSCR‑UTS‑E (Plain discipline).** No per‑column Plain text appears in BCC/DC columns; any additional Plain aliases are tracked in Annex with **tv:** entries and counted against the alias budget (F.13). \n",
        "canonical_heading_templates_(fill_with_your_contexts/discipline_columns)": "### F.17:12 - Canonical Heading Templates (fill with your Contexts/Discipline columns)\n\n**Layout A — Kernel‑first**\n\n```\n# | Block | FPF U.Type | Unified Tech name | Unified Plain name | Plain‑Twin Governance (PTG) | Twin‑Map Id (LEX) | FPF Description\n  | BCC‑1 (Context name, edition) | BCC‑2 (Context name, edition) | BCC‑3 (Context name, edition) | … (more BCCs from the F.1 cut)\n  | Bridges (CL/Loss) | Unification Rationale | Notes\n```\n\n**Example headers (illustrative, not canonical):**  \n`OMG BPMN 2.0 (2011) | W3C PROV‑O (2013) | ITIL 4 (2020) | W3C SOSA/SSN (2017) | OMG Essence (Language, 2023)`  \n_(Use the actual Contexts from your F.1 cut; always include the edition.)_\n\n**Layout B — Base‑concept pivot**\n_(Plain twin discipline identical: only one **Unified Plain name (tv:primary)** in the left rail; DCs carry senses, not Plain.)_\n\n```\n# | Block | Base concept (EN / RU) | Scale‑map (Σ/Π/μ)\n  | Unified Tech name | Unified Plain name | Plain‑Twin Governance (PTG) | Twin‑Map Id (LEX) | Formal U.Type\n  | DisciplineColumn‑1 (discipline) | DisciplineColumn-2 (discipline) | DisciplineColumn‑3 (discipline) | DisciplineColumn‑4 (discipline) | DisciplineColumn‑5 (discipline)\n  | Unification Rationale | Notes\n```\n\n**Examples of Discipline Columns (illustrative):** Operational Management - IT/Software - Physics - Science/Theory - Mathematics - Literature - Religion.  \n_(Choose 3–5 that fit the thread; do not place Contexts here.)_\n",
        "didactic_aids": "### F.17:13 - Didactic Aids\n\n* **Trip‑wire column (optional).** A ⚡ marker in `Notes` for known homonyms (e.g., *process (BPMN) ≠ process (thermo)*).\n* **DesignRunTag tag (optional).** `design` / `run` hint for concepts whose senses split by time.\n",
        "micro_examples_(one_line_each,_illustrative)": "### F.17:14 - Micro Examples (one line each, illustrative)\n\n*(These illustrate Layout A headings; swap Contexts to match your cut.)*\n\n**Row: `U.Work` (Execution)**\n`Tech=Execution - Plain=run` — “Dated, resource‑consuming occurrence realising a MethodDescription.”\n**BPMN 2.0 (2011)**: *Activity instance* - **PROV‑O (2013)**: `prov:Activity` - **ITIL 4**: *change/incident record (run)* - **SOSA/SSN**: *(context: producer of Observation)* - **Essence (Language)**: *Activity occurrence* - **Bridges**: CL=3 (BPMN≍PROV) - **Rationale**: *All cells denote the concrete happening, not the recipe nor the capability.*\n\n**Row: `U.MethodDescription` (Recipe)**\n`Tech=MethodDescription - Plain=recipe` — “Recorded specification guiding executions.”\n**BPMN 2.0 (2011)**: *Process model* - **PROV‑O (2013)**: `prov:Plan` - **ITIL 4**: *SOP / Work instruction* - **Essence (Language)**: *Activity space/Practice description* - **Bridges**: CL=2 (loss: control‑flow vs intent) - **Rationale**: *All cells denote the codified ‘how’, distinct from both the performer and the run.*\n\n> These rows are examples only; your UTS MUST be compiled from your chosen **Contexts** (Layout A) or **Discipline Columns (DC)** (Layout B) and SenseCells.\n",
        "relations": "### F.17:15 - Relations\n\n* **Builds on:** F.1–F.3 (contexts & local senses), F.7 (Concept‑Set), F.5 (names), F.9 (Bridges).\n* **Feed:** Part A and Part C definitions/examples (row ids used as cross‑refs); teaching bundles (F.16).\n* **Constrained by.** A.7 **Strict Distinction**, A.11 **Parsimony**, **E.10 §6 Twin‑Register Discipline** (Tech/Plain), **E.10.P (prefix registry: tv: / ut:)**, E.10.D1 **Context discipline**.\n",
        "migration_notes": "### F.17:16 - Migration Notes\n\n* **Re‑blocking.** If the Block Plan changes, keep row ids stable; move rows between blocks rather than renumbering.\n* **Context growth.** When adding a new Context, populate SenseCells progressively; do not claim coverage until ≥ 1 row per block cites it.\n* **Name evolution.** Update **Plain** labels freely for pedagogy; change **Tech** labels only via F.5 with clear S‑rules.\n\n",
        "faq_(authoring_hygiene)": "### F.17:17 - FAQ (authoring hygiene)\n\n**Q1. Is the UTS a registry?**\n*A.* No. It is a **didactic publication artifact**. No CRUD semantics, no workflows.\n\n**Q2. Can we collapse two Contexts if their terms look identical?**\n*A.* Only via **F.9 Bridge** with **CL=3**. Identity must be argued, not assumed by spelling.\n\n**Q3. Where do state‑graphs (A.2.5) show up?**\n*A.* In `Notes` or as a dedicated row if the stateful nature of a Role family is central to the thread.\n\n**Q4. How do we show deontic approvals?**\n*A.* The concept rows (`U.SpeechAct`, `U.Commitment`, `U.ServiceClauseClause`, `U.ServiceClauseEvaluation`) make the communicative/epistemic pieces visible; enactment appears in examples, not as sheet mechanics.\n",
        "90‑second_teaching_script": "### F.17:18 - 90‑Second Teaching Script\n\n> “To make our language usable, we publish a **Unified Term Sheet** for each thread. Each **row** is one **unified concept** (a Concept‑Set) named with a **Tech** and a **Plain** label and tied to concrete senses in our chosen **context of meaning**. If two contexts differ, we show an explicit **Bridge** with a **CL score** and a short **loss note**. The rows are grouped into 5–7 **didactic blocks** so the whole sheet fits in working memory. This is not a database; it’s the **one table** a careful mind can hold. From this sheet, everyone—engineers, managers, researchers—can talk precisely about **the same things** across disciplines.”\n",
        "f.17:end": "### F.17:End\n"
      },
      "content": "### F.17:End\n",
      "metadata": {},
      "part": "F",
      "cluster": null
    },
    {
      "id": "F.18",
      "title": "Local‑First Unification Naming Protocol",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## F.18 - Local‑First Unification Naming Protocol\n*Status: normative (Part F, Unification Suite). Audience: engineer‑managers, lead architects, editors of FPF artefacts.* \n",
        "context": "### F.18:1 - Context\n\nNames must carry enough signal for everyday use, yet never smuggle in Cross‑context identities, hidden assumptions, or role/metric clutter. F.18 supplies that naming discipline and weaves it through F.1–F.17: Term Harvesting, Sense Clustering, Role Descriptions, Concept‑Sets, Bridges, Lexical Continuity, Anti‑Explosion control, and the Unified Term Sheet (UTS).\n\n**Scope.** This protocol applies to naming of **any concepts** authored in Part F (U.Types and **local concepts** alike: kinds, roles, services, methods, works, relations, characteristics, states/statuses, etc.). The **U.Types** norms in this section are a **specialization**, not a restriction of scope.\n\n**Purpose of this pattern.** Provide a **human‑legible, context‑anchored naming protocol** that:\n* keeps *local meaning first* and prevents Cross‑context conflation;\n* makes the **kind** of thing explicit (System, Episteme, Role, Service, Method, Work, Decision, Requirement, etc.);\n* integrates smoothly with **Concept-Sets**, **`U.RoleDescription`**, and **Bridges** without requiring any special notation or tooling;\n* supports lifecycle actions (mint, reuse, align, deprecate, split/merge) with a paper trail that managers can audit.\n",
        "problem": "### F.18:2 - Problem\n\nWithout a shared naming protocol inside Part F, the same recurrent failures appear:\n\n1. **Global‑name illusion.** A short label travels from one context to another and is *assumed* to mean the same thing; later, contradictions surface during acceptance or assurance.\n2. **Context drift.** A label gradually changes inside its Context (edition, scope, envelope) without leaving a clean trace; readers argue over “what we meant.”\n3. **Kind confusion.** Names hide *what sort of thing* is being named (System vs Episteme vs Role vs Service, etc.), leading to category errors and brittle integration.\n4. **Threshold‑in‑the‑name.** Numeric limits, duty segregation, or state qualifiers get baked into names (“Critical‑Reviewer‑0.2 mm”), which cannot age or compose.\n5. **Stealth renames.** Quiet label swaps, steered by fashion or politics, sever continuity with earlier evidence, plans, and bridges.\n6. **Explosion by synonyms.** Teams mint many near‑synonyms instead of reusing a Concept‑Set row or creating an explicit Bridge with loss notes.\n\nThese failures erode trust, block reuse, and make Part F machinery (Concept-Sets, `U.RoleDescription`, Bridges) harder to apply.\n",
        "forces": "### F.18:3 - Forces\n\n| Force                                      | Tension to balance                                                                                                            |\n| ------------------------------------------ | ----------------------------------------------------------------------------------------------------------------------------- |\n| **Local truth vs Cross‑context portability**  | The name must “belong” inside one context while remaining referenceable from other contexts through explicit bridges.               |\n| **Human ergonomics vs conceptual clarity** | Short, natural labels help teams move; explicit kind and Context cues keep reasoning sound.                                          |\n| **Stability vs evolution**                 | Names should be durable, yet easy to deprecate or refine without breaking links to past evidence and work.                    |\n| **Brevity vs auditability**                | A compact “badge” for everyday speech, plus an authoritative **Name Card** that records meaning, scope, edition, and lineage. |\n| **Parsimony vs inclusivity**               | Reuse existing Concept‑Set rows where possible; mint new names only when indispensable in the local context.                     |\n",
        "solution": "### F.18:4 - Solution — The Local‑First Naming Protocol\n\nF.18 defines **eight rules** (R‑rules) and **six practices** (P‑practices). Together they produce **Name Cards** that any reader can interpret **ontologically** without guessing, and that slot cleanly into the rest of Part F.\n\n**Path Card (subset of Name Card).** A **Name Card** whose **object‑of‑talk/entity-of-interest** is an **EvidenceGraph Path**: it cites a **PathId** (or **PathSliceId**), **Context**, **ReferencePlane**, **Γ_time**, and any **Bridge id(s) + CL/CL^plane** (with loss notes). Used by **G.6** and **G.10** to make justifications portable on UTS.\n\n#### F.18:4.1 - The Eight R‑rules (normative)\n\n**R1 — Speak every name *with its Context*.**\nA name is **never** context‑free. When you introduce or use a name, **pair it with the Bounded Context** where it lives (the “Context of meaning”), and with the **edition** of that Context if relevant. In everyday speech: “X, *in* Y.” Cross‑context use requires a Bridge; labels alone do not travel. \n\n**R2 — State the ontological *Kind* on the Card.**\nEvery Name Card **must** state the **Kind** (System, Episteme, Role, Service, Method, Work, Objective, Requirement, Decision, Characteristic, etc.). This prevents category errors and keeps Role–Method–Work alignment clean. *Clarification:* this is a **Card requirement**, not a demand that the label string begin with the Kind.\n\n**R3 — Declare the *Purpose / use‑domain* on the Card.**\nIn addition to **Kind**, the Name Card **must** state the intended **Purpose / use‑domain** that situates the concept in practice and signals **which families of contexts** are expected to use it (e.g., mathematical formalism, engineering practice, computer science, systems management). This enables reconstruction of usage from the lexicon and reduces unintended scope drift. *Clarification:* this is a **Card field**; it does **not** require the label string to carry the purpose qualifier.\n\n**R4 — Resolve the name to a *Local‑Sense*.**\nA minted name must resolve to a Local-Sense inside its Context (the result of F.2–F.3). If a name points to a Role Description, state that template and its sense basis. Avoid heavily overloaded surface terms: when needed, prefer concise two-word Tech labels that hint at the intended sense.\n\n**R5 — Use *Twin Registers* (Unified Tech + Plain).**\nProvide two human‑oriented labels on the Name Card, per **E.10** register discipline:\n* a **Unified Tech** label (short, morphology‑stable, neutral in wording);\n* a **Plain** label (reader‑friendly phrasing for managers and subject‑matter experts).\n\nThe **Unified Tech** label is the only one used in **Core** normative prose; **Plain** is for teaching and examples. Both remain **context‑local**; neither establishes Cross‑context identity (that is the job of the **UTS row** and **Bridges**).\n\n**R6 — Keep thresholds and states *out of the name*.**\nDo not encode numeric limits, separation‑of‑duties, or readiness states in the label. Put thresholds on **Method steps** (capability/acceptance), states in **Role State Graphs**, and SoD via **incompatibility** relations. Names carry *what this is* and *which Context claims it*—not *when and how it may act*.\n\n**R7 — Cross‑context only by *Bridge* with loss notes.**\nWhen another Context needs to reference a name, use an **Alignment Bridge** that states the relation (equivalent, narrower, broader, analogous) and its **Congruence Level** with explicit **loss/fit** annotations. Never equate two names by label alone.\n\n**R8 — Make renames and merges *first‑class events*.**\nWhen a label changes, or two labels consolidate or split, record it on the Name Card as a lifecycle action (rename, merge, split, retire) with rationale and dates. Past uses *remain valid as historical facts*; continuity comes from lineage, not silent edits.\n\n#### F.18:4.2 - The Six P‑practices (normative process)\n\n**P1 — Candidate set (*NQD-front* of seed-words).**\nDo **not** pick a label “in one shot”. Build a **small, non-dominated candidate set** (an *NQD-front*, typically 5–10 items) by seeding and varying along:\n**Traditions** — mathematics, physics, engineering, computer science, systems thinking, management, etc. with their typical contexts and situations; use maximum diversity here;\n **Novelty/Familiarity** — from careful **reuse** of established terms to sharper **neologisms** from recent SoTA traditions;  \n **Lexical form** — distinct **head terms** and morpheme families, readability/pronounceability, inflection/declension, transparency.\nUse the **Novelty–Quality–Diversity** discipline from **Part G** to maintain only **non-dominated** candidates; when appropriate, you may implement this via **Γ_nqd.generate (G.18)**. Record the **seeds** and the short rationale in the Card’s notes. Choose final **Unified Tech**/**Plain** labels **from this frontier**; if a strong candidate is discarded, briefly note why.\n\nFor the purposes of **Diversity_P**, group candidates into **head-term families** (same base noun/verb + minor prepositions or case endings). Variants such as *“Reference plane”*, *“Plane of reference”* and *“Referred plane”* **count as one family**, not three distinct candidates. An NQD-front with multiple near-clones from one family **does not** satisfy the diversity requirement. Aim for **≥ 3 distinct head-term families** in the CandidateSet; if the front ends up with fewer families (e.g. due to a very narrow domain or strong AliasRisk on other heads), the Name Card **MUST** record a brief rationale in the NQD-front notes.\n\n**Lexical Q‑axes for the NQD‑front**\nWhen P1 uses **NQD‑CAL (C.18)**, treat the **Quality vector** over candidates as part of the same archive as C.18’s **NQD‑frontier**. Recommended axes (all **ordinal; no arithmetic means**):\n\n * **SemanticFidelity (P — Ontological precision).**\n  *Question.* Does the label verify against the **Minimal Definitional Statement (MDS)** and Concept‑Set row without adding or losing core invariants?\n  *Scale (ordinal; ↑ better).* `{Misleading, Vague, Precise, Exact}` with `Exact ≻ Precise ≻ Vague ≻ Misleading`.  \n  *Link to P2.* When **P2** is run, derive the SemanticFidelity rating from the per‑sense‑seed judgements: candidates with any **core** sense‑seeds classified as `wrong‑prototype` **MUST** be rated **Misleading**; candidates rated **SemanticFidelity ≥ Precise** **SHOULD** have at least a configurable fraction `θ_P` (default `θ_P = 0.7`) of sense‑seeds in `on‑target` and **NONE** in `wrong‑prototype`. Discard candidates that remain **Misleading** after revision.\n\n* **CognitiveErgonomics (S — Sociolinguistic admissibility).**  \n  *Question.* Can the target **RoleEnactors** (engineers, managers) read, pronounce, and recall the label without specialist training?  \n  *Scale (ordinal; ↑ better).* `{Alienating, Jargon, Acceptable, Natural}` with `Natural ≻ Acceptable ≻ Jargon ≻ Alienating`. Prefer labels **≥ Acceptable** in the home Context.\n\n* **OperationalAffordance (O — Morphological/action alignment).**\n  *Question.* Does the morphology of the label hint at its role in **methods/morphisms** (object vs process vs result) and support the required derivational family (noun/verb/participial forms)?\n  *Scale (ordinal; ↑ better).* `{Opaque, Role‑hinting, Action‑aligned}`. Action‑aligned labels make it obvious whether we are naming an **actor**, an **activity**, or an **artifact** (e.g., *Author* vs *Authoring* vs *AuthoredArtifact*).  \n  *Kind‑sensitive cues.* When the **Kind** on the Card is a **Role**, prefer agentive/holder morphology (*…Role*, *…er*, *…or* or local equivalents); when the Kind is **Method/MethodDescription**, prefer verbal or gerundive forms; when the Kind is **Holon**, prefer result nouns, when **Work**, prefer verb. Misaligned morphology (e.g., a Role named with a pure process noun) should be treated as a **penalty on OperationalAffordance** and, if retained for legacy or regulatory reasons, called out explicitly in **Card notes**. See F.5/F.11/F.12 and **LEX‑BUNDLE §8**.\n\n* **AliasRisk (A — Lexical overload).**  \n  *Question.* How likely is a careful reader to import a **wrong sense** from neighbouring FPF artefacts or external canons when they see this string?  \n  *Scale (ordinal; ↓ better).* `{Safe, Context‑dependent, High‑Risk, Overloaded}` with `Safe ≻ Context‑dependent ≻ High‑Risk ≻ Overloaded`. Avoid adopting **Overloaded** labels unless required by legacy and called out explicitly in notes. When C.18’s **DomainDiversitySignature** is available, AliasRisk MAY be refined into a CHR‑typed characteristic with the same polarity.\n\nUse these axes for **Pareto comparison only** (per **C.16** ordinal discipline). Do **not** collapse them into a single scalar score; the NQD‑front is computed over the **vector of lexical Q‑components** together with **Novelty** and **Diversity_P**.\n\n**P2 — Semantic read‑through against archetypal situations.**  \nAlongside the NQD‑front of label candidates, maintain a **small set of 5–10 archetypal situations** (“**sense‑seeds**”) that instantiate the intended use (purpose) across different traditions. For **each** candidate label and each sense‑seed, perform a **read‑through test**:  \n– write **1–2 short example sentences per sense‑seed** (e.g., “In case X, we perform \\<Label\\>”);  \n– classify the outcome, for a careful reader in the home Context, as one of `{too‑narrow, on‑target, too‑wide, wrong‑prototype}`.  \nMaintain, on the Name Card, a small tally per candidate of how many sense‑seeds fall into each class. Use these tallies both to **prune candidates** and to instantiate **SemanticFidelity** (P‑axis): labels with a sustained pattern of `wrong‑prototype` hits on core sense‑seeds **SHALL** be removed from the NQD‑front (or kept only as deprecated aliases with an explicit warning). Candidates rated **SemanticFidelity ≥ Precise** **SHOULD** satisfy the `θ_P` constraint from the SemanticFidelity definition (fraction of `on‑target` seeds) and have no `wrong‑prototype` counts.  \nRecord **rejected candidates** and their **mismatch patterns** in the Name Card’s **NQD‑front notes**.\n\n**P3 — Mint‑or‑Reuse gate (F.8).**\nBefore minting, search your Context’s **Concept‑Set table**. If a row already covers your sense, reuse it and only add a **local label**. If not, propose a **new row** and capture the decision in a brief rationale.\n\n**P4 — Concept‑Set linkage (F.7).**\nEvery Name Card **must** indicate its Concept‑Set row (or record “not applicable” for intentionally Context‑unique names). This is the handle for alignment and anti‑explosion control.\n\n**P5 — UTS registration (F.17).**\nPublish each Name Card to the **Unified Term Sheet** with Context, kind, twin labels, sense anchor, edition, and lifecycle status. Keep the UTS the single, human‑readable table of record.\n\n**P6 — Lifecycle hygiene (F.13).**\nApply the same discipline to renames, splits/merges, and retirements; leave a forward/backward pointer so readers can trace continuity at a glance.\n",
        "the_name_card_(authoring_template,_representation_agnostic)": "### F.18:5 - The Name Card (authoring template, representation-agnostic)\n\n#### F.18:5.1 - Card purpose & mode guard (normative)\n\nTo prevent “post-hoc justification” of intuitively chosen labels, every **Name Card** SHALL declare its\n**CardMode ∈ {MintNew, DocumentLegacy}**:\n\n* **MintNew.** The Card is the **output of an NQD-style lexical search** over a **candidate label set** generated inside\n  the home Context(s), using the lexical Q-tuple `{SemanticFidelity, CognitiveErgonomics, OperationalAffordance,\n  AliasRisk}` together with **Novelty (N)** and **Diversity_P** (per A.0 / C.17–C.18 / B.5.2.1).  \n  – The Card SHALL record:  \n    – a minimal **CandidateSet** (the labels actually evaluated), with **head-term family** tags for each candidate;  \n    – the resulting **NQD-front** of **non-dominated candidates** over ⟨Q-tuple, N, Diversity_P⟩;  \n    – a short **selection note** explaining why the chosen Tech/Plain pair was picked from that front\n      (e.g., “better CognitiveErgonomics at equal SemanticFidelity”).  \n \n  – A single-element NQD-front is permitted only if the Card records a brief rationale why **no alternative candidate\n    survived** the lexical and NQD filters (e.g., legacy constraints, strong AliasRisk on all other options).\n\n* **DocumentLegacy.** The Card documents an **externally imposed legacy label** (e.g., a regulatory or de facto Standard)\n  and its mapping to FPF structures. In this mode the Card MAY omit a full NQD-front, but SHALL:  \n  – state the **legacy source / provenance**;  \n  – either (i) provide at least a **sketched NQD-comparison** of viable internal variants against the legacy label, or  \n    (ii) record a short **out-of-scope rationale** (e.g., “name frozen by law; see cited Standard”) explaining why NQD\n    search is not being used for selection.\n\nFor all **Core-surface naming of U.Types and other canonical FPF concepts**, **MintNew** is the **default** CardMode; using\nDocumentLegacy for such names requires an explicit justification on the Card.\n\nA **Name Card** is the authoritative, human‑readable record of a name inside its Context. It has these fields; teams may add local notes.\n\n1. **Row ID** — the stable, opaque **UTS row identifier** (the identity anchor).\n2. **Twin labels** — **Unified Tech** and **Plain** (per E.10).\n3. **Context of meaning** — the Bounded Context and, if relevant, its edition.\n4. **Kind** — what sort of thing this is (System, Episteme, Role, Service, Method, Work, Objective, Requirement, Decision, Characteristic, etc.). This is an **ontological category**, not a surface‑string prefix. \n5. **Purpose / use‑domain** — the intended area(s) of use (which families of contexts are expected to use it).\n6. **Minimal Definitional Statement (MDS)** — one‑paragraph intended sense in the home context (no tool/process slang).\n7. **Didactic subtitle** — ≤ 12 words that signal pragmatic use.\n8. **Sense reference** — a Local‑Sense reference (how F.2–F.3 clustered it).\n9. **Concept‑Set linkage** — Concept‑Set reference or “not applicable” (with rationale).\n10. **Alignment note** — if a Bridge exists to other Contexts, cite it and record **loss/fit** in plain words (no formulas required on the Card).\n11. **Relation kind** — if the name is for a relation, declare **structural** vs **epistemic** and `validationMode ∈ {axiomatic, inferential, postulate}`. For **structural** relations, provide **Constructive** grounding (`tv:groundedBy → Γₘ.sum|set|slice`). If the name is not for a relation with arity ≥ 2, set this field to “n/a”.\n12. **Manager’s clip** — one‑line “use/avoid” guidance for everyday communication.\n13. **Archetypal situations (sense‑seeds)** — **5-10 short “X‑case” lines** used by **P2** for the semantic read‑through; keep them **edition‑aware** and **context‑local**.\n14. **NQD‑front seeds** — brief rationale for discarded candidates (**include mismatch patterns from P2 and any lexical Q‑scores used in P1**).\n15. **SemanticFidelity/CognitiveErgonomics/OperationalAffordance/AliasRisk** scores for the NQD-front labels.\n16. **Version**  — current status and history of editions.\n17. **Card notes** — optional free text with comments about the name (e.g., recommended translations, etymology, pronunciation). \n\n**Manager’s reading habit.** When two names collide in a meeting, ask for their **Context**, **Kind**, **Purpose/use‑domain**, and **Sense anchor**. If any of those differ, you are comparing different things; switch to **Bridge** talk, not label talk.\n",
        "what_*belongs*_in_the_label—and_what_does_not": "### F.18:6 - What *belongs* in the label—and what does not\n\n**Belongs (keeps the label clean and durable):**\n\n* The **core head word** that names the thing *(the **Kind** is recorded on the Card; the string need not encode it)* (e.g., “Pump”, “Standard”, “Requirement”, “Surgeon”, “Cooling”).\n* A **purpose qualifier** if it is essential to the local sense and stable across editions (e.g., “Cooling” vs “Fuel”).\n* A **scope qualifier** only if it is part of the *meaning* rather than the current plan (“Surgical Ward” rather than dates or batch numbers).\n\n**Does not belong (move elsewhere):**\n\n* **Numbers and thresholds** (put on steps, capabilities, acceptance clauses).\n* **States** (use Role State Graphs and checklists).\n* **Temporal windows** (work plans and history).\n* **Organisational authorisations** (speech acts and assignments).\n* **Imported acronyms** from other Contexts (use Bridges with loss notes instead).\n\n**Quick litmus for authors.** If removing a number, date, or state *does not* change the *meaning* of the thing, it should **not** be in the label.\n",
        "worked_triad_(three_short,_context‑local_examples)": "### F.18:7 - Worked triad (three short, context‑local examples)\n\n*(Names below are illustrative; the same words in other Contexts may mean something else. The point is how the Name Card keeps them clear.)*\n\n#### F.18:7.1 - Industrial operations Context: “Thermal Management - 2026”\n\n* **Kind:** Service\n* **Purpose / use‑domain:** industrial thermal utilities; line‑level planning and operations\n* **Unified Tech label:** Cooling Supply\n* **Plain label:** Chilled water for line B\n* **Sense anchor:** supply of water at defined temperature/flow to boundary B\n* **Concept‑Set:** “Utility service” row; local variant recorded\n* **Alignment note:** Bridge to “Plant Utilities - 2026” notes that “Cooling Supply” there bundles filtration; *loss:* filtration is not guaranteed in this Context\n* **Version:** 20 Feb 2024\n* **NQD‑front (seed candidates):** *Cooling Supply*, *Chilled Water Service*, *Process Cooling*, *Cooling Utility*. **Chosen:** *Cooling Supply* (neutral, morphology‑stable).\n\n**Why it’s good.** The label doesn’t encode temperature or flow limits (those live in acceptance). It names a Service; nobody will confuse it with a pump System or a Method.\n\n#### F.18:7.2 - Clinical Context: “Hospital OR - 2026”\n\n* **Kind:** Role\n* **Purpose / use‑domain:** OR governance and staffing; credentialing and checklists\n* **Unified Tech label:** Surgeon Role\n* **Plain label:** Operating surgeon\n* **Sense anchor:** person who is authorised to perform surgical steps under defined checks\n* **Concept‑Set:** “Clinical roles” row\n* **Alignment note:** Bridge to “Training & Credentialing - 2026” shows partial overlap; *loss:* that Context’s “Senior Surgeon” carries teaching duties that do not apply here\n* **Version:** Feb 2025; renamed‑from “Lead Surgeon” (2025) with rationale: avoided “lead” vs “operating” ambiguity\n* **NQD‑front (seed candidates):** *Surgeon Role*, *Operating Surgeon*, *Primary Surgeon*, *Operating Physician*. **Chosen:** *Surgeon Role* (Kind‑neutral string; Plain clarifies).\n*Lexical Q snapshot (PSOA‑style, informative).*  \n\n| Candidate | SF | CE | OA | A‑Risk | Comment |\n| --- | --- | --- | --- | --- | --- |\n| Surgeon Role | Precise | Acceptable | Role‑hinting | Safe | Neutral head noun; morphology matches **Role** Kind; works across departments. |\n| Operating Surgeon | Precise | Natural | Role‑hinting | Context‑dependent | Reads well, but “operating” competes with “operating theatre/room”; kept as Plain label only. |\n| Primary Surgeon | Vague | Natural | Role‑hinting | Context‑dependent | “Primary” ambiguous (training vs shift); rejected for governance vocabulary. |\n| Operating Physician | Vague | Jargon | Role‑hinting | High‑Risk | Collides with non‑surgical physician roles; rejected despite familiarity in some hospitals. |\n \n**Why it’s good.** No fatigue thresholds or readiness states in the name; those live in the Role’s state graph and checklists.\n\n#### F.18:7.3 - Public service Context: “Civic Services - 2026”\n\n* **Kind:** Requirement\n* **Purpose / use‑domain:** service performance management; public service SLAs\n* **Unified Tech label:** Passport Lead‑Time\n* **Plain label:** Time to issue a passport\n* **Sense anchor:** elapsed time from complete application to issuance\n* **Concept‑Set:** “Service quality requirements” row\n* **Alignment note:** Bridge to “Legal Framework - 2026” records that legal “deadline” has different remedies; *loss:* legal exemptions not carried into this Context\n* **Version:** current\n* **NQD‑front (seed candidates):** *Passport Lead‑Time*, *Issuance Time*, *Service Turnaround*, *Time to Issue Passport*. **Chosen:** *Passport Lead‑Time* (neutral; Plain remains didactic).\n\n**Why it’s good.** Target values (e.g., ≤ 20 days) are not in the label; they live in acceptance clauses.\n\n",
        "conformance_checklist": "### F.18:8 - Conformance Checklist (editor aid) — *Part I: naming & cards* (**non‑normative**)\n\n**CCE‑F18.1 (Context pairing).**\nEvery name used in normative text **must** be paired with its **Context of meaning**. If you cannot name the Context, you do not have a valid name.\n\n**CCE‑F18.2 (Kind clarity).**\nEvery Name Card **must** state the **kind** (System, Episteme, Role, Service, Method, Work, Objective, Requirement, Decision, Characteristic, …). Using labels that hide kind is non‑conformant.\n\n**CCE‑F18.2a (Purpose declared).**\nEvery Name Card **must** state the **Purpose / use‑domain** (families of contexts where the concept is expected to be used). Omitting Purpose is non‑conformant.\n\n**CCE‑F18.3 (Sense anchoring).**\nA minted name **must** resolve to a **Local‑Sense** in its Context. If a sense cannot be stated, label minting is deferred.\n\n**CCE‑F18.4 (Twin registers).**\nEach Name Card carries a **Unified Tech** and a **Plain** label (E.10). Tech appears in **Core** prose; Plain in teaching/examples.\n\n**CCE‑F18.5 (No thresholds/states in labels).**\nNumeric limits, readiness states, and separation‑of‑duties **must not** appear in labels. Put them on steps, checklists, and role algebra.\n\n**CCE‑F18.6 (Bridge‑only travel).**\nCross‑context reuse of a name **must** go through an **Alignment Bridge** with an explicit relation and **loss/fit** notes. Label matching alone is forbidden.\n\n**CCE‑F18.7 (Lifecycle visibility).**\nRenames, splits/merges, and retirements **must** be recorded on the Name Card with dates and rationale. Past occurrences remain valid as historical facts.\n\n**CCE‑F18.8 (Mint‑or‑Reuse gate).**\nBefore minting, authors **must** check the Context’s Concept‑Set table; if a row exists, **reuse** it with a local label unless a documented reason compels a new row.\n\n**CCE‑F18.9 (UTS entry).**\nNames used in normative artefacts **must** appear on the **Unified Term Sheet** with the specified **Name‑Card fields**; include Notes when present).\n\n**CCE‑F18.10 (No cross‑kind labels).**\nDo not reuse the same **Unified Tech label** for different kinds inside one context (e.g., “Cooling” as a Service and as a Method). If unavoidable, add a stable qualifier to disambiguate and record the decision on both Name Cards.\n\n**CCE‑F18.11 (Manager’s clip).**\nEach Name Card **should** carry a one‑line “use/avoid” note to guide everyday speech. Where omitted, editors add it during review.\n\n**CCE‑F18.12 (Anti‑explosion check).**\nIf three or more near‑synonyms for the same Local‑Sense appear in drafts, authors **must** either consolidate to one label or record an intentional synonym pair with use/avoid notes and a plan to converge.\n",
        "normative_standard_(what_must_be_true)": "### F.18:9 - Normative Standard (what must be true)\n\n> This section is binding. It specifies the publication Standard for unification‑oriented names in the Unification Suite (Part F), with **local‑first authority**, **bounded context clarity**, and **one‑way unification** upwards along the ladder. It complements, and does not replace, the structural and epistemic Standards elsewhere in FPF.\n\n**9.1 Local authority & home.**\nEvery unification name has a **single home**: exactly one *Bounded Context* that authors and stewards it. The home is responsible for the definition, examples, and lifecycle of the name. Cross‑context reuse happens by **bridges**, not by relocating the home.\n\n**9.2 Minimum definitional payload.**\nA published name MUST ship with a human‑readable **Minimal Definitional Statement (MDS)** that states the intended sense in the home context, and a **Didactic Subtitle** (≤ 12 words) that signals its pragmatic use. The MDS must be free of process slang and implementation jargon.\n\n**9.3 Row ID + label surfaces.**\nFor each adopted name, the home supplies:\n* a **Row ID** (the opaque UTS identifier — the **identity anchor**), and\n* two **label surfaces**: a **Unified Tech** label (for Core prose) and a **Plain** label (for teaching).\n  Both labels refer to the same underlying sense; **Plain** may simplify terms, not premises.\n\n**9.4 One‑way dependencies.**\nEach rung on the ladder depends only **downwards**: a name at rung *n* can rely on names ratified at rungs ≤ *n*, never sideways or upwards. Cycles are prohibited. If a dependency is not yet ratified at the required rung, the new name remains Draft or Pilot.\n\n**9.5 Local‑first before reuse.**\nTeams MUST first **identify and stabilize the local sense** (within their Bounded Context). **Within the home**, reuse existing **Concept‑Set rows** where they fit (§4.2 **P1**). **Across contexts**, reuse occurs via **Alignment Bridges** that map the local sense to an existing sense elsewhere—without collapsing the local home.\n\n**9.6 Sense, not string.**\nPublication concerns **sense** (intended meaning in context), not the literal string. Synonyms are allowed as **Plain** labels or **aliases** only if they point to the same **Row ID** and pass the conformance checks in §15 (“CC‑F18”). Strings must not be treated as identity.\n\n**9.7 Relation-kind discipline (structural vs epistemic).**\nIf the public name surfaces a **structural relation**, its intended sense **MUST** be backed by *exactly one Constructive trace* in the structural calculus (Compose-CAL) and **SHALL** declare `validationMode=axiomatic` (see E.14). If the name surfaces an **epistemic relation**, Constructive backing is optional; **declare** `validationMode ∈ {inferential, postulate}` and use **Logical/Mapping** and/or **Empirical Validation** as appropriate. **Do not mix relation kinds** inside a single name. *(Do not use “Tier-1/2”; formality is expressed via F per C.2.3.)*\n\n**9.8 Member vs Component.**\nNames that describe collection membership MUST NOT be used to imply part‑whole structure, and vice versa. If both aspects are needed, publish two names with their own MDS and an explicit bridge.\n\n**9.9 Lifecycle states.**\nA name travels through **Idea → Draft → Pilot → Ratified → Deprecated**. Transitions require explicit human review gates. Ratified names carry a clear stewardship contact and date.\n\n**9.10 Anti‑duplication duty.**\nBefore ratification, the home MUST perform a **near‑neighbor review**: identify adjacent names, record the decision to align, merge, or keep separate, and publish the rationale in the name’s record.\n\n**9.11 Local clarity over global neatness.**\nWhen in doubt, prefer **local intelligibility** for practitioners over global symmetry. Global neatness can be achieved later via bridges; loss of local sense is hard to repair.\n\n**9.12 No imported tool terms in Core names.**\nNames and their MDS must not carry terms whose only meaning is tied to operating tools or pipelines. If such terms are unavoidable in pedagogy, confine them to Working-Names and examples with disclaimers.\n\n**9.13 Human‑only conformance.**\nConformance for this protocol is judged by trained human reviewers using the author/reviewer checklists in §14 and the conformance criteria in §15 (“CC‑F18”). Automated heuristics, if any exist in an organization, have no standing in the Core.\n",
        "rationale": "### F.18:10 - Rationale (why this exists and why these rules)\n\n**10.1 Local‑first unlocks velocity without lexical debt.**\nCentralized naming regimes seem tidy but slow learning and create brittle compromises. Local‑first minting lets teams speak clearly **now**; unification comes from disciplined bridges and one‑way dependencies, not from premature centralization.\n\n**10.2 One home lowers ambiguity.**\nNames with “many owners” drift. A **single home** concentrates accountability for sense, examples, and lifecycle, while still enabling broad reuse via alignment bridges.\n\n**10.3 Unified Tech + Plain serve two audiences.**\nEngineers need **precise** wording; managers and stakeholders need **approachable** wording. Splitting the surfaces keeps the same sense while protecting accuracy and pedagogy; both are anchored by the **Row ID**.\n\n**10.4 One‑way ladder prevents conceptual knots.**\nAcyclic dependencies cut off circular definitions and policy deadlocks. The ladder provides a simple mental model: *build on what is already firm*.\n\n**10.5 Relation-kind discipline prevents category errors.**\nPart-whole claims **(structural)** must rest on **Constructive** grounds (`tv:groundedBy → Γₘ.sum|set|slice`, `validationMode=axiomatic`). Experience-based or evaluative relations **(epistemic)** follow assurance rules (**Logical/Mapping**, and **Empirical Validation** when *postulate*), with an explicit `validationMode ∈ {inferential, postulate}`. Mixing relation kinds inside a single name confuses review and invites hidden assumptions. \n\n**10.6 Sense over string reduces false conflicts.**\nDisputes often orbit the string (“we hate that word”). By separating **sense** (what we mean) from **string** (how we say it), the protocol enables peaceful coexistence: keep the **Row ID** constant; use one **Plain** label and, where helpful, a budgeted **alias** per register.\n\n",
        "application_guidance_(how_to_apply,_step_by_step)": "### F.18:11 - Application Guidance (how to apply, step by step)\n\n**11.1 Prepare (30–60 min).**\n\n* Clarify **your Bounded Context** and audience.\n* Collect 2–3 typical user stories that require the name.\n* Scan near‑neighbors in adjacent contexts (see §14.2 Reviewer checklist).\n\n**11.2 Mint locally.**\n\n* Write the **MDS** in plain language, one paragraph.\n* Draft a **Didactic Subtitle** (≤ 12 words): “what this name buys you.”\n* Decide whether the intended **relation kind** is **structural** or **epistemic** (do not mix), and declare `validationMode`.\n\n**11.3 Choose surfaces.**\n\n* **Unified Tech label**: concise, morphology‑stable, neutral; avoid metaphor.\n* **Plain label**: approachable phrasing for non‑specialists.\n* **How to choose**: pick both **from a small NQD‑frontier** (see §4.2 P1 (candidate set), P2(read-through)): diversify by tradition, novelty/familiarity, and lexical form; record discarded contenders and rationale on the Card.\n\n**11.4 Place on the ladder.**\n\n* Verify all dependencies are at the same rung or below.\n* If a dependency is still Draft/Pilot, keep this name at most Pilot.\n\n**11.5 Align, don’t erase.**\n\n* Where overlap exists with another context, propose an **alignment bridge**.\n* Keep your home; record the mapping and any known divergence in reading.\n\n**11.6 Publish and steward.**\n\n* Publish the name with MDS, subtitle, rung, home contact, examples.\n* Schedule a **first refresh**: when should the home examine usage and drift?\n\n**11.7 Deprecate gracefully.**\n\n* If the sense is superseded, publish **Deprecation Notes**: what to use instead, and why. Keep old Working-Names visible long enough to allow safe migration.\n\n**11.8 The “Friday test.”**\n\n* On a busy Friday, could a competent colleague apply the name correctly using only the MDS, subtitle, and two examples? If not, refine before ratification: it too overloaded with meanings to be helpful.\n",
        "examples_(worked_mini‑cases_for_engineer‑managers)": "### F.18:12 - Examples (worked mini‑cases for engineer‑managers)\n\n> These examples are deliberately simple. They show how local‑first minting, one‑way unification, and tier discipline operate together.\n\n**12.1 “Module” vs “Component” (engineering structure).**\n\n* *Home A (Platform)* mints **Component** with MDS: “A physically or logically integrated part whose removal would alter the integrity of the whole.” **Structural**.\n* *Home B (App Team)* mints **Module** with MDS: “A deployable bundle of functionality maintained as a unit.” **Epistemic** (usage practice), not a structural claim.\n* **Unification:** An alignment bridge states: “In Platform, every Component may host one or more Modules; Modules are not Parts.” Dependencies are one‑way: *Module* depends on *Component*; *Component* does not depend on *Module*. No synonymy asserted. Both names remain in their homes.\n\n**12.2 “Incident” vs “Event” (operational sense).**\n\n* *Home C (Operations)* mints **Incident** with MDS: “An unplanned interruption or reduction in the quality of a service.” **Epistemic**.\n* *Home D (Monitoring)* mints **Event** with MDS: “A recorded observation of a state change in a system.” **Epistemic**.\n* **Unification:** Bridge notes: “Some Events are Incidents when they degrade service; not all Events are Incidents.” **Plain** labels (and at most one alias per register) may vary (e.g., “Outage” as an alias for **Incident**), but the **Row IDs** stay distinct. No part‑whole claims are implied.\n\n**12.3 “Customer” vs “Account Holder” (business roles).**\n\n* *Home E (Sales)* mints **Customer**: “A party that receives value from an offering in exchange for consideration.” **Epistemic**.\n* *Home F (Finance)* mints **Account Holder**: “A party legally responsible for an account.” **Epistemic**.\n* **Unification:** Bridge states overlaps and divergence: “A Customer can be an Account Holder; an Account Holder may not be a Customer (e.g., trustee).” The homes retain stewardship; a shared Working-Name “Client” may be used in executive materials with a clear note: **Working-Name only; see Concept-IDs for decisions**.\n\n**12.4 “Batch” vs “Lot” (collection vs integration).**\n\n* *Home G (Manufacturing)* mints **Batch**: “A collection of items produced under shared conditions.” **Epistemic membership**.\n* *Home H (Quality)* mints **Lot**: “An integrated whole packaged and tracked as one item.” **Structural whole**.\n* **Unification:** Bridge notes: “A **Lot** may originate from a single **Batch** or a slice of a Batch; not every Batch yields a single Lot.” Relation mapping: **MemberOf** (Batch membership) vs **ComponentOf**/**Whole** (Lot integration). *Loss note:* membership evidence does **not** imply part‑whole structure; part‑whole structure does **not** imply shared production conditions.\n",
        "anti‑patterns_&_failure_modes_(what_to_avoid)": "### F.18:13 - Anti‑Patterns & Failure Modes (what to avoid)\n\n**13.1 “Global name first.”**\nTrying to coin a single global string before local understanding is mature. **Fix:** mint locally, publish MDS, then align.\n\n**13.2 “Synonym storm.”**\nCollecting many strings without stabilizing the Concept-ID. **Fix:** one Concept-ID per sense; multiple Working-Names only if they truly help didactics.\n\n**13.3 “Process leakage into names.”**\nBurying workflow or tool steps inside the MDS. **Fix:** keep process in method descriptions; keep names about sense, not procedure.\n\n**13.4 “Member‑implies‑part.”**\nLetting collection names induce part‑whole claims. **Fix:** separate names, separate MDS; don’t smuggle structure into membership.\n\n**13.5 “Sideways dependency.”**\nDefining a name by appealing to another Draft at the same rung or higher. **Fix:** depend only downward or postpone ratification.\n\n**13.6 “Alias/Plain drift.”**\nLetting a Plain label or alias accumulate extra meanings absent in the underlying row. **Fix:** periodic label review; prune metaphors that start bending sense; respect the alias budget.\n",
        "assurance_&_conformance_(human‑only_checks)": "### F.18:14 - Assurance & Conformance (human‑only checks)\n\n#### F.18:14.1 - Author checklist (before requesting review).\n\n* [ ] I identified the **home Bounded Context** and audience.\n* [ ] I wrote a clear **MDS** (≤ 1 paragraph) and a **Didactic Subtitle** (≤ 12 words).\n* [ ] I declared the **relation kind** (structural vs epistemic) and the **validationMode**; no mixing.\n* [ ] If **structural**, I can point to **exactly one Constructive trace** that backs the structural claim.\n* [ ] I surveyed near‑neighbors and recorded my decision to align, merge, or keep separate.\n* [ ] I produced both **Unified Tech** and **Plain** labels (per E.10), with the same sense and pointing to the same **Row ID**.\n* [ ] Dependencies point **only downward**; no sideways or upward pulls.\n* [ ] I scheduled a **refresh date** and listed 2–3 usage examples.\n\n#### F.18:14.2 - Reviewer checklist (at the gate).**\n\n* [ ] One home is declared; stewardship contact is clear.\n* [ ] The MDS is free from process jargon and implementation slang.\n* [ ] The declared **relation kind** is justified; **structural** claims are constructively grounded; **epistemic** claims declare `validationMode` and evidential posture.\n* [ ] Member vs Component is respected where relevant.\n* [ ] Alignment bridges are proposed where overlap exists, with explicit reading of convergence/divergence.\n* [ ] The ladder discipline holds: acyclic, downward‑only dependencies.\n* [ ] The **Plain** label does not smuggle extra commitments; **Unified Tech** and **Plain** remain co‑referential and point to the same **Row ID**.\n* [ ] Lifecycle state is accurate (Idea/Draft/Pilot/Ratified/Deprecated) and dated.\n\n#### F.18:14.3 - Lightweight outcomes.**\n\n* **Ratify** (meets all checks).\n* **Pilot** (publish with explicit questions and a refresh date).\n* **Revise** (return to author with targeted gaps).\n* **Merge** (replace with an alignment to an existing name).\n* **Deprecate** (publish successor guidance and sunset plan).\n",
        "conformance_criteria_(normative_“cc‑f18”)": "### F.18:15 - Conformance Criteria (normative “CC‑F18”)\n\n> These are **language‑level** obligations for authors and reviewers. They ensure every unified name is **local‑first**, **bridge‑aware**, and **teachable**.\n\n**CC‑F18‑1 (Context first).** Every unified name **SHALL** be grounded in **local senses** that were harvested and clustered **inside named Contexts** (“context of meaning”) prior to unification. No name may be minted from free‑floating glosses or Cross‑context intuition. Use F.1–F.3 first.\n\n**CC‑F18‑2 (Bridge‑only sameness).** Claims of sameness across Contexts **SHALL** be expressed only via explicit **Bridges** with a stated congruence and loss note. Mere spelling similarity never licenses a unified name. Use F.9.\n\n**CC‑F18‑3 (Twin‑register naming).** Each unified concept **SHALL** carry **two labels**—a **Unified Tech** label (used in Core prose) and a **Plain** label (used for teaching). Labels are chosen per the naming discipline of F.5 and the register rules of **E.10**.\n\n**CC‑F18‑4 (Neutrality of the Tech label).** The **Unified Tech** label **SHALL NOT** be borrowed wholesale from any single source Context where that borrowing would re‑import that Context’s private distinctions. Prefer a **neutral** term; **Cross‑context reuse occurs only via the UTS row and explicit Bridges**. (See F.5 “allowed/forbidden forms”.)\n\n**CC‑F18‑5 (One concept per row, one Tech label per row).** A unified concept **SHALL** be captured as **one Concept‑Set row** in the **UTS**. Exactly **one Unified Tech label** is normative for that row; additional legacy strings are aliases in Annex (budgeted). Use F.7 with F.17.\n\n**CC‑F18‑6 (SenseCell citations).** For each unified name, the **SenseCells** (Context × Local‑Sense) that justify it **SHALL** be cited in the UTS row with **Context name + edition**. Omit edition only if the Context has a single stable edition. See F.17 §6.\n\n**CC‑F18‑7 (Sheet‑level coverage).** Within a thread’s UTS, the **set of rows** carrying unified names **SHALL** collectively cite **≥ 3 distinct Contexts**, ensuring breadth of evidence. Coverage is a property of the **sheet**, not of every single row. See F.17 §6 constraint.\n\n**CC‑F18‑8 (No global words).** In Core text, **“Context” always means `U.BoundedContext`**; **discipline columns** may be used in teaching layouts but **is not** a bearer of meaning. Do not write context‑free claims of sameness. See E.10 and F.17 §5.\n\n**CC‑F18‑9 (Didactic primacy).** A unified name **SHALL** be teachable on **one page**: its **UTS row** + a short narrative that a careful reader can replay (F.16 template). If it cannot be taught concisely, the naming attempt is premature.\n\n**CC‑F18‑10 (No lifecycle connotations).** Names **SHALL NOT** encode imagined “maturity stages” or time‑ordering unless those are part of the concept’s intension. Stages belong in **state‑space** and dynamics narratives, not in names. (See A‑series CHR patterns.)\n\n**CC‑F18‑11 (Strict distinction guard).** Names **SHALL** respect **A.7 Strict Distinction**: do not collapse **Role ↔ Method ↔ Work** or **Status ↔ Description** into one word. Align with F.11/F.12 where relevant.\n\n**CC‑F18‑12 (Change control via F.13).** Renames, splits, merges, and retirements **SHALL** follow F.13’s lexical continuity rules; the UTS remains the canonical public surface for these changes.\n\n**CC‑F18‑13 (Lexical Pareto discipline).** When a Name Card uses **NQD‑CAL (C.18)** to score label candidates, the **chosen Unified Tech label** **SHALL** lie on the **Pareto frontier** of the lexical Q‑tuple `{SemanticFidelity, CognitiveErgonomics, OperationalAffordance, AliasRisk}` (per **C.16** ordinal discipline and P1’s NQD‑front definition), unless an explicit exception is recorded. If authors deliberately select a dominated candidate (e.g., to honour legacy regulation or user muscle memory), the Name Card’s notes **MUST** state the reason for stepping off the frontier.\n\n**CC-F18-13 (NQD-front surfaced, with honest diversity).**  \nWhen a Name Card is in **MintNew** mode, the **candidate label set** and the resulting **NQD-front of non-dominated label candidates** over the lexical Q-tuple `{SemanticFidelity, CognitiveErgonomics, OperationalAffordance, AliasRisk}` **SHALL** be explicitly recorded on the Card (at least as a small table or list), together with the NQD evidence hooks (`DescriptorMapRef`, `DistanceDefRef`, and a brief `Diversity_P` / coverage summary).  \nEach candidate **SHALL** carry a **head-term family** tag; morphological or prepositional variants built on the same head (e.g. “X plane”, “plane of X”, “planar X”) **MAY NOT** be counted as distinct for Diversity_P. The Card **SHALL** indicate how many distinct head-term families are represented on the NQD-front.  \nAn NQD-front with fewer than **three** head-term families is permitted **only** if the Card records why no lexically more diverse alternatives survived the SemanticFidelity / AliasRisk filters (e.g., very narrow domain, frozen legacy idiom).\n\n**CC-F18-14 (Selection from the front only).**  \nThe **Unified Tech** and **Plain** labels published on the UTS row for a unified concept **SHALL** be drawn from the currently recorded **NQD-front** on the Name Card. Publishing a Tech/Plain pair that is **not** on that front (or that is dominated with respect to the declared lexical Q-axes plus NQD) is **non-conformant**, except in explicit **DocumentLegacy** mode as defined in §5.1.\n\n**CC-F18-15 (Mode declaration).**  \nEvery Name Card **SHALL** declare its `CardMode ∈ {MintNew, DocumentLegacy}`. For Core-surface naming of **U.Types** and other canonical FPF concepts, **MintNew** is the default; **DocumentLegacy** is permitted only when recording pre-existing external names and MUST (i) cite the legacy source, and (ii) either attach an NQD-front over viable FPF variants or record a short rationale why NQD search is out-of-scope.\n",
        "anti‑patterns_&_safe_rewrites_(normative)": "### F.18:16 - Anti‑patterns & safe rewrites (normative)\n\n> Each item names a **speaking error** and a **local‑first repair**. Use this as an author’s lint pass before proposing a unified name.\n\n| #  | Anti‑pattern (do **not** say)                           | Why it fails                                                    | Safe rewrite (how to speak)                                                                                         |\n| -- | ------------------------------------------------------- | --------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------- |\n| A1 | “These terms are the same **because they look alike**.” | Cross‑context **spelling** is not evidence of conceptual identity. | “We assert sameness **via a Bridge**; the loss note explains what survives across Contexts.” (F.9)                     |\n| A2 | “Use the BPMN word as our Tech label.”                  | Imports BPMN’s local commitments into the unified term.         | “Choose a **neutral** Unified Tech label; cite BPMN as a **SenseCell** in the row.” (F.5, F.17 §6)                  |\n| A3 | “Merge *process* (recipe) with *process* (execution).”  | Collapses **MethodDescription** with **Work**.                  | “Split the concepts: one row for **MethodDescription**, another for **Work**; align them in examples.” (F.11/F.16)  |\n| A4 | “Our name encodes the lifecycle stage.”                 | Lifecycle phrasing sneaks in time.                              | “Name the **concept**; show **state‑space** changes in examples, not in the label.” (A‑series CHR rationale)        |\n| A5 | “Contextless glossary.”                                 | Violates local‑first; readers re‑globalise.                     | “Publish a **UTS** per thread; each row lists **Contexts** (Contexts+editions).” (F.17)                                |\n| A6 | “We’ll fix synonyms later.”                             | Synonym sprawl grows costs.                                     | “Apply **E.10** rules now: one Tech, one Plain; retire extras via **F.13**.”                                        |\n| A7 | “One mega‑row for everything service‑like.”             | Bundles distinct concepts; harms teachability.                  | “One **Concept‑Set per idea**; group with a **Block Plan** for pedagogy.” (F.17 §7)                                 |\n\n\n\n#### F.18:16.1 - Canonical semantic unpacking for “contract” language (normative; used across FPF)\n\nIn FPF, everyday “contract” talk is treated as shorthand for a bundle of distinct roles. When precision matters (architecture, audit, compliance), authors **SHALL** avoid mapping “contract” to a single concept and instead disambiguate at least:\n\n* **Service / promise clause (`U.ServiceClause`)** — the promised external effect + acceptance criteria (a spec/Standard), not a run (`U.Work`).\n* **Utterance (`U.SpeechAct`)** — the published statement (a Description) that declares or invokes the service clause.\n* **Commitment (`U.Commitment`)** — the deontic bond that binds an accountable agent/role to the service clause.\n* **Work & evidence (`U.Work` + carriers)** — the actual enactment and the traces/metrics used to adjudicate fulfilment.\n\nA “contract” bundle typically spans the whole A.6.B square; route each piece explicitly:\n\n* `L-*`: definitions/invariants of the signature (“what it means”).\n* `A-*`: admissibility/entry predicates (“when it can be applied”).\n* `D-*`: duties/SLAs/penalties and who is accountable (“who is bound to what”).\n* `E-*`: evidence/observability claims (“how fulfilment/violation is adjudicated”).\n\nExample 2 (§F.18:18.2) shows one naming instantiation of this unpacking.\n",
        "migration_notes_(renames,_splits,_merges,_retirements)": "### F.18:17 - Migration notes (renames, splits, merges, retirements)\n\n**M1 — Start from Contexts, not from the old global word.** When inheriting legacy names, first **re‑harvest** terms inside the chosen Contexts (F.2–F.3). Only then decide whether to **reuse** or **mint** (F.8).\n\n**M2 — Preserve reader muscle memory without duplicating meaning.** Keep the **Plain** label close to familiar speech, but make the **Tech** label precise. If a legacy term is overloaded, publish it as a **deprecated alias** in Annexes, not as a second Tech label. (F.13; Part H “Deprecated Aliases”.)\n\n**M3 — Prefer split‑then‑bridge over vague merges.** If one legacy word covers two distinct concepts, **split** into two rows and add a short **relation note** between them (e.g., “recipe vs run”). Do **not** hide the split under a wide new name. (F.7; F.16.)\n\n**M4 — Keep identifiers stable; move rows between blocks.** When the **Block Plan** evolves, move rows rather than renumbering; record the move in the row’s **Notes** field. (F.17 §16.)\n\n**M5 — Upgrade rationale quality with worked examples.** Every rename or split should be accompanied by a **one‑page example** that shows the new row in action across at least **two Contexts**. (F.16; “tell‑show‑show”.)\n\n",
        "worked_examples_(compact)": "### F.18:18 - Worked examples (compact)\n\n> Each example shows **how the Protocol steers naming** so engineers and managers can communicate without hidden Cross‑context leaks.  \n> **Card hygiene shown explicitly:** each example **states the Kind and the Purpose/use‑domain** and **chooses Tech/Plain labels from a small NQD‑frontier** (seed set diversified by traditions, novelty/familiarity, and lexical form; see Part G (G.18)).\n> **Head-term diversity:** each example **MUST** also state the **distinct head-term families** represented in its NQD candidate set (lexical “roots” such as *Recipe*, *Run*, *Episode*, not prepositional/morphological variants). This prevents faking Diversity_P with near-clones of one head.\n\n#### F.18:18.1 - Example 1 — *MethodDescription* vs *Work* (recipe vs run)\n\n* **Context harvest:**\n  *BPMN 2.0 (2011):* “Process model” (recipe) and “Activity instance” (run).\n  *PROV‑O (2013):* `prov:Plan` vs `prov:Activity`.\n  *ITIL:* “Work instruction” vs “Change implementation record.”\n* **Kind:** `U.MethodDescription` (design‑time artifact) **and** `U.Work` (run‑time occurrence).\n* **Purpose / use‑domain:** planning/scheduling vocabulary across BPMN, PROV‑O, ITIL; separates *design recipe* from *execution episode* for governance and telemetry.\n* **NQD‑front (seed candidates):**  \n  *design‑time:* *Procedure*, *ProcessModel*, *MethodSpec*, *WorkflowDefinition*, *Recipe*, *MethodScript*  \n  *run‑time:* *Run*, *Execution*, *Enactment*, *ActivityInstance*, *Job*, *Episode*\n* **Head-term families used (design/run):**  \n  *design-time heads:* {Procedure, ProcessModel, MethodSpec, WorkflowDefinition, Recipe, MethodScript}  \n  *run-time heads:* {Run, Execution, Enactment, ActivityInstance, Job, Episode}\n* **Chosen from frontier (Unified Tech / Plain):**  \n  `U.MethodDescription` / “recipe”; `U.Work` / “run”.  \n  *Discarded highlights:* **Procedure** (collides with governance “procedure/policy”); **Execution** (overloaded in CS/security); \n* **Anti-pattern (for illustration only, non-conformant).**  \n > *Bad CandidateSet (lexically narrow):* {“Reference plane”, “Plane of reference”, “Planar reference”, “Ref. plane v2”}.  \n > All four are one **head-term family** (*plane*). Even if Diversity_P over raw strings looks high (four labels), **head-term diversity is 1**, so this set **fails** the F.18 diversity intent. A conformant Card would either: (a) add labels with other heads (e.g., *Layer*, *Track*, *Band*), or (b) explicitly record why other heads are rejected (AliasRisk, domain idiom) and accept low lexical Diversity_P with a rationale.\n* **Enactment** (speech‑act nuance).\n* **Bridges:** recipe↔run **related**, not identical; loss note “control‑flow vs. execution.”\n* **Why it matters:** Managers can schedule **Work** while authors improve the **MethodDescription**—no category errors. The NQD‑front preserves tradition‑diverse, lexically stable options until a reasoned choice is made. (F.11/F.16; F.17 rows.)\n\n#### F.18:18.2 - Example 2 — *Service* (promise) vs *SpeechAct* (utterance) vs *Commitment* (deontic)\n\n* **Context harvest:**\n  *IT service canon:* “SLA/OLA clause”, “ticket approved”.\n  *Speech‑act theory:* “performative utterance”.\n  *Org governance:* “approval signature”.\n* **Kind:** `U.ServiceClause` (promise), `U.SpeechAct` (utterance), `U.Commitment` (deontic bond).\n* **Purpose / use‑domain:** ops/governance vocabulary connecting ITSM, organizational policy, and pragmatics; separates saying, binding, and promising.\n* **NQD‑front (seed candidates):**  \n  *promise:* *Service*, *Offering*, *Provision*, *CapabilityOffer*  \n  *utterance:* *SpeechAct*, *Performative*, *Utterance*, *Declaration*  \n  *deontic bond:* *Commitment*, *Obligation*, *Binding*, *Duty*\n* **Chosen from frontier (Unified Tech / Plain):**  \n  `U.ServiceClause` / “service (promise)”; `U.SpeechAct` / “utterance”; `U.Commitment` / “commitment”.  \n  *Discarded highlights:* **Offering** (business‑model connotations); **Declaration** (too narrow for performatives); **Obligation** (legalese; narrower than commitment envelope).\n* **Ontology note (informative):**\n  `U.SpeechAct` and `U.Commitment` are defined normatively in Part A (A.2.9 and A.2.8 respectively). This F.18 card is a lexical/NQD anchor, not the ontology definition site.\n\n* **Bridges:** utterance **institutes** commitment; commitment **binds** service clause; no synonymy claimed.\n* **Why it matters:** Status tracking becomes intelligible without pretending that a “service” acts; the NQD‑front yields neutral, cross‑tradition readable labels. (F.12; F.17 blocks D/R.)\n\n#### F.18:18.3 - Example 3 — *Characteristic* names without lifecycle bias\n\n* **Context harvest:**\n  *Quality canon:* “maturity level”; *Performance canon:* “throughput”.\n **Kind:** `U.Characteristic` (measurement names).\n* **Purpose / use‑domain:** CHR‑compatible measurements for planning and performance; bridgeable across engineering and management.\n* **NQD‑front (seed candidates):**  \n  *readiness (ordinal):* *MaturityLevel*, *ReadinessLevel*, *PhaseReadiness*, *TRL*, *ReadinessScore*  \n  *throughput (ratio):* *Throughput*, *Rate*, *ProcessingRate*, *OpsPerSecond*, *FlowRate*\n* **Chosen from frontier (Unified Tech / Plain):**  \n  `U.ReadinessLevel` / “readiness level” (ordinal); `U.Throughput` / “throughput” (ratio).  \n  *Discarded highlights:* **TRL** (tied to a specific scale/tradition); **Rate/OpsPerSecond** (over‑specific units baked in).\n* **Narrative:** Dynamics are shown as **movement in state‑space**, not via lifecycle‑laden names such as “pre‑production process”.\n* **Why it matters:** Prevents lifecycle/time from leaking into labels; the NQD‑front ensures neutrality and recognizability. (A‑series CHR rationale; F.17 §4–§6.)\n",
        "faq_(authoring_hygiene)": "### F.18:19 - FAQ (authoring hygiene)\n\n**Q1. How many Contexts must a naming proposal cite?**\n**A.** The **sheet** for a thread should cite **≥ 3** distinct Contexts overall; an individual row may cite fewer if the concept appears in fewer Contexts. The point is breadth at the **UTS** level, not token‑stuffing rows. (F.17 §6 constraint.)\n\n**Q2. Can a Source Context’s term ever become the Tech label?**\n**A.** Only if its form is **already neutral** and does **not** smuggle in that Context’s private commitments. When in doubt, pick a fresh neutral Tech label and keep the Source term in **SenseCells**. (F.5.)\n\n**Q3. Where do we put discipline‑vantage views like “Operations” vs “Research”?**\n**A.** Use the **discipline columns** in a teaching layout if helpful, but remember: **discipline columns are not Context columns** and carry no editions. (F.17 §5.)\n\n**Q4. How do we keep names stable while the story evolves?**\n**A.** Keep **row ids** stable; evolve placement via the **Block Plan** and record moves in **Notes**. Use F.13 for renames/splits/merges. (F.17 §16; F.13.)\n\n**Q5. What if two teams insist on different Tech labels for the same concept?**\n**A.** Publish **one** Tech label; treat the other as a **deprecated alias** (Annex). Bridge their local senses on the row. (F.13; Part H.)\n\n",
        "90‑second_teaching_script_(for_engineer‑managers)": "### F.18:20 - 90‑second teaching script (for engineer‑managers)\n\n> “**Local‑first** means we start in **context of meaning**—we harvest terms **inside** each Context and only then unify. A unified name is a **teachable promise**: one **Tech** label for precision, one **Plain** label for outreach. Its **row** in the **UTS** shows where the idea lives in real disciplines (the **SenseCells**) and how those Contexts connect (explicit **Bridges** with a brief loss note). We never equate terms by spelling; we argue sameness with a **bridge**. We also never bake stages or actors into names—those belong to **dynamics** and **roles**, not labels. When the story changes, we evolve names with **lexical continuity** rather than re‑inventing words. The result is a vocabulary managers and engineers can **hold on one page** and use the same way across projects.”\n",
        "acceptance_harness_(scr/rscr)_for_f.18": "### F.18:21 - Acceptance Harness (SCR/RSCR) for F.18\n\n**Purpose.** Provide auditable, notation‑independent checks that a proposed unified name (and its publication on a UTS line) satisfies the **local‑first** unification discipline. The harness extends the general unification checks in **F.15** with **naming‑specific** obligations.\n\n#### F.18:21.1 - Static Conformance Rules (SCR‑UNIFY)\n\n| ID                                                                                                                                                                                                       | Requirement (normative “SHALL/SHALL NOT”)                   | Why this exists (conceptual)                                 | Where this is reflected |\n| -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------- | ------------------------------------------------------------ | ----------------------- |\n| **SCR‑U‑01 (Row‑first).** A unified Tech/Plain name **SHALL** be published **only** on a **Concept‑Set row** whose cells are SenseCells drawn from declared Contexts. No free‑floating names.               | Names are *lenses* onto a defended **row**, not vice‑versa. | **F.7** row‑as‑unit; **F.17** UTS row discipline.            | §F.7; §F.17             |\n| **SCR‑U‑02 (Bridge‑only equivalence).** Cross‑context sameness **SHALL** be claimed **only** via an explicit **Bridge** with a relation kind and **CL** + loss/fit note.                                    | Prevents “string‑match identity”.                           | **F.9** Bridges; **F.0.1** principles.                       | §F.9                    |\n| **SCR‑U‑03 (Neutral Tech).** The **Unified Tech** label **SHALL** be **neutral**—not lifted wholesale from any single Context **unless** the row’s Concept‑Set shows exact identity.                        | Avoids importing a local worldview as global.               | **F.5** naming neutrality; **F.17** 9.8 naming neutrality.   | §F.5; §F.17             |\n| **SCR‑U‑04 (Twin registers).** Each row **SHALL** carry **Tech** and **Plain** names with the Part E register discipline; Plain is teacher‑friendly, Tech is morphology‑stable.                          | Satisfies didactic primacy without jargon creep.            | **E.10** registers; **F.5** naming rules.                    | §E.10; §F.5             |\n| **SCR‑U‑05 (No window‑in‑name).** Variations by **time/phase/scale** **SHALL** be handled by **applicability windows** on **Statuses** (or examples), **NOT** by baking modifiers into the unified name. | Prevents type/status explosion by adjectives.               | **F.10/F.12** windows; **F.14** explosion guard.             | §F.10; §F.12; §F.14     |\n| **SCR‑U‑06 (Heterogeneity).** A UTS block **SHALL** demonstrate **≥ 3** independent domain families across its rows, or an explicit Bias‑Annotation shall scope the claim.                               | Enforces trans‑disciplinary reach or honest scope.          | **F.17** invariants 3; **E.8** Bias‑Annotation.              | §F.17; §E.8             |\n| **SCR‑U‑07 (Member≠Component sanity).** Names **SHALL NOT** imply holarchic composition when the row unifies **collections**; keep **MemberOf** distinct from **ComponentOf**.                           | Stops structural category errors.                           | Part F principles / anti‑patterns.                           | §9.8; §13               |\n| **SCR‑U‑08 (One‑breath rationale).** Each row **SHALL** include a **single‑sentence** Unification Rationale that states **why** the cells denote the same thing despite wording differences.             | Keeps the argument visible and auditable.                   | **F.17** invariant 7.                                        | §F.17                   |\n| **SCR‑U‑09 (Alias budget).** Per register, legacy aliases on a unified name **SHALL** be **≤ 1**; additional legacy labels go to Annex/Glossary.                                                         | Controls lexical drift while preserving continuity.         | **F.13** alias budget rule.                                  | §F.13                   |\n| **SCR‑U‑10 (No Cross‑context rename).** A rename **SHALL** occur **within** the same Context or same row; Cross‑context “renames” are **prohibited**—use Bridges.                                                 | Keeps locality intact; forbids silent conflation.           | **F.13** continuity; **F.9** Bridges.                        | §F.13; §F.9             |\n| **SCR‑U‑11 (Semantic read‑through).** A unified Tech/Plain name **SHALL** pass a **semantic read‑through**: the Name Card lists **5–10 diverse NQD archetypal situations** and the **NQD‑front notes** record rejected candidate and their **mismatch patterns**. | Prevents labels that mislead across the intended situations; ties lexical choice to demonstrated use. | §F.18 §4.2; §F.18 §5. | §F.18 |\n\n#### F.18:21.2 - Regression Rules (RSCR‑UNIFY)\n\n| ID                                                                                                                                                                       | Regression duty across editions                                        | Effect |\n| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------- | ------ |\n| **RSCR‑U‑E01 (Edition drift).** When a source Context updates, re‑validate the row: stable sense ⇒ **rename/alias**; changed sense ⇒ **split/merge** rows; never overwrite. | Preserves truthfulness without erasing history. **F.13** RSCR.         |        |\n| **RSCR‑U‑E02 (CL honesty).** Bridges **SHALL NOT** increase their CL (claiming stronger sameness) without new witnesses; **SHOULD** reduce CL when editions diverge.     | Guards against optimism bias in equivalence. **F.17** migration cues.  |        |\n| **RSCR‑U‑E03 (Alias creep).** Periodically prune aliases to the **≤ 1** budget per register.                                                                             | Maintains narratively crisp UTS. **F.13** RSCR‑Alias.                  |        |\n| **RSCR‑U‑E04 (Name neutrality check).** If the Unified Tech label is traceable to one context’s idiom, re‑justify neutrality or retitle the row.                            | Keeps the name “ours,” not “theirs.” **F.17** 9.7–9.8.                 |        |\n| **RSCR‑U‑E05 (Window misuse).** Reject newly proposed types that are really **windows** on an existing Status/Role.                                                      | Prevents explosion by adjectives. **F.14** S14/E11 patterns.           |        |\n",
        "migration_&_deprecation_notes_(informative,_naming‑specific)": "### F.18:21 - Migration & Deprecation Notes (informative, naming‑specific)\n\n1. **Start from rows, not strings.** When consolidating legacy labels, **build or revisit the Concept‑Set row** first; only then pick the **Unified Tech/Plain** names. This keeps **meaning** primary. **(F.7, F.17)** \n2. **Prefer alias over merge.** If the *sense* is stable but the label misleads, **rename and retain one alias**; if the sense changed, **mint a new row** (no retrofits). **(F.13)**\n3. **Resist modifier types.** New adjectives (e.g., *Peak*, *Remote*, *Night*) usually belong to **windows** or **examples**, not to the unified name. **(F.10/F.12/F.14)** \n4. **Keep neutrality visible.** If stakeholders push a brand‑coloured label, document why the chosen **Unified Tech** is **neutral** and include the brand as an **alias** in Glossary/Annex. **(F.5, F.17)** \n5. **Don’t globalise a Context.** Never move a Context label into the unified name as if it were universal. Use **Bridges** to relate Contexts, with an explicit **loss note**. **(F.0.1, F.9)** \n",
        "faq_(authoring_hygiene_for_engineer‑managers)": "### F.18:22 - FAQ (authoring hygiene for engineer‑managers)\n\n**Q1. Can we reuse a dominant industry term as the Unified Tech name?**\n**A.** Only if the row’s Concept‑Set shows **exact identity** across Contexts; otherwise pick a **neutral** Unified Tech and list the industry label as an **alias** in the Glossary. **(F.5, F.17)** \n\n**Q2. Two terms look identical across Contexts—may we skip Bridges?**\n**A.** No. **Sameness is argued, not spelled.** Publish a **Bridge** with relation kind and **CL** plus a short **loss/fit** note. **(F.9, F.0.1)** \n\n**Q3. When do we mint a new U.Type vs. add a new row vs. add an alias?**\n**A.** Use **F.8 Mint‑or‑Reuse**: if the *intension* changes, **new U.Type**; if the *same thing* spans new Context, **new row**; if only the label misleads, **alias/rename**.\n\n**Q4. Our team keeps proposing “qualified roles” (e.g., *Night‑Operator*). What do we do?**\n**A.** Keep the **Role** unified and express qualifiers as **windows** on **Statuses** or as **example context**. This follows **F.14** and **F.12**.\n\n**Q5. Can we compress two near‑equivalent rows into one to “simplify the sheet”?**\n**A.** Only if the **one‑breath rationale** remains true after review and the Bridges support equivalence with the same or stronger CL; otherwise keep **two rows** with explicit differences. **(F.17, F.9)** \n",
        "didactic_distillation_(90‑second_script)": "### F.18:23 - Didactic distillation (90‑second script)\n\n> **“Name on a row, never on a whim.”** In FPF we **speak on rows, not on vibes**: a **Name Card** ties each Tech/Plain pair to a concrete Context, Concept‑Set row, and SenseCells, with a small **NQD‑front** of rejected alternatives. This gives you **bridged precision** without losing **local comfort**. **Your UTS is the one page a careful mind can hold.**\n",
        "sota‑echoing_(post‑2015_practice_alignment)": "### F.18:24 - SoTA‑Echoing (post‑2015 practice alignment)\n\n* **Neural WSD & sense evaluation (2015→).** P2’s sense‑seed read‑through is a human‑scale analogue of modern **word‑sense disambiguation** evaluation, where models are scored by the fraction of examples assigned the correct sense and by error profiles across sense inventories. Post‑2015 neural WSD benchmarks (e.g., multi‑domain evaluations reported in ACL venues) motivate the explicit `{too‑narrow, on‑target, too‑wide, wrong‑prototype}` labelling and the `θ_P` threshold for **SemanticFidelity**.\n* **Quality‑Diversity & multi‑objective search (MAP‑Elites, NSGA‑II families, 2015→).** P1’s NQD‑front and **CC‑F18‑13** follow the same discipline as QD/NSGA‑style archives in optimisation: maintain a **set of non‑dominated candidates** over a vector of objectives rather than a single scalar score. The lexical Q‑tuple `{SemanticFidelity, CognitiveErgonomics, OperationalAffordance, AliasRisk}` is deliberately small so that human authors can inspect a Pareto frontier in the same way QD methods expose illumination archives.\n* **Design‑space exploration & idea ranking (mechanical/industrial design, 2018→).** The PSOA‑style Name‑Card tables echo contemporary **design‑space ranking** practice, where candidate concepts are compared on diversity and quality rather than on a single “score”. Explicitly surfacing *why* one candidate dominates another improves auditability and supports teaching, mirroring recent work on ranking ideas for both diversity and quality in engineering design.\n* **Semantic transparency & morphology in interfaces and code (HCI and PL practice, 2015→).** The strengthened **OperationalAffordance** guidance aligns with empirical results on **semantic transparency** of labels and identifier names: morphology that cues “actor vs activity vs artifact” improves comprehension and reduces error rates in both UIs and source code. F.18 turns these findings into a simple naming discipline (agentive forms for Roles, verbal forms for Methods, result nouns for Work/Artifacts) that can be enforced on Name Cards.\n",
        "relations": "### F.18:25 - Relations\n\n**Builds on:**\n**F.0.1** Contextual Lexicon Principles (local meaning; bridge‑only Cross‑context claims). **F.1–F.3** Contexts → term harvesting → local sense clustering. **F.5** Naming discipline. **F.7** Concept‑Set construction. **F.8** Mint‑or‑Reuse decision lattice. **F.13** Lexical continuity (renames/aliases/splits/merges). **F.14** Anti‑explosion controls (bundles, SoD, windows). **F.15** SCR/RSCR harness. **F.17** UTS as the publication surface.  \n\n**Constrains:** \nAll patterns that propose or consume unified names and rows in Part F; any Part A/C pattern that cites U.Types on UTS rows inherits these naming duties (through the UTS linkage), while keeping **structural/epistemic/temporal** aspects distinct per Part E authoring rules.\n\n**Coordinates with.**\n**A.17/A.18** for measurement lexicon when rows concern measurable notions (Characteristic/Scale/Level/Coordinate vocabulary), ensuring neutral naming aligns with canonical terms and eases external alignment via Bridges.  \n",
        "f.18:end": "### F.18:End\n\n# Part G – Discipline SoTA Architheory Kit\n"
      },
      "content": "### F.18:End\n\n# Part G – Discipline SoTA Architheory Kit\n",
      "metadata": {},
      "part": "F",
      "cluster": null
    },
    {
      "id": "G.0",
      "title": "Frame Standard & Comparability Governance (CG‑Spec)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## G.0 - Frame Standard & Comparability Governance (CG‑Spec)\n\n**Tag:** Architectural pattern (foundational Standard; constrains G.1–G.5)\n**Stage:** *design‑time* (establishes comparison legality & evidence minima; constrains run‑time gates)\n**Primary hooks:** **USM / Scope (G)** (A.2.6), **Design–Run split** (A.4), **Evidence carriers** (A.10), **Assurance F–G–R with Γ‑fold** (B.1, B.3), **Change rationale** (B.4), **MM‑CHR discipline** (A.17–A.19/C.16), **Creativity‑CHR** (C.17), **NQD‑CAL** (C.18), **E/E‑LOG** (C.19), **Method‑SoS‑LOG** (C.23), **Bounded Contexts & Bridges + CL** (F.1–F.3, F.9), **Concept‑Sets** (F.7), **Mint/Reuse** (F.8), **RSCR** (F.15), **Lifecycle/Deprecations** (F.13–F.14), **UTS & Naming** (F.17–F.18), **No tool lock‑in** (E.5.1–E.5.3), **Lexical rules** (E.10), **GateCrossing visibility hooks** (E.18; GateChecks **A.21**; Bridge+UTS **A.27**; BridgeCard **F.9**).\n\nComparability Governance is the design‑time standard that fixes, for a given `CG‑Frame`, **what comparisons and aggregations are lawful**, under which declared **normalization/UNM** assumptions and **evidence minima**, so that run‑time publication and selection remain auditable. CG constrains run‑time gate checks (E.TGA/E.18) by supplying the referenced `CG‑Spec` artifacts and pinned editions; CG itself is not an admissibility mechanism.\n\n**Didactic subtitle:** “Design‑time rules for safe, auditable comparison.”\n",
        "intent_(informative)": "### G.0:1 - Intent (informative)\n\nProvide a **single, normative Standard** for a **CG‑Frame** that (a) names *what may be compared or aggregated*, (b) defines **lawful ScaleComplianceProfile (SCP) and aggregators** over CHR‑typed data, and (c) sets **minimal evidence** and **trust folding** rules so that all downstream generation (G.1), harvesting (G.2), measurement authoring (G.3), calculus (G.4), and dispatch/selection (G.5) operate **safely, comparably, and in‑scope**.\n",
        "problem": "### G.0:3 - Problem (informative)\n\nRecurring pains without a frame‑level spec:\n\n* **Undefined comparison set.** Teams compare quantities without a declared **Characteristic/SCP** basis.\n* **Illicit arithmetic.** Ordinals get averaged; units are mixed; polarity flips are implicit.\n* **Opaque evidence minima.** Numeric gates run on *whatever is at hand*, not on declared **KD‑CAL lanes** or carriers.\n* **Trust blur.** Cross‑Context reuse lacks **CL penalties** and Γ‑fold rules; selection **R_eff** is not auditable.\n* **Inconsistent scope.** Global claims leak; boundaries and *describedEntity* are not attached to names.\n",
        "forces": "### G.0:4 - Forces (informative)\n\n* **Pluralism vs. comparability.** Rival Traditions must co‑exist while enabling lawful comparison.\n* **Expressiveness vs. safety.** Rich **SCP profiles** and aggregators vs. **MM‑CHR** legality.\n* **Locality vs. portability.** Context‑local semantics with explicit **Bridges + CL** when crossing.\n* **Assurance vs. agility.** Minimal evidence gates that are strong enough to matter, light enough to adopt.\n* **Design‑time vs. run‑time.** Keep Standards and thresholds **design‑time**; run‑time only *uses* them.\n",
        "solution": "### G.0:5 - Solution — **The CG‑Spec Standard**\n\nA **notation‑independent** object, published to **UTS**, that fixes *what is comparable, how, and under which evidence and trust minima*.\n\nFor top‑level disciplines, CG‑Spec is restricted to comparability, tolerances, and aggregation surfaces where sufficient basis exists (KD‑CAL lanes, Worked Examples, Γ‑fold reliability). CG‑Spec MUST NOT introduce “universal” cross‑Tradition scoring; run‑time choice belongs to the G.5 selector under CHR/CAL legality.\n\n#### G.0:5.1 - CG‑Spec - Data Model (normative)\n\n```\nCG‑Spec :=\n⟨ UTS.id, Edition, Context, Purpose, Audience,\n  Scope := USM.ScopeSlice(G) ⊕ Boundary{TaskKinds, ObjectKinds},\n  describedEntity := ⟨GroundingHolon, ReferencePlane ∈ {world|concept|episteme}⟩,\n  WorldRegime? ∈ {prep|live}, // refines ReferencePlane=world; affects acceptance/telemetry; introduces no new planes\n  ReferenceMap := minimal map{term/id → UTS|CHR|G.2} (stabilizes naming & describedEntity),\n\n  ComparatorSet := [ComparatorSpec…],                 // finite, explicit\n    // MUST NOT encode illegal scalarisation of partial orders;\n    // lawful forms include: ParetoDominance, Lexicographic over typed traits,\n    // medoid/median on ordinals; WeightedSum only on interval/ratio with unit alignment (CSLC‑proven)\n  Characteristics := [CHR.Characteristic.id…],        // must exist in G.3 pack\n\n  SCP := map Characteristic.id → ⟨\n    ScaleTypes, Polarity ∈ {↑|↓|=}, Unit alignment rules,\n    CoordinatePolicy?, GuardMacros ⊇ {UNIT_CHECK, ORD_COMPARE_ONLY, FRESHNESS_CHECK, PLANE_NOTE, PHI_CL_MONOTONE(policy_id), METRIC_EDITION_REF(id)?},\n    AggregationSpecs\n  ⟩,\n\n  MinimalEvidence := map Characteristic.id → ⟨\n    KD‑CAL lanes ⊆ {TA,LA,VA}, Carriers ⊆ A.10,\n    Sample/Replication minima, Freshness/HalfLife (PathSlice window), ReferencePlane,\n    Bridge allowances (CL thresholds, CL^plane policy id), I/D/S layer exposed to SCR fields,\n    FailureBehavior ∈ {abstain | degrade.order | sandbox},\n    UnknownHandling := tri‑state {pass|degrade|abstain} with explicit binding to Acceptance (no silent `unknown→0` coercion)\n  ⟩,\n\n  Γ‑fold := ⟨default:=weakest‑link | override(proof_refs, monotonicity, boundary)⟩,\n  CL‑Routing := map Bridge.CL → penalty on R_eff only (F invariant),\n  Φ := ⟨ Φ(CL) MUST be monotone, bounded (R_eff ≥ 0), and table‑backed; optional Φ_plane for {world|concept|episteme} crossings (unaffected by WorldRegime) ⟩,\n  AcceptanceStubs := [AcceptanceClause template…],    // templates only; **context‑local thresholds live in CAL.Acceptance (G.4)**\n  \n  E/E‑LOG Guard := ⟨explore↔exploit budgets, probe accounting, NQD constraints⟩,\n  Illumination := ⟨\n    Q_refs ⊆ Characteristics, D_refs ⊆ Characteristics,\n    QD_score := definition (typed), ArchiveRef := U.DescriptorMapRef (Tech; d≥2),\n    InsertionPolicy, Edition := ⟨DHCMethodRef.edition, DistanceDefRef.edition⟩,\n    DominanceDefault := exclude, PromotionPolicy? := lens/policy‑id\n  ⟩, // IlluminationSummary is a report‑only telemetry summary over Diversity_P (coverage/QD‑score) and informs exploration; not part of dominance unless PromotionPolicy (lens/policy‑id) is named\n\n RSCR := testset{\n    illegal_op_refusals,\n    unit/scale checks,\n    freshness windows,\n    partial‑order scalarisation refusals,\n    threshold semantics,\n    CL→R_eff routing,\n    refuse degrade.order on unit mismatches (MM‑CHR)\n },\n\n  Naming := UTS Name Cards (required fields per F.17/F.18) with **Unified Tech** and **Plain** labels, Concept‑Set linkage, Bridge loss/fit notes, and lifecycle,\n  Lifecycle := ⟨owner, DRR link, refresh cadence, decay/aging, deprecation + lexical continuity⟩,\n  Provenance := ⟨carrier types, SoTA pack refs (G.2), DRR/SCR linkage⟩\n⟩\n```\n\n**Notes:**\n* `Characteristics[]` are pointers—no measurement semantics live here; those are authored in **G.3**.\n* `SCP` binds **what** aggregations/comparisons are lawful **for this Frame** over those characteristics (using **G.3 AggregationSpecs**).\n* `MinimalEvidence` is the **gate** consumed by G.1/M4 and G.5: if not met, numeric comparisons **degrade** to safe forms or **abstain** (see **§7.13**).\n* `Γ‑fold` must state monotonicity and boundary behavior if not weakest‑link; proofs/anchors go to **CAL.ProofLedger** (G.4); legality constraints summarized in **§7.5–§7.7**.\n* **Legality proof.** Units/scale/polarity legality **MUST** be proven via **MM‑CHR/CSLC** before any aggregation; **no silent `unknown→0` coercion**; thresholds live **only** in Acceptance (G.4) — see **§7.7** and **§7.8**.\n* `CL‑Routing` sends penalties to **R_eff only**; **F** is invariant under Bridging.\n* **Illumination default.** **IlluminationSummary** is a **report‑only telemetry summary** over **Diversity_P** (coverage/QD‑score). It informs exploration/refresh and tie‑breaks; it is **not** in the dominance set unless a **PromotionPolicy (lens/policy‑id)** is named.\n* **Partial orders.** Where only a partial order is lawful, **do not force total orders** in `ComparatorSet`; downstream (G.5) returns explicit non‑dominated sets.\n* **Guard macros.** Recommended set includes: `UNIT_CHECK`, `ORD_COMPARE_ONLY`, `FRESHNESS_CHECK`, `PLANE_NOTE`, `PHI_CL_MONOTONE(policy_id)`.\n\n#### G.0:5.2 - SoTAPalette\n\n1. **SoTAPalette (I).** Intensional profile of a discipline’s Traditions and method‑families with intentions and tolerances:\n* admissible TaskKinds/ObjectKinds,\n* required CHR types,\n* characteristic operators/proofs,\n* typical CL bridges (with known loss).\n\n2. **SoTAPaletteDescription (D).** Publication of the palette: \n* metadata of Traditions, \n* Operator & Object Inventory, \n* Bridge Matrix with CL/loss notes, \n* micro‑examples, \n* UTS drafts. \n \nThis is the “SoTA Synthesis Pack” of G.2 and must be citable in G.5 decisions.\n\n3. **SoTAPaletteSpec (S).** Minimal gates on completeness/quality of a palette: \n* coverage of Traditions/sub‑tasks, \n* minimum replications/carriers across KD‑CAL lanes (TA/LA/VA), \n* explicit CL penalties for reductions, and bans on illegal operations (e.g., ordinal ≠ mean). \n \nThese gates are consumed by CG‑Spec.Acceptance and Γ‑fold where cross‑Tradition comparison/aggregation is attempted\n\n#### G.0:5.3 - Tradition\n\n* In this framework, **“scientific/engineering Tradition/lineage/tradition” is an epistemic kind**: **`Tradition`** (I) with its **`TraditionDescription`** (D) and **`TraditionSpec`** (S).\n* The **community of people** behind a Tradition is modeled separately as an optional **`TraditionCarrier`** that _carries_ a `Tradition` but does **not** determine cross‑Tradition comparability rules.\n* In the **SoTA‑palette**, entries are **`Tradition`** items (epistemic) with their D/S artifacts; the palette composes them and exposes bridges/limits. The Dispatcher (G.5) selects among these entries under CHR/CAL constraints; CG‑Spec (G.0) only governs comparability/Γ‑fold where justified.\n\nTradition (I): an epistemic formation (Tradition‑of‑thought, lineage) identified by its method family:\n- operator set and admissible transformations,\n- admissible TaskKinds/ObjectKinds,\n- necessary CHR types and proof idioms,\n- canonical CL bridges and stated limits,\n- stance on measurement scales and allowed algebra.\n(Notes: This is an epistemic kind, not a social group. See §TraditionCarrier for the social carrier.)\n\nTraditionDescription (D): the documentary corpus of a Tradition:\n- charter/lineage and key references,\n- Operator & Object inventory with CHR preconditions,\n- Bridge Matrix (CL) with loss and validity regions,\n- Worked Examples with CHR annotations,\n- UTS drafts for typical tasks,\n- KD‑CAL lane coverage and replication notes,\n- explicit anti‑operators / banned reductions (e.g., ordinal ≠ mean).\n\nTraditionSpec (S): inclusion gates for a Tradition to be considered comparable/aggregable:\n- minimum replication across KD‑CAL lanes (TA/LA/VA),\n- declared CHR prerequisites and proof idioms,\n- declared CL penalties/conditions for any cross‑Tradition bridge,\n- Γ‑fold contribution rule (how evidence accumulates),\n- prohibitions on illegal scale algebra.\nThese S‑level gates are referenced by CG‑Spec.acceptance only where aggregation/comparison is attempted; otherwise the Tradition remains descriptive.\n\nTraditionCarrier (I): role of a social/organizational system (people, labs, consortia) that holds a Tradition. Carriers supply replication capacity and provenance but have no normative authority over cross‑Tradition aggregation rules.\n\nΓ‑fold: an evidence/reliability fold that aggregates only along declared commensurate dimensions; includes penalties from CL bridges and lane‑mismatch factors. Γ‑fold parameters MUST be cited to KD‑CAL lanes and Worked Examples; when absent, aggregation is disallowed.\n\nDefault composition: weakest‑link; admissible overrides: {min‑k‑of‑n, harmonic, conservative Bayesian}; override requires CAL.ProofLedger refs\n\n#### G.0:5.4 - Authoring Steps (S1–S6)\n\n**S1 - Frame Charter (Scope & describedEntity)**\nDeclare **Context**, **USM scope**, *describedEntity* (`GroundingHolon`, `ReferencePlane`), TaskKinds/ObjectKinds; record boundary examples and non‑examples.\n\n**S2 - ComparatorSet & SCP Draft**\nList **which** comparisons/aggregations the Frame intends (e.g., dominance, lexicographic, Pareto, affine sums on interval/ratio with unit alignment). Bind each comparator to **G.3/AggregationSpecs** and attach **GuardMacros**; capture legality/tolerance assumptions in the CG‑Spec **ScaleComplianceProfile (SCP)**. **Do not** scalarise partial orders; for ordinals, use medoid/median; **WeightedSum is forbidden** on mixed scale types.\n\n**S3 - Characteristics Binding**\nFor each comparison you intend to allow, bind the **CHR.Characteristic id** and required **Scale/Unit/Polarity**; if missing, author in **G.3** or reuse via UTS (F.8). For any numeric encoding of ordinals, publish **CoordinatePolicy** with non‑entitlements.\n\n**S4 - Minimal Evidence Gates**\nPer characteristic, declare **KD‑CAL lanes** (TA/LA/VA), required **carriers** (A.10), freshness/half‑life, and **Bridge/CL allowances**. Define **failure behavior**: **degrade to order‑only**, **sandbox**, or **abstain**.\n\nFor unit mismatches specify **sandbox (quarantine) or refuse**; **degrade.order is not permitted for unit mismatches under MM‑CHR**.\n\nMinimalEvidence MUST name **CHR.Characteristics** used by Acceptance/Flows and the **TaskSignature fields** they constrain (by id), so **G.5** can gate **before** selection.\n\n**S5 - Γ‑fold & CL Routing**\nSet default **Γ‑fold** for trust aggregation and the **CL penalty** table. Document proofs or references if overriding weakest‑link.\n\n**S6 - Publication & Tests**\nMint **UTS** Name Cards with twin labels; attach **loss notes** for Bridges. Register **RSCR** tests: (i) refuse illegal ops (e.g., mean on ordinal), (ii) enforce unit/scale checks, (iii) verify freshness/PathSlice handling, (iv) refuse illegal scalarisation of partial orders, (v) verify **CL → R_eff** routing and **Φ(policy‑id)** publication in SCR.\nAcceptance depends on (a) presence of SoTAPaletteDescription (G.2) with attached CHR/CAL evidence (G.3–G.4), and (b) justification of any aggregation via Γ‑fold (reliability fold) with explicit CL loss accounting. Where evidence is insufficient, acceptance MUST fall back to per‑Tradition reporting without cross‑Tradition aggregation.\n",
        "interfaces_—_minimal_i/o_standard_(normative)": "### G.0:6 - Interfaces — minimal I/O Standard (normative)\n\n| Interface          | Consumes                                | Produces / Constrains                                                    |\n| ------------------ | --------------------------------------- | ------------------------------------------------------------------------ |\n| **G.0‑1 Charter**  | CG‑Frame brief, USM scope, SoTA signals | `CG‑Spec.Scope`, `describedEntity`, `ComparatorSet`                            |\n| **G.0‑2 SCP**      | G.3 CHR Pack, AggregationSpecs          | `CG‑Spec.SCP` + guard bindings                                           |\n| **G.0‑3 Evidence** | SoTA carriers (G.2), KD‑CAL norms       | `CG‑Spec.MinimalEvidence`, `Γ‑fold`, `CL‑Routing`                        |\n| **G.0‑4 Publish**  | All above                               | Versioned `CG‑Spec@UTS` + Name Cards, RSCR ids, Lifecycle                |\n| **→ G.1**          | `CG‑Spec`                               | M1/M4 guardrails; abstain/degrade paths wired; M3/M4 scoring legality; Characteristic refs bound (F invariant) |\n| **→ G.2**          | `CG‑Spec`                               | Inclusion/exclusion & Bridge/CL policy for SoTA Synthesis                |\n| **→ G.3**          | `CG‑Spec`                               | Which Characteristics/Scales must exist; legality macros to expose       |\n| **→ G.4**          | `CG‑Spec`                               | Acceptance templates; evidence gates; Γ‑fold/CL routing Standards        |\n| **→ G.5**          | `CG‑Spec`                               | Eligibility gates; minimum **R_eff** checks; degradation/abstain policies; Illumination hooks (ArchiveRef/U.DescriptorMapRef, InsertionPolicy, Edition), publication of **Φ(CL)/Φ_plane policy‑ids** in SCR |\n| **→ G.6**          | `CG‑Spec`                               | EvidenceGraph guard fields (**Φ(CL)/Φ_plane policy‑ids**, freshness windows, **PathId/PathSliceId**) made citable; selectors/audits reference PathIds (no formats mandated) |\n",
        "conformance_checklist": "### G.0:7 - Conformance Checklist (normative)\n\n1. **Context declared.** `CG‑Spec` is published **in** a `U.BoundedContext`; no global claims.\n2. **Comparator set explicit.** Every permitted comparison/aggregation is named and typed; anything else **abstains by default**.\n3. **CHR‑bound.** All compared quantities reference **CHR.Characteristic ids** with declared **Scale/Unit/Polarity**; guard macros attached.\n4. **Minimal evidence published.** Per characteristic: **KD‑CAL lanes**, carriers, freshness, Bridge/CL allowances, and **failure behavior** are declared.\n5. **Γ‑fold stated.** Default **weakest‑link**, or an alternative with proof obligations (monotonicity, boundary).\n6. **CL penalties** routed to R_eff only; F is invariant; **publish Φ(CL)/Φ_plane policy‑ids in SCR** for any penalised claim.\n7. **No illegal ops.** Ordinal **SHALL NOT** be averaged/subtracted; unit mismatches **SHALL** fail fast (MM‑CHR).\n8. **Design/run split.** **AcceptanceStubs** provide templates in **G.0**; all **context‑local thresholds live only in CAL.Acceptance (G.4)**; nothing is hidden in CHR or code paths; manifests are externally inspectable.\n9. **UTS‑ready.** Name Cards minted/reused with twin labels; Bridges carry **CL** and loss notes.\n10. **RSCR wired.** Tests exist for refusal paths, unit/scale checks, threshold semantics, and CL→R_eff routing.\n11. **Lifecycle set.** Refresh cadence and decay policy declared; deprecations follow **F.13–F.14** with lexical continuity notes.\n12. **describedEntity present.** `GroundingHolon`, `ReferencePlane`, and a minimal `referenceMap` are recorded.\n13. **Pre‑flight numeric gates.** Any numeric comparison/aggregation **MUST** cite a `CG‑Spec` entry with lawful **SCP/Γ‑fold** and **MinimalEvidence** satisfied; cross‑Context reuse requires **Bridge + CL** with penalties routed to **R_eff only** (never F).\n14. **Partial‑order stance.** `ComparatorSet` SHALL NOT force total orders where only partial orders are lawful; **no scalarisation of partial orders**. Use Pareto/Lexicographic/medoid/median as lawful.\n15. **Illumination discipline.** If Illumination is used, publish `ArchiveRef`, `InsertionPolicy`, and `Edition`; **exclude from dominance by default**; any promotion into dominance **MUST** cite a named lens/policy‑id and be recorded in provenance.\n16. **Freshness/PathSlice.** Freshness windows are published and enforced; PathSlice identifiers are recorded in SCR when freshness gates influence gating/selection.\n17. **GateCrossing hook exposure.** Exports **MUST** provide `Expose_CrossingHooks` inputs so GateChecks (**A.21**) can validate EvidenceGraph paths and crossings: **CrossingSurface** present/consistent (**E.18/A.27/F.9**), **LanePurity**, and **Lexical SD** (**E.10**). Any failure is **blocking** for publication.\n\n**Guards as in C.20:**\n* **CC‑G0‑Φ.** **Φ(CL)** (and **Φ\\_plane**, if used) **MUST** be **monotone, bounded, table‑backed**; publish policy ids; **R\\_eff ≥ 0** by construction.\n* **CC‑G0‑Unknowns.** **Unknowns propagate tri‑state** {pass|degrade|abstain} to **Acceptance**; **no silent coercions**.\n* **CC‑G0‑CSLC.** **Scale/Unit/Polarity legality** MUST be proven (MM‑CHR/CSLC) **before** any aggregation; **no mean on ordinals; no unit mixing**.\n**Registry hooks.** Every CG‑Spec entry declares Lifecycle/DRR and **RSCR triggers for Φ‑table, SCP, Γ‑fold, Bridge edits** (parity re‑runs required).\n",
        "consequences": "### G.0:8 - Consequences (informative)\n\n* **Lawful comparability.** Teams know *exactly* what can be compared/aggregated and under which evidence minima.\n* **Auditable trust.** Γ‑fold and CL routing make **R_eff** computation transparent to selectors and reviewers.\n* **Frictionless downstream.** G.1–G.5 consume a single spec; CHR/CAL avoid hidden thresholds; dispatch is explainable.\n* **Local first, portable later.** Context‑local semantics are primary; Bridges make portability deliberate and costed.\n",
        "worked_micro‑example_(indicative)": "### G.0:9 - Worked micro‑example (indicative)\n\nCG‑Frame: R&D Portfolio Decisions\nScope: ObjectKinds={Project}, TaskKinds={SelectPortfolio}\ndescribedEntity: ⟨GroundingHolon=R&D, ReferencePlane=world⟩\n\nComparatorSet = {\n  ParetoDominance,\n  LexicographicMin(SafetyClass),\n  AffineSum(CostUSD_2025)\n}\n\nCharacteristics = \\[\n  SafetyClass : scale=ordinal,  polarity=↑, levels={D,C,B,A,AA},\n  CostUSD_2025 : scale=ratio,   polarity=↓, unit=USD_2025,\n  Readiness : scale=nominal,    polarity=\"=\"\n]\n\n SCP:\n  SafetyClass   → ORD_COMPARE_ONLY; aggregator=LexiMin; coordinate=Isotonic(order‑only) // no means\n  CostUSD_2025  → UNIT_CHECK; aggregator=Sum; unit_alignment=USD_2025; polarity=↓\n  Readiness     → equality_only; aggregator=None; ordering via Bridge only (CL≥2 with loss note)\n\nMinimalEvidence:\n  SafetyClass  → lanes={LA}, carriers={test_reports}, freshness≤18mo,\n                  failure={abstain if lanes/carriers missing; refuse if mean() attempted}\n   CostUSD_2025 → lanes={LA,VA}, carriers={ERP,audit}, freshness≤12mo,\n                  failure={refuse if unit misaligned; sandbox if carrier missing}\n\n  Readiness    → lanes={VA}, carriers={process_docs}, freshness≤12mo,\n                  failure={abstain for ordering unless Bridge(CL≥2)}\n\nΓ‑fold := weakest‑link across lanes\nCL‑Routing: CL=2 (Marketing→Engineering) → multiplicative penalty on R_eff; F invariant\n\nAcceptanceStubs:\n  AC_SafetyGate: SafetyClass ≥ B\n  AC_Budget: Σ CostUSD_2025 ≤ Envelope\n\nRSCR:\n* refuse mean(SafetyClass)\n* fail on (USD + Readiness)\n* verify AC_Budget on worked examples\n",
        "relations": "### G.0:10 - Relations (wiring)\n\n**Builds on:** A.4, A.10; **B.1/B.3/B.4**; **A.17–A.19/C.16**; **C.17–C.19**; **F.1–F.3/F.7–F.9/F.13–F.15/F.17–F.18**; **E.5.1–E.5.3** (no tool lock‑in); **E.10**.\n**Publishes to:** G.1 (generator guards), G.2 (harvesting policy & CL), G.3 (required CHR), G.4 (acceptance/evidence), G.5 (eligibility gates).\n**Constrains:** any LOG implementation via CAL/CHR legality and evidence minima.\n",
        "author’s_quick_checklist": "### G.0:11 - Author’s quick checklist\n\n1. Write the **Frame Charter** (Context, USM scope, describedEntity).\n2. Enumerate the **ComparatorSet**; bind **SCP** with guard macros and AggregationSpecs.\n3. Bind **Characteristics\\[]** to **CHR** ids; ensure Scale/Unit/Polarity are declared (reuse or mint in UTS).\n4. Publish **MinimalEvidence** per characteristic (KD‑CAL lanes, carriers, freshness, Bridge/CL allowances, failure behavior).\n5. State Γ‑fold and CL‑Routing; **default Γ‑fold = weakest‑link**; if overriding, attach CAL proofs (monotonicity, boundary behavior). Record **Φ(CL)/Φ_plane** **policy ids**; penalties → **R_eff only**.\n6. Publish to **UTS** with Name Cards, twin labels, Bridges (+loss notes); register **RSCR** tests.\n7. Set **refresh/decay**; log changes to **DRR/SCR**; maintain lexical continuity on deprecations.\n",
        "g.0:end": "### G.0:End\n"
      },
      "content": "### G.0:End\n",
      "metadata": {},
      "part": "G",
      "cluster": null
    },
    {
      "id": "G.1",
      "title": "CG-Frame‑Ready Generator",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## G.1 - CG-Frame‑Ready Generator\n\n**Stage:** *design‑time* (produces design‑time architheories & assets; enables run‑time use by target architheories)\n**Working‑Model first:** prefer working models and didactic micro‑examples; escalate to formal harnesses only where risk warrants (per E.8).\n**Primary hooks:** see **§11 Relations** for wiring. **Pre‑flight (via G.0/G.3/G.4):** lawful CHR typing + CG‑Spec for any comparison/aggregation; publish **ReferencePlane** on claims; on plane mismatch compute and publish **CL^plane** with **Φ_plane** (policy‑id); **Φ(CL)**/**Φ_plane** are **monotone, bounded, table‑backed** (policy‑ids recorded); **unknowns tri‑state** propagate as {pass|degrade|abstain} (no `unknown→0`); **CL penalties → R only** (F/G invariants); **fail‑fast on CSLC/scale mismatches** with **RSCR wiring**. See **§8 (Conformance), items 7 and 17–19**.\n**Minimal publication unit:** the **six M1–M6 cards** (Context, SoTA‑set, VariantPool+EmitterTrace, Shortlist+DRR/SCR, F‑bindings, Refresh plan) are published as a **complete, reusable package** for the CG‑Frame.\n",
        "intent": "### G.1:1 - Intent\n\nProvide a **repeatable generator scaffold** that **targets goldilocks slots (feasible‑but‑hard)** and records **abductive provenance** for candidate variants for a declared **CG‑Frame**, (a) assembles a **local SoTA set**, (b) **emits** well‑typed **variant candidates** for private cases, and (c) **selects & packages** the winners into the **F‑suite** (RoleDescription templates, Concept‑Sets, UTS rows, names) with explicit trust and scope.\n**Outputs (design‑time):** `TaskPack` + `VariantPool` + provenance (**A.10** anchors, **EmitterPolicyRef**) **+ per‑candidate SCR‑preview** (fields: **Φ(CL)/Φ_plane policy‑ids**, CL notes, ReferencePlane, UnknownHandling branch) **+ an ε‑Pareto front and an IlluminationSummary (pre‑thinning)** with **DescriptorMapRef**, **DHCMethodRef.edition/DistanceDef**, and archive **InsertionPolicy (incl. K‑capacity/dedup)** recorded, ready for G.2/G.5.\n",
        "problem": "### G.1:3 - Problem (recurring pains the pattern solves)\n\n* SoTA is scattered; no **local, scoped** set for a CG-Frame.\n* Variant generation is ad‑hoc; **private cases** lack a principled emitter.\n* Selection is taste‑driven; **trust & comparability** are opaque.\n* Output doesn’t land in **F‑artifacts** (RoleAssignments/UTS/names), so it can’t be reused.\n",
        "forces": "### G.1:4 - Forces (tensions to balance)\n\n* **Breadth vs depth** (cover SoTA yet stay actionable).\n* **Generativity vs assurance** (novel variants vs safety/trace).\n* **Local meaning vs portability** (Context‑local semantics vs Bridges/CL).\n* **Expressiveness vs parsimony** (new types vs reuse per F.8).\n",
        "solution": "### G.1:5 - Solution — **Six‑module generator chassis**\n\n*(Each module is a slot with explicit inputs/outputs and guard‑rails; minimal, substrate‑neutral.)*\n\n**M1 - CG-Frame Card (scope anchor)**\n\n **Inputs:** CG-Frame name; purpose; audience; boundary; **USM scope claims (G) + SenseCells (F.3)**; **comparability/CL policy**;  **describedEntity:** GroundingHolon(X); **ReferencePlane ∈ {world, concept, episteme}**;   **referenceMap:** observable cues → CHR candidates (instrument/protocol/uncertainty)\n**Outputs:**` CG-FrameContext := U.BoundedContext `+ **USM.ScopeSlice(G) + MDS** + **describedEntity block** + **Bridge policy** (CL thresholds) + **Γ‑fold** hints (B.1) + **UTS row id** (⟨CG‑FrameDescription | CG‑Spec⟩)`\n\n**M2 - SoTA Harvester (scoped set)**\n\n**Inputs:** discovery queries, canonical sources (**post‑2015 Science‑of‑Science surveys & field studies**), inclusion/exclusion criteria\n**Ops:** normalise terms (F.2), cluster senses (F.3), draft Concept‑Set rows (F.7), **apply G.2 harvesting discipline** (discovery → claim sheets → bridge matrix)\n**Outputs:** `SoTA_Set@CG-Frame` with provenance (A.10) + preliminary **UTS stubs** (F.17) **incl. twin labels + loss notes for bridged terms**\n**Guards:** Evidence Graph Ref; CL for cross‑Context reuse (F.9); **lawful measurement (A.17–A.19/C.16)**; Trust baseline (B.3).\n\n**M3 - Variant Emitter (illumination search)**\n\n* **Inputs:** SoTA_Set; private constraints; resource envelopes\n* **Ops:** open‑ended emitters (**NQD‑CAL**, **d≥2 DescriptorMap**); policy governor (E/E‑LOG); **abductive trace** (B.5.2) with A.10 anchors per lane and **ReferencePlane** on claims. **Optional OEE branch:** register a **Task/Environment GeneratorFamily (POET‑class)** with `EnvironmentValidityRegion` and `TransferRules`; bind SoS‑LOG/Acceptance branches for environment evolution; **telemetry must record edition‑aware Illumination increases with policy‑id**.\n* **Scoring:** Creativity‑CHR characteristics (Novelty, Surprise, ConstraintFit, **Diversity**), **QD‑triad {Q, D, QD‑score}** per C.18; \n* **Outputs:** `VariantPool` with **EmitterTrace** (who/why/where) **+ SCR‑per‑candidate preview** (constraints/gates consulted; CL notes; **Φ policy‑ids**; ReferencePlane; **UnknownHandling={pass|degrade|abstain}** recorded) **+ IlluminationSummary (DescriptorMapRef, DHCMethodRef.edition, grid/binning)**.\n* **Guards:** explore↔exploit policy (C.19); SoD (A.2 `⊥`); no category leaks (A.7); **metric legality/typing per MM‑CHR (A.17–A.19/C.16)**; **unknowns are tri‑state with explicit failure policy {degrade|abstain|sandbox} recorded in the EmitterTrace/SCR‑preview**; if a score/aggregation implies cross‑candidate comparison, cite a registered **CG‑Spec.characteristic**; otherwise degrade to lawful orders (median/medoid/lexi) or **abstain**.\n\nCharacteristicSpace includes a **domain‑family coordinate** (grid or CVT / Centroidal Voronoi Tessellation centroids) per F1‑Card. **Archive InsertionPolicy** and **DistanceDefRef** editions MUST be recorded. Pre‑front thinning MAY use DPP or submodular Max‑min under the **Heterogeneity‑first** lens. Record in provenance: sampler class & seed, family‑quota vector (incl. k), subFamilyDef id (if used), and **δ_family/DistanceDefRef.edition** (via DescriptorMapRef).\n\n**M4 - Selector & Assurer (fit‑for‑purpose)**\n\n* **Inputs:** VariantPool; acceptance clauses; risk constraints\n* **Ops:** evaluation & evidence (CAL hooks); **apply ConstraintFit=pass as an eligibility filter before any front computation**; compute an **ε‑Pareto front** (and/or archive under lawful partial orders) with **no forced scalarisation**; **Γ‑fold** aggregation (B.1); F–G–R roll‑up (B.3) with **CL→R only**; enforce **CG‑Spec.MinimalEvidence** for any characteristic used in evaluation; **keep thresholds in `G.4 CAL.Acceptance` (no thresholds in CHR/LOG)**; gate Γ‑fold contributors accordingly; when only ordinal semantics are lawful, avoid weighted sums and use lexicographic/median/medoid comparators; **surface Φ(CL)**/**Φ_plane** policy‑ids in SCR (per Pre‑flight); record **ε** and **DHCMethodRef.edition** used for any front computation.\n* **Outputs:** `Shortlist` (**ε‑Pareto/Archive set**, not a singleton) with **Assurance tuples** ⟨F,G,**R_eff**⟩ + decision rationale (E.9 **DRR + SCR**, including **Φ(CL)/Φ_plane policy‑ids** and ReferencePlane on any penalised claim)\n* **Guards:** CL penalties for cross‑Context imports; ageing/decay (B.3.4); **SoD for approval; minimum‑R gates**.\n\n**M5 - F‑Binding (publication surface)**\n\n* **Inputs:** Shortlist; local senses\n* **Ops:** mint/ reuse (F.8), create RoleDesc (F.4), finalise Concept‑Set rows (F.7), write UTS entries (F.17), propose names (F.18), **register RSCR tests (F.15) and Worked‑Examples**; carry the **describedEntity block** (GroundingHolon, ReferencePlane, referenceMap summary) into UTS Name Cards/rows; ensure **CharacteristicRef**s point to **CG‑Spec.characteristics\\[] ids**.\n\n* **Outputs:** `CG-FrameLibrary` (CAL/LOG/CHR bundles) + **UTS entries with twin labels + loss/bridge notes** + Name Cards **+ RSCR ids**\n* **Guards:** **No tool lock‑in (E.5.1–E.5.3)**; lexical rules (E.10); measurement discipline (A.17–A.19/C.16).\n \n**M6 - Packaging & Refresh (evolution loop)**\n\n* **Inputs:** DRR changes; telemetry (**PathSlice**, **IlluminationSummary (edition‑aware)**, coverage/regret); evidence refresh cadence; adoption feedback; policy‑ids (Φ).\n* **Ops:** version sign‑off; bias audit (D.5); refresh NQD emitters; retire/merge per F.13–F.14; **refresh RSCR/Worked‑Examples; maintain lexical continuity; record refresh/decay signals from telemetry**.\n* **Outputs:** `CG‑Kit@CG‑Frame` (versioned), with refresh policy & refresh hooks **+ deprecation notices (F.13)** and **telemetry hooks** (PathSliceId, policy‑ids, coverage/regret)\n* **Guards:** A.4 temporal duality; evidence decay; change‑impact trace (B.4/E.9).\n\n> **Julia‑inspired specialisation note (design‑time only):** within M3–M4, **parametric specialisation** and **trait‑like dispatch** are allowed as a *notation‑free* idea: variants are emitted/selectable by **type‑parameters** (capability envelopes, scale, constraint traits) rather than ad‑hoc flags. No tool lock‑in; semantics live in CAL/CHR.\n",
        "interfaces_—_minimal_i/o_standard": "### G.1:6 - Interfaces — minimal I/O Standard\n\n| Module | Consumes                       | Produces                                              |\n| ------ | ------------------------------ | ----------------------------------------------------- |\n| M1     | CG-Frame brief                    | `CG-FrameContext` (+ CL policy, Γ‑fold)                  |\n| M2     | sources, criteria              | `SoTA_Set@CG-Frame`, UTS stubs                           |\n| M3     | SoTA_Set, private constraints | `VariantPool` (+ Creativity‑CHR scores, QD‑triad, IlluminationSummary, EmitterTrace, DescriptorMapRef/DHCMethodRef.edition/DistanceDefRef) |\n| M4     | VariantPool, acceptance        | `Shortlist` (**ε‑Pareto/Archive set**; + ⟨F,G,R_eff⟩, DRR + SCR, **ε**, **DHCMethodRef.edition/DistanceDefRef**) |\n| M5     | Shortlist                      | RoleDesc templates, Concept‑Set rows, UTS rows, Name Cards |\n| M6     | DRR deltas, **telemetry (PathSlice, coverage/regret, policy‑ids Φ)** | Versioned `CG‑Kit@CG‑Frame`, refresh plan + **telemetry hooks** |\n",
        "archetypal_grounding": "### G.1:7 - Archetypal Grounding (Tell–Show–Show)\n**Tell.** The generator targets **goldilocks** problems (feasible‑but‑hard), assembling a local SoTA set, a `VariantPool`, and (when needed) an `TaskPack`, under **E/E‑LOG** policy with lawful CHR typing and CG‑Spec bindings.\n**Show A (Software R&D).** Context: R&D multi‑criteria decisions. M2 harvests outranking/value/portfolio fronts; M3 emits variants under budget/risk; M4 selects with acceptance clauses; M5 publishes RoleDesc/Concept‑Sets/UTS; M6 versions the `CG‑Kit` with quarterly refresh.\n**Show B (Clinical ops).** Context: dose‑adjustment design. M2 harvests SoTA dosage models and safety invariants; M3 emits policy‑constrained variants; M4 gates by safety acceptance; M5 publishes `Safety‑Invariants` and Name Cards; M6 maintains refresh & deprecations.\n",
        "conformance_checklist": "### G.1:8 - Conformance Checklist (normative, terse)\n\n1. **Context declared.** Every artifact is spoken **in** `CG-FrameContext` (U.BoundedContext); no global claims.\n2. **describedEntity present.** Every …Description published in G.1 carries `describe: GroundingHolon`, `ReferencePlane`, and a minimal `referenceMap`.\n3. **CG‑Spec required for comparisons.** Any numeric comparison/aggregation cites a **CG‑Spec** (characteristics, ComparatorSet, ScaleComplianceProfile (SCP), Γ‑fold); cross‑Context/Tradition use via **Bridge + CL** with penalties to **R_eff** only (never to F).\n4. **Evidence anchored.** All SoTA imports and evaluations link to carriers (A.10); no self‑evidence.\n5. **Design/run split.** Generators & selections are **design‑time**; operational runs are **Work** (A.4/A.15).\n6. **Emitter governed.** NQD emitters operate under an explicit **E/E‑LOG** policy; portfolio coverage is recorded (C.18–C.19).\n7. **Trust visible.** Each shortlist item carries ⟨F,G,**R_eff**⟩ with CL penalties (B.3; F.9).\n8. **F‑surface complete.** Winners are published as **RoleAssignment/Concept‑Set/UTS** with local naming (F.4/F.7/F.17–F.18).\n9. **Parsimony.** Prefer *reuse* over minting new U.Types (F.8); justify new ones via C.1 universality.\n10. **Measurement typed.** All metrics use **CHR typing (Characteristic/Scale/Level/Coordinate)**; forbid illegal ops (A.17–A.19/C.16).\n11. **SoD enforced.** Exploration authors ≠ selection approvers where required (A.2 `⊥`).\n12. **Refresh set.** A cadence for evidence/variants is declared; stale items accrue **Epistemic Debt** (B.3.4).\n13. **DRR/SCR emitted.** Every selection emits **DRR + SCR**; **R_eff** computed via **Γ‑fold** with CL penalties.\n14. **UTS twin labels.** Published winners include **twin labels** and **loss notes** for any bridge.\n15. **No tool lock‑in.** Core artifacts are notation‑independent; **no vendor/tool keywords in Core**; implementations live under **E.5.\\***.\n16. **RSCR wired.** Regression tests are registered for each published artifact (F.15).\n17. **Φ‑policies surfaced.** Wherever CL/CL^plane penalties are used, **Φ** policies are **monotone, bounded, table‑backed**, with **policy‑ids** in SCR; **R_eff ≥ 0** by construction (per Pre‑flight/G.0).\n18. **Unknowns are tri‑state.** Unknowns **propagate as {pass|degrade|abstain}** to Acceptance/Eligibility; **no `unknown→0/false` coercion**; behavior recorded in SCR.\n19. **GateCrossing checks pass.** Published crossings pass GateChecks (**A.21**) for **CrossingSurface** attestation (**E.18/A.27/F.9**), **LanePurity** incl. **CL→R only** and **CL^plane** when planes differ, and **Lexical SD** (**E.10**).\n20. **Three‑family breadth (domains).** `SoTA_Set@CG‑Frame` spans **≥3 domain‑families** per A.8 (Exact/Natural/Eng&Tech/Formal/Social&Behavioural), with Bridge hygiene for any crossings. AND MinInterFamilyDistance ≥ δ_family (from F1‑Card); publish {FamilyCoverage, MinInterFamilyDistance, Diversity_P, IlluminationSummary} with explicit F1‑Card reference and **DistanceDefRef.edition**.\n21. **QD‑triad evidence.** The generator **records** `Diversity_P` and **IlluminationSummary** for the triad used to motivate any “universal” UTS row or Core candidate; provenance includes `DescriptorMapRef`, **DHCMethodRef.edition**, and grid/binning; **archive InsertionPolicy (K‑capacity/dedup)** is visible.\n22. **Emitter trace includes coverage.** `EmitterTrace` (M3) **MUST** log triad coverage (IlluminationSummary) alongside ⟨F,G,R_eff⟩ and CL notes; promotion of illumination to dominance remains **forbidden by default** (policy‑opt‑in per C.19).\n23. **Variant Emitter.** CharacteristicSpace MUST include a domain‑family coordinate when available from F1‑Card; use HET‑FIRST lens (C.19) before exploit lenses.\n24. **ε‑front recorded.** Any front computation **records ε and DHCMethodRef.edition**, and **returns sets** (Pareto/Archive) under lawful partial orders; **no forced scalarisation**.\n25. **OEE branch legality.** When a **Task/Environment GeneratorFamily (POET‑class)** is used, publish `EnvironmentValidityRegion`, `TransferRules`, and the dedicated **SoS‑LOG/Acceptance** branches; **telemetry logs edition‑aware Illumination increases with Φ policy‑id**.\n26. **MOO (method of obtaining output) surfaced (generator).** Any emission of a **VariantPool** or shortlist **set** **MUST** name its **generation mechanism**: cite **EmitterPolicyRef** (and, where applicable, **InsertionPolicyRef/DHCMethodRef**) and record the active **E/E‑LOG policy‑id (PolicyIdRef)** in **SCR** and telemetry. (No file formats mandated; Core remains notationally independent.)\n",
        "consequences": "### G.1:9 - Consequences (informative)\n\n* **Generativity with guard‑rails:** wide variant search **and** computable trust.\n* **Local first, portable later:** clear Context‑local semantics with **explicit Bridges** (CL) for crossing.\n* **Direct line to F:** outputs are *immediately usable* in F.17 UTS & F.18 naming; no translation pass.\n",
        "worked_micro‑sketch": "### G.1:10 - Worked micro‑sketch\n\n**CG-Frame:** Multi‑criteria Decisions in R\\&D\n\n* **M1:** `CG-FrameContext=R&D_Decisions_2026` (Γ‑fold default = weakest‑link for safety; mean for cost where interval/ratio scales allow; CL≥2 for cross‑Context reuse).\n* **M2:** Harvest outranking, value models, portfolio fronts → SoTA_Set + UTS stubs.\n* **M3:** Emit variants under constraints (budget, risk, hiring cap) via **NQD (d≥2)**; record **IlluminationSummary** and **DescriptorMapRef/DHCMethodRef.edition**; score by Creativity‑CHR and QD‑triad.\n* **M4:** Select with acceptance clauses (must meet safety reqs; cost within envelope) using an **ε‑Pareto/Archive** set (no scalarisation) + ⟨F,G,**R_eff**⟩; **emit DRR + SCR** with **ε/DHCMethodRef.edition**.\n* **M5:** Publish RoleDesc templates (`DecisionRole`, `EvaluatorRole`), Concept‑Set rows for “Alternative/Option”, and UTS rows with **local names**.\n* **M6:** Version `VEK‑Pkg@R&D` with refresh every quarter; decay old evidence after 12 months.\n",
        "relations": "### G.1:11 - Relations (wiring map)\n\n* **Builds on:* A.4 (time split), A.10 (evidence), B.3 (assurance), B.5.2.1 (creative abduction), F.1–F.3 (Contexts/lexicon), F.7/F.8 (Concept‑Sets; mint/reuse).\n* **Imports:** C.17 (Creativity‑CHR), C.18 (NQD‑CAL), C.19 (E/E‑LOG), C.16 (MM‑CHR).\n* **Publishes to:* F.4 (RoleAssignment), **F.15 (RSCR)**, F.17 (UTS), F.18 (naming), optional Bridges (F.9).\n",
        "author’s_checklist_(how_to_use_the_skeleton)": "### G.1:12 - Author’s checklist (how to use the skeleton)\n\n* Fill **M1–M6 slots** with the minimal cards (one page each).\n* Keep **names local**; propose cross‑Context Bridges only after the local UTS is stable.\n* Treat **Julia‑style specialisation** as a *design idiom* (parametric variant families), not as tooling; keep lenses/policies recorded (EmitterPolicyRef; lens id).\n* Commit every major decision into a **DRR** entry; wire outputs to **F‑artifacts** immediately.\n",
        "g.1:end": "### G.1:End\n"
      },
      "content": "### G.1:End\n",
      "metadata": {},
      "part": "G",
      "cluster": null
    },
    {
      "id": "G.2",
      "title": "SoTA Harvester & Synthesis",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## G.2 - SoTA Harvester & Synthesis\n\n> **Purpose.** Provide a rigorous, repeatable way to **discover**, **triage**, and **synthesize** state‑of‑the‑art (SoTA) across competing Traditions before we mint any CHR/CAL/LOG for a CG-Frame. The output is a **SoTA Synthesis Pack** that feeds naming (UTS), formalisation (CHR/CAL), and the algorithmic dispatcher (G.5).\n> **Also outputs:** (i) **SoS‑indicator families** (as MethodFamily variants, not single metrics), and (ii) candidate **GeneratorFamily** bundles for open‑ended task/environment generation (QD/OEE class).\n> **Form.** Architectural pattern with a conformance checklist, aligned to FPF’s pattern grammar and publication Standard.\n> **Guardrail.** No forced scalarisation: downstream selectors (G.5) operate with partial orders and may return Pareto sets/archives, not single winners.\n",
        "problem": "### G.2:2 - Problem\n\nHow to **systematically** assemble a *complete‑enough* SoTA view that:\n\n* respects **bounded contexts** and **bridges** (no global meaning leaks);\n* records **evidence & trust** attributes suitable for later calculus;\n* identifies **incompatible commitments** and **points of translation loss**;\n* produces **actionable payloads** (names, claims, operators, exemplars) ready for CHR/CAL/LOG authoring and later **multi‑method dispatch** (G.5).\n",
        "forces": "### G.2:3 - Forces (tensions you must balance)\n\n* **Pluralism vs. comparability.** Rival Traditions speak different dialects; we must compare **without** flattening their semantics (use Bridges with CL and loss notes).\n* **Breadth vs. depth.** Coverage must be wide across sub‑fields yet deep on the load‑bearing claims.\n* **Recency vs. stability.** Post‑2015 advances matter, but we need durable claims and exemplars (record freshness windows; edition every distance/metric).\n* **Exploration vs. exploitation.** Illumination/QD (diversity‑seeking) vs. best‑response optimisation; keep policies separate and publish which stance a synthesis adopts.\n* **Formalism vs. pedagogy.** Early outputs must be teachable and auditable (UTS + Name Cards).\n* **Design‑time vs. run‑time.** Keep modeling commitments separate from operational policies and proofs; record the DesignRunTag explicitly.\n",
        "solution": "### G.2:4 - Solution (the harvesting & synthesis loop)\n\n#### G.2:4.1 - Discovery funnel (iterate until saturation)\n\n* **Seed → Expand → Prune.** Start with canonical surveys & top venues (post‑2015); expand via forward/backward citation and method keywords; prune with *CG-Frame‑fit* and *load‑bearing* tests (does this claim change how we would model/decide?). Maintain a **PRISMA‑style flow** (identification→screening→eligibility→included) in the pack’s provenance.\n* **Contexting.** Assign each artifact to a **home Context** (Bounded Context + edition). If cross‑Context reuse is needed, draft a **Bridge** and a **CL** with a human‑legible *loss/fit* note.\n\nGate@M2‑exit: if FamilyCoverage < k (default k=3 for triad/“universal” claims; otherwise per lens policy and recorded in provenance) or MinInterFamilyDistance < δ_family (per F1‑Card edition) → expand search window/policies and rerun harvesting. **MUST record** `k`, the **F1‑Card id+edition**, and the `DistanceDefRef.edition` in `SoTA_Set` provenance.\n\n**SoS‑indicators.** Where the literature offers Science-of-Science disciplinary indicators (replication, standardisation, disruptive balance, alignment) treat each as a **MethodFamily** with variants (calculation windows/constraints), not as a single scalar; record Acceptance branches for each variant.\n\n#### G.2:4.2 - Claim distillation (per lineage/`Tradition`)\n* For each Tradition, extract a **Claim Sheet** (minimal, typed statements) with **F‑ratings**, **G‑scope cues**, and **R‑Evidence Graph Ref** **tagged with KD‑CAL lanes (TA/VA/LA)**, plus **describedEntity** (`GroundingHolon`) and **ReferencePlane ∈ {world, concept, episteme}**; **Domain mentions stitched to D.CTX + UTS** (catalog‑only); include a stub **referenceMap** (observable cues → prospective CHR). Record **freshness windows** and the **edition** of any metric/distance used.\n\n#### G.2:4.3 - Operator & object inventory\n\n* Enumerate **characterisation candidates** (Characteristics, Scales, Levels, Coordinates) and **operators** the Tradition needs. Park all measurement terms under **MM‑CHR** discipline (no ordinal arithmetic; declare polarity; unit coherence).\n* Identify **decision objects** (options, lotteries, policies), **evidence objects** (observations, proofs), and **search objects** (frontiers, VOI heuristics) to be handed to CHR/CAL/LOG later.\n* Compile **MethodFamily candidates** (common signature → multiple implementations) with `ValidityRegion`, `CostModel`, `Guarantees`, `KnownFailures`.\n* If the Tradition includes task/environment generation, compile **GeneratorFamily candidates** (OEE/QD class; **POET/Enhanced‑POET‑like**) with `EnvironmentValidityRegion`, `TransferRules`, and **SoS‑LOG**/**Acceptance** branches to govern when transfers/migrations are legal.\n\n#### G.2:4.4 - Alignment & divergence map\n\n* Build a **Bridge Matrix**: `Tradition`×`Tradition` with where alignment is possible, **CL** and explicit **loss**; **note that CL penalties route to R_eff only (F and G invariant)**. Publish the **`DistanceDefRef.edition`** used to compute inter‑family distances.\n\n#### G.2:4.5 - Didactic micro‑grounding & describedEntity anchoring\n\n*For every load‑bearing claim, attach two micro‑examples …* **and link each micro‑example to carriers (A.10)** to serve as minimal anchors for future **CG‑Frame** characteristics and CHR cards.\n\n#### G.2:4.6 - Publication surface (SoTA Synthesis Pack)\n\n* **UTS delta.** Proposed **Name Cards** (Unified Tech / Plain) **with twin labels** (per F.17–F.18), Context, MDS, sense anchor, alignment/Bridges, lifecycle = *Draft*; **no new conceptual prefix without E.10 (LEX) and a DRR citation**; **use registered Γ‑fold family** (do not re‑use Γ for scoring/normalization mechanisms).\n* **ReferencePlane** is published per row; on any crossing compute and record **CL^plane**; penalties **route to R_eff only** (never F/G).\n* **SoTA Tables.** Side‑by‑side claim sheets, operator lists, exemplar pointers, and **SoS‑indicator families** per Tradition/Context.\n* **NQD/Illumination annex (if applicable).** For any QD‑style family, publish **Q/D/QD‑score** definitions, the **IlluminationSummary** (as a telemetry summary over Diversity_P), its **edition id**, and the **policies** used: `DescriptorMapRef.edition`, **`DHCMethodRef.edition`**, **`DistanceDefRef.edition`**, `EmitterPolicyRef`, and **`InsertionPolicyRef`** (archive dedup/elite replacement/`K`‑capacity). By default, **Illumination** does **not** enter dominance unless enabled by an explicit **CAL.Acceptance** policy.\n\n* **Risk & trust notes.** Where translation exists, log **CL penalties** and evidence fragility for later **R** aggregation; on any plane crossing publish the **Φ_plane policy‑id** alongside `CL^plane`.\n\nRequired artifact for top‑level disciplines: **SoTAPaletteDescription (D)**, accompanied by CHR evidence (G.3) and CAL traces (G.4). The SoTA Synthesis Pack MUST include: (i) claim sheets, (ii) operator & object inventory, (iii) bridge matrix (CL with loss notes), (iv) worked micro‑examples, (v) UTS drafts, **(vi) PRISMA‑style flow record, (vii) SoS‑indicator families, and (viii) where relevant, QD/OEE annex with Illumination/Policy fields**. This Description precedes any CG‑Spec normalization.\n\n **G.2‑F (Γ_epist Synthesis Step).** For any cross‑source consolidation, produce a **`Γ_epist^synth`** with:\n(i) **Provenance union** (no source loss),\n(ii) **Object alignment** (LCA or **`CompositeEntity`** with explicit mappings),\n(iii) **Assurance tuple = WLNK(…; Φ(CL), Φ_plane)** with **monotone, bounded, table‑backed** Φ‑policies; **publish policy‑ids in SCR** (including any **Illumination‑policy id**) and document them in **CG‑Spec**, (iv) **Conflict handling**: **no averaging** across rival planes/scales; preserve disjoint claims with Bridges + **loss notes**,\n(v) **ReferencePlane per row**; **compute CL^plane** on crossings; **penalties → R_eff only**; **emit SCR** for each synthesis result.\n\n **G.2‑G (DHC hooks, C.21).** For each Tradition×Context, emit **DHC‑SenseCells** (UTS ids) and declare units for\n**AlignmentDensity = `bridges_per_100_DHC_SenseCells`**; count only Bridges with **CL ≥ 2**; interpret **CL=3** as *free substitution*, **CL=2** as *guarded* (loss notes attached). Publish **freshness windows** and the **edition** of all DHC series, including the **DistanceDefRef.edition** wherever distances are used.\n\n Head‑anchoring + I/D/S; Plain twins present; GateCrossings recorded (**Bridge + UTS** with **CL/CL^plane**); Domain mentions stitched to **D.CTX + UTS**.\n**See §7 Conformance for the normative guard set (pluralism floor; Bridge+CL with loss notes; lane tags; RSCR hooks; ReferencePlane & CL^plane; penalties → R only).** This avoids duplication and drift.\n",
        "payload_(what_this_pattern_*exports*)": "### G.2:5 - Payload (what this pattern *exports*)\n\n1. **SoTA Synthesis Pack** for the CG-Frame (folder):\n* **G.2a** *Corpus Ledger*: bib entries + Context/edition + quick verdict (keep/park/retire).\n* **G.2b** *Claim Sheets* (per Tradition) with F/G/R annotations and freshness windows.\n* **G.2c** *Operator & Object Inventory* (candidate CHR terms; CAL hooks).\n* **G.2d** *Bridge Matrix* with CL & loss notes.\n* **G.2e** *Micro‑examples* (1‑pagers).\n* **G.2f** *UTS Proposals* (Name Cards + proposed rows/aliases).\n* **G.2g** *describedEntity Map*: per Tradition, a table `{term → GroundingHolon, ReferencePlane, referenceMap stubs}`.\n* **G.2h** *PRISMA Flow Record* (identification→screening→eligibility→included).\n* **G.2i** *SoS‑Indicator Families* (variants, constraints, Acceptance branches).\n* **G.2j** *MethodFamily Cards* (signature, ValidityRegion, CostModel, Guarantees, KnownFailures, EvidenceRefs).\n* **G.2k** *GeneratorFamily Cards* (OEE/QD class; EnvironmentValidityRegion; TransferRules; SoS‑LOG/Acceptance hooks).\n* **G.2l** *(If applicable) NQD Annex*: Q/D/QD‑score definitions; **IlluminationSummary** (+ **edition id**); `EmitterPolicyRef`; `InsertionPolicyRef`; `DistanceDefRef.edition`.\n\n1. **Hand‑off manifests** to:\n* **G.3/G.4** (CHR authoring and CAL scoping) with the operator/object inventory;\n* **G.5** (Dispatcher) with a **Method Family Index** per Tradition (candidate LOG bundles) **aligned to the Registry fields (Eligibility predicates, Assurance profile, CL notes)**, plus (where relevant) **GeneratorFamily** entries and **Illumination/Policy metadata** for QD families.\n",
        "interfaces_&_dependencies": "### G.2:6 - Interfaces & dependencies\n\n* **Consumes:** CG-Frame Charter (G.1), naming rules & UTS protocol (F.17), measurement discipline (A.17–A.19), **Bridges & CL (F.9) with Trust (B.3)** + CAL evidence hooks.\n* **(May also consume)** **G.13 `ClaimSheet@Context`/`SoSFeatureSet@Context`/`InteropSurface@Context`** when external scholarly indexes are mapped via conceptual interop; Core semantics unchanged.\n* **Produces:** Draft **definitional** terms for **G.2 → G.3**; operator stubs for **CAL** in **G.4**; initial **LOG** families for **G.5**; **SoS‑indicator families**; and, where applicable, **GeneratorFamily** bundles and **NQD/Illumination** metadata.\n",
        "conformance_checklist": "### G.2:7 - Conformance Checklist (author must be able to tick “yes”)\n\n* **Pluralism floor.** ≥ 2 `Tradition` and ≥ 3 `U.BoundedContext` present.\n* **Contexts declared.** Every artifact has a **home Context**; cross‑Context reuse uses a **Bridge** with **CL** and a **loss note**.  **ReferencePlane on crossings; CL→R only** with loss notes.\n* **Rival Traditions kept disjoint.** No fused claims without an explicit alignment proof or Bridge. \n* **Measurement lawful.** All proposed characteristics/scales honour MM‑CHR guards (no illegal ordinal arithmetic; unit coherence; declared polarity). \n* **Hand‑offs produced.** CHR/CAL/LOG manifests exist and reference the SoTA pack components. \n* **describedEntity declared.** Each Claim Sheet states `GroundingHolon` and `ReferencePlane`; micro‑examples cite carriers (A.10).\n* **Didactic grounding.** Each load‑bearing claim has **two worked micro‑examples** (heterogeneous substrates) and **A.10 anchors** with lane tags (**TA/VA/LA**).\n* **UTS‑ready.** Each candidate term has a **Name Card** draft **with twin labels** (F.17–F.18), Context, MDS, concept‑set linkage (or rationale for “not applicable”).\n* **DHC hooks present.** DHC‑SenseCells are emitted; **AlignmentDensity** units declared; **freshness windows + edition** stated (C.21).\n* **PRISMA present.** The SoTA pack includes a PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) style flow record.\n* **SoS‑indicators as families.** Indicators are represented as MethodFamily variants with Acceptance branches; no single unqualified scalar.\n* **QD/OEE readiness (if applicable).** NQD annex includes Q/D/QD‑score defs, **IlluminationSummary** (edition), `EmitterPolicyRef`, `InsertionPolicyRef`, and **policy‑id**; dominance does not include Illumination unless enabled by E/E‑LOG.\n\n* **DomainDiversity Guarantee.** If FamilyCoverage < k OR MinInterFamilyDistance < δ_family (F1‑Card), expand search radius under E/E‑LOG and re‑harvest; log policy id in SCR.\n",
        "anti‑patterns_&_rewrites_(what_to_avoid,_what_to_do_instead)": "### G.2:8 - Anti‑patterns & rewrites (what to avoid, what to do instead)\n\n* **“Global definition” temptation.** *Don’t:* collapse causal, evidential, and thermodynamic decision theories into one utility function. *Do:* keep **parallel claim sheets** and map **where** and **why** they diverge; attach **Bridges** with CL.\n* **Ordinal arithmetic creep.** *Don’t:* average Likert‑style scores across studies. *Do:* treat as ordinal; use order‑safe summaries, or justify interval mapping via MM‑CHR evidence.\n* **Design/run blur.** *Don’t:* treat policy heuristics as proven laws. *Do:* DesignRunTagtance, and route proofs/policies to the proper lanes.\n",
        "consequences": "### G.2:9 - Consequences\n\n* **Comparable plurality.** Teams can hold multiple Traditions in view, compare them **safely**, and trace translation risk via CL.\n* **Frictionless downstream work.** CHR/CAL/LOG authors receive **well‑shaped inputs**; UTS publication stays disciplined.\n* **Pedagogical leverage.** Micro‑examples and Name Cards make the synthesis teachable and auditable.\n",
        "worked_micro‑example_(1_paragraph,_indicative_only)": "### G.2:10 - Worked micro‑example (1 paragraph, indicative only)\n\n*CG-Frame:* Decision theory. *Traditions:* (i) **Classical expected‑utility** (ordinal vs cardinal utility variants); (ii) **Causal decision theory**; (iii) **Quantum‑like cognitive models**; (iv) **Active‑inference thermodynamic stance**.\n*Moves:* Each Tradition gets a **Claim Sheet** (e.g., choice rule, independence/separability, belief update), **Operator Inventory** (e.g., utility/likelihood/variational free energy), **Bridge Matrix** entries (*e.g.*, CDT ↔ EDT misalign on counterfactual conditioning; CL=2; *loss:* evidential dependence), two **micro‑examples** (manufacturing escalation vs human‑choice vignette), and **UTS proposals** for contested terms (`U.DecisionPolicy`, `U.PreferenceOrder`, `U.FreeEnergyBound`). If illumination is relevant (e.g., exploring diverse policy classes), include an **NQD annex** (Q/D/QD‑score defs, IlluminationSummary w/ edition, Emitter/Insertion policies). (Downstream: G.3 authors CHR for *Decision Object/Profile/Policy*; G.4 authors CAL variants; G.5 registers **MethodFamily/GeneratorFamily** entries.)\n",
        "editorial_template_(1‑page_“sota_sheet”_per_tradition)": "### G.2:11 - Editorial template (1‑page “SoTA Sheet” per Tradition)\n\n* **Context & edition** - **Core claims** (typed; intended **F**) - **Objects & operators** - **Measurement stance** (MM‑CHR notes) - **Evidence stance** (what counts; typical *R* anchors; freshness window) - **Micro‑examples** - **Known bridges** (targets; CL; loss notes) - **Citations (≥2015)** - **UTS candidates** (Name Card ids) - *(if relevant)* **SoS‑indicator family variants** - *(if relevant)* **NQD fields** (Q/D/QD‑score defs; IlluminationSummary edition; Emitter/Insertion policy refs).\n",
        "g.2:end": "### G.2:End\n"
      },
      "content": "### G.2:End\n",
      "metadata": {},
      "part": "G",
      "cluster": null
    },
    {
      "id": "G.3",
      "title": "CHR Authoring: Characteristics - Scales - Levels - Coordinates",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## G.3 - CHR Authoring: Characteristics - Scales - Levels - Coordinates\n\n**Tag:** Architectural pattern (publishes CHR; constrains CAL/LOG)\n**Stage:** *design‑time* (authoring & publication; enables lawful run‑time use by G.4/G.5)\n**Primary hooks:** G.1 CG‑Frame Card; G.2 SoTA Pack; **MM‑CHR discipline** (A.17–A.19/C.16); **Trust & Assurance** (B.3, Γ‑fold B.1); **Contexts & Bridges with CL** (F.1–F.3, F.9); **UTS & Naming** (F.17–F.18); **RoleAssignment** (F.4); **RSCR** (F.15); **No tool lock‑in** (E.5.1–E.5.3); **Lexical rules** (E.10); **Design–Run split** (A.4);\n**Illumination/QD & Dispatch** (C.18 NQD‑CAL, C.19 E/E‑LOG, G.5 registry/selector).\n**Pre‑flight (applies to G.0–G.5).** Any numeric comparison/aggregation **MUST** (i) cite a **CG‑Spec.characteristic id**, and (ii) prove **CSLC legality** (A.18/C.16: **Scale/Unit/Polarity**) **before numbers move**; minimal evidence recorded via CG‑Spec. Cross‑Context reuse requires **Bridge + CL** with penalties routed to **R_eff only** (never **F/G**). **Φ(CL)**/**Φ_plane** **MUST** be monotone and table‑backed (policy‑ids recorded). **ReferencePlane** **MUST** be surfaced for any definitional claim. **Freshness windows** are normative per Characteristic and enforced at **G.4 CAL.Acceptance** via `FRESHNESS_CHECK(-)`. Unknowns propagate as a tri‑state {**admit**|**degrade**|**abstain**} into **Acceptance**.\n",
        "intent": "### G.3:1 - Intent\n\nProvide a **notation‑independent authoring discipline** to turn SoTA plurality into a **lawful characterization layer (CHR)**: precisely typed **Characteristics**, **Scales**, **Levels**, and **Coordinates** with **guard‑rails** on what operations and aggregations are **legal**. The output is a **CHR Pack** consumable by CAL authoring (G.4) and dispatch (G.5), and publishable to **UTS**. CHR prioritizes **method‑centric generation** (increases the probability of producing acceptable results) over ex‑post governance; **thresholds live only in G.4**.\n",
        "problem": "### G.3:3 - Problem\n\nTeams repeatedly stumble on:\n\n* **Meaning leaks** across Contexts (same word, different sense).\n* **Illicit arithmetic** (e.g., averaging ordinals, mixing units).\n* **Hidden normalizations** that silently change polarity or scale.\n* **Unverifiable aggregation** (no proof obligations, no Γ‑fold hooks).\n* **Unreusable outputs** (no UTS rows, no test surface, no scope).\n",
        "forces": "### G.3:4 - Forces\n\n* **Pluralism vs. uniformity.** Preserve Tradition‑specific semantics yet deliver a common **typing** substrate.\n* **Expressiveness vs. parsimony.** Reuse existing U.Types (F.8) vs. mint new ones with justification.\n* **Pedagogy vs. formalism.** Make authoring teachable (Name Cards, micro‑examples) without weakening the legality guards.\n* **Local context vs. portability.** Keep CHR **Context‑local** while preparing **Bridges** with **CL** and explicit **loss notes**.\n",
        "solution": "### G.3:5 - Solution — *CHR Authoring chassis* (S1–S8)\n\n**S1 - Measurement Charter (scope anchor)**\n**Inputs:** CG-FrameContext (G.1), SoTA Pack (G.2). CAL traces supporting SoTAPaletteDescription MUST identify KD‑CAL lanes used (TA / VA / LA) and expose any lane‑dependent tolerances. **Cross‑lane comparisons are forbidden**; lane purity is enforced in **CAL.EvidenceProfiles**. If a claim crosses **ReferencePlanes**, declare **Φ_plane** and route penalties to **R_eff only**; there is **no “Bridge” across lanes**.\n\n**Ops:** declare **ObjectKinds** and **TaskKinds** in the home **Context**; state **USM ScopeSlice(G)**, invariants, **ReferencePlane**, and **freshness** needs; list contested terms that require Bridges.\n**Outputs:** `KindMap@Context`, `MeasurementCharter` (design‑time stance).\n**Guards:** A.4 split; F.1–F.3 Contexting; E.10 lexical hygiene; **E.18 GateCrossing / CrossingSurface** recorded for any cross‑CtxState transition with **Bridge id**, **PathSliceId**, and **CL** captured (penalties → **R_eff** only).\n\n**S2 - Term Minting & Reuse (UTS‑first)**\n**Ops:** for each candidate term, attempt **reuse** (F.8) via UTS; if minting, draft **Name Card** (Unified + Plain), Context, MDS, twin labels, and **loss notes** for any Bridge.\n**Outputs:** `UTS.Drafts{Characteristic,Scale,Level,Coordinate}` with ids.\n**Guards:** No global claims; Bridges carry **CL** (F.9).\n\n**S3 - Characteristic Cards (the core unit)**\n**Template (normative fields):**\n`CharacteristicCard := ⟨UTS.id, Context, ReferencePlane, ObjectKind, Intent, Definition (typed), **ObservableOf ⟨instrument/protocol, uncertainty model, validity window⟩**, EvidenceLanes (KD‑CAL), ScaleRef, Polarity ∈ {↑, ↓, ⊥}, Domain/Range, UnitSet, Freshness/Half‑life, Missingness semantics, Reliability/Stability notes, **QD.Role ∈ {Q, D, QD‑score, none}, DescriptorMapRef (Tech; d≥2, optional), DistanceDefRef (if QD.Role=D), DHCMethodRef.edition (if Q/QD‑score)**, Micro‑examples⟩`\n**Rules:** Definition references **MM‑CHR**; **Polarity** explicit; **UnitSet** coherent; **Missingness** classified (MCAR / MAR / MNAR, or local equivalents with mapping).\n**Outputs:** `CHR.Characteristic[]` (if used in any **CG‑Spec**, the **CG‑Spec.characteristics\\[] id** MUST be referenced here).  If a Characteristic plays a role in **Illumination/QD**, publish **QD.Role** and the corresponding **DHCMethodRef.edition/DistanceDefRef** for reproducibility of fronts (visible to G.5/C.18).\n\n**S4 - Scales & Levels (lawful measurement)**\n**ScaleCard:** `⟨type ∈ {nominal, ordinal, interval, ratio, count, cyclic,…}, admissibleTransforms (group), unit(s), resolution, bounds, zero semantics⟩`.\n**LevelCard (for nominal/ordinal):** `⟨enumeration, partial/total order, ties policy⟩`.\n**Rules:**\n\n* **Nominal:** only equality, counting by category; transforms = permutations.\n* **Ordinal:** order‑preserving transforms only; **no** addition/subtraction; medians allowed; quantiles allowed.\n* **Boolean:** treated as **nominal with two levels**; only equality and counts; transforms = permutations.\n* **Count:** non‑negative integers; addition allowed; **do not** assume ratio‑scale unless exposure/time base is fixed and declared; declare rate conversions explicitly.\n* **Interval:** positive affine transforms; differences meaningful; means allowed.\n* **Ratio:** positive scalar transforms; ratios and products allowed.\n* **Cyclic:** operations respect wrap‑around; define principal interval.\n  **Outputs:** `CHR.Scale[]`, `CHR.Level[]`.\n\n**S5 - Coordinates & Encodings (without hidden cardinalization; state preserved invariants and non‑entitlements per A.18 CSLC)**\nWhen a numeric **Coordinate** is required (e.g., for ranking), publish `CoordinatePolicy` with: mapping, invariants preserved (order/ratio/etc.), **what operations remain illegal**, and **proof obligations** if stronger structure is claimed. **Coordinates do not authorize scalarization of partial orders**; for partial orders, consumers **MUST** return sets.\n**Examples:** isotonic embeddings for ordinal (order‑only), log‑scale coordinates for ratio positives, circular coordinates for cyclic.\n**Outputs:** `CHR.Coordinate[]` + legality annotations.\n**Guards:** Coordinate **does not** upgrade scale type without evidence; illegal ops remain blocked.\n**Note:** if a Characteristic participates in any **CG‑Spec** characteristic, reference the characteristic id in the card.\n\n**S6 - Operation Legality & Guard Macros** (explicitly forbid mean/subtract on ordinal; fail unit mismatches)\nPublish a **Legality Matrix** per Scale type and a set of **Guard Macros** for CAL/LOG:\n`ORD_COMPARE_ONLY`, `INTERVAL_MEAN_ALLOWED`, `RATIO_PRODUCT_ALLOWED`, `UNIT_CHECK`, `CROSS_Context_CL_PENALTY`, `POLARITY_CHECK`, `CYCLIC_DIFF`, `FRESHNESS_CHECK`,\n`CSLC_PROOF_REQUIRED(x)` — aggregation/comparison proceeds **only** after **CSLC legality** is proven for the participating Scales/Units (per A.18/C.16),\n`UNKNOWN_TRI_STATE(x)` — on missingness/unknowns, emit **{admit\\|degrade\\|abstain}** branch for **Acceptance** (no silent coercions),\n`PHI_CL_MONOTONE(policy_id)` — assert that **Φ(CL)**/**Φ_plane** used for penalties is **monotone**; record **policy_id** (visible to G.4/G.5 **SCR**).\n`RETURN_NONDOMINATED_SET()` — for partial orders (e.g., Pareto), the comparator **must** return the explicit non‑dominated set; scalarization is forbidden unless CAL justifies a lawful order.\n`METRIC_EDITION_REF(id)` — surface the **DHCMethodRef.edition/DistanceDefRef.edition** used for any Q/D/QD‑score‑based comparison (ties to G.5/C.18).\n\n**Outputs:** `CHR.Guards`, `CHR.LegalityMatrix`.\n**Guards:** Enforce at authoring time + RSCR; route cross‑Context penalties to **R_eff** (never to **F/G**).\n**Freshness windows** MUST be published per Characteristic (Context‑local; stale ⇒ {degrade|abstain} at Acceptance) and enforced via `FRESHNESS_CHECK(x)` in **CAL.Acceptance**.\n\n**S7 - Aggregation & Comparison Patterns (safe by construction)**\nProvide **typed aggregation templates** (e.g., lexicographic min, Pareto dominance — **return the explicit non‑dominated set** for partial orders; medoid/median for ordinal; **t‑norms only on ratio‑scale quantities in [0,1]**; **for interval: means allowed; for ratio: sums/products allowed after unit alignment**). Any comparator/aggregator used **across candidates** MUST cite a **CG‑Spec** characteristic id (A.19.D1) and, if based on **Q/D/QD‑score**, its **DHCMethodRef.edition/DistanceDefRef**; otherwise degrade to order‑only or abstain. **Record the chosen Γ‑fold contributor policy (default = weakest‑link) with an edition id; silent changes are forbidden.** Scalarization of partial orders is **forbidden**; selection is delegated to **G.5** which returns **sets/archives** under lawful orders.\n**Outputs:** `CHR.AggregationSpecs` with legality proofs/links.\n\n**S8 - Publication, Tests, and Evolution**\nPublish all artifacts to **UTS** (with twin labels and Bridges); register **RSCR** tests: unit coherence, guard coverage, polarity invariants, illegal‑op refusal. Provide **Worked‑Examples** and a **Refresh Plan** (ageing/decay → B.3.4). Surface **policy‑ids Φ(CL), Φ_plane**, and, where applicable, **DHCMethodRef.edition/DistanceDefRef** for Q/D/QD‑score. Record **PathId/PathSliceId** for refresh/decay telemetry.\n**Outputs:** versioned `CHR Pack@CG-Frame` + RSCR ids + deprecation notices (F.13) + provenance fields (Φ‑policies, PathSlice).\n**Guards:** E.5.\\* no tool lock‑in; lexical continuity (F.13–F.14).\n",
        "archetypal_grounding": "### G.3:6 - Archetypal Grounding (informative; two CHR examples from distinct fields)\n\n**AG‑1 (ML fairness, post‑2015 practice).**  \nCharacteristic: `DemographicParityGap` — **interval** (symmetric bounds around 0), Unit: percentage points, Polarity: **target‑band** with center at 0.  \nLegality: **no cross‑ordinal scalarisation**; comparisons use intervals; **UNIT_CHECK** and **ORD_COMPARE_ONLY** guarding when gap is disclosed alongside ordinal labels; **CSLC_PROOF_REQUIRED** before any aggregation across cohorts; stale evidence ⇒ **UNKNOWN_TRI_STATE → {degrade|abstain}**.  \nBridge: when imported from an external auditing Tradition, require **Bridge + CL**; penalties via **PHI_CL_MONOTONE** → **R_eff** only.\n\n**AG‑2 (Clinical diagnostics).**  \nCharacteristic: `Sensitivity` — **ratio** (dimensionless in \\[0,1]), Unit: none; Polarity: **↑**.  \nLegality: means allowed on ratio; **t‑norms only on \\[0,1]**; no mixing with **ordinal** labelling of test difficulty; **CSLC_PROOF_REQUIRED** on any rate→rate transformations (e.g., pooled sensitivity under varying prevalence).  \nEvidence lanes: declare **TA/VA/LA** per protocol and trials; freshness window declared.\n\n**AG‑note (Illumination/QD, post‑2015 practice).**  \nWhen a Characteristic serves as **Diversity** or **Quality** in QD/Illumination (e.g., MAP‑Elites‑class methods), set `QD.Role` and publish **DHCMethodRef.edition/DistanceDefRef**; comparisons **return sets** under partial orders and do **not** introduce scalarisation in CHR.\n",
        "interfaces_—_minimal_i/o_standard": "### G.3:7 - Interfaces — minimal I/O Standard\n\n| Interface                | Consumes                            | Produces                                                              |\n| ------------------------ | ----------------------------------- | --------------------------------------------------------------------- |\n| **G.3‑1 Charter**        | CG-FrameContext (G.1), SoTA Pack (G.2) | `KindMap@Context`, `MeasurementCharter`                                  |\n| **G.3‑2 MintOrReuse**    | SoTA terms, UTS registry            | `Characteristic/Scale/Level/Coordinate` Name Cards (UTS ids)          |\n| **G.3‑3 DefineScale**    | CharacteristicCard                  | `ScaleCard`, `LevelCard`                                              |\n| **G.3‑4 Coordinate**     | ScaleCard, use‑cases                | `CoordinatePolicy` + legality annotations                             |\n| **G.3‑5 Guards**         | Scale/Level/Coordinate specs        | `LegalityMatrix`, `GuardMacros` (for CAL/LOG)                         |\n| **G.3‑6 AggregateSpecs** | CHR set, acceptance clauses         | `AggregationSpecs` (typed, with proofs/obligations; **DHCMethodRef.edition/DistanceDefRef.edition** if Q/D/QD‑score) |\n| **G.3‑7 Publish**        | All above                           | Versioned `CHR Pack@CG-Frame`, RSCR tests, Worked‑Examples, deprecations, Φ‑policies, PathSlice |\n",
        "payload_(what_g.3_exports)": "### G.3:8 - Payload (what G.3 exports)\n\n1. **CHR Pack\\@CG-Frame** (folder):\n\n   * `CHR.Characteristic[]` (Cards)\n   * `CHR.Scale[]`, `CHR.Level[]`\n  * `CHR.Coordinate[]` (with legality notes)\n   * `CHR.Guards`, `CHR.LegalityMatrix`\n   * `CHR.AggregationSpecs` (**Γ‑fold contributor policy + edition id**, **DHCMethodRef.edition/DistanceDefRef.edition** if applicable; visible to G.4/G.5 **SCR**)\n   * **UTS Entries** (Name Cards + twin labels + Bridge CL & loss notes)\n   * **RSCR** tests + **Worked‑Examples** (**Archetypal Grounding included**)\n   * **Provenance fields**: **ReferencePlane**, **Φ(CL)**/**Φ_plane** policy‑ids, **PathId/PathSliceId**\n\n1. **Hand‑off manifests** to G.4 (admissible CAL operators; unit/scale constraints; freshness routing) and to G.5 (TaskSignature trait inferences; eligibility predicates; QD roles/editions for lawful archives).\n",
        "conformance_checklist": "### G.3:9 - Conformance Checklist (normative)\n\n1. **Context declared.** Every CHR artifact has a **home Context**; cross‑Context reuse uses a **Bridge** with **CL** and **loss note**.\n2. **Scale typed.** Each Characteristic declares **Scale type**, **Polarity**, **UnitSet**, **Bounds**, **Zero semantics**, **Freshness**.\n3. **ReferencePlane surfaced.** Any definitional claim carries an explicit **ReferencePlane**.\n4. **ObservableOf filled.** Each CharacteristicCard declares `ObservableOf` with instrument/protocol and uncertainty.\n5. **CG‑Spec link.** If a Characteristic is used as a **CG‑Spec** characteristic, the characteristic id is referenced.\n6. **Legality explicit.** A **Legality Matrix** and **Guard Macros** exist and are referenced by all downstream operators.\n7. **No scalarization of partial orders.** Partial orders **MUST** return sets (archives) at selection time; scalarization is forbidden in CHR.\n8. **No illegal ops.** Ordinal **SHALL NOT** be averaged/subtracted; unit mismatches **SHALL** fail fast (A.17–A.19/C.16).\n9. **Coordinates honest.** Numeric encodings **SHALL** state what invariants they preserve and **SHALL NOT** silently upgrade measurement structure.\n10. **Aggregation proven.** Published aggregation specs come with **proof obligations** (monotonicity, idempotence, boundary) or a rationale for weaker claims.\n11. **UTS‑ready.** Names minted or reused; **twin labels** present; **loss notes** attached where bridged (F.17–F.18, F.9).\n12. **Evidence wired.** Each Characteristic links to **R‑anchors** (KD‑CAL lanes) and **Worked‑Examples**.\n13. **RSCR passing.** Tests enforce guards (ordinal arithmetic refusal, unit coherence, polarity checks, cyclic wrap rules).\n14. **Design/run split.** Authoring is **design‑time**; run‑time policies live in CAL/LOG (A.4).\n15. **Φ/planes surfaced in provenance.** Where a CHR card depends on cross‑Context/plane import, provenance **MUST** cite Bridge id and record **CL/CL^plane** policy‑ids visible to **G.4/G.5 SCR**; include **PathSliceId** for refresh.\n16. **Lifecycle set.** Refresh/decay declared; deprecations follow **F.13–F.14** with **Lexical Continuity** notes.\n17. **No thresholds in CHR.** All thresholds/guard‑bands live **only** in **AcceptanceClauses** (G.4); CHR **MUST NOT** embed policy cut‑offs (cf. C.21 practice).\n18. **Φ(CL) monotone & recorded.** If CL penalties apply, **Φ(CL)**/**Φ_plane** **MUST** be monotone, table‑backed, and recorded with **policy id**; penalties route to **R_eff** only (never **F/G**).\n19. **QD roles reproducible.** If a Characteristic participates in QD/Illumination, **QD.Role** and **DHCMethodRef.edition/DistanceDefRef.edition** are published (fronts reproducible across runs).\n20. **Unknowns are tri‑state.** Missingness/unknowns propagate as **{admit\\|degrade\\|abstain}** into **Acceptance**; silent coercions forbidden.\n21. **Archetypal Grounding present.** Two cross‑domain CHR examples are included (per E.8) to teach lawful CHR authoring without weakening legality guards; add a QD note if any Characteristic is used for Illumination.\n",
        "anti‑patterns_&_rewrites": "### G.3:10 - Anti‑patterns & rewrites\n\n* **Hidden cardinalization.** *Don’t:* treat ordinal encodings as interval; *Do:* publish an **isotonic** coordinate with clear limits.\n* **Unit laundering.** *Don’t:* add cost (USD) to time (hours); *Do:* transform to lawful quantities or keep vector comparisons.\n* **Global definitions.** *Don’t:* one “utility” for all Contexts; *Do:* Context‑local Characteristics with Bridges + CL.\n* **Aggregation by convenience.** *Don’t:* “weighted averages” on ordinals; *Do:* medians, majority order, or lexicographic rules with proofs.\n* **Design/run blur.** *Don’t:* bake policy thresholds into Scale definitions; *Do:* keep thresholds in CAL acceptance clauses.\n* **Scalarizing partial orders.** *Don’t:* compress Pareto/poset outcomes into a single score; *Do:* return the **non‑dominated set** and defer selection to G.5 under lawful orders.\n",
        "consequences": "### G.3:11 - Consequences\n\n* **Safety by construction.** Illegal operations are blocked at the **type/guard** level.\n* **Comparable plurality.** Rival Traditions can co‑exist because CHR preserves **local meaning** and exposes **lawful** comparison.\n* **Frictionless downstream.** CAL (G.4) and Dispatcher (G.5) receive **typed, UTS‑published** primitives with RSCR tests; QD/Illumination roles are reproducible (editions surfaced), and partial orders flow through as **sets/archives**.\n",
        "worked_micro‑example_(indicative)": "### G.3:12 - Worked micro‑example (indicative)\n\n*CG-Frame:* R\\&D portfolio decisions.\n**Objects:** `Project`. **Characteristics:**\n\n1. `SafetyClass` — **ordinal**, Levels = {D,C,B,A,AA} (↑ better), admissible transforms = **order‑preserving**, **aggregation** default = **lexicographic min** across subsystems; **Coordinate** = isotonic map (order only).\n2. `CostUSD_2025` — **ratio**, unit = USD (2025 real), admissible = positive scalar; allowed ops: +, × by scalar; **aggregation** = sum after **unit alignment**.\n3. `Readiness` — **nominal**, Levels = {lab, pilot, field}; ops = equality, counts; no ordering unless a Bridge provides one with **CL** and loss note.\n   **Guards:** `ORD_COMPARE_ONLY(SafetyClass)`, `UNIT_CHECK(CostUSD_2025)`, `RETURN_NONDOMINATED_SET()`.\n   **UTS:** Name Cards minted; twin label “Safety rating” with loss note for marketing Context Bridge.\n   **RSCR:** tests refuse `mean(SafetyClass)`; accept `median(SafetyClass)`; fail `CostUSD + Readiness`.\n   **QD note:** if `SafetyClass` is used as a **D**‑characteristic (axis) in Illumination, publish `QD.Role=D` and `DistanceDef` (edition recorded).\n",
        "relations": "### G.3:13 - Relations\n\n**Builds on:** G.1, G.2; **MM‑CHR** (A.17–A.19/C.16); **F–G–R**; **Contexts/Bridges + CL**; **UTS**; **RoleAssignment**; **C.18 NQD‑CAL / C.19 E/E‑LOG**.\n**Publishes to:** G.4 (CAL admissible operators, legality macros, freshness checks), G.5 (TaskSignature traits, QD roles/editions), **UTS**, RSCR, Worked‑Examples.\n**Constrains:** any CAL/LOG implementation that consumes CHR.\n",
        "author’s_quick_checklist": "### G.3:14 - Author’s quick checklist\n\n1. Write the **Measurement Charter** and **KindMap** for the CG-Frame.\n2. For each candidate Characteristic, **reuse** or **mint** in UTS with Name Card **+ twin labels**; cite **Bridge ids** where a CHR term is imported across Contexts, and surface **ReferencePlane** for any definitional claim.\n3. Declare **Scale**, **Levels**, **Polarity**, **UnitSet**, **Bounds**, **Freshness**, **Evidence lanes**.\n4. Publish any **Coordinate** with invariants preserved and explicit **non‑entitlements**.\n5. Generate **Legality Matrix** + **Guard Macros** (`RETURN_NONDOMINATED_SET`, `METRIC_EDITION_REF` where applicable); wire **AggregationSpecs** with proofs.\n6. Emit **RSCR** tests and **Worked‑Examples**; version the **CHR Pack**; set refresh/decay; surface **Φ‑policy ids** and, if QD is used, DHCMethodRef.edition/DistanceDefRef.edition.\n",
        "g.3:end": "### G.3:End\n"
      },
      "content": "### G.3:End\n",
      "metadata": {},
      "part": "G",
      "cluster": null
    },
    {
      "id": "G.4",
      "title": "CAL Authoring: Calculi - Acceptance - Evidence",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## G.4 - CAL Authoring: Calculi - Acceptance - Evidence\n\n**Tag:** Architectural pattern (publishes CAL; consumes CHR; constrains LOG & G.5; binds **GateCrossing discipline (E.18/A.21/A.27)**; exposes **ReferencePlane** and **Φ‑policy ids** to **SCR**)\n**Crossing visibility note.** Any **cross‑stance import** (any change in `CtxState = ⟨L,P,E⃗,D⟩`, including `DesignRunTag` changes, plane changes, edition/policy‑id pins, or a `Locus` change) **MUST** be published as a **GateCrossing** with a **CrossingSurface** (**E.18**; Bridge+UTS **A.27**; BridgeCard **F.9**) and pass **LanePurity** + **Lexical SD** GateChecks (**A.21/E.10**); failure is **blocking** for CAL publication (register as **RSCR** defect).\n**Stage:** *design‑time* (authoring & publication; enables lawful run‑time evaluation)\n**Primary hooks:** G.1 CG-Frame Card; G.2 SoTA Synthesis Pack; **G.3 CHR Pack**; **G.5 Dispatcher** (MethodFamily & **GeneratorFamily** registry); **KD‑CAL F–G–R** (B.3, B.1 Γ‑fold); **MM‑CHR discipline** (A.17–A.19/C.16); **Contexts & Bridges + CL** (F.1–F.3, F.9); **UTS & naming** (F.17–F.18); **RoleAssignment** (F.4); **RSCR** (F.15); **E/E‑LOG** (C.19); **SoS‑LOG** (C.23); **GateCrossing / CrossingSurface** hooks (**E.18/A.21/A.27**); **Lexical rules** (E.10); **Design–Run split** (A.4); **Telemetry/Refresh** (G.11).\n",
        "intent": "### G.4:1 - Intent\n\nProvide a **notation‑independent authoring discipline** to turn CHR‑typed measurement (from **G.3**) and SoTA plurality (from **G.2**) into a **lawful calculus layer (CAL)** that is **portfolio‑aware** (partial orders return **sets/archives**, not forced scalars) and **GateCrossing‑ready**:\n\n* **Operators** (transform, compare, aggregate, optimize, decide),\n* **Acceptance Clauses** (typed predicates for *fit‑for‑purpose*), and\n* **Evidence wiring** (F–G–R lanes, Γ‑fold integration, CL routing, **ReferencePlane** and **Φ‑policy id** publication),\n\nso that run‑time **LOG** bundles and the **G.5** selector can execute choices **safely, auditably, and with scope/trust visible**.\n",
        "problem": "### G.4:3 - Problem\n\nTeams repeatedly face:\n\n* **Illicit operations** (hidden cardinalization; unit laundering; ordinal arithmetic).\n* **Opaque acceptance** (thresholds scattered; no typed predicates; no Γ‑fold).\n* **Unstated assumptions** (regularity, noise, independence) that break comparability.\n* **Evidence ambiguity** (what lane? how to aggregate? where do CL penalties land?).\n* **Tool entanglement** (vendor flags baked into core logic).\n",
        "forces": "### G.4:4 - Forces\n\n* **Power vs. safety.** Expressive operators vs. strict legality under **MM‑CHR**.\n* **Pluralism vs. unification.** Preserve Tradition‑specific calculi vs. a common **typed** substrate.\n* **Pedagogy vs. proof burden.** Make acceptance teachable while binding **proof obligations**.\n* **Locality vs. portability.** Keep Context‑local semantics yet prepare **Bridges** (with **CL** and loss notes).\n* **Exploration vs. exploitation.** Enable **NQD/E/E‑LOG** probing without leaking un‑assured results.\n",
        "solution": "### G.4:5 - Solution — *CAL Authoring chassis* (C1–C9)\n\n**C1 - CAL Charter (scope anchor)**\n**Inputs:** CG-FrameContext (G.1), SoTA Pack (G.2), CHR Pack (G.3). CAL traces supporting SoTAPaletteDescription MUST identify KD‑CAL lanes used (TA / LA / VA) and expose any lane‑dependent tolerances. Cross‑lane comparisons are forbidden unless an explicit **Bridge** with declared **CL** and loss notes is provided; penalties route to **R_eff** only.\n**Ops:** declare **TaskKinds** and **ObjectKinds** *in the home Context*; state **assumption envelopes** (data shape, noise, independence, stationarity), **USM ScopeSlice(G)**, and **evidence lanes** intended per KD‑CAL (e.g., TA/LA/VA);  enumerate intended **CG‑Spec.characteristic ids** **iff** any numeric comparison/aggregation will be performed in this CAL pack; declare **ReferencePlane** for any cross‑plane readings and the **freshness_window**/**Γ_time** policy to be used by EvidenceProfiles.\n**Outputs:** `CAL.Charter@Context` (design‑time stance) + `TaskMap`.\n**Guards:** A.4 split; F.1–F.3 Contexting; E.10 lexical hygiene; **E.18/A.27/F.9** (GateCrossing recorded with **CrossingSurface**: BridgeCard + UTS row; **Bridge id**, **PathSliceId**, **CL** captured; non‑conformance blocks publication).\n\nAny cross‑Tradition or cross‑lane reduction MUST declare a CL bridge with explicit loss notes. Such reductions contribute a penalty term to Γ‑fold and are ineligible for “universal” aggregation.\n\n**C2 - Operator Cards (typed & lawful)**\nDefine **OperatorCard** as the core unit:\n\n```\nOperatorCard :=\n⟨ UTS.id, Context, Lineage/Tradition, Intent,\n  Signature: X → Y over CHR types,\n  Preconditions (typed; Guard Macros),\n  Postconditions (typed; invariants),\n  Evidence lanes used (KD‑CAL),\n  Complexity/Cost cues,\n  Failure modes & safe degradations,\n  Micro‑examples, Bridges (+CL, loss notes) if any ⟩\n  CG‑Spec refs: ids of CG‑Spec.characteristics used for any numeric comparison/aggregation; ReferencePlane note (if non‑home); policy‑ids Φ(CL), Φ_plane to be cited by LOG/SCR.\n```\n\n*Signatures* reference **CHR** types (Characteristics/Scales/Units/Coordinates).\n**Guards:** `UNIT_CHECK`, `ORD_COMPARE_ONLY`, `POLARITY_CHECK`, `CYCLIC_DIFF`, `FRESHNESS_CHECK`, `PLANE_NOTE`, `PHI_CL_MONOTONE(policy_id)`.\n**Outputs:** `CAL.Operator[]` (versioned; UTS‑published with twin labels).\n\n**C3 - Acceptance Clauses (typed predicates)**\nCraft **AcceptanceClause** as a minimal, typed grammar:\n\n```\nAcceptanceClause :=\n⟨ ClauseId (UTS), applies_to: {TaskKind|OperatorId},\n  CharacteristicRefs: CHR.Characteristic[],      // explicit binding to CHR ids\n  CGSpecRefs?: CG‑Spec.characteristic[],         // REQUIRED iff Pred induces any numeric comparison/aggregation\n  EvidenceProfileRefs?: CAL.EvidenceProfile[],   // provenance hooks for SCR/LOG (C5)\n  Pred := boolean formula over CHR‑typed observables\n          + CAL outcomes + Scope(G) + Resource envelope,\n  Thresholds declared (Context‑local),\n  Freshness: `freshness_window` and `Γ_time` selector (lane‑aware),\n  UnknownHandling: {pass|degrade|abstain}, // tri‑state per G.0; \"sandbox\" is a LOG‑level degrade mode\n  Dependence on evidence lanes (KD‑CAL) and ReferencePlane,\n  Failure policy (degrade/abstain/escalate) ⟩\n```\n\n*Thresholds live here*, **not** inside CHR. Clauses are **design‑time** artifacts that run at selection/evaluation time.\n**Outputs:** `CAL.Acceptance[]` (publish to UTS).\n**Guards:** **No global thresholds**; cross‑Context reuse via **Bridge + CL** only.\n\"**Rule:** thresholds **live only in AcceptanceClauses**; if a clause induces comparison/aggregation, cite the CG‑Spec characteristic id; otherwise degrade to order‑only or **abstain**.\"\n**Idiom (MaturityFloor).** Contexts MAY author `AC_MaturityFloor(MethodFamilyId, rung≥Lk)` as a typed predicate over the published `MaturityCard@Context` (C.23). The selector/SoS‑LOG MUST reference this clause by id; no maturity thresholds are embedded in LOG.\n**UnknownHandling:** predicates MUST define behavior for `unknown` (tri‑state from **TaskSignature/CHR Missingness** and **ShiftClass**), recorded in SCR; default SHALL NOT coerce to numeric 0/−∞; when **ShiftClass=unknown|non‑iid**, families MAY **degrade** or **abstain** with scope notes (LOG‑executable branch ids). LOG‑level **sandbox/probe‑only** modes, if used, are expressed in **SoS‑LOG** branches, not as Acceptance outcomes. **Clauses SHALL expose stable `clauseId` for SoS‑LOG citation.**\n**GateCrossing hooks:** Acceptance must expose **GateCrossing ids** and the corresponding **CrossingSurface** (E.18; surfaced via **G.10‑3** `Expose_CrossingHooks`) for clause‑triggered gates; failures are *blocking* for publication.\n\n**C4 - Aggregation & Comparison Flows (safe by construction)**\nCompose operators via **FlowSpecs** with legality checks:\n\n```\nFlowSpec := DAG of OperatorIds\n  + Admissible Aggregators (from CHR.AggregationSpecs)\n  + Γ-fold hints for R-aggregation\n  + Unit/scale checks at each edge\n```\n\nProvide **typed templates** (lexicographic, Pareto with explicit **non‑dominated set** output, ε‑Pareto thinning, t‑norms, medoid/median, affine sums for interval/ratio only with unit alignment). **If only a partial order is lawful, the Flow returns a set (portfolio/archive), never a forced scalarization.** Record **ReferencePlane** for every numeric edge.\n\n**Outputs:** `CAL.Flow[]` + legality proofs/links.\n**Guards:** Ordinal **MUST NOT** be averaged/subtracted; unit mismatches **fail fast**.\n\n**C5 - Evidence Wiring & Γ‑fold (R aggregation)** (declare **TA/LA/VA lanes + describedEntity‑E0 fields readable to SCR; Γ = weakest‑link unless proven otherwise; **Φ‑policies must be monotone and bounded**)\nFor each Operator/Flow, define **EvidenceProfile**:\n\n```\nEvidenceProfile :=\n⟨ lanes ∈ KD‑CAL[], anchors (A.10 carriers),\n  contribution to R via Γ-fold,\n  CL penalties routing (to R_eff; never to F),\n    ageing/decay policy (B.3.4),\n  freshness_window (Γ_time selector),\n  edition semantics for illumination/archives (see C6) ⟩\n```\n\nShip a **default Γ‑fold = weakest‑link**, overridable with proof of monotonicity & boundary behavior.\n**Outputs:** `CAL.EvidenceProfiles` + **SCR** fields to be emitted at run‑time.\n\nRecord **ReferencePlane** on each EvidenceProfile row and publish **Φ(CL)**/**Φ_plane** **policy‑ids** (table‑backed) for every predicate branch; **No self‑evidence** (A.10); unknowns escalate to {degrade|abstain} at Acceptance, with any **sandbox/probe‑only** handling modeled as a **SoS‑LOG** branch; penalties route to **R_eff only** (never F/G).\n\n**Publication hook for LOG.** EvidenceProfiles **SHALL** expose `profileId` and record **ReferencePlane**; these ids are **citable** from SoS‑LOG rules (C.23).\n\n**C6 - NQD Operators & Explore↔Exploit Policy Surface (QD & OEE‑ready)**\nWhere the CG-Frame needs search/generation, define **NQD‑class** operators with explicit:\n\n* **Portfolio coverage** obligations (C.18) and **QD‑metric triad**: *Quality (Q)*, *Diversity (D)*, *QD‑score*.\n* **Risk budgets** and **probe accounting** under **E/E‑LOG**.\n* **Illumination mode:** declare **Descriptor space** as `U.DescriptorMap (Tech; d≥2)` with its **CharacteristicSpace (Plain)** twin (E.10); provide `ArchiveRef`, **InsertionPolicyRef** (from G.5), and **IlluminationSummary := telemetry summary over Diversity_P**; record **Edition := {DHCMethodRef.edition, DistanceDefRef.edition}** on `DescriptorMapRef/ArchiveRef`. By default **Illumination does not enter dominance** unless an explicit policy id (Φ) says otherwise.\n* **OEE/GeneratorFamily support:** where tasks/environments are co‑evolved, register **GeneratorFamily (POET‑class)** with `EnvironmentValidityRegion` and `TransferRules`; author **Acceptance/SoS‑LOG branches** for {environment, method} pairs.\n* **Emission trace** schema (who/why/where → VariantPool metadata for G.1/M3), including **edition** bumps for archives/descriptors and the active **policy‑id**.\n\n+**Outputs:** `CAL.NQD[]` + policy knobs the **G.5 selector** can read (**EmitterPolicyRef**, **ArchiveRef**, **DescriptorMapRef** with **Edition{DHCMethodRef.edition, DistanceDefRef.edition}**, **IlluminationSummary**, **Q/D/QD‑score**).\n\n**Guards:** Probes **MUST** respect AcceptanceClauses; unsafe probes **MUST** abstain or sandbox.\n\n**C7 - Proof Obligations & Soundness Ledger**\nFor each Operator/Flow/Acceptance, attach **obligations**:\n* **Measurement legality** (scale/unit/polarity),\n* **Monotonicity / idempotence / stability** of aggregators,\n* **Assumption checks** (e.g., independence, convexity),\n* **Φ‑policy monotonicity/boundedness** (Φ(CL), Φ_plane) per published policy id (explicit link to EvidenceProfile rows),\n* **Degradation conditions** (when to drop to ordinal or abstain) and **tie‑handling rules** for partial orders (why a set is returned).\n\n* Log proofs or references; if empirical, bind to KD‑CAL lanes and A.10 carriers.\n* AcceptanceClause.Sketch: if CGSpecRefs ≠ ∅ then attach ProofRef: CAL.ProofLedger.Id (**A.18 CSLC** check)\n\n**Outputs:** `CAL.ProofLedger` (linked from UTS).\n**Guards:** Missing proofs **MUST** be visible in **SCR** (severity affects **R**, not **F**).\n\n**C8 - Publication, RSCR, and Bridges**\nPublish all CAL artifacts to **UTS** (with twin labels; Context noted; Bridges + CL + loss notes). Register **RSCR** tests:\n\n* Refuse illegal ops (e.g., `mean(ordinal)`),\n* Enforce **Guard Macros**,\n* Check Flow unit/scale coherence,\n* Verify **AcceptanceClause** semantics on Worked‑Examples; verify **ε‑Pareto** non‑scalarizing behavior; verify **freshness_window** enforcement.\n\n**Outputs:** `CAL Pack@CG-Frame` + RSCR ids + Worked‑Examples + deprecation notices (F.13).\n**Guards:** E.5.\\* (no tool lock‑in); lexical continuity (F.12/F.14).\n\n**C9 - Packaging & Refresh**\nVersion the CAL pack; set **refresh cadence** (evidence decay, probe telemetry, SoTA deltas). Track change‑impact to AcceptanceClauses and Flows; emit **deprecation** and **lexical continuity** notes. Record **PathSliceId** for telemetry updates and **edition** changes for archives/descriptors.\n**Outputs:** Versioned `CAL‑Pkg@CG-Frame` + refresh hooks.\n**Guards:** A.4 temporal duality; B.4 change rationale logged in **DRR**/**SCR**.\n",
        "interfaces_—_minimal_i/o_standard": "### G.4:6 - Interfaces — minimal I/O Standard\n\n| Interface             | Consumes                                 | Produces                                                                          |\n| --------------------- | ---------------------------------------- | --------------------------------------------------------------------------------- |\n| **G.4‑1 Charter**     | CG-FrameContext (G.1), SoTA Pack (G.2), CHR | `CAL.Charter@Context`, `TaskMap`                                                     |\n| **G.4‑2 Operators**   | CHR types, SoTA operator inventory (G.2) | `CAL.Operator[]` (UTS ids; legality guards; EvidenceProfiles)                     |\n| **G.4‑3 Acceptance**  | TaskMap, policy intents, CHR guards      | `CAL.Acceptance[]` (typed clauses; thresholds; failure policies)                  |\n| **G.4‑4 Flows**       | Operators, CHR AggregationSpecs          | `CAL.Flow[]` (typed pipelines; Γ‑fold hints; legality proofs)                     |\n| **G.4‑5 NQD Surface** | CHR types, E/E‑LOG policy                | `CAL.NQD[]` (emitters; risk budgets; telemetry schema)                            |\n| **G.4‑6 Publish**     | All above                                | Versioned `CAL Pack@CG-Frame`, RSCR tests, Worked‑Examples, Bridges/CL, deprecations |\n\n**Notes:** `CAL.NQD[]` SHALL expose `DescriptorMapRef`, `ArchiveRef`, **IlluminationSummary**, and publish **Q/D/QD‑score** fields; all Interfaces emitting numeric comparisons **MUST** cite **CG‑Spec.characteristic ids** and **ReferencePlane**.\n",
        "payload_(what_g.4_exports)": "### G.4:7 - Payload (what G.4 exports)\n\n1. **CAL Pack\\@CG-Frame** (folder):\n\n   * `CAL.Operator[]` (cards, signatures, guards)\n   * `CAL.Acceptance[]` (typed clauses)\n   * `CAL.Flow[]` (composition with legality checks)\n   * `CAL.EvidenceProfiles` + **Γ‑fold** annotations (with **ReferencePlane** & **Φ‑policy ids**)\n   * `CAL.NQD[]` (if applicable; with `DescriptorMapRef`, `ArchiveRef`, **IlluminationSummary**, **Q/D/QD‑score**, **edition**)\n   * `CAL.ProofLedger`\n   * **UTS entries** (Name Cards, twin labels, Bridges + CL/loss notes)\n   * **RSCR** tests + **Worked‑Examples**\n1. **Hand‑off manifests** to **G.5** (Eligibility Standards derive from Operator/Flow preconditions; Acceptance as selector gates; Evidence to **SCR**).\n",
        "conformance_checklist": "### G.4:8 - Conformance Checklist (normative)\n\n1. **Context declared.** Every CAL artifact has a **home Context**; cross‑Context reuse requires **Bridge + CL + loss note**.\n2. **Typed throughout.** Signatures, predicates, and flows **MUST** use **CHR** types (Characteristics/Scales/Units/Coordinates).\n3. **Legality enforced.** **Guard Macros** from **G.3** are attached and **RSCR‑tested**; ordinal arithmetic **MUST NOT** be performed.\n4. **CG‑Spec & CSLC.** Any operator/flow/acceptance that induces **numeric** comparison/aggregation **MUST** cite the **CG‑Spec.characteristic id** and **prove CSLC legality**. In Acceptance, supply `CGSpecRefs` and a `ProofRef` to the **CAL.ProofLedger**; otherwise **degrade/abstain**. Where only a partial order is lawful, the Flow returns a **set (Pareto/archive)** with optional **ε‑thinning**; **no forced scalarization**.\n5. **CHR binding in Acceptance**. `AcceptanceClause.CharacteristicRefs` SHALL enumerate CHR characteristics used by each threshold/comparison (machine‑checkable).\n6. **Evidence link in Acceptance**. `AcceptanceClause.EvidenceProfileRefs` SHALL list EvidenceProfile ids consulted by the clause so SCR can surface Φ(CL)/Φ_plane policy‑ids per branch.\n7. **C.21 guard‑bands live only in Acceptance** (no thresholds embedded in CHR); cross‑plane penalties recorded (**Φ_plane**) **with policy‑ids**; **no distance language**.\n8. **Acceptance explicit.** All thresholds/policies live in **AcceptanceClauses**, not in CHR or Operator definitions.\n9. **Evidence wired.** Each Operator/Flow declares lanes and anchors; **CL penalties** route to **R_eff** only (not **F**).\n10. **Γ‑fold & freshness recorded.** R aggregation rule (default **weakest‑link**) is stated; **freshness windows** are declared; contributors appear in **SCR**; **Φ‑policies** are cited by id and shown to be monotone/bounded.\n11. **Degradation safe.** When assumptions fail, flows **MUST** degrade (e.g., cardinal→ordinal) or **abstain**, never perform illegal ops.\n12. **No tool lock‑in.** No vendor keywords in core fields; implementations live under **E.5.\\***.\n13. **Lifecycle set.** Refresh/decay declared; deprecations follow **F.13–F.14** with **Lexical Continuity** notes.\n14. **UTS‑ready.** Names minted/reused; twin labels present; **Worked‑Examples** attached.\n15. **Φ‑policies monotone.** **Φ(CL)** and **Φ_plane** **MUST** be **monotone** and published by **policy id**; penalties route to **R_eff only** (never **F/G**). **Illumination** enters dominance **only** if an explicit **CAL.Acceptance** policy authorises it (policy‑id recorded in SCR); Φ‑policies do **not** govern dominance.\n16. **No self‑evidence (A.10).** EvidenceProfiles and Acceptance proofs **MUST NOT** rely on carriers produced by the same holon without an external **TransformerRole**; cyclic provenance fails acceptance.\n17. **QD/OEE readiness.** If **NQD** or **GeneratorFamily** are present: (a) publish `DescriptorMapRef` (Tech; d≥2) and **CharacteristicSpace (Plain)**; (b) expose **Q/D/QD‑score** and **IlluminationSummary**; (c) record **edition** on archive updates; (d) declare `EnvironmentValidityRegion` and `TransferRules`; (e) Acceptance/SoS‑LOG branches exist for {environment, method}.\n18. **No new U.Types for strategy/policy.** Strategies/policies are **compositions** governed by **E/E‑LOG** and registered via G.5, not minted as new core types.\n",
        "anti‑patterns_&_rewrites": "### G.4:9 - Anti‑patterns & rewrites\n\n* **Hidden thresholds.** *Don’t:* bake policy cut‑offs into CHR or code; *Do:* publish **AcceptanceClause** with Context‑local thresholds.\n* **Operator without signature.** *Don’t:* “score(x)” with implicit units; *Do:* declare `Signature: Project × SafetyClass(ord) × CostUSD(ratio) → {ord, ratio,…}` and guards.\n* **Globalized flows.** *Don’t:* reuse an optimization flow across Contexts without Bridge; *Do:* declare **Bridge + CL** and attach loss notes.\n* **Evidence blur.** *Don’t:* cite “validated” without lane; *Do:* mark **KD‑CAL** lane(s) + anchors and Γ‑fold effect.\n* **Design/run blur.** *Don’t:* trigger side effects inside selection; *Do:* keep selection pure (G.5), evaluation emits **DRR/SCR**.\n* **Forced scalarization.** *Don’t:* collapse partial orders to a single score; *Do:* return **non‑dominated sets (Pareto/archives)** with optional ε‑thinning; let **G.5** dispatch portfolios.\n",
        "consequences": "### G.4:10 - Consequences\n\n* **Safety by construction.** Illegal operations are blocked; acceptance becomes auditable.\n* **Comparable plurality.** Rival calculi co‑exist as separate **Operator/Flow** families with explicit Bridges and **CL**.\n* **Frictionless dispatch.** **G.5** reads typed **Eligibility** from CAL preconditions and gates by **AcceptanceClauses** with **SCR** ready.\n* **Pedagogical clarity.** Operator/Acceptance cards + Worked‑Examples make the calculus teachable and inspectable; QD/OEE fields clarify illumination portfolios without over‑scalarization.\n",
        "worked_micro‑example_(indicative)": "### G.4:11 - Worked micro‑example (indicative)\n\n*CG-Frame:* **R\\&D portfolio decisions** (same as G.1/G.3 for continuity).\n**CHR recap:** `SafetyClass` (ordinal ↑), `CostUSD_2025` (ratio), `Readiness` (nominal).\n\n**Operators:**\n\n* `DominatesPareto : Project×Project → bool` over ⟨↓CostUSD, ↑SafetyClass⟩ with `ORD_COMPARE_ONLY(SafetyClass)` + `UNIT_CHECK(CostUSD)`; lane = **LA**.\n* `BudgetFeasible : Portfolio → bool` with unit‑aligned sum; lane = **LA/VA**.\n* `LexiMinSafety : Portfolio → SafetyClass` (aggregator = lexicographic min); lane = **LA**.\n\n**AcceptanceClauses:**\n\n* `AC_SafetyGate`: *must meet* `SafetyClass ≥ B` (ordinal predicate; Context‑local levels).\n* `AC_Budget`: `TotalCostUSD_2025 ≤ Envelope`.\n* `AC_Explain`: DRR must cite top‑3 trade‑offs; lane = **VA** for exemplars.\n\n**Flows:**\n\n* `Flow_SelectPareto`: filter by `AC_Budget ∧ AC_SafetyGate`, compute Pareto front via `DominatesPareto`; Γ‑fold = weakest‑link over **LA/VA**.\n* `Flow_IlluminateAlternatives` (optional): run **NQD** over `U.DescriptorMap (Tech; d≥2)` with archive `ArchiveRef` and emitter `EmitterPolicyRef`; publish **IlluminationSummary** and **Q/D/QD‑score**; **does not enter dominance** unless Φ‑policy allows.\n\n**Evidence:**\n\n* CL penalty applied if `SafetyClass` is bridged from a *marketing* Context rating; penalty lowers **R_eff** only; **F** unchanged.\n* EvidenceProfile rows cite **ReferencePlane** and **Φ‑policy ids**; telemetry records **edition** on any archive update.\n\nRun‑time: **G.5** reads CAL preconditions/acceptance to form eligibility and gates; emits **DRR+SCR** citing Γ‑fold contributors.\n",
        "relations": "### G.4:12 - Relations\n\n**Builds on:** G.1, G.2, **G.3**; **MM‑CHR**; **F–G–R / KD‑CAL**; **Contexts/Bridges + CL**; **UTS**; **Role Assignment**.\n**Publishes to:** **G.5** (eligibility, acceptance, evidence), **UTS**, **RSCR**, Worked‑Examples.\n**Constrains:** any **LOG** implementation that executes these operators/flows; **SoS‑LOG** bundles MUST cite `clauseId`/`profileId` and honor portfolio/non‑scalarization contracts.\n",
        "author’s_quick_checklist": "### G.4:13 - Author’s quick checklist\n\n1. Write the **CAL Charter** and **TaskMap** for the CG-Frame.\n2. For each SoTA operator candidate, author an **OperatorCard** with typed signature, guards, lanes, proofs/anchors.\n3. Externalize all thresholds into **AcceptanceClauses**; define failure policies and safe degradations.\n4. Assemble **Flows** using CHR‑approved aggregators; attach Γ‑fold hints and legality proofs.\n5. Define **EvidenceProfiles** and **CL** routing; ensure **SCR** fields are computable.\n6. Publish to **UTS** with twin labels and Bridges; register **RSCR** tests; ship **Worked‑Examples**.\n7. Set **refresh/decay**; version the **CAL‑Pkg**; log change impact to **DRR/SCR**; wire **GateCrossing checks (E.18/A.21)**; ensure **QD/OEE** fields (DescriptorMapRef, ArchiveRef, IlluminationSummary, Q/D/QD‑score, **edition**) are present when NQD is used.\n",
        "g.4:end": "### G.4:End\n"
      },
      "content": "### G.4:End\n",
      "metadata": {},
      "part": "G",
      "cluster": null
    },
    {
      "id": "G.5",
      "title": "Multi‑Method Dispatcher & MethodFamily Registry",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## G.5 - Multi‑Method Dispatcher & MethodFamily Registry\n\n**Tag:** Architectural pattern (uses CHR/CAL/LOG)\n**Stage:** *design‑time* (authoring & registration) with a *run‑time* selector facade (policy‑governed; edition‑aware)\n**Primary hooks:** G.1 CG-Frame Card, G.2 SoTA Synthesis Pack, G.3 CHR authoring, G.4 CAL variants, **KD‑CAL** (C.2), **Trust & Assurance** (B.3), **Formality F** (C.2.3), **USM / Scope (G)** (A.2.6), **Bounded Contexts & Bridges with CL** (Part F + B‑patterns), **SCR/RSCR** (F.15), **NQD‑CAL** (C.18), **E/E‑LOG** (C.19), **SoS‑LOG** (C.23), **GateCrossing / CrossingSurface** (**E.18**; GateChecks **A.21**; Bridge+UTS **A.27**; BridgeCard **F.9**), **G.6 Evidence Graph (PathId)**, **UTS & Naming** (F.17–F.18), **Guard‑Rails E.5.1–E.5.3** (no tool lock‑in, unidirectional dependency), **CSLC** (A.18).\n",
        "intent": "### G.5:1 - Intent\n\nProvide a **notation‑independent** architecture to register **families of methods** (LOG bundles) and to **select, combine, or fall back** among them for a concrete problem instance—*given typed characteristics (CHR), admissible calculi (CAL), and trust constraints (F–G–R).* The pattern embraces **No‑Free‑Lunch** realities: *there is no universal best method*, so selection is **trait‑ and evidence‑aware**, under explicit **explore↔exploit** policy. The selector returns a **Pareto set** and explicit **abstain/degrade** outcomes under **No‑Free‑Lunch**, governed by the **E/E‑LOG** policy lens. Optionally, the selector operates in **Quality‑Diversity (Illumination)** and **Open‑Ended Family** modes that (co‑)evolve solver families and, when registered, their task/environments; both modes remain **notation‑independent** and policy‑governed.\n",
        "problem": "### G.5:3 - Problem\n\nHow to design a **general, auditable selector** that:\n\n* prefers **well‑matched** methods for a task instance (shape, noise, constraints) *without* hard‑coding an algorithmic dogma;\n* respects **Bounded Contexts**, using **Bridges + CL** only when crossing (with penalties routed to **R**, never **F**);\n* explains *why* a choice was made and **how much trust** it buys (F–G–R) with a **SCR**;\n* remains free of **tooling jargon** and **implementation bias** at the Core level.   \n",
        "forces": "### G.5:4 - Forces\n\n* **Pluralism vs. dispatchability.** Competing Traditions expose different invariants; the selector must compare **without semantic flattening**.\n* **Evidence vs. formality.** **F** shapes expression rigor; **R** tracks support; **G** is scope—**orthogonal** yet interacting under composition. \n* **Local semantics vs. reuse.** Cross‑Context reuse requires **Bridges** with **CL** and **loss notes**; penalties hit **R_eff**, not F. \n* **Exploration vs. exploitation.** Run‑time must sometimes **probe alternatives** (NQD/E‑E), but within declared **risk envelopes**.\n",
        "solution": "### G.5:5 - Solution — *Dispatcher & Registry chassis*\n\n**Selection kernel.** Apply **lawful orders only**; for partial orders **return a set** governed by **`PortfolioMode ∈ {Pareto | Archive}`** (default **Pareto**; **Archive** when QD is active), no forced scalarisation; **unit/scale mismatches fail fast**. **Default `DominanceRegime = ParetoOnly`; inclusion of Illumination in dominance requires an explicit `CAL.Acceptance` policy and its policy‑id recorded in SCR.** Eligibility/Acceptance are **tri‑state**; unknowns behave per MethodFamily policy (**pass**/**degrade**/**abstain**) and are logged in **SCR** **together with MinimalEvidence verdicts for each referenced characteristic**; **gate additionally by CG‑Spec.minimal_evidence** (by Characteristic id) before applying orders. **SoS‑LOG rule sets (C.23) are the executable shells consumed here**; any **maturity floors** are enforced via **CAL.AcceptanceClause** (not by LOG). **Maturity is an ordinal poset; no global scalarisation is permitted in Core.**\n\n**Strategizing escalation.** When no admissible `MethodFamily` exists for the declared `TaskSignature`, the selector **MUST NOT fail closed**; it **SHALL** return an **empty `CandidateSet`** together with a **`Run‑safe Plan`** that includes an **`ActionHint=strategize`** (C.23 branch‑id), and—where registered—a **`GeneratorFamily`** stub (`EnvironmentValidityRegion`, `TransferRulesRef`). This escalates to **method creation/selection** under **E/E‑LOG**, avoiding ad‑hoc execution.\n\n**Telemetry & parity.** Open hooks for **G.11** (refresh) and **G.9** (parity/baselines). Route **CL penalties → R_eff only**; declare **ReferencePlane** for any claim; **record Φ(CL)/Φ_plane policy‑ids in SCR (Φ MUST be monotone and bounded)**; on plane/context crossings **cite Bridge ids**. When **Illumination** is active, compute and publish **Q (quality), D (diversity), and QD‑score** and the **Archive state**; **IlluminationSummary is a lawful telemetry summary over `Diversity_P`** and **does not enter dominance** unless an explicit **CAL** policy states otherwise **and its policy‑id is recorded in SCR**. **Any increase of Illumination MUST log `PathSliceId`, the active policy‑id, and the active editions of `DescriptorMapRef` and `DistanceDefRef`.**\n\n“Strategy” is a **composition** inside G.5 under **E/E‑LOG** governance; **no new U.Type ‘Strategy’** is minted (**Plain‑register only** per E.10).\n\n**S1 - MethodFamily Registry (design‑time, per CG-Frame)**\nDefine a **registry row** per *MethodFamily* (e.g., *Outranking*, *CDT*, *Active‑Inference*, *Pareto‑front MOMAs*, *Gradient‑based optimizer*, *RL policy search*), each row comprising:\n\n* **Identity:** local Context, lineage/Tradition, version, **UTS name card**;\n* **SolverSignature:** I/O contracts and invariants (types, units, monotonicity), objective kinds, side‑effect constraints;\n* **ValidityRegion:** declared TaskClass and tolerances (shape/conditioning/noise) for which guarantees apply; if applicable, **EnvironmentValidityRegion** (for co‑evolved tasks);\n* **Eligibility Standard** (typed): required **Object/Task kinds**, **Data shape/regularity traits**, **Noise/uncertainty model**, **Resource envelope**, **Scope prerequisites** (USM claims), **Evidence lanes per KD‑CAL** (e.g., VA/LA/TA) it relies on; **predicates MUST support tri‑state {true|false|unknown} and define a failure policy for `unknown` (degrade/abstain)**. If a “sandbox/probe‑only” route is desired, it MUST be modeled as a distinct **SoS‑LOG** branch (C.23) with a branch‑id and not as a fourth Acceptance status;\n* **Assurance profile:** **I/D/S** of the method artefact (e.g., `MethodDescription` vs `MethodSpec` per E.10.D2), **Formality F** anchored to **U.Formality** scale **F0…F9** (C.2.3), expected **R** lane(s), **CL** allowances for cross‑Context operation; **CL penalties SHALL route to R_eff only**;\n* **Guarantees:** accuracy/robustness/regret bounds and their preconditions; **EvidenceRefs** to **EvidenceGraph** paths supporting claims;\n* **CostModel** and **KnownFailures** (adversarial/degenerate cases);\n* **PolicyHooks:** E/E‑LOG knobs (exploration quota, risk budget); optional **EmitterPolicyRef** (C.19) when Illumination is used;\n* **BridgeUsage:** declared Bridges and **CL** allowances with loss notes for any cross‑Context transfer;\n* **Twin‑naming (E.10):** **Tech:** `U.DescriptorMapRef`; **require `d≥2` only when QD/illumination surfaces are active** (otherwise `d≥1` is lawful); **Plain twin:** `CharacteristicSpaceRef`. **Aliases between them are forbidden** (distinct objects);\n* When Illumination is used, declare `U.DescriptorMapRef.edition` and **pin all QD metrics to it**, together with **`DistanceDefRef.edition`** (diversity metric) and **`DHCMethodRef.edition`** to ensure reproducible fronts;\n* **InsertionPolicyRef** for archives (elitist replacement, **K‑capacity**, dedup/tie rules);\n* **Proof obligations** (what must be established before/after selection).\n* **Artefacts:** list **MethodDescription** ids (UTS); where harnessed, also **MethodSpec** ids; cross‑Context reuse requires Bridges + CL.\n\n  All fields are **Core‑level concepts**; concrete notations live in Tooling per **E.5.1–E.5.3**. Publish to **UTS** with twin labels and loss notes if bridged. \n\n**S1′ - GeneratorFamily Registry (design‑time, Open‑Ended mode)**\nRegister **GeneratorFamily** (POET/Enhanced‑POET‑class) entries that (co‑)evolve **tasks/environments** and solvers. Each row declares:\n* **GeneratorSignature** (I/O, state, budget semantics), **EnvironmentValidityRegion**, **TransferRules** (when/what to transfer across environments) with **`TransferRulesRef.edition` (mandatory in OEE mode)**, **CoEvoCouplers** (which MethodFamilies co‑evolve), **Stop/Refresh** conditions;\n* **SoS‑LOG/Acceptance hooks** (discipline‑level gates for validity of generated tasks); any thresholds live in CAL.Acceptance (not LOG);\n* **Publication shape:** the selector returns portfolios of pairs `{Environment, MethodFamily}` with their **Eligibility/Assurance** and **PortfolioMode**; telemetry records **coverage/regret** and **IlluminationSummary** (**edition‑aware**, pinned to `DescriptorMapRef.edition` and `DistanceDefRef.edition`).\n\n**S2 - TaskSignature & Trait Inference (design‑time + run‑time)**\nA **TaskSignature** is a *minimal typed record* the dispatcher consumes:\n`⟨Context, TaskKind, KindSet:U.Kind[], DataShape, NoiseModel, ObjectiveProfile, Constraints{incl. ResourceEnvelope}, ScopeSlice(G), EvidenceGraphRef, Size/Scale, Freshness, Missingness, PortfolioMode⟩`. Values are **CHR‑typed** (Characteristics/Scales/Levels/Coordinates per MM‑CHR discipline) with provenance. Traits may be **inferred** from CHR/CAL bindings (e.g., *convexity known? differentiable? ordinal vs interval scales?*) and from **USM** scope metadata. **When Illumination is active**, extend with `QualityDiversity: {DescriptorMapRef (Tech; d≥2), CharacteristicSpaceRef (Plain twin)}`, `ArchiveConfig (grid/CVT cells)`, `EmitterPolicyRef`, `InsertionPolicyRef`, `DistanceDefRef.edition`, `Q‑budget/D‑budget`. Descriptor and space are distinct objects (no aliases) and must be provided as twins.\n**Design/Run hygiene.** No mixed‑stance signatures; GateCrossings publish Bridge+UTS and record **Φ(CL)/Φ_plane** ids.\n**UnknownHandling:** all fields admit `unknown` (tri‑state {true|false|unknown}); **Missingness semantics MUST align with CHR.Missingness** (MCAR/MAR/MNAR or mapped equivalents) and be honored by Acceptance/Flows.\n\n**S3 - Selection Kernel (run‑time, policy‑governed)**\n**No‑Free‑Lunch is enforced**: choose Tradition/Operator sets from the SoTAPaletteDescription conditioned on task/object/CHR preconditions, rather than by “universal” cross‑Tradition formulas in CG‑Spec. Selector decisions MUST cite palette entries and CHR/CAL constraints used. **CG‑Spec MUST NOT override this with one‑size‑fits‑all formulas.**\n\nThe selector MUST:\n\n(1) read SoTAPaletteDescription,\n(2) filter Traditions by CHR preconditions and KD‑CAL lane fit,\n(3) pick operators consistent with declared scales and taboos,\n(4) emit a rationale with links to palette entries and Worked Examples.\n\nA **pure selector** computes a **CandidateSet** with an **admissible (possibly partial) order** (no illegal cross‑scale scoring) and constrained by an *AssuranceGate*:\n\n1. **Eligibility filter:** `MethodFamily` passes iff all **Eligibility Standard** predicates hold **and** all **CG‑Spec.MinimalEvidence** gates for referenced characteristics are met; **if CG‑Frame uses NQD, enforce `ConstraintFit=pass` before front selection**; otherwise **abstain**. Where a “sandbox/probe‑only” route is intended, express it via a dedicated **SoS‑LOG** branch (C.23) with a branch‑id; Acceptance remains tri‑state {pass|degrade|abstain}.\n2. **CG‑Spec gate:** require all **CHR characteristics** referenced by Acceptance/Flows to meet the **CG‑Spec.minimal\\_evidence** in the current Context; otherwise **abstain** under E/E‑LOG. If a probe‑only path is needed, route via a dedicated **SoS‑LOG** branch (C.23).\n3. **Admissible preference:** apply **lexicographic** precedence over lawful traits (e.g., *assumption fit* ≻ *evidence alignment* ≻ *resource/cost*). **Weighted sums across mixed scale types (ordinal vs interval/ratio) are forbidden**; prefer lexicographic/medoid/median where lawful; **any unit/scale conversions MUST be proven legal via CSLC (A.18) before aggregation**.\n4. **F–G–R aware gating:** compute **R_eff** with **Γ‑fold** (default = weakest‑link; **override only if CAL/EvidenceProfile supplies an alternative with proofs of monotonicity & boundary behavior**) and apply **CL** penalties (R_eff only; F and G invariant); block candidates failing *minimum R*; **record Γ‑fold contributors explicitly in SCR**. **F** is read from method formalisation level; **G** from **USM** slice; penalties **never alter F**. \n5. **Partial‑order handling:** if after gating the order is not total, **return a Pareto (non‑dominated) set** and explain tie‑criteria in DRR/SCR; do not force a total order via illegal scalarization.\n6. **Explore↔Exploit policy:** under **E/E‑LOG**, admit a quota of **NQD‑emitted** alternatives (guarded by risk budgets) to avoid local optima; log probes and outcomes for **refresh**. In **Illumination** mode, selection produces/updates an **Archive** (cells/niches) and computes **Q/D/QD‑score** per edition; ordering within a niche remains lawful (lexicographic/median), never cross‑scale weighted sums.\n\n**S4 - Composition & Fallbacks (design‑time templates)**\nProvide templates for **composed strategies**: (i) *pre‑conditioners* (e.g., rescale/denoise), (ii) *meta‑selectors* (e.g., *small‑n* vs *large‑n* switch), (iii) *cascade fallbacks* on **Assurance failure** (e.g., degrade objective from cardinal to ordinal when CHR forbids interval arithmetic). Guard with **CSLC (A.18)** for **unit/scale legality**; **disallow illegal ordinal arithmetic**.\nAdd a **Verifier stage**: on run‑time preconditions failing or **evidence freshness** expiring, trigger the next lawful fallback; emit DRR/SCR deltas.\n\n**S5 - Publication & Telemetry**\nEach selection produces a **Decision Rationale Record (DRR)** + **SCR**, citing chosen family, **why**, **CG‑Spec ids and characteristics consulted with MinimalEvidence verdicts (per characteristic & lane)**, **Γ‑fold contributors**, **ReferencePlane & CL^plane usage**, **CL penalties**, expected **R_eff**, and any **explore** probes. Register the family and selection policy to **UTS** **with twin labels and loss notes where bridged**; provide **RSCR** parity/regression tests as conformance artefacts. **Record on‑policy outcomes and off‑policy regret signals via telemetry (G.11)** to support registry refresh.  \n\n**If Illumination is active,** also publish **IlluminationSummary** (Q/D/QD‑score, Archive snapshot, coverage/regret) and `DescriptorMapRef.edition` with `DistanceDefRef.edition`/`DHCMethodRef.edition`; in **Open‑Ended** mode publish `{Environment, MethodFamily}` portfolios with their coverage **and record `TransferRulesRef.edition`**. **Exports also include:** a **Dispatcher Report** (candidates and reasons in/out), a **Portfolio Pack** (_Pareto set_ + tie‑break notes), and a **Run‑safe Plan** (flows + legality proofs).\n\nFor any **Illumination increase**, telemetry **MUST** record the **`PathSliceId`**, the **active policy‑id**, and the active **editions** of `DescriptorMapRef` and `DistanceDefRef`; **in Open‑Ended (GeneratorFamily) mode it MUST also record `TransferRulesRef.edition`**. These **MUST** be visible to **RSCR** triggers.\n\n**S6 - Governance & Evolution**\n\n* **Unidirectional dependency:** Registry and selector are Core patterns; implementations are Tooling; tutorials are Pedagogy.\n* **Change control:** versioned entries; deprecations flow through **Lexical Continuity** and **Worked‑Examples** refresh.\n\n> **Julia‑style specialisation (design idiom).** Use **trait‑like dispatch** and **parametric specialisation** *at the level of typed Standards*, not code, to keep selection semantics **portable** across languages and stacks. The Core remains **notation‑independent**.\n",
        "interfaces_—_minimal_i/o_standard": "### G.5:6 - Interfaces — minimal I/O Standard\n\n| Interface                | Consumes                                                | Produces                                                                      |\n| ------------------------ | ------------------------------------------------------- | ----------------------------------------------------------------------------- |\n| **G.5‑1 RegisterFamily** | SoTA row(s) from **G.2**, CHR/CAL stubs (G.3/G.4), Context | `MethodFamily` record (eligibility Standard, assurance profile, UTS entry id) |\n| **G.5‑2 RegisterGeneratorFamily** | SoTA row(s) from **G.2**, Context | `GeneratorFamily` record (GeneratorSignature, EnvironmentValidityRegion, TransferRules **(+ TransferRulesRef.edition in OEE)**, CoEvoCouplers, Acceptance hooks) |\n| **G.5‑3 Select**         | `TaskSignature`, policy (E/E‑LOG), **SoS‑LOG rules (C.23)**, acceptance clauses   | `CandidateSet` with admissible (possibly partial) order; **return a set per `PortfolioMode`** (Pareto or Archive) when the order is non‑total; chosen `MethodFamily`; **DRR + SCR** (F–G–R/CL, **ReferencePlane & Φ ids**); **Portfolio Pack** (return mode + tie‑break notes); **Run‑safe Plan** (flows + legality proofs); **if no candidate is admissible**, emit `ActionHint=strategize` (with responsible **C.23 branch‑id**) and **MAY** include a minimal `GeneratorFamily` stub (EVR + `TransferRulesRef.edition`) for lawful exploration under **E/E‑LOG**. |\n| **G.5‑4 Compose**        | `CandidateSet`, composition template                    | Composite strategy spec (with legality checks)                                |\n| **G.5‑5 Telemetry**      | Outcomes, probes                                        | Registry refresh cues; RSCR deltas; (if Illumination) Q/D/QD‑score + Archive deltas + `DescriptorMapRef.edition`/`DistanceDefRef.edition`/**`CharacteristicSpaceRef.edition` when a domain‑family coordinate is declared per C18‑1b**, **`PathSliceId`**, **policy‑id**; (if Open‑Ended) coverage/regret per `{Environment, MethodFamily}` |\n",
        "conformance_checklist": "### G.5:7 - Conformance Checklist (normative)\n\n**CC‑G5.0** Core Standards **SHALL** remain notation‑independent; vendor/tool keywords are forbidden in eligibility or assurance fields (E.5.1–E.5.3).\n**CC‑G5.1** Every `MethodFamily` **SHALL** declare an **Eligibility Standard** using CHR terms; Standards **SHALL NOT** rely on tool‑specific keywords.\n**CC‑G5.2** Selection **SHALL** be a **pure function** of `TaskSignature` + policy; side effects limited to DRR/SCR emission.\n**CC‑G5.3** Cross‑Context use **MUST** cite a **Bridge** with **CL**; penalties **MUST** flow to **R_eff**; **F** and **G** remain invariant; **attach a loss note**. \n**CC‑G5.4** The selector **MUST** **default** to the **weakest‑link** rule for **R_eff** and record contributors in **SCR**; it **MAY** use an alternative Γ‑fold **only** when provided by CAL with proof obligations satisfied (monotonicity, boundary behavior).\n**CC‑G5.5** Ordinal scales **MUST NOT** be averaged/subtracted; unit/scale legality **MUST** be enforced by CHR guards.\n**CC‑G5.6** Chosen families **SHALL** be published to **UTS** with twin labels and scope notes; deprecations follow F.13.\n**CC‑G5.7** Exploration **MUST** be budgeted under **E/E‑LOG**; probe outcomes **MUST** feed refresh.\n**CC‑G5.8** **CG‑Frame gate enforced.** Selection rejects candidates that do not meet **CG‑Spec.minimal_evidence** for the characteristics they use; **Maturity floors** (if present) are enforced via **AcceptanceClauses**.\n**CC‑G5.9** **Admissible ordering.** Candidate ordering **MUST** be lexicographic or otherwise lawful over CHR‑typed traits; **weighted sums across ordinal/interval/ratio mixes are forbidden**. If only a partial order is available, **return a Pareto set**.\n**CC‑G5.10** **SCR completeness.** SCR **MUST** enumerate Γ‑fold contributors, **CG‑Spec characteristics** used, and **MinimalEvidence gating verdicts** (by lane & carrier).\n**CC‑G5.11** **Tri‑state eligibility.** Eligibility predicates **MUST** define behavior for `unknown` (**degrade/abstain**); **unknowns propagate into Acceptance decisions**; silent coercion to `false` is forbidden. Any “sandbox/probe‑only” handling MUST be modeled as a dedicated **SoS‑LOG** branch (C.23) with a branch‑id, not as a fourth Acceptance status.\n**CC‑G5.12** **No “universal” cross‑Tradition scoring.** Cross‑Tradition selection **MUST NOT** rely on a single numeric formula not justified by CHR/CAL and CG‑Spec.  Enforce heterogeneity gate: FamilyCoverage ≥ 3 and MinInterFamilyDistance ≥ δ_family for triads/portfolios that claim universality; cite **Context Card id (F.1)** in DRR/SCR.\n**CC‑G5.13** The selector **MUST NOT** recompute Acceptance thresholds or Maturity floors; it **consumes** `AdmissibilityLedger@Context` rows (C.23) and **cites** the referenced clause/rung ids in SCR.\n**CC‑G5.14** **Φ(CL) and (where applicable) Φ_plane MUST be monotone and bounded, and published in CG‑Spec;** SCR **MUST** record the policy‑id in use.\n**CC‑G5.15** **Units/scale legality MUST be proven via CSLC (A.18) before any aggregation or Γ‑fold;** unit/scale mismatches fail fast. *(Complements CC‑G5.5 on ordinal arithmetic.)*\n**CC‑G5.16** **Hidden thresholds are forbidden.** All thresholds live in **AcceptanceClauses** (not in CHR, LOG, or code).\n**CC‑G5.17** **ReferencePlane MUST be declared for any claim and noted in SCR,** including **CL^plane** usage for plane crossings.\n**CC‑G5.18** **Numeric comparisons/aggregations MUST cite a lawful CG‑Spec SCP with declared Γ‑fold;** cross‑Context reuse **requires Bridge + CL**, with penalties routed to **R_eff** only (never **F**).\n**CC‑G5.19** **Illumination triad.** When Illumination is active, **Q, D, and QD‑score MUST be computed and published** with Archive state; **Illumination is excluded from dominance unless explicitly enabled by policy.**\n**CC‑G5.20** **Telemetry semantics.** **IlluminationSummary SHALL be treated as a telemetry summary over `Diversity_P`**; inclusion in dominance requires an explicit **CAL** policy with a recorded **policy‑id** in SCR.\n**CC‑G5.21** **Archive reproducibility.** Any use of archives **MUST** declare **`InsertionPolicyRef`** (replacement, **K‑capacity**, dedup/tie rules) and record **`DistanceDefRef.edition`** and **`DHCMethodRef.edition`**; **`DescriptorMapRef.edition` MUST** be logged in telemetry; **all QD metrics SHALL be pinned to `DescriptorMapRef.edition`**.\n**CC‑G5.22** **Twin‑naming (E.10).** Use **Tech** `U.DescriptorMapRef` (d≥2) with **Plain twin** `CharacteristicSpaceRef`; **aliases are forbidden** (they are distinct objects).\n**CC‑G5.23** **Portfolio mode.** The selector **MUST** expose **`PortfolioMode ∈ {Pareto | Archive}`** (**default = Archive**) and echo it in DRR/SCR and the Portfolio Pack; ε‑fronts are allowed as *local* decision aids under CG‑Spec.\n**CC‑G5.24** **Open‑Ended portfolios.** In Open‑Ended mode, the selector **MUST** return portfolios of `{Environment, MethodFamily}` pairs; **EnvironmentValidityRegion** and **TransferRules** **MUST** be declared; SoS‑LOG/Acceptance branches govern validity of generated tasks.\n**CC‑G5.25** **Transfer rules edition (OEE).** In OEE mode, **`TransferRulesRef.edition` is mandatory** and **MUST** be visible to Telemetry and **RSCR** triggers.\n**CC‑G5.26** **Lawful ordering in niches.** Within any archive niche/cell, ordering **MUST** be lawful (lexicographic/medoid/median over compatible scales); **weighted sums across mixed scale types are forbidden**.\n**CC‑G5.27** **GateCrossing visibility (CrossingSurface).** Any **GateCrossing** (E.18) referenced by the selector **MUST** publish **CrossingSurface** (**E.18:CrossingSurface**); missing or non‑conformant CrossingSurface is a **fail‑fast** defect of publication and blocks downstream consumption.\n**CC‑G5.28** **Dominance policy default.** `DominanceRegime` **SHALL** default to `ParetoOnly`; inclusion of illumination in dominance **MUST** be explicitly authorised by **CAL.Acceptance** (`ParetoPlusIllumination`) with the policy‑id recorded in SCR; **parity‑run publication (CC‑G5.23a) remains mandatory** irrespective of dominance policy.\n**CC‑G5.29** **Illumination increase logging.** Any **increase in Illumination** **MUST** log `PathSliceId`, **policy‑id**, and the active **`DescriptorMapRef.edition`/`DistanceDefRef.edition`** in telemetry and expose them to **RSCR** triggers; **in Open‑Ended (GeneratorFamily) mode, `TransferRulesRef.edition` MUST also be logged.**\n**CC‑G5.30** **No Strategy minting (centralised).** “Strategy/policy” are **compositions** governed by **E/E‑LOG** and published via **G.5.Compose**; **no new `U.Type` “Strategy”** may be minted by other Part G patterns.\n**CC‑G5.31 (Strategy hint on non‑admissible sets).** If selection yields **∅** under the active SoS‑LOG and Acceptance, the selector **SHALL** emit `ActionHint=strategize` with the responsible **C.23 branch‑id** and **MAY** include a `GeneratorFamily` stub (EVR + `TransferRulesRef.edition`) to guide exploration under **E/E‑LOG**.\n**CC‑G5.32** **Parity‑run publication.** A selector/generator **MUST** publish an **Illumination Map** (archive topology + coverage per niche with `DescriptorMapRef`/`DistanceDefRef.edition`). **Single‑score leaderboards are forbidden**; any roll‑up **MUST** be lawful under **CG‑Spec** (no mixed‑scale sums).\n",
        "consequences": "### G.5:8 - Consequences\n\n* **Auditable plurality.** Rivals co‑exist, selected with **explainable** trust and scope handling.\n* **Safety by construction.** Illegal measurements and cross‑Context leaks are blocked by Standard and CL penalties. \n* **Evolvability.** Families can be **added/retired** without rewriting the selector; UTS provides a stable publication surface.\n",
        "worked_micro‑examples_(indicative)": "### G.5:9 - Worked micro‑examples (indicative)\n\n**9.1 Decision Theory (multi‑Tradition)**\n`TaskSignature:` *one‑shot, high‑stakes, observational dataset; causal graph partially known; counterfactuals needed; ordinal preference ordering only in some panels; strict risk constraint.*\n\n* Eligibility filters admit **CDT** (needs counterfactuals), **EDT** (if evidential suffices), **Active‑Inference** (if a generative model with variational free energy is in scope), and **reject cardinal EU** where CHR shows *ordinal‑only* preferences.\n* CL appears if a *psychological Context* Bridge is used for utility elicitation; selector applies **CL penalty** to **R_eff** only; **F** remains the method’s declared formalism level. **DRR** explains the choice (CDT) and logs an **NQD** probe of *Active‑Inference* under small budget. \n\n**9.2 Creativity (portfolio search)**\n`TaskSignature:` *wide design space; resource cap; novelty emphasis; diversity quota.*\n\n* Registry offers **Pareto‑front NQD** and **IPO‑style recombiners**; **E/E‑LOG** sets an explore‑heavy policy initially, then shifts to exploit on observed Use‑Value. **SCR** reports that Use‑Value evidence is **LA** lane while novelty scoring rests on **VA** heuristics. \n\n**9.3 Quality‑Diversity & Open‑Ended (GeneratorFamily portfolios)**  \n`TaskSignature:` *co‑evolving task family; descriptor map d≥2; risk‑budgeted exploration; environment shifts allowed; strict ConstraintFit gate; freshness windows active.*\n\n* **Registry (design‑time).** Register a **GeneratorFamily** of the **POET/Enhanced‑POET (and compatible DGM‑class)** with  \n  `EnvironmentValidityRegion := {grid mazes with dynamic doors; hazard_intensity ≤ L2; size ≤ 50×50}`,  \n `TransferRules (+ TransferRulesRef.edition) := {transfer policy when ConstraintFit=pass; else abstain; reset if MinInterFamilyDistance < δ}`,  \n  `CoEvoCouplers := {RL‑policy‑search, CMA‑ME planner}`; attach **SoS‑LOG/Acceptance** branches for validity of generated tasks (no lethal hazards; budget ≤ envelope). *CL penalties route to R_eff only; F/G stay invariant; ReferencePlane is recorded on every claim.*\n\n* **Selection (run‑time).** The dispatcher reads the SoTA palette and CAL gates, applies **ConstraintFit=pass** as a hard eligibility filter, then produces a **portfolio of pairs** `{Environment, MethodFamily}`:  \n – a **Pareto/Archive** (per `PortfolioMode`) over niches (quality/diversity lawful order; no forced scalarization),  \n  – ε‑Pareto thinning when applicable,  \n  – ties broken by lawful lenses only. *Illumination does **not** enter dominance unless policy explicitly promotes it.*\n\n* **Policy (E/E‑LOG).** Use a named **lens** `Barbell` with `explore_share ≈ 0.4`, `wild_bet_quota = 2`, `backstop_confidence = L1`; cite `EmitterPolicyRef` (UCB‑class, moderate τ). Record the **lens id** and **policy‑id Φ** in provenance.\n\n* **Telemetry & publication.** Emit **DRR+SCR** with: CG‑Spec characteristics consulted and MinimalEvidence verdicts (by lane), Γ‑fold contributors, ReferencePlane/CL^plane usage, CL penalties→R_eff, selected `{Environment, MethodFamily}` portfolio, and probe logs. Publish **IlluminationSummary** with `Q/D/QD‑score`, Archive snapshot, and **DescriptorMap edition** (`{DHCMethodRef.edition, DistanceDef}`); for open‑ended mode also publish **coverage/regret per {Environment, MethodFamily}**. Register families and policies to **UTS** (twin labels; loss notes where bridged).\n\n",
        "relations": "### G.5:10 - Relations\n\n**Builds on:** G.1–G.4; **F–G–R / KD‑CAL**; **Formality F**; **USM**; **Bridges & CL**; **Guard‑Rails E.5.\\***.    \n**Publishes to:** **UTS**, Worked‑Examples, RSCR.\n**Constrains:** any run‑time *selector implementations* (Tooling) via the Core Standards.\n",
        "editorial_notes_(authoring_guidance)": "### G.5:11 - Editorial notes (authoring guidance)\n\n* Keep **Standards minimal** and **typed**; resist adding tool‑level flags to the Core (route to Tooling Glossaries).\n* Treat **composition patterns** as first‑class (preconditioner → solver → verifier); publish each as a **UTS row** with clear Contexts.\n* When a selection *raises F* (e.g., recasting acceptance as predicates), record **ΔF** separately from **ΔG/ΔR**.\n",
        "quick_author_checklist": "### G.5:12 - Quick author checklist\n\n1. Register ≥ 3 **MethodFamilies** per competing Tradition with typed **Eligibility** and **Assurance**.\n2. Define the **TaskSignature** schema for the CG-Frame; prove it is **minimal** but **sufficient** for dispatch.\n3. Implement **Selection Kernel** as a pure Core algorithm; ensure **CL penalties** and **weakest‑link R** are computed and logged in **SCR**.\n4. Publish families and selection policy to **UTS**; add one **Worked‑Example** per policy branch.\n5. Provide **RSCR** parity/regression tests as conformance obligations; ensure telemetry hooks (G.11) are connected.\n",
        "g.5:end": "### G.5:End\n"
      },
      "content": "### G.5:End\n",
      "metadata": {},
      "part": "G",
      "cluster": null
    },
    {
      "id": "G.6",
      "title": "Evidence Graph & Provenance Ledger",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## G.6 - Evidence Graph & Provenance Ledger\n\n**Tag:** Architectural pattern\n**Stage:** design‑time (assembly) + run‑time (telemetry ingestion)\n**Builds on:** A.10 (Evidence Graph Referring), B.3 (Assurance), G.4 (CAL.ProofLedger & EvidenceProfiles), F.9 (Bridges/CL), **C.18 (NQD‑CAL)**, **C.19 (E/E‑LOG & policies)**, **E.18/A.21/A.27** (GateCrossing/CrossingSurface checks), E.8 (template), E.10 (LEX), C.23 (**Science‑of‑Science LOG**, SoS‑LOG hooks)\n**Publishes to:** **Unified Term Sheet (UTS)** (twin‑label **Name Card**s), RSCR, G.5 selector (by PathId citation), **G.11 Telemetry/Refresh**\n**Guards respected:** Notational independence (E.5.2), lexical discipline (E.10), lane separation (TA/VA/LA), CL→R routing only, Γ‑fold = WLNK unless proven otherwise\n",
        "problem": "### G.6:2 - Problem\n\n1. Readers cannot **audit CL penalties and decay** on SoTA claims without chasing many tables. 2) Cross‑Context reuse must prove penalties hit **R only** (not F/G) and expose the **lowest‑link** path; today this is implicit. 3) **Maturity** decisions (C.23) need a stable **PathId** to re‑check later or in other Contexts.\n",
        "forces": "### G.6:3 - Forces\n\n| Force                        | Tension                                                                                                                                                                                     |\n| ---------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **Provenance vs agility**    | Fine‑grained audit trails ↔ friction for authors.                                                                                                                                           |\n| **Lane purity vs synthesis** | Keep TA/VA/LA separable ↔ Publish a single *why* for admission.                                                                                                                             |\n| **Notation independence**    | Define semantics in prose/math ↔ teams want diagrams/tables (kept informative only).                                                                                                        |\n| **Design vs run**            | Evidence at design‑time vs telemetry at run‑time must not be conflated.                         |\n| **Plane mixing**             | World↔Concept↔Episteme crossings must be penalised only in **R** and be table‑backed Φ‑policies. |\n",
        "solution": "### G.6:4 - Solution — **EvidenceGraph** (notation‑independent; lane‑aware; path‑addressable)\n\n**4.1 Definition (object).**\nAn **EvidenceGraph** is a **typed DAG** whose nodes are the **A.10 anchors/carriers and evidencing roles** and whose edges are minimal, normative provenance relations. Each node/edge carries attributes sufficient for the B.3 trust calculus and E.10 lexical discipline; edges never build mereology (A.10 firewall).\n\n* **Nodes (informative types)**: `U.EvidenceRole` (holder = `U.Episteme`), `SymbolCarrier`, `TransformerRole` (external), `MethodDescription` (design), `Observation` (dated result); all resolvable to **SCR/RSCR** rows. **When QD/illumination or portfolio selection is involved (C.18/C.19), nodes MAY carry:** `U.DescriptorMapRef` **(with** `edition` **and** `DistanceDef` **ids)**, `ArchiveCellRef`, `EmitterPolicyRef`, and `InsertionPolicyRef` (K‑capacity & replacement semantics) **as attributes**.\n* **Edges (normative vocabulary, minimal):** `verifiedBy` (formal line), `validatedBy` (empirical line), `fromWorkSet` (run‑time provenance), `happenedBefore` (temporal), `derivedFrom`.  \n* **Informative only:** `usedCarrier`, `interpretedBy` MAY appear in SCR narratives but are not part of the normative edge set. **No mereology** here; structural relations publish via CT2R‑LOG.\n* **Lane tags:** every binding is typed with **assuranceUse ∈ {TA, VA, LA}** and kept separable through to the assurance tuple and SCR display.\n* **Context & Plane:** nodes and claims declare `U.BoundedContext` and **ReferencePlane**; any crossing uses a **Bridge** with **CL / CL^k / CL^plane** and **loss notes**, and **penalises only R** via published, table‑backed **Φ/Ψ** policies.\n* **Freshness/decay:** empirical bindings declare **time windows**; on expiry they incur **Epistemic Debt** that must be resolved via refresh/deprecate/waive; proofs may fence to a **TheoryVersion** (no decay). **Editioned telemetry** MUST cite `PathSliceId` and any `U.DescriptorMapRef.edition` used to compute Illumination/QD metrics.\n* **No self‑evidence:** evidencing `TransformerRole` is **external** to the evaluated holon.\n\n**4.2 PathId (address for justifications)**.\nA **PathId** is a **stable identifier** minted for a **claim‑local, lane‑typed path** in an EvidenceGraph under a declared **TargetSlice** (Scope G with Γ\\_time selector) and **ReferencePlane**. PathIds are **editioned**; they denote a **proof spine** from the claim to carriers and include: the **lane split**, the **lowest CL on the path**, the **Γ‑fold in effect** (default = WLNK), **policy‑ids** **Φ(CL)** **and, if applicable,** **Φ\\_plane**, and **valid‑until** (freshness) for empirical legs. PathIds are **citable from SoS‑LOG** and **UTS**; missing or stale PathIds **forbid maturity rung advance**.\n\n**4.3 PathSliceId (time‑ & plane‑lifted slice).**\nA **PathSliceId := PathId × Γ_time window × ReferencePlane**. It keys **release‑quality snapshots** and enables **path‑granular refresh** (G.11) when freshness or bridges change. **If QD/illumination is present, the PathSliceId MUST also pin** `U.DescriptorMapRef.edition` **and** `DistanceDefRef.edition` **to make front/coverage snapshots reproducible.** A PathSliceId MUST declare its Γ_time selector and plane; crossings require Bridge + CL^plane and route penalties to R only.\n\n**4.4 Computation hooks (reusing B.3 & G.4, not redefining).**\n\n* **Γ‑fold & penalties.** Unless justified otherwise in **CAL.ProofLedger**, **R** aggregates by **weakest‑link**, then applies **Φ(CL_min)**, any applicable **Ψ(`CL^k`)** (where a **KindBridge** is traversed), and **Φ_plane** (all **bounded, monotone**), and is **clipped**: `R_eff := max(0, …)`. **F = min**. **G** composes as **intersection along a path**; **SpanUnion** across **independent** lines only (see CC‑G6‑10/12). Penalties **never** modify F/G. **All numeric operations MUST be lawful per CG‑Spec (declared characteristic, unit/scale, Γ‑fold); illegal mixes trigger fail‑fast and RSCR.**\n* **Lane separation.** Evidence lanes remain **separable** through to the assurance surface and SCR; no averaging across lanes.\n* **Exposure to SCR.** Every path resolves to **SCR/RSCR** entries; the **Assurance SCR** displays node/edge values, describedEntity and plane, **TA/VA/LA table**, **valid‑until/decay**, and **Epistemic‑Debt**. **Mandatory fields:** lane‑split, **Γ‑fold contributors** (with ids), **Φ(CL)**/**Φ\\_plane policy‑ids**, **PathId/PathSliceId**, and, when QD/illumination is involved, `U.DescriptorMapRef.edition` and `DistanceDefRef.edition` ids.\n* **Reuse across Contexts.** Any cross‑Context/plane reuse must cite **Bridge ids + loss notes**; penalties route to **R\\_eff only**; **policy‑ids** for Φ/Ψ are published in the SCR and CG‑Spec.\n\n**4.5 Conceptual API (notation‑independent surface).**\n\n* `Explain(pathId)` → returns lane‑split, **min R\\_i**, **CL\\_min**, applied **Φ/Ψ** policy‑ids, **valid‑until**, and the **contributing EvidenceProfile ids**.\n* `PathsFor(claim, TargetSlice, plane)` → enumerates admissible paths, ordered by WLNK cutset; returns **PathId\\[]**.\n* `Snapshot(pathId | pathSliceId)` → emits an **RSCR‑grade** snapshot (for release, UTS) with **twin labels**; when a **PathSliceId** is provided, the snapshot is **time‑local** (no reweave).\n  (These are **conceptual shapes**, not APIs; per E.5 they stay tool‑neutral.)\n\n**4.6 RSCR triggers (conceptual).**\nEdits that change **computed values (Score or telemetry signals) or acceptance**, **Φ/Ψ policies**, **Bridge CL**, or **Γ‑fold** for a path **trigger RSCR**; **QD/OEE‑related edits** (e.g., `U.DescriptorMapRef.edition`/`DistanceDef`, `EmitterPolicyRef`, `InsertionPolicyRef`) **also trigger RSCR**. Selectors in G.5 must **re‑cite** PathIds on re‑run, or degrade/abstain per LOG duties.\n\n> **Aphorism.** *“If you can’t point to a path, you don’t have provenance—only a story.”*\n",
        "archetypal_grounding": "### G.6:5 - Archetypal Grounding (System / Episteme)\n\n**System (Γ\\_sys):** *Autonomous brake envelope claim*.\nClaim: “Stop within 50 m from 100 km/h.” EvidenceGraph nodes: `verifiedBy` static‑analysis proof; `validatedBy` instrumented track tests; calibration carriers; external test lab as `TransformerRole`. **PathId** combines VA+LA legs; **R\\_eff** = min(R\\_i) − Φ(CL\\_min); **G** is the **operational envelope** covered by tests; **F** limited by least‑formal leg. Freshness windows and decay are shown in SCR; any cross‑plant reuse applies **Scope Bridge** penalties to **R only**.\n\n**Episteme (Γ\\_epist):** *Vision benchmark SoTA (2015→) replication path*.\nClaim: “Method family M attains parity on ImageNet‑style tasks.” EvidenceGraph nodes: replicated studies (LA), proof obligations for metric legality (VA), tool‑qualification declarations (TA). RSCR adapts vocabularies/units per Context; **Bridge** entries across sub‑traditions carry **loss notes** and **CL**. The **PathId** cited by SoS‑LOG at admission includes **ReferencePlane**, **Φ(CL)** policy ids, and **valid‑until** on rolling 24 mo windows.\n",
        "bias‑annotation": "### G.6:6 - Bias‑Annotation\n\nLenses tested: **Gov**, **Arch**, **Onto/Epist**, **Prag**, **Did**.\nScope: **Universal** within the Conceptual Core; numerical policies (Φ/Ψ tables) remain **Context‑local** and are **cited by id**, not embedded, preserving independence and avoiding tool lock‑in.\n",
        "conformance_checklist": "### G.6:7 - Conformance Checklist (CC‑G6)\n\n| ID                                     | Requirement                                                                                                                                              | Purpose                                                                                                                                                                                                                                 |\n| -------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **CC‑G6‑1 (Anchor & lanes)**           | Every path **MUST** resolve to A.10 anchors (SCR/RSCR) and declare **lane tags TA/VA/LA** on bindings.                                                   | Enforces evidential reality and lane separation. |\n| **CC‑G6‑2 (No self‑evidence)**         | The evidencing `TransformerRole` is **external**; reflexive cases model a meta‑holon.                                                                    | Prevents circular proof.                                                                                                                     |\n| **CC‑G6‑3 (Plane & Context declared)** | Each path **SHALL** declare `U.BoundedContext`, **ReferencePlane**, and (if crossing) the **Bridge id + loss notes**.                                    | Makes penalties auditable.                                                                                                                   |\n| **CC‑G6‑4 (CL routing)**               | **Φ(CL)**, **Ψ(`CL^k`)** (when a **KindBridge** is used), and, if applicable, **Φ\\_plane** penalties **reduce R\\_eff only**; **F/G invariant**.          | Preserves scale/plane safety.                                                                                                                |\n| **CC‑G6‑5 (Γ‑fold discipline)**        | **Declare Γ‑fold**; default is **weakest‑link**. Overrides **MUST** cite CAL.ProofLedger ids for monotonicity/boundary behaviour.                        | Legal aggregation without redefining B.3.                                                                                                   |\n| **CC‑G6‑6 (Time & decay)**             | Empirical legs **MUST** expose **freshness windows** and **valid‑until**; expiry incurs **Epistemic Debt** with managed resolution.                      | Stops “latest” drift.                                                                                                                        |\n| **CC‑G6‑7 (Design/run split)**         | EvidenceGraph **SHALL NOT** mix design‑time MethodDescription with run‑time Work traces in one node; use explicit instantiation bridges.                 | Avoids stance chimeras.                                                                                                                     |\n| **CC‑G6‑8 (SCR surface)**              | For any **PathId**, the **Assurance SCR** **SHALL** list node/edge F,G,R, CL, describedEntity, plane, TA/VA/LA table, decay, and Epistemic‑Debt.               | Complete audit surface.                                                                                                                     |\n| **CC‑G6‑9 (Citable PathIds)**          | **SoS‑LOG** decisions (admit/degrade/abstain) and **Maturity rung transitions** **MUST** cite **EvidenceGraph PathId(s)**. Absence forbids rung advance. | Stable justifications per C.23.                                                                                                              |\n| **CC‑G6‑10 (Independence note)**       | If a **SpanUnion** of evidence lines is claimed, publish the **independence justification**.                                                             | Lawful enlargement of G.                                                                                                                     |\n| **CC‑G6‑11 (UTS hooks)**               | Evidence artefacts and PathIds **MUST** be **UTS‑citable** with twin labels (Tech/Plain).                                                                | Publication discipline.                                                                                                                     |\n| **CC‑G6‑12 (IndependenceCertificate)** | Independence for any **SpanUnion** MUST be carried by a **USM (`A.2.6 §7.3`) IndependenceCertificate** (partition of essential components; reference id in SCR). | Makes SpanUnion auditable and machine‑checkable. |\n| **CC‑G6‑13 (Mandatory SCR/DRR fields)** | SCR/DRR for any cited path **MUST** expose: lane‑split, **Γ‑fold contributors (ids)**, **Φ(CL)**/**Φ\\_plane** policy‑ids, **PathId/PathSliceId**; with QD/illumination also expose `U.DescriptorMapRef.edition` and `DistanceDefRef.**edition**` ids. | Ensures lawful, reproducible audits and refresh. |\n| **CC‑G6‑14 (Legality of numeric ops)** | Any numeric comparison/aggregation in paths **MUST** cite **CG‑Spec** (characteristic id, unit/scale, Γ‑fold). **Fail‑fast** on CSLC violations; no ordinal→cardinal promotion. | Prevents illegal arithmetic and hidden assumptions. |\n| **CC‑G6‑15 (Editioned QD/OEE telemetry)** | Ingested QD/illumination or OEE events **SHALL** record `U.DescriptorMapRef.edition`, `EmitterPolicyRef`, `InsertionPolicyRef`, and (for OEE) `EnvironmentValidityRegion`/`TransferRules` refs. | Reproducible fronts/coverage and environment lineage. |\n",
        "interfaces_&_hooks_(normative)": "### G.6:8 - Interfaces & Hooks (normative)\n\nEach hook below defines: **Trigger → Obligation → Publishes/Consumes → Invariants**.\n\n#### G.6:8.1 - **H1 — UTS Name Card for Evidence Artefacts**\n\n* **Trigger.** A new **EvidenceGraph node** is minted (an **A.10 anchor/carrier** classifying evidence for a claim).\n* **Obligation.** Mint a **UTS Name Card** with **twin labels** for the artefact (Tech/Plain), citing the **home `U.BoundedContext`** (per D.CTX) and edition; do **not** borrow a Context‑local Tech label as a “global” name. \n* **Publishes/Consumes.** **Publishes:** UTS row; **Consumes:** A.10 anchor metadata.\n* **Invariants.** Cross‑Context sameness is **Bridge‑only**; the UTS row lists Bridges with **CL** and a short **loss note**.\n\n#### G.6:8.2 - **H2 — UTS PathCard (PathId/PathSliceId)**\n\n**Trigger.** A new **PathId** (or **PathSliceId**) is minted for a claim.  \n**Obligation.** Publish a **UTS Name Card** with twin labels for the Path (or PathSlice), listing **Context, ReferencePlane, Γ_time**, and cited **Bridge ids + CL/CL^plane** (with loss notes). **If present, include** `U.DescriptorMapRef.edition` **and** `DistanceDefRef.edition` **ids.**  \n* **Invariants.** **F/G invariants never mutate** due to CL penalties; penalties reduce **R only**. **Illumination/QD signals do not alter dominance unless a selection policy (C.19) explicitly declares it; such policy ids MUST be cited.**\n\n#### G.6:8.3 - **H3 — RSCR Trigger on Evidence‑Impacting Edit (with Bridge Sentinels)**\n\n* **Trigger.** Any edit in G.6 that can change **computed values (Score or telemetry signals), acceptance verdicts, Γ‑fold contributors, or `R_eff`**; examples: freshness/decay change; Bridge **CL/CL^k** or loss update; **Φ/Ψ** policy change; lane tag correction; ReferencePlane correction; **QD/OEE artefact updates** (`U.DescriptorMapRef.edition`/`DistanceDef`, `EmitterPolicyRef`, `InsertionPolicyRef`, archive K‑capacity).\n* **Obligation.** Emit a **typed RSCR trigger**; the corresponding regression test must verify: (i) legality of CHR ops in affected flows, (ii) unit/scale checks, (iii) **CL→`R_eff` routing only**, (iv) presence of Φ policy‑ids in the SCR. \n* **Publishes/Consumes.** **Publishes:** RSCR test id(s); **Consumes:** CAL.EvidenceProfiles, CAL.Acceptance, Φ‑policies.\n* **Invariants.** **F/G invariants never mutate** due to CL penalties; penalties reduce **R only**.\n\n#### G.6:8.4 - **H4 — SoS‑LOG Path Citation (Selector Explainability)**\n\n* **Trigger.** A **C.23 SoS‑LOG** rule returns {**Admit | Degrade(mode) | Abstain**} for a `(TaskSignature, MethodFamily)` pair.\n* **Bridge Sentinels.** All **Bridge ids** referenced by live **PathIds/PathSliceIds** are **watch‑listed**; any change to **CL/CL^plane** or **Φ policy id** triggers **path‑local RSCR** on the affected set of Paths/Slices only.\n* **Obligation.** The LOG branch **MUST** cite **EvidenceGraph `PathId`(s)** that justify the decision, together with **lane tags (TA/VA/LA)**, freshness windows, **Bridge ids + loss notes** (if any), and Φ policy‑ids. **When the decision relies on QD/illumination or portfolio telemetry, the citation MUST include** `U.DescriptorMapRef.edition`, the relevant `EmitterPolicyRef`/`InsertionPolicyRef` **ids, and the** **lens id** *(per C.19)* **if a lens was used.**\n* **Publishes/Consumes.** **Publishes:** SCR‑visible branch record with `PathId`; **Consumes:** EvidenceGraph API path query.\n* **Invariants.** **No self‑evidence**; cross‑plane penalties **MUST** be monotone, bounded, and table‑backed.\n\n#### G.6:8.5 - **H5 — Maturity Rung Transition Justification**\n\n* **Trigger.** A `MethodFamily.MaturityCard@Context` rung change is proposed.\n* **Obligation.** The transition **MUST** be justified by one or more **EvidenceGraph paths** and then **published on UTS**; **missing anchors ⇒ no advance**.\n* **Publishes/Consumes.** **Publishes:** updated UTS entry for the MaturityCard; **Consumes:** EvidenceGraph paths and A.10 anchors.\n* **Invariants.** Maturity is an **ordinal poset**, not a global scalar; any gating thresholds live **only** in **AcceptanceClauses** and are cited by id from LOG (no thresholds inside LOG). \n\n#### G.6:8.6 - **H6 — Bridge/CL Edge Annotation (GateCrossings)**\n\n* **Trigger.** An EvidenceGraph edge crosses a **GateCrossing boundary** (Context/kind/plane/design↔run/edition).\n* **Obligation.** Record a **`BridgeCard`** (when a Bridge is involved) and publish a **UTS crossing row** with: `fromCtxState→toCtxState` (E.18 `CtxState = ⟨L,P,E⃗,D⟩`), Context ids (D.CTX), **Bridge id** (if any), **bridgeChannel**, **CL** (and **CL^k** if KindBridge), **ReferencePlane**(s), and **CL^plane** (if planes differ). **No implicit crossings**.\n* **Publishes/Consumes.** **Publishes:** UTS crossing row; **Consumes:** GateCrossing metadata.\n* **Invariants.** CL/CL^plane penalties **route to R only**; lanes are **explicit**.\n\n#### G.6:8.7 - **H7 — ReferencePlane Penalty Publication**\n\n* **Trigger.** A claim/evidence path spans different **ReferencePlanes** `{world|concept|episteme}`.\n* **Obligation.** Compute and publish **Φ\\_plane** (policy id + loss note) alongside **Φ(CL)**; both policies are **monotone, bounded, table‑backed**; report in SCR for any affected verdict. **Publish ids, not tables; values live in CAL.Acceptance/Φ‑policy registries.** \n* **Publishes/Consumes.** **Publishes:** SCR fields with Φ policy‑ids; **Consumes:** CAL.EvidenceProfiles row(s).\n* **Invariants.** Penalties affect **`R_eff`** only; **F/G** remain invariant.\n\n#### G.6:8.8 - **H8 — CrossingSurface Exposure (E.18)**\n\n* **Trigger.** G.6 exports are bundled for release or consumed by selectors.\n* **Obligation.** Provide inputs so that GateCrossing checks can run against **EvidenceGraph paths and published CrossingSurfaces** (**E.18:CrossingSurface**):\n  * FAIL if any required **CrossingSurface** is missing (`CrossingRef` + matching UTS row + required pins).\n  * FAIL if lane purity is violated (**CL/CL^k/CL^plane → R only**; F/G invariant).\n  * EXPOSE penalty policy ids (`Φ(CL)`, `Φ_plane`, `Ψ(CL^k)` where used) as **`PolicyIdRef`** bundles (policy-id + `PolicySpecRef` + `MintDecisionRef?`; F.8:8.1) so checks can verify monotonicity/bounds and mint/reuse provenance without implying any tool format.\n* **Publishes/Consumes.** **Publishes:** harness-readable identifiers (no formats mandated); **Consumes:** GateCrossing + lane tags.\n* **Invariants.** LEX hygiene (head-anchoring, I/D/S) holds for all exported tokens.\n\n#### G.6:8.9 - **H9 — SCR Surface for Assurance**\n\n* **Trigger.** Selector reports or acceptance checks reference evidence.\n* **Obligation.** Expose **lane‑split**, freshness windows, **Γ‑fold** contributors, **Φ(CL/plane)** policy‑ids, **IndependenceCertificate ids** (if SpanUnion), and (where present) **ProofLedger** references **as SCR‑visible fields**. \n* **Publishes/Consumes.** **Publishes:** SCR views; **Consumes:** CAL.Acceptance, CAL.ProofLedger, EvidenceGraph paths.\n* **Invariants.** **WLNK default = weakest‑link** unless proved otherwise; any override cites monotonicity/boundary proofs.\n\n#### G.6:8.10 - **H10 — ProofLedger Linkage (CAL ↔ G.6)**\n\n* **Trigger.** A formal proof obligation or evidence role is attached to a claim.\n* **Obligation.** Link the EvidenceGraph node/edge to **CAL.ProofLedger** entries and **A.10 carriers** via `verifiedBy/validatedBy` relations; **SCR/RSCR anchors are mandatory** for all carriers. **No self‑evidence**. \n* **Publishes/Consumes.** **Publishes:** ProofRef ids in the path; **Consumes:** CAL.ProofLedger entries.\n* **Invariants.** **TA/VA/LA** distinctions remain explicit; tool qualification belongs to **TA**.\n\n#### G.6:8.11 - **H11 — Telemetry Ingest (Selector & Probe Outcomes)**\n\n* **Trigger.** Run‑time **selector** or **probe** outcomes (E/E‑LOG) return observations that bear on previously asserted claims; **this includes QD/illumination updates and OEE `GeneratorFamily` events** (environment edits/transfers).\n* **Obligation.** Ingest as **external evidence lines** into the EvidenceGraph with proper **lane typing** (LA/VA/TA), **Context slice** and **Γ\\_time**; record **edition‑aware fields** when applicable: `U.DescriptorMapRef.edition`, `DistanceDef`, `ArchiveCellRef`, `EmitterPolicyRef`, `InsertionPolicyRef`, the **policy‑id**, and the **lens id** *(per C.19)* used by the selector. For OEE events, capture `EnvironmentValidityRegion` and `TransferRules` references. Opening/closing of refresh windows produces **DRR/RSCR hooks** outside the Core text. *This hook wires G.6 to G.11 Telemetry/Refresh while keeping Core prose tool‑agnostic as required by E.5.*\n* **Publishes/Consumes.** **Publishes:** new EvidenceGraph nodes/edges + UTS rows; **Consumes:** selector/probe attestation (as conceptual carriers) **and (when present) GeneratorFamily attestations**.\n* **Invariants.** Separate **ΔR / ΔF** from **ΔG** in rationale (Assurance calculus discipline). **Illumination increments are logged as editioned deltas; they do not change dominance unless declared by policy (C.19).**\n\n#### G.6:8.12 - Minimal conformance (hooks)\n\n1. **UTS publication (H1)** for every minted evidence artefact; Bridges carry **CL + loss note**.\n2. **RSCR triggers (H3)** on any edit impacting computed values (Score/telemetry signals), acceptance, Γ‑fold, or Φ penalties.\n3. **LOG path citation (H4)** is mandatory for **all** Admit/Degrade/Abstain decisions; **no self‑evidence**. \n4. **Maturity rung transitions (H5)** **forbid** advancement without EvidenceGraph paths and UTS publication.\n5. **Gate‑crossings (H6/H7)** publish **Bridge + CL/CL^plane** and route penalties to **R only**; **no implicit crossings**.\n6. **GateCrossing visibility harness (H8).** Crossings pass **CrossingSurface** attestation (**E.18/A.27/F.9**), **LanePurity**, and **Lexical SD** (**E.10**) under GateChecks/GateProfile (**A.21**).\n7. **SCR surface (H9)** exposes lane split, Γ‑fold, Φ‑policies, ProofRefs; default **WLNK** unless proved otherwise.\n8. **ProofLedger linkage (H10)** ties formal/empirical roles to **A.10 carriers**; **SCR/RSCR anchors** present.\n\n",
        "consequences": "### G.6:9 - Consequences\n\n**Benefits.** Path‑addressable provenance; transparent **CL** and decay; clean **DesignRunTag**; selectors and auditors share the *same* object; **R** penalties become explainable deltas rather than folklore.\n**Trade‑offs.** Authors must declare freshness and planes; mitigated by reusing G.4 **EvidenceProfiles** instead of duplicating fields.\n",
        "rationale": "### G.6:10 - Rationale\n\nG.6 concretises the “**because‑graph**” already implicit in A.10 as a **typed, lane‑aware DAG** with **stable path addresses**. It relies on B.3’s **assurance skeleton**—WLNK for R, penalties by **Φ(CL\\_min)**, **SpanUnion constrained by support** for G, and **F = min**—rather than inventing a new calculus. The **SCR/RSCR** obligations keep the graph grounded in carriers and external Transformers, matching post‑2015 provenance practice for reproducible knowledge and auditability.\n",
        "relations": "### G.6:11 - Relations\n**Builds on:** A.10 (anchors, SCR/RSCR, externality), B.3 (assurance lanes & Γ‑fold skeleton), G.4 (EvidenceProfiles & ProofLedger), F.9 (Bridges/CL), **C.18 (NQD‑CAL)**, **C.19 (E/E‑LOG & policies)**, **E.18/A.21/A.27** (GateCrossing/CrossingSurface checks), E.8/E.10 (template & lexical rules).\n**Publishes to:** **UTS** (Name Cards for evidence artefacts and PathIds) and **RSCR**; **G.5** selectors cite **PathId** in their **SoS‑LOG** branches (admit/degrade/abstain); **G.11** consumes editioned telemetry for refresh/decay.\n**Constrains:** **G.5** (eligibility/selector must point to PathIds; **portfolio results MUST cite policy‑ids and, when QD present, DescriptorMap editions**), **G.9** (parity checks cite concrete paths), **G.11** (telemetry drives Path refresh & deprecation via evidence windows and edition changes).\n",
        "g.6:end": "### G.6:End\n"
      },
      "content": "### G.6:End\n",
      "metadata": {},
      "part": "G",
      "cluster": null
    },
    {
      "id": "G.7",
      "title": "Cross‑Tradition Bridge Matrix & CL Calibration",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## G.7 - Cross‑Tradition Bridge Matrix & CL Calibration\n\n**Tag:** Architectural pattern\n**Stage:** design‑time\n**Hooks:** **G.2** (SoTA Bridge Matrix), **F.9** (Bridges/CL & CL^k/Ψ), **G.5** (eligibility & selection across bridges), **C.23** (SoS-LOG rules), **G.4** (CAL/Acceptance routes), **C.18/C.19** (NQD/QD spaces & governor), **G.6 hooks H1, H3–H7, H9–H10** (UTS, RSCR, LOG path citation, gate-crossings, SCR/ProofLedger), **E.18/A.21** (GateCrossing / OperationalGate(profile) + DecisionLog)\n**Publishes to:** **UTS**; registers **Bridge Sentinels** for **G.11** refresh; emits **Telemetry(PathSlice)** with policy‑ids and **edition markers** (`DescriptorMapRef.edition`, `DistanceDefRef.edition`, and — when QD archives are implicated — `InsertionPolicyRef`) where relevant.\n",
        "intent": "### G.7:1 - Intent\n\nTurn the **SoTA Bridge Matrix** produced in **G.2** into **formal Bridges** with **Congruence Levels (CL)**, **loss notes**, and **ReferencePlane** penalties where applicable; calibrate **CL/CL^k** and (where relevant) **CL^plane** using a small, auditable procedure; maintain a **Bridge Calibration Table (BCT)** with **sentinel‑sets** and **regression tests** to guard stability of CL/CL^k/CL^plane over time; register sentinels so any change to CL or Φ‑policies triggers **path‑local** RSCR re‑checks rather than whole‑pack reruns. Cross‑Tradition reuse **without** a Bridge is **forbidden**.  \n",
        "problem": "### G.7:3 - Problem\n\n1. **Rival Traditions** must be compared **without** semantic flattening; 2) cross‑plane talk (world|concept|episteme) introduces **CL^plane** penalties; 3) penalty routing must stay **assurance‑only (R)**, leaving **F/G** invariant; 4) changes to Bridges need **targeted** refresh, not a full re‑weave of evidence; 5) when Bridges touch **DescriptorMap** used by illumination/QD, their **DescriptorMapRef.edition** and **DistanceDefRef.edition** must be tracked to avoid silent drift.\n",
        "forces": "### G.7:4 - Forces\n\n| Force                                | Tension                                                                                              |\n| ------------------------------------ | ---------------------------------------------------------------------------------------------------- |\n| **Comparability vs Local Authority** | Compare Traditions but never override Context‑local meaning; reuse is **Bridge‑only**.               |\n| **Didactic Simplicity vs Fidelity**  | Managers need compact tables, yet **Row CL(min)** and explicit losses bound where sameness is safe.  |\n| **Auditability vs Throughput**       | Calibration must be light‑weight but **UTS‑visible** and **CrossingSurface/GateCrossing** checks runnable.                    |\n| **Refresh Cost vs Safety**           | Move from pack‑wide reruns to **path‑local** triggers on **Bridge** edits.                           |\n| **QD comparability vs Metric drift** | QD/illumination comparisons require **stable DescriptorMap and Degree‑of‑difference (DistanceDef)** definitions.     |\n",
        "solution": "### G.7:5 - Solution — **From Matrix to Bridges, with CL/CL^k Calibration, BCT & Sentinels**\n\n**S0 - Prepare a Bridge Calibration Table (BCT) & Regression Set.**\nPer Tradition‑pair, materialize a **BCT** capturing: `TradPairId`, `ComparableConstruct`, `FreshnessWindow`, `SentinelSetId`, `RegressionSetId`, and **declared units** (per C.21). Include **stability checks** for CL/CL^k/CL^plane across editions; record **edition ids** for `DescriptorMapRef.edition` and **DistanceDefRef.edition** (C.18) and — when applicable — `InsertionPolicyRef` to ensure edition‑aware auditing.\n\n**S1 - Forge Bridges from Matrix rows.**\nFor each comparable construct in the G.2 Bridge Matrix, mint an F.9 BridgeCard **anchored at SenseCell granularity** (F.3/F.7); **never whole Contexts**. If tokens other than SenseCells are used, **declare their SenseCell anchors**. State `bridgeChannel ∈ {Scope, Kind}`, `kind` (≡/⊑/⋈/≈/… as supported), `CL ∈ {3,2,1,0}` with loss notes (Scope) and, where a KindBridge is used, `CL^k ∈ {3,2,1,0}` with loss notes. Record direction if non‑symmetric and the validity region. **CL ≥ 2** (and **CL^k ≥ 2**) is permitted; **= 1** requires a **Waiver**; **= 0** is forbidden. Publish a **UTS row** for every GateCrossing. **No implicit crossings.**\n\n**S2 - Calibrate CL with a minimal, auditable procedure.**\nPer Bridge:\n\n1. Plane check. Record `ReferencePlane`(source,target). If planes differ, compute **CL^plane** and attach **Φ_plane** (policy‑id + loss note). **Plane penalties SHALL NOT mutate `CL`**; they **only reduce `R_eff` via Φ_plane**. Crossing **≥ 2 planes MAY be policy‑blocked** (Φ_plane = block) unless a documented Waiver is cited. **F/G remain invariant.**\n2. **Counter‑example duty.** Assign **CL/CL^k** only if you can state at least one **counter‑example** for ≤ 2, or explain its absence for 3 (**honesty rule**).\n3. Penalty policies. Reference **Φ(CL)** (Scope) and, where applicable, **Ψ(CL^k)** (Kind), and **Φ_plane** — all **monotone, bounded, table‑backed** — used by your CG‑Frame. **Route penalties to `R_eff` only; F/G invariant.**\n4. Row scope (by reference). For Concept‑Set rows supported by Bridges, apply **F.7** row rules: **Row CL(min) = bottleneck** (no averages) and include a counter‑example when any cell carries a loss note. (Do not restate them here.)\n5. Stability check. Run the **BCT Regression Set**; if CL/CL^k/CL^plane changes, attach the regression delta, update **SentinelSet**, and emit **Telemetry(PathSlice)** with `policy‑id`(s) and any affected **DescriptorMapRef.edition** or **DistanceDefRef.edition**.\n\n**S3 - Publish crossings to UTS & Evidence surfaces.**\nEvery GateCrossing emits a UTS row listing `fromCtxState→toCtxState` (E.18 `CtxState = ⟨L,P,E⃗,D⟩`), `Context ids`, `Bridge id` (if any), `bridgeChannel`, `CL` (and `CL^k` if KindBridge), `ReferencePlane(s)`, and `CL^plane` (if planes differ). **SCR shows the policy‑ids for Φ(CL), Ψ(CL^k) (if used), and Φ_plane** and cites the **BCT id** and **RegressionSet id**. (No implicit crossings.)\n\n**S4 - Register Bridge Sentinels (watch‑list).**\nAll **Bridge ids** referenced by live **EvidenceGraph `PathId`/`PathSliceId`** are **watch‑listed**. On any change in **CL/CL^k/CL^plane** or **Φ/Ψ policy‑id**, emit **path‑local RSCR** triggers (per **H3/H4**) and schedule refresh **per PathSlice** (Γ_time × plane), not per pack. Where Bridges reference **DescriptorMapRef** or **DistanceDef**, any **edition change** also triggers sentinels and publishes an edition note to Telemetry.\n\n**S5 - Dispatcher & DHC hooks.**\nG.5 may only compare across Traditions when a Bridge exists; selection uses admissible orders, **bans cross‑ordinal scalarisation**, and applies **CL/CL^k/CL^plane penalties to R only**. **SoS‑LOG (C.23) gates** accompany any cross‑Tradition choice; **Acceptance (G.4)** holds thresholds/unknowns. For illumination/QD comparisons, G.5 must cite the **DescriptorMapRef.edition** and the **DistanceDefRef.edition** exposed by **G.7**. G.12 reports AlignmentDensity using Bridges with **CL ≥ 2** (units declared).\n",
        "structure_(conceptual_surfaces)": "### G.7:6 - Structure (conceptual surfaces)\n\n**BridgeCard (core fields).**\n`⟨BridgeId, Source⟨Context, SenseCell⟩, Target⟨Context, SenseCell⟩, bridgeChannel∈{Scope, Kind}, kind, CL, CL^k?, lossNotes, validityRegion, ReferencePlane(src,tgt), CL^plane?, Φ(CL) policy‑id, Ψ(CL^k) policy‑id?, Φ_plane policy‑id?, DescriptorMapRef?, DescriptorMapRef.edition?, DistanceDefRef?, DistanceDefRef.edition?, InsertionPolicyRef?, Evidence lanes, UTS.rowId, BCT.id, RegressionSet.id, SenseCellAnchorRefs?⟩`\n(“SenseCell‑only; never Contexts.”)\n\n**Calibration Ledger (per Tradition pair).**\n`⟨TradPairId, ComparableConstruct, Bridges[], RowScope, RowCL(min), Counter‑example link, Freshness window, SentinelSet.id, RegressionSet.id, DescriptorMapRef?, DescriptorMapRef.edition?, DistanceDefRef?, DistanceDefRef.edition?, InsertionPolicyRef?, Steward⟩`\n(Attach to **SoTA Synthesis Pack** and cite from **G.5**.)\n\nThis is pure conceptual, notation-independent.\n",
        "interfaces_&_dependencies": "### G.7:7 - Interfaces & Dependencies\n\n* **Consumes:** G.2 Bridge Matrix; E.10 LEX/I‑D‑S; **E.18 GateCrossing/CrossingSurface**; B.3 Φ‑policies; C.21 metrics schema; **C.18/C.19** QD descriptors & policies (when relevant); **C.23** SoS‑LOG clauses; **G.4** Acceptance thresholds.    \n* **Produces:** F.9‑conformant **BridgeCards**; **UTS** crossing rows; **PathSlice** sentinel registrations; CL policy ids for **SCR**; DHC‑visible bridge counts; **Telemetry(PathSlice)** entries with policy‑ids and, where applicable, **DescriptorMapRef.edition** and **DistanceDefRef.edition** and **InsertionPolicyRef**.\n",
        "conformance_checklist": "### G.7:8 - Conformance Checklist (normative)\n\n1. **Bridge‑only reuse.** Any Cross‑Tradition or Cross‑Context reuse **MUST** cite a **Bridge** with **CL** (and **CL^k** if KindBridge) and **loss notes**; **mentions without Bridge+UTS row are non‑conformant**.\n2. **CL regimes.** **CL, CL^k ∈ {3,2,1,0}**; **≥ 2** permitted; **= 1** only with **Waiver**; **= 0** forbidden. **Honesty rule** holds (counter‑example for ≤ 2 or stated absence for 3).\n3. Plane guard. On plane mismatch, compute **CL^plane** and publish **Φ_plane** policy‑id. **Plane penalties SHALL NOT change `CL`; penalties reduce `R_eff` only.** Blocking is a **Φ_plane** policy outcome (not a CL edit).\n4. R‑only routing. **Φ(CL)**/**Ψ(CL^k)**/**Φ_plane** are **monotone, bounded, table‑backed**; **penalties reduce `R_eff` only**; **F/G invariant**.\n5. Row bottleneck (by reference). Apply **F.7** row rules: **Row CL(min)=bottleneck** (no averages) and include a counter‑example when any cell has a loss note.\n6. **UTS publication.** Each GateCrossing publishes a **UTS row** with **ReferencePlane**(s) and **CL^plane** (if any); cites **BCT.id/RegressionSet.id**; **no implicit crossings**.\n7. **GateCrossing checks.** Published crossings **MUST** expose **CrossingSurface** (**E.18:CrossingSurface**) and satisfy **LanePurity** and **Lexical SD**; **fail** on missing/non‑conformant surface or lane impurity.\n8. **Sentinel wiring.** Bridges cited by live **PathId/PathSliceId** are **watch‑listed**; edits to **CL/CL^k/CL^plane** or **Φ/Ψ** trigger **path‑local RSCR** per **H3/H4**; **DescriptorMapRef.edition / DistanceDefRef.edition changes** trigger the same.\n9. **ReferencePlane on transfer.** Any **inter‑Context** or **inter‑plane** transfer **MUST** explicitly declare `ReferencePlane(src,tgt)` and publish **Φ_plane** (if planes differ); absence is **fail‑fast**.\n10. **DHC accounts.** **AlignmentDensity** counts only **CL ≥ 2**; **CL=3** is free substitution, **CL=2** guarded (loss published).\n11. SenseCell anchoring. BridgeCards **MUST** anchor to **SenseCells**; if other tokens are used, **declare SenseCell anchors**.\n12. **BCT presence.** A **BCT** with **freshness window**, **SentinelSet**, and **RegressionSet** MUST exist for any Tradition‑pair with Bridges; **stability checks** must be runnable via the **GateCrossing visibility harness** (E.18; LanePurity + Lexical SD; GateChecks A.21).\n",
        "micro‑examples_(post‑2015_contexts;_*indicative_only*)": "### G.7:9 - Micro‑examples (post‑2015 contexts; *indicative only*)\n\n> **Scope note.** Examples illustrate **row scopes** and **loss notes**. They are not endorsements of equivalence beyond the stated scope. Penalties route to **R** only; **F/G** invariant.\n\n1. “Preference‑learning objective” *(senseFamily=Method; **Row Scope: Naming‑only**)* …\n   *Cells:* `RLHF@Context‑A:policy‑gradient‑on‑reward‑model` ↔ `DPO@Context‑B:direct‑preference‑optimization` • *Row CL(min):* 2 • *Loss:* KL‑regularisation vs. implicit logistic form; sensitivity to label‑noise mix • *Use:* didactic (naming/expository); **no** substitution of acceptance thresholds. *(2017→2023 literature evolution; rival training programs with overlapping intent.)*\n\n2. “Causal effect (ATE) reading” *(senseFamily=Method; **Row Scope: Naming‑only**)* …\n   *Cells:* `SCM@Context‑C:do(x)` ↔ `Potential‑Outcomes@Context‑D:ATE` • *Row CL(min):* 2 • *Loss:* identifiability conditions differ (ignorability/positivity vs. graph‑based rules); estimator families diverge • *Use:* expository mapping in Claim Sheets; **no** estimator substitution across pipelines.\n\n3. “Stiffness indicator for ODE suites” *(senseFamily=Measurement; **Row Scope: MM‑CHR metric (measurement comparandum)**)* …\n   *Cells:* `Rosenbrock:stability‑region test` ↔ `IMEX:stiff‑ratio heuristic` • *Row CL(min):* 2 • *Loss:* test regimes differ; grid dependence; asymptotic constants • *Use:* **G.5** eligibility hints; acceptance thresholds live in **G.4**, not here.\n\n4. “Illumination descriptor mapping” *(senseFamily=Measurement; **Row Scope: QD comparability (DescriptorMap-only)**)* …\n  *Cells:* `MAP‑Elites:grid indices` ↔ `CVT‑MAP‑Elites:Voronoi centroids` • *Row CL(min):* 2 • *Loss:* binning vs. centroidal tessellation; drift when **DistanceDef** or centroid‑counts change • *Use:* lawful cross‑reporting of Q/D/QD‑scores; **DescriptorMapRef.edition** and **DistanceDefRef.edition** must be cited; thresholds remain in **G.4**.\n\n*(All four rows presume extant F.9 Bridges; row bottlenecks and losses are printed as per F.7.)*\n",
        "anti‑patterns_&_remedies": "### G.7:10 - Anti‑patterns & Remedies\n\n* **Semantic flattening.** Treating rival definitions as synonyms without Bridges. → **Bridge first;** print **loss**; keep **Row Scope** tight.\n* **CL averaging.** Computing Row CL as an average. → **Bottleneck min**; never averages.\n* **SenseFamily jump.** Using an interpretation bridge to license substitution. → **Substitution requires senseFamily‑preserving bridges**.\n* **Plane blindness.** Ignoring **CL^plane** when crossing world↔concept↔episteme. → Compute **CL^plane** and publish **Φ_plane id**.\n* **Pack‑wide reruns.** Reweaving all evidence on a minor Bridge edit. → **Sentinels + PathSlice** for targeted RSCR. \n* **QD metric drift.** Comparing illumination/QD outcomes after **DescriptorMap** or **DistanceDef** changes without editioning. → **Record editions in BridgeCard/BCT**; publish to Telemetry; re‑run BCT regression checks.\n",
        "consequences": "### G.7:11 - Consequences\n\n* **Auditable plurality.** Teams can hold multiple Traditions in view and compare them **safely**; losses are visible; penalties touch **R** only.\n* **Selective & edition‑aware refresh.** Bridge edits or **DescriptorMapRef.edition / DistanceDefRef.edition** changes trigger **path‑local** refresh (lower cost, higher reactivity).\n* **Downstream cleanliness.** **G.5** selectors have lawful crossings and **Φ** ids; **G.12** can compute DHC signals with declared units and windows; illumination/QD comparisons carry **edition** context, preventing silent drift.\n",
        "relations": "### G.7:12 - Relations\n\n**Builds on:** **G.2** (Matrix), **F.9** (Bridges/CL), **B.3** (Φ penalties), **E.10** (LEX), **E.18** (GateCrossing), **C.18/C.19** (QD descriptors & governor), **C.23** (SoS‑LOG). **Prerequisite for:** **G.5** eligibility across bridges and edition‑aware QD parity; **G.11** responds to **Bridge Sentinels**.   \n",
        "g.7:end": "### G.7:End\n"
      },
      "content": "### G.7:End\n",
      "metadata": {},
      "part": "G",
      "cluster": null
    },
    {
      "id": "G.8",
      "title": "SoS‑LOG Bundles & Maturity Ladders",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## G.8 - SoS‑LOG Bundles & Maturity Ladders\n\n**Stage:** *design‑time packaging* (authoring & publication) with a *run‑time* consumer facade for **G.5** (selector/registry).\n**Primary hooks:** **C.23** (Method‑SoS‑LOG), **G.4** (Acceptance & EvidenceProfiles), **G.6** (EvidenceGraph & PathId/PathSlice), **G.5** (Registry/Selector), **C.22** (TaskSignature S2), **C.18** (NQD‑CAL), **C.19** (E/E‑LOG), **F.9** (Bridges & CL), **G.7** (Bridge Matrix & CL calibration), **E.18** (GateCrossing), **E.5.2** (Notational Independence), **E.10** (LEX twin registers).\n**Why this exists.** Families of methods compete inside a CG‑Frame; the selector must *admit, degrade,* or *abstain* per family without illicit scalarisation and with auditable provenance. This pattern **packages** the rule sets and maturity description defined elsewhere, so G.5 can lawfully dispatch portfolios/archives while keeping thresholds in **Acceptance** and justifications in **EvidenceGraph** paths. **It does not redefine SoS‑LOG semantics** (see **C.23**).\n**Modularity note.** The bundle cleanly separates **LOG decisions** (C.23) from **Acceptance thresholds** (G.4), **evidence wiring** (G.6), **selection semantics** (G.5), and **refresh/decay** (G.11); each module evolves independently under **E.18 GateCrossing** + **A.21 DecisionLog** discipline (no hidden crossings; no silent policy-id minting — policy-ids are reference-only and must be resolvable via `PolicySpecRef` (+ `MintDecisionRef` when newly minted) per F.8:8.1).\n",
        "intent": "### G.8:1 - Intent\n\nBind **C.23 SoS‑LOG** rule sets and a **maturity ladder (ordinal poset)** into a selector‑facing, **notation‑independent** bundle that: (i) **exposes** the decisions produced by C.23 rules, (ii) wires **EvidenceGraph** citations and GateCrossing hooks, and (iii) exports edition‑aware telemetry for **Illumination (QD)** and **Open‑Ended** generator families—without embedding thresholds inside LOG (thresholds live only in **G.4 AcceptanceClauses**).\n",
        "problem": "### G.8:2 - Problem frame\n\nUnstructured readiness stories and prose‑only gates cannot be executed by **G.5**; cross‑Context reuse often lacks Bridges/CL and plane penalties, and QD/OEE signals are mixed into dominance unlawfully. We need a **bundle** that a) keeps **maturity** visible but **non‑scalar**, b) cites lawful paths in **EvidenceGraph** for every LOG decision, and c) exports **DominanceRegime**/**PortfolioMode** so the selector can **return sets** (Pareto/Archive) rather than forcing scalarisation.   \n",
        "forces": "### G.8:3 - Forces\n\n* **Pluralism vs. dispatchability.** Competing Traditions must be comparable without semantic flattening. \n* **Assurance vs. results.** Assurance lanes (TA/VA/LA) must not crowd out **method generation**; *degrade* branches should enable safe exploration under **E/E‑LOG** budgets. \n* **No‑Free‑Lunch.** Selection must return **sets** under partial orders; **Illumination** is a **report-only telemetry** by default.  \n* **Edition‑awareness.** QD/OEE surfaces require pinned **`…Ref.edition`** and **policy‑id** for refresh/RSCR. \n",
        "solution": "### G.8:4 - Solution — *Bundle the LOG; publish the Ladder; keep thresholds in Acceptance*\n\n#### G.8:4.1 - Objects (LEX heads; twin‑register discipline)\n\n**`SoS‑LOG.Rule`** — executable rule schema `{Admit | Degrade(mode) | Abstain}` for `(TaskSignature, MethodFamily)`; authored per **C.23** (this pattern does not redefine rule semantics).\n* **`MethodFamily.MaturityCardDescription@Context`** — an **ordinal** (closed enum) ladder with declared **ReferencePlane**; *no thresholds inside*. \n* **`SoS‑LOGBundle@Context`** — the **selector‑facing** package defined in §4.2.\n* **Naming discipline.** Do **not** alias **Spaces** and **Maps**. **Tech = `U.DescriptorMapRef` (d≥2); Plain‑twin = `CharacteristicSpaceRef`** (per CC‑G5.22). Editions live on **Refs** (e.g., `DescriptorMapRef.edition`, `DistanceDefRef.edition`, `CharacteristicSpaceRef.edition` when pinning a historical Space phase).\n* **Twin registers.** Tech labels are normative; Plain twins are didactic only and must not cross Kinds.\n\n#### G.8:4.2 - Bundle schema (conceptual; notationally independent)\n\n```\nSoS-LOGBundle@Context :=\n⟨ BundleId (UTS), MethodFamilyId, HomeContext,\n  RuleIds[],                      // C.23 rules (Admit/Degrade/Abstain)\n  MaturityCardDescription,        // closed enum; ordinal; ReferencePlane declared\n  ClosedEnums: {DegradeModeEnum, MaturityRungs}, // UTS-registered\n  DominanceRegime, PortfolioMode, // default DominanceRegime=ParetoOnly\n  BridgeIds[], ΦPolicyIds[],      // CL/CL^plane policies cited by id\n  A10EvidenceGraphRef?[],          // OPTIONAL at packaging time: A.10 carriers (lanes + freshness windows) for G.6 resolution\n  EvidenceGraphPathIds?[],        // MAY be included when stable PathIds exist (e.g., rung justifications);\n                                  // branch‑specific PathIds are recorded at run‑time in SCR per C.23/H4\n  // Acceptance thresholds live in G.4; selector cites clause ids from CAL at run‑time (no duplication here)\n\n  QD/OEE: {CharacteristicSpaceRef, CharacteristicSpaceRef.edition?,\n           DescriptorMapRef.edition,\n           DistanceDefRef.edition, EmitterPolicyRef, InsertionPolicyRef}?,\n  OEE?: {EnvironmentValidityRegion, TransferRulesRef.edition}?,\n  AuthoringMethodDescriptionRefs?[], // OPTIONAL: cite MethodDescription/Spec ids (with editions) of methods that materially shaped rules/ladder (SoTA-of-description traceability across stances/loci)\n  Edition, Notes ⟩\n```\n\n*Default.* `DominanceRegime = ParetoOnly`; **IlluminationSummary** (telemetry summary) and coverage/regret (telemetry metrics) are **report‑only telemetry** and **do not** affect dominance unless an explicit **CAL** policy states otherwise (*policy‑id appears in SCR*). **Ψ(CL^k)**, where used for kind‑bridges, is cited by id alongside Φ.\n\n#### G.8:4.3 - Admissibility Ledger (selector‑facing export)\n\nPublish an **`AdmissibilityLedger@Context`** with rows\n`(MethodFamilyId, RuleId, MaturityRung, BranchIds, BridgeIds, ΦPolicyIds, EvidenceGraphPathIds?, DominanceRegime, PortfolioMode, Edition)` — **UTS‑registered** and consumed by **G.5**. The selector **cites** Acceptance clause/rung ids from CAL/C.23 and does **not** recompute thresholds.\n\n#### G.8:4.4 - Binding obligations (packaging‑only; refer to **C.23 R0–R8** for rule semantics)\n\n* **B1 — Evidence wiring.** At packaging time, provide **A.10 Evidence Graph Ref** (lanes + freshness windows) that back the C.23 rules; where already minted, **MAY** include stable **`EvidenceGraph PathId`(s)** (e.g., rung justifications). **Branch‑specific PathIds are recorded at run‑time in SCR** per **C.23/H4**.\n* **B2 — CL/plane routing.** Cross‑Context/plane reuse in the bundle **MUST** cite **Bridge ids** and the applicable **Φ(CL)**/**Φ_plane** policy‑ids; penalties route to **`R_eff` only**; **F/G invariant**.\n* **B3 — QD portfolio fields.** If `PortfolioMode=Archive`, the bundle **MUST** pin `DescriptorMapRef.edition`, `DistanceDefRef.edition`, `EmitterPolicyRef`, and `InsertionPolicyRef`; **IlluminationSummary** is a **report-only telemetry metrics** and is excluded from dominance unless CAL promotes it (policy‑id recorded).\n* **B4 — Open‑ended fields.** If `GeneratorIntent` applies, the bundle **MUST** carry `EnvironmentValidityRegion` and `TransferRulesRef.edition`; selector outputs are `{environment, method}` portfolios; coverage/regret are **telemetry metrics**.\n* **B5 — Telemetry hooks.** On any illumination increase/archive change, telemetry **SHALL** log `PathSliceId`, the active **policy‑id**, and the editions of `DescriptorMapRef`/`DistanceDefRef`; in OEE also `TransferRulesRef.edition`. (Feeds **G.11** refresh; aligns with **C.23 R8**.)\n\n#### G.8:4.5 - Maturity ladder (poset, not a scalar; Description, not Spec)\n\nPublish **`MethodFamily.MaturityCardDescription@Context`** (UTS twin labels; **Scale kind=ordinal**; **ReferencePlane declared**). Do **not** embed thresholds. **Rung semantics live in C.23**; this pattern only **binds** the card into the bundle and requires UTS publication and **EvidenceGraph** justification for rung transitions.\n",
        "interfaces_—_minimal_i/o_standard_(conceptual)": "### G.8:5 - Interfaces — minimal I/O standard (conceptual)\n\n| Interface                               | Consumes                                                                               | Produces                                                             |\n| --------------------------------------- | -------------------------------------------------------------------------------------- | -------------------------------------------------------------------- |\n| **G.8‑1 `Publish_LOGBundle`**           | `MethodFamily`, C.23 rules, G.4 Acceptance, Bridges/Φ policies, (optional) QD/OEE refs | `SoS‑LOGBundle@Context` (UTS row)                                    |\n| **G.8‑2 `Publish_AdmissibilityLedger`** | Bundle + per‑rule branch records (with A.10 anchors; PathIds if available)            | `AdmissibilityLedger@Context` (UTS row)                              |\n| **G.8‑3 `Publish_MaturityCard`**        | Ladder description + EvidenceGraph PathIds for rung justification                      | `MaturityCardDescription@Context` (UTS row; editioned)               |\n| **G.8‑4 `Expose_TelemetryHooks`**       | Archive/illumination/OEE signals                                                       | `PathSliceId`, `…Ref.edition`, **policy‑id** for RSCR/refresh (G.11) |\n\n*Note.* Surfaces are **conceptual only** per **E.5.2**; actual serializations (e.g., RO‑Crate) belong in **G.10 / Annex**. \n",
        "conformance_checklist": "### G.8:6 - Conformance Checklist (CC‑G8)\n\n* **CC‑G8‑1 (No thresholds in LOG).** Any maturity floor or numeric gate **SHALL** be authored as a **G.4 AcceptanceClause** and cited by id from the LOG; **LOG never embeds thresholds**. \n* **CC‑G8‑2 (Tri‑state discipline).** Unknowns **MUST** map to an explicit LOG branch (`Degrade` or `Abstain`); `sandbox/probe‑only` is a **LOG branch** with an **E/E‑LOG policy‑id (PolicyIdRef)**. \n* **CC‑G8‑3 (Path citation).** Every `Admit/Degrade/Abstain` **MUST** cite **EvidenceGraph PathId(s)** at run‑time when G.6 is present (per C.23/H4). **At packaging time**, the Bundle/Ledger **SHALL** provide **A.10 Evidence Graph Ref** and **MAY** include stable **PathId(s)** where available.* **CC‑G8‑4 (Bridge & plane penalties).** Crossings **MUST** cite **Bridge ids** and **Φ(CL)**/**Φ_plane** policy‑ids; **penalties reduce `R_eff` only**; **F/G invariant**. \n* **CC‑G8‑5 (Dominance defaults).** **Default** `DominanceRegime = ParetoOnly`; inclusion of **Illumination** in dominance **requires** an explicit CAL policy with **policy‑id recorded in SCR**. \n* **CC‑G8‑6 (QD/OEE edition discipline).** When QD/OEE are active, bundles **MUST** pin **`U.DescriptorMapRef.edition`**, `DistanceDefRef.edition`, `EmitterPolicyRef`/`InsertionPolicyRef`, and (for OEE) `TransferRulesRef.edition`. **`CharacteristicSpaceRef.edition` SHALL be pinned whenever grid/cell boundaries or de‑duplication rules affect parity/selection;** otherwise it MAY be omitted from packaging, but **telemetry MUST still record it when QD is in scope**. Any illumination increase **MUST** log `PathSliceId` + **policy‑id**. `CharacteristicSpaceRef.edition` **MUST NOT** be used as a substitute for `DescriptorMapRef.edition`.\n* **CC‑G8‑7 (Maturity = ordinal).** Ladders **SHALL** declare **Scale kind=ordinal** and closed rungs; rung transitions **MUST** be justified by EvidenceGraph paths and published to UTS. \n* **CC‑G8‑8 (Spaces ≠ Maps).** Do not alias `CharacteristicSpace` and `DescriptorMap`; use **Tech** heads with editions on **Refs** only; obey twin‑register rules. \n* **CC‑G8‑9 (Notational independence).** Bundles **SHALL** remain tool/format‑neutral (Core semantics only). \n* **CC‑G8‑10 (MOO cross‑reference).** Method of obtaining outputs: when the LOG bundle is consumed to emit selector **sets**, the producing step **SHALL** surface the **generation/parity mechanism** id (e.g., **ParityHarnessId** under G.9) and the controlling **policy‑id** in **SCR** and telemetry. (Packaging remains conceptual per **E.5.2**.)\n* **CC‑G8‑11 (SoTA‑of‑description trace).** If any authoring methods (e.g., discovery, clustering, summarisation) materially influenced rule text or ladder rungs, **cite their `AuthoringMethodDescriptionRefs` with editions**. This supports cross‑stance SoTA tracking of the *methods that describe methods* without adding tool lock‑in (E.5.2).\n",
        "archetypal_grounding": "### G.8:7 - Archetypal grounding (informative, SoTA‑oriented)\n\n**Show‑A - Decision‑making (selector returns a set).**\n*S2 excerpt.* `TaskKind=multi‑criteria; Orders=partial; PortfolioMode=Pareto`.\n*Families.* Outranking/MCDA, Causal (SCM), Offline‑RL/Decision‑Transformer, Bayesian Optimisation (risk‑aware).\n*Bundle.* `SoS‑LOG` cites **PathIds** for replication/legality; **MaturityFloor** enforced via **AcceptanceClause** `AC_MaturityFloor(≥L2)`; selector returns a **Pareto set**, no cross‑ordinal averaging.  \n\n**Show‑B - QD archive (policy search, MAP‑Elites‑class).**\n*S2 excerpt.* `PortfolioMode=Archive; CharacteristicSpaceRef(d=2); ArchiveConfig(K=1, CVT, DistanceDefRef.edition=v2); EmitterPolicyRef=v3; DominanceRegime=ParetoOnly`.\n*Bundle.* `Admit` returns an **archive**; **IlluminationSummary** (Q/D/QD‑score) is reported; editions and **policy‑id** are pinned for refresh. Contemporary QD families include **MAP‑Elites (2015)**, **CMA‑ME/MAE (2020–)**, **Differentiable QD/MEGA (2022–)**, **QDax (2024)**. \n\n**Show‑C - Open‑ended generators (POET‑class; environments + methods).**\n*S2 excerpt.* `GeneratorIntent; EnvironmentValidityRegion=EVR‑A; TransferRulesRef=TR‑A`.\n*Bundle.* Admits portfolios over `{environment, method}`; unknown `TransferRules` ⇒ `Degrade(scope‑narrow)`; telemetry logs **coverage/regret** and **edition bumps**; SoTA includes **POET (2019)**, **Enhanced‑POET (2020)**, and **Darwin Gödel Machine (2025)**‑class approaches.\n\n> *Didactic note.* These examples reflect the **“single call, many solvers”** idiom and portfolio‑first selection (akin to **DifferentialEquations.jl** and **JuMP** ecosystems), which the **G.5** registry expects. \n",
        "relations": "### G.8:8 - Relations\n\n**Builds on:** **C.23** (SoS‑LOG), **G.4** (Acceptance), **G.6** (EvidenceGraph, PathId), **C.22** (TaskSignature S2), **F.9** (Bridges & CL), **G.7** (Bridge Matrix & CL calibration), **C.18/C.19** (QD/E‑E), **E.18/A.21/A.27** (GateCrossing/CrossingSurface checks).\n**Publishes to:** **G.5** (selector/registry), **UTS** (bundle, ladder, ledger), **G.11** (refresh via PathSlice & editions).  \n**Constrains:** Any LOG implementation that claims FPF conformance; **default dominance** and **tri‑state** behavior must match **G.5** semantics. \n",
        "bias‑annotation": "### G.8:9 - Bias‑Annotation\n\nLenses tested: **Gov**, **Arch**, **Onto/Epist**, **Prag**, **Did**.\nScope: **Core‑wide**; ordinal scales are never averaged; **Illumination** stays report-only telemetry unless explicitly promoted into dominance by CAL policy (policy‑id cited).  \n",
        "author’s_quick_checklist": "### G.8:10 - Author’s quick checklist\n\n1. Compile **RuleIds[]** with tri‑state handling and **PathId** citations; run **GateCrossing/CrossingSurface** visibility checks (**E.18/A.21/A.27**).\n2. Describe the **MaturityCard** (ordinal; closed enum; ReferencePlane declared); **do not** embed thresholds. \n3. Register **Φ(CL)**/**Φ_plane** policies (ids only); ensure penalties route to **R_eff** only. \n4. If QD/OEE is active, pin **editions** (`DescriptorMapRef`/`DistanceDefRef`/`TransferRulesRef`) and expose **PathSliceId** for refresh. \n5. Publish **SoS‑LOGBundle** and **AdmissibilityLedger** to **UTS** (twin labels; editioned). \n6. Declare `DominanceRegime`/`PortfolioMode`; **default = ParetoOnly**; if Illumination is promoted into dominance, cite the **CAL policy id**.\n",
        "g.8:end": "### G.8:End\n"
      },
      "content": "### G.8:End\n",
      "metadata": {},
      "part": "G",
      "cluster": null
    },
    {
      "id": "G.9",
      "title": "Parity / Benchmark Harness",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## G.9 - Parity / Benchmark Harness\n\n**Tag:** Architectural pattern\n**Stage:** design‑time planning **+** run‑time execution (selector‑adjacent)\n**Primary hooks:** **G.5** (selector & portfolios), **G.6** (EvidenceGraph, PathId/PathSlice), **G.4** (Acceptance & CAL predicates), **C.23** (SoS‑LOG branches & maturity), **C.22** (TaskSignature S2), **C.18/C.19** (QD & E/E‑LOG policies), **G.7** (Bridge Matrix & CL calibration, BCT/Sentinels), **F.15** (RSCR parity/regression), **F.9** (Bridges & CL), **E.18/A.21/A.27** (GateCrossing & CrossingSurface), **E.5.2** (Notation‑independence).\n**Why this exists.** Rival **MethodFamilies/Traditions** are often “benchmarked” under different freshness windows, editions, or via illegal scalarisations; results cannot be lawfully compared or reproduced. **G.9** provides a *method of obtaining outputs*: a **parity plan + execution harness** that produces a **ParityReport@Context** consumable by **G.5**, with apples‑to‑apples baselines, lawful orders (often partial), and **PathId‑cited** provenance. IlluminationSummary (telemetry summary) and coverage/regret (telemetry metrics) are exposed as **report‑only telemetry** and **excluded from dominance by default**; any promotion into dominance must be explicit in CAL policy and the **policy‑id** must be recorded in SCR. Parity pins are **edition‑aware** and **bridge/plane‑aware** by construction.\n**Modularity note.** G.9 does **not** redefine SoS‑LOG or Acceptance; it **binds** them into a parity plan, calls the **G.5** selector in set‑returning mode, and **publishes** evidence per **G.6** with **GateCrossing visibility** (CrossingSurface, E.18/A.27). Thresholds remain in **G.4**; LOG semantics remain in **C.23**.\n",
        "intent": "### G.9:1 - Intent\n\nProvide a **notation‑independent** harness that designs and executes **lawful, edition‑aware** parity runs **across families/traditions**—with equal **freshness windows**, **editions**, **budgets**, and **Bridge/CL/CL^plane routing**—so that **G.5** can select **sets** (Pareto/Archive) without illicit scalarisation. Parity outputs are published as **`ParityReport@Context`** with **EvidenceGraph PathIds** and **CAL policy‑ids** for any non‑default dominance behaviour.\n\nWhen Characteristics live on different scales/units or spaces, parity **MUST** use **SCP‑based comparability** (“normalize, then compare”) before any numeric comparison, per the CG‑Spec/MM‑CHR legality.\n",
        "problem": "### G.9:2 - Problem frame\n\nBenchmarks routinely compare unlike with unlike: different dataset editions, metric definitions, or QD grids; ordinal measures get averaged; illumination is mixed into dominance. Cross‑Context reuse skips **Bridges** and **CL penalties**. G.9 cures this by fixing a **BaselineSet**, **FreshnessWindows**, and a **ComparatorSet** bound to **CG‑Spec** characteristics and editions, then **driving** the selector to return **sets** under admissible orders and **publishing** legally interpretable results.  \n",
        "forces": "### G.9:3 - Forces\n\n* **Pluralism vs comparability.** Rival traditions must be comparable **without** semantic collapse; comparisons cross **Bridges**, incur **CL→R** penalties only. \n* **Partial orders vs totals.** Many targets remain **partially ordered**; the harness must not force totals; **return sets**. \n* **Edition‑awareness.** QD/OEE outcomes depend on **`DescriptorMapRef.edition`**, **`DistanceDefRef.edition`**, **Emitter/Insertion** policies; parity must *pin* them. \n* **Telemetry vs objectives.** **IlluminationSummary** (telemetry summary) and **coverage/regret** (telemetry metrics) inform health but are **report‑only by default**; dominance may only change via CAL policy‑id (recorded in SCR). \n* **GateCrossing visibility.** Crossings/gates must be visible via **CrossingSurface** (**E.18**; **A.27**; **F.9**) and must pass **LanePurity** + **Lexical SD** GateChecks (A.21/E.10); failures block publication.\n",
        "solution": "### G.9:4 - Solution — *Plan parity; execute once; publish sets with path‑cited evidence*\n\n#### G.9:4.1 - Objects (LEX heads; twin‑register discipline)\n\n* **`ParityPlan@Context`** — design‑time object that fixes comparison terms:\n  `⟨PlanId(UTS), CG‑FrameId, HomeContext, BaselineSet, FreshnessWindows, ComparatorSet(id), Budgeting, ε, BridgeIds[], ΦPolicyIds[], EvidenceGraphRef(A.10), EditionPins, PortfolioMode, DominanceRegime, Notes⟩`.\n\n* **`EditionPins`** (when QD/OEE):\n  `⟨DescriptorMapRef.edition, DistanceDefRef.edition, DHCMethodRef.edition, DHCMethodSpecRef.edition, CharacteristicSpaceRef.edition?, EmitterPolicyRef, InsertionPolicyRef, (OEE) TransferRulesRef.edition⟩`.\n\n* **`ComparatorSet`** — a set of **CG‑Spec‑bound** characteristics with declared **Scale kind, units, polarity**, lawful order (≤, ≽, lexicographic, Pareto), **ReferencePlane**, and the **editions used by any measures** (`DHCMethodRef.edition`/**`DHCMethodSpecRef.edition`**, `DistanceDefRef.edition`). **Ordinal averages are forbidden.** Where spaces/scales differ, parity **MUST** declare the **UNM/NormalizationMethod‑based mapping** used to lawfully embed one coordinate space into the other prior to comparison. Any numeric comparison/aggregation **must** be CSLC‑lawful and cite the corresponding CG‑Spec entry.\n\n* **`ParityReport@Context`** — run‑time publication object (below §5).\n\n**Naming discipline.** Heads reuse existing U‑types and LEX rules; **no new “Strategy” U.Type** is minted (policies live in **E/E‑LOG**). Tech/Plain twins follow **E.10**. \n\n#### G.9:4.2 - Parity planning (design‑time; notation‑independent)\n\n1. **Fix the BaselineSet.** Choose **MethodFamilies** (and, if present, **GeneratorFamilies**) to compare; cite **SoS‑LOG bundle ids** and **MaturityCard** rungs for context; thresholds stay in **Acceptance**. Where cross‑Tradition reuse occurs, ensure corresponding **G.7 BridgeCards** and **Calibration Ledger/BCT** entries exist and are referenced by id.\n2. **Equalise FreshnessWindows.** Declare **identical** evidence windows for all baselines; record **lanes** (TA/VA/LA) and carriers in **A.10**. \n3. **Pin editions.** Freeze **`DHCMethodRef.edition`/`DHCMethodSpecRef.edition`/`DistanceDefRef.edition`**, `DescriptorMapRef.edition`, and (if applicable) **`CharacteristicSpaceRef.edition`**; pin `EmitterPolicyRef` and `InsertionPolicyRef`; in OEE also **`TransferRulesRef.edition`**. \n4. **Bind ComparatorSet to CG‑Spec.** For every numeric operation, cite **CG‑Spec.Characteristics** and prove **CSLC** legality; attach **ReferencePlane**. Where scales/units/spaces differ, declare the **UNM**/**NormalizationMethod(s)** used (“normalize, then compare”) and its lawful scope.\n5. **Declare order & portfolio semantics.** **Default** `DominanceRegime = ParetoOnly`; **IlluminationSummary** is a **telemetry summary** (report‑only) unless CAL declares `ParetoPlusIllumination` by id (policy‑id recorded in SCR); choose `PortfolioMode ∈ {Pareto|Archive}`. If ε‑front thinning is used, declare **`EpsilonDominance (ε≥0)`** explicitly and cite policy/edition where relevant.\n6. **Route crossings.** Where Traditions/planes or Kinds differ, require **Bridge ids** and publish **Φ(CL)**/**Φ_plane** (and, where used, **Ψ(CL^k)**) policy‑ids; penalties **reduce R_eff only**; **F/G invariant**. \n\n#### G.9:4.3 - Execution protocol (run‑time; selector‑adjacent)\n\n* **E1 - Gate on legality.** Run **Eligibility → Acceptance** on the shared **S2 TaskSignature**; refuse illegal CHR ops (e.g., ordinal means). \n* **E2 - Call G.5 with parity pins.** Execute **G.5.Select** under the parity **ComparatorSet**/**EditionPins**; **return a set** (Pareto/Archive) when order is non‑total; record **Bridge/Φ/Φ_plane** (and **Ψ**, if kind‑bridges apply) policy‑ids and compute **R_eff** with penalties *to R only*. If **UNM**/**NormalizationMethod(s)** were declared, record their ids/notes in SCR and cite the applicable PathIds.\n* **E3 - Report telemetry.** Publish **IlluminationSummary** (Q/D/QD‑score) as a **telemetry summary** and **coverage/regret** as **telemetry metrics**; keep them **excluded from dominance by default** unless a CAL policy explicitly promotes them (policy‑id recorded in SCR). \n* **E4 - Cite paths.** Every inclusion/exclusion decision **cites EvidenceGraph PathId(s)**; path‑local **PathSliceId** is emitted for editioned QD/OEE events. \n* **E5 - Telemetry for refresh.** On illumination increase or archive change, log **policy‑id** and **editions** (`DescriptorMapRef`/`DistanceDefRef`/`CharacteristicSpaceRef`/`DHCMethodSpecRef`/`TransferRulesRef`), enabling **G.11** refresh and **F.15 RSCR** triggers. \n\n#### G.9:4.4 - QD & OEE parity (specialisations)\n\n* **QD parity.** Require identical **CharacteristicSpace** resolution/topology and **`CharacteristicSpaceRef.edition`**, plus **`DescriptorMapRef.edition`**, **`DistanceDefRef.edition`**, **InsertionPolicyRef**, **EmitterPolicyRef** across families during comparison; **IlluminationSummary** remains a **telemetry summary** (report‑only) unless CAL promotes it into dominance (policy‑id recorded in SCR). \n* **OEE parity (POET/Enhanced‑POET/DGM‑class).** Declare a shared **`EnvironmentValidityRegion`** and **`TransferRulesRef.edition`**; outputs are **{environment, method}** portfolios; **coverage/regret** are **telemetry metrics** (report‑only). \n",
        "interfaces_—_minimal_i/o_(conceptual;_core‑only)": "### G.9:5 - Interfaces — minimal I/O (conceptual; Core‑only)\n\n| Interface                          | Consumes                                                                                                  | Produces                                                                                                                                                                                                                    |\n| ---------------------------------- | --------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **G.9‑1 `Plan_Parity`**            | BaselineSet; FreshnessWindows; **CG‑Spec** ids; **SoS‑LOG bundles**; Bridges/Φ; EditionPins; Budgeting; ε | **`ParityPlan@Context`** (UTS row; editioned)                                                                                                                                                                               |\n| **G.9‑2 `Run_Parity`**             | `ParityPlan@Context`; `TaskSignature (S2)`; **G.5.Select**                                                | Selector outputs (**set** per `PortfolioMode`), DRR+SCR with **PathIds/PathSliceId**, Portfolio Pack                                                                                                                        |\n| **G.9‑3 `Publish_ParityReport`**   | Run artefacts; Telemetry                                                                                  | **`ParityReport@Context`**: `⟨BaselineSet, FreshnessWindows, ComparatorSet(id), EpsilonDominance ε?, PathIds[], AbstainReasons[], Portfolio, Telemetry{IlluminationSummary, coverage, regret}, DHCMethodRef.edition/DHCMethodSpecRef.edition/DistanceDefRef.edition/CharacteristicSpaceRef.edition?, EditionPins, CalibrationLedgerId?/BCT.id?, RSCRRefs[]⟩` |\n| **G.9‑4 `Expose_ParityTelemetry`** | Archive/regret signals; illumination deltas                                                               | Telemetry events (`PathSliceId`, **policy‑id**, editions) for **G.11** refresh/**F.15** RSCR                                                                                                                                |\n\nSurfaces are **conceptual**; serialisations belong to **G.10 Annex/Interop** (no tool lock‑in). \n",
        "conformance_checklist": "### G.9:6 - Conformance Checklist (CC‑G9)\n\n1. **Equal windows & editions.** All baselines **SHALL** use **identical FreshnessWindows** and **pinned editions** for **`DHCMethodRef`** and **`DistanceDefRef`**; QD pins include `DescriptorMapRef.edition`, `CharacteristicSpaceRef.edition` (if applicable), `DistanceDefRef.edition`, and `Emitter/Insertion` policies. \n2.  **Spec‑level pin.** Where DHC methods are used, parity **SHALL** also pin **`DHCMethodSpecRef.edition`** to forbid silent spec drift and to enable RSCR triggers.\n3. **Lawful orders; no scalarisation.** The harness **MUST NOT** force a total order where only partial orders are lawful; return **Pareto/Archive** and tie‑notes; **no ordinal averages**. \n4. **Normalization discipline.** If Characteristics differ by unit/scale/space, parity **MUST** declare lawful **UNM**/**NormalizationMethod(s)** and compare only after normalizing to **NCVs** (“normalize, then compare”).\n5. **Default dominance.** `DominanceRegime` **SHALL** default to **`ParetoOnly`**; any inclusion of illumination into dominance **MUST** be a CAL policy with **policy‑id** cited in SCR. \n6. **Bridge routing.** Cross‑Context/plane/Kind use **MUST** cite **Bridge ids** and **Φ(CL)**/**Φ_plane** (and **Ψ(CL^k)** where used); penalties **→ R_eff only**; **F/G invariant**. \n7. **Path citation.** Every parity decision **MUST** cite **EvidenceGraph PathId(s)** (and **A.10** anchors); refusal paths included. \n8. **Telemetry for illumination/OEE.** Any illumination increase or OEE transfer **MUST** log `PathSliceId`, **policy‑id**, and active editions (incl. **`CharacteristicSpaceRef.edition`** and **`TransferRulesRef.edition`**). \n9. **RSCR parity tests.** Publish RSCR tests covering **negative/refusal paths** (illegal CHR, missing Bridges/Φ tables, edition drift). \n10. **GateCrossing visibility (CrossingSurface).** Any cited crossing **MUST** publish **CrossingSurface** (**E.18:CrossingSurface**) and satisfy **LanePurity** and **Lexical SD** (E.10); failures block publication. \n11. **Tech‑register discipline.** Do not use the noun *metric* as a Tech primitive; cite **`DHCMethodRef`**/**`U.Measure`** and **`DistanceDefRef`** editions.\n12. **MOO surfaced (parity).** Method-of-obtaining-output: `Run_Parity` **MUST** record the **ParityHarnessId** and any active **EmitterPolicyRef/InsertionPolicyRef** (where QD applies), together with the **CAL policy‑id** for any non‑default dominance. These ids **SHALL** appear in **SCR** and parity telemetry (PathSlice‑keyed). (No scalarisation is introduced by this reporting.)\n",
        "anti‑patterns_&_remedies": "### G.9:7 - Anti‑patterns & remedies\n\n* **AP‑1 Hidden edition drift.** *Remedy:* Pin editions in `EditionPins`; re‑run RSCR on any change. \n* **AP‑2 Averaging ordinals.** *Remedy:* CG‑Spec guards + CSLC proofs; report as **ordinal compare‑only**. \n* **AP‑3 Illumination in dominance by default.** *Remedy:* Keep **IlluminationSummary** as a **report‑only telemetry summary** (and coverage/regret as **telemetry metrics**); promote only via CAL policy‑id (recorded in SCR). \n* **AP‑4 Bridge‑free crossings.** *Remedy:* Require **Bridge** with **CL** and **loss note**; penalties to **R**. \n* **AP‑5 “Metric” as a primitive in Tech.** *Remedy:* Use **`DHCMethodRef`**/**`U.Measure`** and **`DistanceDefRef`** with editions; in Plain register *metric* may appear only as a didactic synonym with an explicit pointer to canonical terms.\n* **AP‑6 Hidden spec drift.** *Remedy:* Pin **`DHCMethodSpecRef.edition`** and register RSCR tests for spec changes; refuse parity reuse on unpinned spec editions.\n",
        "archetypal_grounding": "### G.9:8 - Archetypal grounding (informative, SoTA‑oriented)\n\n**Show‑A - Decision‑making multi‑Tradition parity (EU/MCDA vs Causal vs Offline‑RL/DT vs BO).**\n*Plan.* Equal **freshness** (e.g., rolling 24 mo); ComparatorSet uses **ordinal** preference and **ratio** risk (CVaR). *Execution:* selector returns a **Pareto set**; **no cross‑ordinal weighting**; **regret** reported as a **telemetry metric** (report‑only).  \n\n**Show‑B - QD parity (MAP‑Elites / CMA‑ME / DQD / QDax‑class).**\n*Plan.* `PortfolioMode=Archive`, fixed grid (or CVT), **CharacteristicSpaceRef.edition=v1**, **DescriptorMapRef.edition=v2**, **DistanceDefRef.edition=v2**, `EmitterPolicyRef=v3`, `InsertionPolicyRef=elite‑replace`. *Execution:* **Archive** is the returned set; **IlluminationSummary (Q/D/QD‑score)** reported; **dominance = ParetoOnly** unless CAL says otherwise.  \n\n**Show‑C - OEE parity (POET/Enhanced‑POET/DGM‑class).**\n*Plan.* Shared **`EnvironmentValidityRegion`** and **`TransferRulesRef.edition`**; ComparatorSet ties coverage to **telemetry‑metric** semantics; selector returns **{environment, method}** portfolios. *Execution:* **coverage/regret** recorded as **telemetry metrics**; edition & **policy‑id** bumps logged with **PathSliceId**; where QD is active, also log **`CharacteristicSpaceRef.edition`**.\n\n> *Didactic note.* These examples follow **“single call, many solvers”** and **portfolio‑first** selection idioms (akin to **DifferentialEquations.jl**/**JuMP**) that **G.5** expects; G.9 supplies the *parity scaffolding* around those calls. \n",
        "payload_—_what_this_pattern_*exports*": "### G.9:9 - Payload — what this pattern *exports*\n\n**`ParityReport@Context`** (UTS row; editioned):\n`⟨BaselineSet, FreshnessWindows, ComparatorSet(id), EpsilonDominance ε?, Portfolio(Set | Archive), Telemetry{IlluminationSummary, coverage, regret}, PathIds[], PathSliceId?, BridgeIds[], ΦPolicyIds[]/Φ_plane?/Ψ(CL^k)?, DHCMethodRef.edition/DHCMethodSpecRef.edition/DistanceDefRef.edition/CharacteristicSpaceRef.edition?, EditionPins, CalibrationLedgerId?/BCT.id?, AbstainReasons[], RSCRRefs[]⟩`.\n\n**Plus:** DRR+SCR bundle; **Portfolio Pack**; **Run‑safe Plan**; Telemetry events for **G.11** refresh. \n",
        "relations": "### G.9:10 - Relations\n\n**Builds on:** **G.5** (set‑returning selector), **G.6** (PathIds, PathSlice), **G.4** (Acceptance thresholds), **C.23** (SoS‑LOG duties), **C.22** (S2 typing), **C.18/C.19** (QD/E‑E), **F.15** (RSCR harness), **F.9** (Bridges/CL).  \n**Publishes to:** **UTS** (plans/reports; twin labels), **G.11** (refresh signals), **G.10** (shipping surface, Annex mappings). \n**Constrains:** **G.5** callers to cite **policy‑ids & editions** in portfolios; **G.12** dashboards to treat parity telemetry lawfully. \n",
        "author’s_quick_checklist": "### G.9:11 - Author’s quick checklist\n\n1. **Plan**: fix BaselineSet (≥2 traditions), equal FreshnessWindows, **ComparatorSet** bound to **CG‑Spec** (CSLC proofs attached; **UNM**/**NormalizationMethod(s)** declared where needed). \n2. **Pin** editions (`DescriptorMapRef`/`DistanceDefRef`/`DHCMethodRef`/**`DHCMethodSpecRef`**/`Emitter`/`Insertion`/`TransferRulesRef` if OEE). \n3. **Declare** `PortfolioMode` and **default** `DominanceRegime=ParetoOnly`; if changing, cite CAL **policy‑id**. \n4. **Route** crossings via Bridges; publish **Φ(CL)**/**Φ_plane**; penalties → **R_eff only**. Reference **G.7** **Calibration Ledger/BCT** ids for the crossings used.\n5. **Execute** G.5; **return a set**; record DRR+SCR with **PathIds**/**PathSliceId**.  \n6. **Publish** `ParityReport@Context`; attach RSCR parity tests (refusal paths; edition drift). \n",
        "g.9:end": "### G.9:End\n"
      },
      "content": "### G.9:End\n",
      "metadata": {},
      "part": "G",
      "cluster": null
    },
    {
      "id": "G.10",
      "title": "SoTA Pack Shipping (Core Publication Surface)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## G.10 - SoTA Pack Shipping (Core Publication Surface)\n\n**Tag:** Architectural pattern (conceptual, notation‑independent; Core surface only)\n**Stage:** *release‑time* composition of discipline packs, consumable by selectors and audits; edition‑aware; **GateCrossing‑gated (E.18/A.21/A.27)**.\n**Builds on:** **G.1–G.8** (generator → harvester → CHR/CAL → dispatcher → evidence/bridges/log bundle),\n**F.17–F.19** (generator orchestration), **B.3** (trust calculus), **E.5.2** (notational independence),\n**E.18** (E.TGA GateCrossing hooks / CrossingSurface), **C.18/C.19/C.23** (NQD/QD‑telemetry; E/E‑LOG; SoS‑LOG)\n\n**Publishes to:** **UTS** (twin‑label Name Cards), **G.5** (selector parity pins & portfolios), **SCR/RSCR**, **G.11** (telemetry/refresh)\n**Optional inputs:** **G.13 `InteropSurface@Context`** (if present) MAY be cited to declare which external‑index editions and embedding specs (`PlaneMap`, `ScaleEmbeddingSpec`) informed the shipped pack; Core remains notation‑independent (Annex handles concrete crosswalks).\n",
        "intent": "### G.10:1 - Intent\n\nProvide a **single, normative shipping surface**—the **SoTA‑Pack(Core)**—that turns the outputs of G.1–G.8 into a **release‑quality, selector‑ready, edition‑aware portfolio** without mandating any file formats. The pack **exposes what was decided, why, and under which policies/editions**, so that **G.5 may return sets (Pareto or Archive)** and audits can cite **stable EvidenceGraph paths**. IlluminationSummary (telemetry summary) and coverage/regret (telemetry metrics) are exported as **report‑only telemetry**, not forced into dominance unless a declared CAL policy says so (policy‑id recorded in SCR). (All order/illumination defaults are **inherited** from **G.5/G.6/G.8**.)\n\n**Why this matters.** Earlier G‑patterns emphasised legality and assurance; **G.10** completes the generative loop by defining how SoTA outputs are *shipped* — with parity pins, PathSlice anchoring, **GateCrossing/CrossingSurface hooks**, and telemetry stubs—so the next author or selector can **use** them immediately, not just verify them.\n\n**Editorial – Close the generative loop.** For each CG‑Frame, drive **G.1 Generator → G.2 SoTA Harvester → G.3–G.4 authoring → G.5 Selector (set‑returning)**, then publish a **SoTA‑Pack(Core)** (this pattern) with parity pins & PathIds, and register **G.11** refresh on illumination increases (QD/OEE). *(No additional file formats; Core remains notation‑independent.)*\n",
        "problem": "### G.10:2 - Problem frame\n\nTeams can already generate variants (G.1), harvest SoTA (G.2), author CHR/CAL/LOG (G.3–G.4), register families (G.5), mint paths (G.6), calibrate bridges (G.7), and bundle SoS‑LOG (G.8). What is **missing** is a **Core, notation‑independent shipping object** that *packages* these moving parts with:\n\n* **UTS‑visible identities and twin labels** (so people can talk about the pack); **no tool lock‑in** in Core.\n* **Selector parity** (ComparatorSet and EditionPins) so G.5 can compute **sets** lawfully; **Illumination** stays **report‑only telemetry** by default.\n* **PathIds/PathSliceIds** and **policy‑ids** so **C.23 decisions** and maturity changes cite **exact evidence paths**.\n* **Telemetry stubs** so **edition‑aware refresh** can be triggered on **illumination increases** or bridge edits. \n",
        "solution": "### G.10:3 - Solution — *Ship a SoTA‑Pack(Core); keep file formats in Annex*\n\nA **SoTA‑Pack(Core)** is a **conceptual object** (published to **UTS** and surfaces) with **no mandated serialisation** in Core; mapping to external crates/registries (e.g., RO‑Crate, ORKG, OpenAlex) lives in **Annex/Interop**. Core prescribes **fields and obligations**, not files or schemas. **Cards/tables are conceptual only**; machine checks and linters belong to Tooling. (Per **E.5.2**, formats are out‑of‑scope for Core.)\n\n#### G.10:3.1 - Data model (normative; notation‑independent)\n\n```\nSoTA‑Pack(Core) :=\n⟨ PackId (UTS), Edition, HomeContext,\n  CG‑FrameRef, describedEntity := ⟨GroundingHolon, ReferencePlane⟩,\n  ComparatorSetRef (CG‑Spec) + Γ‑fold notes,            // legality & folding\n  ParityPins := { EditionPins, ΦPolicyIds },             // edition/policy anchors (ids only)\n  Families := { MethodFamilyIds[], GeneratorFamilyIds?[] },\n  SoS‑LOGBundleRef?, MaturityCardRef?,                   // G.8 outputs\n  AdmissibilityLedgerRef?,                               // selector-facing rows\n  Portfolio := { DominanceRegime, PortfolioMode, ε? },   // default: ParetoOnly\n  Bridges := { BridgeIds[], ΦPolicyIds[], Φ_plane?, Ψ(CL^k)?[] },\n  Evidence := { A10EvidenceGraphRef?[], EvidenceGraphPathIds?[] }, // path-justified slots\n  QD := { CharacteristicSpaceRef,\n          CharacteristicSpaceRef.edition?,\n          DescriptorMapRef.edition,\n          DistanceDefRef.edition,\n\t          DHCMethodRef.edition?,        // optional: guards QD telemetry computations when CHR-provided\n          DHCMethodSpecRef.edition?,    // optional: prevents silent spec drift (parity alignment)\n          EmitterPolicyRef?, InsertionPolicyRef?, \n          IlluminationSummary? },       // telemetry summary; report-only by default\n  OEE? := { EnvironmentValidityRegion, TransferRulesRef.edition }, // generator families\n  PathSlices := { PathSliceId?[] },                      // pins Γ_time & plane\n  SCR/DRR := { SelectionReports[], RationaleEntries[] },\n  Notes ⟩\n```\n\n**Defaults & invariants.** Inherit order/illumination and measurement legality from **CC‑G5/CC‑G6/CC‑G8**. Locally for shipping: (i) **ParityPins** MUST include `EditionPins` for any QD/OEE surfaces (`DescriptorMapRef.edition`, `DistanceDefRef.edition`, and, where applicable, `CharacteristicSpaceRef.edition`, `TransferRulesRef.edition`). (ii) **PathSliceId** MUST be recorded whenever QD/OEE pins exist (for path‑local refresh). (iii) **CL/CL^plane** penalties **reduce `R_eff` only** (F/G invariant).\n\n> *Rationale.* This structure gives **G.5** everything it needs: admissible order, portfolio semantics, **parity pins** and **policy ids**, and (when present) **QD/OEE telemetry** (`IlluminationSummary`, coverage, regret) and **PathIds** for explainability, without binding to any vendor notation.\n",
        "shipping_choreography_(normative_steps;_sota_method_for_release)": "### G.10:4 - Shipping choreography (normative steps; SoTA method for release)\n\n**S‑1 - Pin parity (ComparatorSet & Editions).**  \nAttach the **CG‑Spec ComparatorSet** (characteristics, **ScaleComplianceProfile (SCP)**, Γ‑fold) and **EditionPins** for QD/OEE (`DescriptorMapRef.edition`, `DistanceDefRef.edition`, `TransferRulesRef.edition`), and, when relevant to reproduction of partitioning, `CharacteristicSpaceRef.edition`. \nFor **QD archive semantics**, also **pin `EmitterPolicyRef` and `InsertionPolicyRef`** (replacement/K‑capacity semantics). \nThis ensures **lawful comparison** and **replayable fronts**; **IlluminationSummary** is exported as a **telemetry summary** (report‑only by default).\n\n**S‑2 - Publish selector semantics.**  \nDeclare `DominanceRegime` and `PortfolioMode ∈ {Pareto|Archive}` (and `ε` if used). **Return sets** (non‑dominated or archive) by default; do **not** force scalarisation.\n\n**S‑3 - Bind crossings to penalties (R‑only).**  \nFor every cross‑Context/plane or kind crossing, cite **Bridge ids** and **ΦPolicyIds**/**Φ_plane** (and **Ψ(CL^k)** where applicable). **Penalties are monotone, bounded, table‑backed** and **route to `R_eff` only**; **F/G invariant**. Publish **loss notes** in UTS/Notes.\n\n**S‑4 - Anchor evidence.**\nProvide **A.10 anchors** (lanes + freshness windows) and, where already minted, **PathIds**/**PathSliceIds** for rung changes and LOG decisions; missing anchors **forbid** maturity advance. **Lane tags** remain separable into **TA/VA/LA** and visible in **SCR**.\n**S‑5 - Expose GateCrossing hooks (CrossingSurface).**\nThe pack **MUST** expose **CrossingSurface** (**E.18:CrossingSurface**) for each GateCrossing (via **G.10‑3 `Expose_CrossingHooks`**) and **fail fast** on any missing or non‑conformant surface. Publication **fails** if lane purity is violated or if required penalty policy‑ids are absent/unresolvable.\n\n**S‑6 - Wire telemetry for refresh.**  \nWhenever **illumination increases** or archive editions change, emit telemetry with **PathSliceId**, the active **policy‑id**, and editions of `DescriptorMapRef`/`DistanceDefRef` (and `TransferRulesRef.edition` for OEE). \nAlso log **`EmitterPolicyRef` and `InsertionPolicyRef`** in telemetry for QD runs. \nWhen QD partitioning depends on the Space phase, include `CharacteristicSpaceRef.edition`. \nThese feed **G.11** refresh/decay and **path‑local RSCR** (Bridge sentinels).\n\n**S‑7 - Publish to UTS (twin labels; local‑first).**\nMint a **UTS Name Card** for the pack and its major items (e.g., `SoS‑LOGBundle@Context`, `AdmissibilityLedger`, `MaturityCardDescription`), with **Tech/Plain twins** under the local Context; **identity travels only via Bridges** with CL and loss notes.\n\n> **Design note.** The choreography is **methodic generation**, not a post‑hoc checklist: parity pinning, path anchoring, GateCrossing/CrossingSurface gating, and telemetry stubs are **produced** during shipping to increase the chance that downstream selections and updates remain lawful and reproducible. (This rebalances FPF from “assurance‑only” toward **result‑oriented generation**.)\n",
        "interfaces_&_hooks_(selector‑_and_audit‑facing)": "### G.10:5 - Interfaces & hooks (selector‑ and audit‑facing)\n\n| ID         | Interface (conceptual)     | Consumes                                                          | Produces                                                |\n| ---------- | -------------------------- | ----------------------------------------------------------------- | ------------------------------------------------------- |\n| **G.10‑1** | `Compose_SoTA_Pack`        | G.1–G.8 outputs, ComparatorSet, Bridges, editions, SCR/DRR deltas | `SoTA‑Pack(Core)` (UTS row + surfaces)                  |\n| **G.10‑2** | `Publish_PortfolioSurface` | Portfolio semantics, parity pins, ε?                              | Selector‑readable parity surface (no formats mandated)  |\n| **G.10‑3** | `Expose_CrossingHooks`     | GateCrossings, lanes/planes/contexts | **CrossingSurface** (**E.18:CrossingSurface**) per GateCrossing; **fail** on missing or non‑conformant surfaces |\n| **G.10‑4** | `Emit_TelemetryPins`       | Illumination/archive/OEE events                                   | PathSlice‑keyed telemetry: `policy‑id`, `…Ref.edition`  |\n| **G.10‑5** | `Publish_PathCitations`    | A.10 anchors, PathIds                                             | PathId/PathSlice citations for C.23/H4 & rung changes   |\n| **G.10‑6** | `Ingest_InteropSurface?`   | (optional) **G.13 `InteropSurface@Context`**                       | Annotated pack notes citing external‑index editions      |\n\n*Surfaces remain **conceptual** per **E.5.2**; RO‑Crate/ORKG/OpenAlex mappings belong to **Annex/Interop** and do not affect Core conformance.*\n",
        "conformance_checklist": "### G.10:6 - Conformance checklist (CC‑G10)\n\nThis pattern **inherits** order/illumination, evidence, and bridge/penalty legality from **CC‑G5**, **CC‑G6**, **CC‑G8**. Shipping‑specific requirements:\n\n1. **CC‑G10.1 (Notation‑independent).** The pack **MUST NOT** rely on any specific file syntax; **cards/tables are conceptual**; tool serialisations are informative only.\n2. **CC‑G10.2 (Pack parity pins).** If QD/OEE fields are present, **pin** `DescriptorMapRef.edition`, `DistanceDefRef.edition`, (OEE) `TransferRulesRef.edition`; include `CharacteristicSpaceRef.edition` where it affects partitioning reproducibility; for **QD archive semantics** also **pin `EmitterPolicyRef` and `InsertionPolicyRef`**. *(Informative alias: **ArchiveConfig** := {`CharacteristicSpaceRef`?, `DescriptorMapRef.edition`, `DistanceDefRef.edition`, `EmitterPolicyRef`, `InsertionPolicyRef`}.)*\n3. **CC‑G10.3 (Telemetry discipline).** Any **illumination increase** or archive edit **SHALL** log **PathSliceId**, active **policy‑id**, the active editions of the pinned `…Ref` fields (including OEE `TransferRulesRef.edition`), **and** the active **`EmitterPolicyRef`/`InsertionPolicyRef`**.\n4. **CC‑G10.4 (UTS publication & twins).** All shipped heads appear on **UTS** with **Tech/Plain twins**; cross‑Context identity travels **only by Bridges** with CL and loss notes.\n5. **CC‑G10.5 (MOO surfaced in shipping).** Method-of-obtaining-output surfacing: for every **Portfolio set** or **Archive** published, the pack **SHALL** list the applicable **generation/parity mechanism** ids (**EmitterPolicyRef/InsertionPolicyRef** for QD archives; **ParityHarnessId** for parity; **DHCMethodRef** where method definitions are generators) and the active **policy‑id(s)** in **SCR** and **telemetry pins**. (Core remains notationally independent.)\n",
        "relations": "### G.10:7 - Relations\n\n**Builds on:** G.1 (generator), **G.2** (SoTA Synthesis), **G.3–G.4** (CHR/CAL legality & acceptance), **G.5** (registry/selection), **G.6** (EvidenceGraph paths & PathSlice), **G.7** (Bridge/CL calibration), **G.8** (SoS‑LOG bundle & maturity ladder).\n**Publishes to:** **UTS**, **G.5** (parity surface), **SCR/RSCR**, **G.11** (refresh on telemetry).\n**Constrains:** any Tooling export; formats exist only in **Annex/Interop** (non‑normative).\n",
        "worked_micro‑sketch_(informative;_post‑2015_sota_families)": "### G.10:8 - Worked micro‑sketch (informative; post‑2015 SoTA families)\n\n**CG‑Frame:** *Decision‑making under constraints* (multi‑method portfolio).\n*Families registered:* Outranking/MCDA; Causal/SCM; BO; RL/Policy‑search; **QD‑RL** (*e.g.,* MAP‑Elites/CMA‑ME‑class); **OEE** task generator (POET‑class).\n**Shipping highlights.**\n(1) **Parity pins**: ComparatorSet cites `SafetyClass(ord)`, `CostUSD_2025(ratio)`, …; Γ‑fold = WLNK for assurance.\n(2) **Portfolio**: `DominanceRegime=ParetoOnly`, `PortfolioMode=Archive`, `ε=0.01`.\n(3) **QD**: `DescriptorMapRef.edition=DM‑v5`, `DistanceDefRef.edition=Δ‑Hamming‑v2`, `CharacteristicSpaceRef.edition=CS‑v3?`, \n    `EmitterPolicyRef=E/E‑LOG:budgeted‑explore`, `InsertionPolicyRef=replace_if_better@K=2`, \n    (`DHCMethodRef.edition?`, `DHCMethodSpecRef.edition?` when CHR‑based QD telemetry computations apply); \n    **IlluminationSummary** reported (triad Q/D/QD‑score), **not** used for dominance. \n(4) **OEE**: `EnvironmentValidityRegion=R&D‑bench v1`, `TransferRulesRef.edition=TFR‑v3`.\n(5) **Crossings**: `Bridge{Marketing→Engineering, CL=2}` with **loss note**; **Φ(CL)** and **Φ_plane** ids shown; **R‑only** penalty routing.\n(6) **Paths**: Shortlist decisions cite **PathIds**; rung upgrades attach PathIds; **PathSliceId** carried for the QD edition snapshot.\n(7) **Telemetry**: when coverage ↑ in archive cell (QD‑RL run), emit `Telemetry(PathSlice)` with **policy‑id** + editions; **G.11** schedules path‑local refresh. \n",
        "author’s_quick_checklist": "### G.10:9 - Author’s quick checklist\n\n1. **Pin parity.** Attach `ComparatorSetRef` + Γ‑fold; freeze `…Ref.edition` (QD/OEE).\n2. **Declare portfolio.** Set `DominanceRegime`/`PortfolioMode`/`ε`.\n3. **Route crossings.** List Bridges + **Φ/Ψ** policy‑ids; put loss notes on UTS.\n4. **Cite evidence.** Include A.10 anchors and any stable **PathIds**; ensure lanes and freshness windows are visible to **SCR**.\n5. **Crossing hooks (E.18).** Expose `CrossingRef` for every GateCrossing (BridgeCard + UTS row + `CL/Φ_plane` policy‑ids).\n   Shipping **blocks** on missing/non‑conformant crossings (**CrossingSurface**, E.18/A.27).\n6. **Telemetry stubs.** Log **PathSliceId** + **policy‑id** + **edition** fields for QD/OEE **and** the active **`EmitterPolicyRef`/`InsertionPolicyRef`**.\n7. **UTS & twins.** Publish Name Cards (Tech/Plain); keep **local‑first**; Bridges carry identity across.\n",
        "didactic_distillation_(90‑second_script)": "### G.10:10 - Didactic distillation (90‑second script)\n\n> *Ship thinking, not files.* A **SoTA‑Pack(Core)** is the **one place** where a discipline’s generated methods and portfolios are **ready to use**: parity‑pinned, path‑anchored, GateCrossing‑gated, and telemetry‑aware. It tells selectors **what order to use** and **which set to return**, auditors **which paths to cite**, and authors **which editions/policies** to repeat. Formats come later (Annex); **Core stays semantic and universal**.\n\n**Annex/Interop pointer (informative).** Serialisation recipes (e.g., RO‑Crate 1.2 profiles for UTS rows, PathSlice pins, Φ‑policy ids; ORKG/OpenAlex cross‑walks) live in **Part I** and are **non‑normative**. Core conformance is judged on **conceptual fields** and **obligations** alone.\n",
        "g.10:end": "### G.10:End\n"
      },
      "content": "### G.10:End\n",
      "metadata": {},
      "part": "G",
      "cluster": null
    },
    {
      "id": "G.11",
      "title": "Telemetry‑Driven Refresh & Decay Orchestrator",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## G.11 - Telemetry‑Driven Refresh & Decay Orchestrator\n\n**Tag.** Architectural pattern (architectural, notation‑independent; Core)\n**Stage.** *run‑time & maintenance‑time* (drives selective re‑computation and republication)\n**Primary hooks.** **G.6** (EvidenceGraph & Path/PathSlice ids), **G.7** (Bridge Sentinels, CL/Φ/plane), **G.5** (set‑returning selector), **G.8** (SoS‑LOGBundle; maturity ladder; QD/OEE pins), **G.10** (SoTA Pack shipping ↦ telemetry pins), **C.18/C.19** (QD/illumination; E/E‑LOG emitters), **C.23** (Method‑SoS‑LOG duties), **B.3.4** (evidence decay/epistemic debt), **E.18** (E.TGA GateCrossing hooks).       \n\n**Why this exists.** Earlier G‑patterns made SoTA packs lawful and selector‑ready; this pattern closes the loop by **turning telemetry and decay into concrete refresh actions** that (i) keep SoTA packs current without pack‑wide reruns, (ii) preserve lawful orders (set‑returning selection; no forced scalarisation), and (iii) make QD/OEE exploration **operational** (edition‑aware, policy‑tracked) rather than merely auditable.  \n\n**Refresh triggers (normative)**\nTreat the following as **refresh causes** (Path‑local where possible) and run **targeted RSCR** before republication:\n* **Illumination/archive deltas (QD).** Telemetry events carrying `PathSliceId`, active `policy‑id`, and editions of `DescriptorMapRef`/`DistanceDefRef` (**plus** `CharacteristicSpaceRef` when domain‑family coordinates are used).\n* **OEE transfer deltas.** Edition change in `TransferRulesRef` or update to `EnvironmentValidityRegion`.\n* **Legality surface edits.** Changes to **Γ‑fold** definitions, **UNM**/**NormalizationMethod(s)** declarations, or **Φ** tables/policies.\n* **Bridge calibration edits.** Bridge/BCT changes that affect **CL** or plane penalties.\n* **Dominance policy changes.** CAL policy‑id changes that promote telemetry metrics into dominance.\n\n**Modularity note.** G.11 is **purely conceptual** (E.5.2): it prescribes identifiers, triggers, and obligations—not file formats or tools. Any serialisation lives in Annex/Interop; Core conformance is judged on semantics only. \n",
        "intent": "### G.11:1 - Intent\n\nGiven **PathSlice‑keyed telemetry** and **evidence freshness windows**, G.11 plans and orchestrates **selective refresh** of affected artefacts (selector inputs, parity packs, dashboards), so that the same Core invariants hold: (a) returns sets under lawful orders (no scalarisation), (b) executes **edition‑aware** QD/OEE reruns **under the same laws** (dominance defaults, telemetry‑metric semantics), and (c) emits **DeprecationNotices** and **EditionBumpLog** while keeping **F/G invariants** and routing Bridge penalties to **R_eff only**.   \n",
        "problem": "### G.11:2 - Problem frame\n\nBlind “full rebuilds” and audit‑only workflows either waste compute or let **epistemic debt** accumulate. QD/OEE runs shift archives and coverage, but without **edition‑pinned** descriptors and policy ids, selectors and dashboards drift silently. Cross‑Context reuse changes (Bridges, CL, Φ/plane) are often handled ad hoc rather than as **sentinel‑driven, path‑local RSCR**. We need an orchestrator that **turns signals into scoped refresh**, maintaining lawful orders and **GateCrossing visibility (CrossingSurface)**.\n",
        "forces": "### G.11:3 - Forces\n\n* **No‑Free‑Lunch vs. stability.** The selector must **return sets** under partial orders; refresh must **not** smuggle in scalarisation. **Default `DominanceRegime = ParetoOnly`.** \n* **Telemetry vs. order.** **IlluminationSummary (Q/D/QD‑score)** informs exploration and dashboards as a **report-only telemetry**; it **does not** enter dominance unless CAL says so (policy‑id cited). \n* **Edition‑awareness.** QD/OEE parity requires pinned **`DescriptorMapRef.edition`**, **`DistanceDefRef.edition`**, **`InsertionPolicyRef`**, **`EmitterPolicyRef`**, and (for OEE) **`TransferRulesRef.edition`**.  \n* **Bridge hygiene.** CL/CL^k/CL^plane changes must trigger **path‑local** refresh; penalties route to **R_eff**; **ReferencePlane** is always declared. \n* **GateCrossing gates (E.18).** Crossings must remain visible via `CrossingRef` (BridgeCard + UTS row + `CL/Φ_plane` policy‑ids).\n",
        "solution": "### G.11:4 - Solution — **From telemetry to targeted recomputation**\n\n#### G.11:4.1 - Signals (what G.11 consumes)\n\n1. **PathSlice Telemetry.** Emitted by G.10/G.9/G.8: `⟨PathSliceId, policy‑id, DescriptorMapRef.edition, DistanceDefRef.edition, CharacteristicSpaceRef.edition?, EmitterPolicyRef?, InsertionPolicyRef?, TransferRulesRef.edition? (OEE), timeWindow⟩`.   \n2. **Bridge Sentinels.** Registered for each GateCrossing; any edit to **CL/CL^k/CL^plane** or Φ/Ψ policy ids raises a **path‑local** refresh event. \n3. **Freshness Windows & Decay.** KD‑CAL lanes carry **freshness**; when windows expire, **epistemic debt** rises and triggers **Refresh/Deprecate/Waive** governance. \n\n#### G.11:4.2 - Trigger catalogue (normative)\n\n* **T0 — Policy change (generation/parity).** A change in the active **policy‑id** for **Emitter/Insertion** (E/E‑LOG) or parity harness under fixed editions ⇒ schedule **slice‑scoped** recomputation for the affected portfolios/archives; do **not** alter dominance defaults.\n* **T1 — Illumination increase.** Δcoverage>0 or ΔQD‑score>0 under the active archive & grid. ⇒ schedule archive‑scoped recomputation; **do not** change dominance unless CAL policy promotes illumination (policy‑id cited to SCR).  \n* **T2 — Edition bump (QD).** Change in `DescriptorMapRef.edition` and/or `DistanceDefRef.edition` (and, when partition depends on Space phase, `CharacteristicSpaceRef.edition`). ⇒ recompute the **same** QD metrics under new editions; publish **EditionBumpLog**. \n* **T3 — Edition bump (OEE).** Change in `TransferRulesRef.edition` triggers re‑evaluation of `{environment, method}` portfolios; **coverage/regret remain telemetry metrics**. \n* **T4 — Bridge change.** Any update to CL/CL^k/CL^plane or Φ/Ψ policy ids on a crossing. ⇒ **path‑local RSCR** + refresh of affected selections; penalties route to **R_eff only**. \n* **T5 — Freshness expiry.** Any A.10 carrier behind a LOG decision or Acceptance gate passes `valid_until`. ⇒ schedule refresh per lane; may issue **DeprecationNotice** if budget exceeded. \n* **T6 — Maturity rung change.** A **C.23** rung justification (PathId) is upgraded/downgraded. ⇒ Rebind **AdmissibilityLedger** rows; update SoS‑LOGBundle edition; cite PathIds. \n* **T7 — Policy change.** CAL policy altering dominance set (e.g., illumination promotion) or Γ‑fold. ⇒ Re‑execute selection under new policy; record policy‑id in SCR; update the **Portfolio Pack** (per G.10), not a new surface term.\n\n#### G.11:4.3 - Planner (conceptual algorithm; minimal recomputation)\n\n```\nGiven: Telemetry events E, Bridge edits B, Freshness expiries F, Policy changes P\n1) Partition events by PathSliceId; compute dependency closure over EvidenceGraph (ancestors that change legality/lanes).\n2) For each slice S:\n   a) Enforce legality: CG‑Spec checks; refuse illegal ops; compute ReferencePlane/Φ_plane.\n   b) If S involves QD: pin editions; schedule Γ_nqd.{updateArchive,illuminate,selectFront}.\n   c) If S involves OEE: schedule portfolio recomputation over {environment, method} with GeneratorFamily parity.\n   d) If Bridges changed: run path‑local RSCR; recompute R_eff (F/G invariant).\n   e) If freshness expired: sample per-lane refresh; if budget limited, raise DeprecationNotice.\n3) Compose a **RefreshPlan@Context** with ordered actions and expected deltas; publish to UTS; execute and update **SCR/RSCR** only (DRR applies to normative edits, not run‑time refresh).\n```\n\n*Lawful orders.* The planner **never** forces total orders; **G.5** stays set‑returning. Coverage/illumination is handled as report‑only telemetry by default; **Illumination** remains a **telemetry metric** unless promoted via CAL policy.  \n\n#### G.11:4.4 - Outputs (selector‑ and audit‑facing)\n\n* **`RefreshPlan@Context` (UTS row; editioned).**\n  `⟨PlanId, PathSliceIds[], Triggers{T1..T7}, Actions{RecomputeSelection | UpdateArchive | RebindBridge | Re‑publishBundle | RebuildPortfolioSurface}, EditionPins{…Ref.edition}, PolicyPins{Φ/Ψ ids}, ExpectedTelemetry{IlluminationSummary, coverage, regret}, AffectedPortfolios{set|archive}, RSCRRefs[], Notes⟩`.\n*Execution results appear in* **`RefreshReport@Context`** (PathIds, **SCR/RSCR deltas**, EditionBumpLog ids). \n* **`EditionBumpLog`** and **`DeprecationNotice[]`** (UTS rows; contextual, lane‑aware). \n* **Telemetry echo.** Every illumination increase or OEE transfer records `PathSliceId`, **policy‑id**, and active editions (incl. `CharacteristicSpaceRef.edition` and `TransferRulesRef.edition`). For PathSlice‑pinned QD/OEE, surface `U.DescriptorMapRef.edition` / `U.DistanceDefRef.edition` to align with PathCard.\n",
        "interfaces_—_minimal_i/o_(conceptual;_core‑only)": "### G.11:5 - Interfaces — minimal I/O (conceptual; Core‑only)\n\n| ID                                 | Interface                                                                   | Consumes                                                                                                            | Produces |\n| ---------------------------------- | --------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------- | -------- |\n| **G.11‑1 `Ingest_Telemetry`**      | PathSlice telemetry; Bridge Sentinel events; freshness expiries             | `RefreshQueue` (slice‑keyed), annotated with Trigger kinds                                                          |          |\n| **G.11‑2 note**                    | Use **Portfolio Pack** / shipping artefacts from G.10; do not introduce new surface names.                         |                                                                                                                      |          |\n| **G.11‑3 `Execute_RefreshPlan`**   | `RefreshPlan@Context`                                                       | Updated portfolios (sets/archives), **SCR** deltas (policy‑id + PathIds), **EditionBumpLog**, **DeprecationNotice** |          |\n| **G.11‑4 `Publish_RefreshReport`** | Execution artefacts                                                         | `RefreshReport@Context` (UTS row) + PathId citations for C.23/H4                                                    |          |\n\n*Crossing visibility harness.* All crossings exposed via **CrossingSurface** (**E.18/A.27/F.9**) remain visible; publication **fails** if UTS+Bridge are missing, policy‑ids are unresolved, or lanes are impure.\n",
        "conformance_checklist": "### G.11:6 - Conformance Checklist (CC‑G11)\n\n1. **CC‑G11.1 (Scoped by PathSlice).** Every refresh is **slice‑scoped**; pack‑wide reruns are prohibited unless the dependency closure spans all slices (record rationale). \n2. **CC‑G11.2 (Edition discipline).** When QD/OEE are active, **pin** and **echo**: `DescriptorMapRef.edition`, `DistanceDefRef.edition`, **`CharacteristicSpaceRef.edition` whenever a domain‑family coordinate is declared per C18‑1b**, `EmitterPolicyRef`, `InsertionPolicyRef`, `TransferRulesRef.edition` (OEE). **`.edition` SHALL apply only on `…Ref`**. **Fail** if any required pin is missing.  \n3. **CC‑G11.3 (Telemetry‑metric legality).** Publish **Q/D/QD‑score** as telemetry metrics and **IlluminationSummary** as a telemetry summary; **exclude from dominance** unless a CAL policy promotes them; record the **policy‑id** in SCR.  \n4. **CC‑G11.4 (Bridge penalties).** CL/CL^k/CL^plane penalties **route to R_eff only**; **F/G invariant**; publish **Φ/Ψ ids** with loss notes. \n5. **CC‑G11.5 (Selector invariants).** **G.5** is called with the same lawful **ComparatorSet** and returns **sets** (Pareto/Archive); no scalarisation is introduced by refresh. \n6. **CC‑G11.6 (Crossing visibility).** All GateCrossings **MUST** satisfy E.18 (`CrossingRef` + BridgeCard+UTS + `CL/Φ_plane` policy‑ids);\n   missing crossings block publication.\n7. **CC‑G11.7 (Decay governance).** Freshness expiry triggers **Refresh/Deprecate/Waive** with budget notes; decisions appear in **DeprecationNotice** and SCR. \n",
        "anti‑patterns_&_remedies": "### G.11:7 - Anti‑patterns & remedies\n\n* **Full‑rerun mania.** Rebuilding everything on minor Bridge edits. → **PathSlice‑scoped** RSCR + refresh; document slice closure. \n* **Editionless QD.** Comparing QD outcomes across space/distance changes without editions. → **Pin editions**; re‑illuminate; log **EditionBump**. \n* **Illumination scalarisation.** Using illumination to alter dominance by default. → Keep as **report‑only telemetry**; require **CAL policy id** to promote. \n* **Bridge blindness.** Ignoring CL^plane at world↔concept↔episteme crossings. → Compute **Φ_plane**; penalties to **R_eff**; cite ids. \n* **Telemetry gaps.** Emitting coverage gain without policy‑id/editions. → Refuse; **G.11‑2** MUST fail the plan until telemetry is complete. \n",
        "consequences": "### G.11:8 - Consequences\n\n* **Selective, edition‑aware upkeep.** Minimal recomputation with **auditable** triggers and **policy‑pinned** context. \n* **Operational QD/OEE.** Illumination and open‑ended exploration inform **refresh**, not dominance, unless explicitly authorised. \n* **Downstream cleanliness.** Selectors and dashboards consume **updated sets** with lawful orders and **Φ** ids; DHC metrics can be charted with declared windows/units. \n",
        "worked_micro‑sketches_(informative;_sota‑oriented)": "### G.11:9 - Worked micro‑sketches (informative; SoTA‑oriented)\n\n* **QD Portfolio (MAP‑Elites / CMA‑ME / DQD / QDax‑class).** A run increases coverage in several cells. Telemetry logs `PathSliceId`, `EmitterPolicyRef`, `InsertionPolicyRef`, editions for `DescriptorMapRef`/`DistanceDefRef`. **G.11** plans an **Archive** refresh only for affected slices; selector returns the **archive set**; **IlluminationSummary** is reported (Q/D/QD‑score) and **excluded from dominance** (default). \n* **OEE Portfolio (POET/Enhanced‑POET/DGM‑class).** `TransferRulesRef.edition` bumps; telemetry cites `EnvironmentValidityRegion`. **G.11** schedules recomputation of `{environment, method}` portfolios; **coverage/regret** reported as telemetry metrics; selector returns a **set of pairs**; CAL policies unchanged. \n",
        "relations": "### G.11:10 - Relations\n\n**Builds on:** **G.6** (PathId/PathSlice), **G.7** (Bridge Sentinels & calibration), **G.8** (bundles; maturity), **G.9** (parity scaffolding & edition pins), **C.18/C.19** (QD & E/E‑LOG), **C.23** (SoS‑LOG), **B.3.4** (decay), **E.18** (GateCrossing).\n**Consumes:** Telemetry pins from **G.10/G.9**; Edition pins and policy ids from **G.5/G.8**.\n**Publishes to:** **UTS** (RefreshPlan/Report; EditionBumpLog; DeprecationNotice), **SCR/RSCR** (path‑local checks), **G.12** (discipline dashboards).  \n",
        "author’s_quick_checklist": "### G.11:11 - Author’s quick checklist\n\n1. **Collect pins.** Ensure telemetry includes `PathSliceId`, **policy‑id**, and all required `…Ref.edition` fields (QD/OEE). For PathSlice‑pinned QD/OEE, expose `U.DescriptorMapRef.edition` / `U.DistanceDefRef.edition` in line with PathCard.\n2. **Scope to slices.** Build the **minimal** dependency closure over EvidenceGraph; avoid pack‑wide reruns. \n3. **Re‑select lawfully.** Call **G.5** with unchanged ComparatorSet; **return sets** (Pareto/Archive). \n4. **Respect telemetry metrics.** Publish **Q/D/QD‑score** and any coverage/regret as **telemetry metrics**; do **not** alter dominance unless CAL policy id promotes. \n5. **Bridge routing.** If CL/plane changed, re‑compute **R_eff**; **F/G invariant**; cite **Φ/Ψ ids**. \n6. **Decay actions.** When freshness expires, choose **Refresh/Deprecate/Waive**; publish notices; update SCR/DRR. \n7. **GateCrossing pass.** Keep `Expose_CrossingHooks` outputs visible; block publication on missing/non‑conformant **CrossingSurface** (E.18/A.27/F.9). Do not emit DRR from run‑time refresh; use DRR only for normative Core edits (E.9).\n",
        "didactic_distillation_(60‑second_script)": "### G.11:12 - Didactic distillation (60‑second script)\n\n> *Refresh thinking, not just files.* **G.11** listens to **telemetry** and **decay**, finds the **smallest PathSlices** that matter, and **re‑runs only those**—with **editions and policies pinned** so parity holds. It never changes your order defaults: the selector still **returns sets**, and illumination remains a **telemetry metric** unless you *explicitly* promote it. The result is SoTA that **stays SoTA**—auditable, edition‑aware, and cost‑aware.  \n",
        "g.11:end": "### G.11:End\n"
      },
      "content": "### G.11:End\n",
      "metadata": {},
      "part": "G",
      "cluster": null
    },
    {
      "id": "G.12",
      "title": "DHC Dashboards - Discipline‑Health Time‑Series (lawful telemetry, generation‑first)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## G.12 - DHC Dashboards - Discipline‑Health Time‑Series (lawful telemetry, generation‑first)\n\n**Stage.** *design‑time authoring* → *run‑time computation & publication* (dashboard series)\n**Primary hooks.** **C.21 Discipline‑CHR** (what to measure), **G.2** (SoTA palette & **DHC‑SenseCells**), **G.5** (selector; set‑returning portfolios), **G.6** (EvidenceGraph & PathId/PathSlice), **G.8** (SoS‑LOG bundle & maturity ladders), **G.10** (SoTA‑Pack shipping & telemetry stubs), **G.11** (telemetry‑driven refresh/decay), **C.18/C.19** (Illumination/QD; E/E‑LOG), **C.23** (SoS‑LOG duties), **F.17/F.18** (UTS & twin labels), **E.5.2** (notation independence).\n**Why this exists.** **C.21** defines lawful *slots* for discipline health (DHC) but not a SoTA method to *produce* dashboard time‑series. **G.12** provides that method: a disciplined, edition‑aware pipeline that computes DHC values from evidence paths, selector outputs, and QD/OEE telemetry (IlluminationSummary + coverage/regret)—without illicit scalarisation, without averaging ordinals, and with telemetry that keeps dashboards fresh via **G.11**. This operationalizes the “coordinates with G.12” promise in **C.21**. \n**Modularity note.** G.12 consumes CHR/CAL/LOG artefacts and emits UTS‑published dashboard rows; formats (e.g., RO‑Crate/ORKG/OpenAlex) remain Annex/Interop and do **not** affect Core conformance (per **G.10**, **E.5.2**). \n",
        "intent": "### G.12:1 - Intent\n\nTurn **discipline‑health definitions** (C.21) into a **lawful, reproducible, refresh‑aware dashboard series** that:\n(i) reads **evidence** by **PathId/PathSlice** (C.21↔G.6), (ii) folds values only where **CG‑Spec** allows (units/scale/polarity proved), (iii) exposes **freshness windows** and **ReferencePlane** explicitly, (iv) uses **selector outputs** as *sets* (Pareto/Archive) rather than forcing total orders, and (v) treats **Illumination/QD** as **report‑only telemetry** by default (promotion into dominance only via explicit CAL **policy‑id** recorded in SCR).  \n",
        "problem": "### G.12:2 - Problem frame\n\nTeams publish “field health” numbers with mixed scales, hidden re‑parameterisations, and cross‑Context roll‑ups that violate Γ‑fold/Bridge discipline. Ordinal quantities (e.g., standardisation stages) get averaged; QD/coverage signals are smuggled into dominance. No one pins **editions** of descriptor spaces or distances, so dashboards silently drift. We need a **generation‑first** pattern that computes DHC time‑series **legally** and **refreshes selectively** when telemetry indicates illumination/edition changes or decay.  \n",
        "forces": "### G.12:3 - Forces\n\n* **Assurance vs. results.** Dashboards must *increase the chance of good results*, not only audit them; legality remains visible. \n* **No‑Free‑Lunch.** Selection returns **sets** under partial orders; dashboards must respect this and never coerce to totals. \n* **Telemetry vs. order.** **IlluminationSummary** (*Q/D/QD‑score*) is a **telemetry summary**; coverage/regret are **telemetry metrics**. None affect dominance unless a CAL **policy‑id** explicitly promotes them (recorded in SCR). \n* **Edition‑awareness.** QD/OEE parity requires **`.edition` on …Ref** for spaces/distances/transfer rules; telemetry must carry **policy‑id** and **PathSliceId** so G.11 can refresh slices, not packs.  \n* **Bridge hygiene & planes.** Cross‑Context/plane comparisons cite **Bridge id + CL** and **Φ/Φ_plane**; penalties reduce **R_eff** only. \n",
        "solution": "### G.12:4 - Solution — *Author C.21 once; compute & publish DHC series lawfully and refresh‑aware*\n\n#### G.12:4.1 - Objects (LEX heads; twin‑register discipline)\n\n* **`DHCSeries@Context`** — the UTS‑published time‑series object for a discipline’s dashboard (editioned).\n* **`DHCSlot`** — a typed slot authored via **C.21** (`Characteristic`, `Scale/Unit/Polarity`, `ReferencePlane`, `Γ_time`, lane tags). **No arithmetic** is permitted until CSLC legality is proved. \n* **`DHCMethodRef` / `DHCMethodSpecRef`** — edition‑pinned references to the method/definition used to compute a slot value (table‑backed registry). \n* **`EditionPins`** — `{ DHCMethodRef.edition, DHCMethodSpecRef.edition, DistanceDefRef.edition, DescriptorMapRef.edition?, CharacteristicSpaceRef.edition?, TransferRulesRef.edition? }` captured per row. \n* **Naming discipline.** Tech register uses **`U.DescriptorMapRef (d≥2)`** for QD spaces; Plain twin is **`CharacteristicSpaceRef`**; **aliasing is forbidden** and **`.edition` SHALL appear only on `…Ref`** per **E.10 §6.2** (see also G.9/G.7 twin‑naming notes). \n\n#### G.12:4.2 - Method‑of‑Obtaining (SoTA, generation‑first; design‑time → run‑time)\n\n**Stage A — Author & Bind (design‑time)**\nA1. **Author slots via C.21.** For each DHC slot (e.g., *ReproducibilityRate*, *StandardisationLevel*, *AlignmentDensity*, *DisruptionBalance*, *EvidenceGranularity*, *MetaDiversity*), bind CHR characteristics, scales/units, lanes, `Γ_time`, and **ReferencePlane**; declare **TargetSlice (USM)** and scope; record **compare‑only** for ordinals. \nA2. **Attach CG‑Spec and Proof stubs.** Cite **CG‑Spec** ids for any numeric comparisons/aggregations; prove CSLC legality/compliance and declare Γ‑fold (WLNK unless justified). **Where Bridges/planes are involved, the penalty policies `Φ(CL)`, `Φ_plane` (and `Ψ` for Kind‑bridges) MUST be *monotone, bounded, and table‑backed* (record policy‑ids).**\nA3. **Pin methods.** Register `DHCMethodSpecRef` and its `DHCMethodRef` for each slot; edition‑pin both for parity & RSCR. \nA4. **Declare QD/OEE hooks (if used).** Name `DescriptorMapRef`/`DistanceDefRef` (+ editions), `EmitterPolicyRef`, `InsertionPolicyRef`; for OEE, register `GeneratorFamily` with `EnvironmentValidityRegion` and `TransferRulesRef.edition`. **IlluminationSummary remains a telemetry summary by default** (see **DominanceRegime ∈ {ParetoOnly, ParetoPlusIllumination}**).\n\n**Stage B — Compute (run‑time, lawful telemetry)**\nB1. **Harvest evidence** by **PathId/PathSlice**, preserving lanes (TA/VA/LA) and freshness windows (Γ_time). \nB2. **Compute per‑slot values** using the *edition‑pinned* `DHCMethodRef` and, where relevant, `DistanceDefRef`. per‑slot values** using the *edition‑pinned* `DHCMethodRef` and, where relevant, `DistanceDefRef`.\n • *ReproducibilityRate (LA lane).* Ratio under declared Γ_time with minimal evidence; abstain/degrade on missingness.\n • *StandardisationLevel (ordinal).* Publish **compare‑only**; forbid means/z‑scores.\n • *AlignmentDensity.* Count Bridges with **CL≥2** per **100 DHC‑SenseCells**; units = `bridges_per_100_DHC_SenseCells`; treat **CL=3** as *free substitution*, **CL=2** as *guarded* (counted with loss notes). Cite Bridge ids + policy‑ids; penalties → **R_eff** only.\n • *DisruptionBalance.* Compute with a **registered CD‑index class** (edition‑pinned) and publish *target bands*; **not** monotone “more is better.”\n • *EvidenceGranularity*/*MetaDiversity.* Compute as declared (entropy/HHI); record units and windows.\nAll numeric ops must cite **CG‑Spec**; cross‑Context values move only via Bridges with CL and loss notes. \nB3. **Integrate selector outputs (sets).** When a DHC slot depends on method performance trade‑offs (e.g., portfolio coverage), call **G.5.Select** and **return sets** (Pareto/Archive); never force totals. Publish **`DominanceRegime ∈ {ParetoOnly, ParetoPlusIllumination}`** and **`PortfolioMode ∈ {Pareto|Archive}`** (defaults: `ParetoOnly`, `Pareto`). \nB4. **Treat QD/OEE signals as report‑only telemetry.** If illumination is active, publish **IlluminationSummary (Q/D/QD‑score)** and **Archive** snapshot; if OEE is active, publish coverage/regret per `{Environment, MethodFamily}` as **telemetry metrics**. **Exclude from dominance** unless an explicit CAL **policy‑id** promotes them (**policy‑id recorded in SCR**). Echo **edition pins** and the active **policy‑id** in SCR.  \n\n**Stage C — Publish & Wire for refresh (run‑time, publication)**\nC1. **Publish DHC rows to UTS** with **twin labels** (Tech/Plain), slots’ *ReferencePlane*, lane tags, windows, and **EditionPins**. \nC2. **Cite paths.** Each row lists contributing **EvidenceGraph PathId(s)**/**PathSliceId**; Bridge ids and **Φ(CL)**/**Φ_plane** (and **Ψ** if Kind‑Bridge) appear in SCR with loss notes; penalties route to **R_eff only**; **Φ/Ψ policies are *monotone, bounded, table‑backed***. \nC3. **Emit telemetry for G.11.** On any **illumination increase** or edition bump (space/distance/transfer‑rules), record `PathSliceId` + **policy‑id** + active editions so **G.11** plans **slice‑scoped** refresh.  \n\n> **SoTA note (informative).** Typical QD/OEE families include **MAP‑Elites/CVT‑ME, CMA‑ME/MAE, DQD/MEGA, QDax (JMLR 2024)** for illumination and **POET/Enhanced‑POET** with **Darwin Gödel Machine (2025)**‑class variants for open‑ended generation. These are registered as `MethodFamily`/`GeneratorFamily` entries and consumed via **G.5**/**C.23** with **IlluminationSummary** reported as a **telemetry summary**. (Default: *not in dominance*.) \n",
        "interfaces_—_minimal_i/o_(conceptual;_core‑only)": "### G.12:5 - Interfaces — minimal I/O (conceptual; Core‑only)\n\n| ID                                     | Interface                                                                                                  | Consumes                                                                                                 | Produces                                                                                    |\n| -------------------------------------- | ---------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------- |\n| **G.12‑1 `Build_DHCSeries`**           | C.21 slot specs, CG‑Spec ids, `DHCMethod*Ref`, windows, ScopeSlice                                         | `DHCSeries@Context` (UTS row; editioned; lanes/windows/planes surfaced)                                  |                                                                                             |\n| **G.12‑2 `Compute_DHCRow`**            | EvidenceGraph **PathId/PathSlice**, Bridges(+CL/Φ/plane), `DistanceDefRef.edition`, `DHCMethodRef.edition` | `(slot_id, value, compare‑only?, units/scale, stance, window, PathIds[], BridgeIds[], Φ/Φ_plane ids, EditionPins)` |\n| **G.12‑3 `Integrate_PortfolioTelemetry`** | `SoTA‑Pack(Core)` parity pins, G.5 outputs, QD/OEE telemetry                                               | `IlluminationSummary`, Archive snapshot, `{Environment,MethodFamily}` coverage/regret telemetry metrics (SCR‑cited) |                                                                                             |\n| **G.12‑4 `Publish_DashboardSlice`**    | Rows from G.12‑2/‑3                                                                                        | UTS Name Cards (Tech/Plain twins); SCR notes (policy‑ids; planes; penalties→R_eff)                       |                                                                                             |\n| **G.12‑5 `Emit_TelemetryPins`**        | Illumination increase, edition bump, transfer events                                                       | PathSlice‑keyed telemetry (`policy‑id`, `…Ref.edition`) for **G.11** refresh plan                        |                                                                                             |\n\n(*Do not introduce file formats; surfaces are conceptual. Serialisation recipes live in Annex/Interop.*) \n",
        "conformance_checklist": "### G.12:6 - Conformance Checklist (CC‑G12, normative)\n\n1. **C.21 compliance.** Every dashboard row traces to a **C.21‑authored DHC slot** with **Characteristic + Scale/Unit/Polarity**, lane tags, **Γ_time**, stance, and **ReferencePlane** declared. **No arithmetic** proceeds without CSLC legality. \n2. **Ordinal discipline.** Ordinal slots (e.g., *StandardisationLevel*) are **compare‑only**; **no means/z‑scores**. \n3. **CG‑Spec citation.** All numeric operations cite **CG‑Spec** characteristics, **ScaleComplianceProfile (SCP)**, **Γ‑fold**, and MinimalEvidence; **UNM**/**NormalizationMethod(s)** are explicit (“normalize, then compare”). \n4. **Set‑returning selection.** When invoking **G.5**, **return sets** (Pareto/Archive); **default `DominanceRegime = ParetoOnly`**; any promotion of Illumination into dominance **MUST** cite CAL **policy‑id** in SCR.  \n5. **Edition discipline.** Pin `DHCMethodRef.edition`, `DHCMethodSpecRef.edition`, `DistanceDefRef.edition`, and—if QD/OEE—`DescriptorMapRef.edition` / `CharacteristicSpaceRef.edition?` / `EmitterPolicyRef` / `InsertionPolicyRef` / `TransferRulesRef.edition`. **`.edition` SHALL appear only on `…Ref`.**  \n6. **Bridge routing & planes.** Cross‑Context/plane rows **MUST** cite **Bridge id + CL** and **Φ(CL)**/**Φ_plane**; penalties route to **R_eff** only; **F/G invariant**; **Φ/Ψ policies SHALL be monotone, bounded, and table‑backed** (ids recorded). \n7. **Telemetry sufficiency.** Any illumination increase or OEE transfer **MUST** log `PathSliceId`, **policy‑id**, and active editions; missing pins **block publication** until remedied. \n8. **UTS publication & twins.** Publish dashboard rows as **UTS Name Cards** with **Tech/Plain twins**; identity travels via Bridges with loss notes. \n",
        "bias‑annotation_(e‑cluster_lenses)": "### G.12:7 - Bias‑Annotation (E‑cluster lenses)\n\n* **Didactic.** One‑screen tables; plain names + twin labels.\n* **Architectural.** No ordinals averaged; penalties never touch F/G; planes explicit. \n* **Pragmatic.** Freshness‑aware; unknowns tri‑state; telemetry‑driven refresh. \n* **Epistemic.** Evidence lanes & PathIds explicit; maturity rungs ordinal; illumination is report‑only telemetry by default. \n",
        "consequences": "### G.12:8 - Consequences\n\n* **Generation‑first dashboards.** Authors publish *how values are produced* (methods, editions, paths), not just thresholds; selectors and dashboards stay lawful by construction. \n* **Selective, edition‑aware upkeep.** Telemetry makes **G.11** refresh **slice‑scoped**, preventing drift without pack‑wide reruns. \n* **Plurality preserved.** Set‑returning selection + Bridge hygiene avoids phlogiston‑like “trans‑disciplines” and illicit scalarisation. \n",
        "relations": "### G.12:9 - Relations\n\n**Builds on:** **C.21** (DHC), **G.6** (PathId/PathSlice), **G.8** (SoS‑LOGBundle), **G.10** (SoTA‑Pack shipping), **G.11** (refresh), **C.18/C.19** (QD/E‑E), **C.23** (SoS‑LOG). **Coordinates with:** **G.5** (selector returns sets; parity pins), **F.17/F.18** (UTS/twins). **Constrains:** dashboard consumers: illumination is **report-only telemetry** by default; cross‑Context use must publish **Φ** ids; planes explicit.   \n**Builds on:** **C.21** (DHC), **G.6** (PathId/PathSlice), **G.8** (SoS‑LOGBundle), **G.10** (SoTA‑Pack shipping), **G.11** (refresh), **C.18/C.19** (QD/E‑E), **C.23** (SoS‑LOG). **Coordinates with:** **G.5** (selector returns sets; parity pins), **F.17/F.18** (UTS/twins). **Constrains:** dashboard consumers: illumination is **report‑only telemetry** by default; cross‑Context use must publish **Φ** ids; planes explicit.   \n",
        "author’s_quick_checklist": "### G.12:10 - Author’s quick checklist\n\n1. Bind each slot via **C.21** (CHR + CG‑Spec + Γ_time + ReferencePlane + stance + lanes). \n2. Register and **pin** `DHCMethodSpecRef`/`DHCMethodRef` and any `DistanceDefRef`. \n3. If QD/OEE active, declare `DescriptorMapRef`/`CharacteristicSpaceRef?`/`Emitter`/`Insertion`/(OEE) `TransferRulesRef` editions; **IlluminationSummary** stays a **telemetry summary** (report‑only by default). \n4. Harvest **PathIds/PathSliceIds** and compute values; forbid ordinal means; cite Bridges + **Φ/Φ_plane**; penalties→**R_eff**. \n5. Publish to **UTS** (twins), attach SCR notes (policy‑ids, planes, edition pins). \n6. Emit telemetry on illumination increase/edition bumps for **G.11**. \n",
        "worked_micro‑examples_(informative;_sota‑oriented)": "### G.12:11 - Worked micro‑examples (informative; SoTA‑oriented)\n\n**(A) Decision‑making discipline (multi‑tradition).**\nSlots: *ReproducibilityRate* (LA, Γ_time=3y), *StandardisationLevel* (ordinal), *AlignmentDensity* (Bridges CL≥2 across EU/MCDA, SCM/DoWhy, RL/Decision‑Transformer), *DisruptionBalance* (DI‑class, target band), *MetaDiversity* (HHI of operator families). QD annex: Descriptor space = `U.DescriptorMapRef (d≥2)`, Archive (MAP‑Elites/CMA‑ME/DQD), **IlluminationSummary** reported with `{DescriptorMapRef.edition, DistanceDefRef.edition}`; OEE annex: POET‑class `GeneratorFamily` with `EnvironmentValidityRegion` and `TransferRulesRef.edition`. **IlluminationSummary** is a **telemetry summary**; coverage/regret are **report‑only telemetry**; selection returns **Pareto/Archive** sets.  \nSlots: *ReproducibilityRate* (LA, Γ_time=3y), *StandardisationLevel* (ordinal), *AlignmentDensity* (Bridges CL≥2 across EU/MCDA, SCM/DoWhy, RL/Decision‑Transformer), *DisruptionBalance* (DI‑class, target band), *MetaDiversity* (HHI of operator families). QD annex: Descriptor space = `U.DescriptorMapRef (d≥2)`, Archive (MAP‑Elites/CMA‑ME/DQD), **IlluminationSummary** reported with `{DescriptorMapRef.edition, DistanceDefRef.edition}`; OEE annex: POET‑class `GeneratorFamily` with `EnvironmentValidityRegion` and `TransferRulesRef.edition`. IlluminationSummary (telemetry summary) and coverage/regret (telemetry metrics) are **report‑only telemetry**; selection returns **Pareto/Archive** sets.  \n\n**(B) Evolutionary software architecture.**\nSlots: *ReproducibilityRate* (LA, Γ_time=3y), *StandardisationLevel* (ordinal), *AlignmentDensity* (Bridges CL≥2 across EU/MCDA, SCM/DoWhy, RL/Decision‑Transformer; units `bridges_per_100_DHC_SenseCells`), *DisruptionBalance* (**CD‑index class**, target band), *MetaDiversity* (HHI of operator families). QD annex: Descriptor space = `U.DescriptorMapRef (d≥2)`, Archive (MAP‑Elites/CMA‑ME/DQD), **IlluminationSummary** reported with `{DescriptorMapRef.edition, DistanceDefRef.edition}`; OEE annex: POET‑class `GeneratorFamily` with `EnvironmentValidityRegion` and `TransferRulesRef.edition`. **IlluminationSummary** is a **telemetry summary**; coverage/regret are **report‑only telemetry**; selection returns **Pareto/Archive** sets.  \nSlots: *ReproducibilityRate* (LA, Γ_time=3y), *StandardisationLevel* (ordinal), *AlignmentDensity* (Bridges CL≥2 across EU/MCDA, SCM/DoWhy, RL/Decision‑Transformer; units `bridges_per_100_DHC_SenseCells`), *DisruptionBalance* (**CD‑index class**, target band), *MetaDiversity* (HHI of operator families). QD annex: Descriptor space = `U.DescriptorMapRef (d≥2)`, Archive (MAP‑Elites/CMA‑ME/DQD), **IlluminationSummary** reported with `{DescriptorMapRef.edition, DistanceDefRef.edition}`; OEE annex: POET‑class `GeneratorFamily` with `EnvironmentValidityRegion` and `TransferRulesRef.edition`. IlluminationSummary (telemetry summary) and coverage/regret (telemetry metrics) are **report‑only telemetry**; selection returns **Pareto/Archive** sets.  \n",
        "g.12:end": "### G.12:End\n"
      },
      "content": "### G.12:End\n",
      "metadata": {},
      "part": "G",
      "cluster": null
    },
    {
      "id": "G.13",
      "title": "External Interop Hooks for SoTA Discipline Packs (conceptual)",
      "status": "Stable",
      "keywords": [],
      "search_queries": [],
      "dependencies": {},
      "sections": {
        "header": "## G.13 - External Interop Hooks for SoTA Discipline Packs (conceptual)\n\n**Tag.** informative pattern (informative, conceptual hooks; no file formats mandated)\n**Stage.** *design‑time mapping* → *run‑time ingestion & refresh*\n**Primary hooks.** **G.2** (SoTA harvester), **G.5** (set‑returning selector & registries), **G.6** (EvidenceGraph & PathId/PathSlice), **G.7** (Bridge Matrix & CL/planes), **G.8** (SoS‑LOG bundles), **G.9** (parity harness), **G.10** (SoTA‑Pack shipping), **G.11** (telemetry‑driven refresh), **G.12** (DHC dashboards), **C.21** (Discipline‑CHR), **C.23** (Method‑SoS‑LOG), **E.5.2** (notation independence), **E.18/A.21/A.27** (GateCrossing/CrossingSurface checks).   \n",
        "problem": "### G.13:2 - Problem\n\nExternal indexes publish **claim‑adjacent signals** (citations, disruption, replication, dataset links, task taxonomies). These signals are valuable for SoTA **generation** (not only audit), but:\n\n* **Comparability risk.** Units/scales vary; ordinal signals are routinely averaged; plane crossings (world↔concept↔episteme) are implicit. (FPF forbids ordinal averages; penalties from plane or context crossings must route to **R_eff** only.)  \n* **Edition drift.** Index snapshots change, silently breaking QD/OEE parity and dashboards unless **editions** and **policy‑ids** are pinned in telemetry. \n* **Assurance overreach.** Without a method to *produce* outputs, teams over‑invest in checks. FPF needs **generation‑first** interop that feeds selector portfolios, SoS‑LOG maturity, and DHC dashboard rows. \n",
        "forces": "### G.13:3 - Forces\n\n| Force                     | Tension                                                                                                                       |\n| ------------------------- | ----------------------------------------------------------------------------------------------------------------------------- |\n| **Notation independence** | Helpful serialisations (RO‑Crate, ORKG, OpenAlex) vs **Core conceptual** surfaces only.                                       |\n| **Pluralism vs parity**   | Diverse scholarly traditions vs lawful, edition‑aware comparison; **return sets** under partial orders.                       |\n| **Telemetry vs dominance**    | Illumination/coverage inform exploration but **do not** change dominance unless CAL policy says so.                           |\n| **Planes & bridges**      | Cross‑plane/context reuse must publish **Φ(CL)** and **Φ_plane** ids; losses touch **R** only.                                |\n| **OEE/QD parity**         | Generator families (POET‑class, DGM‑class) require **TransferRulesRef.edition**, environment validity, and coverage telemetry metrics.   |\n",
        "solution": "### G.13:4 - Solution — *Conceptual mappers + telemetry that drive generation, not just audit*\n\n#### G.13:4.1 - Objects (LEX heads; twin‑register discipline)\n\n* **`ExternalIndexCard@Context`** — conceptual registration of an external index/snapshot:\n  `⟨IndexId, ProviderName, Edition (date/commit), CoverageScope, Licence, describedEntity := ⟨GroundingHolon, ReferencePlane⟩, FreshnessWindow, Notes⟩`.\n  *Edition lives on the **Card**, and is cited by downstream mappers and telemetry.*\n\n* **`ClaimMapperCard@Context`** — executable *conceptual* mapping (no file syntax) from index entities to FPF artefacts:\n  `⟨MapperId, Source[IndexId], Targets{ClaimSheet|BridgeHints|SoS-LOG hints}, PlaneMap(world|concept|episteme), ScaleEmbeddingSpec (for scale/unit/space embeddings), EvidenceGraphRef(A.10), CSLC Proof Stubs, Edition⟩`.\n  *PlaneMap and ScaleEmbeddingSpec define lawful embeddings; Bridge generation is **not** automatic — crossings publish **Φ**/**Ψ** policy‑ids and **CL/CL^k** as applicable (monotone, bounded, table‑backed).*  \n\n  * **Name Card (F.18; MintNew).**\n    * **Tech label:** `ScaleEmbeddingSpec`\n    * **Plain label:** scale embedding specification\n    * **Kind:** `Spec` (S‑layer; mapper embedding constraints)\n    * **Purpose:** constrain admissible UNM/NormalizationMethod embeddings when aligning scale/unit/space before comparison or scoring.\n    * **Migration note:** this Core spec keeps no legacy aliases; see **DRR‑LEX‑2025‑12‑SCALE‑EMBEDDING** for external mapping notes.\n\n* **`SoSFeatureTransform@Context`** — turns mapped claims into **CHR‑typed** SoS features (e.g., disruption, replication coverage, standardisation rate), each bound to **CG‑Spec** characteristics with declared **Scale kind, units, polarity, ReferencePlane**. \n\n*Any numeric operation **MUST** be CSLC‑legal; ordinal measures are compare‑only; units are aligned per CG‑Spec; no ordinal→cardinal promotion.*\n\n* **`IndexTelemetryPin`** — edition bump or policy change signal (notation‑independent):\n  `⟨IndexId, Edition, PathSliceId?, policy‑id?, When⟩` routed to **G.11** for slice‑scoped refresh. \n\n*Edition fields **SHALL** appear **only** on `…Ref` objects when references are present (cf. CC‑G10/CC‑G12); parity pins echo active editions and policy‑ids.*\n\n* **`InteropSurface@Context`** — selector‑ and dashboard‑facing summary: what has been mapped, from which index edition, with which plane/scale embedding specs (published on UTS; twins Tech/Plain). \n\n#### G.13:4.2 - Generation‑first interop flow (notation‑independent)\n\n1. **Register sources.** Author **ExternalIndexCard**(s) with editions & freshness windows; declare describedEntityPlane. \n2. **Map claims.** Run **ClaimMapperCard** to produce **ClaimSheets** (e.g., problem/task taxonomies, method assertions, dataset links) and **BridgeHints** (candidate context crossings with loss notes). Plane crossings publish **Φ_plane** alongside **Φ(CL)**; penalties route to **R_eff** only. \n3. **Type as SoS features.** Apply **SoSFeatureTransform** to bind mapped signals to **CG‑Spec** characteristics (scale legality via CSLC proofs), producing lawful SoS inputs for **C.21** DHC slots and **C.23** maturity rules.  \n4. **Feed generation.**\n\n   * **G.2** harvests *competing Traditions* plus mapped SoS features to build SoTA palettes and **Bridge Matrices**;\n   * **G.5** registers **MethodFamily/GeneratorFamily** entries and, on selection, **returns sets (Pareto/Archive)** with **DRR+SCR** and portfolios, never forcing totals;\n   * **G.9** executes parity under equal windows/editions; **IlluminationSummary**, coverage, regret are **report‑only telemetry** by default.  \n5. **Publish & ship.** **G.8** bundles SoS‑LOG rules and **MaturityCard** (ordinal; thresholds stay in Acceptance), and **G.10** composes SoTA Packs with telemetry pins — still **conceptual** surfaces (Annex handles RO‑Crate/ORKG/OpenAlex).  \n6. **Refresh by telemetry.** Index edition bumps emit **IndexTelemetryPin**. **G.11** plans **slice‑scoped** refresh, respecting **DominanceRegime = ParetoOnly** and keeping illumination as **report‑only telemetry** unless CAL promotes it (policy‑id in SCR). **Φ/Ψ policies are monotone, bounded, table‑backed; penalties route to `R_eff` only (F/G invariant).**  \n\n#### G.13:4.3 - Interop specialisations (worked patterns; all conceptual)\n\n* **OpenAlex‑class mapper.** Works/Authors/Concepts → `ClaimSheet`(Problem/Method/Result) + SoS features (e.g., growth, disruption, collaboration breadth); Concept graph crossings publish **Bridge ids** with **Φ** penalties to **R_eff**.\n* **ORKG‑class mapper (claim‑level).** ResearchProblem/Contribution/Comparison → `ClaimSheet` + **SoS‑LOG** rule hints (admit/degrade/abstain branches tied to evidence lanes and maturity rungs). Thresholds remain in **G.4 Acceptance**. \n* **PRISMA‑class artefacts.** Systematic‑review metadata mapped to **EvidenceGraph** anchors (A.10 lanes, freshness windows) to back **C.23** decisions; PathIds cited at run‑time in SCR. \n\n> **OEE/QD parity.** When interop powers **GeneratorFamily** work (e.g., importing environment families or transfer rules from external corpora), **pin `TransferRulesRef.edition`** and publish coverage/regret as **telemetry metrics**; selection returns **{environment, method}** portfolios. \n",
        "interfaces_—_minimal_i/o_standard_(conceptual;_core‑only)": "### G.13:5 - Interfaces — minimal I/O standard (conceptual; Core‑only)\n\n| ID                                  | Interface                                                  | Consumes                                                     | Produces                                                                 |\n| ----------------------------------- | ---------------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------------------ |\n| **G.13‑1 `Register_ExternalIndex`** | `ExternalIndexCard` fields                                 | Provider metadata, scope, **Edition**, freshness             | `ExternalIndexCard@Context` (UTS row; twin labels)                       |\n| **G.13‑2 `Map_ClaimsToFPF`**        | `ExternalIndexCard`, mapper embedding specs (`PlaneMap`, `ScaleEmbeddingSpec`), A.10 anchors | Claim entities, taxonomies                                   | `ClaimSheet@Context`, `BridgeHints`, PathId anchors (conceptual)         |\n| **G.13‑3 `Derive_SoSFeatures`**     | ClaimSheets, CG‑Spec ids, CSLC stubs                       | typed SoS features                                           | `SoSFeatureSet@Context` (CHR‑typed; planes & units declared; **ordinal → compare‑only**) |\n| **G.13‑4 `Publish_InteropSurface`** | G.13‑2/‑3 outputs                                          | parity pins (windows, **editions**), planes, bridges, scale embeddings | `InteropSurface@Context` (UTS row; selector/dashboard‑readable)          |\n| **G.13‑5 `Emit_IndexTelemetryPin`** | Edition bump / policy change                               | Index & edition, PathSlice?, policy‑id?                      | Telemetry to **G.11** (`PathSliceId`, **policy‑id**, active editions; **editions appear only on `…Ref`**)    |\n| **G.13‑6 `Wire_To_SoTA_Pack`**      | InteropSurface + G.1–G.8 outputs                           | SoTA shipping data                                           | **G.10** pack hooks (conceptual surfaces; Annex maps to ORKG/OpenAlex).  |\n",
        "archetypal_grounding": "### G.13:6 - Archetypal Grounding (informative; SoTA‑oriented)\n\n**System.** *Software architecture portfolio design.* Import OpenAlex “software architecture” concept neighbourhood; map to ClaimSheets of architectural tactics. Feed **G.5** to select a **Pareto set** of tactics under cost/performance/reliability; publish **Bridge/Φ** ids for any cross‑context reuse; **IlluminationSummary** remains a **report-only telemetry summary**.  \n\n**Episteme.** *Science‑of‑science discipline dashboard.* Use ORKG comparison graphs to derive SoS features (replication coverage, standardisation rate, disruption balance) as **CHR‑typed** characteristics for **C.21** DHC slots; publish on UTS with twins; **G.11** refreshes slices when index **Edition** changes. \n\n**OEE/QD.** *Open‑ended environment generation.* Import external environment taxonomies; register a **GeneratorFamily** with `EnvironmentValidityRegion` and **`TransferRulesRef.edition`**; selector returns **{environment, method}** portfolios; coverage/regret are **report-only telemetry**. \n",
        "bias‑annotation": "### G.13:7 - Bias‑Annotation\n\n* **Didactic lens.** Tech/Plain twins at publication; no vendor/tool tokens. \n* **Architectural lens.** **No forced scalarisation**; dominance defaults to **ParetoOnly**; illumination & coverage are **report-only telemetry metrics** unless CAL promotes.  \n* **Epistemic lens.** Plane crossings publish **Φ(CL)**/**Φ_plane** ids; penalties reduce **R_eff** only; **F/G invariant**. \n",
        "conformance_checklist": "### G.13:8 - Conformance Checklist (CC‑G13, conceptual; applies when G.13 surfaces are used)\n\n1. **Notation‑independence.** Interop surfaces are **conceptual**; any serialisation lives in **Annex/Interop**; Core conformance is judged on semantics only. \n2. **CHR legality.** Every numeric SoS feature **MUST** bind to **CG‑Spec** with declared **Scale kind, units, polarity, ReferencePlane** and **CSLC** legality; ordinal measures are **never** averaged/subtracted. \n3. **Bridges & planes.** Cross‑context/plane reuse **MUST** cite **Bridge ids** and **Φ(CL)**/**Φ_plane** (and **Ψ(CL^k)** when a KindBridge is involved) **policy‑ids**; **Φ/Ψ policies SHALL be monotone, bounded, table‑backed**; penalties route to **`R_eff` only**; **F/G invariant**. \n4. **Edition discipline.** Interop outputs **SHALL** pin index **Edition** and echo it in parity pins; QD/OEE interop also pins `DescriptorMapRef.edition`, `DistanceDefRef.edition`, and (OEE) **`TransferRulesRef.edition`**. **Edition fields SHALL appear only on `…Ref` objects.**  \n5. **Telemetry defaults.** **IlluminationSummary** (telemetry summary) and any coverage/regret (telemetry metrics) **SHALL** be treated as **report‑only telemetry** and **excluded from dominance** unless a CAL policy promotes them (policy‑id appears in **SCR**). \n6. **Selector invariants.** Any selection spawned from interop **MUST** use **G.5** and **return sets** (Pareto/Archive) under lawful orders; no scalarisation is introduced by interop. \n7. **GateCrossing visibility (CrossingSurface).** All crossings must publish **CrossingSurface** (**E.18:CrossingSurface**); missing/non‑conformant surface or impure lanes **blocks publication**. \n",
        "consequences": "### G.13:9 - Consequences\n\n* **Generation‑first interop.** External indexes become **inputs to method generation** (palettes, portfolios, OEE seeds), not just audit decorations.\n* **Edition‑aware parity & refresh.** Index updates trigger **slice‑scoped** recomputation via **G.11**; parity pins stay lawful; dashboards remain stable. \n* **Trans‑disciplinary hygiene.** Bridge/plane publication prevents “phlogiston‑like” pseudo‑disciplines from entering Core without loss notes and penalties to **R** only. \n",
        "rationale": "### G.13:10 - Rationale\n\n**FPF is a creativity framework, not an audit checklist.** By making **claim‑level interop** a first‑class conceptual layer, **G.13** routes SoS signals into the **generation loop** (G.2→G.5→G.9) while preserving Core invariants: notation independence, lawful orders, UNM/NormalizationMethod semantics, and plane‑aware penalties. The result is faster, safer SoTA authoring that remains **auditable, edition‑aware, and modular**.\n",
        "relations": "### G.13:11 - Relations\n\n**Builds on:** **G.2**, **G.5**, **G.6**, **G.7**, **G.8**, **G.9**, **G.10**, **G.11**, **G.12**, **C.21**, **C.23**, **E.5.2**, **E.18**. \n**Publishes to:** **UTS** (twin labels) and **G.10** shipping surfaces; **G.11** via telemetry pins.  \n**Constrains:** Any interop consumer that claims FPF conformance **must** respect telemetry/dominance defaults, parity pins, and plane/bridge publication.\n",
        "author’s_quick_checklist": "### G.13:12 - Author’s quick checklist\n\n1. **Card the source.** Register `ExternalIndexCard` with **Edition**, Plane, and FreshnessWindow.\n2. **Map claims with legality.** Write `ClaimMapperCard` including **ScaleEmbeddingSpec** and **PlaneMap**; attach A.10 anchors; supply CSLC stubs. \n3. **Type SoS features.** Bind to **CG‑Spec** (units/scale/polarity/plane); forbid ordinal averages. \n4. **Pin parity.** Echo index **Edition**; if QD/OEE, also pin `DescriptorMapRef`/`DistanceDefRef`/(OEE) `TransferRulesRef`.  \n5. **Feed generation.** Call **G.5** (set‑returning) via **G.9** parity; keep illumination/coverage as **report-only telemetry**. \n6. **Ship conceptually.** Publish `InteropSurface@Context` and pack via **G.10** (no file formats in Core). \n7. **Refresh on telemetry.** Emit `IndexTelemetryPin` on edition changes or policy changes; let **G.11** plan **slice‑scoped** refresh; ensure **GateCrossing/CrossingSurface** checks (E.18/A.21/A.27) pass.\n",
        "sota_echoing": "### G.13:13 SoTA-Echoing (post‑2015, for orientation)\n\n* **Quality‑Diversity / Illumination.** MAP‑Elites and its successors (CVT‑MAP‑Elites, CMA‑ME/MAE, Differentiable QD incl. MEGA‑variants, QDax JMLR 2024, SAIL) — portfolio‑first exploration with **Q/D/QD‑score** telemetry metrics.\n* **Open‑Ended Evolution.** POET / Enhanced‑POET and **Darwin Gödel Machine**‑class algorithms — `{environment, method}` portfolios with **coverage/regret** as telemetry metrics; **`TransferRulesRef.edition`** pinned. \n",
        "g.13:end": "### G.13:End\n\n# **Part H – Glossary & Definitional Pattern Index**\n\n| §   | ID & Title                     | Concise reminder                                               |\n| --- | ------------------------------ | ---- | -------------------------------------------------------------- |\n| H.1 | Alphabetic Glossary            |  Every `U.Type`, relation & operator with four‑register naming. |\n| H.2 | Definitional Pattern Catalogue |  One‑page micro‑stubs of every definitional pattern for quick lookup.  |\n| H.3 | Cross‑Reference Maps           |  Bidirectional links: Part A ↔ Part C ↔ Part B terms.           |\n\n\n# **Part I – Annexes & Extended Tutorials**\n\n| §   | ID & Title                  |  Concise reminder                                                |\n| --- | --------------------------- | --- | --------------------------------------------------------------- |\n| I.1 | Deprecated Aliases          |  Legacy names kept for backward compatibility.                   |\n| I.2 | Detailed Walk‑throughs      |  Step‑by‑step modelling of a pump + proof + dev‑ops pipeline.    |\n| I.3 | Change‑Log (auto‑generated) |  Version history keyed to DRR ids.                               |\n| I.4 | External Standards Mappings |  Trace tables to ISO 15926, BORO, CCO, Constructor‑Theory terms. |\n\n\n# **Part J – Indexes & Navigation Aids**\n\n| §   | ID & Title               |  Concise reminder                                        |\n| --- | ------------------------ | --- | ------------------------------------------------------- |\n| J.1 | Concept‑to‑Pattern Index |  Quick jump from idea (“boundary”) to pattern (§, id).   |\n| J.2 | Pattern‑to‑Example Index |  Table listing every archetypal grounding vignette.      |\n| J.3 | Principle‑Trace Index    |  Maps each Pillar / C‑rule / P‑rule to concrete clauses. |\n\n# **Part K  – Lexical debt**\n## Mandatory replacement map for measurement terms\n\n> **Rule:** In all **normative** content (specifications, data schemas, etc.), the deprecated terms **“axis”** and **“dimension”** (and their plural or compound forms) **MUST NOT** be used to denote a measurable aspect. Use **Characteristic** in the Tech register instead. Other colloquial terms should be mapped to canonical terms as listed below. In **Plain** narrative, the legacy words may appear _only on first use_ and only if paired with their canonical equivalent for clarity.\n\n| Legacy Term (context) | **Replace with** (Tech register) | Plain register allowance | Canonical Reference |\n| --- | --- | --- | --- |\n| axis (of measurement); dimension (of a system or quality) | **(disallowed in Core prose)** → use **Characteristic** | No parenthetical allowance in Core; use **Characteristic / Measure / Coordinate** only | A.17 (CHR-NORM) |\n| point (on an axis); data point | **Coordinate** (on a Scale) | “point” _(in explanations only, e.g. “a point on the scale”)_ | A.18 (CSLC-KERNEL) |\n| metric value; raw score | **Coordinate** (or **Value**) | “value” _(acceptable in plain usage when context is clear, but formally it’s a Coordinate tied to a Characteristic)_ | A.18, C.16 |\n| score (composite or normalized) | **Score** (produced via a **ScoringMethod**) | “score” _(if needed in narrative, ensure it’s explained as a result of a defined ScoringMethod)_ | A.17/A.18 (ScoringMethod/Score) |\n| unit dimension; unit axis | **Unit** (of a Scale) | “unit” _(plain usage okay)_ | A.18 (Scale/Unit) |\n| metric (as a noun) | **Avoid in Tech and as primitive** → use **`U.DHCMethodRef` / `U.Measure` / Score** | “metric” _(Plain only on first use, with pointer to canonical terms)_ | C.16 § 5.1 (L5), A.18 |\n\n## Migration debt from A.2.6 (Scope, ClaimScope, WorkScope)\n",
        "deprecations_(normative)": "### Deprecations (normative)\n\nThe following terms **MUST NOT** name scope characteristics in normative text, guards, or conformance blocks:\n\n* *applicability*, *envelope*, *generality*, *capability envelope*, *validity* (as a characteristic name).\n\nUse instead:\n\n* **`U.ClaimScope`** (*Claim scope*, nick **G**) for epistemes;\n* **`U.WorkScope`** (*Work scope*) for capabilities;\n* **`U.Scope`** only when explaining the abstract mechanism (not in guards).\n",
        "affected_locations_and_required_edits_(normative)": "### Affected locations and required edits (normative)\n\nEditors SHALL apply the following replacements:\n\n1. **Part C.2.2 (F–G–R).**\n\n   * Replace any internal definition of “Generality” with a normative reference to **A.2.6 §6.3** (*Claim scope (G)*).\n   * Where “abstraction level” is mentioned as G, replace with “Claim scope (where the claim holds)”; keep **AT** (AbstractionTier) only as optional didactics (non‑G).\n   * Ensure composition examples use **intersection/SpanUnion** for G, not ordinal “more/less general”.\n\n2. **Part C.2.3 (Formality F).**\n\n   * No change to F itself.\n   * Any example that implies “raising F widens G” MUST be rephrased: F changes expression form; G changes only via **ΔG**.\n\n3. **Part A.2.2 (Capabilities).**\n\n   * Replace “capability envelope/applicability” with **`U.WorkScope`**.\n   * Method–Work gates MUST test **Work scope covers JobSlice**, with **measures** and **qualification windows** bound.\n\n4. **Part B (Bridges & CL).**\n\n   * Add a note: **CL penalties apply to R**, not to **F/G**; mapping MAY recommend **narrowing** the mapped scope (best practice).\n\n5. **Part E (Lexicon).**\n\n   * Add entries for **Claim scope (G)**, **Work scope**, **Scope** (mechanism).\n   * Mark listed deprecated terms as **legacy aliases** allowed only in explanatory notes.\n\n6. **ESG & Method–Work templates.**\n\n   * Replace any “applicability”/“envelope” guard phrasing with **ScopeCoverage** (see §10).\n   * Require explicit **`Γ_time`** selectors in all scope‑sensitive guards.\n",
        "migration_playbook_(informative)": "### Migration playbook (informative)\n\n1. **Inventory** scope‑like phrases across your Context (search: applicability, envelope, generality, capability envelope, valid\\*).\n2. **Classify** each occurrence as **Claim scope** (episteme) or **Work scope** (capability); replace any “scope characteristic(s)” with “scope type” or “USM scope object” depending on sentence grammar.\n3. **Rewrite** guards to use `Scope covers TargetSlice` + explicit **`Γ_time`**; remove “latest”.\n4. **Publish** any required **Bridges** with **CL** for Cross‑context usage.\n5. **Document** ΔG changes separately from evidence freshness (R).\n",
        "backwards_compatibility_(informative)": "### Backwards compatibility (informative)\n\nLegacy artifacts MAY keep their historical phrasing in body prose. All **guards, conformance checklists, and state assertions** MUST be rewritten to the USM terms and semantics.\n",
        "change_log_(normative_migration_record)": "### Change Log (normative migration record)\n\n* **A.2.6 introduced.** Defines `U.ContextSlice`, `U.Scope`, `U.ClaimScope (G)`, `U.WorkScope`; sets algebra and guard patterns.\n* **Deprecated labels.** “applicability / envelope / generality / capability envelope / validity” as characteristic names.\n* **Edits required.** C.2.2 (G = Claim scope), A.2.2 (Work scope for capabilities), Part B (CL→R note), Part E (Lexicon updates), ESG/Method–Work guard templates (ScopeCoverage + `Γ_time`).\n* **No change.** C.2.3 (F) unchanged; its examples updated only for wording consistency.\n## Navigation Links\n\n- **Parent**: [Project Overview](../README.md)\n- **Module Index**: [All Agents](../../AGENTS.md)\n- **Documentation**: [Reference Guides](../../../docs/README.md)\n- **Home**: [Root README](../../../README.md)\n"
      },
      "content": "### Change Log (normative migration record)\n\n* **A.2.6 introduced.** Defines `U.ContextSlice`, `U.Scope`, `U.ClaimScope (G)`, `U.WorkScope`; sets algebra and guard patterns.\n* **Deprecated labels.** “applicability / envelope / generality / capability envelope / validity” as characteristic names.\n* **Edits required.** C.2.2 (G = Claim scope), A.2.2 (Work scope for capabilities), Part B (CL→R note), Part E (Lexicon updates), ESG/Method–Work guard templates (ScopeCoverage + `Γ_time`).\n* **No change.** C.2.3 (F) unchanged; its examples updated only for wording consistency.\n## Navigation Links\n\n- **Parent**: [Project Overview](../README.md)\n- **Module Index**: [All Agents](../../AGENTS.md)\n- **Documentation**: [Reference Guides](../../../docs/README.md)\n- **Home**: [Root README](../../../README.md)\n",
      "metadata": {},
      "part": "G",
      "cluster": null
    }
  ],
  "concepts": [
    {
      "name": "U.BoundedContext",
      "definition": "FPF elevates **semantic framing** to a kernel primitive by introducing `U.BoundedContext` as a first-class holon of meaning.\nInspired by Domain-Driven Design (DDD) but generalized beyond software, a bounded context is not a mere namespace: it is **a governable model locale** with explicit vocabulary, rules, and role taxonomy.",
      "pattern_id": "A.1.1",
      "type": "U.Type",
      "references": [
        "A.1.1"
      ],
      "aliases": [],
      "metadata": {}
    },
    {
      "name": "U.RoleAssignment",
      "definition": "Defined in pattern A.2.1: U.RoleAssignment: Contextual Role Assignment",
      "pattern_id": "A.2.1",
      "type": "U.Type",
      "references": [
        "A.2.1"
      ],
      "aliases": [],
      "metadata": {}
    },
    {
      "name": "U.ServiceClause",
      "definition": "### A.2.3:4 - Solution — The unified concept `U.ServiceClause`\n\n**Definition (normative).**",
      "pattern_id": "A.2.3",
      "type": "U.Type",
      "references": [
        "A.2.3"
      ],
      "aliases": [],
      "metadata": {}
    },
    {
      "name": "U.EvidenceRole",
      "definition": "`U.EvidenceRole` — a **non-behavioural role** that a `U.Episteme` may play **inside a `U.BoundedContext`** to serve as **evidence** for a declared target claim (or theory/version).\nThe target claim, its applicability scope, polarity, weighting model, and other normative facets are **properties of the `U.EvidenceRole` definition itself** *within that bounded context*.",
      "pattern_id": "A.2.4",
      "type": "U.Type",
      "references": [
        "A.2.4"
      ],
      "aliases": [],
      "metadata": {}
    },
    {
      "name": "U.RoleStateGraph",
      "definition": "Defined in pattern A.2.5: U.RoleStateGraph: The Named State Space of a Role",
      "pattern_id": "A.2.5",
      "type": "U.Type",
      "references": [
        "A.2.5"
      ],
      "aliases": [],
      "metadata": {}
    },
    {
      "name": "U.RoleAlgebra",
      "definition": "Defined in pattern A.2.7: U.RoleAlgebra: In‑Context Role Relations",
      "pattern_id": "A.2.7",
      "type": "U.Type",
      "references": [
        "A.2.7"
      ],
      "aliases": [],
      "metadata": {}
    },
    {
      "name": "U.Commitment",
      "definition": "* **(SA‑C4) If used for gating/audit, it must be observable.** If a speech act is used as a checklist criterion, guard condition, or provenance hook for a `U.Commitment`, the model **SHALL** include at least one observable handle: `utteranceRefs` and/or `carrierRefs`. When the act is used as evidence, at least one carrier reference **SHOULD** be SCR/RSCR‑resolvable per A.10.\n* **(SA‑C5) Institutional effects are references, not paraphrases.** When the act is intended to institute/update commitments, role assignments, or statuses, `institutes.*` **SHOULD** reference the corresponding object IDs/claim IDs rather than restating content.\n* **(SA‑C6) Cross-context use is Bridge-only.** If a `SpeechActRef` is used for checking/gating/provenance in a **different bounded context** than the act’s judgement context, the referencing object **MUST** satisfy the spec’s cross-context discipline by citing an explicit Bridge/policy that licenses the interpretation (and surfacing congruence vs loss where applicable), rather than assuming equivalence by label.",
      "pattern_id": "A.2.8",
      "type": "U.Type",
      "references": [
        "A.2.8"
      ],
      "aliases": [],
      "metadata": {}
    },
    {
      "name": "U.Method",
      "definition": "**`U.Method`** is a **context‑defined abstract transformation type**—the **semantic “way of doing”** a kind of work.  \nIt is:\n**Described** (never *identical*) by one or more **`U.MethodDescription`** epistemes (code/SOP/diagram/rules),",
      "pattern_id": "A.3.1",
      "type": "U.Type",
      "references": [
        "A.3.1",
        "A.3.2"
      ],
      "aliases": [],
      "metadata": {}
    },
    {
      "name": "U.MethodDescription",
      "definition": "**`U.MethodDescription`** is an **`U.Episteme`** that **describes a `U.Method`** in a concrete representation (text, code, diagram, model). It is **knowledge on a carrier** that can be reviewed and validated; at run-time a **`U.System`** **uses it to execute the `U.Method` as `U.Work` under a `U.RoleAssignment`**.\n\n> **Strict Distinction (memory aid):**",
      "pattern_id": "A.3.2",
      "type": "U.Type",
      "references": [
        "A.3.2"
      ],
      "aliases": [],
      "metadata": {}
    },
    {
      "name": "U.Dynamics",
      "definition": "### A.3.3:4 - Solution — The unified concept `U.Dynamics`\n\n**Definition (normative).**",
      "pattern_id": "A.3.3",
      "type": "U.Type",
      "references": [
        "A.3.3"
      ],
      "aliases": [],
      "metadata": {}
    },
    {
      "name": "U.Signature",
      "definition": "### A.6.0:4 - Solution — **Define `U.Signature` once, reuse everywhere**\n\n**Definition.** A **`U.Signature`** is a **public, law-governed declaration** for a named **SubjectKind** on a declared **BaseType**. Where quantification depends on context, the Signature **SHALL** expose an explicit **SliceSet** and **ExtentRule**. A Signature (i) introduces a **vocabulary** (types, relations, operators), (ii) states **laws** (axioms/invariants; no operational admissions), and (iii) records **applicability** (where and under which contextual assumptions the declarations hold). Dependencies (**imports**) are governed by specialisations (e.g., A.6.A) and are **not** part of the universal Block. **Discipline for argument-position typing is delegated to A.6.5 `U.RelationSlotDiscipline`: whenever the Vocabulary declares an n-ary relation or operator, SlotSpecs for its parameter positions SHALL be provided as in §4.1.1 and A.6.5.**",
      "pattern_id": "A.6.0",
      "type": "U.Type",
      "references": [
        "A.6.0",
        "A.6.S"
      ],
      "aliases": [],
      "metadata": {}
    },
    {
      "name": "U.Mechanism",
      "definition": "A `U.Mechanism` **publishes**  \n        `U.Mechanism.Intension := ⟨IntensionHeader, Imports,\n                SubjectBlock := ⟨SubjectKind, BaseType, SliceSet, ExtentRule, ResultKind?⟩,",
      "pattern_id": "A.6.1",
      "type": "U.Type",
      "references": [
        "A.6.1"
      ],
      "aliases": [],
      "metadata": {}
    },
    {
      "name": "U.EffectFreeEpistemicMorphing",
      "definition": "### A.6.2:4 - Solution — define `U.EffectFreeEpistemicMorphing` once\n\n#### A.6.2:4.1 - Informal definition",
      "pattern_id": "A.6.2",
      "type": "U.Type",
      "references": [
        "A.6.2"
      ],
      "aliases": [],
      "metadata": {}
    },
    {
      "name": "U.EpistemicViewing",
      "definition": "### A.6.3:4 - Solution — `U.EpistemicViewing` as EFEM profile (`describedEntityChangeMode = preserve`)\n\n#### A.6.3:4.1 - Informal definition",
      "pattern_id": "A.6.3",
      "type": "U.Type",
      "references": [
        "A.6.3"
      ],
      "aliases": [],
      "metadata": {}
    },
    {
      "name": "U.EpistemicRetargeting",
      "definition": "Defined in pattern A.6.4: `U.EpistemicRetargeting` — describedEntity‑retargeting morphism",
      "pattern_id": "A.6.4",
      "type": "U.Type",
      "references": [
        "A.6.4"
      ],
      "aliases": [],
      "metadata": {}
    },
    {
      "name": "U.RelationSlotDiscipline",
      "definition": "`U.RelationSlotDiscipline` extends `U.Signature` with a **three‑layer description** for every argument position (whether we call it “parameter”, “slot”, “coordinate”, or “port” in colloquial prose).\nIn **normative** text, the canonical word is **slot**, and the canonical carrier is a **SlotSpec** triple (A.6.0).",
      "pattern_id": "A.6.5",
      "type": "U.Type",
      "references": [
        "A.6.5"
      ],
      "aliases": [],
      "metadata": {}
    },
    {
      "name": "U.BaseDeclarationDiscipline",
      "definition": "Defined in pattern A.6.6: U.BaseDeclarationDiscipline - Kind-explicit, scoped, witnessed base declaration discipline (with base-change lexicon)",
      "pattern_id": "A.6.6",
      "type": "U.Type",
      "references": [
        "A.6.6"
      ],
      "aliases": [],
      "metadata": {}
    },
    {
      "name": "U.SignatureEngineeringPair",
      "definition": "A.6.S names this pairing discipline **U.SignatureEngineeringPair**: a signature engineering arrangement where a ConstructorSignature is explicitly defined for (at least) one Signature‑of‑Interest.\nA.6.S names this pairing discipline **U.SignatureEngineeringPair**: a signature engineering arrangement where a ConstructorSignature is explicitly defined for (at least) one TargetSignature.",
      "pattern_id": "A.6.S",
      "type": "U.Type",
      "references": [
        "A.6.S"
      ],
      "aliases": [],
      "metadata": {}
    },
    {
      "name": "V - Constitutional Principle",
      "definition": "Defined in pattern A.6.S: U.SignatureEngineeringPair - Signature engineering via a ConstructorSignature and a TargetSignature",
      "pattern_id": "A.6.S",
      "type": "Principle",
      "references": [
        "A.6.S"
      ],
      "aliases": [],
      "metadata": {}
    },
    {
      "name": "U.Work",
      "definition": "### A.15.1:4 - Solution — define `U.Work` as the accountable, dated occurrence\n\n#### A.15.1:4.1 - Definition",
      "pattern_id": "A.15.1",
      "type": "U.Type",
      "references": [
        "A.15.1",
        "A.15.2",
        "G.13"
      ],
      "aliases": [],
      "metadata": {}
    },
    {
      "name": "U.WorkPlan",
      "definition": "### A.15.2:4 - Solution — the `U.WorkPlan` as the time‑bound intention to execute Work\n\n#### A.15.2:4.1 - Definition",
      "pattern_id": "A.15.2",
      "type": "U.Type",
      "references": [
        "A.15.2"
      ],
      "aliases": [],
      "metadata": {}
    },
    {
      "name": "U.Flow",
      "definition": "Defined in pattern A.20: U.Flow.ConstraintValidity — Eulerian",
      "pattern_id": "A.20",
      "type": "U.Type",
      "references": [
        "A.20"
      ],
      "aliases": [],
      "metadata": {}
    },
    {
      "name": "U.Episteme",
      "definition": "### C.2.1:4 - Solution — from outdated semantic triangle to `U.EpistemeSlotGraph`\n\n#### C.2.1:4.0 - Overview",
      "pattern_id": "C.2.1",
      "type": "U.Type",
      "references": [
        "C.2.1"
      ],
      "aliases": [],
      "metadata": {}
    },
    {
      "name": "U.Kind",
      "definition": "* **`U.Kind`** — a **context‑local intensional** object naming a “kind of thing” claims may quantify over.\n* **`U.SubkindOf (⊑)`** — a **partial order** on kinds (reflexive, transitive, antisymmetric). `k₁ ⊑ k₂` reads “`k₁` refines `k₂`.”",
      "pattern_id": "C.3.1",
      "type": "U.Type",
      "references": [
        "C.3.1"
      ],
      "aliases": [],
      "metadata": {}
    },
    {
      "name": "U.Discipline",
      "definition": "* **`U.Discipline`** — a **Holon** that composes an **EpistemeCanon**, **Standards/Practices**, and **Organisational Carriers** into a durable **unit of talk** (R‑core name; twin labels).  \n* **`U.AppliedDiscipline`**, **`U.Transdiscipline`** — subtypes of `U.Discipline`.  (**Kernel U‑types; LEX‑governed**).\n* **`U.Tradition`**, **`U.Lineage`** — auxiliary holons that organise variants/editions within a `U.Discipline`.",
      "pattern_id": "C.20",
      "type": "U.Type",
      "references": [
        "C.20"
      ],
      "aliases": [],
      "metadata": {}
    },
    {
      "name": "U.System",
      "definition": "* **Carrier.** `U.System | U.ServiceClause | U.Episteme` (what bears the quality).  \n* **ClaimScope / WorkScope.** **USM** set(s) over `U.ContextSlice` (where the claim holds / where the capability can deliver). **Set‑valued; not CHR.**  (A.2.6 § 6.2).  \n* **Measures[CHR].** One or more **CHR Characteristics bound to one Scale each** (e.g., `AvailabilityRatio[%]`, `RTO[min]`). **These are the measurable slots.** (C.16/A.18).",
      "pattern_id": "C.25",
      "type": "U.Type",
      "references": [
        "C.25"
      ],
      "aliases": [],
      "metadata": {}
    },
    {
      "name": "U.Agent",
      "definition": "Defined in pattern C.25: Q‑Bundle: Authoring “‑ilities” as Structured Quality Bundles",
      "pattern_id": "C.25",
      "type": "U.Type",
      "references": [
        "C.25"
      ],
      "aliases": [],
      "metadata": {}
    },
    {
      "name": "Axiological Neutrality Principle",
      "definition": "Defined in pattern C.25: Q‑Bundle: Authoring “‑ilities” as Structured Quality Bundles",
      "pattern_id": "C.25",
      "type": "Principle",
      "references": [
        "C.25"
      ],
      "aliases": [],
      "metadata": {}
    },
    {
      "name": "U.MultiViewDescribing",
      "definition": "### E.17.0:4 - Solution — `U.MultiViewDescribing` as the universal multi‑view scaffold  *(normative core)*\n\n#### E.17.0:4.1 - Overview",
      "pattern_id": "E.17.0",
      "type": "U.Type",
      "references": [
        "E.17.0"
      ],
      "aliases": [],
      "metadata": {}
    },
    {
      "name": "U.ViewpointBundleLibrary",
      "definition": "### E.17.1:4 - Solution — `U.ViewpointBundleLibrary`  *(normative core)*\n\n#### E.17.1:4.1 - Overview",
      "pattern_id": "E.17.1",
      "type": "U.Type",
      "references": [
        "E.17.1"
      ],
      "aliases": [],
      "metadata": {}
    },
    {
      "name": "U.Types",
      "definition": "Defined in pattern F.5: Naming Discipline for U.Types & Roles",
      "pattern_id": "F.5",
      "type": "U.Type",
      "references": [
        "F.5"
      ],
      "aliases": [],
      "metadata": {}
    },
    {
      "name": "U.Type",
      "definition": "Defined in pattern F.8: Mint or Reuse? (U.Type vs Concept-Set vs Role Description vs Alias)",
      "pattern_id": "F.8",
      "type": "U.Type",
      "references": [
        "F.5",
        "F.8"
      ],
      "aliases": [],
      "metadata": {}
    },
    {
      "name": "U.WorkScope",
      "definition": "Defined in pattern G.13: External Interop Hooks for SoTA Discipline Packs (conceptual)",
      "pattern_id": "G.13",
      "type": "U.Type",
      "references": [
        "G.13"
      ],
      "aliases": [],
      "metadata": {}
    },
    {
      "name": "U.ClaimScope",
      "definition": "Defined in pattern G.13: External Interop Hooks for SoTA Discipline Packs (conceptual)",
      "pattern_id": "G.13",
      "type": "U.Type",
      "references": [
        "G.13"
      ],
      "aliases": [],
      "metadata": {}
    },
    {
      "name": "U.Scope",
      "definition": "Defined in pattern G.13: External Interop Hooks for SoTA Discipline Packs (conceptual)",
      "pattern_id": "G.13",
      "type": "U.Type",
      "references": [
        "G.13"
      ],
      "aliases": [],
      "metadata": {}
    },
    {
      "name": "U.ContextSlice",
      "definition": "Defined in pattern G.13: External Interop Hooks for SoTA Discipline Packs (conceptual)",
      "pattern_id": "G.13",
      "type": "U.Type",
      "references": [
        "G.13"
      ],
      "aliases": [],
      "metadata": {}
    }
  ],
  "relationships": [],
  "table_of_contents": {
    "preface": [],
    "parts": {
      "A": [
        "| § | ID & Title | Status | Keywords & Search Queries | Dependencies |",
        "| § | ID & Title | Status | Keywords & Search Queries | Dependencies |",
        "| § | ID & Title | Status | Keywords & Search Queries | Dependencies |"
      ],
      "D": [
        "| § | ID & Title | Status | Keywords & Search Queries | Dependencies |"
      ],
      "E": [
        "| § | ID & Title | Status | Keywords & Search Queries | Dependencies |",
        "| § | ID & Title | Status | Keywords & Search Queries | Dependencies |"
      ],
      "G": [
        "| § | ID & Title | Status | Keywords & Search Queries | Dependencies |"
      ],
      "H": [
        "| § | ID & Title |  Status | Concise reminder |"
      ],
      "I": [
        "| § | ID & Title | Status | Concise reminder |"
      ],
      "J": [
        "| § | ID & Title | Status | Concise reminder |",
        "| J.1 | **Concept‑to‑Pattern Index** | stub | Quick jump from idea (“boundary”) to pattern (§, id). |"
      ],
      "K": [
        "| § | ID & Title | Status | Concise content reminder — “what belongs here” |"
      ]
    },
    "sections": []
  }
}